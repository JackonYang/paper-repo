{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145749654"
                        ],
                        "name": "M. Rattray",
                        "slug": "M.-Rattray",
                        "structuredName": {
                            "firstName": "Magnus",
                            "lastName": "Rattray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rattray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2506116"
                        ],
                        "name": "D. Saad",
                        "slug": "D.-Saad",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Saad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Saad"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 219
                            }
                        ],
                        "text": "Orr (1995) found that in the late, annealing phase of learning, matrix momentum converges at optimal (second-order) asymptotic rates; this has been confirmed by subsequent analysis in a statistical mechanics framework (Rattray & Saad, 1999; Scarpetta, Rattray, & Saad, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 122
                            }
                        ],
                        "text": "Instead, it is thought to be a consequence of the noise inherent in the stochastic approximation of the curvature matrix (Rattray & Saad, 1999; Scarpetta et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 116644481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55cc3685811a4c3366800914aab144408dbdce20",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyse the dynamics of a number of second order on-line learning algorithms training multi-layer neural networks, using the methods of statistical mechanics. We first consider on-line Newton's method, which is known to provide optimal asymptotic performance. We determine the asymptotic generalization error decay for a soft committee machine, which is shown to compare favourably with the result for standard gradient descent. Matrix momentum provides a practical approximation to this method by allowing an efficient inversion of the Hessian. We consider an idealized matrix momentum algorithm which requires access to the Hessian and find close correspondence with the dynamics of on-line Newton's method. In practice, the Hessian will not be known on-line and we therefore consider matrix momentum using a single example approximation to the Hessian. In this case good asymptotic performance may still be achieved, but the algorithm is now sensitive to parameter choice because of noise in the Hessian estimate. On-line Newton's method is not appropriate during the transient learning phase, since a suboptimal unstable fixed point of the gradient descent dynamics becomes stable for this algorithm. A principled alternative is to use Amari's natural gradient learning algorithm and we show how this method provides a significant reduction in learning time when compared to gradient descent, while retaining the asymptotic performance of on-line Newton's method."
            },
            "slug": "Incorporating-curvature-information-into-on-line-Rattray-Saad",
            "title": {
                "fragments": [],
                "text": "Incorporating curvature information into on-line learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Amari's natural gradient learning algorithm is used and it is shown how this method provides a significant reduction in learning time when compared to gradient descent, while retaining the asymptotic performance of on-line Newton's method."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34782608"
                        ],
                        "name": "G. Orr",
                        "slug": "G.-Orr",
                        "structuredName": {
                            "firstName": "Genevieve",
                            "lastName": "Orr",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3222903"
                        ],
                        "name": "T. Leen",
                        "slug": "T.-Leen",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Leen",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 92
                            }
                        ],
                        "text": "We then examine two learning algorithms that use this approach: matrix momentum (Orr, 1995; Orr & Leen, 1997) and stochastic meta-descent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 165
                            }
                        ],
                        "text": "We know of two neural network learning algorithms that combine the O(n) curvature matrix-vector product with iteration 1.1 in some form: matrix momentum (Orr, 1995; Orr & Leen, 1997) and our own stochastic metadescent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 195
                            }
                        ],
                        "text": "Current implementations therefore rely on simple (first-order) stochastic gradient descent initially, turning on matrix momentum only once the vicinity of an optimum has been reached (Orr,\n1995; Orr & Leen, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17683874,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08cd6e1a08a09ebe7eff7b0dece2e4ef2264bfad",
            "isKey": true,
            "numCitedBy": 33,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for fast stochastic gradient descent that uses a nonlinear adaptive momentum scheme to optimize the late time convergence rate. The algorithm makes effective use of curvature information, requires only O(n) storage and computation, and delivers convergence rates close to the theoretical optimum. We demonstrate the technique on linear and large nonlinear backprop networks."
            },
            "slug": "Using-Curvature-Information-for-Fast-Stochastic-Orr-Leen",
            "title": {
                "fragments": [],
                "text": "Using Curvature Information for Fast Stochastic Search"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "An algorithm for fast stochastic gradient descent that uses a nonlinear adaptive momentum scheme to optimize the late time convergence rate and demonstrates the technique on linear and large nonlinear backprop networks."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688076"
                        ],
                        "name": "S. Scarpetta",
                        "slug": "S.-Scarpetta",
                        "structuredName": {
                            "firstName": "Silvia",
                            "lastName": "Scarpetta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Scarpetta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145749654"
                        ],
                        "name": "M. Rattray",
                        "slug": "M.-Rattray",
                        "structuredName": {
                            "firstName": "Magnus",
                            "lastName": "Rattray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rattray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2506116"
                        ],
                        "name": "D. Saad",
                        "slug": "D.-Saad",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Saad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Saad"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 164
                            }
                        ],
                        "text": "The instability of matrix momentum is not caused by lack of semidefiniteness on behalf of the curvature matrix: Orr (1995) used the Gauss-Newton approximation, and Scarpetta et al. (1999) reached similar conclusions for the Fisher information matrix."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 144
                            }
                        ],
                        "text": "Instead, it is thought to be a consequence of the noise inherent in the stochastic approximation of the curvature matrix (Rattray & Saad, 1999; Scarpetta et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8369169,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7f384384e1186151659f8044e7d0085a62dd370",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "An on-line learning rule, based on the introduction of a matrix momentum term, is presented, aimed at alleviating the computational costs of standard natural gradient learning. The new rule, natural gradient matrix momentum, is analysed in the case of two-layer feed-forward neural network learning via methods of statistical physics. It appears to provide a practical algorithm that performs as well as standard natural gradient descent in both the transient and asymptotic regimes but with a hugely reduced complexity."
            },
            "slug": "MATRIX-MOMENTUM-FOR-PRACTICAL-NATURAL-GRADIENT-Scarpetta-Rattray",
            "title": {
                "fragments": [],
                "text": "MATRIX MOMENTUM FOR PRACTICAL NATURAL GRADIENT LEARNING"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An on-line learning rule, based on the introduction of a matrix momentum term, appears to provide a practical algorithm that performs as well as standard natural gradient descent in both the transient and asymptotic regimes but with a hugely reduced complexity."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145468098"
                        ],
                        "name": "M. M\u00f8ller",
                        "slug": "M.-M\u00f8ller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "M\u00f8ller",
                            "middleNames": [
                                "Fodslette"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. M\u00f8ller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 33
                            }
                        ],
                        "text": "This fast Hessian-vector product (Pearlmutter, 1994; Werbos, 1988; M\u00f8ller, 1993) can be used in conjunction with equation 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 67
                            }
                        ],
                        "text": "This fast Hessian-vector product (Pearlmutter, 1994; Werbos, 1988; M\u00f8ller, 1993) can be used in conjunction with equation 1.1 to create an efficient, iterative O(n) implementation of Newton\u2019s method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15127497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "384094cff75cfa240d5acfe24cf340242c364847",
            "isKey": true,
            "numCitedBy": 27,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Several methods for training feed-forward neural networks require second order information from the Hessian matrix of the error function. Although it is possible to calculate the Hessian matrix exactly it is often not desirable because of the computation and memory requirements involved. Some learning techniques do, however, only need the Hessian matrix times a vector. This paper presents a method to calculate the Hessian matrix times a vector in O(N) time, where N is the number of variables in the network. This is the same order as the calculation of the gradient to the error function. The usefulness of this algorithm is demonstrated by improvement of existing learning techniques."
            },
            "slug": "Exact-Calculation-of-the-Product-of-the-Hessian-of-M\u00f8ller",
            "title": {
                "fragments": [],
                "text": "Exact Calculation of the Product of the Hessian Matrix of Feed-Forward Network Error Functions and a Vector in 0(N) Time"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method to calculate the Hessian matrix times a vector in O(N) time, where N is the number of variables in the network, which is the same order as the calculation of the gradient to the error function."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700974"
                        ],
                        "name": "Barak A. Pearlmutter",
                        "slug": "Barak-A.-Pearlmutter",
                        "structuredName": {
                            "firstName": "Barak",
                            "lastName": "Pearlmutter",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barak A. Pearlmutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 5
                            }
                        ],
                        "text": "(See Pearlmutter, 1994, for details and examples.)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 33
                            }
                        ],
                        "text": "This fast Hessian-vector product (Pearlmutter, 1994; Werbos, 1988; M\u00f8ller, 1993) can be used in conjunction with equation 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 34
                            }
                        ],
                        "text": "This fast Hessian-vector product (Pearlmutter, 1994; Werbos, 1988; M\u00f8ller, 1993) can be used in conjunction with equation 1.1 to create an efficient, iterative O(n) implementation of Newton\u2019s method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 231
                            }
                        ],
                        "text": "We have given algorithms that compute the product of either the Fisher information or our extended Gauss-Newton matrix with an arbitrary vector in O(n), similar to but even cheaper than the fast Hessian-vector product described by Pearlmutter (1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 150
                            }
                        ],
                        "text": "After f1-propagating E v forward throughN ,M, and L, r2-propagate RE v(1) = 0 back through the entire model (L,M, then N ) to obtain HE v = RE v(E g) (Pearlmutter, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 10
                            }
                        ],
                        "text": "Following Pearlmutter (1994), we define the Gateaux derivative\nREv(F( Ew)) \u2261 \u2202F( Ew+ rEv)\n\u2202r\n\u2223\u2223\u2223\u2223 r=0 = JF Ev, (4.1)\nwhich describes the effect on a functionF( Ew) of a weight perturbation in the direction of Ev."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 146
                            }
                        ],
                        "text": "After f1-propagating Ev forward throughN ,M, and L, r2-propagate REv(1) = 0 back through the entire model (L,M, then N ) to obtain HEv = REv(Eg) (Pearlmutter, 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1251969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6867b6b564462d6b902f68e0bfa58f4717ca1cc",
            "isKey": true,
            "numCitedBy": 586,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Just storing the Hessian H (the matrix of second derivatives 2E/wiwj of the error E with respect to each pair of weights) of a large neural network is difficult. Since a common use of a large matrix like H is to compute its product with various vectors, we derive a technique that directly calculates Hv, where v is an arbitrary vector. To calculate Hv, we first define a differential operator Rv{f(w)} = (/r)f(w rv)|r=0, note that Rv{w} = Hv and Rv{w} = v, and then apply Rv{} to the equations used to compute w. The result is an exact and numerically stable procedure for computing Hv, which takes about as much computation, and is about as local, as a gradient evaluation. We then apply the technique to a one pass gradient calculation algorithm (backpropagation), a relaxation gradient calculation algorithm (recurrent backpropagation), and two stochastic gradient calculation algorithms (Boltzmann machines and weight perturbation). Finally, we show that this technique can be used at the heart of many iterative techniques for computing various properties of H, obviating any need to calculate the full Hessian."
            },
            "slug": "Fast-Exact-Multiplication-by-the-Hessian-Pearlmutter",
            "title": {
                "fragments": [],
                "text": "Fast Exact Multiplication by the Hessian"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work derives a technique that directly calculates Hv, where v is an arbitrary vector, and shows that this technique can be used at the heart of many iterative techniques for computing various properties of H, obviating any need to calculate the full Hessian."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739396"
                        ],
                        "name": "N. Schraudolph",
                        "slug": "N.-Schraudolph",
                        "structuredName": {
                            "firstName": "Nicol",
                            "lastName": "Schraudolph",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Schraudolph"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 139
                            }
                        ],
                        "text": "We then examine two learning algorithms that use this approach: matrix momentum (Orr, 1995; Orr & Leen, 1997) and stochastic meta-descent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 247
                            }
                        ],
                        "text": "The learning rate update, equation 5.2, minimizes the system\u2019s loss with respect to Ep by exponentiated gradient descent (Kivinen & Warmuth, 1995), but has been relinearized in order to avoid the computationally expensive exponentiation operation (Schraudolph, 1999a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 219
                            }
                        ],
                        "text": "We know of two neural network learning algorithms that combine the O(n) curvature matrix-vector product with iteration 1.1 in some form: matrix momentum (Orr, 1995; Orr & Leen, 1997) and our own stochastic metadescent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14443129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50d67989f1969e302909b0ef194bede593f3dd7d",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Almeida et al. have recently proposed online algorithms for local step size adaptation in nonlinear systems trained by gradient descent. Here we develop an alternative to their approach by extending Sutton\u2019s work on linear systems to the general, nonlinear case. The resulting algorithms are computationally little more expensive than other acceleration techniques, do not assume statistical independence between successive training patterns, and do not require an arbitrary smoothing parameter. In our benchmark experiments, they consistently outperform other acceleration methods as well as stochastic gradient descent with fixed learning rate and momentum."
            },
            "slug": "Online-Learning-with-Adaptive-Local-Step-Sizes-Schraudolph",
            "title": {
                "fragments": [],
                "text": "Online Learning with Adaptive Local Step Sizes"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The resulting algorithms are computationally little more expensive than other acceleration techniques, do not assume statistical independence between successive training patterns, and do not require an arbitrary smoothing parameter."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739396"
                        ],
                        "name": "N. Schraudolph",
                        "slug": "N.-Schraudolph",
                        "structuredName": {
                            "firstName": "Nicol",
                            "lastName": "Schraudolph",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Schraudolph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37367995"
                        ],
                        "name": "X. Giannakopoulos",
                        "slug": "X.-Giannakopoulos",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Giannakopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Giannakopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 166
                            }
                        ],
                        "text": "We then examine two learning algorithms that use this approach: matrix momentum (Orr, 1995; Orr & Leen, 1997) and stochastic meta-descent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 246
                            }
                        ],
                        "text": "We know of two neural network learning algorithms that combine the O(n) curvature matrix-vector product with iteration 1.1 in some form: matrix momentum (Orr, 1995; Orr & Leen, 1997) and our own stochastic metadescent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8929338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7200263a84b6f34a02f0a9429f486a1f4176389",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic meta-descent (SMD) is a new technique for online adaptation of local learning rates in arbitrary twice-differentiable systems. Like matrix momentum it uses full second-order information while retaining O(n) computational complexity by exploiting the efficient computation of Hessian-vector products. Here we apply SMD to independent component analysis, and employ the resulting algorithm for the blind separation of time-varying mixtures. By matching individual learning rates to the rate of change in each source signal's mixture coefficients, our technique is capable of simultaneously tracking sources that move at very different, a priori unknown speeds."
            },
            "slug": "Online-Independent-Component-Analysis-with-Local-Schraudolph-Giannakopoulos",
            "title": {
                "fragments": [],
                "text": "Online Independent Component Analysis with Local Learning Rate Adaptation"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work applies stochastic meta-descent to independent component analysis, and employs the resulting algorithm for the blind separation of time-varying mixtures."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739396"
                        ],
                        "name": "N. Schraudolph",
                        "slug": "N.-Schraudolph",
                        "structuredName": {
                            "firstName": "Nicol",
                            "lastName": "Schraudolph",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Schraudolph"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 139
                            }
                        ],
                        "text": "We then examine two learning algorithms that use this approach: matrix momentum (Orr, 1995; Orr & Leen, 1997) and stochastic meta-descent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 247
                            }
                        ],
                        "text": "The learning rate update, equation 5.2, minimizes the system\u2019s loss with respect to Ep by exponentiated gradient descent (Kivinen & Warmuth, 1995), but has been relinearized in order to avoid the computationally expensive exponentiation operation (Schraudolph, 1999a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 219
                            }
                        ],
                        "text": "We know of two neural network learning algorithms that combine the O(n) curvature matrix-vector product with iteration 1.1 in some form: matrix momentum (Orr, 1995; Orr & Leen, 1997) and our own stochastic metadescent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6304315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "812b49a877b98941f258f7c2bfc8e890963142bd",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Gain adaptation algorithms for neural networks typically adjust learning rates by monitoring the correlation between successive gradients. Here we discuss the limitations of this approach, and develop an alternative by extending Sutton''s work on linear systems to the general, nonlinear case. The resulting online algorithms are computationally little more expensive than other acceleration techniques, do not assume statistical independence between successive training patterns, and do not require an arbitrary smoothing parameter. In our benchmark experiments, they consistently outperform other acceleration methods, and show remarkable robustness when faced with non-i.i.d. sampling of the input space."
            },
            "slug": "Local-Gain-Adaptation-in-Stochastic-Gradient-Schraudolph",
            "title": {
                "fragments": [],
                "text": "Local Gain Adaptation in Stochastic Gradient Descent"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The limitations of this approach are discussed, and an alternative is developed by extending Sutton''s work on linear systems to the general, nonlinear case, and the resulting online algorithms are computationally little more expensive than other acceleration techniques, and do not assume statistical independence between successive training patterns."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8896870"
                        ],
                        "name": "H. Yang",
                        "slug": "H.-Yang",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Yang",
                            "middleNames": [
                                "Hua"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 21
                            }
                        ],
                        "text": "This is exploited by Yang and Amari (1998) to compute efficiently the natural gradient for multilayer perceptrons with a single output and one hidden layer: assuming independently and identically distributed (i.i.d.) gaussian input, they explicitly derive the form of the Fisher information matrix\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 22304550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e88407f3a5591ca5c46c4c26751bdeba1e42a41",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The natural gradient descent method is applied to train an n-m-1 multilayer perceptron. Based on an efficient scheme to represent the Fisher information matrix for an n-m-1 stochastic multilayer perceptron, a new algorithm is proposed to calculate the natural gradient without inverting the Fisher information matrix explicitly. When the input dimension n is much larger than the number of hidden neurons m, the time complexity of computing the natural gradient is O(n)."
            },
            "slug": "Complexity-Issues-in-Natural-Gradient-Descent-for-Yang-Amari",
            "title": {
                "fragments": [],
                "text": "Complexity Issues in Natural Gradient Descent Method for Training Multilayer Perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new algorithm is proposed to calculate the natural gradient without inverting the Fisher information matrix explicitly, when the input dimension n is much larger than the number of hidden neurons m."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 168
                            }
                        ],
                        "text": "The Fisher information matrix proper, F\u0304 \u2261 \u3008F\u3009E x, describes the geometric structure of weight space (Amari, 1985) and is used in the natural gradient descent approach (Amari, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 163
                            }
                        ],
                        "text": "The Fisher information matrix proper, F\u0304 \u2261 \u3008F\u3009Ex, describes the geometric structure of weight space (Amari, 1985) and is used in the natural gradient descent approach (Amari, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 75
                            }
                        ],
                        "text": "One alternative that has been proposed is the Fisher information matrix F\u0304 (Amari, 1998), which, being a quadratic form, is positive semidefinite by definition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 30
                            }
                        ],
                        "text": "This is exploited by Yang and Amari (1998) to compute efficiently the natural gradient for multilayer perceptrons with a single output and one hidden layer: assuming independently and identically distributed (i.i.d.) gaussian input, they explicitly derive the form of the Fisher information matrix\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207585383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a767a341364de1f75bea85e0b12ba7d3586a461",
            "isKey": true,
            "numCitedBy": 2730,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "When a parameter space has a certain underlying structure, the ordinary gradient of a function does not represent its steepest direction, but the natural gradient does. Information geometry is used for calculating the natural gradients in the parameter space of perceptrons, the space of matrices (for blind source separation), and the space of linear dynamical systems (for blind source deconvolution). The dynamical behavior of natural gradient online learning is analyzed and is proved to be Fisher efficient, implying that it has asymptotically the same performance as the optimal batch estimation of parameters. This suggests that the plateau phenomenon, which appears in the backpropagation learning algorithm of multilayer perceptrons, might disappear or might not be so serious when the natural gradient is used. An adaptive method of updating the learning rate is proposed and analyzed."
            },
            "slug": "Natural-Gradient-Works-Efficiently-in-Learning-Amari",
            "title": {
                "fragments": [],
                "text": "Natural Gradient Works Efficiently in Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The dynamical behavior of natural gradient online learning is analyzed and is proved to be Fisher efficient, implying that it has asymptotically the same performance as the optimal batch estimation of parameters."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 163
                            }
                        ],
                        "text": "The Fisher information matrix proper, F\u0304 \u2261 \u3008F\u3009Ex, describes the geometric structure of weight space (Amari, 1985) and is used in the natural gradient descent approach (Amari, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 75
                            }
                        ],
                        "text": "One alternative that has been proposed is the Fisher information matrix F\u0304 (Amari, 1998), which, being a quadratic form, is positive semidefinite by definition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 145
                            }
                        ],
                        "text": "\u20268092 Zu\u0308rich, Switzerland\nWe propose a generic method for iteratively approximating various second-order gradient steps\u2014-Newton, Gauss-Newton, Levenberg-Marquardt, and natural gradient\u2014-in linear time per iteration, using special curvature matrix-vector products that can be computed in O(n)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 30
                            }
                        ],
                        "text": "This is exploited by Yang and Amari (1998) to compute efficiently the natural gradient for multilayer perceptrons with a single output and one hidden layer: assuming independently and identically distributed (i.i.d.) gaussian input, they explicitly derive the form of the Fisher information matrix\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35762,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1c2a2fd6a26947e5bbb8df47e30c1199ab1270d",
            "isKey": true,
            "numCitedBy": 84,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "When a parameter space has a certain underlying structure, the ordinary gradient of a function does not represent its steepest direction but the natural gradient does. Information geometry is used for calculating the natural gradients in the parameter space of perceptrons, the space of matrices (for blind source separation) and the space of linear dynamical systems (for blind source deconvolution). The dynamical behavior of natural gradient on-line learning is analyzed and is proved to be Fisher ecient, implying that it has asymptotically the same performance as the optimal batch estimation of parameters. This suggests that the plateau phenomenon which appears in the backpropagation learning algorithm of multilayer perceptrons might disappear or might be not so serious when the natural gradient is used. An adaptive method of updating the learning rate is proposed and analyzed."
            },
            "slug": "Natural-Gradient-Works-Eciently-in-Learning-Amari",
            "title": {
                "fragments": [],
                "text": "Natural Gradient Works Eciently in Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The dynamical behavior of natural gradient on-line learning is analyzed and is proved to be Fisher ecient, implying that it has asymptotically the same performance as the optimal batch estimation of parameters."
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700597"
                        ],
                        "name": "Jyrki Kivinen",
                        "slug": "Jyrki-Kivinen",
                        "structuredName": {
                            "firstName": "Jyrki",
                            "lastName": "Kivinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jyrki Kivinen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 121
                            }
                        ],
                        "text": "The learning rate update, equation 5.2, minimizes the system\u2019s loss with respect to Ep by exponentiated gradient descent (Kivinen & Warmuth, 1995), but has been relinearized in order to avoid the computationally expensive exponentiation operation (Schraudolph, 1999a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15718458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4dc175e8f6e7ca5c40ffd6fb9c6b92323bf7daf2",
            "isKey": true,
            "numCitedBy": 281,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider two algorithms for on-line prediction based on a linear model. The algorithms are the well-known Gradient Descent (GD) algorithm and a new algorithm, which we call EG *. They both maintain a weight vector using simple updates. For the GD algorithm, the weight vector is updated by subtracting from it the gradient of the squared error made on a prediction multiplied by a parameter called the learning rate. The EG* uses the components of the gradient in the exponents of factors that are used in updating the weight vector multiplicatively. We present worst-case on-line loss bounds for EG* and compare them to previously known bounds for the GD algorithm. The bounds suggest that although the on-line losses of the algorithms are in general incomparable, EG * has a much smaller loss if only few of the input variables are relevant for the predictions. Experiments show that the worst-case upper bounds are quite tight already on simple artificial data. Our main methodological idea is using a distance function between weight vectors both in motivating the algorithms and as a potential function in an amortized analysis that leads to worst-case loss bounds. Using squared Euclidean distance leads to the GD algorithm, and using the relative entropy leads to the EG* algorithm."
            },
            "slug": "Additive-versus-exponentiated-gradient-updates-for-Kivinen-Warmuth",
            "title": {
                "fragments": [],
                "text": "Additive versus exponentiated gradient updates for linear prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The main methodological idea is using a distance function between weight vectors both in motivating the algorithms and as a potential function in an amortized analysis that leads to worst-case loss bounds."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739396"
                        ],
                        "name": "N. Schraudolph",
                        "slug": "N.-Schraudolph",
                        "structuredName": {
                            "firstName": "Nicol",
                            "lastName": "Schraudolph",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Schraudolph"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5799102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f6a2a99b59f73ae1aefd0dcb69046450d539e21",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper derives a family of differential learning rules that optimize the Shannon entropy at the output of an adaptive system via kernel density estimation. In contrast to parametric formulations of entropy, this nonparametric approach assumes no particular functional form of the output density. We address problems associated with quantized data and finite sample size, and implement efficient maximum likelihood techniques for optimizing the regularizer. We also develop a normalized entropy estimate that is invariant with respect to affine transformations, facilitating optimization of the shape, rather than the scale, of the output density. Kernel density estimates are smooth and differentiable; this makes the derived entropy estimates amenable to manipulation by gradient descent. The resulting weight updates are surprisingly simple and efficient learning rules that operate on pairs of input samples. They can be tuned for data-limited or memory-limited situations, or modified to give a fully online implementation."
            },
            "slug": "Gradient-based-manipulation-of-nonparametric-Schraudolph",
            "title": {
                "fragments": [],
                "text": "Gradient-based manipulation of nonparametric entropy estimates"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Kernel density estimates are smooth and differentiable; this makes the derived entropy estimates amenable to manipulation by gradient descent, and a normalized entropy estimate is developed that is invariant with respect to affine transformations, facilitating optimization of the shape, rather than the scale, of the output density."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3222903"
                        ],
                        "name": "T. Leen",
                        "slug": "T.-Leen",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Leen",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34782608"
                        ],
                        "name": "G. Orr",
                        "slug": "G.-Orr",
                        "structuredName": {
                            "firstName": "Genevieve",
                            "lastName": "Orr",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 107
                            }
                        ],
                        "text": "The investigation of asymptotically optimal adaptive momentum for first-order stochastic gradient descent (Leen & Orr, 1994) led Orr (1995) to propose the following weight update:\nEwt+1 = Ewt + Evt+1, Evt+1 = Evt \u2212 \u00b5(%t Eg+ CEvt), (5.5)\nwhere \u00b5 is a scalar constant less than the inverse of C\u0304\u2019s\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8315550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b353e93d4a6dbe34d2d32fffa1207177f43266bf",
            "isKey": true,
            "numCitedBy": 33,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic optimization algorithms typically use learning rate schedules that behave asymptotically as \u00b5(t) = \u00b50/t. The ensemble dynamics (Leen and Moody, 1993) for such algorithms provides an easy path to results on mean squared weight error and asymptotic normality. We apply this approach to stochastic gradient algorithms with momentum. We show that at late times, learning is governed by an effective learning rate \u00b5eff = \u00b50/(1 - \u03b2) where \u03b2 is the momentum parameter. We describe the behavior of the asymptotic weight error and give conditions on \u00b5eff that insure optimal convergence speed. Finally, we use the results to develop an adaptive form of momentum that achieves optimal convergence speed independent of \u00b50."
            },
            "slug": "Optimal-Stochastic-Search-and-Adaptive-Momentum-Leen-Orr",
            "title": {
                "fragments": [],
                "text": "Optimal Stochastic Search and Adaptive Momentum"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work shows that at late times, learning is governed by an effective learning rate \u00b5eff = \u00b50/(1 - \u03b2) where \u03b2 is the momentum parameter and develops an adaptive form of momentum that achieves optimal convergence speed independent of \u00b50."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102235031"
                        ],
                        "name": "Kenneth Levenberg",
                        "slug": "Kenneth-Levenberg",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Levenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Levenberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Levenberg (1944) suggested adding \u03bbI to the Gauss-Newton matrix G\u0304; Marquardt (1963) elaborated the additive term to \u03bbdiag(G\u0304)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 213
                            }
                        ],
                        "text": "Practical second-order methods therefore prefer measures of curvature that are better behaved, such as the outer product (Gauss-Newton) approximation of the Hessian, a model-trust region modification of the same (Levenberg, 1944; Marquardt, 1963), or the Fisher information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 124308544,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b1afd5740cdb03295f14e6c993b8d36844956dce",
            "isKey": false,
            "numCitedBy": 10367,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The standard method for solving least squares problems which lead to non-linear normal equations depends upon a reduction of the residuals to linear form by first order Taylor approximations taken about an initial or trial solution for the parameters.2 If the usual least squares procedure, performed with these linear approximations, yields new values for the parameters which are not sufficiently close to the initial values, the neglect of second and higher order terms may invalidate the process, and may actually give rise to a larger value of the sum of the squares of the residuals than that corresponding to the initial solution. This failure of the standard method to improve the initial solution has received some notice in statistical applications of least squares3 and has been encountered rather frequently in connection with certain engineering applications involving the approximate representation of one function by another. The purpose of this article is to show how the problem may be solved by an extension of the standard method which insures improvement of the initial solution.4 The process can also be used for solving non-linear simultaneous equations, in which case it may be considered an extension of Newton's method. Let the function to be approximated be h{x, y, z, \u2022 \u2022 \u2022 ), and let the approximating function be H{oc, y, z, \u2022 \u2022 \u25a0 ; a, j3, y, \u25a0 \u2022 \u25a0 ), where a, /3, 7, \u2022 \u25a0 \u25a0 are the unknown parameters. Then the residuals at the points, yit zit \u2022 \u2022 \u2022 ), i = 1, 2, \u25a0 \u2022 \u2022 , n, are"
            },
            "slug": "A-METHOD-FOR-THE-SOLUTION-OF-CERTAIN-NON-\u2013-LINEAR-Levenberg",
            "title": {
                "fragments": [],
                "text": "A METHOD FOR THE SOLUTION OF CERTAIN NON \u2013 LINEAR PROBLEMS IN LEAST SQUARES"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1944
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2690025"
                        ],
                        "name": "M. Harmon",
                        "slug": "M.-Harmon",
                        "structuredName": {
                            "firstName": "Mance",
                            "lastName": "Harmon",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Harmon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1844179"
                        ],
                        "name": "L. Baird",
                        "slug": "L.-Baird",
                        "structuredName": {
                            "firstName": "Leemon",
                            "lastName": "Baird",
                            "middleNames": [
                                "C."
                            ],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 118
                            }
                        ],
                        "text": "Even so, this is still significantly faster than the degenerate case of \u03bb = 0 (dotted), which in effect implements IDD (Harmon & Baird, 1996), to our knowledge the best on-line method for local learning rate adaptation preceding SMD."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61023440,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e5d0e5093541c7c629824162ff53179a0529e15",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : A new algorithm advantage learning, is presented that improves on advantage updating by requiring that a single function be learned rather than two. Furthermore, advantage learning requires only a single type of update, the learning, while advantage updating requires two different types of updates, a learning update and a normalization update. The reinforcement learning system uses the residual form of advantage learning. An application of reinforcement learning to a Markov game is presented. The test-bed has continuous states and nonlinear dynamics. The advantage function is stored in a single-hidden-layer sigmoidal network. Speed of learning is increased by a new algorithm, Incremental Delta-Delta (IDD), which extends Jacob's (1988) Delta-Delta for use in incremental training, and differs from Sutton's Incremental Delta-Bar-Delta (1992) in that it does not require the use of a trace and is amenable for use with general function approximation systems. To our knowledge, this is the first time an approximate second order method has been used with residual algorithms. Empirical results are presented comparing convergence rates with and without the use of lDD for the reinforcement learning test-bed and for a supervised learning test-bed."
            },
            "slug": "Multi-Agent-Residual-Advantage-Learning-with-Harmon-Baird",
            "title": {
                "fragments": [],
                "text": "Multi-Agent Residual Advantage Learning with General Function Approximation."
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new algorithm, Incremental Delta- Delta (IDD), is presented, which extends Jacob's (1988) Delta-Delta for use in incremental training, and differs from Sutton's IncrementalDelta-Bar-Delta in that it does not require the use of a trace and is amenable for use with general function approximation systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8974886"
                        ],
                        "name": "G. Cawley",
                        "slug": "G.-Cawley",
                        "structuredName": {
                            "firstName": "Gavin",
                            "lastName": "Cawley",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cawley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 139
                            }
                        ],
                        "text": "We then examine two learning algorithms that use this approach: matrix momentum (Orr, 1995; Orr & Leen, 1997) and stochastic meta-descent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 247
                            }
                        ],
                        "text": "The learning rate update, equation 5.2, minimizes the system\u2019s loss with respect to Ep by exponentiated gradient descent (Kivinen & Warmuth, 1995), but has been relinearized in order to avoid the computationally expensive exponentiation operation (Schraudolph, 1999a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 219
                            }
                        ],
                        "text": "We know of two neural network learning algorithms that combine the O(n) curvature matrix-vector product with iteration 1.1 in some form: matrix momentum (Orr, 1995; Orr & Leen, 1997) and our own stochastic metadescent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9165813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16b384730624acac4e7d57f627bcd084f2253953",
            "isKey": true,
            "numCitedBy": 61,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently Schraudolph (1999) described an ingenious, fast, and compact approximation of the exponential function through manipulation of the components of a standard (IEEE-754 (IEEE, 1985)) floating-point representation. This brief note communicates a recoding of this procedure that overcomes some of the limitations of the original macro at little or no additional computational expense."
            },
            "slug": "On-a-Fast,-Compact-Approximation-of-the-Exponential-Cawley",
            "title": {
                "fragments": [],
                "text": "On a Fast, Compact Approximation of the Exponential Function"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A recoding of this procedure that overcomes some of the limitations of the original macro at little or no additional computational expense is communicated."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739396"
                        ],
                        "name": "N. Schraudolph",
                        "slug": "N.-Schraudolph",
                        "structuredName": {
                            "firstName": "Nicol",
                            "lastName": "Schraudolph",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Schraudolph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 61
                            }
                        ],
                        "text": "A simple architecture-dependent technique such as tempering (Schraudolph & Sejnowski, 1996) should usually suffice to initialize Ep adequately; the fine tuning can be left to the SMD algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2134909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e8ea3876cafe6e26c88463c8692e2fc79cad501",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Backpropagation learning algorithms typically collapse the network's structure into a single vector of weight parameters to be optimized. We suggest that their performance may be improved by utilizing the structural information instead of discarding it, and introduce a framework for \"tempering\" each weight accordingly. \n \nIn the tempering model, activation and error signals are treated as approximately independent random variables. The characteristic scale of weight changes is then matched to that of the residuals, allowing structural properties such as a node's fan-in and fan-out to affect the local learning rate and backpropagated error. The model also permits calculation of an upper bound on the global learning rate for batch updates, which in turn leads to different update rules for bias vs. non-bias weights. \n \nThis approach yields hitherto unparalleled performance on the family relations benchmark, a deep multi-layer network: for both batch learning with momentum and the delta-bar-delta algorithm, convergence at the optimal learning rate is sped up by more than an order of magnitude."
            },
            "slug": "Tempering-Backpropagation-Networks:-Not-All-Weights-Schraudolph-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Tempering Backpropagation Networks: Not All Weights are Created Equal"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work suggests that backpropagation learning algorithms may be improved by utilizing the structural information instead of discarding it, and introduces a framework for \"tempering\" each weight accordingly, yielding hitherto unparalleled performance on the family relations benchmark, a deep multi-layer network."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772099"
                        ],
                        "name": "D. Helmbold",
                        "slug": "D.-Helmbold",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Helmbold",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Helmbold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700597"
                        ],
                        "name": "Jyrki Kivinen",
                        "slug": "Jyrki-Kivinen",
                        "structuredName": {
                            "firstName": "Jyrki",
                            "lastName": "Kivinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jyrki Kivinen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 122
                            }
                        ],
                        "text": "(2.2)\n1 For supervised learning, a similar if somewhat more restrictive definition of matching loss functions is given by Helmbold, Kivinen, and Warmuth (1996) and Auer, Herbster, and Warmuth (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18269579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c07d63295b084af6904a4055e59774640643841f",
            "isKey": true,
            "numCitedBy": 15,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze and compare the well-known Gradient Descent algorithm and a new algorithm, called the Exponentiated Gradient algorithm, for training a single neuron with an arbitrary transfer function. Both algorithms are easily generalized to larger neural networks, and the generalization of Gradient Descent is the standard back-propagation algorithm. In this paper we prove worst-case loss bounds for both algorithms in the single neuron case. Since local minima make it difficult to prove worst-case bounds for gradient-based algorithms, we must use a loss function that prevents the formation of spurious local minima. We define such a matching loss function for any strictly increasing differentiable transfer function and prove worst-case loss bound for any such transfer function and its corresponding matching loss. For example, the matching loss for the identity function is the square loss and the matching loss for the logistic sigmoid is the entropic loss. The different structure of the bounds for the two algorithms indicates that the new algorithm out-performs Gradient Descent when the inputs contain a large number of irrelevant components."
            },
            "slug": "Worst-case-Loss-Bounds-for-Single-Neurons-Helmbold-Kivinen",
            "title": {
                "fragments": [],
                "text": "Worst-case Loss Bounds for Single Neurons"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This paper analyzes and compares the well-known Gradient Descent algorithm and a new algorithm, called the Exponentiated Gradient algorithm, for training a single neuron with an arbitrary transfer function and proves worst-case loss bounds for both algorithms in the single neuron case."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144855227"
                        ],
                        "name": "Mark Harmon",
                        "slug": "Mark-Harmon",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Harmon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Harmon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4492668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "497cbb6df00e6cbbb92d87cb72216d0455dd89c2",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A new algorithm, advantage learning, is presented that improves on advantage updating by requiring that a single function be learned rather than two. Furthermore, advantage learning requires only a single type of update, the learning update, while advantage updating requires two different types of updates, a learning update and a normilization update. The reinforcement learning system uses the residual form of advantage learning. An application of reinforcement learning to a Markov game is presented. The test-bed has continuous states and nonlinear dynamics. The game consists of two players, a missile and a plane; the missile pursues the plane and the plane evades the missile. On each time step, each player chooses one of two possible actions; turn left or turn right, resulting in a 90 degree instantaneous change in the aircraft\u2019 s heading. Reinforcement is given only when the missile hits the plane or the plane reaches an escape distance from the missile. The advantage function is stored in a single-hidden-layer sigmoidal network. Speed of learning is increased by a new algorithm, Incremental Delta-Delta (IDD), which extends Jacobs\u2019 (1988) Delta-Delta for use in incremental training, and differs from Sutton\u2019s Incremental Delta-Bar-Delta (1992) in that it does not require the use of a trace and is amenable for use with general function approximation systems. The advantage learning algorithm for optimal control is modified for games in order to find the minimax point, rather than the maximum. Empirical results gathered using the missile/aircraft test-bed validate theory that suggests residual forms of reinforcement learning algorithms converge to a local minimum of the mean squared Bellman residual when using general function approximation systems. Also, to our knowledge, this is the first time an approximate second order method has been used with residual algorithms. Empirical results are presented comparing convergence rates with and without the use of IDD for the reinforcement learning test-bed described above and for a supervised learning test-bed. The results of these experiments demonstrate IDD increased the rate of convergence and resulted in an order of magnitude lower total asymptotic error than when using backpropagation alone."
            },
            "slug": "Multi-player-residual-advantage-learning-with-Harmon",
            "title": {
                "fragments": [],
                "text": "Multi-player residual advantage learning with general function"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Empirical results gathered using the missile/aircraft test-bed validate theory that suggests residual forms of reinforcement learning algorithms converge to a local minimum of the mean squared Bellman residual when using general function approximation systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143860820"
                        ],
                        "name": "S. Singhal",
                        "slug": "S.-Singhal",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Singhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Singhal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145722821"
                        ],
                        "name": "Lance Wu",
                        "slug": "Lance-Wu",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lance Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11946868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4ea370b7261f2a2bf3a9339cedb1ab1de348301",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A large fraction of recent work in artificial neural nets uses multilayer perceptrons trained with the back-propagation algorithm described by Rumelhart et. al. This algorithm converges slowly for large or complex problems such as speech recognition, where thousands of iterations may be needed for convergence even with small data sets. In this paper, we show that training multilayer perceptrons is an identification problem for a nonlinear dynamic system which can be solved using the Extended Kalman Algorithm. Although computationally complex, the Kalman algorithm usually converges in a few iterations. We describe the algorithm and compare it with back-propagation using two-dimensional examples."
            },
            "slug": "Training-Multilayer-Perceptrons-with-the-Extende-Singhal-Wu",
            "title": {
                "fragments": [],
                "text": "Training Multilayer Perceptrons with the Extende Kalman Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that training multilayer perceptrons is an identification problem for a nonlinear dynamic system which can be solved using the Extended Kalman Algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2653061"
                        ],
                        "name": "N. Murata",
                        "slug": "N.-Murata",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Murata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Murata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716788"
                        ],
                        "name": "M. Kawanabe",
                        "slug": "M.-Kawanabe",
                        "structuredName": {
                            "firstName": "Motoaki",
                            "lastName": "Kawanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kawanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2522238"
                        ],
                        "name": "A. Ziehe",
                        "slug": "A.-Ziehe",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Ziehe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ziehe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 3192964,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0bd33cc288e1320fd51082d14e3ae1d8e099ef7",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-line-learning-in-changing-environments-with-in-Murata-Kawanabe",
            "title": {
                "fragments": [],
                "text": "On-line learning in changing environments with applications in supervised and unsupervised learning"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47055692"
                        ],
                        "name": "P. Werbos",
                        "slug": "P.-Werbos",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Werbos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Werbos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 33
                            }
                        ],
                        "text": "This fast Hessian-vector product (Pearlmutter, 1994; Werbos, 1988; M\u00f8ller, 1993) can be used in conjunction with equation 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 53
                            }
                        ],
                        "text": "This fast Hessian-vector product (Pearlmutter, 1994; Werbos, 1988; M\u00f8ller, 1993) can be used in conjunction with equation 1.1 to create an efficient, iterative O(n) implementation of Newton\u2019s method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14060545,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c33b70cf34814fdfe045026cc2a39fb9636d1b4a",
            "isKey": true,
            "numCitedBy": 283,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Some scientists have concluded that backpropagation is a specialized method for pattern classification, of little relevance to broader problems, to parallel computing, or to our understanding of the human brain. The author questions these beliefs and proposes development of a general theory of intelligence in which backpropagation and comparisons to the brain play a central role. He also points to a series of intermediate steps and applications leading up to the construction of such generalized systems, including past applications to social science which in some ways go beyond the work in AI as such. The author presents a condensed mathematical summary of that work. He begins by summarizing a generalized formulation of backpropagation, and then discusses network architectures and applications which it opens up.<<ETX>>"
            },
            "slug": "Backpropagation:-past-and-future-Werbos",
            "title": {
                "fragments": [],
                "text": "Backpropagation: past and future"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The author proposes development of a general theory of intelligence in which backpropagation and comparisons to the brain play a central role, and points to a series of intermediate steps and applications leading up to the construction of such generalized systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE 1988 International Conference on Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48590121"
                        ],
                        "name": "S. Teukolsky",
                        "slug": "S.-Teukolsky",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Teukolsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teukolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103655437"
                        ],
                        "name": "W. T. Vettering",
                        "slug": "W.-T.-Vettering",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Vettering",
                            "middleNames": [
                                "T"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. T. Vettering"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35046585"
                        ],
                        "name": "B. Flannery",
                        "slug": "B.-Flannery",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Flannery",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flannery"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119493087,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7f2eb5ae3cac743a109bc707a04f27520310ad6",
            "isKey": false,
            "numCitedBy": 1497,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The two Numerical Recipes books are marvellous. The principal book, The Art of Scientific Computing, contains program listings for almost every conceivable requirement, and it also contains a well written discussion of the algorithms and the numerical methods involved. The Example Book provides a complete driving program, with helpful notes, for nearly all the routines in the principal book. The first edition of Numerical Recipes: The Art of Scientific Computing was published in 1986 in two versions, one with programs in Fortran, the other with programs in Pascal. There were subsequent versions with programs in BASIC and in C. The second, enlarged edition was published in 1992, again in two versions, one with programs in Fortran (NR(F)), the other with programs in C (NR(C)). In 1996 the authors produced Numerical Recipes in Fortran 90: The Art of Parallel Scientific Computing as a supplement, called Volume 2, with the original (Fortran) version referred to as Volume 1. Numerical Recipes in C++ (NR(C++)) is another version of the 1992 edition. The numerical recipes are also available on a CD ROM: if you want to use any of the recipes, I would strongly advise you to buy the CD ROM. The CD ROM contains the programs in all the languages. When the first edition was published I bought it, and have also bought copies of the other editions as they have appeared. Anyone involved in scientific computing ought to have a copy of at least one version of Numerical Recipes, and there also ought to be copies in every library. If you already have NR(F), should you buy the NR(C++) and, if not, which version should you buy? In the preface to Volume 2 of NR(F), the authors say 'C and C++ programmers have not been far from our minds as we have written this volume, and we think that you will find that time spent in absorbing its principal lessons will be amply repaid in the future as C and C++ eventually develop standard parallel extensions'. In the preface and introduction to NR(C++), the authors point out some of the problems in the use of C++ in scientific computing. I have not found any mention of parallel computing in NR(C++). Fortran has quite a lot going for it. As someone who has used it in most of its versions from Fortran II, I have seen it develop and leave behind other languages promoted by various enthusiasts: who now uses Algol or Pascal? I think it unlikely that C++ will disappear: it was devised as a systems language, and can also be used for other purposes such as scientific computing. It is possible that Fortran will disappear, but Fortran has the strengths that it can develop, that there are extensive Fortran subroutine libraries, and that it has been developed for parallel computing. To argue with programmers as to which is the best language to use is sterile. If you wish to use C++, then buy NR(C++), but you should also look at volume 2 of NR(F). If you are a Fortran programmer, then make sure you have NR(F), volumes 1 and 2. But whichever language you use, make sure you have one version or the other, and the CD ROM. The Example Book provides listings of complete programs to run nearly all the routines in NR, frequently based on cases where an anlytical solution is available. It is helpful when developing a new program incorporating an unfamiliar routine to see that routine actually working, and this is what the programs in the Example Book achieve. I started teaching computational physics before Numerical Recipes was published. If I were starting again, I would make heavy use of both The Art of Scientific Computing and of the Example Book. Every computational physics teaching laboratory should have both volumes: the programs in the Example Book are included on the CD ROM, but the extra commentary in the book itself is of considerable value. P Borcherds"
            },
            "slug": "Numerical-Recipes-in-C++:-The-Art-of-Scientific-CD-Press-Teukolsky",
            "title": {
                "fragments": [],
                "text": "Numerical Recipes in C++: The Art of Scientific Computing (2nd edn)1 Numerical Recipes Example Book (C++) (2nd edn)2 Numerical Recipes Multi-Language Code CD ROM with LINUX or UNIX Single-Screen License Revised Version3"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Anyone involved in scientific computing ought to have a copy of at least one version of Numerical Recipes, and there also ought to be copies in every library."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145833095"
                        ],
                        "name": "S. Kothari",
                        "slug": "S.-Kothari",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Kothari",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kothari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681982"
                        ],
                        "name": "H. Oh",
                        "slug": "H.-Oh",
                        "structuredName": {
                            "firstName": "Heekuck",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Oh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 147
                            }
                        ],
                        "text": "For the standard loss functions used in neural network regression and classification, G has additional interesting properties:\nFirst, the residual J\u2032L\u25e6M = Ez \u2212 Ez\u2217 vanishes at the optimum for realizable problems, so that the Gauss-Newton approximation, equation 3.2, of the Hessian, equation 3.1, becomes exact in this case."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "Using the product rule, the instantaneous Hessian of our neural network model can be written as\nH = \u2202 \u2202 Ew\u2032 (JL\u25e6MJN ) = J \u2032 NHL\u25e6MJN + o\u2211 i=1 (JL\u25e6M)i HNi , (3.1)\nwhere i ranges over the o outputs of N , with Ni denoting the subnetwork that produces the ith output."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "Eg \u2261 J\u2032L\u25e6M\u25e6N is computed by an f0 pass through the entire model (N , M, and L), followed by an r1 pass propagating Eu = 1 back through the entire model (L, M, then N )."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Following the f1 pass, r2-propagate REv(1) = 0 back through L andM to obtain REv(J\u2032L\u25e6M) = HL\u25e6MJN Ev, then r1-propagate that back throughN , giving GEv."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 198
                            }
                        ],
                        "text": "We consider neural network learning as the minimization of a scalar loss function L: Ro \u2192 R defined as the log-likelihood L(E z) \u2261 \u2212 log Pr(E z) of the output E z under a suitable statistical model (Bishop, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 190
                            }
                        ],
                        "text": "We consider neural network learning as the minimization of a scalar loss function L: Ro \u2192 R defined as the log-likelihood L(Ez) \u2261 \u2212 log Pr(Ez) of the output Ez under a suitable statistical model (Bishop, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "For matching loss functions, there is a shortcut: since J\u2032L\u25e6M = AEz+ Eb, we can limit the forward pass toN andM (to compute Ez), then r1-propagate Eu = AEz+ Eb back through justN ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "We say that the loss function L matches the output nonlinearityM iff J\u2032L\u25e6M = AEz+ Eb, for some A and Eb not dependent on Ew.1 The standard loss functions used in neural network regression and classification\u2014sum-squared error for linear outputs and cross-entropy error for softmax or logistic outputs\u2014are all matching loss functions with A = I (the identity matrix) and Eb = \u2212Ez\u2217, so that J\u2032L\u25e6M = Ez\u2212Ez\u2217 (Bishop, 1995, chapter 6)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 265
                            }
                        ],
                        "text": "\u2026standard loss functions used in neural network regression and classification\u2014sum-squared error for linear outputs and cross-entropy error for softmax or logistic outputs\u2014are all matching loss functions with A = I (the identity matrix) and Eb = \u2212Ez\u2217, so that J\u2032L\u25e6M = Ez\u2212Ez\u2217 (Bishop, 1995, chapter 6)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 123
                            }
                        ],
                        "text": "For matching loss functions, the shortcut is\nto f1-propagate Ev through justN andM to obtainREv(Ez), then r2-propagate REv(J\u2032L\u25e6M) = AREv(Ez) back through justN ."
                    },
                    "intents": []
                }
            ],
            "corpusId": 177751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbc0a468ab103ae29717703d4aa9f682f6a2b664",
            "isKey": true,
            "numCitedBy": 15338,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Networks-for-Pattern-Recognition-Kothari-Oh",
            "title": {
                "fragments": [],
                "text": "Neural Networks for Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144543541"
                        ],
                        "name": "P. Auer",
                        "slug": "P.-Auer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Auer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1839746"
                        ],
                        "name": "M. Herbster",
                        "slug": "M.-Herbster",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Herbster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Herbster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 164
                            }
                        ],
                        "text": "(2.2)\n1 For supervised learning, a similar if somewhat more restrictive definition of matching loss functions is given by Helmbold, Kivinen, and Warmuth (1996) and Auer, Herbster, and Warmuth (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37098239,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "36282c0ec1bd900a294ce7f99759b32c90cf90d2",
            "isKey": true,
            "numCitedBy": 148,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that for a single neuron with the logistic function as the transfer function the number of local minima of the error function based on the square loss can grow exponentially in the dimension."
            },
            "slug": "Exponentially-many-local-minima-for-single-neurons-Auer-Herbster",
            "title": {
                "fragments": [],
                "text": "Exponentially many local minima for single neurons"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "It is shown that for a single neuron with the logistic function as the transfer function the number of local minima of the error function based on the square loss can grow exponentially in the dimension."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 129
                            }
                        ],
                        "text": "The investigation of asymptotically optimal adaptive momentum for first-order stochastic gradient descent (Leen & Orr, 1994) led Orr (1995) to propose the following weight update:\nEwt+1 = Ewt + Evt+1, Evt+1 = Evt \u2212 \u00b5(%t Eg+ CEvt), (5.5)\nwhere \u00b5 is a scalar constant less than the inverse of C\u0304\u2019s\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 50
                            }
                        ],
                        "text": "We are now investigating whether matrix momentum (Orr, 1995) can similarly be stabilized though the incorporation of an adaptive diagonal conditioner and a model-trust region parameter."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 32
                            }
                        ],
                        "text": "1 in some form: matrix momentum (Orr, 1995; Orr & Leen, 1997) and our own stochastic metadescent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 112
                            }
                        ],
                        "text": "The instability of matrix momentum is not caused by lack of semidefiniteness on behalf of the curvature matrix: Orr (1995) used the Gauss-Newton approximation, and Scarpetta et al. (1999) reached similar conclusions for the Fisher information matrix."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 184
                            }
                        ],
                        "text": "Current implementations therefore rely on simple (first-order) stochastic gradient descent initially, turning on matrix momentum only once the vicinity of an optimum has been reached (Orr,\n1995; Orr & Leen, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 154
                            }
                        ],
                        "text": "We know of two neural network learning algorithms that combine the O(n) curvature matrix-vector product with iteration 1.1 in some form: matrix momentum (Orr, 1995; Orr & Leen, 1997) and our own stochastic metadescent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 81
                            }
                        ],
                        "text": "We then examine two learning algorithms that use this approach: matrix momentum (Orr, 1995; Orr & Leen, 1997) and stochastic meta-descent (Schraudolph, 1999b, 1999c; Schraudolph & Giannakopoulos, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Orr (1995) found that in the late, annealing phase of learning, matrix momentum converges at optimal (second-order) asymptotic rates; this has been confirmed by subsequent analysis in a statistical mechanics framework (Rattray & Saad, 1999; Scarpetta, Rattray, & Saad, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamics and algorithms for stochastic learning"
            },
            "venue": {
                "fragments": [],
                "text": "Doctoral dissertation, Oregon Graduate Institute, Beaverton. Available on-line ftp://neural.cse.ogi.edu/pub/neural/papers/orrPhDch1-5.ps.Z,"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71225891"
                        ],
                        "name": "D. Marquardt",
                        "slug": "D.-Marquardt",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Marquardt",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marquardt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 135
                            }
                        ],
                        "text": "Moreover, the elements along the diagonal are not all identical as in Levenberg\u2019s (1944) method, but scale individually as suggested by Marquardt (1963)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "Levenberg (1944) suggested adding \u03bbI to the Gauss-Newton matrix G\u0304; Marquardt (1963) elaborated the additive term to \u03bbdiag(G\u0304)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 230
                            }
                        ],
                        "text": "Practical second-order methods therefore prefer measures of curvature that are better behaved, such as the outer product (Gauss-Newton) approximation of the Hessian, a model-trust region modification of the same (Levenberg, 1944; Marquardt, 1963), or the Fisher information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122360030,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "288f41a655a178bf28d5883f68aa95807edbc950",
            "isKey": false,
            "numCitedBy": 27199,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Algorithm-for-Least-Squares-Estimation-of-Marquardt",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Least-Squares Estimation of Nonlinear Parameters"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 101
                            }
                        ],
                        "text": "The Fisher information matrix proper, F\u0304 \u2261 \u3008F\u3009E x, describes the geometric structure of weight space (Amari, 1985) and is used in the natural gradient descent approach (Amari, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 96
                            }
                        ],
                        "text": "The Fisher information matrix proper, F\u0304 \u2261 \u3008F\u3009Ex, describes the geometric structure of weight space (Amari, 1985) and is used in the natural gradient descent approach (Amari, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 116956004,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "420322994c59e9081786b46b31e2c82a9753e23a",
            "isKey": false,
            "numCitedBy": 1490,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Differential-geometrical-methods-in-statistics-Amari",
            "title": {
                "fragments": [],
                "text": "Differential-geometrical methods in statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123962567"
                        ],
                        "name": "M. C. Seiler",
                        "slug": "M.-C.-Seiler",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Seiler",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. C. Seiler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50678756"
                        ],
                        "name": "F. A. Seiler",
                        "slug": "F.-A.-Seiler",
                        "structuredName": {
                            "firstName": "Fritz",
                            "lastName": "Seiler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. A. Seiler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62717952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e980fbf251ecb28ba85eb092fc66ce284bb63be",
            "isKey": false,
            "numCitedBy": 13115,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Numerical-Recipes-in-C:-The-Art-of-Scientific-Seiler-Seiler",
            "title": {
                "fragments": [],
                "text": "Numerical Recipes in C: The Art of Scientific Computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48590121"
                        ],
                        "name": "S. Teukolsky",
                        "slug": "S.-Teukolsky",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Teukolsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teukolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608024"
                        ],
                        "name": "W. Vetterling",
                        "slug": "W.-Vetterling",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Vetterling",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Vetterling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35046585"
                        ],
                        "name": "B. Flannery",
                        "slug": "B.-Flannery",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Flannery",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flannery"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60603839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2543002ba67026c669aa67243c30e416e079f1d",
            "isKey": false,
            "numCitedBy": 1709,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Numerical-recipes-in-C-(2nd-ed.):-the-art-of-Press-Teukolsky",
            "title": {
                "fragments": [],
                "text": "Numerical recipes in C (2nd ed.): the art of scientific computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Received December"
            },
            "venue": {
                "fragments": [],
                "text": "Received December"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 94
                            }
                        ],
                        "text": "We illustrate the behavior of SMD with empirical data obtained on the \u201cfour regions\u201d benchmark (Singhal & Wu, 1989): a fully connected feedforward networkN with two hidden layers of 10 units each (see Figure 1, right) is to classify two continuous inputs in the range [\u22121, 1] into four disjoint,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Training multilayer perceptrons with the extended Kalman filter"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 94
                            }
                        ],
                        "text": "We illustrate the behavior of SMD with empirical data obtained on the \u201cfour regions\u201d benchmark (Singhal & Wu, 1989): a fully connected feedforward networkN with two hidden layers of 10 units each (see Figure 1, right) is to classify two continuous inputs in the range [\u22121, 1] into four disjoint,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Training multilayer perceptrons with the extended Kalman \u008elter"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Training multilayer perceptrons with the extended Kalman filter Advances in neural information processing systems"
            },
            "venue": {
                "fragments": [],
                "text": "Training multilayer perceptrons with the extended Kalman filter Advances in neural information processing systems"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 94
                            }
                        ],
                        "text": "We illustrate the behavior of SMD with empirical data obtained on the \u201cfour regions\u201d benchmark (Singhal & Wu, 1989): a fully connected feedforward networkN with two hidden layers of 10 units each (see Figure 1, right) is to classify two continuous inputs in the range [\u22121, 1] into four disjoint,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Training multilayer perceptrons with the extended Kalman lter Advances in neural information processing systems"
            },
            "venue": {
                "fragments": [],
                "text": "Training multilayer perceptrons with the extended Kalman lter Advances in neural information processing systems"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Numerical recipes in C: The art of scienti\u008ec computing (2nd ed.)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamics and algorithms for stochastic learning. Doctoral dissertation, Oregon Graduate Institute, Beaverton. Available on-line ftp"
            },
            "venue": {
                "fragments": [],
                "text": "Dynamics and algorithms for stochastic learning. Doctoral dissertation, Oregon Graduate Institute, Beaverton. Available on-line ftp"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 22
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 38,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Fast-Curvature-Matrix-Vector-Products-for-Gradient-Schraudolph/ffa94bba647817fa5e8f8d3250fc977435b5ca76?sort=total-citations"
}