{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2198160,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e23c634a7beb02a127ecb11551fd0333491c602",
            "isKey": false,
            "numCitedBy": 2302,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Linear and quadratic discriminant analysis are considered in the small-sample, high-dimensional setting. Alternatives to the usual maximum likelihood (plug-in) estimates for the covariance matrices are proposed. These alternatives are characterized by two parameters, the values of which are customized to individual situations by jointly minimizing a sample-based estimate of future misclassification risk. Computationally fast implementations are presented, and the efficacy of the approach is examined through simulation studies and application to data. These studies indicate that in many circumstances dramatic gains in classification accuracy can be achieved."
            },
            "slug": "Regularized-Discriminant-Analysis-Friedman",
            "title": {
                "fragments": [],
                "text": "Regularized Discriminant Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Alternatives to the usual maximum likelihood estimates for the covariance matrices are proposed, characterized by two parameters, the values of which are customized to individual situations by jointly minimizing a sample-based estimate of future misclassification risk."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1887059"
                        ],
                        "name": "W. Loh",
                        "slug": "W.-Loh",
                        "structuredName": {
                            "firstName": "Wei-Yin",
                            "lastName": "Loh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Loh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13617534"
                        ],
                        "name": "N. Vanichsetakul",
                        "slug": "N.-Vanichsetakul",
                        "structuredName": {
                            "firstName": "Nunta",
                            "lastName": "Vanichsetakul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vanichsetakul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120681576,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bddf0884c1629f77833eb59b8fa76fe02773bab",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The problem of constructing classification rules that can be represented as decision trees is considered. Each object to be classified has an associated x vector containing possibly incomplete covariate information. Tree construction is based on the information provided in a \u201clearning sample\u201d of objects with known class identities. The x vectors in the learning sample may have missing values as well. Procedures are proposed for each of the components of classifier construction, such as split selection, tree-size determination, treatment of missing values, and ranking of variables. The main idea is recursive application of linear discriminant analysis, with the variables at each stage being appropriately chosen according to the data and the type of splits desired. Standard statistical techniques used as basic building blocks include analysis of variance, linear and canonical discriminant analysis, and principal component analysis. A new method of tree-structured classification is obtained by assem..."
            },
            "slug": "Tree-Structured-Classification-via-Generalized-Loh-Vanichsetakul",
            "title": {
                "fragments": [],
                "text": "Tree-Structured Classification via Generalized Discriminant Analysis."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new method of tree-structured classification is obtained by recursive application of linear discriminant analysis, with the variables at each stage being appropriately chosen according to the data and the type of splits desired."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67034272"
                        ],
                        "name": "I. E. Frank",
                        "slug": "I.-E.-Frank",
                        "structuredName": {
                            "firstName": "Ildiko",
                            "lastName": "Frank",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. E. Frank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122381283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd8ba96abde97b7ba40ec71ac11dbf0bd405207d",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification and regression techniques are among the most used tools by chemometricians. With classification, the two classic methods are discriminant analysis and SIMCA. In this paper we discuss the connection between these two methods and introduce two new ones of the same family: DASCO (discriminant analysis with shrunken covariances) and RDA (regularized discriminant analysis). We demonstrate on both simulated and real data sets that their performance is superior to the old favorites. This is especially true in small\u2010sample/high\u2010dimension settings typical in chemistry."
            },
            "slug": "Classification:-Oldtimers-and-newcomers-Frank-Friedman",
            "title": {
                "fragments": [],
                "text": "Classification: Oldtimers and newcomers"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper discusses the connection between these two methods and introduces two new ones of the same family: DASCO (discriminant analysis with shrunken covariances) and RDA (regularized discriminant analysis), demonstrating on both simulated and real data sets that their performance is superior to the old favorites."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2880938"
                        ],
                        "name": "W. Rayens",
                        "slug": "W.-Rayens",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Rayens",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Rayens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060064829"
                        ],
                        "name": "Tom Greene",
                        "slug": "Tom-Greene",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Greene",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Greene"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122010849,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "58986f894c11447423f72b90445995d9ea770163",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Covariance-pooling-and-stabilization-for-Rayens-Greene",
            "title": {
                "fragments": [],
                "text": "Covariance pooling and stabilization for classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060064829"
                        ],
                        "name": "Tom Greene",
                        "slug": "Tom-Greene",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Greene",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Greene"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2880938"
                        ],
                        "name": "W. Rayens",
                        "slug": "W.-Rayens",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Rayens",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Rayens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123584060,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cfc685bcab55b14d10a29ab0c5f6d77b3b2e471f",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The Linear Discriminant Rule (LD) is theoretically justified for use in classification when the population within-groups covariance matrices are equal, something rarely known in practice. As an alternative, the Quadratic Discriminant Rule (QD) avoids assuming equal covariance matrices, but requires the estimation of a large number of parameters. Hence, the performance of QD may be poor if the training set sizes are small or moderate. In fact, simulation studies have shown that in the two-groups case LD often outperforms QD for small training sets even when the within -groups covariance matrices differ substantially. The present article shows this to be true when there are more than two groups, as well. Thus, it would seem reasonable and useful to develop a data-based method of classification that, in effect, represents a compromise between QD and LD. In this article we develop such a method based on an empirical Bayes formulation in which the within-groups covariance matrices are assumed to be outcomes of..."
            },
            "slug": "Partially-Pooled-Covariance-Matrix-Estimation-in-Greene-Rayens",
            "title": {
                "fragments": [],
                "text": "Partially Pooled Covariance Matrix Estimation in Discriminant Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378652"
                        ],
                        "name": "R. Olshen",
                        "slug": "R.-Olshen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Olshen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Olshen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103556459"
                        ],
                        "name": "C. J. Stone",
                        "slug": "C.-J.-Stone",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29458883,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8017699564136f93af21575810d557dba1ee6fc6",
            "isKey": false,
            "numCitedBy": 16307,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Background. Introduction to Tree Classification. Right Sized Trees and Honest Estimates. Splitting Rules. Strengthening and Interpreting. Medical Diagnosis and Prognosis. Mass Spectra Classification. Regression Trees. Bayes Rules and Partitions. Optimal Pruning. Construction of Trees from a Learning Sample. Consistency. Bibliography. Notation Index. Subject Index."
            },
            "slug": "Classification-and-Regression-Trees-Breiman-Friedman",
            "title": {
                "fragments": [],
                "text": "Classification and Regression Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This chapter discusses tree classification in the context of medicine, where right Sized Trees and Honest Estimates are considered and Bayes Rules and Partitions are used as guides to optimal pruning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1256,
                                "start": 122
                            }
                        ],
                        "text": "The initial approach to this problem, and indeed to discriminant analysis in its modern guise as remarked earlier, was by Fisher (1936). In the context of g = 2 groups, he proposed that an entity with feature vector x be assigned on the basis of the linear discriminant function a'x, where a maximizes an index of separation between the two groups. The index was defined to be the magnitude of the difference between the groupsample means of a'x normalized by the pooled sample estimate of its assumed common variance within a group. The derivation of Fisher's (1936) linear discriminant function is to be discussed further in Section 3.3, where it is contrasted with normal theory-based discriminant rules. The early development of discriminant analysis before Fisher (1936) dealt primarily with measures of differences between groups based on sample moments or frequency tables, and ignored correlations among different variates in the feature vector (Pearson, 1916; Mahalanobis, 1927, 1928). One of Fisher's first contacts with discriminant problems was in connection with M. M. Barnard's (1935) work on the secular variation of Egyptian skull characteristics. By 1940, Fisher had published four papers on discriminant analysis, including Fisher (1938) in which he reviewed his 1936 work and related it to the contributions by Hotelling (1931) on his now famous T2 statistic and by Mahalanobis (1936) on his 0' statistic and earlier measures of distance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 56
                            }
                        ],
                        "text": "Discriminant analysis in its modem guise was founded by Fisher (1936). His pioneering paper, which did not take the group-conditional distributions to be known, is to be discussed later in this chapter in the context of samplebased allocation rules."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 56
                            }
                        ],
                        "text": "Discriminant analysis in its modem guise was founded by Fisher (1936)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 122
                            }
                        ],
                        "text": "The initial approach to this problem, and indeed to discriminant analysis in its modern guise as remarked earlier, was by Fisher (1936). In the context of g = 2 groups, he proposed that an entity with feature vector x be assigned on the basis of the linear discriminant function a'x, where a maximizes an index of separation between the two groups."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 54
                            }
                        ],
                        "text": "The early development of discriminant analysis before Fisher (1936) dealt primarily with measures of differences between groups based on sample moments or frequency tables, and ignored correlations among different variates in the feature vector (Pearson, 1916; Mahalanobis, 1927, 1928)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 122
                            }
                        ],
                        "text": "The initial approach to this problem, and indeed to discriminant analysis in its modern guise as remarked earlier, was by Fisher (1936)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 568,
                                "start": 122
                            }
                        ],
                        "text": "The initial approach to this problem, and indeed to discriminant analysis in its modern guise as remarked earlier, was by Fisher (1936). In the context of g = 2 groups, he proposed that an entity with feature vector x be assigned on the basis of the linear discriminant function a'x, where a maximizes an index of separation between the two groups. The index was defined to be the magnitude of the difference between the groupsample means of a'x normalized by the pooled sample estimate of its assumed common variance within a group. The derivation of Fisher's (1936) linear discriminant function is to be discussed further in Section 3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1099,
                                "start": 122
                            }
                        ],
                        "text": "The initial approach to this problem, and indeed to discriminant analysis in its modern guise as remarked earlier, was by Fisher (1936). In the context of g = 2 groups, he proposed that an entity with feature vector x be assigned on the basis of the linear discriminant function a'x, where a maximizes an index of separation between the two groups. The index was defined to be the magnitude of the difference between the groupsample means of a'x normalized by the pooled sample estimate of its assumed common variance within a group. The derivation of Fisher's (1936) linear discriminant function is to be discussed further in Section 3.3, where it is contrasted with normal theory-based discriminant rules. The early development of discriminant analysis before Fisher (1936) dealt primarily with measures of differences between groups based on sample moments or frequency tables, and ignored correlations among different variates in the feature vector (Pearson, 1916; Mahalanobis, 1927, 1928). One of Fisher's first contacts with discriminant problems was in connection with M. M. Barnard's (1935) work on the secular variation of Egyptian skull characteristics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 885,
                                "start": 56
                            }
                        ],
                        "text": "Discriminant analysis in its modem guise was founded by Fisher (1936). His pioneering paper, which did not take the group-conditional distributions to be known, is to be discussed later in this chapter in the context of samplebased allocation rules. Concerning initial work in the case of known group conditional distributions, Welch (1939) showed for g = 2 groups that a rule of the form (1.4.4) is deducible either from Bayes theorem if prior probabilities are specified for the groups or by the use of the Neyman-Pearson lemma if the two groupspecific errors of allocation are to be minimized in any given ratio. Wald (1939, 1949) developed a general theory of decision functions, and von Mises (1945) obtained the solution to the problem of minimizing the maximum of the errors of allocation for a finite number of groups, which was in the general theme of Wald\u2019s work. Rao (1948) discussed explicit solutions of the form (1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 776,
                                "start": 122
                            }
                        ],
                        "text": "The initial approach to this problem, and indeed to discriminant analysis in its modern guise as remarked earlier, was by Fisher (1936). In the context of g = 2 groups, he proposed that an entity with feature vector x be assigned on the basis of the linear discriminant function a'x, where a maximizes an index of separation between the two groups. The index was defined to be the magnitude of the difference between the groupsample means of a'x normalized by the pooled sample estimate of its assumed common variance within a group. The derivation of Fisher's (1936) linear discriminant function is to be discussed further in Section 3.3, where it is contrasted with normal theory-based discriminant rules. The early development of discriminant analysis before Fisher (1936) dealt primarily with measures of differences between groups based on sample moments or frequency tables, and ignored correlations among different variates in the feature vector (Pearson, 1916; Mahalanobis, 1927, 1928)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 341,
                                "start": 56
                            }
                        ],
                        "text": "Discriminant analysis in its modem guise was founded by Fisher (1936). His pioneering paper, which did not take the group-conditional distributions to be known, is to be discussed later in this chapter in the context of samplebased allocation rules. Concerning initial work in the case of known group conditional distributions, Welch (1939) showed for g = 2 groups that a rule of the form (1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1219,
                                "start": 56
                            }
                        ],
                        "text": "Discriminant analysis in its modem guise was founded by Fisher (1936). His pioneering paper, which did not take the group-conditional distributions to be known, is to be discussed later in this chapter in the context of samplebased allocation rules. Concerning initial work in the case of known group conditional distributions, Welch (1939) showed for g = 2 groups that a rule of the form (1.4.4) is deducible either from Bayes theorem if prior probabilities are specified for the groups or by the use of the Neyman-Pearson lemma if the two groupspecific errors of allocation are to be minimized in any given ratio. Wald (1939, 1949) developed a general theory of decision functions, and von Mises (1945) obtained the solution to the problem of minimizing the maximum of the errors of allocation for a finite number of groups, which was in the general theme of Wald\u2019s work. Rao (1948) discussed explicit solutions of the form (1.4.4) and also the use of a doubtful region of allocation. In a subsequent series of papers, he pursued related problems and extensions; see Rao (1952, 1954) for an account. There is an extensive literature on the develop ment of allocation rules. The reader is referred to Das Gupta (1973) for a comprehensive review."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 705,
                                "start": 56
                            }
                        ],
                        "text": "Discriminant analysis in its modem guise was founded by Fisher (1936). His pioneering paper, which did not take the group-conditional distributions to be known, is to be discussed later in this chapter in the context of samplebased allocation rules. Concerning initial work in the case of known group conditional distributions, Welch (1939) showed for g = 2 groups that a rule of the form (1.4.4) is deducible either from Bayes theorem if prior probabilities are specified for the groups or by the use of the Neyman-Pearson lemma if the two groupspecific errors of allocation are to be minimized in any given ratio. Wald (1939, 1949) developed a general theory of decision functions, and von Mises (1945) obtained the solution to the problem of minimizing the maximum of the errors of allocation for a finite number of groups, which was in the general theme of Wald\u2019s work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "His pioneering paper, which did not take the group-conditional distributions to be known, is to be discussed later in this chapter in the context of samplebased allocation rules"
            },
            "venue": {
                "fragments": [],
                "text": "Concerning initial work in the case of known group conditional distributions, Welch (1939) showed for g = 2 groups that a rule of"
            },
            "year": 1936
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 660,
                                "start": 0
                            }
                        ],
                        "text": "Additional references on the earlier work may be found in the books devoted to the topic as a whole or in part by Lachenbruch (1975a), Goldstein and Dillon (1978), Klecka (1980), and Hand (1981a, 1982). They have been supplemented recently by the volume edited by s. C. Choi (1986), the notes of Hjort (1986a), and the report by a panel of the Committee on Applied and Theoretical Statistics of the Board on Mathematical Sciences of the National Research Council, chaired by Professor R. Gnanadesikan (Panel on Discriminant Analysis, Classification and Clustering, 1989). Further references may be found in the symposium proceedings edited by Cacoullos (1973) and Van Ryzin (1977), the review article by Lachenbruch and Goldstein (1979), and in the encyclopedia entry by Lachenbruch (1982)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 61
                            }
                        ],
                        "text": "For example, with the enzyme-linked immunosorbent assay (ELISA) test used to screen donated blood for antibodies to the AIDS virus, a positive test would result in a more definitive test such as the Western blot being performed (Gastwirth, 1987). J. A. Anderson (1982) has given an example on patient care where an irrevocable outright assignment has to be made."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 0
                            }
                        ],
                        "text": "Additional references on the earlier work may be found in the books devoted to the topic as a whole or in part by Lachenbruch (1975a), Goldstein and Dillon (1978), Klecka (1980), and Hand (1981a, 1982). They have been supplemented recently by the volume edited by s. C. Choi (1986), the notes of Hjort (1986a), and the report by a panel of the Committee on Applied and Theoretical Statistics of the Board on Mathematical Sciences of the National Research Council, chaired by Professor R."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1001,
                                "start": 0
                            }
                        ],
                        "text": "Additional references on the earlier work may be found in the books devoted to the topic as a whole or in part by Lachenbruch (1975a), Goldstein and Dillon (1978), Klecka (1980), and Hand (1981a, 1982). They have been supplemented recently by the volume edited by s. C. Choi (1986), the notes of Hjort (1986a), and the report by a panel of the Committee on Applied and Theoretical Statistics of the Board on Mathematical Sciences of the National Research Council, chaired by Professor R. Gnanadesikan (Panel on Discriminant Analysis, Classification and Clustering, 1989). Further references may be found in the symposium proceedings edited by Cacoullos (1973) and Van Ryzin (1977), the review article by Lachenbruch and Goldstein (1979), and in the encyclopedia entry by Lachenbruch (1982). There are also the relevant chapters in the rapidly growing list of textbooks on multivariate analysis. Another source of references is the pattern recognition literature. Fukunaga (1972, 1990), Patrick (1972), Duda and Hart (1973), Young and Calvert (1974), and Devijver and Kittler (1982) are examples of texts on statistical pattern recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 0
                            }
                        ],
                        "text": "Additional references on the earlier work may be found in the books devoted to the topic as a whole or in part by Lachenbruch (1975a), Goldstein and Dillon (1978), Klecka (1980), and Hand (1981a, 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 790,
                                "start": 0
                            }
                        ],
                        "text": "Additional references on the earlier work may be found in the books devoted to the topic as a whole or in part by Lachenbruch (1975a), Goldstein and Dillon (1978), Klecka (1980), and Hand (1981a, 1982). They have been supplemented recently by the volume edited by s. C. Choi (1986), the notes of Hjort (1986a), and the report by a panel of the Committee on Applied and Theoretical Statistics of the Board on Mathematical Sciences of the National Research Council, chaired by Professor R. Gnanadesikan (Panel on Discriminant Analysis, Classification and Clustering, 1989). Further references may be found in the symposium proceedings edited by Cacoullos (1973) and Van Ryzin (1977), the review article by Lachenbruch and Goldstein (1979), and in the encyclopedia entry by Lachenbruch (1982). There are also the relevant chapters in the rapidly growing list of textbooks on multivariate analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kolmogorov used 4CO(Fl,FZ) = 1 - P. Chemoff (1952) introduced the more general distance measure WkFZ) = -log~Ifl(x)}a{~2(x)}\u2019-Ddv, where a E [0,1]. It reduces to -1ogp in the special case of a = 0.5"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1952
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 145
                            }
                        ],
                        "text": "Other ways of assessing the discriminatory performance of a fitted model have been considered by Habbema, Hilden, and Bjerregaard (1978b, 1981); Hilden, Habbema, and Bjerregaard (1978a, 1978b); and Habbema and Hilden (1981)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1978a, 1978b); and Habbema and Hilden"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chapter 1). For t obtained under mixture sampling, the log likelihood function for 3P"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chapter l l) , the predictive approach was first presented explicitly by Geisser"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 3,
            "methodology": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 11,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Discriminant-Analysis-and-Statistical-Pattern-McLachlan/20ce95262aa2781c2c3127ca77f18afece3c8f69?sort=total-citations"
}