{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2142595748"
                        ],
                        "name": "Paul Harrison",
                        "slug": "Paul-Harrison",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Harrison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Harrison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11708679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e21811d69201a433094519ba38ee0dc756396295",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A procedure is described for synthesizing an image with the same texture as a given input image. \nTo achieve this, the output image is built up by successively adding pixels selected from the input \nimage. Pixels are chosen by searching the input image for patches that closely match pixels already \npresent in the output image. It is shown that the accurate reproduction of features in the input \ntexture depends on the order in which pixels are added to the output image. A procedure for \nselecting an ordering which transfers large complex features of the input to the output image is \ndescribed. This procedure is capable of reproducing large features even if only the interactions of \nnearby pixels are considered. The procedure can be altered to allow speci cation of the placement \nof particular features in the output texture. Several applications of this are described."
            },
            "slug": "A-Non-Hierarchical-Procedure-for-Re-Synthesis-of-Harrison",
            "title": {
                "fragments": [],
                "text": "A Non-Hierarchical Procedure for Re-Synthesis of Complex Textures"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that the accurate reproduction of features in the input texture depends on the order in which pixels are added to the output image, which is capable of reproducing large features even if only the interactions of nearby pixels are considered."
            },
            "venue": {
                "fragments": [],
                "text": "WSCG"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2821129"
                        ],
                        "name": "M. Ashikhmin",
                        "slug": "M.-Ashikhmin",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ashikhmin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ashikhmin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "We use an autoregression algorithm, based primarily on recent work in texture synthesis by Wei and Levoy [49] and Ashikhmin [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 328,
                                "start": 325
                            }
                        ],
                        "text": "It finds the pixel p in the source pair that best matches the pixel being synthesized, using two different approaches: an approximate search, which attempts to efficiently find the closest-matching pixel according to the feature vectors of p, q, and their neighborhoods; and a coherence search, based on Ashikhmin\u2019s approach [2], which attempts to preserve coherence with the neighboring synthesized pixels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "This application bears some resemblance to the user-guided texturing described by Ashikhmin [2]; however, it fixes several of the problems with that method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "Ashikhmin\u2019s algorithm [2] gives high-quality coherent patches, but creates horizontal edges when patches reach the end of the source image, such as in the upper right corner of the flower texture."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "In recently published work, Ashikhmin [2] describes a texture synthesis method that works by greedily extending existing patches whenever possible, rather than by searching the entire example texture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 403573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fdc959a9403c92bf99247f482713e795cc4ebd42",
            "isKey": true,
            "numCitedBy": 865,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple texture synthesis algorithm that is well-suited for a specific class of naturally occurring textures. This class includes quasi-repeating patterns consisting of small objects of familiar but irregular size, such as flower fields, pebbles, forest undergrowth, bushes and tree branches. The algorithm starts from a sample image and generates a new image of arbitrary size the appearance of which is similar to that of the original image. This new image does not change the basic spatial frequencies the original image; instead it creates an image that is a visually similar, and is of a size set by the user. This method is fast and its implementation is straightforward. We extend the algorithm to allow direct user input for interactive control over the texture synthesis process. This allows the user to indicate large-scale properties of the texture appearance using a standard painting-style interface, and to choose among various candidate textures the algorithm can create by performing different number of iterations."
            },
            "slug": "Synthesizing-natural-textures-Ashikhmin",
            "title": {
                "fragments": [],
                "text": "Synthesizing natural textures"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The algorithm is extended to allow direct user input for interactive control over the texture synthesis process, which allows the user to indicate large-scale properties of the texture appearance using a standard painting-style interface, and to choose among various candidate textures the algorithm can create by performing different number of iterations."
            },
            "venue": {
                "fragments": [],
                "text": "I3D '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9334387,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd7bf950093fc65f3ae6ad79666ce1077f9dfb2e",
            "isKey": false,
            "numCitedBy": 2464,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple image-based method of generating novel visual appearance in which a new image is synthesized by stitching together small patches of existing images. We call this process image quilting. First, we use quilting as a fast and very simple texture synthesis algorithm which produces surprisingly good results for a wide range of textures. Second, we extend the algorithm to perform texture transfer \u2014 rendering an object with a texture taken from a different object. More generally, we demonstrate how an image can be re-rendered in the style of a different image. The method works directly on the images and does not require 3D information."
            },
            "slug": "Image-quilting-for-texture-synthesis-and-transfer-Efros-Freeman",
            "title": {
                "fragments": [],
                "text": "Image quilting for texture synthesis and transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work uses quilting as a fast and very simple texture synthesis algorithm which produces surprisingly good results for a wide range of textures and extends the algorithm to perform texture transfer \u2014 rendering an object with a texture taken from a different object."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 170
                            }
                        ],
                        "text": "One possible extension of this work would be to synthesize from non-stationary images in a completely automatic fashion, perhaps using a texture segmentation as an input [35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 119
                            }
                        ],
                        "text": "Vector quantization [20] or other clustering may be used to summarize and accelerate the nearest-neighbors computation [17, 34, 35, 39, 49]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10617783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b3dbc36ae4d8171f9a4179001e37299554f1652",
            "isKey": false,
            "numCitedBy": 344,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper makes two contributions: it provides (1) an operational definition of textons, the putative elementary units of texture perception, and (2) an algorithm for partitioning the image into disjoint regions of coherent brightness and texture, where boundaries of regions are defined by peaks in contour orientation energy and differences in texton densities across the contour. B. Julesz (1981) introduced the term texton, analogous to a phoneme in speech recognition, but did not provide an operational definition for gray-level images. We re-invent textons as frequently co-occurring combinations of oriented linear filter outputs. These can be learned using a K-means approach. By mapping each pixel to its nearest texton, the image can be analyzed into texton channels, each of which is a point set where discrete techniques such as Voronoi diagrams become applicable. Local histograms of texton frequencies can be used with a /spl chi//sup 2/ test for significant differences to find texture boundaries. Natural images contain both textured and untextured regions, so we combine this cue with that of the presence of peaks of contour energy derived from outputs of odd- and even-symmetric oriented Gaussian derivative filters. Each of these cues has a domain of applicability, so to facilitate cue combination we introduce a gating operator based on a statistical test for isotropy of Delaunay neighbors. Having obtained a local measure of how likely two nearby pixels are to belong to the same region, we use the spectral graph theoretic framework of normalized cuts to find partitions of the image into regions of coherent texture and brightness. Experimental results on a wide range of images are shown."
            },
            "slug": "Textons,-contours-and-regions:-cue-integration-in-Malik-Belongie",
            "title": {
                "fragments": [],
                "text": "Textons, contours and regions: cue integration in image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "An operational definition of textons, the putative elementary units of texture perception, and an algorithm for partitioning the image into disjoint regions of coherent brightness and texture, where boundaries of regions are defined by peaks in contour orientation energy and differences in texton densities across the contour."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2284054"
                        ],
                        "name": "O. Veryovka",
                        "slug": "O.-Veryovka",
                        "structuredName": {
                            "firstName": "Oleg",
                            "lastName": "Veryovka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Veryovka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237562"
                        ],
                        "name": "J. Buchanan",
                        "slug": "J.-Buchanan",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Buchanan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buchanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5422272,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5371fb3a5df466813bff01f6ab8a17ea2913a268",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Continuous tone images must be halftoned to be displayed on binary output devices such as printers. The ordered dither algorithm is a popular approach to halftoning. This algorithm uses a threshold matrix to approximate gray scale values. The arrangement of thresholds in the matrix determines texture artifacts introduced into the halftoned image. Thus, the challenge of research in ordered dithering is to find a matrix that results in the least visible texture artifacts. In this work we control the halftoning texture by generating a threshold matrix from an arbitrary image. We demonstrate that processing images using adaptive histogram equalization results in pixel distributions similar to traditional dither screens. Ordered dithering with the resulting threshold matrix enables us to define texture in the halftoned image. We control the appearance of this texture by a combination of the ordered dither algorithm with an error diffusion process. We present applications of the image-based dither screens to both photorealistic and artistic rendering. In the case of photorealistic tone reproduction this technique preserves textures and edges of the original image. The ability to define an arbitrary texture enables us to introduce a variety of artistic effects. A halftoned image can be embossed with another image, texture, or text. Also, halftoning with textures clipped from the existing art works approximates the look of traditional illustration media."
            },
            "slug": "Halftoning-With-Image-Based-Dither-Screens-Veryovka-Buchanan",
            "title": {
                "fragments": [],
                "text": "Halftoning With Image-Based Dither Screens"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work controls the halftoning texture by generating a threshold matrix from an arbitrary image, and demonstrates that processing images using adaptive histogram equalization results in pixel distributions similar to traditional dither screens."
            },
            "venue": {
                "fragments": [],
                "text": "Graphics Interface"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39685930"
                        ],
                        "name": "A. Sch\u00f6dl",
                        "slug": "A.-Sch\u00f6dl",
                        "structuredName": {
                            "firstName": "Arno",
                            "lastName": "Sch\u00f6dl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sch\u00f6dl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145955800"
                        ],
                        "name": "Irfan Essa",
                        "slug": "Irfan-Essa",
                        "structuredName": {
                            "firstName": "Irfan",
                            "lastName": "Essa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irfan Essa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 173
                            }
                        ],
                        "text": "Recently, a number of applications of machine learning to problems in computer graphics have been published, including Video Rewrite [7], Voice Puppetry [5], Video Textures [43], and Style Machines [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 219107796,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "b1cfc0aab0b3b4c2abf030479d8a663d747a6501",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a new type of medium, called a video texture, which has qualities somewhere between those of a photograph and a video. A video texture provides a continuous infinitely varying stream of images. While the individual frames of a video texture may be repeated from time to time, the video sequence as a whole is never repeated exactly. Video textures can be used in place of digital photos to infuse a static image with dynamic qualities and explicit actions. We present techniques for analyzing a video clip to extract its structure, and for synthesizing a new, similar looking video of arbitrary length. We combine video textures with view morphing techniques to obtain 3D video textures. We also introduce video-based animation, in which the synthesis of video textures can be guided by a user through high-level interactive controls. Applications of video textures and their extensions include the display of dynamic scenes on web pages, the creation of dynamic backdrops for special effects and games, and the interactive control of video-based animation."
            },
            "slug": "Video-textures-Sch\u00f6dl-Szeliski",
            "title": {
                "fragments": [],
                "text": "Video textures"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents techniques for analyzing a video clip to extract its structure, and for synthesizing a new, similar looking video of arbitrary length, and combines video textures with view morphing techniques to obtain 3D video textures."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722325"
                        ],
                        "name": "J. Bonet",
                        "slug": "J.-Bonet",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Bonet",
                            "middleNames": [
                                "S.",
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bonet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 119
                            }
                        ],
                        "text": "Another way to improve the perceptual results of matching is to compute multiple scales of oriented derivative filters [4, 23, 54]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "More recently, De Bonet [4] and Efros and Leung [11] showed that a nearest-neighbor search can perform high-quality texture synthesis in a single pass, using multiscale and single-scale neighborhoods, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1908692,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "18bc39207b4d24eabf9d98649db53563d9c2e3fd",
            "isKey": false,
            "numCitedBy": 726,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines a technique for treating input texture images as probability density estimators from which new textures, with similar appearance and structural properties, can be sampled. In a two-phase process, the input texture is first analyzed by measuring the joint occurrence of texture discrimination features at multiple resolutions. In the second phase, a new texture is synthesized by sampling successive spatial frequency bands from the input texture, conditioned on the similar joint occurrence of features at lower spatial frequencies. Textures synthesized with this method more successfully capture the characteristics of input textures than do previous techniques."
            },
            "slug": "Multiresolution-sampling-procedure-for-analysis-and-Bonet",
            "title": {
                "fragments": [],
                "text": "Multiresolution sampling procedure for analysis and synthesis of texture images"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A technique for treating input texture images as probability density estimators from which new textures, with similar appearance and structural properties, can be sampled, which more successfully capture the characteristics of input textures than do previous techniques."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2284054"
                        ],
                        "name": "O. Veryovka",
                        "slug": "O.-Veryovka",
                        "structuredName": {
                            "firstName": "Oleg",
                            "lastName": "Veryovka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Veryovka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237562"
                        ],
                        "name": "J. Buchanan",
                        "slug": "J.-Buchanan",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Buchanan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buchanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 205
                            }
                        ],
                        "text": "Our texture transfer method also bears some resemblance to Veryovka and Buchanan\u2019s methods for halftoning one image with the texture of another [47] and for using multiple textures to illustrate 3D meshes [46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5001455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "640d69043fbc690452f4167c702aa41b19b55278",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "The display of images on binary output hardware requires a halftoning step. Conventional halftoning algorithms approximate image values independently from the image content and often introduce artificial texture that obscures fine details. The objective of this research is to adapt a halftoning technique to 3D scene information and thus to enhance the display of computer generated 3D scenes. Our approach is based on the control of halftoning texture by the combination of ordered dithering and error diffusion techniques. We extend our previous work and enable a user to specify the shape, scale, direction, and contrast of the halftoning texture using an external buffer. We control texture shape by constructing a dither matrix from an arbitrary image or a procedural texture. Texture direction and scale are adapted to the external information by the mapping function. Texture contrast and the accuracy of tone reproduction are varied across the image using the error diffusion process. We halftone images of 3D scenes by using the geometry, position, and illumination information to control the halftoning texture. Thus, the texture provides visual cues and can be used to enhance the viewer's comprehension of the display."
            },
            "slug": "Comprehensive-Halftoning-of-3D-Scenes-Veryovka-Buchanan",
            "title": {
                "fragments": [],
                "text": "Comprehensive Halftoning of 3D Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The objective of this research is to adapt a halftoning technique to 3D scene information and thus to enhance the display of computer generated 3D scenes by using the geometry, position, and illumination information to control the halftoned texture."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Forum"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34437150"
                        ],
                        "name": "Li-yi Wei",
                        "slug": "Li-yi-Wei",
                        "structuredName": {
                            "firstName": "Li-yi",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-yi Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801789"
                        ],
                        "name": "M. Levoy",
                        "slug": "M.-Levoy",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Levoy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Levoy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "We use an autoregression algorithm, based primarily on recent work in texture synthesis by Wei and Levoy [49] and Ashikhmin [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Wei and Levoy [49] unify these approaches, using neighborhoods consisting of pixels both at the same scale and at coarser scales."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": ") Wei and Levoy [49] unify these approaches, using neighborhoods consisting of pixels both at the same scale and at coarser scales."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 77
                            }
                        ],
                        "text": "As mentioned earlier, our work builds upon this algorithm, combining it with Wei and Levoy\u2019s approach and generalizing this combination to image analogies."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "The textures synthesized with Wei and Levoy\u2019s algorithm [49] give blurry results because the L2 norm is a poor measure of perceptual similarity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 119
                            }
                        ],
                        "text": "Vector quantization [20] or other clustering may be used to summarize and accelerate the nearest-neighbors computation [17, 34, 35, 39, 49]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3131710,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1e1a39534aed2cf4894896de75d0ba1fa75ab6a",
            "isKey": true,
            "numCitedBy": 1601,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Texture synthesis is important for many applications in computer graphics, vision, and image processing. However, it remains difficult to design an algorithm that is both efficient and capable of generating high quality results. In this paper, we present an efficient algorithm for realistic texture synthesis. The algorithm is easy to use and requires only a sample texture as input. It generates textures with perceived quality equal to or better than those produced by previous techniques, but runs two orders of magnitude faster. This permits us to apply texture synthesis to problems where it has traditionally been considered impractical. In particular, we have applied it to constrained synthesis for image editing and temporal texture generation. Our algorithm is derived from Markov Random Field texture models and generates textures through a deterministic searching process. We accelerate this synthesis process using tree-structured vector quantization."
            },
            "slug": "Fast-texture-synthesis-using-tree-structured-vector-Wei-Levoy",
            "title": {
                "fragments": [],
                "text": "Fast texture synthesis using tree-structured vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents an efficient algorithm for realistic texture synthesis derived from Markov Random Field texture models and generates textures through a deterministic searching process that accelerates this synthesis process using tree-structured vector quantization."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119595335"
                        ],
                        "name": "T. Welsh",
                        "slug": "T.-Welsh",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Welsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Welsh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2821129"
                        ],
                        "name": "M. Ashikhmin",
                        "slug": "M.-Ashikhmin",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ashikhmin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ashikhmin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3367666"
                        ],
                        "name": "K. Mueller",
                        "slug": "K.-Mueller",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Mueller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mueller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7018966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5c6edb53dc41f298f145041cd2c53e40e3acf2b",
            "isKey": false,
            "numCitedBy": 801,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a general technique for \"colorizing\" greyscale images by transferring color between a source, color image and a destination, greyscale image. Although the general problem of adding chromatic values to a greyscale image has no exact, objective solution, the current approach attempts to provide a method to help minimize the amount of human labor required for this task. Rather than choosing RGB colors from a palette to color individual components, we transfer the entire color \"mood\" of the source to the target image by matching luminance and texture information between the images. We choose to transfer only chromatic information and retain the original luminance values of the target image. Further, the procedure is enhanced by allowing the user to match areas of the two images with rectangular swatches. We show that this simple technique can be successfully applied to a variety of images and video, provided that texture and luminance are sufficiently distinct. The images generated demonstrate the potential and utility of our technique in a diverse set of application domains."
            },
            "slug": "Transferring-color-to-greyscale-images-Welsh-Ashikhmin",
            "title": {
                "fragments": [],
                "text": "Transferring color to greyscale images"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This approach attempts to provide a method to help minimize the amount of human labor required for this task by transferring color between a source, color image and a destination, greyscale image by matching luminance and texture information between the images."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072103224"
                        ],
                        "name": "Michael Salisbury",
                        "slug": "Michael-Salisbury",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Salisbury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Salisbury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "112967255"
                        ],
                        "name": "M. Wong",
                        "slug": "M.-Wong",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399419990"
                        ],
                        "name": "J. Hughes",
                        "slug": "J.-Hughes",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hughes",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hughes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5091350,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "680bb58093261b4cc8f58f9b575549d6260833dd",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an interactive system for creating pen-and-ink-style line drawings from greyscale images in which the strokes of the rendered illustration follow the features of the original image. The user, via new interaction techniques for editing a direction field, specifies an orientation for each region of the image; the computer draws oriented strokes, based on a user-specified set of example strokes, that achieve the same tone as the image via a new algorithm that compares an adaptively-blurred version of the current illustration to the target tone image. By aligning the direction field with surface orientations of the objects in the image, the user can create textures that appear attached to those objects instead of merely conveying their darkness. The result is a more compelling pen-and-ink illustration than was previously possible from 2D reference imagery. CR"
            },
            "slug": "Orientable-textures-for-image-based-pen-and-ink-Salisbury-Wong",
            "title": {
                "fragments": [],
                "text": "Orientable textures for image-based pen-and-ink illustration"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An interactive system for creating pen-and-ink-style line drawings from greyscale images in which the strokes of the rendered illustration follow the features of the original image."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 119
                            }
                        ],
                        "text": "Vector quantization [20] or other clustering may be used to summarize and accelerate the nearest-neighbors computation [17, 34, 35, 39, 49]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2166325,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "191c3c15cc4c957ee3437fc27ba3178bae292e7f",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the recognition of surfaces made from different materials such as concrete, rug, marble or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions. Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions."
            },
            "slug": "Recognizing-surfaces-using-three-dimensional-Leung-Malik",
            "title": {
                "fragments": [],
                "text": "Recognizing surfaces using three-dimensional textons"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A unified model to address both the reflectance and surface normal aspects of natural texture and to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties is provided."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747779"
                        ],
                        "name": "Aaron Hertzmann",
                        "slug": "Aaron-Hertzmann",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Hertzmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Hertzmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6201996,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "f835978a33a86219a5e93852b2fe03c8aabba13e",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for creating an image with a handpainted appearance from a photograph, and a new approach to designing styles of illustration. We \u201cpaint\u201d an image with a series of spline brush strokes. Brush strokes are chosen to match colors in a source image. A painting is built up in a series of layers, starting with a rough sketch drawn with a large brush. The sketch is painted over with progressively smaller brushes, but only in areas where the sketch differs from the blurred source image. Thus, visual emphasis in the painting corresponds roughly to the spatial energy present in the source image. We demonstrate a technique for painting with long, curved brush strokes, aligned to normals of image gradients. Thus we begin to explore the expressive quality of complex brush strokes. Rather than process images with a single manner of painting, we present a framework for describing a wide range of visual styles. A style is described as an intuitive set of parameters to the painting algorithm that a designer can adjust to vary the style of painting. We show examples of images rendered with different styles, and discuss long-term goals for expressive rendering styles as a general-purpose design tool for artists and animators. CR"
            },
            "slug": "Painterly-rendering-with-curved-brush-strokes-of-Hertzmann",
            "title": {
                "fragments": [],
                "text": "Painterly rendering with curved brush strokes of multiple sizes"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This work presents a new method for creating an image with a handpainted appearance from a photograph, and a new approach to designing styles of illustration, and presents a framework for describing a wide range of visual styles."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29614547"
                        ],
                        "name": "Allison W. Klein",
                        "slug": "Allison-W.-Klein",
                        "structuredName": {
                            "firstName": "Allison",
                            "lastName": "Klein",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Allison W. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108638905"
                        ],
                        "name": "Wilmot Li",
                        "slug": "Wilmot-Li",
                        "structuredName": {
                            "firstName": "Wilmot",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wilmot Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690653"
                        ],
                        "name": "M. Kazhdan",
                        "slug": "M.-Kazhdan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kazhdan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kazhdan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3176798"
                        ],
                        "name": "W. Corr\u00eaa",
                        "slug": "W.-Corr\u00eaa",
                        "structuredName": {
                            "firstName": "Wagner",
                            "lastName": "Corr\u00eaa",
                            "middleNames": [
                                "Toledo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Corr\u00eaa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37737599"
                        ],
                        "name": "A. Finkelstein",
                        "slug": "A.-Finkelstein",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Finkelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Finkelstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807080"
                        ],
                        "name": "T. Funkhouser",
                        "slug": "T.-Funkhouser",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Funkhouser",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Funkhouser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 96
                            }
                        ],
                        "text": "Recently, a number of EBR approaches to NPR have been proposed in a variety of research systems [8, 27, 30, 53]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6073358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98edf16a5de90d1009b6c6a2915efce3409eae38",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a system for non-photorealistic rendering (NPR) of virtual environments. In real time, it synthesizes imagery of architectural interiors using stroke-based textures. We address the four main challenges of such a system \u2014 interactivity, visual detail, controlled stroke size, and frame-to-frame coherence \u2014 through image based rendering (IBR) methods. In a preprocessing stage, we capture photos of a real or synthetic environment, map the photos to a coarse model of the environment, and run a series of NPR filters to generate textures. At runtime, the system re-renders the NPR textures over the geometry of the coarse model, and it adds dark lines that emphasize creases and silhouettes. We provide a method for constructing non-photorealistic textures from photographs that largely avoids seams in the resulting imagery. We also offer a new construction, art-maps, to control stroke size across the images. Finally, we show a working system that provides an immersive experience rendered in a variety of NPR styles."
            },
            "slug": "Non-photorealistic-virtual-environments-Klein-Li",
            "title": {
                "fragments": [],
                "text": "Non-photorealistic virtual environments"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A method for constructing non-photorealistic textures from photographs that largely avoids seams in the resulting imagery is provided, and a new construction, art-maps, is offered to control stroke size across the images."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "More recently, De Bonet [4] and Efros and Leung [11] showed that a nearest-neighbor search can perform high-quality texture synthesis in a single pass, using multiscale and single-scale neighborhoods, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 221583955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bba3264d6794538381687ad6e151a7f42f3872a9",
            "isKey": false,
            "numCitedBy": 1649,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A non-parametric method for texture synthesis is proposed. The texture synthesis process grows a new image outward from an initial seed, one pixel at a time. A Markov random field model is assumed, and the conditional distribution of a pixel given all its neighbors synthesized so far is estimated by querying the sample image and finding all similar neighborhoods. The degree of randomness is controlled by a single perceptually intuitive parameter. The method aims at preserving as much local structure as possible and produces good results for a wide variety of synthetic and real-world textures."
            },
            "slug": "Texture-synthesis-by-non-parametric-sampling-Efros-Leung",
            "title": {
                "fragments": [],
                "text": "Texture synthesis by non-parametric sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A non-parametric method for texture synthesis that aims at preserving as much local structure as possible and produces good results for a wide variety of synthetic and real-world textures."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360881"
                        ],
                        "name": "D. Heeger",
                        "slug": "D.-Heeger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heeger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heeger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116003860"
                        ],
                        "name": "J. Bergen",
                        "slug": "J.-Bergen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Heeger and Bergen [23] introduced this problem to the computer graphics community in 1995."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 119
                            }
                        ],
                        "text": "Another way to improve the perceptual results of matching is to compute multiple scales of oriented derivative filters [4, 23, 54]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 47266338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38850b393d7132dc14141f7d643aca4cb9c321da",
            "isKey": false,
            "numCitedBy": 844,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method for synthesizing images that match the texture appearance of a given digitized sample. This synthesis is completely automatic and requires only the \"target\" texture as input. It allows generation of as much texture as desired so that any object can be covered. The approach is based on a model of human texture perception, and has potential to be a practically useful tool for image processing and graphics applications."
            },
            "slug": "Pyramid-based-texture-analysis/synthesis-Heeger-Bergen",
            "title": {
                "fragments": [],
                "text": "Pyramid-based texture analysis/synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper describes a method for synthesizing images that match the texture appearance of a given digitized sample that is based on a model of human texture perception, and has potential to be a practically useful tool for image processing and graphics applications."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., International Conference on Image Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219281"
                        ],
                        "name": "P. Haeberli",
                        "slug": "P.-Haeberli",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Haeberli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haeberli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5108976,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "27ed1b78ec80d38d7b28254c82767ddd88f00613",
            "isKey": false,
            "numCitedBy": 623,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer graphics research has concentrated on creating photo-realistic images of synthetic objects. These images communicate surface shading and curvature, as well as the depth relationships of objects in a scene. These renderings are traditionally represented by a rectangular array of pixels that tile the image plane.As an alternative to photo-realism, it is possible to create abstract images using an ordered collection of brush strokes. These abstract images filter and refine visual information before it is presented to the viewer. By controlling the color, shape, size, and orientation of individual brush strokes, impressionistic paintings of computer generated or photographic images can easily be created."
            },
            "slug": "Paint-by-numbers:-abstract-image-representations-Haeberli",
            "title": {
                "fragments": [],
                "text": "Paint by numbers: abstract image representations"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "Computer graphics research has concentrated on creating photo-realistic images of synthetic objects, which communicate surface shading and curvature, as well as the depth relationships of objects in a scene, which are traditionally represented by a rectangular array of pixels that tile the image plane."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739995"
                        ],
                        "name": "Y. Horry",
                        "slug": "Y.-Horry",
                        "structuredName": {
                            "firstName": "Youichi",
                            "lastName": "Horry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Horry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794380"
                        ],
                        "name": "K. Anjyo",
                        "slug": "K.-Anjyo",
                        "structuredName": {
                            "firstName": "Ken-ichi",
                            "lastName": "Anjyo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Anjyo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144050755"
                        ],
                        "name": "K. Arai",
                        "slug": "K.-Arai",
                        "structuredName": {
                            "firstName": "Kiyoshi",
                            "lastName": "Arai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Arai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 96
                            }
                        ],
                        "text": "Recently, a number of EBR approaches to NPR have been proposed in a variety of research systems [8, 27, 30, 53]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6914801,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "d30c530bfebfa6e6d31ccb2bd503ebb17845aab6",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method called TIP (Tour Into the Picture) is presented for easily making animations from one 2D picture or photograph of a scene. In TIP, animation is created from the viewpoint of a camera which can be three-dimensionally \"walked or flownthrough\" the 2D picture or photograph. To make such animation, conventional computer vision techniques cannot be applied in the 3D modeling process for the scene, using only a single 2D image. Instead a spidery mesh is employed in our method to obtain a simple scene model from the 2D image of the scene using a graphical user interface. Animation is thus easily generated without the need of multiple 2D images. Unlike existing methods, our method is not intended to construct a precise 3D scene model. The scene model is rather simple, and not fully 3D-structured. The modeling process starts by specifying the vanishing point in the 2D image. The background in the scene model then consists of at most five rectangles, whereas hierarchical polygons are used as a model for each foreground object. Furthermore a virtual camera is moved around the 3D scene model, with the viewing angle being freely controlled. This process is easily and effectively performed using the spidery mesh interface. We have obtained a wide variety of animated scenes which demonstrate the efficiency of TIP. CR"
            },
            "slug": "Tour-into-the-picture:-using-a-spidery-mesh-to-make-Horry-Anjyo",
            "title": {
                "fragments": [],
                "text": "Tour into the picture: using a spidery mesh interface to make animation from a single image"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A new method called TIP (Tour Into the Picture) is presented for easily making animations from one 2D picture or photograph of a scene using a graphical user interface, which is not intended to construct a precise 3D scene model."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747779"
                        ],
                        "name": "Aaron Hertzmann",
                        "slug": "Aaron-Hertzmann",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Hertzmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Hertzmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "We then warped the example source image with a custom image warping program designed for local image adjustments [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "This same approach can be extended to matching color distributions in a fairly straightforward way [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "However, texture transfer is actually another valid interpretation [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8086570,
            "fieldsOfStudy": [
                "Art",
                "Computer Science"
            ],
            "id": "1f5b17ea06db7d26a930360970847eef5adff837",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe new algorithms and tools for generating paintings, illustrations, and animation on a computer. These algorithms are designed to produce visually appealing and expressive images that look hand-painted or hand-drawn. In many contexts, painting and illustration have many advantages over photorealistic computer graphics, in aspects such as aesthetics, expression, and computational requirements. We explore three general strategies for non-photorealistic rendering: First, we describe explicit procedures for placing brush strokes. We begin with a painterly image processing algorithm inspired by painting with real physical media. This method produces images with a much greater subjective impression of looking hand-made than do earlier methods. By adjusting algorithm parameters, a variety of styles can be generated, such as styles inspired by the Impressionists and the Expressionists. This method is then extended to processing video, as demonstrated by painterly animations and an interactive installation. We then present a new style of line art illustration for smooth 3D surfaces. This style is designed to clearly convey surface shape, even for surfaces without predefined material properties or hatching directions. Next, we describe a new relaxation-based algorithm, in which we search for the painting that minimizes some energy function. In contrast to the first approach, we ideally only need to specify what we want, not how to directly compute it. The system allows as fine user control as desired: the user may interactively change the painting style, specify variations of style over an image, and/or add specific strokes to the painting."
            },
            "slug": "Algorithms-for-Rendering-in-Artistic-Styles-Hertzmann",
            "title": {
                "fragments": [],
                "text": "Algorithms for Rendering in Artistic Styles"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A painterly image processing algorithm inspired by painting with real physical media is described, which produces images with a much greater subjective impression of looking hand-made than do earlier methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891751"
                        ],
                        "name": "E. Pasztor",
                        "slug": "E.-Pasztor",
                        "structuredName": {
                            "firstName": "Egon",
                            "lastName": "Pasztor",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Pasztor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "Perhaps most similar in spirit to our own approach (albeit in somewhat different domains) are a method for creating pen strokes from examples [18] and a method for estimating parameters of a 3D line-drawing illustration system from an example rendering made within the same system [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15053603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c70fbb62ea308f6e609fccb599f74516cd10d1e",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based system for translating line drawings into di erent styles. The system is given a training set of many di erent lines, each drawn by an artist in various styles, which is used to translate new lines made by a user into a particular desired style with a K-nearest neighbor algorithm. This algorithm ts each input line as a linear combination of the several training lines in the same style which are most similar to it. The t line can then be rendered in di erent styles because the training set contains versions of each training line in each style. By describing input lines as linear combinations of training set lines, this procedure is expressive enough to t a broad range of input drawings. By restricting these linear combinations to contain only the most similar training set lines, this procedure is constrained enough to preserve the distinctive stylistic features of translated lines. We represent input lines by splines with nonuniformly spaced control points, which emphasizes these stylistic features. Our example-based approach has a number of advantages over conventional parameteric approaches to translating style. It can handle styles which are di cult to describe parametrically, and its repertoire can be easily extended by the user at any time. Moreover, given appropriate representations, it can be generalized to modify the style of other kinds of graphics objects, such as the font of a letter or the movement style of an animated character."
            },
            "slug": "An-example-based-approach-to-style-translation-for-Freeman-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "An example-based approach to style translation for line drawings"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "An example-based system used to translate new lines made by a user into a particular desired style with a K-nearest neighbor algorithm, which represents input lines by splines with nonuniformly spaced control points, which emphasizes the distinctive stylistic features of translated lines."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49750469"
                        ],
                        "name": "Daniel N. Wood",
                        "slug": "Daniel-N.-Wood",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Wood",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel N. Wood"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37737599"
                        ],
                        "name": "A. Finkelstein",
                        "slug": "A.-Finkelstein",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Finkelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Finkelstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399419990"
                        ],
                        "name": "J. Hughes",
                        "slug": "J.-Hughes",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hughes",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hughes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864823"
                        ],
                        "name": "Craig E. Thayer",
                        "slug": "Craig-E.-Thayer",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Thayer",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig E. Thayer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 96
                            }
                        ],
                        "text": "Recently, a number of EBR approaches to NPR have been proposed in a variety of research systems [8, 27, 30, 53]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2126257,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21afee690733cecc586198212352ec4b5e6f0187",
            "isKey": false,
            "numCitedBy": 248,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new approach for simulating apparent camera motion through a 3D environment. The approach is motivated by a traditional technique used in 2D cel animation, in which a single background image, which we call a multiperspective panorama, is used to incorporate multiple views of a 3D environment as seen from along a given camera path. When viewed through a small moving window, the panorama produces the illusion of 3D motion. In this paper, we explore how such panoramas can be designed by computer, and we examine their application to cel animation in particular. Multiperspective panoramas should also be useful for any application in which predefined camera moves are applied to 3D scenes, including virtual reality fly-throughs, computer games, and architectural walk-throughs. CR Categories: I.3.3 [Computer Graphics]: Picture/Image Generation. Additional"
            },
            "slug": "Multiperspective-panoramas-for-cel-animation-Wood-Finkelstein",
            "title": {
                "fragments": [],
                "text": "Multiperspective panoramas for cel animation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "How such panoramas can be designed by computer is explored, and their application to cel animation in particular is examined, in which a single background image is used to incorporate multiple views of a 3D environment as seen from along a given camera path."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065808108"
                        ],
                        "name": "Pietro Perona",
                        "slug": "Pietro-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pietro Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "To create A from A\u2032, we apply an anisotropic diffusion [37] or similar filter to A\u2032 (we used the \u201cSmart Blur\u201d filter from Adobe Photoshop), in order to maintain sharp contours but eliminate texture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14502908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "496c3d75b81b336411e53da1ac632a8139655604",
            "isKey": false,
            "numCitedBy": 12585,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced. The diffusion coefficient is chosen to vary spatially in such a way as to encourage intraregion smoothing rather than interregion smoothing. It is shown that the 'no new maxima should be generated at coarse scales' property of conventional scale space is preserved. As the region boundaries in the approach remain sharp, a high-quality edge detector which successfully exploits global information is obtained. Experimental results are shown on a number of images. Parallel hardware implementations are made feasible because the algorithm involves elementary, local operations replicated over the image. >"
            },
            "slug": "Scale-Space-and-Edge-Detection-Using-Anisotropic-Perona-Malik",
            "title": {
                "fragments": [],
                "text": "Scale-Space and Edge Detection Using Anisotropic Diffusion"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced, chosen to vary spatially in such a way as to encourage intra Region smoothing rather than interregion smoothing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50415353"
                        ],
                        "name": "B. Meier",
                        "slug": "B.-Meier",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Meier",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Meier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 99
                            }
                        ],
                        "text": "In the past few years, there has been a great deal of work in creating artistic styles by computer [10, 21, 24, 26, 32, 36, 41, 42, 50, 51], a field that has come to be known as non-photorealistic rendering (NPR)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1199189,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "1067fe830a0d277f01521e798674bc812a64e57b",
            "isKey": false,
            "numCitedBy": 480,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a technique for rendering animations in a painterly style. The difficulty in using existing still frame methods for animation is getting the paint to \u201cstick\u201d to surfaces rather than randomly change with each frame, while still retaining a hand-crafted look. We extend the still frame method to animation by solving two major specific problems of previous techniques. First our method eliminates the \u201cshower door\u201d effect in which an animation appears as if it were being viewed through textured glass because brush strokes stick to the viewplane not to the animating surfaces. Second, our technique provides for frame-to-frame coherence in animations so that the resulting frames do not randomly change every frame. To maintain coherence, we model surfaces as 3d particle sets which are rendered as 2d paint brush strokes in screen space much like an artist lays down brush strokes on a canvas. We use geometric and lighting properties of the surfaces to control the appearanceof brush strokes. This powerful combination of using 3d particles, surface lighting information, and rendering 2d brush strokes in screen space gives us the painterly style we desire and forces the brush strokes to stick to animating surfaces. By varying lighting and choosing brush stroke parameters we can create many varied painterly styles. We illustrate the method with images and animated sequences and present specific technical and creative suggestions for achieving different looks. CR"
            },
            "slug": "Painterly-rendering-for-animation-Meier",
            "title": {
                "fragments": [],
                "text": "Painterly rendering for animation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work extends the still frame method to animation by solving two major specific problems of previous techniques, eliminating the \u201cshower door\u201d effect and providing for frame-to-frame coherence in animations so that the resulting frames do not randomly change every frame."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072103224"
                        ],
                        "name": "Michael Salisbury",
                        "slug": "Michael-Salisbury",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Salisbury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Salisbury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2997797"
                        ],
                        "name": "Sean E. Anderson",
                        "slug": "Sean-E.-Anderson",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Anderson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sean E. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716832"
                        ],
                        "name": "Ronen Barzel",
                        "slug": "Ronen-Barzel",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Barzel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronen Barzel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 99
                            }
                        ],
                        "text": "In the past few years, there has been a great deal of work in creating artistic styles by computer [10, 21, 24, 26, 32, 36, 41, 42, 50, 51], a field that has come to be known as non-photorealistic rendering (NPR)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1098501,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "183a3c50f995b93cb849a884300d389f4948b02e",
            "isKey": false,
            "numCitedBy": 337,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an interactive system for creating pen-and-ink illustrations. The system uses stroke textures\u2014collections of strokes arranged in different patterns\u2014to generate texture and tone. The user \u201cpaints\u201d with a desired stroke texture to achieve a desired tone, and the computer draws all of the individual strokes. The system includes support for using scanned or rendered images for reference to provide the user with guides for outline and tone. By following these guides closely, the illustration system can be used for interactive digital halftoning, in which stroke textures are applied to convey details that would otherwise be lost in this black-and-white medium. By removing the burden of placing individual strokes from the user, the illustration system makes it possible to create fine stroke work with a purely mouse-based interface. Thus, this approach holds promise for bringing high-quality black-and-white illustration to the world of personal computing and desktop publishing."
            },
            "slug": "Interactive-pen-and-ink-illustration-Salisbury-Anderson",
            "title": {
                "fragments": [],
                "text": "Interactive pen-and-ink illustration"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "By removing the burden of placing individual strokes from the user, the illustration system makes it possible to create fine stroke work with a purely mouse-based interface and holds promise for bringing high-quality black-and-white illustration to the world of personal computing and desktop publishing."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570836"
                        ],
                        "name": "G. Winkenbach",
                        "slug": "G.-Winkenbach",
                        "structuredName": {
                            "firstName": "Georges",
                            "lastName": "Winkenbach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Winkenbach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2263727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00d29b2b3ece8cf2ab3fd34e27c5154142d77928",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents new algorithms and techniques for rendering parametric free-form surfaces in pen and ink. In particular, we introduce the idea of \u201ccontrolled-density hatching\u201d for conveying tone, texture, and shape. The fine control over tone this method provides allows the use of traditional texture mapping techniques for specifying the tone of pen-and-ink illustrations. We also show how a planar map, a data structure central to our rendering algorithm, can be constructed from parametric surfaces, and used for clipping strokes and generating outlines. Finally, we show how curved shadows can be cast onto curved objects for this style of illustration. CR"
            },
            "slug": "Rendering-parametric-surfaces-in-pen-and-ink-Winkenbach-Salesin",
            "title": {
                "fragments": [],
                "text": "Rendering parametric surfaces in pen and ink"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The idea of \u201ccontrolled-density hatching\u201d for conveying tone, texture, and shape is introduced and the fine control over tone this method provides allows the use of traditional texture mapping techniques for specifying the tone of pen-and-ink illustrations."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570836"
                        ],
                        "name": "G. Winkenbach",
                        "slug": "G.-Winkenbach",
                        "structuredName": {
                            "firstName": "Georges",
                            "lastName": "Winkenbach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Winkenbach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3234749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "217bbb982268ade929816572c5f98a62f1d8041d",
            "isKey": false,
            "numCitedBy": 563,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the principles of traditional pen-and-ink illustration, and shows how a great number of them can be implemented as part of an automated rendering system. It introduces \u201cstroke textures,\u201d which can be used for achieving both texture and tone with line drawing. Stroke textures also allow resolution-dependent rendering, in which the choice of strokes used in an illustration is appropriately tied to the resolution of the target medium. We demonstrate these techniques using complex architectural models, including Frank Lloyd Wright's \u201cRobie House.\u201d"
            },
            "slug": "Computer-generated-pen-and-ink-illustration-Winkenbach-Salesin",
            "title": {
                "fragments": [],
                "text": "Computer-generated pen-and-ink illustration"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "\u201cstroke textures,\u201d which can be used for achieving both texture and tone with line drawing, are introduced, which allow resolution-dependent rendering, in which the choice of strokes used in an illustration is appropriately tied to the resolution of the target medium."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31597613"
                        ],
                        "name": "Michael A. Kowalski",
                        "slug": "Michael-A.-Kowalski",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kowalski",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Kowalski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426759"
                        ],
                        "name": "L. Markosian",
                        "slug": "L.-Markosian",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Markosian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Markosian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5187966"
                        ],
                        "name": "J. Northrup",
                        "slug": "J.-Northrup",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Northrup",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Northrup"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769383"
                        ],
                        "name": "Lubomir D. Bourdev",
                        "slug": "Lubomir-D.-Bourdev",
                        "structuredName": {
                            "firstName": "Lubomir",
                            "lastName": "Bourdev",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lubomir D. Bourdev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716832"
                        ],
                        "name": "Ronen Barzel",
                        "slug": "Ronen-Barzel",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Barzel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronen Barzel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3276217"
                        ],
                        "name": "Loring Holden",
                        "slug": "Loring-Holden",
                        "structuredName": {
                            "firstName": "Loring",
                            "lastName": "Holden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Loring Holden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399419990"
                        ],
                        "name": "J. Hughes",
                        "slug": "J.-Hughes",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hughes",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hughes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8256633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e779064878fd5d9822c3685200338c5c3afbf6a8",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Artists and illustrators can evoke the complexity of fur or vegetation with relatively few well-placed strokes. We present an algorithm that uses strokes to render 3D computer graphics scenes in a stylized manner suggesting the complexity of the scene without representing it explicitly. The basic algorithm is customizable to produce a range of effects including fur, grass and trees, as we demonstrate in this paper and accompanying video. The algorithm is implemented within a broader framework that supports procedural stroke-based textures on polyhedral models. It renders moderately complex scenes at multiple frames per second on current graphics workstations, and provides some interframe coherence. CR"
            },
            "slug": "Art-based-rendering-of-fur,-grass,-and-trees-Kowalski-Markosian",
            "title": {
                "fragments": [],
                "text": "Art-based rendering of fur, grass, and trees"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm that uses strokes to render 3D computer graphics scenes in a stylized manner suggesting the complexity of the scene without representing it explicitly is presented."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69564702"
                        ],
                        "name": "F. Petrie",
                        "slug": "F.-Petrie",
                        "structuredName": {
                            "firstName": "Ferdinand",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Petrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144015217"
                        ],
                        "name": "John Shaw",
                        "slug": "John-Shaw",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shaw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Shaw"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "(Leftmost image courtesy John Shaw [38]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 191040500,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "a1ac9c7dbcd76c0c272835384c46751ac1231166",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Providing 135 lessons from three previous volumes by this artist-photographer team - \"The Watercolourist's Guide to Painting Water\", \"The Watercolourist's Guide to Painting Trees\", and \"The Watercolourist's Guide to Painting Skies\". A new introductory chapter has been added on materials and tools, as well as such basic techniques as mixing colours, laying in washes, and lifting colour. Each lesson is based on photography by John Shaw, one of America's leading nature photographers, and centres on a specific technique, from such basics as masking out or stippling to special effects like painting ice or capturing backlighting. Step-by-step demonstrations enhance the instruction, and assignments throughout the book encourage the reader to apply the lessons to other painting situations. Ferdinand Petrie is also the author of \"Drawing Landscapes in Pencil\" (Watson-Guptill). John Shaw is the author of \"The Nature Photographer's Complete Guide to Professional Field Techniques\" and \"John Shaw's Closeups in Nature\" (Amphoto)."
            },
            "slug": "The-big-book-of-painting-nature-in-watercolor-Petrie-Shaw",
            "title": {
                "fragments": [],
                "text": "The big book of painting nature in watercolor"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326400"
                        ],
                        "name": "B. Julesz",
                        "slug": "B.-Julesz",
                        "structuredName": {
                            "firstName": "B\u00e9la",
                            "lastName": "Julesz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Julesz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "(In a sense, 2 \u2212L\u03ba represents an estimate of the scale of \u201ctextons\u201d [29] at level ."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4327694,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "8999355e47248bc60f5768fc2168fd28295b5f27",
            "isKey": false,
            "numCitedBy": 1772,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Research with texture pairs having identical second-order statistics has revealed that the pre-attentive texture discrimination system cannot globally process third- and higher-order statistics, and that discrimination is the result of a few local conspicuous features, called textons. It seems that only the first-order statistics of these textons have perceptual significance, and the relative phase between textons cannot be perceived without detailed scrutiny by focal attention."
            },
            "slug": "Textons,-the-elements-of-texture-perception,-and-Julesz",
            "title": {
                "fragments": [],
                "text": "Textons, the elements of texture perception, and their interactions"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Research with texture pairs having identical second-order statistics has revealed that the pre-attentive texture discrimination system cannot globally process third- and higher- order statistics, and that discrimination is the result of a few local conspicuous features, called textons."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144549270"
                        ],
                        "name": "M. Brand",
                        "slug": "M.-Brand",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Brand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 153
                            }
                        ],
                        "text": "Recently, a number of applications of machine learning to problems in computer graphics have been published, including Video Rewrite [7], Voice Puppetry [5], Video Textures [43], and Style Machines [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5458576,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2062c4359e57b22789cc38d0a97cc12acb930f43",
            "isKey": false,
            "numCitedBy": 432,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a method for predicting a control signal from another related signal, and apply it to voice puppetry: Generating full facial animation from expressive information in an audio track. The voice puppet learns a facial control model from computer vision of real facial behavior, automatically incorporating vocal and facial dynamics such as co-articulation. Animation is produced by using audio to drive the model, which induces a probability distribution over the manifold of possible facial motions. We present a lineartime closed-form solution for the most probable trajectory over this manifold. The output is a series of facial control parameters, suitable for driving many different kinds of animation ranging from video-realistic image warps to 3D cartoon characters. CR Categories: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism\u2014Animation; I.2.9 [Artificial Intelligence]: Robotics\u2014Kinematics and Dynamics; I.4.8 [Image Processing and Computer Vision]: Scene Analysis\u2014Time-varying images; G.3 [Mathematics of Computing]: Probability and Statistics\u2014Time series analysis; E.4 [Data]: Coding and Information Theory\u2014Data compaction and compression; J.5 [Computer Applications]: Arts and Humanities\u2014Performing Arts"
            },
            "slug": "Voice-puppetry-Brand",
            "title": {
                "fragments": [],
                "text": "Voice puppetry"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A method for predicting a control signal from another related signal is introduced, and applied to voice puppetry: Generating full facial animation from expressive information in an audio track, suitable for driving many different kinds of animation ranging from video-realistic image warps to 3D cartoon characters."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1396777509"
                        ],
                        "name": "M. Covell",
                        "slug": "M.-Covell",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Covell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Covell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145290352"
                        ],
                        "name": "M. Slaney",
                        "slug": "M.-Slaney",
                        "structuredName": {
                            "firstName": "Malcolm",
                            "lastName": "Slaney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Slaney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2341707,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "3a78995510cf33edf0ee4265abe23ffdc55986cb",
            "isKey": false,
            "numCitedBy": 722,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Video Rewrite uses existing footage to create automatically new video of a person mouthing words that she did not speak in the original footage. This technique is useful in movie dubbing, for example, where the movie sequence can be modified to sync the actors\u2019 lip motions to the new soundtrack. Video Rewrite automatically labels the phonemes in the training data and in the new audio track. Video Rewrite reorders the mouth images in the training footage to match the phoneme sequence of the new audio track. When particular phonemes are unavailable in the training footage, Video Rewrite selects the closest approximations. The resulting sequence of mouth images is stitched into the background footage. This stitching process automatically corrects for differences in head position and orientation between the mouth images and the background footage. Video Rewrite uses computer-vision techniques to track points on the speaker\u2019s mouth in the training footage, and morphing techniques to combine these mouth gestures into the final video sequence. The new video combines the dynamics of the original actor\u2019s articulations with the mannerisms and setting dictated by the background footage. Video Rewrite is the first facial-animation system to automate all the labeling and assembly tasks required to resync existing footage to a new soundtrack."
            },
            "slug": "Video-Rewrite:-driving-visual-speech-with-audio-Bregler-Covell",
            "title": {
                "fragments": [],
                "text": "Video Rewrite: driving visual speech with audio"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Video Rewrite is the first facial-animation system to automate all the labeling and assembly tasks required to resync existing footage to a new soundtrack."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054252"
                        ],
                        "name": "Ashok Popat",
                        "slug": "Ashok-Popat",
                        "structuredName": {
                            "firstName": "Ashok",
                            "lastName": "Popat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashok Popat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15863104,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcd3fca85366ce22b62c9022efd2964f84829ac3",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop, analyze, and apply a specific form of mixture modeling for density estimation within the context of image and texture processing. The technique captures much of the higher order, nonlinear statistical relationships present among vector elements by combining aspects of kernel estimation and cluster analysis. Experimental results are presented in the following applications: image restoration, image and texture compression, and texture classification."
            },
            "slug": "Cluster-based-probability-model-and-its-application-Popat-Picard",
            "title": {
                "fragments": [],
                "text": "Cluster-based probability model and its application to image and texture processing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The technique captures much of the higher order, nonlinear statistical relationships present among vector elements by combining aspects of kernel estimation and cluster analysis within the context of image and texture processing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1877119"
                        ],
                        "name": "M. Barnsley",
                        "slug": "M.-Barnsley",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Barnsley",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Barnsley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2953392"
                        ],
                        "name": "L. Hurd",
                        "slug": "L.-Hurd",
                        "structuredName": {
                            "firstName": "Lyman",
                            "lastName": "Hurd",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hurd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 142
                            }
                        ],
                        "text": "An interesting area for future work is to choose the training pairs automatically for image compression, similar to fractal image compression [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5495267,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "f74e190201fe149d5646f0d862e762a599f8e994",
            "isKey": false,
            "numCitedBy": 985,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Fractal-image-compression-Barnsley-Hurd",
            "title": {
                "fragments": [],
                "text": "Fractal image compression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747779"
                        ],
                        "name": "Aaron Hertzmann",
                        "slug": "Aaron-Hertzmann",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Hertzmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Hertzmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145516498"
                        ],
                        "name": "D. Zorin",
                        "slug": "D.-Zorin",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Zorin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zorin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 99
                            }
                        ],
                        "text": "In the past few years, there has been a great deal of work in creating artistic styles by computer [10, 21, 24, 26, 32, 36, 41, 42, 50, 51], a field that has come to be known as non-photorealistic rendering (NPR)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7530801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab94f0e8e24dd2c3f639faa54b56c5c29a77f66f",
            "isKey": false,
            "numCitedBy": 641,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new set of algorithms for line-art rendering of smooth surfaces. We introduce an efficient, deterministic algorithm for finding silhouettes based on geometric duality, and an algorithm for segmenting the silhouette curves into smooth parts with constant visibility. These methods can be used to find all silhouettes in real time in software. We present an automatic method for generating hatch marks in order to convey surface shape. We demonstrate these algorithms with a drawing style inspired by A Topological Picturebook by G. Francis."
            },
            "slug": "Illustrating-smooth-surfaces-Hertzmann-Zorin",
            "title": {
                "fragments": [],
                "text": "Illustrating smooth surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An efficient, deterministic algorithm for finding silhouettes based on geometric duality, and an algorithm for segmenting the silhouette curves into smooth parts with constant visibility can be used to find all silhouettes in real time in software."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144549270"
                        ],
                        "name": "M. Brand",
                        "slug": "M.-Brand",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Brand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747779"
                        ],
                        "name": "Aaron Hertzmann",
                        "slug": "Aaron-Hertzmann",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Hertzmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Hertzmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 352517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdb8f3288cb65b463a8e7aad557d3f1bb3ff5e25",
            "isKey": false,
            "numCitedBy": 719,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We approach the problem of stylistic motion synthesis by learning motion patterns from a highly varied set of motion capture sequences. Each sequence may have a distinct choreography, performed in a distinct sytle. Learning identifies common choreographic elements across sequences, the different styles in which each element is performed, and a small number of stylistic degrees of freedom which span the many variations in the dataset. The learned model can synthesize novel motion data in any interpolation or extrapolation of styles. For example, it can convert novice ballet motions into the more graceful modern dance of an expert. The model can also be driven by video, by scripts or even by noise to generate new choreography and synthesize virtual motion-capture in many styles."
            },
            "slug": "Style-machines-Brand-Hertzmann",
            "title": {
                "fragments": [],
                "text": "Style machines"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This work approaches the problem of stylistic motion synthesis by learning motion patterns from a highly varied set of motion capture sequences, and identifies common choreographic elements across sequences, the different styles in which each element is performed, and a small number of styling degrees of freedom which span the many variations in the dataset."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1099364,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "89b6a5a136bc0a938b792df6bdde134def28335e",
            "isKey": false,
            "numCitedBy": 1150,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an architecture for efficient and accurate linear decomposition of an image into scale and orientation subbands. The basis functions of this decomposition are directional derivative operators of any desired order. We describe the construction and implementation of the transform."
            },
            "slug": "The-steerable-pyramid:-a-flexible-architecture-for-Simoncelli-Freeman",
            "title": {
                "fragments": [],
                "text": "The steerable pyramid: a flexible architecture for multi-scale derivative computation"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "An architecture for efficient and accurate linear decomposition of an image into scale and orientation subbands and the construction and implementation of the transform is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., International Conference on Image Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389543793"
                        ],
                        "name": "D. Spalding",
                        "slug": "D.-Spalding",
                        "structuredName": {
                            "firstName": "DOUGLAS A.",
                            "lastName": "Spalding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spalding"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4033418,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "c1a09e2d91009f11c464640d5fd2b9c843178ab3",
            "isKey": false,
            "numCitedBy": 8572,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "I.TO give readers some idea of the contents of a good book is very often the most useful thing a reviewer can do. Unfortunately that course is not open to us in the present instance. The subject is too vast. We cannot exhibit the grandeur; we can only in a few general phrases express our admiration of the profound, all-embracing philosophy of which the work before us is an instalment. The doctrine of evolution when taken up by Mr. Spencer was little more than a crotchet. He has made it the idea of the age. In its presence other systems of philosophy are hushed, they cease their strife and become its servants, while all the sciences do it homage. The place that the doctrine of evolution has secured in the minds of those who think for the educated public may be indicated by a few names taken just as they occur. Mr. Darwin's works, the novels of George Eliot, Mr. Tylor's \u201c Primitive Culture,\u201d Dr. Bastian's \u201c Beginnings of Life,\u201d and Mr. Bagehot's \u201c Physics and Politics,\u201d have almost nothing in common but the idea of evolution, with which they are all more or less imbued. In a word we have but one other thinker with whom in point of influence on the higher thought of this, and probably of several succeeding generations, Mr. Spencer can be classed:-it does not need saying' that that other is Mr. J, S. Mill.The Principles of Psychology.By Herbert Spencer. Second Edition. (London: Williams and Norgate.)"
            },
            "slug": "The-Principles-of-Psychology-Spalding",
            "title": {
                "fragments": [],
                "text": "The Principles of Psychology"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1873
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784290"
                        ],
                        "name": "T. Ertl",
                        "slug": "T.-Ertl",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Ertl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ertl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "Luminance can be computed in a number of ways; we use the Y channel from the YIQ color space [16], where the I and Q channels are \u201ccolor difference\u201d components."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60744504,
            "fieldsOfStudy": [
                "Education",
                "Art"
            ],
            "id": "459d0724afbcd591edde2dcc83e5e2750d878c0e",
            "isKey": false,
            "numCitedBy": 2423,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "These are the short notes for a two hour tutorial on principles and practice of computer graphics and scientific visualization. They are intended to summarize the contents of the tutorial transparencies and slides but they cannot completely replace them since restrictions in space and print quality do not permit the inclusion of figures and example images. For further reference the following standard text should be consulted: [3, 8, 5, 1, 6, 2, 9]"
            },
            "slug": "Computer-graphics\u2014principles-and-practice-Ertl",
            "title": {
                "fragments": [],
                "text": "Computer graphics\u2014principles and practice"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "These are the short notes for a two hour tutorial on principles and practice of computer graphics and scientific visualization and they cannot completely replace the contents of the tutorial transparencies and slides since restrictions in space and print quality do not permit the inclusion of figures and example images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1987164"
                        ],
                        "name": "Cassidy J. Curtis",
                        "slug": "Cassidy-J.-Curtis",
                        "structuredName": {
                            "firstName": "Cassidy",
                            "lastName": "Curtis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cassidy J. Curtis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2997797"
                        ],
                        "name": "Sean E. Anderson",
                        "slug": "Sean-E.-Anderson",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Anderson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sean E. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2739862"
                        ],
                        "name": "Joshua E. Seims",
                        "slug": "Joshua-E.-Seims",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Seims",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua E. Seims"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4564909"
                        ],
                        "name": "K. Fleischer",
                        "slug": "K.-Fleischer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Fleischer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fleischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "The lower image pair is a photograph and a watercolor created from it with a semi-automatic digital filter [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 99
                            }
                        ],
                        "text": "In the past few years, there has been a great deal of work in creating artistic styles by computer [10, 21, 24, 26, 32, 36, 41, 42, 50, 51], a field that has come to be known as non-photorealistic rendering (NPR)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3051452,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "41e32ac0fd2be3c72402ac060410be042d96ef0e",
            "isKey": false,
            "numCitedBy": 538,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "A watercolor model based on an ordered set of translucent glazes, which are created independently usinig a shallow water fluid simulation. A Kubelka-Munk compositing model is used for simulating the optical effect of the superimposed glazes. The computer generated watercolor model is used as part of an interactive watercolor paint system, or as a method for automatic image \u201cwatercolorization.\u201d"
            },
            "slug": "Computer-generated-watercolor-Curtis-Anderson",
            "title": {
                "fragments": [],
                "text": "Computer-generated watercolor"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "A watercolor model based on an ordered set of translucent glazes, which are created independently usinig a shallow water fluid simulation, and a Kubelka-Munk compositing model is used for simulating the optical effect of the superimposed glazes."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33822270"
                        ],
                        "name": "J\u00f6rg Hamel",
                        "slug": "J\u00f6rg-Hamel",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Hamel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J\u00f6rg Hamel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697367"
                        ],
                        "name": "T. Strothotte",
                        "slug": "T.-Strothotte",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Strothotte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Strothotte"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 281
                            }
                        ],
                        "text": "Perhaps most similar in spirit to our own approach (albeit in somewhat different domains) are a method for creating pen strokes from examples [18] and a method for estimating parameters of a 3D line-drawing illustration system from an example rendering made within the same system [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17432475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d74baec1dec8bb56cfc3cbebbcc6a7b48c6e096",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Rendering high\u2010quality non\u2010photorealistic images of a given geometric model is often associated with a considerable amount of effort on the part of a user to fine\u2010tune the rendition. In this paper we introduce a method and tools for re\u2010using the user's effort invested in one model for the rendering of other models."
            },
            "slug": "Capturing-and-Re\u2010Using-Rendition-Styles-for-Hamel-Strothotte",
            "title": {
                "fragments": [],
                "text": "Capturing and Re\u2010Using Rendition Styles for Non\u2010Photorealistic Rendering"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A method and tools for re\u2010using the user's effort invested in one model for the rendering of other models is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Forum"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608771"
                        ],
                        "name": "A. Gersho",
                        "slug": "A.-Gersho",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gersho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gersho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "For the BESTAPPROXIMATEMATCH procedure, we have tried using both approximate-nearest-neighbor search (ANN) [1] and treestructured vector quantization (TSVQ) [20], using the same norm over the feature vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Vector quantization [20] or other clustering may be used to summarize and accelerate the nearest-neighbors computation [17, 34, 35, 39, 49]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118950728,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c564aa7639a08c280423489e52b6e32055c9aa7f",
            "isKey": false,
            "numCitedBy": 7028,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Introduction.- 1.1 Signals, Coding, and Compression.- 1.2 Optimality.- 1.3 How to Use this Book.- 1.4 Related Reading.- I Basic Tools.- 2 Random Processes and Linear Systems.- 2.1 Introduction.- 2.2 Probability.- 2.3 Random Variables and Vectors.- 2.4 Random Processes.- 2.5 Expectation.- 2.6 Linear Systems.- 2.7 Stationary and Ergodic Properties.- 2.8 Useful Processes.- 2.9 Problems.- 3 Sampling.- 3.1 Introduction.- 3.2 Periodic Sampling.- 3.3 Noise in Sampling.- 3.4 Practical Sampling Schemes.- 3.5 Sampling Jitter.- 3.6 Multidimensional Sampling.- 3.7 Problems.- 4 Linear Prediction.- 4.1 Introduction.- 4.2 Elementary Estimation Theory.- 4.3 Finite-Memory Linear Prediction.- 4.4 Forward and Backward Prediction.- 4.5 The Levinson-Durbin Algorithm.- 4.6 Linear Predictor Design from Empirical Data.- 4.7 Minimum Delay Property.- 4.8 Predictability and Determinism.- 4.9 Infinite Memory Linear Prediction.- 4.10 Simulation of Random Processes.- 4.11 Problems.- II Scalar Coding.- 5 Scalar Quantization I.- 5.1 Introduction.- 5.2 Structure of a Quantizer.- 5.3 Measuring Quantizer Performance.- 5.4 The Uniform Quantizer.- 5.5 Nonuniform Quantization and Companding.- 5.6 High Resolution: General Case.- 5.7 Problems.- 6 Scalar Quantization II.- 6.1 Introduction.- 6.2 Conditions for Optimality.- 6.3 High Resolution Optimal Companding.- 6.4 Quantizer Design Algorithms.- 6.5 Implementation.- 6.6 Problems.- 7 Predictive Quantization.- 7.1 Introduction.- 7.2 Difference Quantization.- 7.3 Closed-Loop Predictive Quantization.- 7.4 Delta Modulation.- 7.5 Problems.- 8 Bit Allocation and Transform Coding.- 8.1 Introduction.- 8.2 The Problem of Bit Allocation.- 8.3 Optimal Bit Allocation Results.- 8.4 Integer Constrained Allocation Techniques.- 8.5 Transform Coding.- 8.6 Karhunen-Loeve Transform.- 8.7 Performance Gain of Transform Coding.- 8.8 Other Transforms.- 8.9 Sub-band Coding.- 8.10 Problems.- 9 Entropy Coding.- 9.1 Introduction.- 9.2 Variable-Length Scalar Noiseless Coding.- 9.3 Prefix Codes.- 9.4 Huffman Coding.- 9.5 Vector Entropy Coding.- 9.6 Arithmetic Coding.- 9.7 Universal and Adaptive Entropy Coding.- 9.8 Ziv-Lempel Coding.- 9.9 Quantization and Entropy Coding.- 9.10 Problems.- III Vector Coding.- 10 Vector Quantization I.- 10.1 Introduction.- 10.2 Structural Properties and Characterization.- 10.3 Measuring Vector Quantizer Performance.- 10.4 Nearest Neighbor Quantizers.- 10.5 Lattice Vector Quantizers.- 10.6 High Resolution Distortion Approximations.- 10.7 Problems.- 11 Vector Quantization II.- 11.1 Introduction.- 11.2 Optimality Conditions for VQ.- 11.3 Vector Quantizer Design.- 11.4 Design Examples.- 11.5 Problems.- 12 Constrained Vector Quantization.- 12.1 Introduction.- 12.2 Complexity and Storage Limitations.- 12.3 Structurally Constrained VQ.- 12.4 Tree-Structured VQ.- 12.5 Classified VQ.- 12.6 Transform VQ.- 12.7 Product Code Techniques.- 12.8 Partitioned VQ.- 12.9 Mean-Removed VQ.- 12.10 Shape-Gain VQ.- 12.11 Multistage VQ.- 12.12 Constrained Storage VQ.- 12.13 Hierarchical and Multiresolution VQ.- 12.14 Nonlinear Interpolative VQ.- 12.15 Lattice Codebook VQ.- 12.16 Fast Nearest Neighbor Encoding.- 12.17 Problems.- 13 Predictive Vector Quantization.- 13.1 Introduction.- 13.2 Predictive Vector Quantization.- 13.3 Vector Linear Prediction.- 13.4 Predictor Design from Empirical Data.- 13.5 Nonlinear Vector Prediction.- 13.6 Design Examples.- 13.7 Problems.- 14 Finite-State Vector Quantization.- 14.1 Recursive Vector Quantizers.- 14.2 Finite-State Vector Quantizers.- 14.3 Labeled-States and Labeled-Transitions.- 14.4 Encoder/Decoder Design.- 14.5 Next-State Function Design.- 14.6 Design Examples.- 14.7 Problems.- 15 Tree and Trellis Encoding.- 15.1 Delayed Decision Encoder.- 15.2 Tree and Trellis Coding.- 15.3 Decoder Design.- 15.4 Predictive Trellis Encoders.- 15.5 Other Design Techniques.- 15.6 Problems.- 16 Adaptive Vector Quantization.- 16.1 Introduction.- 16.2 Mean Adaptation.- 16.3 Gain-Adaptive Vector Quantization.- 16.4 Switched Codebook Adaptation.- 16.5 Adaptive Bit Allocation.- 16.6 Address VQ.- 16.7 Progressive Code Vector Updating.- 16.8 Adaptive Codebook Generation.- 16.9 Vector Excitation Coding.- 16.10 Problems.- 17 Variable Rate Vector Quantization.- 17.1 Variable Rate Coding.- 17.2 Variable Dimension VQ.- 17.3 Alternative Approaches to Variable Rate VQ.- 17.4 Pruned Tree-Structured VQ.- 17.5 The Generalized BFOS Algorithm.- 17.6 Pruned Tree-Structured VQ.- 17.7 Entropy Coded VQ.- 17.8 Greedy Tree Growing.- 17.9 Design Examples.- 17.10 Bit Allocation Revisited.- 17.11 Design Algorithms.- 17.12 Problems."
            },
            "slug": "Vector-quantization-and-signal-compression-Gersho-Gray",
            "title": {
                "fragments": [],
                "text": "Vector quantization and signal compression"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The author explains the design and implementation of the Levinson-Durbin Algorithm, which automates the very labor-intensive and therefore time-heavy and expensive process of designing and implementing a Quantizer."
            },
            "venue": {
                "fragments": [],
                "text": "The Kluwer international series in engineering and computer science"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48911597"
                        ],
                        "name": "J. Lawler",
                        "slug": "J.-Lawler",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Lawler",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lawler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143716922"
                        ],
                        "name": "G. Lakoff",
                        "slug": "G.-Lakoff",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Lakoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lakoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34262157"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 77
                            }
                        ],
                        "text": "Analogical reasoning is central to problem solving, learning, and creativity [19, 31, 33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1898149,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1456fba651c261326d8cbec451aca4925092141f",
            "isKey": false,
            "numCitedBy": 11078,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "People use metaphors every time they speak. Some of those metaphors are literary - devices for making thoughts more vivid or entertaining. But most are much more basic than that - they're \"metaphors we live by\", metaphors we use without even realizing we're using them. In this book, George Lakoff and Mark Johnson suggest that these basic metaphors not only affect the way we communicate ideas, but actually structure our perceptions and understandings from the beginning. Bringing together the perspectives of linguistics and philosophy, Lakoff and Johnson offer an intriguing and surprising guide to some of the most common metaphors and what they can tell us about the human mind. And for this new edition, they supply an afterword both extending their arguments and offering a fascinating overview of the current state of thinking on the subject of the metaphor."
            },
            "slug": "Metaphors-We-Live-by-Lawler-Lakoff",
            "title": {
                "fragments": [],
                "text": "Metaphors We Live by"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808752"
                        ],
                        "name": "C. Schunn",
                        "slug": "C.-Schunn",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Schunn",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schunn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144280578"
                        ],
                        "name": "K. Dunbar",
                        "slug": "K.-Dunbar",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Dunbar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Dunbar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15398110,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "acf8849a7a86c9161913f33f09ca9d6f55519606",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "The mechanisms by which a concept used in solving one complex task can influence performance on another complex task were investigated. We tested the hypothesis that even when subjects do not spontaneously make an analogy between two domains, knowledge of one domain can still spontaneously influence reasoning about the other domain via the mechanism of priming. Four groups of subjects (two experimental and two control) were given a simulated biochemistry problem on Day 1 and a simulated molecular genetics problem on Day 2. For the two experimental groups, the solution to the biochemistry problem involved inhibition. For the two control groups, the solution did not involve inhibition. On Day 2, all subjects received the same version of the molecular genetics problem in which the solution involved the concept of inhibition. Subjects in the experimental conditions were more likely to attain the correct answer, to propose inhibition, and to propose inhibition early in the problemsolving session than were subjects in the control conditions. However, subjects in the experimental conditions made no reference to the biochemistry problem either in their verbal protocols or in a posttask questionnaire. The results are interpreted as demonstrating that an implicit process\u2014priming\u2014 can make old knowledge available for current problem solving."
            },
            "slug": "Priming,-analogy,-and-awareness-in-complex-Schunn-Dunbar",
            "title": {
                "fragments": [],
                "text": "Priming, analogy, and awareness in complex reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The hypothesis that even when subjects do not spontaneously make an analogy between two domains, knowledge of one domain can still spontaneously influence reasoning about the other domain via the mechanism of priming is tested."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724709"
                        ],
                        "name": "S. Arya",
                        "slug": "S.-Arya",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Arya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Arya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709509"
                        ],
                        "name": "D. Mount",
                        "slug": "D.-Mount",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mount",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mount"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712586"
                        ],
                        "name": "N. Netanyahu",
                        "slug": "N.-Netanyahu",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Netanyahu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Netanyahu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37746341"
                        ],
                        "name": "R. Silverman",
                        "slug": "R.-Silverman",
                        "structuredName": {
                            "firstName": "Ruth",
                            "lastName": "Silverman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Silverman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736712"
                        ],
                        "name": "A. Wu",
                        "slug": "A.-Wu",
                        "structuredName": {
                            "firstName": "Angela",
                            "lastName": "Wu",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "We used ANN for all of the examples shown in this paper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "In our experience, ANN generally provides more accurate results for the same computation time, although it is also more memory intensive."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "Although we have made use of several techniques to enhance performance (e.g., PCA, ANN), our algorithm is still rather slow, taking anywhere from on the order of tens of seconds to do simple texture synthesis, to a few minutes for the texture transfer\nexamples, to a few hours for the artistic renderings on a 1GHz PC processor."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "For the BESTAPPROXIMATEMATCH procedure, we have tried using both approximate-nearest-neighbor search (ANN) [1] and treestructured vector quantization (TSVQ) [20], using the same norm over the feature vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 229
                            }
                        ],
                        "text": "The algorithm can be described more precisely in pseudocode as follows:\nfunction CREATEIMAGEANALOGY(A, A\u2032, B): Compute Gaussian pyramids for A, A\u2032, and B Compute features for A, A\u2032, and B Initialize the search structures (e.g., for ANN) for each level , from coarsest to finest, do:\nfor each pixel q \u2208 B\u2032 , in scan-line order, do: p \u2190 BESTMATCH(A, A\u2032, B, B\u2032, s, , q) B\u2032 (q) \u2190 A\u2032 (p) s (q) \u2190 p\nreturn B\u2032L\nThe heart of the image analogies algorithm is the BESTMATCH subroutine."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 259
                            }
                        ],
                        "text": "First, in an initialization phase, multiscale (Gaussian pyramid) representations of A, A\u2032, and B is constructed, along with their feature vectors and some additional indices used for speeding the matching process (e.g., an approximate-nearest-neighbor search (ANN), as described below)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8193729,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "219101fe724232acc330ff0910152931538f85c7",
            "isKey": true,
            "numCitedBy": 2723,
            "numCiting": 94,
            "paperAbstract": {
                "fragments": [],
                "text": "Consider a set of <italic>S</italic> of <italic>n</italic> data points  in real <italic>d</italic>-dimensional space, R<supscrpt>d</supscrpt>, where distances are measured using any Minkowski metric. In nearest neighbor searching, we preprocess <italic>S</italic> into a data structure, so that given any query point <italic>q</italic><inline-equation> <f>\u2208</f></inline-equation> R<supscrpt>d</supscrpt>, is the closest point of S to <italic>q</italic> can be reported quickly. Given any positive real \u03b5, data point <italic>p</italic> is a (1 +\u03b5)-<italic>approximate nearest neighbor</italic> of <italic>q</italic> if its distance from <italic>q</italic> is within a factor of (1 + \u03b5) of the distance to the true nearest neighbor. We show that it is possible to preprocess a    set of <italic>n</italic> points in     R<supscrpt>d</supscrpt> in <italic>O(dn</italic> log <italic>n</italic>) time and <italic>O(dn)</italic> space, so that given a query point <italic> q</italic> <inline-equation> <f>\u2208</f></inline-equation> R<supscrpt>d</supscrpt>, and \u03b5 > 0, a (1 + \u03b5)-approximate nearest neighbor of <italic>q</italic> can be computed in <italic>O</italic>(<italic>c</italic><subscrpt><italic>d</italic>, \u03b5</subscrpt> log <italic>n</italic>) time, where <italic>c<subscrpt>d,\u03b5</subscrpt></italic>\u2264<italic>d</italic> <inline-equation> <f><fen lp=\"ceil\">1 + 6d/<g>e</g><rp post=\"ceil\"></fen></f></inline-equation>;<supscrpt>d</supscrpt> is a factor depending only on dimension and \u03b5. In general, we show that given an integer <italic>k</italic> \u2265 1, (1 + \u03b5)-approximations  to the  <italic>k</italic> nearest neighbors of <italic>q</italic> can  be computed in additional <italic>O(kd</italic> log <italic>n</italic>) time."
            },
            "slug": "An-optimal-algorithm-for-approximate-nearest-fixed-Arya-Mount",
            "title": {
                "fragments": [],
                "text": "An optimal algorithm for approximate nearest neighbor searching fixed dimensions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that it is possible to preprocess a set of data points in real D-dimensional space in O(kd) time and in additional space, so that given a query point q, the closest point of S to S to q can be reported quickly."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060896"
                        ],
                        "name": "P. Winston",
                        "slug": "P.-Winston",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Winston",
                            "middleNames": [
                                "Henry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Winston"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 254
                            }
                        ],
                        "text": "For this reason, a goal from the early days of artificial intelligence has been to build systems able to reason by analogy; early works include Evan\u2019s ANALOGY program [15] and Winston\u2019s seminal work on finding and exploiting parallels in simple theories [52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9814700,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7066d011f1eaa7b0ab3e97f683d2bda9d978131f",
            "isKey": false,
            "numCitedBy": 567,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We use analogy when we say something is a Cinderella story and when we learn about resistors by thinking about water pipes. We also use analogy when we learn subjects like economics, medicine, and law. This paper presents a theory of analogy and describes an implemented system that embodies the theory. The specific competence to be understood is that of using analogies to do certain kinds of learning and reasoning. Learning takes place when analogy is used to generate a constraint description in one domain, given a constraint description in another, as when we learn Ohm's law by way of knowledge about water pipes. Reasoning takes place when analogy is used to answer questions about one situation, given another situation that is supposed to be a precedent, as when we answer questions about Hamlet by way of knowledge about Macbeth."
            },
            "slug": "Learning-and-reasoning-by-analogy-Winston",
            "title": {
                "fragments": [],
                "text": "Learning and reasoning by analogy"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A theory of analogy is presented and an implemented system that embodies the theory is described that is designed to answer questions about Hamlet by way of knowledge about Macbeth."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "96524227"
                        ],
                        "name": "A. Koestler",
                        "slug": "A.-Koestler",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Koestler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Koestler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 77
                            }
                        ],
                        "text": "Analogical reasoning is central to problem solving, learning, and creativity [19, 31, 33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 144895955,
            "fieldsOfStudy": [
                "Art",
                "Psychology",
                "Education"
            ],
            "id": "04c12d5bd845611bf06e6808245702cc76c52ac5",
            "isKey": false,
            "numCitedBy": 2235,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "While the study of psychology has offered little in the way of explaining the creative process, Koestler examines the idea that we are at our most creative when rational thought is suspended--for example, in dreams and trancelike states. All who read The Act of Creation will find it a compelling and illuminating book."
            },
            "slug": "The-Act-of-Creation-Koestler",
            "title": {
                "fragments": [],
                "text": "The Act of Creation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704065"
                        ],
                        "name": "D. Gentner",
                        "slug": "D.-Gentner",
                        "structuredName": {
                            "firstName": "Dedre",
                            "lastName": "Gentner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gentner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5371492,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "c0373426c8e5579dcff60cc0bd930277822edc7d",
            "isKey": false,
            "numCitedBy": 2309,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "ion Anomaly No. of No. of attributes relations mopped to mapped to target target"
            },
            "slug": "Structure-Mapping:-A-Theoretical-Framework-for-Gentner",
            "title": {
                "fragments": [],
                "text": "Structure-Mapping: A Theoretical Framework for Analogy"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114114112"
                        ],
                        "name": "A. Erfos",
                        "slug": "A.-Erfos",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Erfos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Erfos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053571265"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18024979,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "b51c2dec05933ac14c1adc1796445805f8f1b38d",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Compositions are provided which protect keratinous material such as skin and hair from the deleterious effects of detergents and adverse climatic conditions. Said compositions contain a modified protein and a surface active agent."
            },
            "slug": "Quilting-for-Texture-Synthesis-and-Transfer-Erfos-Freeman",
            "title": {
                "fragments": [],
                "text": "Quilting for Texture Synthesis and Transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Compositions provided which protect keratinous material such as skin and hair from the deleterious effects of detergents and adverse climatic conditions contain a modified protein and a surface active agent."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118099045"
                        ],
                        "name": "James C. Miller",
                        "slug": "James-C.-Miller",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Miller",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James C. Miller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46508778,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24591ab0148144fa76035e380270646701ae11e1",
            "isKey": false,
            "numCitedBy": 658,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-graphics-principles-and-practice,-second-Miller",
            "title": {
                "fragments": [],
                "text": "Computer graphics principles and practice, second edition"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085584309"
                        ],
                        "name": "Ian Buck",
                        "slug": "Ian-Buck",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Buck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Buck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37737599"
                        ],
                        "name": "A. Finkelstein",
                        "slug": "A.-Finkelstein",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Finkelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Finkelstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10251113"
                        ],
                        "name": "C. Jacobs",
                        "slug": "C.-Jacobs",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jacobs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29614547"
                        ],
                        "name": "Allison W. Klein",
                        "slug": "Allison-W.-Klein",
                        "structuredName": {
                            "firstName": "Allison",
                            "lastName": "Klein",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Allison W. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2739862"
                        ],
                        "name": "Joshua E. Seims",
                        "slug": "Joshua-E.-Seims",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Seims",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua E. Seims"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769685"
                        ],
                        "name": "K. Toyama",
                        "slug": "K.-Toyama",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Toyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Toyama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53223328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48aaa75f722e684260c7d1fc033f6a87d10a3631",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Performance-driven-hand-drawn-animation-Buck-Finkelstein",
            "title": {
                "fragments": [],
                "text": "Performance-driven hand-drawn animation"
            },
            "venue": {
                "fragments": [],
                "text": "NPAR '00"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Buchanan . Comprehensive Halftoning of 3 D Scenes"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Graphics Forum"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Salesin . Computer - Generated Watercolor"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of SIGGRAPH"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Heeger and James R . Bergen . Pyramid - Based Texture Analysis / Synthesis"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of SIGGRAPH"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Salesin , and Irfan Essa . Video Textures"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Video Textures. Proceedings of SIGGRAPH 2000"
            },
            "venue": {
                "fragments": [],
                "text": "Video Textures. Proceedings of SIGGRAPH 2000"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Meier . Painterly Rendering for Animation"
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH 96 Conference Proceedings , pages 477 \u2013 484 , August"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fractal Image Compression . A.K. Peters Ltd"
            },
            "venue": {
                "fragments": [],
                "text": "Fractal Image Compression . A.K. Peters Ltd"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "We are grateful to Matthew Brand for suggesting that we look at histograms, and to Shlomo Gortler for showing us his students\u2019 work on texture transfer [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13] demonstrate a method for synthesizing texture to match a given image, work that we extend in this paper under the name \u201ctexture transfer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combining Textures and Pictures with Specialized Texture Synthesis, 2000. http://www.people.fas.harvard.edu/\u223cpritikin/cs/graphics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Curtis , Sean E . Anderson , Joshua E . Seims , Kurt W . Fleischer , and David H . Salesin . Computer - Generated Watercolor"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "For this reason, a goal from the early days of artificial intelligence has been to build systems able to reason by analogy; early works include Evan\u2019s ANALOGY program [15] and Winston\u2019s seminal work on finding and exploiting parallels in simple theories [52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A program for the solution of geometric analogy intelligence test questions"
            },
            "venue": {
                "fragments": [],
                "text": "Semantic Information Processing. MIT Press,"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Heeger and James R . Bergen . PyramidBased Texture Analysis / Synthesis"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of SIGGRAPH 95 , pages 229 \u2013 238 , August"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ", Ronen Barzel , and David H . Salesin . Interactive Pen \u2013 And \u2013 Ink Illustration"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "This paper describes a new framework for processing images by example, called \u201cimage analogies.\u201d"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dictionary of Philosophy of Mind"
            },
            "venue": {
                "fragments": [],
                "text": "Dictionary of Philosophy of Mind"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Salesin . Multiperspective panoramas for cel animation"
            },
            "venue": {
                "fragments": [],
                "text": "Communications of the ACM"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Michael Ashikhmin. Synthesizing Natural Textures. 2001 ACM Symposium on Interactive 3D Graphics"
            },
            "venue": {
                "fragments": [],
                "text": "Michael Ashikhmin. Synthesizing Natural Textures. 2001 ACM Symposium on Interactive 3D Graphics"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combining Textures and Pictures with Specialized Texture Synthesis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 96
                            }
                        ],
                        "text": "Recently, a number of EBR approaches to NPR have been proposed in a variety of research systems [8, 27, 30, 53]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Performance-driven handdrawn animation"
            },
            "venue": {
                "fragments": [],
                "text": "NPAR 2000: First International Symposium on Non Photorealistic Animation and Rendering,"
            },
            "year": 2000
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 22,
            "methodology": 16
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 67,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Image-analogies-Hertzmann-Jacobs/923562d216386a88947d40da310d94bbb1376a41?sort=total-citations"
}