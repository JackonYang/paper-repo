{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821711"
                        ],
                        "name": "Thang Luong",
                        "slug": "Thang-Luong",
                        "structuredName": {
                            "firstName": "Thang",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thang Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143950636"
                        ],
                        "name": "Hieu Pham",
                        "slug": "Hieu-Pham",
                        "structuredName": {
                            "firstName": "Hieu",
                            "lastName": "Pham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hieu Pham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 231
                            }
                        ],
                        "text": "\u2026leverage recurrence (Sutskever et al., 2014), convolution (Gehring et al., 2017; Kalchbrenner et al., 2016), attention (Vaswani et al., 2017), or a combination of recurrence and attention (Bahdanau et al., 2014; Cho et al., 2014; Luong et al., 2015; Wu et al., 2016) as basic building blocks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1998416,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93499a7c7f699b6630a86fad964536f9423bb6d0",
            "isKey": false,
            "numCitedBy": 5892,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there has been little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout. Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMT\u201915 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker. 1"
            },
            "slug": "Effective-Approaches-to-Attention-based-Neural-Luong-Pham",
            "title": {
                "fragments": [],
                "text": "Effective Approaches to Attention-based Neural Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A global approach which always attends to all source words and a local one that only looks at a subset of source words at a time are examined, demonstrating the effectiveness of both approaches on the WMT translation tasks between English and German in both directions."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40348417"
                        ],
                        "name": "Ashish Vaswani",
                        "slug": "Ashish-Vaswani",
                        "structuredName": {
                            "firstName": "Ashish",
                            "lastName": "Vaswani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashish Vaswani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846258"
                        ],
                        "name": "Noam M. Shazeer",
                        "slug": "Noam-M.-Shazeer",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Shazeer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam M. Shazeer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3877127"
                        ],
                        "name": "Niki Parmar",
                        "slug": "Niki-Parmar",
                        "structuredName": {
                            "firstName": "Niki",
                            "lastName": "Parmar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Niki Parmar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39328010"
                        ],
                        "name": "Jakob Uszkoreit",
                        "slug": "Jakob-Uszkoreit",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Uszkoreit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Uszkoreit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145024664"
                        ],
                        "name": "Llion Jones",
                        "slug": "Llion-Jones",
                        "structuredName": {
                            "firstName": "Llion",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llion Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19177000"
                        ],
                        "name": "Aidan N. Gomez",
                        "slug": "Aidan-N.-Gomez",
                        "structuredName": {
                            "firstName": "Aidan",
                            "lastName": "Gomez",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aidan N. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3443442"
                        ],
                        "name": "Illia Polosukhin",
                        "slug": "Illia-Polosukhin",
                        "structuredName": {
                            "firstName": "Illia",
                            "lastName": "Polosukhin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Illia Polosukhin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 96
                            }
                        ],
                        "text": "We compared our model using only relative position representations to the baseline Transformer (Vaswani et al., 2017) with sinusoidal position encodings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 19
                            }
                        ],
                        "text": ", 2016), attention (Vaswani et al., 2017), or a combination of recurrence and attention (Bahdanau et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 151
                            }
                        ],
                        "text": "The Transformer computes self-attention efficiently for all sequences, heads, and positions in a batch using parallel matrix multiplication operations (Vaswani et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 152
                            }
                        ],
                        "text": "The Transformer computes self-attention efficiently for all sequences, heads, and positions in\na batch using parallel matrix multiplication operations (Vaswani et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 17
                            }
                        ],
                        "text": "The Transformer (Vaswani et al., 2017) employs an encoder-decoder structure, consisting of stacked encoder and decoder layers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 95
                            }
                        ],
                        "text": "These position encodings can be a deterministic function of position (Sukhbaatar et al., 2015; Vaswani et al., 2017) or learned representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "We used the same warmup and decay strategy for learning rate as Vaswani et al. (2017), with 4,000 warmup steps."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 174
                            }
                        ],
                        "text": "For our machine translation experiments, the result was a modest 7% decrease in steps per second, but we were able to maintain the same model and batch sizes on P100 GPUs as Vaswani et al. (2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 149
                            }
                        ],
                        "text": "\u2026sequence learning typically leverage recurrence (Sutskever et al., 2014), convolution (Gehring et al., 2017; Kalchbrenner et al., 2016), attention (Vaswani et al., 2017), or a combination of recurrence and attention (Bahdanau et al., 2014; Cho et al., 2014; Luong et al., 2015; Wu et al., 2016) as\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13756489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "isKey": false,
            "numCitedBy": 35148,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
            },
            "slug": "Attention-is-All-you-Need-Vaswani-Shazeer",
            "title": {
                "fragments": [],
                "text": "Attention is All you Need"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely is proposed, which generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2265067"
                        ],
                        "name": "Sainbayar Sukhbaatar",
                        "slug": "Sainbayar-Sukhbaatar",
                        "structuredName": {
                            "firstName": "Sainbayar",
                            "lastName": "Sukhbaatar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sainbayar Sukhbaatar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3149531"
                        ],
                        "name": "Arthur D. Szlam",
                        "slug": "Arthur-D.-Szlam",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Szlam",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arthur D. Szlam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 70
                            }
                        ],
                        "text": "These position encodings can be a deterministic function of position (Sukhbaatar et al., 2015; Vaswani et al., 2017) or learned representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1399322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e",
            "isKey": false,
            "numCitedBy": 1990,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network [23] but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch [2] to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering [22] and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results."
            },
            "slug": "End-To-End-Memory-Networks-Sukhbaatar-Szlam",
            "title": {
                "fragments": [],
                "text": "End-To-End Memory Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A neural network with a recurrent attention model over a possibly large external memory that is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3444569"
                        ],
                        "name": "Petar Velickovic",
                        "slug": "Petar-Velickovic",
                        "structuredName": {
                            "firstName": "Petar",
                            "lastName": "Velickovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petar Velickovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7153363"
                        ],
                        "name": "Guillem Cucurull",
                        "slug": "Guillem-Cucurull",
                        "structuredName": {
                            "firstName": "Guillem",
                            "lastName": "Cucurull",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guillem Cucurull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8742492"
                        ],
                        "name": "Arantxa Casanova",
                        "slug": "Arantxa-Casanova",
                        "structuredName": {
                            "firstName": "Arantxa",
                            "lastName": "Casanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arantxa Casanova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144290131"
                        ],
                        "name": "Adriana Romero",
                        "slug": "Adriana-Romero",
                        "structuredName": {
                            "firstName": "Adriana",
                            "lastName": "Romero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adriana Romero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144269589"
                        ],
                        "name": "P. Lio\u2019",
                        "slug": "P.-Lio\u2019",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Lio\u2019",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lio\u2019"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 105
                            }
                        ],
                        "text": "There are practical space complexity concerns when considering edges between input elements, as noted by Velic\u030ckovic\u0301 et al. (2017), which considers unlabeled graph inputs to an attention model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3292002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33998aff64ce51df8dee45989cdca4b6b1329ec4",
            "isKey": false,
            "numCitedBy": 5524,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training)."
            },
            "slug": "Graph-Attention-Networks-Velickovic-Cucurull",
            "title": {
                "fragments": [],
                "text": "Graph Attention Networks"
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3282833"
                        ],
                        "name": "Z. Wojna",
                        "slug": "Z.-Wojna",
                        "structuredName": {
                            "firstName": "Zbigniew",
                            "lastName": "Wojna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Wojna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 64
                            }
                        ],
                        "text": "During training, we employed label smoothing of value ls = 0.1 (Szegedy et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": " = 0:98, and = 10 9. We used the same warmup and decay strategy for learning rate as Vaswani et al. (2017), with 4,000 warmup steps. During training, we employed label smoothing of value  ls = 0:1 (Szegedy et al., 2016). For evaluation, we used beam search with a beam size of 4 and length penalty = 0:6 (Wu et al.,2016). For our base model, we used 6 encoder and decoder layers, d x = 512, d z = 64, 8 attention heads,"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206593880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23ffaa0fe06eae05817f527a47ac3291077f9e58",
            "isKey": true,
            "numCitedBy": 15542,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5% top-5 error and 17:3% top-1 error on the validation set and 3:6% top-5 error on the official test set."
            },
            "slug": "Rethinking-the-Inception-Architecture-for-Computer-Szegedy-Vanhoucke",
            "title": {
                "fragments": [],
                "text": "Rethinking the Inception Architecture for Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work is exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48607963"
                        ],
                        "name": "Yonghui Wu",
                        "slug": "Yonghui-Wu",
                        "structuredName": {
                            "firstName": "Yonghui",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yonghui Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144927151"
                        ],
                        "name": "M. Schuster",
                        "slug": "M.-Schuster",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Schuster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schuster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2545358"
                        ],
                        "name": "Z. Chen",
                        "slug": "Z.-Chen",
                        "structuredName": {
                            "firstName": "Z.",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144739074"
                        ],
                        "name": "Mohammad Norouzi",
                        "slug": "Mohammad-Norouzi",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Norouzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohammad Norouzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3153147"
                        ],
                        "name": "Wolfgang Macherey",
                        "slug": "Wolfgang-Macherey",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Macherey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Macherey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2048712"
                        ],
                        "name": "M. Krikun",
                        "slug": "M.-Krikun",
                        "structuredName": {
                            "firstName": "Maxim",
                            "lastName": "Krikun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krikun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145144022"
                        ],
                        "name": "Yuan Cao",
                        "slug": "Yuan-Cao",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145312180"
                        ],
                        "name": "Qin Gao",
                        "slug": "Qin-Gao",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qin Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113439369"
                        ],
                        "name": "Klaus Macherey",
                        "slug": "Klaus-Macherey",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Macherey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klaus Macherey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2367620"
                        ],
                        "name": "J. Klingner",
                        "slug": "J.-Klingner",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Klingner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Klingner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145825976"
                        ],
                        "name": "Apurva Shah",
                        "slug": "Apurva-Shah",
                        "structuredName": {
                            "firstName": "Apurva",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Apurva Shah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145657834"
                        ],
                        "name": "Melvin Johnson",
                        "slug": "Melvin-Johnson",
                        "structuredName": {
                            "firstName": "Melvin",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Melvin Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109059862"
                        ],
                        "name": "Xiaobing Liu",
                        "slug": "Xiaobing-Liu",
                        "structuredName": {
                            "firstName": "Xiaobing",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaobing Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2776283"
                        ],
                        "name": "Stephan Gouws",
                        "slug": "Stephan-Gouws",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Gouws",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephan Gouws"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2739610"
                        ],
                        "name": "Y. Kato",
                        "slug": "Y.-Kato",
                        "structuredName": {
                            "firstName": "Yoshikiyo",
                            "lastName": "Kato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Kato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765329"
                        ],
                        "name": "Taku Kudo",
                        "slug": "Taku-Kudo",
                        "structuredName": {
                            "firstName": "Taku",
                            "lastName": "Kudo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taku Kudo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754386"
                        ],
                        "name": "H. Kazawa",
                        "slug": "H.-Kazawa",
                        "structuredName": {
                            "firstName": "Hideto",
                            "lastName": "Kazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144077726"
                        ],
                        "name": "K. Stevens",
                        "slug": "K.-Stevens",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Stevens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Stevens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753079661"
                        ],
                        "name": "George Kurian",
                        "slug": "George-Kurian",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Kurian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George Kurian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056800684"
                        ],
                        "name": "Nishant Patil",
                        "slug": "Nishant-Patil",
                        "structuredName": {
                            "firstName": "Nishant",
                            "lastName": "Patil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nishant Patil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49337181"
                        ],
                        "name": "Wei Wang",
                        "slug": "Wei-Wang",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39660914"
                        ],
                        "name": "C. Young",
                        "slug": "C.-Young",
                        "structuredName": {
                            "firstName": "Cliff",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119125158"
                        ],
                        "name": "Jason R. Smith",
                        "slug": "Jason-R.-Smith",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909504"
                        ],
                        "name": "Jason Riesa",
                        "slug": "Jason-Riesa",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Riesa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Riesa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29951847"
                        ],
                        "name": "Alex Rudnick",
                        "slug": "Alex-Rudnick",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Rudnick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Rudnick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48342565"
                        ],
                        "name": "Macduff Hughes",
                        "slug": "Macduff-Hughes",
                        "structuredName": {
                            "firstName": "Macduff",
                            "lastName": "Hughes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Macduff Hughes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3603249,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbde7dfa6cae81df8ac19ef500c42db96c3d1edd",
            "isKey": false,
            "numCitedBy": 4645,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT's use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (\"wordpieces\") for both input and output. This method provides a good balance between the flexibility of \"character\"-delimited models and the efficiency of \"word\"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google's phrase-based production system."
            },
            "slug": "Google's-Neural-Machine-Translation-System:-the-Gap-Wu-Schuster",
            "title": {
                "fragments": [],
                "text": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "GNMT, Google's Neural Machine Translation system, is presented, which attempts to address many of the weaknesses of conventional phrase-based translation systems and provides a good balance between the flexibility of \"character\"-delimited models and the efficiency of \"word\"-delicited models."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 82
                            }
                        ],
                        "text": "Recent approaches to sequence to sequence learning typically leverage recurrence (Sutskever et al., 2014), convolution (Gehring et al., 2017; Kalchbrenner et al., 2016), attention (Vaswani et al., 2017), or a combination of recurrence and attention (Bahdanau et al., 2014; Cho et al., 2014; Luong et\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 81
                            }
                        ],
                        "text": "Recent approaches to sequence to sequence learning typically leverage recurrence (Sutskever et al., 2014), convolution (Gehring et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7961699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "isKey": false,
            "numCitedBy": 14880,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier."
            },
            "slug": "Sequence-to-Sequence-Learning-with-Neural-Networks-Sutskever-Vinyals",
            "title": {
                "fragments": [],
                "text": "Sequence to Sequence Learning with Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure, and finds that reversing the order of the words in all source sentences improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2583391"
                        ],
                        "name": "Nal Kalchbrenner",
                        "slug": "Nal-Kalchbrenner",
                        "structuredName": {
                            "firstName": "Nal",
                            "lastName": "Kalchbrenner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nal Kalchbrenner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2311318"
                        ],
                        "name": "Lasse Espeholt",
                        "slug": "Lasse-Espeholt",
                        "structuredName": {
                            "firstName": "Lasse",
                            "lastName": "Espeholt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lasse Espeholt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422336"
                        ],
                        "name": "A\u00e4ron van den Oord",
                        "slug": "A\u00e4ron-van-den-Oord",
                        "structuredName": {
                            "firstName": "A\u00e4ron",
                            "lastName": "Oord",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A\u00e4ron van den Oord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 142
                            }
                        ],
                        "text": "Recent approaches to sequence to sequence learning typically leverage recurrence (Sutskever et al., 2014), convolution (Gehring et al., 2017; Kalchbrenner et al., 2016), attention (Vaswani et al., 2017), or a combination of recurrence and attention (Bahdanau et al., 2014; Cho et al., 2014; Luong et\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 21
                            }
                        ],
                        "text": ", 2014), convolution (Gehring et al., 2017; Kalchbrenner et al., 2016), attention (Vaswani et al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13895969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98445f4172659ec5e891e031d8202c102135c644",
            "isKey": false,
            "numCitedBy": 454,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel neural network for processing sequences. The ByteNet is a one-dimensional convolutional neural network that is composed of two parts, one to encode the source sequence and the other to decode the target sequence. The two network parts are connected by stacking the decoder on top of the encoder and preserving the temporal resolution of the sequences. To address the differing lengths of the source and the target, we introduce an efficient mechanism by which the decoder is dynamically unfolded over the representation of the encoder. The ByteNet uses dilation in the convolutional layers to increase its receptive field. The resulting network has two core properties: it runs in time that is linear in the length of the sequences and it sidesteps the need for excessive memorization. The ByteNet decoder attains state-of-the-art performance on character-level language modelling and outperforms the previous best results obtained with recurrent networks. The ByteNet also achieves state-of-the-art performance on character-to-character machine translation on the English-to-German WMT translation task, surpassing comparable neural translation models that are based on recurrent networks with attentional pooling and run in quadratic time. We find that the latent alignment structure contained in the representations reflects the expected alignment between the tokens."
            },
            "slug": "Neural-Machine-Translation-in-Linear-Time-Kalchbrenner-Espeholt",
            "title": {
                "fragments": [],
                "text": "Neural Machine Translation in Linear Time"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The ByteNet decoder attains state-of-the-art performance on character-level language modelling and outperforms the previous best results obtained with recurrent networks and the latent alignment structure contained in the representations reflects the expected alignment between the tokens."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 190
                            }
                        ],
                        "text": "\u2026leverage recurrence (Sutskever et al., 2014), convolution (Gehring et al., 2017; Kalchbrenner et al., 2016), attention (Vaswani et al., 2017), or a combination of recurrence and attention (Bahdanau et al., 2014; Cho et al., 2014; Luong et al., 2015; Wu et al., 2016) as basic building blocks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 54
                            }
                        ],
                        "text": ", 2017), or a combination of recurrence and attention (Bahdanau et al., 2014; Cho et al., 2014; Luong et al., 2015; Wu et al., 2016) as basic building blocks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11212020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "isKey": false,
            "numCitedBy": 19339,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition."
            },
            "slug": "Neural-Machine-Translation-by-Jointly-Learning-to-Bahdanau-Cho",
            "title": {
                "fragments": [],
                "text": "Neural Machine Translation by Jointly Learning to Align and Translate"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and it is proposed to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2401865"
                        ],
                        "name": "Jonas Gehring",
                        "slug": "Jonas-Gehring",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "Gehring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonas Gehring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2325985"
                        ],
                        "name": "Michael Auli",
                        "slug": "Michael-Auli",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Auli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Auli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529182"
                        ],
                        "name": "David Grangier",
                        "slug": "David-Grangier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Grangier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Grangier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13759615"
                        ],
                        "name": "Denis Yarats",
                        "slug": "Denis-Yarats",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Yarats",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Denis Yarats"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2921469"
                        ],
                        "name": "Yann Dauphin",
                        "slug": "Yann-Dauphin",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Dauphin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann Dauphin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 120
                            }
                        ],
                        "text": "Recent approaches to sequence to sequence learning typically leverage recurrence (Sutskever et al., 2014), convolution (Gehring et al., 2017; Kalchbrenner et al., 2016), attention (Vaswani et al., 2017), or a combination of recurrence and attention (Bahdanau et al., 2014; Cho et al., 2014; Luong et\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 21
                            }
                        ],
                        "text": ", 2014), convolution (Gehring et al., 2017; Kalchbrenner et al., 2016), attention (Vaswani et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 63
                            }
                        ],
                        "text": "They have been shown to still benefit from position encodings (Gehring et al., 2017), however."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3648736,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43428880d75b3a14257c3ee9bda054e61eb869c0",
            "isKey": false,
            "numCitedBy": 2422,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "The prevalent approach to sequence to sequence learning maps an input sequence to a variable length output sequence via recurrent neural networks. We introduce an architecture based entirely on convolutional neural networks. Compared to recurrent models, computations over all elements can be fully parallelized during training and optimization is easier since the number of non-linearities is fixed and independent of the input length. Our use of gated linear units eases gradient propagation and we equip each decoder layer with a separate attention module. We outperform the accuracy of the deep LSTM setup of Wu et al. (2016) on both WMT'14 English-German and WMT'14 English-French translation at an order of magnitude faster speed, both on GPU and CPU."
            },
            "slug": "Convolutional-Sequence-to-Sequence-Learning-Gehring-Auli",
            "title": {
                "fragments": [],
                "text": "Convolutional Sequence to Sequence Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work introduces an architecture based entirely on convolutional neural networks, which outperform the accuracy of the deep LSTM setup of Wu et al. (2016) on both WMT'14 English-German and WMT-French translation at an order of magnitude faster speed, both on GPU and CPU."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144729897"
                        ],
                        "name": "Ankur P. Parikh",
                        "slug": "Ankur-P.-Parikh",
                        "structuredName": {
                            "firstName": "Ankur",
                            "lastName": "Parikh",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ankur P. Parikh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2556289"
                        ],
                        "name": "Oscar T\u00e4ckstr\u00f6m",
                        "slug": "Oscar-T\u00e4ckstr\u00f6m",
                        "structuredName": {
                            "firstName": "Oscar",
                            "lastName": "T\u00e4ckstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oscar T\u00e4ckstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143790066"
                        ],
                        "name": "Dipanjan Das",
                        "slug": "Dipanjan-Das",
                        "structuredName": {
                            "firstName": "Dipanjan",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dipanjan Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39328010"
                        ],
                        "name": "Jakob Uszkoreit",
                        "slug": "Jakob-Uszkoreit",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Uszkoreit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Uszkoreit"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 109
                            }
                        ],
                        "text": "Attention-based models have therefore used position encodings or biased attention weights based on distance (Parikh et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8495258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2cd8e8f510c89c7c18268e8ad51c061e459ad321",
            "isKey": false,
            "numCitedBy": 1059,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a simple neural architecture for natural language inference. Our approach uses attention to decompose the problem into subproblems that can be solved separately, thus making it trivially parallelizable. On the Stanford Natural Language Inference (SNLI) dataset, we obtain state-of-the-art results with almost an order of magnitude fewer parameters than previous work and without relying on any word-order information. Adding intra-sentence attention that takes a minimum amount of order into account yields further improvements."
            },
            "slug": "A-Decomposable-Attention-Model-for-Natural-Language-Parikh-T\u00e4ckstr\u00f6m",
            "title": {
                "fragments": [],
                "text": "A Decomposable Attention Model for Natural Language Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work proposes a simple neural architecture for natural language inference that uses attention to decompose the problem into subproblems that can be solved separately, thus making it trivially parallelizable."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 27
                            }
                        ],
                        "text": "We used the Adam optimizer (Kingma and Ba, 2014) with \u03b21 = 0."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 90054,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3158246"
                        ],
                        "name": "Bart van Merrienboer",
                        "slug": "Bart-van-Merrienboer",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Merrienboer",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bart van Merrienboer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854385"
                        ],
                        "name": "\u00c7aglar G\u00fcl\u00e7ehre",
                        "slug": "\u00c7aglar-G\u00fcl\u00e7ehre",
                        "structuredName": {
                            "firstName": "\u00c7aglar",
                            "lastName": "G\u00fcl\u00e7ehre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c7aglar G\u00fcl\u00e7ehre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076086"
                        ],
                        "name": "Fethi Bougares",
                        "slug": "Fethi-Bougares",
                        "structuredName": {
                            "firstName": "Fethi",
                            "lastName": "Bougares",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fethi Bougares"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 213
                            }
                        ],
                        "text": "\u2026leverage recurrence (Sutskever et al., 2014), convolution (Gehring et al., 2017; Kalchbrenner et al., 2016), attention (Vaswani et al., 2017), or a combination of recurrence and attention (Bahdanau et al., 2014; Cho et al., 2014; Luong et al., 2015; Wu et al., 2016) as basic building blocks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 54
                            }
                        ],
                        "text": ", 2017), or a combination of recurrence and attention (Bahdanau et al., 2014; Cho et al., 2014; Luong et al., 2015; Wu et al., 2016) as basic building blocks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5590763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b544dfe355a5070b60986319a3f51fb45d1348e",
            "isKey": false,
            "numCitedBy": 15050,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel neural network model called RNN Encoder\u2010 Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder\u2010Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases."
            },
            "slug": "Learning-Phrase-Representations-using-RNN-for-Cho-Merrienboer",
            "title": {
                "fragments": [],
                "text": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Qualitatively, the proposed RNN Encoder\u2010Decoder model learns a semantically and syntactically meaningful representation of linguistic phrases."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51131802"
                        ],
                        "name": "J. Kiros",
                        "slug": "J.-Kiros",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Kiros",
                            "middleNames": [
                                "Ryan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kiros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 92
                            }
                        ],
                        "text": "It uses residual connections around each of the sublayers, followed by layer normalization (Ba et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8236317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97fb4e3d45bb098e27e0071448b6152217bd35a5",
            "isKey": false,
            "numCitedBy": 3049,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feedforward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques."
            },
            "slug": "Layer-Normalization-Ba-Kiros",
            "title": {
                "fragments": [],
                "text": "Layer Normalization"
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 70
                            }
                        ],
                        "text": "These position encodings can be a deterministic function of position (Sukhbaatar et al., 2015; Vaswani et al., 2017) or learned representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "End-to-end memory networks. In Advances in neural information processing systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "End - toend memory networks"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in neural information processing systems"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 231
                            }
                        ],
                        "text": "\u2026leverage recurrence (Sutskever et al., 2014), convolution (Gehring et al., 2017; Kalchbrenner et al., 2016), attention (Vaswani et al., 2017), or a combination of recurrence and attention (Bahdanau et al., 2014; Cho et al., 2014; Luong et al., 2015; Wu et al., 2016) as basic building blocks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 54
                            }
                        ],
                        "text": ", 2017), or a combination of recurrence and attention (Bahdanau et al., 2014; Cho et al., 2014; Luong et al., 2015; Wu et al., 2016) as basic building blocks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Effective approaches to attentionbased neural machine translation"
            },
            "venue": {
                "fragments": [],
                "text": "arXiv preprint arXiv:1508.04025 ."
            },
            "year": 2015
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Self-Attention-with-Relative-Position-Shaw-Uszkoreit/c8efcc854d97dfc2a42b83316a2109f9d166e43f?sort=total-citations"
}