{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2396681"
                        ],
                        "name": "D. Eck",
                        "slug": "D.-Eck",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Eck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Eck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 146
                            }
                        ],
                        "text": "\u2026existing models output only monophonic notes along with predefined chords or other reduced-dimensionality representation (e.g. Mozer, 1994; Eck & Schmidhuber, 2002; Paiement et al., 2009), we aim to model unconstrained polyphonic music in the piano-roll representation, i.e. as a binary matrix\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 146
                            }
                        ],
                        "text": "\u2026most existing models output only monophonic notes along with predefined chords or other reduced-dimensionality representation (e.g. Mozer, 1994; Eck & Schmidhuber, 2002; Paiement et al., 2009), we aim to model unconstrained polyphonic music in the piano-roll representation, i.e. as a binary\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 579926,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4ffd2f5dd98ee744c013060c5bc06503336d931",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of extracting essential ingredients of music signals, such as a well-defined global temporal structure in the form of nested periodicities (or meter). We investigate whether we can construct an adaptive signal processing device that learns by example how to generate new instances of a given musical style. Because recurrent neural networks (RNNs) can, in principle, learn the temporal structure of a signal, they are good candidates for such a task. Unfortunately, music composed by standard RNNs often lacks global coherence. The reason for this failure seems to be that RNNs cannot keep track of temporally distant events that indicate global music structure. Long short-term memory (LSTM) has succeeded in similar domains where other RNNs have failed, such as timing and counting and the learning of context sensitive languages. We show that LSTM is also a good mechanism for learning to compose music. We present experimental results showing that LSTM successfully learns a form of blues music and is able to compose novel (and we believe pleasing) melodies in that style. Remarkably, once the network has found the relevant structure, it does not drift from it: LSTM is able to play the blues with good timing and proper structure as long as one is willing to listen."
            },
            "slug": "Finding-temporal-structure-in-music:-blues-with-Eck-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Finding temporal structure in music: blues improvisation with LSTM recurrent networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Long short-term memory (LSTM) has succeeded in similar domains where other RNNs have failed, such as timing and counting and the learning of context sensitive languages, and it is shown that LSTM is also a good mechanism for learning to compose music."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 12th IEEE Workshop on Neural Networks for Signal Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39651651"
                        ],
                        "name": "Jean-Fran\u00e7ois Paiement",
                        "slug": "Jean-Fran\u00e7ois-Paiement",
                        "structuredName": {
                            "firstName": "Jean-Fran\u00e7ois",
                            "lastName": "Paiement",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Fran\u00e7ois Paiement"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2396681"
                        ],
                        "name": "D. Eck",
                        "slug": "D.-Eck",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Eck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Eck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 132
                            }
                        ],
                        "text": "While most existing models output only monophonic notes along with predefined chords or other reduced-dimensionality representation (e.g. Mozer, 1994; Eck & Schmidhuber, 2002; Paiement et al., 2009), we aim to model unconstrained polyphonic music in the piano-roll representation, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 150
                            }
                        ],
                        "text": "\u2026output only monophonic notes along with predefined chords or other reduced-dimensionality representation (e.g. Mozer, 1994; Eck & Schmidhuber, 2002; Paiement et al., 2009), we aim to model unconstrained polyphonic music in the piano-roll representation, i.e. as a binary matrix specifying precisely\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17913104,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "831b3a28c070a0a6047c13848f49159eac069b1c",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-models-for-melodic-prediction-Paiement-Bengio",
            "title": {
                "fragments": [],
                "text": "Probabilistic models for melodic prediction"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2142019"
                        ],
                        "name": "Graham E. Poliner",
                        "slug": "Graham-E.-Poliner",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Poliner",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham E. Poliner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745455"
                        ],
                        "name": "D. Ellis",
                        "slug": "D.-Ellis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ellis",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ellis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 76
                            }
                        ],
                        "text": "Piano-midi.de is a classical piano MIDI archive that was split according to Poliner & Ellis (2007)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5719274,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "598d394d156aab29eab94a9b38461e211f8ba0b3",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a discriminative model for polyphonic piano transcription. Support vector machines trained on spectral features are used to classify frame-level note instances. The classifier outputs are temporally constrained via hidden Markov models, and the proposed system is used to transcribe both synthesized and real piano recordings. A frame-level transcription accuracy of 68% was achieved on a newly generated test set, and direct comparisons to previous approaches are provided."
            },
            "slug": "A-Discriminative-Model-for-Polyphonic-Piano-Poliner-Ellis",
            "title": {
                "fragments": [],
                "text": "A Discriminative Model for Polyphonic Piano Transcription"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A discriminative model for polyphonic piano transcription is presented and a frame-level transcription accuracy of 68% was achieved on a newly generated test set, and direct comparisons to previous approaches are provided."
            },
            "venue": {
                "fragments": [],
                "text": "EURASIP J. Adv. Signal Process."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144473519"
                        ],
                        "name": "M. Mozer",
                        "slug": "M.-Mozer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mozer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mozer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 138
                            }
                        ],
                        "text": "While most existing models output only monophonic notes along with predefined chords or other reduced-dimensionality representation (e.g. Mozer, 1994; Eck & Schmidhuber, 2002; Paiement et al., 2009), we aim to model unconstrained polyphonic music in the piano-roll representation, i.e. as a binary\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1675838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69a8e331ea493894066d003ab3e5987d30527b06",
            "isKey": false,
            "numCitedBy": 235,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In algorithmic music composition, a simple technique involves selecting notes sequentially according to a transition table that specifies the probability of the next note as a function of the previous context. An extension of this transition-table approach is described, using a recurrent autopredictive connectionist network called CONCERT. CONCERT is trained on a set of pieces with the aim of extracting stylistic regularities. CONCERT can then be used to compose new pieces. A central ingredient of CONCERT is the incorporation of psychologically grounded representations of pitch, duration and harmonic structure. CONCERT was tested on sets of examples artificially generated according to simple rules and was shown to learn the underlying structure, even where other approaches failed. In larger experiments, CONCERT was trained on sets of J. S. Bach pieces and traditional European folk melodies and was then allowed to compose novel melodies. Although the compositions are occasionally pleasant, and are..."
            },
            "slug": "Neural-Network-Music-Composition-by-Prediction:-the-Mozer",
            "title": {
                "fragments": [],
                "text": "Neural Network Music Composition by Prediction: Exploring the Benefits of Psychoacoustic Constraints and Multi-scale Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An extension of this transition-table approach is described, using a recurrent autopredictive connectionist network called CONCERT, which is trained on a set of pieces with the aim of extracting stylistic regularities and incorporation of psychologically grounded representations of pitch, duration and harmonic structure."
            },
            "venue": {
                "fragments": [],
                "text": "Connect. Sci."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145578392"
                        ],
                        "name": "Juhan Nam",
                        "slug": "Juhan-Nam",
                        "structuredName": {
                            "firstName": "Juhan",
                            "lastName": "Nam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juhan Nam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2020608"
                        ],
                        "name": "Jiquan Ngiam",
                        "slug": "Jiquan-Ngiam",
                        "structuredName": {
                            "firstName": "Jiquan",
                            "lastName": "Ngiam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiquan Ngiam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145290352"
                        ],
                        "name": "M. Slaney",
                        "slug": "M.-Slaney",
                        "structuredName": {
                            "firstName": "Malcolm",
                            "lastName": "Slaney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Slaney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 127
                            }
                        ],
                        "text": "Digital audio has been generated for the four datasets and we report in Figure 5 the frame-level transcription accuracy of the Nam et al. (2011) algorithm, either alone, after HMM smoothing, or using our best performing model as a symbolic prior."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 198
                            }
                        ],
                        "text": "However, combining these two sources of information is not trivial, with the result that temporal smoothing with an HMM is often the only post-processing involved in state-of-the-art transcription (Nam et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 69
                            }
                        ],
                        "text": "We combine our polyphonic sequence models with the acoustic model of Nam et al. (2011) in order to demonstrate a practical application of the sequence models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 24
                            }
                        ],
                        "text": "At each time frame, the Nam et al. (2011) algorithm outputs independent probabilities that each note is present and reports every note with probability p \u2265 0.5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14661817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4de9647f1102dbe3718a9534fd51121d97389e78",
            "isKey": true,
            "numCitedBy": 78,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Recentlyunsupervisedfeaturelearningmethodshaveshown great promise as a way of extracting features from high dimensional data, such as image or audio. In this paper, we apply deep belief networks to musical data and evaluate the learned feature representations on classification-based polyphonic piano transcription. We also suggest a way of training classifiers jointly for multiple notes to improve training speed and classification performance. Our method is evaluated on three public piano datasets. The results show that the learned features outperform the baseline features, and also our method gives significantly better frame-level accuracy than other state-of-the-art music transcription methods."
            },
            "slug": "A-Classification-Based-Polyphonic-Piano-Approach-Nam-Ngiam",
            "title": {
                "fragments": [],
                "text": "A Classification-Based Polyphonic Piano Transcription Approach Using Learned Feature Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper applies deep belief networks to musical data and evaluates the learned feature representations on classification-based polyphonic piano transcription and suggests a way of training classifiers jointly for multiple notes to improve training speed and classification performance."
            },
            "venue": {
                "fragments": [],
                "text": "ISMIR"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757708"
                        ],
                        "name": "V. Lavrenko",
                        "slug": "V.-Lavrenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lavrenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lavrenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143998882"
                        ],
                        "name": "Jeremy Pickens",
                        "slug": "Jeremy-Pickens",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Pickens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeremy Pickens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 31
                            }
                        ],
                        "text": "\u2022 The \u2018random fields\u2019 approach of Lavrenko & Pickens (2003) is a type of fully visible sigmoid belief network with learned connectivity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fbd89f915ae5fd06e8e105d30132372b5433c0e",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent interest in the area of music information retrieval and related technologies is exploding. However, very few of the existing techniques take advantage of recent developments in statistical modeling. In this paper we discuss an application of Random Fields to the problem of creating accurate yet flexible statistical models of polyphonic music. With such models in hand, the challenges of developing effective searching, browsing and organization techniques for the growing bodies of music collections may be successfully met. We offer an evaluation of these models in terms of perplexity and prediction accuracy, and show that random fields not only outperform Markov chains, but are much more robust in terms of overfitting."
            },
            "slug": "Polyphonic-music-modeling-with-random-fields-Lavrenko-Pickens",
            "title": {
                "fragments": [],
                "text": "Polyphonic music modeling with random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper discusses an application of Random Fields to the problem of creating accurate yet flexible statistical models of polyphonic music, and shows that random fields not only outperform Markov chains, but are much more robust in terms of overfitting."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9235290"
                        ],
                        "name": "A. Cemgil",
                        "slug": "A.-Cemgil",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Cemgil",
                            "middleNames": [
                                "Taylan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cemgil"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 237
                            }
                        ],
                        "text": "It has long been known that, in the same way that natural language models tremendously improve the performance of speech recognition systems, musical language models can improve purely auditive approaches to music information retrieval (Cemgil, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 70453797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5dde63cea9931a139422f6ddfbe153fc7d18c4aa",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "Music transcription refers to extraction of a human readable and interpretable description from a recording of a music performance. The final goal is to implement a program that can automatically infer a musical notation that lists the pitch levels of notes and corresponding score positions in any arbitrary acoustical input. However, in this full generality, music transcription stays yet as a very hard problem and is arguably ``AI-complete'', i.e. requires simulation of a human level intelligence. On the other hand, under some realistic assumptions, a practical engineering solution is possible by an interplay of scientific knowledge from cognitive science, musicology, musical acoustics and computational techniques from artificial intelligence, machine learning and digital signal processing. In this context, the aim of this thesis is to integrate this vast amount of prior knowledge in a consistent and transparent computational framework and to demonstrate the feasibility of such an approach in moving us closer to a practical solution to music transcription. In this thesis, we approach music transcription as a statistical inference problem where given a signal, we search for a score that is consistent with the encoded music. In this context, we identify three subproblems: Rhythm Quantization, Tempo Tracking and Polyphonic Pitch Tracking. For each subproblem, we define a probabilistic generative model, that relates the observables (i.e. onsets or audio signal) with the underlying score. Conceptually, the transcription task is then to 'invert' this generative model by using the Bayes Theorem and recover back the original score"
            },
            "slug": "Bayesian-Music-Transcription-Cemgil",
            "title": {
                "fragments": [],
                "text": "Bayesian Music Transcription"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The aim of this thesis is to integrate this vast amount of prior knowledge in a consistent and transparent computational framework and to demonstrate the feasibility of such an approach in moving us closer to a practical solution to music transcription."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 230
                            }
                        ],
                        "text": "\u2026we wish to exploit the ability of RBMs to represent a complicated distribution for each time step, with parameters that depend on the previous ones, an idea first put forward with the so-called temporal RBM (Taylor et al., 2007; Sutskever & Hinton, 2007) which is trained via a heuristic procedure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2837110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c74e230a5a6fd5e2db6ace765ce38afe65f96214",
            "isKey": false,
            "numCitedBy": 242,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new family of non-linear sequence models that are substantially more powerful than hidden Markov models or linear dynamical systems. Our models have simple approximate inference and learning procedures that work well in practice. Multilevel representations of sequential data can be learned one hidden layer at a time, and adding extra hidden layers improves the resulting generative models. The models can be trained with very high-dimensional, very non-linear data such as raw pixel sequences. Their performance is demonstrated using synthetic video sequences of two balls bouncing in a box."
            },
            "slug": "Learning-Multilevel-Distributed-Representations-for-Sutskever-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning Multilevel Distributed Representations for High-Dimensional Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new family of non-linear sequence models that are substantially more powerful than hidden Markov models or linear dynamical systems are described, and their performance is demonstrated using synthetic video sequences of two balls bouncing in a box."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121704378"
                        ],
                        "name": "Yipeng Li",
                        "slug": "Yipeng-Li",
                        "structuredName": {
                            "firstName": "Yipeng",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yipeng Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38053687"
                        ],
                        "name": "Deliang Wang",
                        "slug": "Deliang-Wang",
                        "structuredName": {
                            "firstName": "Deliang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deliang Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 176
                            }
                        ],
                        "text": "Most existing transcription algorithms are frame-based and rely exclusively on the audio signal, even though some approaches employ rudimentary musicological constraints (e.g. Li & Wang, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 134
                            }
                        ],
                        "text": "We combine our polyphonic sequence models with the acoustic model of Nam et al. (2011) in order to demonstrate a practical application of the sequence models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11248882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d99530af7203ae6b40f1d42aaa26e3ffb836a3fc",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a hidden Markov model (HMM) based system to detect the pitch of an instrument in polyphonic music using an instrument tone model. Our system calculates at every time frame the salience of a pitch hypothesis based on the magnitudes of harmonics associated with the hypothesis. A hypothesis selection method is introduced to choose pitch hypotheses with sufficiently high salience as pitch candidates. Then the system applies an instrument model to evaluate the likelihood of each candidate. The transition probability between successive pitch points is constructed using the prior knowledge of the musical key of the input. Finally an HMM integrates the instrument likelihood and the pitch transition probability. Quantitative evaluation shows the proposed system performs well for different instruments. We also compare a Gaussian mixture model and kernel density estimation for instrument modeling, and find that kernel density estimation gives better overall performance while the Gaussian mixture model is more robust."
            },
            "slug": "Pitch-Detection-in-Polyphonic-Music-using-Tone-Li-Wang",
            "title": {
                "fragments": [],
                "text": "Pitch Detection in Polyphonic Music using Instrument Tone Models"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A hidden Markov model (HMM) based system to detect the pitch of an instrument in polyphonic music using an instrument tone model and a hypothesis selection method to choose pitch hypotheses with sufficiently high salience as pitch candidates is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2621946"
                        ],
                        "name": "B. Schrauwen",
                        "slug": "B.-Schrauwen",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Schrauwen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schrauwen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981334"
                        ],
                        "name": "Lars Buesing",
                        "slug": "Lars-Buesing",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Buesing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lars Buesing"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 84
                            }
                        ],
                        "text": "A similar architecture based on the echo state network was also recently developed (Schrauwen & Buesing, 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14750487,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0113c0d62be40a3c64b1151df1055546146b56ea",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Generative models for sequential data based on directed graphs of Restricted Boltzmann Machines (RBMs) are able to accurately model high dimensional sequences as recently shown. In these models, temporal dependencies in the input are discovered by either buffering previous visible variables or by recurrent connections of the hidden variables. Here we propose a modification of these models, the Temporal Reservoir Machine (TRM). It utilizes a recurrent artificial neural network (ANN) for integrating information from the input over \ntime. This information is then fed into a RBM at each time step. To avoid difficulties of recurrent network learning, the ANN remains untrained and hence can be thought of as a random feature extractor. Using the architecture of multi-layer RBMs (Deep Belief Networks), the TRMs can be used as a building block for complex hierarchical models. This approach unifies RBM-based approaches for sequential data modeling and the Echo State Network, a powerful approach for black-box system identification. The TRM is tested on a spoken digits task under noisy conditions, and competitive performances compared to previous models are observed."
            },
            "slug": "A-hierarchy-of-recurrent-networks-for-speech-Schrauwen-Buesing",
            "title": {
                "fragments": [],
                "text": "A hierarchy of recurrent networks for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This approach unifies RBM-based approaches for sequential data modeling and the Echo State Network, a powerful approach for black-box system identification."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS 2009"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 167
                            }
                        ],
                        "text": "This property makes them well suited to represent long-term dependencies, but it is nevertheless a challenge to train them efficiently by gradient-based optimization (Bengio et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206457500,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0be39ee052d246ae99c082a565aba25b811be2d",
            "isKey": false,
            "numCitedBy": 6144,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered."
            },
            "slug": "Learning-long-term-dependencies-with-gradient-is-Bengio-Simard",
            "title": {
                "fragments": [],
                "text": "Learning long-term dependencies with gradient descent is difficult"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases, and exposes a trade-off between efficient learning by gradient descent and latching on information for long periods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37549110"
                        ],
                        "name": "Mert Bay",
                        "slug": "Mert-Bay",
                        "structuredName": {
                            "firstName": "Mert",
                            "lastName": "Bay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mert Bay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742797"
                        ],
                        "name": "A. Ehmann",
                        "slug": "A.-Ehmann",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Ehmann",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145656248"
                        ],
                        "name": "J. S. Downie",
                        "slug": "J.-S.-Downie",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Downie",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. S. Downie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 65
                            }
                        ],
                        "text": "The log-likelihood (LL) and expected frame-level accuracy (ACC) (Bay et al., 2009) of the symbolic models are presented in Table 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "Using our hybrid approach, we can improve transcription accuracy (Bay et al., 2009) much more than the popular HMM approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8520936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b73a65bda7467401d46bf41c9c7e438e39fc359f",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-pitch estimation of sources in music is an ongoing research area that has a wealth of applications in music information retrieval systems. This paper presents the systematic evaluations of over a dozen competing methods and algorithms for extracting the fundamental frequencies of pitched sound sources in polyphonic music. The evaluations were carried out as part of the Music Information Retrieval Evaluation eXchange (MIREX) over the course of two years, from 2007 to 2008. The generation of the dataset and its corresponding ground-truth, the methods by which systems can be evaluated, and the evaluation results of the different systems are presented and discussed."
            },
            "slug": "Evaluation-of-Multiple-F0-Estimation-and-Tracking-Bay-Ehmann",
            "title": {
                "fragments": [],
                "text": "Evaluation of Multiple-F0 Estimation and Tracking Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents the systematic evaluations of over a dozen competing methods and algorithms for extracting the fundamental frequencies of pitched sound sources in polyphonic music."
            },
            "venue": {
                "fragments": [],
                "text": "ISMIR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144639556"
                        ],
                        "name": "Graham W. Taylor",
                        "slug": "Graham-W.-Taylor",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Taylor",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham W. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 108
                            }
                        ],
                        "text": "This important distinction makes exact inference of the \u0125 very easy and improves the efficiency of training (Sutskever et al., 2008):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 147
                            }
                        ],
                        "text": "In this section, we compare the performance of the RTRBM with the RNN-RBM on two baseline datasets: bouncing balls videos and motion capture data (Sutskever et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 10
                            }
                        ],
                        "text": "The RTRBM (Sutskever et al., 2008) is a sequence of conditional RBMs (one at each time step) whose parameters b (t) v , b (t) h ,W (t) are time-dependent and depend on the sequence history at time t, denoted A \u2261 {v, \u0125|\u03c4 < t} where \u0125 is the mean-field value of h."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 36
                            }
                        ],
                        "text": "The recurrent temporal RBM (RTRBM) (Sutskever et al., 2008) is a similar model that allows for exact inference and efficient training by contrastive divergence (CD)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 112
                            }
                        ],
                        "text": "This important distinction makes exact inference of the h\u0302(t) very easy and improves the efficiency of training (Sutskever et al., 2008):\nh\u0302(t) = \u03c3(Wv(t) + b (t) h ) = \u03c3(Wv (t) +W \u2032h\u0302(t\u22121) + bh) (10) is obtained directly from equations (2) and (8)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 11
                            }
                        ],
                        "text": "The RTRBM (Sutskever et al., 2008) is a sequence of conditional RBMs (one at each time step) whose\nparameters b (t) v , b (t) h ,W (t) are time-dependent and depend on the sequence history at time t, denoted A(t) \u2261 {v(\u03c4), h\u0302(\u03c4)|\u03c4   t} where h\u0302(t) is the mean-field value of h(t)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8435923,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0228810a988f6b8f06337e14f564e2fd3f6e1056",
            "isKey": true,
            "numCitedBy": 389,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "The Temporal Restricted Boltzmann Machine (TRBM) is a probabilistic model for sequences that is able to successfully model (i.e., generate nice-looking samples of) several very high dimensional sequences, such as motion capture data and the pixels of low resolution videos of balls bouncing in a box. The major disadvantage of the TRBM is that exact inference is extremely hard, since even computing a Gibbs update for a single variable of the posterior is exponentially expensive. This difficulty has necessitated the use of a heuristic inference procedure, that nonetheless was accurate enough for successful learning. In this paper we introduce the Recurrent TRBM, which is a very slight modification of the TRBM for which exact inference is very easy and exact gradient learning is almost tractable. We demonstrate that the RTRBM is better than an analogous TRBM at generating motion capture and videos of bouncing balls."
            },
            "slug": "The-Recurrent-Temporal-Restricted-Boltzmann-Machine-Sutskever-Hinton",
            "title": {
                "fragments": [],
                "text": "The Recurrent Temporal Restricted Boltzmann Machine"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Recurrent TRBM is introduced, which is a very slight modification of the TRBM for which exact inference is very easy and exact gradient learning is almost tractable."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144639556"
                        ],
                        "name": "Graham W. Taylor",
                        "slug": "Graham-W.-Taylor",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Taylor",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham W. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9330607"
                        ],
                        "name": "S. Roweis",
                        "slug": "S.-Roweis",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Roweis",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roweis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 173
                            }
                        ],
                        "text": "The human motion capture dataset(2) is represented by a sequence of joint angles, translations and rotations of the base of the spine in an exponential-map parameterization (Hsu et al., 2005; Taylor et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 209
                            }
                        ],
                        "text": "\u2026we wish to exploit the ability of RBMs to represent a complicated distribution for each time step, with parameters that depend on the previous ones, an idea first put forward with the so-called temporal RBM (Taylor et al., 2007; Sutskever & Hinton, 2007) which is trained via a heuristic procedure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 224
                            }
                        ],
                        "text": "In this context, we wish to exploit the ability of RBMs to represent a complicated distribution for each time step, with parameters that depend on the previous ones, an idea first put forward with the so-called temporal RBM (Taylor et al., 2007; Sutskever & Hinton, 2007) which is trained via a heuristic procedure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 190
                            }
                        ],
                        "text": "The human motion capture dataset2 is represented by a sequence of joint angles, translations and rotations of the base of the spine in an exponential-map parameterization (Hsu et al., 2005; Taylor et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14962437,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "497a80b2813cffb17f46af50e621a71505094528",
            "isKey": true,
            "numCitedBy": 513,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued \"visible\" variables that represent joint angles. The latent and visible variables at each time step receive directed connections from the visible variables at the last few time-steps. Such an architecture makes on-line inference efficient and allows us to use a simple approximate learning procedure. After training, the model finds a single set of parameters that simultaneously capture several different kinds of motion. We demonstrate the power of our approach by synthesizing various motion sequences and by performing on-line filling in of data lost during motion capture."
            },
            "slug": "Modeling-Human-Motion-Using-Binary-Latent-Variables-Taylor-Hinton",
            "title": {
                "fragments": [],
                "text": "Modeling Human Motion Using Binary Latent Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued \"visible\" variables that represent joint angles that makes on-line inference efficient and allows for a simple approximate learning procedure."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785530"
                        ],
                        "name": "Roni Mittelman",
                        "slug": "Roni-Mittelman",
                        "structuredName": {
                            "firstName": "Roni",
                            "lastName": "Mittelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roni Mittelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145585296"
                        ],
                        "name": "B. Kuipers",
                        "slug": "B.-Kuipers",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Kuipers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kuipers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702137"
                        ],
                        "name": "S. Savarese",
                        "slug": "S.-Savarese",
                        "structuredName": {
                            "firstName": "Silvio",
                            "lastName": "Savarese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Savarese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6662536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5209f8559c97800ae06451cd34c14506c20ec23",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The recurrent temporal restricted Boltzmann machine (RTRBM) is a probabilistic time-series model. The topology of the RTRBM graphical model, however, assumes full connectivity between all the pairs of visible units and hidden units, thereby ignoring the dependency structure within the observations. Learning this structure has the potential for not only improving the prediction performance, but also revealing important dependency patterns in the data. For example, given a meteorological dataset, we could identify regional weather patterns. In this work, we propose a new class of RTRBM, which we refer to as the structured RTRBM (SRTRBM), which explicitly uses a graph to model the dependency structure. Our technique is related to methods such as graphical lasso, which are used to learn the topology of Gaussian graphical models. We also develop a spike-and-slab version of the RTRBM, and combine it with the SRTRBM to learn dependency structures in datasets with real-valued observations. Our experimental results using synthetic and real datasets demonstrate that the SRTRBM can significantly improve the prediction performance of the RTRBM, particularly when the number of visible units is large and the size of the training set is small. It also reveals the dependency structures underlying our benchmark datasets."
            },
            "slug": "Structured-Recurrent-Temporal-Restricted-Boltzmann-Mittelman-Kuipers",
            "title": {
                "fragments": [],
                "text": "Structured Recurrent Temporal Restricted Boltzmann Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The SRTRBM can significantly improve the prediction performance of the RTRBM, particularly when the number of visible units is large and the size of the training set is small, and reveals the dependency structures underlying the authors' benchmark datasets."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145704247"
                        ],
                        "name": "James Martens",
                        "slug": "James-Martens",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Martens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 114
                            }
                        ],
                        "text": "It was recently shown that training RNNs via Hessian-free (HF) optimization could help reduce these difficulties (Martens & Sutskever, 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 37
                            }
                        ],
                        "text": "\u2022 In accordance with earlier results (Martens & Sutskever, 2011), the use of HF significantly helps the density estimation and prediction performance of RNNs (eq."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 9153163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d6203718c15f137fda2f295c96269bc2b254644",
            "isKey": false,
            "numCitedBy": 585,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we resolve the long-outstanding problem of how to effectively train recurrent neural networks (RNNs) on complex and difficult sequence modeling problems which may contain long-term data dependencies. Utilizing recent advances in the Hessian-free optimization approach (Martens, 2010), together with a novel damping scheme, we successfully train RNNs on two sets of challenging problems. First, a collection of pathological synthetic datasets which are known to be impossible for standard optimization approaches (due to their extremely long-term dependencies), and second, on three natural and highly complex real-world sequence datasets where we find that our method significantly outperforms the previous state-of-the-art method for training neural sequence models: the Long Short-term Memory approach of Hochreiter and Schmidhuber (1997). Additionally, we offer a new interpretation of the generalized Gauss-Newton matrix of Schraudolph (2002) which is used within the HF approach of Martens."
            },
            "slug": "Learning-Recurrent-Neural-Networks-with-Martens-Sutskever",
            "title": {
                "fragments": [],
                "text": "Learning Recurrent Neural Networks with Hessian-Free Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This work solves the long-outstanding problem of how to effectively train recurrent neural networks on complex and difficult sequence modeling problems which may contain long-term data dependencies and offers a new interpretation of the generalized Gauss-Newton matrix of Schraudolph which is used within the HF approach of Martens."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145797336"
                        ],
                        "name": "Iain Murray",
                        "slug": "Iain-Murray",
                        "structuredName": {
                            "firstName": "Iain",
                            "lastName": "Murray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iain Murray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 57
                            }
                        ],
                        "text": "The neural autoregressive distribution estimator (NADE) (Larochelle & Murray, 2011) is a tractable model inspired by the RBM and specializing (with tying constraints) an earlier model for the joint distribution of high-dimensional variables (Bengio & Bengio,\n2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 104
                            }
                        ],
                        "text": "NADE is similar to a fully visible sigmoid belief network in that the conditional probability distribution of a visible unit vj is expressed as a nonlinear function of vk,\u2200k   j."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "Figure 4 clearly demonstrates the importance of pretraining and finetuning the RNN and the additional advantage of using HF. \u2022 Although frame-level NADEs are slightly less powerful than RBMs, their desirable properties make the combined RNN-NADE model the most robust distribution estimator."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 126
                            }
                        ],
                        "text": "In the following discussion, one can substitute RBMs with NADEs by replacing equation (6) with the exact gradient defined in (Larochelle & Murray, 2011) where the biases are set to b = v (t) b , c = v (t) h ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "The RNN-NADE, obtained by substituting NADEs for RBMs, allows for exact gradient computation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13975441,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32f078a7478d1ec2169599500a4507aceaccdda7",
            "isKey": true,
            "numCitedBy": 469,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new approach for modeling the distribution of high-dimensional vectors of discrete variables. This model is inspired by the restricted Boltzmann machine (RBM), which has been shown to be a powerful model of such distributions. However, an RBM typically does not provide a tractable distribution estimator, since evaluating the probability it assigns to some given observation requires the computation of the so-called partition function, which itself is intractable for RBMs of even moderate size. Our model circumvents this diculty by decomposing the joint distribution of observations into tractable conditional distributions and modeling each conditional using a non-linear function similar to a conditional of an RBM. Our model can also be interpreted as an autoencoder wired such that its output can be used to assign valid probabilities to observations. We show that this new model outperforms other multivariate binary distribution estimators on several datasets and performs similarly to a large (but intractable) RBM."
            },
            "slug": "The-Neural-Autoregressive-Distribution-Estimator-Larochelle-Murray",
            "title": {
                "fragments": [],
                "text": "The Neural Autoregressive Distribution Estimator"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new approach for modeling the distribution of high-dimensional vectors of discrete variables inspired by the restricted Boltzmann machine, which outperforms other multivariate binary distribution estimators on several datasets and performs similarly to a large (but intractable) RBM."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 242
                            }
                        ],
                        "text": "The neural autoregressive distribution estimator (NADE) (Larochelle & Murray, 2011) is a tractable model inspired by the RBM and specializing (with tying constraints) an earlier model for the joint distribution of high-dimensional variables (Bengio & Bengio,\n2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9580239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "190e4800c67ef445e4bd0944a55debaccebcf43f",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The curse of dimensionality is severe when modeling high-dimensional discrete data: the number of possible combinations of the variables explodes exponentially. In this paper we propose a new architecture for modeling high-dimensional data that requires resources (parameters and computations) that grow only at most as the square of the number of variables, using a multi-layer neural network to represent the joint distribution of the variables as the product of conditional distributions. The neural network can be interpreted as a graphical model without hidden random variables, but in which the conditional distributions are tied through the hidden units. The connectivity of the neural network can be pruned by using dependency tests between the variables. Experiments on modeling the distribution of several discrete data sets show statistically significant improvements over other methods such as naive Bayes and comparable Bayesian networks, and show that significant improvements can be obtained by pruning the network."
            },
            "slug": "Modeling-High-Dimensional-Discrete-Data-with-Neural-Bengio-Bengio",
            "title": {
                "fragments": [],
                "text": "Modeling High-Dimensional Discrete Data with Multi-Layer Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A new architecture for modeling high-dimensional data that requires resources that grow only at most as the square of the number of variables is proposed, using a multi-layer neural network to represent the joint distribution of the variables as the product of conditional distributions."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "91102164"
                        ],
                        "name": "Eugene Hsu",
                        "slug": "Eugene-Hsu",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Hsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704409"
                        ],
                        "name": "K. Pulli",
                        "slug": "K.-Pulli",
                        "structuredName": {
                            "firstName": "Kari",
                            "lastName": "Pulli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Pulli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145492783"
                        ],
                        "name": "Jovan Popovi\u0107",
                        "slug": "Jovan-Popovi\u0107",
                        "structuredName": {
                            "firstName": "Jovan",
                            "lastName": "Popovi\u0107",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jovan Popovi\u0107"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 173
                            }
                        ],
                        "text": "The human motion capture dataset(2) is represented by a sequence of joint angles, translations and rotations of the base of the spine in an exponential-map parameterization (Hsu et al., 2005; Taylor et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 172
                            }
                        ],
                        "text": "The human motion capture dataset2 is represented by a sequence of joint angles, translations and rotations of the base of the spine in an exponential-map parameterization (Hsu et al., 2005; Taylor et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 740096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cd6d6cb70ed8a3bb2c13fc6aabf907d620b527f",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Style translation is the process of transforming an input motion into a new style while preserving its original content. This problem is motivated by the needs of interactive applications, which require rapid processing of captured performances. Our solution learns to translate by analyzing differences between performances of the same content in input and output styles. It relies on a novel correspondence algorithm to align motions, and a linear time-invariant model to represent stylistic differences. Once the model is estimated with system identification, our system is capable of translating streaming input with simple linear operations at each frame."
            },
            "slug": "Style-translation-for-human-motion-Hsu-Pulli",
            "title": {
                "fragments": [],
                "text": "Style translation for human motion"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This solution learns to translate by analyzing differences between performances of the same content in input and output styles by relying on a novel correspondence algorithm to align motions, and a linear time-invariant model to represent stylistic differences."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 90
                            }
                        ],
                        "text": "First, CD may not be ideally suited for conditional RBMs with slowly-mixing Gibbs chains (Mnih et al., 2011), a non-issue for exact-gradient models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6153957,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94b0e8e97c19ad0977d26e3e355d3ae09ad49365",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Conditional Restricted Boltzmann Machines (CRBMs) are rich probabilistic models that have recently been applied to a wide range of problems, including collaborative filtering, classification, and modeling motion capture data. While much progress has been made in training non-conditional RBMs, these algorithms are not applicable to conditional models and there has been almost no work on training and generating predictions from conditional RBMs for structured output problems. We first argue that standard Contrastive Divergence-based learning may not be suitable for training CRBMs. We then identify two distinct types of structured output prediction problems and propose an improved learning algorithm for each. The first problem type is one where the output space has arbitrary structure but the set of likely output configurations is relatively small, such as in multi-label classification. The second problem is one where the output space is arbitrarily structured but where the output space variability is much greater, such as in image denoising or pixel labeling. We show that the new learning algorithms can work much better than Contrastive Divergence on both types of problems."
            },
            "slug": "Conditional-Restricted-Boltzmann-Machines-for-Mnih-Larochelle",
            "title": {
                "fragments": [],
                "text": "Conditional Restricted Boltzmann Machines for Structured Output Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work argues that standard Contrastive Divergence-based learning may not be suitable for training CRBMs, and proposes an improved learning algorithm for two distinct types of structured output prediction problems and shows that the new learning algorithms can work much better than Contrastives Divergence on both types of problems."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398315116"
                        ],
                        "name": "M. Rosen-Zvi",
                        "slug": "M.-Rosen-Zvi",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Rosen-Zvi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosen-Zvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 90
                            }
                        ],
                        "text": "Since the data consists of 49 real values per time step, we use the Gaussian RBM variant (Welling et al., 2005) for this task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2388827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2184fb6d32bc46f252b940035029273563c4fc82",
            "isKey": false,
            "numCitedBy": 502,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Directed graphical models with one layer of observed random variables and one or more layers of hidden random variables have been the dominant modelling paradigm in many research fields. Although this approach has met with considerable success, the causal semantics of these models can make it difficult to infer the posterior distribution over the hidden variables. In this paper we propose an alternative two-layer model based on exponential family distributions and the semantics of undirected models. Inference in these \"exponential family harmoniums\" is fast while learning is performed by minimizing contrastive divergence. A member of this family is then studied as an alternative probabilistic model for latent semantic indexing. In experiments it is shown that they perform well on document retrieval tasks and provide an elegant solution to searching with keywords."
            },
            "slug": "Exponential-Family-Harmoniums-with-an-Application-Welling-Rosen-Zvi",
            "title": {
                "fragments": [],
                "text": "Exponential Family Harmoniums with an Application to Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An alternative two-layer model based on exponential family distributions and the semantics of undirected models is proposed, which performs well on document retrieval tasks and provides an elegant solution to searching with keywords."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 175
                            }
                        ],
                        "text": "Initialization strategies based on unsupervised pretraining of each layer have been shown to be important both for supervised and unsupervised training of deep architectures (Bengio, 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207178999,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e60ff004dde5c13ec53087872cfcdd12e85beb57",
            "isKey": false,
            "numCitedBy": 7558,
            "numCiting": 345,
            "paperAbstract": {
                "fragments": [],
                "text": "Theoretical results strongly suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one needs deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult optimization task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This paper discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks."
            },
            "slug": "Learning-Deep-Architectures-for-AI-Bengio",
            "title": {
                "fragments": [],
                "text": "Learning Deep Architectures for AI"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer modelssuch as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Mach. Learn."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3841331"
                        ],
                        "name": "Moray Allan",
                        "slug": "Moray-Allan",
                        "structuredName": {
                            "firstName": "Moray",
                            "lastName": "Allan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Moray Allan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 109
                            }
                        ],
                        "text": "JSB chorales refers to the entire corpus of 382 fourpart harmonized chorales by J. S. Bach with the split of Allan & Williams (2005)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 50
                            }
                        ],
                        "text": "\u2022 An interesting model for chorales harmonisation (Allan & Williams, 2005) has been adapted to serve as a generative model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 28
                            }
                        ],
                        "text": "\u2022 The harmonisation model of Allan & Williams (2005), tailored to the specific style of four-part chorales, requires annotated harmonic symbols and yet performs relatively poorly compared to our best performer."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 111776,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f3bd4e6b16817e332b9be8357e3eddb8a461990",
            "isKey": true,
            "numCitedBy": 177,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe how we used a data set of chorale harmonisations composed by Johann Sebastian Bach to train Hidden Markov Models. Using a probabilistic framework allows us to create a harmonisation system which learns from examples, and which can compose new harmonisations. We make a quantitative comparison of our system's harmonisation performance against simpler models, and provide example harmonisations."
            },
            "slug": "Harmonising-Chorales-by-Probabilistic-Inference-Allan-Williams",
            "title": {
                "fragments": [],
                "text": "Harmonising Chorales by Probabilistic Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Using a probabilistic framework allows us to create a harmonisation system which learns from examples, and which can compose new harmonisations, and a quantitative comparison of the system's harmonisation performance against simpler models is made."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 72
                            }
                        ],
                        "text": "(6)\nresulting in the well-known contrastive divergence (CDk) algorithm (Hinton, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 67
                            }
                        ],
                        "text": "resulting in the well-known contrastive divergence (CDk) algorithm (Hinton, 2002)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 207596505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9360e5ce9c98166bb179ad479a9d2919ff13d022",
            "isKey": false,
            "numCitedBy": 4571,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual expert models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called contrastive divergence whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data."
            },
            "slug": "Training-Products-of-Experts-by-Minimizing-Hinton",
            "title": {
                "fragments": [],
                "text": "Training Products of Experts by Minimizing Contrastive Divergence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A product of experts (PoE) is an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary because it is hard even to approximate the derivatives of the renormalization term in the combination rule."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145797336"
                        ],
                        "name": "Iain Murray",
                        "slug": "Iain-Murray",
                        "structuredName": {
                            "firstName": "Iain",
                            "lastName": "Murray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iain Murray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 104
                            }
                        ],
                        "text": "We estimate the partition function of each conditional RBM by 100 runs of annealed importance sampling (Salakhutdinov & Murray, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 458722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08d0ea90b53aba0008d25811268fe46562cfb38c",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Belief Networks (DBN's) are generative models that contain many layers of hidden variables. Efficient greedy algorithms for learning and approximate inference have allowed these models to be applied successfully in many application domains. The main building block of a DBN is a bipartite undirected graphical model called a restricted Boltzmann machine (RBM). Due to the presence of the partition function, model selection, complexity control, and exact maximum likelihood learning in RBM's are intractable. We show that Annealed Importance Sampling (AIS) can be used to efficiently estimate the partition function of an RBM, and we present a novel AIS scheme for comparing RBM's with different architectures. We further show how an AIS estimator, along with approximate inference, can be used to estimate a lower bound on the log-probability that a DBN model with multiple hidden layers assigns to the test data. This is, to our knowledge, the first step towards obtaining quantitative results that would allow us to directly assess the performance of Deep Belief Networks as generative models of data."
            },
            "slug": "On-the-quantitative-analysis-of-deep-belief-Salakhutdinov-Murray",
            "title": {
                "fragments": [],
                "text": "On the quantitative analysis of deep belief networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that Annealed Importance Sampling (AIS) can be used to efficiently estimate the partition function of an RBM, and a novel AIS scheme for comparing RBM's with different architectures is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 96
                            }
                        ],
                        "text": "Propagate the estimated gradient with respect to b (t) v , b (t) h backward through time (BPTT) (Rumelhart et al., 1986) to obtain the estimated gradient with respect to the RNN parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 97
                            }
                        ],
                        "text": "Propagate the estimated gradient with respect to\nb (t) v , b (t) h backward through time (BPTT) (Rumelhart et al., 1986) to obtain the estimated gradient with respect to the RNN parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 33
                            }
                        ],
                        "text": "Recurrent neural networks (RNN) (Rumelhart et al., 1986) incorporate an internal memory that can, in principle, summarize the entire sequence history."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": true,
            "numCitedBy": 19355,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748557"
                        ],
                        "name": "P. Smolensky",
                        "slug": "P.-Smolensky",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Smolensky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Smolensky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 210
                            }
                        ],
                        "text": "This difficulty motivates energy-based models which allow us to express the negative log-likelihood of a given configuration by an arbitrary energy function, among which the restricted Boltzmann machine (RBM) (Smolensky, 1986) has become notorious."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 533055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f7476037408ac3d993f5088544aab427bc319c1",
            "isKey": false,
            "numCitedBy": 1949,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : At this early stage in the development of cognitive science, methodological issues are both open and central. There may have been times when developments in neuroscience, artificial intelligence, or cognitive psychology seduced researchers into believing that their discipline was on the verge of discovering the secret of intelligence. But a humbling history of hopes disappointed has produced the realization that understanding the mind will challenge the power of all these methodologies combined. The work reported in this chapter rests on the conviction that a methodology that has a crucial role to play in the development of cognitive science is mathematical analysis. The success of cognitive science, like that of many other sciences, will, I believe, depend upon the construction of a solid body of theoretical results: results that express in a mathematical language the conceptual insights of the field; results that squeeze all possible implications out of those insights by exploiting powerful mathematical techniques. This body of results, which I will call the theory of information processing, exists because information is a concept that lends itself to mathematical formalization. One part of the theory of information processing is already well-developed. The classical theory of computation provides powerful and elegant results about the notion of effective procedure, including languages for precisely expressing them and theoretical machines for realizing them."
            },
            "slug": "Information-processing-in-dynamical-systems:-of-Smolensky",
            "title": {
                "fragments": [],
                "text": "Information processing in dynamical systems: foundations of harmony theory"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The work reported in this chapter rests on the conviction that a methodology that has a crucial role to play in the development of cognitive science is mathematical analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 175
                            }
                        ],
                        "text": "Initialization strategies based on unsupervised pretraining of each layer have been shown to be important both for supervised and unsupervised training of deep architectures (Bengio, 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 94
                            }
                        ],
                        "text": "The gradient of C with respect to the parameters of the conditional RBMs can be estimated by CD using equations (4) and (6):\n\u2202C\n\u2202b (t) v\n' v(t)\u2217 \u2212 v(t) (13)\n\u2202C \u2202W ' T\u2211 t=1 \u03c3(Wv(t)\u2217\u2212b(t)h )v (t)\u2217T\u2212\u03c3(Wv(t)\u2212b(t)h )v (t)T\n(14) \u2202C\n\u2202b (t) h\n' \u03c3(Wv(t)\u2217 \u2212 b(t)h )\u2212 \u03c3(Wv (t) \u2212 b(t)h )."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning deep architectures for AI. Foundations and Trends in Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Learning deep architectures for AI. Foundations and Trends in Machine Learning"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modeling temporal dependencies in highdimensional sequences: Application to polyphonic music generation and transcription"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the Twenty-nine International Conference on Machine Learning"
            },
            "year": 2012
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 16,
            "methodology": 17,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Modeling-Temporal-Dependencies-in-High-Dimensional-Boulanger-Lewandowski-Bengio/18c82d4b6cf94fb84ba6ea230e80cb07ed9a9cf8?sort=total-citations"
}