{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 140
                            }
                        ],
                        "text": ", a single global bandwidth value is used, the adaptive mean shift (AMS) procedure becomes the fixed bandwidth mean shift (MS) discussed in [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 691081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74f4ecc3e4e5b91fbb54330b285ed5214afe2001",
            "isKey": false,
            "numCitedBy": 11481,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance."
            },
            "slug": "Mean-Shift:-A-Robust-Approach-Toward-Feature-Space-Comaniciu-Meer",
            "title": {
                "fragments": [],
                "text": "Mean Shift: A Robust Approach Toward Feature Space Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proved the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "\u2013 S: A set of 13 circular symmetric filters was used by Schmid [15] to obtain a rotationally invariant feature set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "Efficient methods exist for texture classification under varying illumination and viewing direction [3],[12], [15], [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 54
                            }
                        ],
                        "text": "S: A set of 13 circular symmetric filters was used by Schmid [15] to obtain a rotationally invariant feature set."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5927402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db7159af39b66cde32cec502a17d48436b541d00",
            "isKey": false,
            "numCitedBy": 423,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new method for constructing models from a set of positive and negative sample images; the method requires no manual extraction of significant objects or features. Our model representation is based on two layers. The first one consists of \"generic\" descriptors which represent sets of similar rotational invariant feature vectors. Rotation invariance allows to group similar, but rotated patterns and makes the method robust to model deformations. The second layer is the joint probability on the frequencies of the \"generic\" descriptors over neighborhoods. This probability is multi-modal and is represented by a set of \"spatial-frequency\" clusters. It adds a statistical spatial constraint which is rotationally invariant. Our two-layer representation is novel; it allows to efficiently capture \"texture-like\" visual structure. The selection of distinctive structure determines characteristic model features (common to the positive and rare in the negative examples) and increases the performance of the model. Models are retrieved and localized using a probabilistic score. Experimental results for \"textured\" animals and faces show a very good performance for retrieval as well as localization."
            },
            "slug": "Constructing-models-for-content-based-image-Schmid",
            "title": {
                "fragments": [],
                "text": "Constructing models for content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A new method for constructing models from a set of positive and negative sample images; the method requires no manual extraction of significant objects or features and allows to efficiently capture \"texture-like\" visual structure."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320582"
                        ],
                        "name": "Visvanathan Ramesh",
                        "slug": "Visvanathan-Ramesh",
                        "structuredName": {
                            "firstName": "Visvanathan",
                            "lastName": "Ramesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Visvanathan Ramesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14661676,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a67e0c5b11caceafc0002b0aaff8d7db21eb3312",
            "isKey": false,
            "numCitedBy": 486,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two solutions for the scale selection problem in computer vision. The first one is completely nonparametric and is based on the the adaptive estimation of the normalized density gradient. Employing the sample point estimator, we define the Variable Bandwidth Mean Shift, prove its convergence, and show its superiority over the fixed bandwidth procedure. The second technique has a semiparametric nature and imposes a local structure on the data to extract reliable scale information. The local scale of the underlying density is taken as the bandwidth which maximizes the magnitude of the normalized mean shift vector. Both estimators provide practical tools for autonomous image and quasi real-time video analysis and several examples are shown to illustrate their effectiveness."
            },
            "slug": "The-variable-bandwidth-mean-shift-and-data-driven-Comaniciu-Ramesh",
            "title": {
                "fragments": [],
                "text": "The variable bandwidth mean shift and data-driven scale selection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The sample point estimator is defined, prove its convergence, and show its superiority over the fixed bandwidth procedure, and an alternative approach for data-driven scale selection which imposes a local structure on the data is studied."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "Since textons capture local spatial configurations, we believe that combining the mode textons with the representation proposed in [19] can offer more insight into why the texton approach is superior to previous techniques."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "However, as was shown recently [19], neighborhood information in the spatial domain may also suffice."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 456211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70284b4fe852f472d4576c30f97a6fddbfef2aee",
            "isKey": false,
            "numCitedBy": 532,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We question the role that large scale filter banks have traditionally played in texture classification. It is demonstrated that textures can be classified using the joint distribution of intensity values over extremely compact neighborhoods (starting from as small as 3 /spl times/ 3 pixels square), and that this outperforms classification using filter banks with large support. We develop a novel texton based representation, which is suited to modeling this joint neighborhood distribution for MRFs. The representation is learnt from training images, and then used to classify novel images (with unknown viewpoint and lighting) into texture classes. The power of the method is demonstrated by classifying over 2800 images of all 61 textures present in the Columbia-Utrecht database. The classification performance surpasses that of recent state-of-the-art filter bank based classifiers such as Leung & Malik, Cula & Dana, and Varma & Zisserman."
            },
            "slug": "Texture-classification:-are-filter-banks-necessary-Varma-Zisserman",
            "title": {
                "fragments": [],
                "text": "Texture classification: are filter banks necessary?"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel texton based representation is developed, which is suited to modeling this joint neighborhood distribution for MRFs, and it is demonstrated that textures can be classified using the joint distribution of intensity values over extremely compact neighborhoods."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3214795,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7417d7dcf6152736612e3f04ccc72731dc8d9505",
            "isKey": false,
            "numCitedBy": 418,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new approach to material classification under unknown viewpoint and illumination. Our texture model is based on the statistical distribution of clustered filter responses. However, unlike previous 3D texton representations, we use rotationally invariant filters and cluster in an extremely low dimensional space. Having built a texton dictionary, we present a novel method of classifying a single image without requiring any a priori knowledge about the viewing or illumination conditions under which it was photographed. We argue that using rotationally invariant filters while clustering in such a low dimensional space improves classification performance and demonstrate this claim with results on all 61 textures in the Columbia-Utrecht database. We then proceed to show how texture models can be further extended by compensating for viewpoint changes using weak isotropy.The new clustering and classification methods are compared to those of Leung and Malik (ICCV 1999), Schmid (CVPR 2001) and Cula and Dana (CVPR 2001), which are the current state-of-the-art approaches."
            },
            "slug": "Classifying-Images-of-Materials:-Achieving-and-Varma-Zisserman",
            "title": {
                "fragments": [],
                "text": "Classifying Images of Materials: Achieving Viewpoint and Illumination Independence"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper presents a novel method of classifying a single image without requiring any a priori knowledge about the viewing or illumination conditions under which it was photographed, and argues that using rotationally invariant filters while clustering in such a low dimensional space improves classification performance."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31983980"
                        ],
                        "name": "G. M. Haley",
                        "slug": "G.-M.-Haley",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Haley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. M. Haley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [8], with the same setup but employing a different texture representation, and using only 109 textures from the Brodatz database the recognition rate was !i ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9784645,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0a41a866ddd70555b629bede2317edb840d481c",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of rotation-invariant texture classification based on a complete space-frequency model is introduced. A polar, analytic form of a two-dimensional (2-D) Gabor wavelet is developed, and a multiresolution family of these wavelets is used to compute information-conserving microfeatures. From these microfeatures a micromodel, which characterizes spatially localized amplitude, frequency, and directional behavior of the texture, is formed. The essential characteristics of a texture sample, its macrofeatures, are derived from the estimated selected parameters of the micromodel. Classification of texture samples is based on the macromodel derived from a rotation invariant subset of macrofeatures. In experiments, comparatively high correct classification rates were obtained using large sample sets."
            },
            "slug": "Rotation-invariant-texture-classification-using-a-Haley-Manjunath",
            "title": {
                "fragments": [],
                "text": "Rotation-invariant texture classification using a complete space-frequency model"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A method of rotation-invariant texture classification based on a complete space-frequency model is introduced, and the essential characteristics of a texture sample, its macrofeatures, are derived from the estimated selected parameters of the micromodel."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2672681"
                        ],
                        "name": "G. O. Cula",
                        "slug": "G.-O.-Cula",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Cula",
                            "middleNames": [
                                "Oana"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. O. Cula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "\u2013 LM: A combination of 48 anisotropic and isotropic filters were used by Leung and Malik [12] and Cula and Dana [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "Efficient methods exist for texture classification under varying illumination and viewing direction [3],[12], [15], [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 97
                            }
                        ],
                        "text": "\u2013 LM: A combination of 48 anisotropic and isotropic fil-\nters were used by Leung and Malik [12] and Cula and Dana [3]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7356365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b45dc2f11ed201f192d9bec153fcca1ca95e460",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A bidirectional texture function (BTF) describes image texture as it varies with viewing and illumination direction. Many real world surfaces such as skin, fur, gravel, etc. exhibit fine-scale geometric surface detail. Accordingly, variations in appearance with viewing and illumination direction may be quite complex due to local foreshortening, masking and shadowing. Representations of surface texture that support robust recognition must account for these effects. We construct a representation which captures the underlying statistical distribution of features in the image texture as well as the variations in this distribution with viewing and illumination direction. The representation combines clustering to learn characteristic image features and principle components analysis to reduce the space of feature histograms. This representation is based on a core image set as determined by a quantitative evaluation of importance of individual images in the overall representation. The result is a compact representation and a recognition method where a single novel image of unknown viewing and illumination direction can be classified efficiently. The CUReT (Columbia-Utrecht reflectance and texture) database is used as a test set for evaluation of these methods."
            },
            "slug": "Compact-representation-of-bidirectional-texture-Cula-Dana",
            "title": {
                "fragments": [],
                "text": "Compact representation of bidirectional texture functions"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A representation is constructed which captures the underlying statistical distribution of features in the image texture as well as the variations in this distribution with viewing and illumination direction and is a compact representation and a recognition method where a single novel image of unknown viewing and illuminated direction can be classified efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490189"
                        ],
                        "name": "Gregory Shakhnarovich",
                        "slug": "Gregory-Shakhnarovich",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Shakhnarovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Shakhnarovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "In a task of estimating the pose of articulated objects, described in these proceedings [16], the LSH technique was extended to accommodate distances in the parameter space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2051403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e1556aea42601df3f457ad43dfb059498931a33",
            "isKey": false,
            "numCitedBy": 906,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Example-based methods are effective for parameter estimation problems when the underlying system is simple or the dimensionality of the input is low. For complex and high-dimensional problems such as pose estimation, the number of required examples and the computational complexity rapidly become prohibitively high. We introduce a new algorithm that learns a set of hashing functions that efficiently index examples relevant to a particular estimation task. Our algorithm extends locality-sensitive hashing, a recently developed method to find approximate neighbors in time sublinear in the number of examples. This method depends critically on the choice of hash functions that are optimally relevant to a particular estimation problem. Experiments demonstrate that the resulting algorithm, which we call parameter-sensitive hashing, can rapidly and accurately estimate the articulated pose of human figures from a large database of example images."
            },
            "slug": "Fast-pose-estimation-with-parameter-sensitive-Shakhnarovich-Viola",
            "title": {
                "fragments": [],
                "text": "Fast pose estimation with parameter-sensitive hashing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new algorithm is introduced that learns a set of hashing functions that efficiently index examples relevant to a particular estimation task, and can rapidly and accurately estimate the articulated pose of human figures from a large database of example images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 72
                            }
                        ],
                        "text": "\u2013 LM: A combination of 48 anisotropic and isotropic fil-\nters were used by Leung and Malik [12] and Cula and Dana [3]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "As in [12] the 5 distance between these two texton distributions 5 _ ) *,+ 1 _ 5 _ (10)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "\u2013 LM: A combination of 48 anisotropic and isotropic filters were used by Leung and Malik [12] and Cula and Dana [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Following [12] this feature space is built from the output of a filter bank applied at every pixel."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "Efficient methods exist for texture classification under varying illumination and viewing direction [3],[12], [15], [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14915716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90d6e7f2202f754d8588f9536e3f5b4a24701f24",
            "isKey": true,
            "numCitedBy": 1713,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the recognition of surfaces made from different materials such as concrete, rug, marble, or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof. Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions.Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions. We also illustrate how the 3D texton model can be used to predict the appearance of materials under novel conditions."
            },
            "slug": "Representing-and-Recognizing-the-Visual-Appearance-Leung-Malik",
            "title": {
                "fragments": [],
                "text": "Representing and Recognizing the Visual Appearance of Materials using Three-dimensional Textons"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A unified model to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions is provided."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31423777"
                        ],
                        "name": "D. DeMenthon",
                        "slug": "D.-DeMenthon",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "DeMenthon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. DeMenthon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 119
                            }
                        ],
                        "text": "Already for , in a video sequence segmentation application, a fineto-coarse hierarchical approach had to be introduced [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14031741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00c384ca3047fd4b1202ec509d9dbcbb819d1992",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a simple new technique for spatio temporal segmentation of video sequences Each pixel of a D space time video stack is mapped to a D feature point whose coordinates include three color components two motion angle components and two motion position components The clustering of these feature points provides color segmentation and motion segmentation as well as a consistent labeling of regions over time which amounts to region tracking For this task we have adopted a hierarchical clustering method which operates by repeatedly applying mean shift analysis over increasingly large ranges using at each pass the cluster centers of the previous pass with weights equal to the counts of the points that contributed to the clusters This technique has lower complexity for large mean shift radii than ordinary mean shift analysis because it can use binary tree structures more e ciently during range search In addition it provides a hierarchical segmentation of the data Applications include video compression and compact descriptions of video sequences for video indexing and retrieval applications The support of NSF grants EAR and IIS is gratefully acknowledged Introduction and Related Work One of the goals of video analysis is to nd out as much as possible about what is going on in the scene from what was captured by the video Finding out what is going on is more formally called semantic interpretation To interpret a scene one rst needs to label independent objects Boundaries of objects typically correspond to boundaries of color patches in the video but situations where a foreground object is in front of a background of similar color can also occur When the camera translates or when objects move independently boundaries of objects correspond to boundaries across which the optical ow changes in the video and the patches inside these image boundaries display some consistency of optical ow but optical ow is notoriously unreliable at object boundaries To overcome these limitations of motion segmentation and color segmentation and to maximize the chances of correctly extracting objects researchers have been combining motion and color cues in various ways The task of dividing video frames into patches that may correspond to objects in the scene is called object based segmentation layer extraction sprite representation or space time segmentation there are arguably subtle di erences between these concepts Color patches produce generalized cylinders in the D spatio temporal pixel volume obtained by piling up frames into a D video stack These space time entities have been called color ows action cylinders and feature trajectories in the literature We refer to them as video strands Our goal in this paper is to extract these strands and characterize them by color average radius and axis position and orientation There are three main strategies for space time segmentation of video sequences Find spatial regions by segmenting each frame then track these regions from frame to frame Track interest points to nd their trajectories then bundle these trajectories Perform D segmentation of the video stack The rst strategy attempts to discover spatial structures and extend them in the temporal dimension the second strategy discovers temporal structures and groups them in the spatial di mension and the third strategy treats the spatial and temporal dimensions equally The strategies are illustrated in Fig In this gure the horizontal dimension represents the sizes of the struc tures in the spatial dimension and the vertical dimension represents their sizes in the temporal dimension The segmentation starts with features that are small both spatially and temporally near the lower left of the gure The goal of spatio temporal segmentation is to group these features into homogeneous structures in the D video stack that are large along both the spatial and temporal dimensions and are therefore at the upper right of the gure The three strate gies correspond to three paths for growing such structures horizontally then vertically vertically then horizontally diagonally Our approach belongs to the third category In the rst category of spatio temporal methods frame by frame tracking there are more vari ants than we can adequately review here Typically the frames are segmented one after the other using motion information Regions of the previous frame are generally shifted and projected into the current frame by motion compensation and these projections are compared to the regions of the current frame in various ways to enforce temporal coherence between spatial regions Another subcategory segments all the frames spatially in a rst step then 2D+t spatiotemporal segmentation of image sequence te m po ra l p ro pa ga tio n or r eg io n m at ch in g motion grouping spatial structure region segmentation approach in st an ta ne ou s lo ng \u2212t er m te m p o ra l s tr u ct u re"
            },
            "slug": "SPATIO-TEMPORAL-SEGMENTATION-OF-VIDEO-BY-MEAN-SHIFT-DeMenthon",
            "title": {
                "fragments": [],
                "text": "SPATIO-TEMPORAL SEGMENTATION OF VIDEO BY HIERARCHICAL MEAN SHIFT ANALYSIS"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A simple new technique for spatio temporal segmentation of video sequences that operates by repeatedly applying mean shift analysis over increasingly large ranges using at each pass the cluster centers of the previous pass with weights equal to the counts of the points that contributed to the clusters."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1851364"
                        ],
                        "name": "S. Nene",
                        "slug": "S.-Nene",
                        "structuredName": {
                            "firstName": "Sameer",
                            "lastName": "Nene",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nene"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "The problem has been addressed before in the vision community by sorting the data according to each of the coordinates [13], but a significant speedup was achieved only when the data is close to a low-dimensional manifold."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9093485,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef55e27cc1853ecf2790bb315335894cef4c59dd",
            "isKey": false,
            "numCitedBy": 372,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of finding the closest point in high-dimensional spaces is common in pattern recognition. Unfortunately, the complexity of most existing search algorithms, such as k-d tree and R-tree, grows exponentially with dimension, making them impractical for dimensionality above 15. In nearly all applications, the closest point is of interest only if it lies within a user-specified distance /spl epsiv/. We present a simple and practical algorithm to efficiently search for the nearest neighbor within Euclidean distance /spl epsiv/. The use of projection search combined with a novel data structure dramatically improves performance in high dimensions. A complexity analysis is presented which helps to automatically determine /spl epsiv/ in structured problems. A comprehensive set of benchmarks clearly shows the superiority of the proposed algorithm for a variety of structured and unstructured search problems. Object recognition is demonstrated as an example application. The simplicity of the algorithm makes it possible to construct an inexpensive hardware search engine which can be 100 times faster than its software equivalent. A C++ implementation of our algorithm is available."
            },
            "slug": "A-simple-algorithm-for-nearest-neighbor-search-in-Nene-Nayar",
            "title": {
                "fragments": [],
                "text": "A simple algorithm for nearest neighbor search in high dimensions"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A simple and practical algorithm to efficiently search for the nearest neighbor within Euclidean distance /spl epsiv/ is presented and made possible to construct an inexpensive hardware search engine which can be 100 times faster than its software equivalent."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682878"
                        ],
                        "name": "A. Gionis",
                        "slug": "A.-Gionis",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Gionis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gionis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688317"
                        ],
                        "name": "P. Indyk",
                        "slug": "P.-Indyk",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Indyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Indyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84095744"
                        ],
                        "name": "R. Motwani",
                        "slug": "R.-Motwani",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Motwani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Motwani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Its minimum is 7 ( which together with j 7 ( are the optimal parameters of the LSH data structure."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "Acknowledgments We thank Bogdan Matei of the Sarnoff Corporation, Princeton, NJ, for calling our attention to the LSH data structure."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 95
                            }
                        ],
                        "text": "The algorithms yield sublinear complexity with a speedup which depends on the desired accuracy [7, 10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "The approximation error of the LSH was d!i !"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "In a task of estimating the pose of articulated objects, described in these proceedings [16], the LSH technique was extended to accommodate distances in the parameter space."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [7] the coordinates J: have equal chance to be selected and the values : are uniformly distributed over the range of the corresponding coordinate."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "The use of the LSH data structure in the mean shift procedure assures a significant speedup."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "The parameters 7 and j of the LSH data structure are selected employing the technique discussed in Section 3.2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "In this paper we have adapted the algorithm in [7] for mean shift based clustering in high dimensions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 101
                            }
                        ],
                        "text": "The optimal 7 j is then chosen such that\n7 j % ; 7 j (9) subject to:\n)_ *,+ % ; _ _ A W where is the LSH approximation threshold set by the user."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "The described technique is called locality-sensitive hashing (LSH) and was introduced in [10]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "We use the approximate nearest neighbor algorithm based on locality-sensitive hashing (LSH) [7] and adapted it to handle the complex data met in computer vision applications."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "Given ^h_ , the current location in the iterations, an LSH based query retrieves the approximate set of neighbors needed to compute the next location (5)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "In the approximate nearest neighbor algorithm based on LSH, for any pair of 7 and j , we define for each of the points % ; _ , the distance to the k-nearest neighbor returned by the query."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Next, the LSH data structure is built with 7 j ."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1578969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e74388f55f2cc704c4de410578887a53a9433b0",
            "isKey": true,
            "numCitedBy": 3455,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "The nearestor near-neighbor query problems arise in a large variety of database applications, usually in the context of similarity searching. Of late, there has been increasing interest in building search/index structures for performing similarity search over high-dimensional data, e.g., image databases, document collections, time-series databases, and genome databases. Unfortunately, all known techniques for solving this problem fall prey to the \\curse of dimensionality.\" That is, the data structures scale poorly with data dimensionality; in fact, if the number of dimensions exceeds 10 to 20, searching in k-d trees and related structures involves the inspection of a large fraction of the database, thereby doing no better than brute-force linear search. It has been suggested that since the selection of features and the choice of a distance metric in typical applications is rather heuristic, determining an approximate nearest neighbor should su ce for most practical purposes. In this paper, we examine a novel scheme for approximate similarity search based on hashing. The basic idea is to hash the points Supported by NAVY N00014-96-1-1221 grant and NSF Grant IIS-9811904. Supported by Stanford Graduate Fellowship and NSF NYI Award CCR-9357849. Supported by ARO MURI Grant DAAH04-96-1-0007, NSF Grant IIS-9811904, and NSF Young Investigator Award CCR9357849, with matching funds from IBM, Mitsubishi, Schlumberger Foundation, Shell Foundation, and Xerox Corporation. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the VLDB copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Very Large Data Base Endowment. To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. Proceedings of the 25th VLDB Conference, Edinburgh, Scotland, 1999. from the database so as to ensure that the probability of collision is much higher for objects that are close to each other than for those that are far apart. We provide experimental evidence that our method gives signi cant improvement in running time over other methods for searching in highdimensional spaces based on hierarchical tree decomposition. Experimental results also indicate that our scheme scales well even for a relatively large number of dimensions (more than 50)."
            },
            "slug": "Similarity-Search-in-High-Dimensions-via-Hashing-Gionis-Indyk",
            "title": {
                "fragments": [],
                "text": "Similarity Search in High Dimensions via Hashing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experimental results indicate that the novel scheme for approximate similarity search based on hashing scales well even for a relatively large number of dimensions, and provides experimental evidence that the method gives improvement in running time over other methods for searching in highdimensional spaces based on hierarchical tree decomposition."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35674406"
                        ],
                        "name": "Shigeo Abe DrEng",
                        "slug": "Shigeo-Abe-DrEng",
                        "structuredName": {
                            "firstName": "Shigeo",
                            "lastName": "DrEng",
                            "middleNames": [
                                "Abe"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shigeo Abe DrEng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9384346,
            "fieldsOfStudy": [
                "Mathematics",
                "Environmental Science"
            ],
            "id": "65a69968bb8c41aad0113cec4c2d981bddf50bc8",
            "isKey": false,
            "numCitedBy": 13095,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification \u2022 Supervised \u2013 parallelpiped \u2013 minimum distance \u2013 maximum likelihood (Bayes Rule) > non-parametric > parametric \u2013 support vector machines \u2013 neural networks \u2013 context classification \u2022 Unsupervised (clustering) \u2013 K-Means \u2013 ISODATA \u2022 Pattern recognition in remote sensing has been based on the intuitive notion that pixels belonging to the same class should have similar gray values in a given band. \u2013 Given two spectral bands, pixels from the same class plotted in a two-dimensional histogram should appear as a localized cluster. \u2013 If n images, each in a different spectral band, are available, pixels from the same class should form a localized cluster in n-space."
            },
            "slug": "Pattern-Classification-DrEng",
            "title": {
                "fragments": [],
                "text": "Pattern Classification"
            },
            "venue": {
                "fragments": [],
                "text": "Springer London"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748224"
                        ],
                        "name": "R. Ostrovsky",
                        "slug": "R.-Ostrovsky",
                        "structuredName": {
                            "firstName": "Rafail",
                            "lastName": "Ostrovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ostrovsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763352"
                        ],
                        "name": "Y. Rabani",
                        "slug": "Y.-Rabani",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Rabani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rabani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 215
                            }
                        ],
                        "text": "Recently new algorithms using tools from probabilistic approximation theory were suggested for performing approximate nearest neighbor search in high dimensions for general datasets [10, 11] and for clustering data [9, 14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 176294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc624889def4c86a5d139b212c3123c3c7ab7ee9",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We deal with the problem of clustering data points. Given n points in a larger set (for example, R/sup d/) endowed with a distance function (for example, L/sup 2/ distance), we would like to partition the data set into k disjoint clusters, each with a \"cluster center\", so as to minimize the sum over all data points of the distance between the point and the center of the cluster containing the point. The problem is provably NP-hard in some high dimensional geometric settings, even for k=2. We give polynomial time approximation schemes for this problem in several settings, including the binary cube (0, 1)/sup d/ with Hamming distance, and R/sup d/ either with L/sup 1/ distance, or with L/sup 2/ distance, or with the square of L/sup 2/ distance. In all these settings, the best previous results were constant factor approximation guarantees. We note that our problem is similar in flavor to the k-median problem (and the related facility location problem), which has been considered in graph-theoretic and fixed dimensional geometric settings, where it becomes hard when k is part of the input. In contrast, we study the problem when k is fixed, but the dimension is part of the input. Our algorithms are based on a dimension reduction construction for the Hamming cube, which may be of independent interest."
            },
            "slug": "Polynomial-time-approximation-schemes-for-geometric-Ostrovsky-Rabani",
            "title": {
                "fragments": [],
                "text": "Polynomial time approximation schemes for geometric k-clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This work deals with the problem of clustering data points, and gives polynomial time approximation schemes for this problem in several settings, including the binary cube (0, 1)/sup d/ with Hamming distance, and R/Sup d/ either with L/sup 1/ distance, or with L /sup 2/ distance."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 41st Annual Symposium on Foundations of Computer Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688317"
                        ],
                        "name": "P. Indyk",
                        "slug": "P.-Indyk",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Indyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Indyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84095744"
                        ],
                        "name": "R. Motwani",
                        "slug": "R.-Motwani",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Motwani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Motwani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "The described technique is called locality-sensitive hashing (LSH) and was introduced in [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 95
                            }
                        ],
                        "text": "The algorithms yield sublinear complexity with a speedup which depends on the desired accuracy [7, 10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 3
                            }
                        ],
                        "text": "In [10, 11] the problem of nonuniformly distributed data was dealt with by building several data structures with different values of 7 and j to accommodate the different local densities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 182
                            }
                        ],
                        "text": "Recently new algorithms using tools from probabilistic approximation theory were suggested for performing approximate nearest neighbor search in high dimensions for general datasets [10, 11] and for clustering data [9, 14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6110572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1955266a8a58d94e41ad0efe20d707c92a069e95",
            "isKey": true,
            "numCitedBy": 4276,
            "numCiting": 160,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two algorithms for the approximate nearest neighbor problem in high-dimensional spaces. For data sets of size n living in R d , the algorithms require space that is only polynomial in n and d, while achieving query times that are sub-linear in n and polynomial in d. We also show applications to other high-dimensional geometric problems, such as the approximate minimum spanning tree. The article is based on the material from the authors' STOC'98 and FOCS'01 papers. It unifies, generalizes and simplifies the results from those papers."
            },
            "slug": "Approximate-nearest-neighbors:-towards-removing-the-Indyk-Motwani",
            "title": {
                "fragments": [],
                "text": "Approximate nearest neighbors: towards removing the curse of dimensionality"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "Two algorithms for the approximate nearest neighbor problem in high-dimensional spaces are presented, which require space that is only polynomial in n and d, while achieving query times that are sub-linear inn and polynometric in d."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688317"
                        ],
                        "name": "P. Indyk",
                        "slug": "P.-Indyk",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Indyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Indyk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 215
                            }
                        ],
                        "text": "Recently new algorithms using tools from probabilistic approximation theory were suggested for performing approximate nearest neighbor search in high dimensions for general datasets [10, 11] and for clustering data [9, 14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17238729,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "76b68dd26e0e2cabcbd376deb76e998eeb323d7a",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The metric 2-clustering problem is defined as follows: given a metric (or weighted graph) (X,d), partition X into two sets S(1) and S(2) in order to minimize the value of /spl Sigma//sub i//spl Sigma//sub {u,v}/spl sub/S(i)/d(u,v). In this paper, we show an approximation scheme for this problem."
            },
            "slug": "A-sublinear-time-approximation-scheme-for-in-metric-Indyk",
            "title": {
                "fragments": [],
                "text": "A sublinear time approximation scheme for clustering in metric spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper shows an approximation scheme for the metric 2-clustering problem, which involves partitioning X into two sets S(1) and S(2) in order to minimize the value of Sigmasub i/spl sub/S(i)/d(u,v)."
            },
            "venue": {
                "fragments": [],
                "text": "40th Annual Symposium on Foundations of Computer Science (Cat. No.99CB37039)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145187873"
                        ],
                        "name": "M. D. Berg",
                        "slug": "M.-D.-Berg",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Berg",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. D. Berg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61828744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "daddeaf80589e618b4b563d20057b1bbfd3e8534",
            "isKey": false,
            "numCitedBy": 6082,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This introduction to computational geometry focuses on algorithms. Motivation is provided from the application areas as all techniques are related to particular applications in robotics, graphics, CAD/CAM, and geographic information systems. Modern insights in computational geometry are used to provide solutions that are both efficient and easy to understand and implement."
            },
            "slug": "Computational-geometry:-algorithms-and-applications-Berg",
            "title": {
                "fragments": [],
                "text": "Computational geometry: algorithms and applications"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This introduction to computational geometry focuses on algorithms as all techniques are related to particular applications in robotics, graphics, CAD/CAM, and geographic information systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 95
                            }
                        ],
                        "text": "The algorithms yield sublinear complexity with a speedup which depends on the desired accuracy [7, 10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 3
                            }
                        ],
                        "text": "In [10, 11] the problem of nonuniformly distributed data was dealt with by building several data structures with different values of 7 and j to accommodate the different local densities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 182
                            }
                        ],
                        "text": "Recently new algorithms using tools from probabilistic approximation theory were suggested for performing approximate nearest neighbor search in high dimensions for general datasets [10, 11] and for clustering data [9, 14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26616023,
            "fieldsOfStudy": [],
            "id": "fb80a27ed3e9e785822d08b9119809c7cc227d64",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient Search for Approximate Nearest Neighbor in High Dimensional Spaces"
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Comput."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586918"
                        ],
                        "name": "D. Stork",
                        "slug": "D.-Stork",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stork",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stork"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 196008710,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78053512af13466c569e5946acfc3953bbfc9d36",
            "isKey": false,
            "numCitedBy": 18023,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pattern-Classification-Hart-Duda",
            "title": {
                "fragments": [],
                "text": "Pattern Classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "\u2013 M4, M8: Both representations were proposed by Varma and Zissermann [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Efficient methods exist for texture classification under varying illumination and viewing direction [3],[12], [15], [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "The normalizations recommended in [18] (both in the image and filter domains) were also performed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17382230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ae123f69492ad7629cb34c64968830916b834a7",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Classifying-materials-from-images:-to-cluster-or-to-Varma-Zisserman",
            "title": {
                "fragments": [],
                "text": "Classifying materials from images: to cluster or not to cluster?"
            },
            "venue": {
                "fragments": [],
                "text": "eccv 2002"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Silverman.Density Estimation for Statistics and Data Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the Ninth IEEE International Conference on Computer Vision (ICCV 2003"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Ninth IEEE International Conference on Computer Vision (ICCV 2003"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "\u2013 M4, M8: Both representations were proposed by Varma and Zissermann [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "The normalizations recommended in [18] (both in the image and filter domains) were also performed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classifying images of materi  als"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. European Conf. on Computer Vision,  Copenhagen, Denmark, volume III, pages 255\u2013271"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Zisserman . Classifying images of materi"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 14,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 24,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Mean-shift-based-clustering-in-high-dimensions:-a-Georgescu-Shimshoni/c41bf09e692ae81b7f81e8c657303b30a4d807b5?sort=total-citations"
}