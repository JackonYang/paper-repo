{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 88
                            }
                        ],
                        "text": "Note that the exponential kernel construction is not related to the result described in (Berg et al., 1984; Haussler, 1999) and (Sch\u00f6lkopf & Smola, 2001), based on Schoenberg\u2019s pioneering work in the late 1930\u2019s in the theory of positive definite functions (Schoenberg, 1938)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 119
                            }
                        ],
                        "text": "Infinite divisibility means that can be written as an 3 -fold convolution BADC ) E BADC )FE @ @ @ E BADC ) for any 3 G (Haussler, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 120
                            }
                        ],
                        "text": "Infinite divisibility means that can be written as an 3 -fold\nconvolution BADC ) E BADC )FE @ @ @ E BADC ) for any 3 G (Haussler, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 105
                            }
                        ],
                        "text": "A notable exception to this is the line of work stemming from the convolution kernel idea introduced in (Haussler, 1999) and related but independently conceived ideas on string kernels first presented in (Watkins, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 108
                            }
                        ],
                        "text": "Note that the exponential kernel construction is not related to the result described in (Berg et al., 1984; Haussler, 1999) and (Scho\u0308lkopf & Smola, 2001), based on Schoenberg\u2019s pioneering work in the late 1930\u2019s in the theory of positive definite functions (Schoenberg, 1938)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17702358,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "5ee0d8aeb2cb01ef4d8a858d234e72a7400c03ac",
            "isKey": true,
            "numCitedBy": 1371,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new method of constructing kernels on sets whose elements are discrete structures like strings, trees and graphs. The method can be applied iteratively to build a kernel on a innnite set from kernels involving generators of the set. The family of kernels generated generalizes the family of radial basis kernels. It can also be used to deene kernels in the form of joint Gibbs probability distributions. Kernels can be built from hidden Markov random elds, generalized regular expressions, pair-HMMs, or ANOVA de-compositions. Uses of the method lead to open problems involving the theory of innnitely divisible positive deenite functions. Fundamentals of this theory and the theory of reproducing kernel Hilbert spaces are reviewed and applied in establishing the validity of the method."
            },
            "slug": "Convolution-kernels-on-discrete-structures-Haussler",
            "title": {
                "fragments": [],
                "text": "Convolution kernels on discrete structures"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A new method of constructing kernels on sets whose elements are discrete structures like strings, trees and graphs is introduced, which can be applied iteratively to build a kernel on a innnite set from kernels involving generators of the set."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145520115"
                        ],
                        "name": "Mikhail Belkin",
                        "slug": "Mikhail-Belkin",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Belkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikhail Belkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770745"
                        ],
                        "name": "P. Niyogi",
                        "slug": "P.-Niyogi",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Niyogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Niyogi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 166
                            }
                        ],
                        "text": "Finally, adjacency graphs are sometimes used when data is expected to be confined to a manifold of lower dimensionality than the original space (Saul & Roweis, 2001; Belkin & Niyogi, 2001) and (Szummer & Jaakkola, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14879317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "88816ae492956f3004daa41357166f1181c0c1bf",
            "isKey": false,
            "numCitedBy": 7047,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider the problem of constructing a representation for data lying on a low-dimensional manifold embedded in a high-dimensional space. Drawing on the correspondence between the graph Laplacian, the Laplace Beltrami operator on the manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for representing the high-dimensional data. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering. Some potential applications and illustrative examples are discussed."
            },
            "slug": "Laplacian-Eigenmaps-for-Dimensionality-Reduction-Belkin-Niyogi",
            "title": {
                "fragments": [],
                "text": "Laplacian Eigenmaps for Dimensionality Reduction and Data Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a geometrically motivated algorithm for representing the high-dimensional data that provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718206"
                        ],
                        "name": "F. Graham",
                        "slug": "F.-Graham",
                        "structuredName": {
                            "firstName": "Fan",
                            "lastName": "Graham",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Graham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116303595"
                        ],
                        "name": "S. Yau",
                        "slug": "S.-Yau",
                        "structuredName": {
                            "firstName": "Shing-Tung",
                            "lastName": "Yau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8285319,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "233e6f41911728cb7ca61b816314fff4539f7e34",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a graph $G$ and a covering $\\tilde{G}$ of $G$ and we study the relations of their eigenvalues and heat kernels. We evaluate the heat kernel for an infinite $k$-regular tree and we examine the heat kernels for general $k$-regular graphs. In particular, we show that a $k$-regular graph on $n$ vertices has at most $$ (1+o(1)) {{2\\log n}\\over {kn \\log k}} \\left( {{ (k-1)^{k-1}}\\over {(k^2-2k)^{k/2-1}}}\\right)^n $$ spanning trees, which is best possible within a constant factor."
            },
            "slug": "Coverings,-Heat-Kernels-and-Spanning-Trees-Graham-Yau",
            "title": {
                "fragments": [],
                "text": "Coverings, Heat Kernels and Spanning Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "It is shown that a $k-regular graph on $n$ vertices has at most (1+o (1) + o(1) n spanning trees, which is best possible within a constant factor."
            },
            "venue": {
                "fragments": [],
                "text": "Electron. J. Comb."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069424108"
                        ],
                        "name": "R. Albert",
                        "slug": "R.-Albert",
                        "structuredName": {
                            "firstName": "R\u00e9ka",
                            "lastName": "Albert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Albert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745069"
                        ],
                        "name": "A. Barabasi",
                        "slug": "A.-Barabasi",
                        "structuredName": {
                            "firstName": "A",
                            "lastName": "Barabasi",
                            "middleNames": [
                                "L"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barabasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 108
                            }
                        ],
                        "text": "Other examples include social networks, citations between scientific articles, and networks in linguistics (Albert & Baraba\u0301si, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dce8146987557735a19771aefa1f027211a2c275",
            "isKey": false,
            "numCitedBy": 17708,
            "numCiting": 369,
            "paperAbstract": {
                "fragments": [],
                "text": "The emergence of order in natural systems is a constant source of inspiration for both physical and biological sciences. While the spatial order characterizing for example the crystals has been the basis of many advances in contemporary physics, most complex systems in nature do not offer such high degree of order. Many of these systems form complex networks whose nodes are the elements of the system and edges represent the interactions between them. \nTraditionally complex networks have been described by the random graph theory founded in 1959 by Paul Erdohs and Alfred Renyi. One of the defining features of random graphs is that they are statistically homogeneous, and their degree distribution (characterizing the spread in the number of edges starting from a node) is a Poisson distribution. In contrast, recent empirical studies, including the work of our group, indicate that the topology of real networks is much richer than that of random graphs. In particular, the degree distribution of real networks is a power-law, indicating a heterogeneous topology in which the majority of the nodes have a small degree, but there is a significant fraction of highly connected nodes that play an important role in the connectivity of the network. \nThe scale-free topology of real networks has very important consequences on their functioning. For example, we have discovered that scale-free networks are extremely resilient to the random disruption of their nodes. On the other hand, the selective removal of the nodes with highest degree induces a rapid breakdown of the network to isolated subparts that cannot communicate with each other. \nThe non-trivial scaling of the degree distribution of real networks is also an indication of their assembly and evolution. Indeed, our modeling studies have shown us that there are general principles governing the evolution of networks. Most networks start from a small seed and grow by the addition of new nodes which attach to the nodes already in the system. This process obeys preferential attachment: the new nodes are more likely to connect to nodes with already high degree. We have proposed a simple model based on these two principles wich was able to reproduce the power-law degree distribution of real networks. Perhaps even more importantly, this model paved the way to a new paradigm of network modeling, trying to capture the evolution of networks, not just their static topology."
            },
            "slug": "Statistical-mechanics-of-complex-networks-Albert-Barabasi",
            "title": {
                "fragments": [],
                "text": "Statistical mechanics of complex networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A simple model based on these two principles was able to reproduce the power-law degree distribution of real networks, indicating a heterogeneous topology in which the majority of the nodes have a small degree, but there is a significant fraction of highly connected nodes that play an important role in the connectivity of the network."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459012"
                        ],
                        "name": "S. Mika",
                        "slug": "S.-Mika",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Mika",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mika"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47342864"
                        ],
                        "name": "Matthias Scholz",
                        "slug": "Matthias-Scholz",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Scholz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Scholz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152597562"
                        ],
                        "name": "Gunnar R\u00e4tsch",
                        "slug": "Gunnar-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gunnar R\u00e4tsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 124
                            }
                        ],
                        "text": "Kernel-based algorithms, such as Gaussian processes (Mackay, 1997), support vector machines (Burges, 1998), and kernel PCA (Mika et al., 1998), are enjoying great popularity in the statistical learning community."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2508678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77cf1b068da9adf55ae84115f7206747368c4198",
            "isKey": false,
            "numCitedBy": 1006,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Kernel PCA as a nonlinear feature extractor has proven powerful as a preprocessing step for classification algorithms. But it can also be considered as a natural generalization of linear principal component analysis. This gives rise to the question how to use nonlinear features for data compression, reconstruction, and de-noising, applications common in linear PCA. This is a nontrivial task, as the results provided by kernel PCA live in some high dimensional feature space and need not have pre-images in input space. This work presents ideas for finding approximate pre-images, focusing on Gaussian kernels, and shows experimental results using these pre-images in data reconstruction and de-noising on toy examples as well as on real world data."
            },
            "slug": "Kernel-PCA-and-De-Noising-in-Feature-Spaces-Mika-Sch\u00f6lkopf",
            "title": {
                "fragments": [],
                "text": "Kernel PCA and De-Noising in Feature Spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work presents ideas for finding approximate pre-images, focusing on Gaussian kernels, and shows experimental results using these pre- images in data reconstruction and de-noising on toy examples as well as on real world data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796044"
                        ],
                        "name": "L. Saul",
                        "slug": "L.-Saul",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Saul",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Saul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9330607"
                        ],
                        "name": "S. Roweis",
                        "slug": "S.-Roweis",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Roweis",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roweis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 145
                            }
                        ],
                        "text": "Finally, adjacency graphs are sometimes used when data is expected to be confined to a manifold of lower dimensionality than the original space (Saul & Roweis, 2001; Belkin & Niyogi, 2001) and (Szummer & Jaakkola, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 72532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da6495102377f8332b21cef50c35d27fbff627df",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Many problems in information processing involve some form of dimensionality reduction. Here we describe locally linear embedding (LLE), an unsupervised learning algorithm that computes low dimensional, neighborhood preserving embeddings of high dimensional data. LLE attempts to discover nonlinear structure in high dimensional data by exploiting the local symmetries of linear reconstructions. Notably, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations\u2014 though capable of generating highly nonlinear embeddings\u2014do not involve local minima. We illustrate the method on images of lips used in audiovisual speech synthesis."
            },
            "slug": "An-Introduction-to-Locally-Linear-Embedding-Saul-Roweis",
            "title": {
                "fragments": [],
                "text": "An Introduction to Locally Linear Embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Locally linear embedding is described, an unsupervised learning algorithm that computes low dimensional, neighborhood preserving embeddings of high dimensional data that attempts to discover nonlinear structure in highdimensional data by exploiting the local symmetries of linear reconstructions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4231116"
                        ],
                        "name": "F. Chung",
                        "slug": "F.-Chung",
                        "structuredName": {
                            "firstName": "Fan",
                            "lastName": "Chung",
                            "middleNames": [
                                "R.",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Chung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 143
                            }
                        ],
                        "text": "The negative of this matrix (sometimes up to normalization) is called the Laplacian of , and it plays a central role in spectral graph theory (Chung, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60624922,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "95d6ff6279fa0f92df6fae0e6bd4c259acfc8f09",
            "isKey": false,
            "numCitedBy": 4221,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Eigenvalues and the Laplacian of a graph Isoperimetric problems Diameters and eigenvalues Paths, flows, and routing Eigenvalues and quasi-randomness Expanders and explicit constructions Eigenvalues of symmetrical graphs Eigenvalues of subgraphs with boundary conditions Harnack inequalities Heat kernels Sobolev inequalities Advanced techniques for random walks on graphs Bibliography Index."
            },
            "slug": "Spectral-Graph-Theory-Chung",
            "title": {
                "fragments": [],
                "text": "Spectral Graph Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778989"
                        ],
                        "name": "M. Szummer",
                        "slug": "M.-Szummer",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Szummer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Szummer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 194
                            }
                        ],
                        "text": "Finally, adjacency graphs are sometimes used when data is expected to be confined to a manifold of lower dimensionality than the original space (Saul & Roweis, 2001; Belkin & Niyogi, 2001) and (Szummer & Jaakkola, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9743839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e6779bb55f7fbed5684ded55df51747ea678a84",
            "isKey": false,
            "numCitedBy": 669,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "To classify a large number of unlabeled examples we combine a limited number of labeled examples with a Markov random walk representation over the unlabeled examples. The random walk representation exploits any low dimensional structure in the data in a robust, probabilistic manner. We develop and compare several estimation criteria/algorithms suited to this representation. This includes in particular multi-way classification with an average margin criterion which permits a closed form solution. The time scale of the random walk regularizes the representation and can be set through a margin-based criterion favoring unambiguous classification. We also extend this basic regularization by adapting time scales for individual examples. We demonstrate the approach on synthetic examples and on text classification problems."
            },
            "slug": "Partially-labeled-classification-with-Markov-random-Szummer-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Partially labeled classification with Markov random walks"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work combines a limited number of labeled examples with a Markov random walk representation over the unlabeled examples and develops and compares several estimation criteria/algorithms suited to this representation."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4562073"
                        ],
                        "name": "C. Watkins",
                        "slug": "C.-Watkins",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Watkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Watkins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 205
                            }
                        ],
                        "text": "A notable exception to this is the line of work stemming from the convolution kernel idea introduced in (Haussler, 1999) and related but independently conceived ideas on string kernels first presented in (Watkins, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17875902,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dd9743183f07b7653cc0335fcc1042aa71032c6",
            "isKey": false,
            "numCitedBy": 232,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "There is much current interest in kernel methods for classi cation re gression PCA and other linear methods of data analysis Kernel methods may be particularly valuable for problems in which the input data is not readily described by explicit feature vectors One such problem is where input data consists of symbol sequences of di erent lengths and the re lationships between sequences are best captured by dynamic alignment scores This paper shows that the scores produced by certain dynamic align ment algorithms for sequences are in fact valid kernel functions This is proved by expressing the alignment scores explicitly as dot products Alignment kernels are potentially applicable to biological sequence data speech data and time series data The kernel construction may be extended from pair HMMs to pair probabilistic context free grammars Introduction Linear Methods using Kernel Functions Introduction Linear Methods using Kernel Functions In many types of machine learning the learner is given a training set of cases or examples a al A A denotes the set of all possible cases cases may be vectors pieces of text biological sequences sentences etc For supervised learning the cases are accompanied by a set of corresponding labels or values y yl The cases are mapped to feature vectors x xl X where the X is a real vector space termed the feature space The mapping from A to X is denoted by so that xi ai Sometimes the cases are given as feature vectors to start with in which case may be the identity mapping otherwise denotes the method of assigning numeric feature values to a case Once a feature vector xi has been de ned for each case ai it becomes pos sible to apply a wide range of linear methods such as support vector machines linear regression principal components analysis PCA and k means cluster analysis As shown in Vap for SV machines in for example Wah for linear re gression and in SSM for PCA and k means cluster analysis the calculations for all of these linear methods may be carried out using a dual rather than a primal formulation of the problem For example in linear least squares regression the primal formulation is to nd a coe cient vector that minimises kX yk whereX is the design matrix an l by d matrix in which the ith row is xi and each xi has d elements If l is larger than d the usual method of nding is to solve the normal equations XX Xy This requires the solution of a set of linear equations with coe cients given by the d d matrix XX The dual formulation is to nd a coe cient vector that minimises kXX yk so that one coe cient i is found for each case vector xi This requires the solution of a set of linear equations with coe cients given by the l l matrix XX Both methods lead to the same predicted value y for a new case x If there are more cases than features that is if l d the primal method is more economical because the d d matrix XX is smaller than the l l matrix XX For example if there are cases each described by a vector of measurements then the primal method requires solving a by system of linear equations while the dual method requires solving a by system which will have rank at most For such a problem the dual method has no advantage The potential advantage of the dual method for regression is that it can be applied to very large feature vectors The coe cient matrix XX contains the dot products of pairs of feature vectors the ijth element of XX is xi xj In the dual calculation it is only dot products of feature vectors that are used feature vectors never appear on their own As the feature vectors xi ai appear only in dot products it is often possible to avoid computing the feature vectors and to compute dot products directly in some economical fashion from the case descriptions ai instead A kernel is a function k that computes a dot product of feature vectors from the corresponding cases Applying Linear Methods to Structured Objects De nition A kernel is a function k such that for all a b A"
            },
            "slug": "Dynamic-Alignment-Kernels-Watkins",
            "title": {
                "fragments": [],
                "text": "Dynamic Alignment Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that the scores produced by certain dynamic align ment algorithms for sequences are in fact valid kernel functions, proved by expressing the alignment scores explicitly as dot products."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144403112"
                        ],
                        "name": "C. Berg",
                        "slug": "C.-Berg",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Berg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144027552"
                        ],
                        "name": "J. Christensen",
                        "slug": "J.-Christensen",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Christensen",
                            "middleNames": [
                                "Peter",
                                "Reus"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Christensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101172055"
                        ],
                        "name": "P. Ressel",
                        "slug": "P.-Ressel",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Ressel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ressel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 89
                            }
                        ],
                        "text": "Note that the exponential kernel construction is not related to the result described in (Berg et al., 1984; Haussler, 1999) and (Scho\u0308lkopf & Smola, 2001), based on Schoenberg\u2019s pioneering work in the late 1930\u2019s in the theory of positive definite functions (Schoenberg, 1938)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 88
                            }
                        ],
                        "text": "Note that the exponential kernel construction is not related to the result described in (Berg et al., 1984; Haussler, 1999) and (Sch\u00f6lkopf & Smola, 2001), based on Schoenberg\u2019s pioneering work in the late 1930\u2019s in the theory of positive definite functions (Schoenberg, 1938)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117820106,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ab57158a286f3b4672fcc9cdc46fa5c51f14cae0",
            "isKey": false,
            "numCitedBy": 474,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Introduction to Locally Convex Topological Vector Spaces and Dual Pairs.- 1. Locally Convex Vector Spaces.- 2. Hahn-Banach Theorems.- 3. Dual Pairs.- Notes and Remarks.- 2 Radon Measures and Integral Representations.- 1. Introduction to Radon Measures on Hausdorff Spaces.- 2. The Riesz Representation Theorem.- 3. Weak Convergence of Finite Radon Measures.- 4. Vague Convergence of Radon Measures on Locally Compact Spaces.- 5. Introduction to the Theory of Integral Representations.- Notes and Remarks.- 3 General Results on Positive and Negative Definite Matrices and Kernels.- 1. Definitions and Some Simple Properties of Positive and Negative Definite Kernels.- 2. Relations Between Positive and Negative Definite Kernels.- 3. Hubert Space Representation of Positive and Negative Definite Kernels.- Notes and Remarks.- 4 Main Results on Positive and Negative Definite Functions on Semigroups.- 1. Definitions and Simple Properties 86 2. Exponentially Bounded Positive Definite Functions on Abelian Semigroups.- 3. Negative Definite Functions on Abelian Semigroups.- 4. Examples of Positive and Negative Definite Functions.- 5. T-Positive Functions.- 6. Completely Monotone and Alternating Functions.- Notes and Remarks.- 5 Schoenberg-Type Results for Positive and Negative Definite Functions.- 1. Schoenberg Triples.- 2. Norm Dependent Positive Definite Functions on Banach Spaces.- 3. Functions Operating on Positive Definite Matrices.- 4. Schoenberg's Theorem for the Complex Hilbert Sphere.- 5. The Real Infinite Dimensional Hyperbolic Space.- Notes and Remarks.- 6 Positive Definite Functions and Moment Functions.- 1. Moment Functions.- 2. The One-Dimensional Moment Problem.- 3. The Multi-Dimensional Moment Problem.- 4. The Two-Sided Moment Problem.- 5. Perfect Semigroups.- Notes and Remarks.- 7 Hoeffding's Inequality and Multivariate Majorization.- 1. The Discrete Case.- 2. Extension to Nondiscrete Semigroups.- 3. Completely Negative Definite Functions and Schur-Monotonicity.- Notes and Remarks.- 8 Positive and Negative Definite Functions on Abelian Semigroups Without Zero.- 1. Quasibounded Positive and Negative Definite Functions.- 2. Completely Monotone and Completely Alternating Functions.- Notes and Remarks.- References.- List of Symbols."
            },
            "slug": "Harmonic-Analysis-on-Semigroups:-Theory-of-Positive-Berg-Christensen",
            "title": {
                "fragments": [],
                "text": "Harmonic Analysis on Semigroups: Theory of Positive Definite and Related Functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714772"
                        ],
                        "name": "Dale Schuurmans",
                        "slug": "Dale-Schuurmans",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Schuurmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Schuurmans"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125105198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e003f0a280275de163269d32046950ad37aa37f0",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Introduction: Linear Methods using Kernel function, Applying Linear Methods to Structured Objects, Conditional Symmetric Independence Kernels, Pair Hidden Markov Models, Conditionally Symmetrically Independent PHMMs, Conclusion"
            },
            "slug": "Dynamic-Alignment-Kernels-Smola-Bartlett",
            "title": {
                "fragments": [],
                "text": "Dynamic Alignment Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter contains sections titled: Introduction: Linear Methods using Kernel function, Applying Linear Methods to Structured Objects, Conditional Symmetric Independence Kernels, Pair Hidden Markov Models, Conditionally Symmetrically Independent PHMMs, Conclusion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187514"
                        ],
                        "name": "R. Durbin",
                        "slug": "R.-Durbin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Durbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Durbin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708077"
                        ],
                        "name": "S. Eddy",
                        "slug": "S.-Eddy",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Eddy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Eddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197258"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145666307"
                        ],
                        "name": "G. Mitchison",
                        "slug": "G.-Mitchison",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Mitchison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mitchison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 122
                            }
                        ],
                        "text": "For the derivation of recursive formul\u00e6 such as this, and comparison to other measures of similarity between strings, see (Durbin et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2852254,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "571f5bbecd3a083a2bb6844f59a3f8cea237252e",
            "isKey": false,
            "numCitedBy": 4477,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Probablistic models are becoming increasingly important in analyzing the huge amount of data being produced by large-scale DNA-sequencing efforts such as the Human Genome Project. For example, hidden Markov models are used for analyzing biological sequences, linguistic-grammar-based probabilistic models for identifying RNA secondary structure, and probabilistic evolutionary models for inferring phylogenies of sequences from different organisms. This book gives a unified, up-to-date and self-contained account, with a Bayesian slant, of such methods, and more generally to probabilistic methods of sequence analysis. Written by an interdisciplinary team of authors, it is accessible to molecular biologists, computer scientists, and mathematicians with no formal knowledge of the other fields, and at the same time presents the state of the art in this new and important field."
            },
            "slug": "Biological-Sequence-Analysis:-Probabilistic-Models-Durbin-Eddy",
            "title": {
                "fragments": [],
                "text": "Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This book gives a unified, up-to-date and self-contained account, with a Bayesian slant, of such methods, and more generally to probabilistic methods of sequence analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 129
                            }
                        ],
                        "text": "Note that the exponential kernel construction is not related to the result described in (Berg et al., 1984; Haussler, 1999) and (Scho\u0308lkopf & Smola, 2001), based on Schoenberg\u2019s pioneering work in the late 1930\u2019s in the theory of positive definite functions (Schoenberg, 1938)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 7
                            }
                        ],
                        "text": "' (1) (Scho\u0308lkopf & Smola, 2001)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 29871328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5051890e501117097eeffbd8ded87694f0d8063",
            "isKey": false,
            "numCitedBy": 6578,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher."
            },
            "slug": "Learning-with-kernels-Smola",
            "title": {
                "fragments": [],
                "text": "Learning with kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This book is intended to be a guide to the art of self-consistency and should not be used as a substitute for a comprehensive guide to self-confidence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72184075"
                        ],
                        "name": "F. William",
                        "slug": "F.-William",
                        "structuredName": {
                            "firstName": "Feller",
                            "lastName": "William",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. William"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 165
                            }
                        ],
                        "text": ", indexed by a real pa-rameter 1 , and are related to infinitely divisible probabil-ity distributions, which are the limits of sums of independent random variables (Feller, 1971)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 162
                            }
                        ],
                        "text": ", indexed by a real parameter 1 , and are related to infinitely divisible probability distributions, which are the limits of sums of independent random variables (Feller, 1971)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 65112646,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "65ba8fd8ef9c2a70cee99d2e5cab9302d0307a1e",
            "isKey": false,
            "numCitedBy": 12393,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Office hours: MWF, immediately after class or early afternoon (time TBA). We will cover the mathematical foundations of probability theory. The basic terminology and concepts of probability theory include: random experiments, sample or outcome spaces (discrete and continuous case), events and their algebra, probability measures, conditional probability A First Course in Probability (8th ed.) by S. Ross. This is a lively text that covers the basic ideas of probability theory including those needed in statistics. Theoretical concepts are introduced via interesting concrete examples. In 394 I will begin my lectures with the basics of probability theory in Chapter 2. However, your first assignment is to review Chapter 1, which treats elementary counting methods. They are used in applications in Chapter 2. I expect to cover Chapters 2-5 plus portions of 6 and 7. You are encouraged to read ahead. In lectures I will not be able to cover every topic and example in Ross, and conversely, I may cover some topics/examples in lectures that are not treated in Ross. You will be responsible for all material in my lectures, assigned reading, and homework, including supplementary handouts if any."
            },
            "slug": "An-Introduction-To-Probability-Theory-And-Its-William",
            "title": {
                "fragments": [],
                "text": "An Introduction To Probability Theory And Its Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A First Course in Probability (8th ed.) by S. Ross is a lively text that covers the basic ideas of probability theory including those needed in statistics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1950
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 220
                            }
                        ],
                        "text": "When dealing with intrinsically discrete data spaces, the usual approach has been either to map the data to Euclidean space first (as is commonly done in text classification, treating integer word counts as real numbers (Joachims, 1998)) or, when no such simple mapping is forthcoming, to forgo using kernel methods altogether."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 190
                            }
                        ],
                        "text": "\u2026discrete data spaces, the usual approach has been either to map the data to Euclidean space first (as is commonly done in text classification, treating integer word counts as real numbers (Joachims, 1998)) or, when no such simple mapping is forthcoming, to forgo using kernel methods altogether."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2427083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40212e9474c3ddf3d8c6ffd13dd3211ec9406c49",
            "isKey": false,
            "numCitedBy": 8601,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of Support Vector Machines (SVMs) for learning text classifiers from examples. It analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task. Empirical results support the theoretical findings. SVMs achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks. Furthermore they are fully automatic, eliminating the need for manual parameter tuning."
            },
            "slug": "Text-Categorization-with-Support-Vector-Machines:-Joachims",
            "title": {
                "fragments": [],
                "text": "Text Categorization with Support Vector Machines: Learning with Many Relevant Features"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper explores the use of Support Vector Machines for learning text classifiers from examples and analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 126385209,
            "fieldsOfStudy": [],
            "id": "57509fd2d4b9db1595335b2d637f7e34a719aa83",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Introduction to Probability Theory and Its Applications, Vol. II"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50456127"
                        ],
                        "name": "I. J. Schoenberg",
                        "slug": "I.-J.-Schoenberg",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Schoenberg",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. J. Schoenberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 256
                            }
                        ],
                        "text": "Note that the exponential kernel construction is not related to the result described in (Berg et al., 1984; Haussler, 1999) and (Scho\u0308lkopf & Smola, 2001), based on Schoenberg\u2019s pioneering work in the late 1930\u2019s in the theory of positive definite functions (Schoenberg, 1938)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 157
                            }
                        ],
                        "text": ", 1984; Haussler, 1999) and (Sch\u00f6lkopf & Smola, 2001), based on Schoenberg\u2019s pioneering work in the late 1930\u2019s in the theory of positive definite functions (Schoenberg, 1938)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123282658,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "026c5719b82bda94d69022b2fac307ec0aa2e850",
            "isKey": false,
            "numCitedBy": 907,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Metric-spaces-and-completely-monotone-functions-Schoenberg",
            "title": {
                "fragments": [],
                "text": "Metric spaces and completely monotone functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1938
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644344103"
                        ],
                        "name": "J. C. BurgesChristopher",
                        "slug": "J.-C.-BurgesChristopher",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "BurgesChristopher",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. BurgesChristopher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 92
                            }
                        ],
                        "text": "Kernel-based algorithms, such as Gaussian processes (Mackay, 1997), support vector machines (Burges, 1998), and kernel PCA (Mika et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 93
                            }
                        ],
                        "text": "Kernel-based algorithms, such as Gaussian processes (Mackay, 1997), support vector machines (Burges, 1998), and kernel PCA (Mika et al., 1998), are enjoying great popularity in the statistical learning community."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215966761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6716697767fc601efc7690f40820d9ea7a7bf57c",
            "isKey": false,
            "numCitedBy": 13527,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, w..."
            },
            "slug": "A-Tutorial-on-Support-Vector-Machines-for-Pattern-BurgesChristopher",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Support Vector Machines for Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This tutorial starts with an overview of the concepts of VC dimension and structural risk minimization and describes linear Support Vector Machines (SVMs) for separable and non-separable data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 108
                            }
                        ],
                        "text": "Other examples include social networks, citations between scientific articles, and networks in linguistics (Albert & Baraba\u0301si, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 1
                            }
                        ],
                        "text": "Graphs are also sometimes used to model complicated or only partially understood structures in a first approximation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical mechanics of complex networks. Available from \u00d8\u00d8\u00d4\u00d4\u00bb\u00bb\u00db\u00db\u00db\u00ba\u00d2\u00d2\u00ba\u00ba\u00ba\u00d9\u00bb\u00bb\u00d2\u00d2\u00d8\u00db\u00d3\u00d6\u00d6\u00d7\u00bb\u00c8\u00c8\u00d4\u00d6\u00d7\u00bb"
            },
            "venue": {
                "fragments": [],
                "text": "Statistical mechanics of complex networks. Available from \u00d8\u00d8\u00d4\u00d4\u00bb\u00bb\u00db\u00db\u00db\u00ba\u00d2\u00d2\u00ba\u00ba\u00ba\u00d9\u00bb\u00bb\u00d2\u00d2\u00d8\u00db\u00d3\u00d6\u00d6\u00d7\u00bb\u00c8\u00c8\u00d4\u00d6\u00d7\u00bb"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 108
                            }
                        ],
                        "text": "Other examples include social networks, citations between scientific articles, and networks in linguistics (Albert & Baraba\u0301si, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical mechanics of complex networks. Available from"
            },
            "venue": {
                "fragments": [],
                "text": "Statistical mechanics of complex networks. Available from"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 30
                            }
                        ],
                        "text": "Despite the promise of these ideas, relatively little work has been done on discrete kernels since the publication of these articles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 205
                            }
                        ],
                        "text": "A notable exception to this is the line of work stemming from the convolution kernel idea introduced in (Haussler, 1999) and related but independently conceived ideas on string kernels first presented in (Watkins, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic alignment kernels Advances in kernel methods"
            },
            "venue": {
                "fragments": [],
                "text": "Dynamic alignment kernels Advances in kernel methods"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 53
                            }
                        ],
                        "text": "Kernel-based algorithms, such as Gaussian processes (Mackay, 1997), support vector machines (Burges, 1998), and kernel PCA (Mika et al., 1998), are enjoying great popularity in the statistical learning community."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gaussian processes: A replacement for neural networks? NIPS tutorial Available from"
            },
            "venue": {
                "fragments": [],
                "text": "Gaussian processes: A replacement for neural networks? NIPS tutorial Available from"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 52
                            }
                        ],
                        "text": "Kernel-based algorithms, such as Gaussian processes (Mackay, 1997), support vector machines (Burges, 1998), and kernel PCA (Mika et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 53
                            }
                        ],
                        "text": "Kernel-based algorithms, such as Gaussian processes (Mackay, 1997), support vector machines (Burges, 1998), and kernel PCA (Mika et al., 1998), are enjoying great popularity in the statistical learning community."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gaussian processes: A replacement for neural networks? NIPS tutorial"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 15,
            "methodology": 7,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 23,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Diffusion-kernels-on-graphs-and-other-discrete-Kondor/a9e51a86d106e73e60650f2c4784c5271e8c9735?sort=total-citations"
}