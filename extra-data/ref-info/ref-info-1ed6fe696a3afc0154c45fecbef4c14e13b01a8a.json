{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144850567"
                        ],
                        "name": "Long Zhu",
                        "slug": "Long-Zhu",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2651359"
                        ],
                        "name": "ZhenQiu Zhang",
                        "slug": "ZhenQiu-Zhang",
                        "structuredName": {
                            "firstName": "ZhenQiu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ZhenQiu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154486"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 175
                            }
                        ],
                        "text": "A direct comparison with the methods reported in literature is difficult since they use different subsets of t his dataset with the most difficult faces removed (about 5 % in [3, 11]!)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 56
                            }
                        ],
                        "text": "\u201cFocus of attention\u201d (e.g. [7]), cascaded classifier [8], FloatBoost [3], boosting chain [11] or nesting-structured cascade [10] implicitly minimize the time to decision while keeping the error rates at a low level."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "[7]), cascaded classifier [8], Float Boost [3], boosting chain [11] or nesting-structured cascade [10] implicitly minimize the time to decision while keeping the error rates at a low level."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "Viola\u2212Jones [9] Boosting chain [12] FloatBoost [3] Wu [11] WaldBoost"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "Unlike [8], the weak classifiers are real valued (defined by equation (16)) and implemented as in [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 286,
                                "start": 276
                            }
                        ],
                        "text": "An ideal way of training a classifier would be to require a zero false negative rate and the smallest possible false positive\n0 100 200 300 400 500 600 700 800 900 1000 0.86\n0.88\n0.9\n0.92\n0.94\n0.96\n0.98\n1\nfalse positives\nde te\nct io\nn ra\nte\nViola\u2212Jones [9] Boosting chain [12] FloatBoost [3] Wu [11] WaldBoost\nFigure 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Method WB VJ[8] Li[3] Xiao[11] Wu[10] #wc 400 4297 2546 700 756 T\u0304S 10."
                    },
                    "intents": []
                }
            ],
            "corpusId": 32107239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c4fdffc12589f9f312a44802b8e2fe8311aa13e",
            "isKey": true,
            "numCitedBy": 462,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A new boosting algorithm, called FloatBoost, is proposed to overcome the monotonicity problem of the sequential AdaBoost learning. AdaBoost [1, 2] is a sequential forward search procedure using the greedy selection strategy. The premise oyered by the sequential procedure can be broken-down when the monotonicity assumption, i.e. that when adding a new feature to the current set, the value of the performance criterion does not decrease, is violated. FloatBoost incorporates the idea of Floating Search [3] into AdaBoost to solve the non-monotonicity problem encountered in the sequential search of AdaBoost.We then present a system which learns to detect multi-view faces using FloatBoost. The system uses a coarse-to-fine, simple-to-complex architecture called detector-pyramid. FloatBoost learns the component detectors in the pyramid and yields similar or higher classification accuracy than AdaBoost with a smaller number of weak classifiers. This work leads to the first real-time multi-view face detection system in the world. It runs at 200 ms per image of size 320x240 pixels on a Pentium-III CPU of 700 MHz. A live demo will be shown at the conference."
            },
            "slug": "Statistical-Learning-of-Multi-view-Face-Detection-Li-Zhu",
            "title": {
                "fragments": [],
                "text": "Statistical Learning of Multi-view Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "FloatBoost incorporates the idea of Floating Search into AdaBoost to solve the non-monotonicity problem encountered in the sequential search of AdaBoost and leads to the first real-time multi-view face detection system in the world."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 104
                            }
                        ],
                        "text": "The WaldBoost learning results in the fastest classifier among the compared methods except for the ViolaJones method which, despite its high speed gains significantly worse detection results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "Step 4 and 5 are similar to the cascade building procedure [8] with the substantial difference that the pruning and new data collection in the WaldBoost learning are run after every weak classifier is trained."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "[7]), cascaded classifier [8], Float Boost [3], boosting chain [11] or nesting-structured cascade [10] implicitly minimize the time to decision while keeping the error rates at a low level."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 168
                            }
                        ],
                        "text": "In the face detection contex t, the WaldBoost algorithm can be also viewed as a theoretically justifiable \u201dboosted cascade of classifiers\u201d propose d by Viola and Jones [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Unlike [8], the weak classifiers are real valued (defined by equation (16)) and implemented as in [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 246
                            }
                        ],
                        "text": "An ideal way of training a classifier would be to require a zero false negative rate and the smallest possible false positive\n0 100 200 300 400 500 600 700 800 900 1000 0.86\n0.88\n0.9\n0.92\n0.94\n0.96\n0.98\n1\nfalse positives\nde te\nct io\nn ra\nte\nViola\u2212Jones [9] Boosting chain [12] FloatBoost [3] Wu [11] WaldBoost\nFigure 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "Method WB VJ[8] Li[3] Xiao[11] Wu[10] #wc 400 4297 2546 700 756 T\u0304S 10."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 166
                            }
                        ],
                        "text": "In the face detection context, the WaldBoost algorithm can be also viewed as a theoretically justifiable \u201dboosted cascade of classifiers\u201d proposed by Viola and Jones [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 77
                            }
                        ],
                        "text": "They correspond to the final false positive and detection rates in the Viola-Jones cascade building [8]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 18
                            }
                        ],
                        "text": "Contrary to Viola-Jones, no stage false positive and detection rates are required."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "The weak classifier set H used in training is the same as in [8] but WaldBoost is not feature-specific and any other weak classifiers can be used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 101
                            }
                        ],
                        "text": "They correspond to the final false positive and detection rates in the Viola-Jones casca de building [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 235084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cb4d685b47001652b29dc41c1b3e786277e7647",
            "isKey": true,
            "numCitedBy": 4016,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features and yields extremely efficient classifiers [4]. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. A set of experiments in the domain of face detection are presented. The system yields face detection performance comparable to the best previous systems [16, 11, 14, 10, 1]. Implemented on a conventional desktop, face detection proceeds at 15 frames per second. Author email: fPaul.Viola,Mike.J.Jonesg@compaq.com c Compaq Computer Corporation, 2001 This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of the Cambridge Research Laboratory of Compaq Computer Corporation in Cambridge, Massachusetts; an acknowledgment of the authors and individual contributors to the work; and all applicable portions of the copyright notice. Copying, reproducing, or republishing for any other purpose shall require a license with payment of fee to the Cambridge Research Laboratory. All rights reserved. CRL Technical reports are available on the CRL\u2019s web page at http://crl.research.compaq.com. Compaq Computer Corporation Cambridge Research Laboratory One Cambridge Center Cambridge, Massachusetts 02142 USA"
            },
            "slug": "Robust-Real-time-Object-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-time Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates is described, with the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "They correspond to the final false positive and detection rates in the Viola-Jones casca de building [ 8 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[7]), cascaded classifier [ 8 ], Float -Boost [3], boosting chain [11] or nesting-structured cascade [10] implicitly minimize the time to decision while keeping the error rates at a low level."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In the face detection context, the WaldBoost algorithm can be also viewed as a theoretically justifiable \u201dboosted cascade of classifiers\u201d propose d by Viola and Jones [ 8 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "training set is enlarged again by newly bootstrapped samples (Step 5). Step 4 and 5 are similar to the cascade building procedure [ 8 ] with the substantial difference that the pruning and new data collection in the WaldBoost learning are run after every weak classifier is trained."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Unlike [ 8 ], the weak classifiers are real valued (defined by equation (16)) and implemented as in [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In the face detection context, the Wald-Boost algorithm can be also viewed as a theoretically justifiable \u201dboosted cascade of classifiers\u201d proposed by Viola and Jones [ 8 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The weak classifier set H used in training is the same as in [ 8 ] but WaldBoost is not feature-specific and any other weak classifiers can be used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2796017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca",
            "isKey": true,
            "numCitedBy": 11227,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second."
            },
            "slug": "Robust-Real-Time-Face-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new image representation called the \u201cIntegral Image\u201d is introduced which allows the features used by the detector to be computed very quickly and a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 23
                            }
                        ],
                        "text": "The AdaBoost algorithm [5, 1] 2 is a greedy learning algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6644398,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccf5208521cb8c35f50ee8873df89294b8ed7292",
            "isKey": false,
            "numCitedBy": 13123,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line."
            },
            "slug": "A-decision-theoretic-generalization-of-on-line-and-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "A decision-theoretic generalization of on-line learning and an application to boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The model studied can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting, and it is shown that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "It has been shown [5,  2 ] that the weak classifier minimizing (15) is"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As shown in [ 2 ], choosing a weak classifier according to (16) in each cycle of the AdaBoost learning converges asymptotically to"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9913392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f4493eff2531536a7aeb3fc11d62c30a8f487f6",
            "isKey": false,
            "numCitedBy": 4829,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Boosting is one of the most important recent developments in classification methodology. Boosting works by sequentially applying a classification algorithm to reweighted versions of the training data and then taking a weighted majority vote of the sequence of classifiers thus produced. For many classification algorithms, this simple strategy results in dramatic improvements in performance. We show that this seemingly mysterious phenomenon can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood. For the two-class problem, boosting can be viewed as an approximation to additive modeling on the logistic scale using maximum Bernoulli likelihood as a criterion. We develop more direct approximations and show that they exhibit nearly identical results to boosting. Direct multiclass generalizations based on multinomial likelihood are derived that exhibit performance comparable to other recently proposed multiclass generalizations of boosting in most situations, and far superior in some. We suggest a minor modification to boosting that can reduce computation, often by factors of 10 to 50. Finally, we apply these insights to produce an alternative formulation of boosting decision trees. This approach, based on best-first truncated tree induction, often leads to better performance, and can provide interpretable descriptions of the aggregate decision rule. It is also much faster computationally, making it more suitable to large-scale data mining applications."
            },
            "slug": "Special-Invited-Paper-Additive-logistic-regression:-Friedman",
            "title": {
                "fragments": [],
                "text": "Special Invited Paper-Additive logistic regression: A statistical view of boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work shows that this seemingly mysterious phenomenon of boosting can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood, and develops more direct approximations and shows that they exhibit nearly identical results to boosting."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761784"
                        ],
                        "name": "R. Tibshirani",
                        "slug": "R.-Tibshirani",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tibshirani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tibshirani"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "As shown in [2], choosing a weak classifier according to (16) in each cycle of the AdaBoost learning converges asymptotically to"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 18
                            }
                        ],
                        "text": "It has been shown [5, 2] that the weak classifier minimizing (15) is"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14723701,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc06ba65edba6f2783bda42da82d90589508e6ab",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Boosting (Freund & Schapire 1996, Schapire & Singer 1998) is one of the most important recent developments in classiication methodology. The performance of many classiication algorithms often can be dramatically improved by sequentially applying them to reweighted versions of the input data, and taking a weighted majority vote of the sequence of classiiers thereby produced. We show that this seemingly mysterious phenomenon can be understood in terms of well known statistical principles, namely additive modeling and maximum likelihood. For the two-class problem, boosting can be viewed as an approximation to additive modeling on the logistic scale using maximum Bernoulli likelihood as a criterion. We develop more direct approximations and show that they exhibit nearly identical results to that of boosting. Direct multi-class generalizations based on multinomial likelihood are derived that exhibit performance comparable to other recently proposed multi-class generalizations of boosting in most situations , and far superior in some. We suggest a minor modiication to boosting that can reduce computation, often by factors of 10 to 50. Finally, we apply these insights to produce an alternative formulation of boosting decision trees. This approach, based on best-rst truncated tree induction, often leads to better performance, and can provide interpretable descriptions of the aggregate decision rule. It is also much faster computationally making it more suitable to large scale data mining applications."
            },
            "slug": "Additive-Logistic-Regression-:-a-Statistical-View-Friedman-Hastie",
            "title": {
                "fragments": [],
                "text": "Additive Logistic Regression : a Statistical View ofBoostingJerome"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work develops more direct approximations of boosting that exhibit performance comparable to other recently proposed multi-class generalizations of boosting, and suggests a minor modiication to boosting that can reduce computation, often by factors of 10 to 50."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "The WaldBoost classifier was tested on the MIT+CMU dataset [4] consisting of 130 images containing 507 labeled faces."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "On the CMU dataset [4], the results are superior to the state-of-the-art in average evaluation time and comparabl e in detection rates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61175113,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ab9d1a4ac312267c4ef2f552471e138bacf68df",
            "isKey": false,
            "numCitedBy": 503,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The system (see Figure 2) uses a neural network, called a \u201crouter\u201d, to analyze each window of the input before it is processed by a \u201cdetector\u201d network. If the window contains a face, the router returns the angle of the face. The window can then be \u201cderotated\u201d to make the face upright. The derotated window is then passed to the detection network, which decides whether a face is present. If a non-face image is encountered, the router will return a meaningless rotation. Since a rotation of a non-face image will yield another nonface image, the detector network will still not detect a face. A rotated face, which would not have been detected by an upright face detector, will be rotated to an upright position, and subsequently detected as a face. Because the detector network is only applied once at each image location, this approach is significantly faster than exhaustively trying all orientations, and will yield fewer false detections [ 1,3]. To speed up the above algorithm for demonstration purposes, we used several techniques. First, we use a change detection algorithm to restrict the search area. Second, we use a model of skin color (acquired online as faces are detected) to further restrict the search. Finally, we use a candidate detection network to quickly rule out some portions of the input image, before examining them more carefully (and slowly) with the detection network. With these techniques, it takes about 6 seconds to process a 160x 120 pixel image on an SGI 02 workstation with a 174 MHz RIO000 processor."
            },
            "slug": "Rotation-Invariant-Neural-Network-Based-Face-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Rotation Invariant Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A neural network is used to analyze each window of the input before it is processed by a \u201cdetector\u201d network, which decides whether a face is present, which is significantly faster than exhaustively trying all orientations, and will yield fewer false detections."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17472092,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b043915a9601fc42ca49808d1d84e24720b0e16",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \u201cface\u201d and \u201cnon-face\u201d prototype clusters. A 2-Value metric is proposed for computing distance features between test patterns and the distribution-based face model during classification. We show empirically that the prototypes we choose for our distribution-based model, and the metric we adopt for computing distance feature vectors, are both critical for the success of our system."
            },
            "slug": "Learning-Human-Face-Detection-in-Cluttered-Scenes-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Learning Human Face Detection in Cluttered Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper presents an example-based learning approach for locating vertical frontal views of human faces in complex scenes by means of a few view-based \u201cface\u201d and \u201cnon- face\u201d prototype clusters, and shows empirically that the prototypes chosen are critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "CAIP"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115595183"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679380"
                        ],
                        "name": "H. Ai",
                        "slug": "H.-Ai",
                        "structuredName": {
                            "firstName": "Haizhou",
                            "lastName": "Ai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144528373"
                        ],
                        "name": "Chang Huang",
                        "slug": "Chang-Huang",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710195"
                        ],
                        "name": "S. Lao",
                        "slug": "S.-Lao",
                        "structuredName": {
                            "firstName": "Shihong",
                            "lastName": "Lao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "[7]), cascaded classifier [8], Float Boost [3], boosting chain [11] or nesting-structured cascade [10] implicitly minimize the time to decision while keeping the error rates at a low level."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "Method WB VJ[8] Li[3] Xiao[11] Wu[10] #wc 400 4297 2546 700 756 T\u0304S 10."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "The only method outperforming the proposed algorithm in the quality of detection is the \u201cnesting-structured cascade\u201d approach by Wu [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1436853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73d8fbafae3b09568ec63e8683b563d395f48308",
            "isKey": false,
            "numCitedBy": 396,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a rotation invariant multi-view face detection method based on Real Adaboost algorithm. Human faces are divided into several categories according to the variant appearance from different viewpoints. For each view category, weak classifiers are configured as confidence-rated look-up-table (LUT) of Haar feature. Real Adaboost algorithm is used to boost these weak classifiers and construct a nesting-structured face detector. To make it rotation invariant, we divide the whole 360-degree range into 12 sub-ranges and construct their corresponding view based detectors separately. To improve performance, a pose estimation method is introduced and results in a processing speed of four frames per second on 320/spl times/240 sized image. Experiments on faces with 360-degree in-plane rotation and /spl mnplus/90-degree out-of-plane rotation are reported, of which the frontal face detector subsystem retrieves 94.5% of the faces with 57 false alarms on the CMU+MlT frontal face test set and the multi-view face detector subsystem retrieves 89.8% of the faces with 221 false alarms on the CMU profile face test set."
            },
            "slug": "Fast-rotation-invariant-multi-view-face-detection-Wu-Ai",
            "title": {
                "fragments": [],
                "text": "Fast rotation invariant multi-view face detection based on real Adaboost"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A rotation invariant multi-view face detection method based on Real Adaboost algorithm is proposed and a pose estimation method is introduced and results in a processing speed of four frames per second on 320/spl times/240 sized image."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth IEEE International Conference on Automatic Face and Gesture Recognition, 2004. Proceedings."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "On the CMU dataset [4], the results are superior to the state-of-the-art in average evaluation time and comparable in detection rates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The WaldBoost classifier was tested on the MIT+CMU dataset [4] consisting of 130 images containing 507 labeled faces."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d76ef8e61395a6e9c32627f1f108772d084e2e9",
            "isKey": false,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069928477"
                        ],
                        "name": "Rong Xiao",
                        "slug": "Rong-Xiao",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144850567"
                        ],
                        "name": "Long Zhu",
                        "slug": "Long-Zhu",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 175
                            }
                        ],
                        "text": "A direct comparison with the methods reported in literature is difficult since they use different subsets of t his dataset with the most difficult faces removed (about 5 % in [3, 11]!)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "[7]), cascaded classifier [8], Float Boost [3], boosting chain [11] or nesting-structured cascade [10] implicitly minimize the time to decision while keeping the error rates at a low level."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "The parenthese s around T\u0304S of Li\u2019s method indicate that this result was not reported by t he authors but in [11]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Viola\u2212Jones [9] Boosting chain [12] FloatBoost [3] Wu [11] WaldBoost"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "Method WB VJ[8] Li[3] Xiao[11] Wu[10] #wc 400 4297 2546 700 756 T\u0304S 10."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5093465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76b9c2e83cd61029e36f1397286ac687d26957a6",
            "isKey": true,
            "numCitedBy": 188,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A general classification framework, called boosting chain, is proposed for learning boosting cascade. In this framework, a \"chain\" structure is introduced to integrate historical knowledge into successive boosting learning. Moreover, a linear optimization scheme is proposed to address the problems of redundancy in boosting learning and threshold adjusting in cascade coupling. By this means, the resulting classifier consists of fewer weak classifiers yet achieves lower error rates than boosting cascade in both training and test. Experimental comparisons of boosting chain and boosting cascade are provided through a face detection problem. The promising results clearly demonstrate the effectiveness made by boosting chain."
            },
            "slug": "Boosting-chain-learning-for-object-detection-Xiao-Zhu",
            "title": {
                "fragments": [],
                "text": "Boosting chain learning for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A linear optimization scheme is proposed to address the problems of redundancy in boosting learning and threshold adjusting in cascade coupling, and the resulting classifier consists of fewer weak classifiers yet achieves lower error rates than boosting cascade in both training and test."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769685"
                        ],
                        "name": "K. Toyama",
                        "slug": "K.-Toyama",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Toyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Toyama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7]), cascaded classifier [8], Float Boost [3], boosting chain [11] or nesting-structured cascade [10] implicitly minimize the time to decision while keeping the error rates at a low level."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14601747,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "181bc0c6c20a22f3a0f1a4b96d80fe994e7f5719",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The Incremental Focus of Attention (IFA) framework provides a structure in which diierent algorithms for visual motion tracking can be assembled into a single system which tracks an object with the best combination of precision, speed, and robustness. IFA puts diierent tracking algorithms in a hierarchy based on speed and precision and supplies a means for determining which algorithm should perform in diierent circumstances. Precision is traded for robustness and speed when ideal environmental conditions are not met, and conversely, when conditions are favorable, tracking proceeds at the greatest precision ooered by the component trackers. Implementations of IFA systems provide robust visual tracking which returns as much tracking information as possible given the constraints of the environment."
            },
            "slug": "Handling-Tradeoos-between-Precision-and-Robustness-Toyama",
            "title": {
                "fragments": [],
                "text": "Handling Tradeoos between Precision and Robustness with Incremental Focus of Attention for Visual Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Implementations of IFA systems provide robust visual tracking which returns as much tracking information as possible given the constraints of the environment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118570"
                        ],
                        "name": "R. Glendinning",
                        "slug": "R.-Glendinning",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Glendinning",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Glendinning"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 145
                            }
                        ],
                        "text": "Moreover, the estimation uses the Parzen windows technique with the kernel width set according to the oversmoothing rule for the Gaussian kernel [6]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 108295844,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "aae7c875fc7531233c2a3ebefa31a33f1a0d7f49",
            "isKey": false,
            "numCitedBy": 4388,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Representation and Geometry of Multivariate Data. Nonparametric Estimation Criteria. Histograms: Theory and Practice. Frequency Polygons. Averaged Shifted Histograms. Kernel Density Estimators. The Curse of Dimensionality and Dimension Reduction. Nonparametric Regression and Additive Models. Special Topics. Appendices. Indexes."
            },
            "slug": "Multivariate-Density-Estimation,-Theory,-Practice-Glendinning",
            "title": {
                "fragments": [],
                "text": "Multivariate Density Estimation, Theory, Practice and Visualization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145549030"
                        ],
                        "name": "J. Andel",
                        "slug": "J.-Andel",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Andel",
                            "middleNames": [
                                "A.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Andel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "The sequential decision-making theory was developed by Wald [9], who proved that the solution of the optimization problem (3) is thesequential probability ratio test ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "Wald [9] studies the effect of truncation of the sequen tial test procedure, however, his derivations hold only for cases where i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "We refer the interested reader to [9]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "Viola\u2212Jones [9] Boosting chain [12] FloatBoost [3] Wu [11] WaldBoost"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 240615,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "18bfe4cd9232f58474eaf91906b46c09f27471a1",
            "isKey": true,
            "numCitedBy": 2282,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "[Sequential-analysis].-Andel",
            "title": {
                "fragments": [],
                "text": "[Sequential analysis]."
            },
            "venue": {
                "fragments": [],
                "text": "Ceskoslovenska fysiologie"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2218687"
                        ],
                        "name": "P. Rousseeuw",
                        "slug": "P.-Rousseeuw",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Rousseeuw",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Rousseeuw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152878142"
                        ],
                        "name": "A. Leroy",
                        "slug": "A.-Leroy",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Leroy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leroy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118443924,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0b2dc0e7234350399850d501943cb8fcac52a026",
            "isKey": false,
            "numCitedBy": 1870,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Wiley-Series-in-Probability-and-Mathematical-Rousseeuw-Leroy",
            "title": {
                "fragments": [],
                "text": "Wiley Series in Probability and Mathematical Statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46345617"
                        ],
                        "name": "D. W. Scott",
                        "slug": "D.-W.-Scott",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Scott",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. W. Scott"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118005924,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "0204e53a26cec30e656d3dfcac0a5222fd14e557",
            "isKey": false,
            "numCitedBy": 2104,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multivariate-Density-Estimation:-Theory,-Practice,-Scott",
            "title": {
                "fragments": [],
                "text": "Multivariate Density Estimation: Theory, Practice, and Visualization"
            },
            "venue": {
                "fragments": [],
                "text": "Wiley Series in Probability and Statistics"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 18
                            }
                        ],
                        "text": "It has been shown [5, 2] that the weak classifier minimizing (15) is"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 23
                            }
                        ],
                        "text": "The AdaBoost algorithm [5, 1] 2 is a greedy learning algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12646365,
            "fieldsOfStudy": [],
            "id": "14e53403a0055dbe5faaf9f1f3be96ca0e692a4d",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improved Boosting Algorithms using Confidence-Rated Predictions"
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[8]), cascaded classifier [9], FloatBoost [3], boosting chain [12] or nesting-structured cascade [11] implicitly minimize the time to decision while keeping the error rates at a low level."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handling tradeoffs between precision and robustness with incremental focus of attention for vi-  sual tracking"
            },
            "venue": {
                "fragments": [],
                "text": "In Working Notes AAAI Smp. on Flexible Computatio in Intelligent Systems,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handling tradeoffs between precision and robustness with incremental focus of attention for visual track"
            },
            "venue": {
                "fragments": [],
                "text": "Multivariate Density Estimation : Theory , Practice , and Visualization . Wiley Series in Probability and Mathematical Statistics"
            },
            "year": 1992
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 19,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/WaldBoost-learning-for-time-constrained-sequential-Sochman-Matas/1ed6fe696a3afc0154c45fecbef4c14e13b01a8a?sort=total-citations"
}