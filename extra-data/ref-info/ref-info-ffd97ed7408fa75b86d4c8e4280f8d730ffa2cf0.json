{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1948055"
                        ],
                        "name": "Frank Steinbr\u00fccker",
                        "slug": "Frank-Steinbr\u00fccker",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Steinbr\u00fccker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Steinbr\u00fccker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730097"
                        ],
                        "name": "T. Pock",
                        "slug": "T.-Pock",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Pock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7272776,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2922175701e0c03af4f4435e42929d2a3271ab0a",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an algorithm for large displacement optical flow estimation which does not require the commonly used coarse-to-fine warping strategy. It is based on a quadratic relaxation of the optical flow functional which decouples data term and regularizer in such a way that the non-linearized variational problem can be solved by an alternation of two globally optimal steps, one imposing optimal data consistency, the other imposing discontinuity-preserving regularity of the flow field. Experimental results confirm that the proposed algorithmic implementation outperforms the traditional warping strategy, in particular for the case of large displacements of small scale structures."
            },
            "slug": "Large-displacement-optical-flow-computation-Steinbr\u00fccker-Pock",
            "title": {
                "fragments": [],
                "text": "Large displacement optical flow computation withoutwarping"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Experimental results confirm that the proposed algorithmic implementation outperforms the traditional warping strategy, in particular for the case of large displacements of small scale structures."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49843309"
                        ],
                        "name": "\u00c9. M\u00e9min",
                        "slug": "\u00c9.-M\u00e9min",
                        "structuredName": {
                            "firstName": "\u00c9tienne",
                            "lastName": "M\u00e9min",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. M\u00e9min"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144565371"
                        ],
                        "name": "P. P\u00e9rez",
                        "slug": "P.-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P\u00e9rez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 524667,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd824a3406cd176edef37888d0e5c74c0774b0c3",
            "isKey": false,
            "numCitedBy": 339,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the issue of recovering and segmenting the apparent velocity field in sequences of images. As for motion estimation, we minimize an objective function involving two robust terms. The first one cautiously captures the optical flow constraint, while the second (a priori) term incorporates a discontinuity-preserving smoothness constraint. To cope with the nonconvex minimization problem thus defined, we design an efficient deterministic multigrid procedure. It converges fast toward estimates of good quality, while revealing the large discontinuity structures of flow fields. We then propose an extension of the model by attaching to it a flexible object-based segmentation device based on deformable closed curves (different families of curve equipped with different kinds of prior can be easily supported). Experimental results on synthetic and natural sequences are presented, including an analysis of sensitivity to parameter tuning."
            },
            "slug": "Dense-estimation-and-object-based-segmentation-of-M\u00e9min-P\u00e9rez",
            "title": {
                "fragments": [],
                "text": "Dense estimation and object-based segmentation of the optical flow with robust techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This paper addresses the issue of recovering and segmenting the apparent velocity field in sequences of images by designing an efficient deterministic multigrid procedure and proposing an extension of the model by attaching to it a flexible object-based segmentation device based on deformable closed curves."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144031005"
                        ],
                        "name": "Andr\u00e9s Bruhn",
                        "slug": "Andr\u00e9s-Bruhn",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Bruhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Bruhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2188270"
                        ],
                        "name": "N. Papenberg",
                        "slug": "N.-Papenberg",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Papenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Papenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "While SIFT flow considers all possible matches at each pixel when introducing the regularity constraint, our scheme only considers the best matches and checks their consistency with the regularity constraint and the other image features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "Articulated motion in general and human motion in particular are problematic."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 211
                            }
                        ],
                        "text": "While warping schemes work well in all cases where the small structures move more or less the same way as larger scale structures, the approach is doomed to fail as soon as the relative motion of a small-scale structure is larger than its own scale, as shown in Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 76390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91228e00fe33ed6072cfe849ab9e98160461549d",
            "isKey": false,
            "numCitedBy": 2733,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We study an energy functional for computing optical flow that combines three assumptions: a brightness constancy assumption, a gradient constancy assumption, and a discontinuity-preserving spatio-temporal smoothness constraint. In order to allow for large displacements, linearisations in the two data terms are strictly avoided. We present a consistent numerical scheme based on two nested fixed point iterations. By proving that this scheme implements a coarse-to-fine warping strategy, we give a theoretical foundation for warping which has been used on a mainly experimental basis so far. Our evaluation demonstrates that the novel method gives significantly smaller angular errors than previous techniques for optical flow estimation. We show that it is fairly insensitive to parameter variations, and we demonstrate its excellent robustness under noise."
            },
            "slug": "High-Accuracy-Optical-Flow-Estimation-Based-on-a-Brox-Bruhn",
            "title": {
                "fragments": [],
                "text": "High Accuracy Optical Flow Estimation Based on a Theory for Warping"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "By proving that this scheme implements a coarse-to-fine warping strategy, this work gives a theoretical foundation for warping which has been used on a mainly experimental basis so far and demonstrates its excellent robustness under noise."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 84
                            }
                        ],
                        "text": "First, as we focus more on classic motion analysis rather than scene matching, our model does not fully rely on histogram-based features such as SIFT."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14070356,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "eee90c038f43370a29b07e46f38dfe6527143a2c",
            "isKey": false,
            "numCitedBy": 1786,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "Most approaches for estimating optical flow assume that, within a finite image region, only a single motion is present. Thissingle motion assumptionis violated in common situations involving transparency, depth discontinuities, independently moving objects, shadows, and specular reflections. To robustly estimate optical flow, the single motion assumption must be relaxed. This paper presents a framework based onrobust estimationthat addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions. We show how therobust estimation frameworkcan be applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions. The approach has been applied to three standard techniques for recovering optical flow: area-based regression, correlation, and regularization with motion discontinuities. This paper focuses on the recovery of multiple parametric motion models within a region, as well as the recovery of piecewise-smooth flow fields, and provides examples with natural and synthetic image sequences."
            },
            "slug": "The-Robust-Estimation-of-Multiple-Motions:-and-Flow-Black-Anandan",
            "title": {
                "fragments": [],
                "text": "The Robust Estimation of Multiple Motions: Parametric and Piecewise-Smooth Flow Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A framework based on robust estimation is presented that addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions of optical flow, and is applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "This renders matching without limitations on the magnitude of the displacement extremely simple and efficient, and explains the enormous success of descriptive features in structure from motion, image search, and object detection."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3243550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa9f82781a0d844faec8616ffbe68113536fefea",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The literature currently provides two ways to establish point correspondences between images with moving objects. On one side, there are energy minimization methods that yield very accurate, dense flow fields, but fail as displacements get too large. On the other side, there is descriptor matching that allows for large displacements, but correspondences are very sparse, have limited accuracy, and due to missing regularity constraints there are many outliers. In this paper we propose a method that can combine the advantages of both matching strategies. A region hierarchy is established for both images. Descriptor matching on these regions provides a sparse set of hypotheses for correspondences. These are integrated into a variational approach and guide the local optimization to large displacement solutions. The variational optimization selects among the hypotheses and provides dense and subpixel accurate estimates, making use of geometric constraints and all available image information."
            },
            "slug": "Large-displacement-optical-flow-Brox-Bregler",
            "title": {
                "fragments": [],
                "text": "Large displacement optical flow"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a method that can combine the advantages of both matching strategies and provides dense and subpixel accurate estimates, making use of geometric constraints and all available image information."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518778"
                        ],
                        "name": "A. Wedel",
                        "slug": "A.-Wedel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Wedel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wedel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730097"
                        ],
                        "name": "T. Pock",
                        "slug": "T.-Pock",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Pock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713941"
                        ],
                        "name": "C. Zach",
                        "slug": "C.-Zach",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Zach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Zach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "Additionally, we need to perform a nearest neighbor search only for a subsampled set of pixels since precise localization is provided by the pixel color and gradient in the variational setting."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17563777,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f671859d83f6c19e0af5f5ccfe8aad3681ccc1b",
            "isKey": false,
            "numCitedBy": 434,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A look at the Middlebury optical flow benchmark [5] reveals that nowadays variational methods yield the most accurate optical flow fields between two image frames. In this work we propose an improvement variant of the original duality based TV-L 1 optical flow algorithm in [31] and provide implementation details. This formulation can preserve discontinuities in the flow field by employing total variation (TV) regularization. Furthermore, it offers robustness against outliers by applying the robust L 1 norm in the data fidelity term. \n \nOur contributions are as follows. First, we propose to perform a structure-texture decomposition of the input images to get rid of violations in the optical flow constraint due to illumination changes. Second, we propose to integrate a median filter into the numerical scheme to further increase the robustness to sampling artefacts in the image data. We experimentally show that very precise and robust estimation of optical flow can be achieved with a variational approach in real-time. The numerical scheme and the implementation are described in a detailed way, which enables reimplementation of this high-end method."
            },
            "slug": "An-Improved-Algorithm-for-TV-L-1-Optical-Flow-Wedel-Pock",
            "title": {
                "fragments": [],
                "text": "An Improved Algorithm for TV-L 1 Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes an improvement variant of the original duality based TV-L 1 optical flow algorithm that can preserve discontinuities in the flow field by employing total variation (TV) regularization and integrates a median filter into the numerical scheme to further increase the robustness to sampling artefacts in the image data."
            },
            "venue": {
                "fragments": [],
                "text": "Statistical and Geometrical Approaches to Visual Motion Analysis"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39010010"
                        ],
                        "name": "Josh Wills",
                        "slug": "Josh-Wills",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "Wills",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josh Wills"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8013868,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "a7bc827fe616f933a2656b29baead1f4233f519c",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Planar motion models can provide gross motion estimation and good segmentation for image pairs with large inter-frame disparity. However, as the disparity becomes larger, the resulting dense correspondences will become increasingly inaccurate for everything but purely planar objects. Flexible motion models, on the other hand, tend to overfit and thus make partitioning difficult. For this reason, to achieve dense optical flow for image sequences with large inter-frame disparity, we propose a two stage process in which a planar model is used to get an approximation for the segmentation and the gross motion, and then a spline is used to refine the fit. We present experimental results for dense optical flow estimation on image pairs with large inter-frame disparity that are beyond the scope of existing approaches."
            },
            "slug": "A-Feature-Based-Approach-for-Determining-Dense-Long-Wills-Belongie",
            "title": {
                "fragments": [],
                "text": "A Feature-Based Approach for Determining Dense Long Range Correspondences"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "To achieve dense optical flow for image sequences with large inter-frame disparity, this work proposes a two stage process in which a planar model is used to get an approximation for the segmentation and the gross motion, and then a spline is used for the fit."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "First, as we focus more on classic motion analysis rather than scene matching, our model does not fully rely on histogram-based features such as SIFT."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15551602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5b4091691a32076c78a0f354994977230f95c23",
            "isKey": false,
            "numCitedBy": 287,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel approach to incrementally estimating visual motion over a sequence of images is presented. The authors start by formulating constraints on image motion to account for the possibility of multiple motions. This is achieved by exploiting the notions of weak continuity and robust statistics in the formulation of a minimization problem. The resulting objective function is non-convex. Traditional stochastic relaxation techniques for minimizing such functions prove inappropriate for the task. A highly parallel incremental stochastic minimization algorithm is presented which has a number of advantages over previous approaches. The incremental nature of the scheme makes it dynamic and permits the detection of occlusion and disocclusion boundaries.<<ETX>>"
            },
            "slug": "Robust-dynamic-motion-estimation-over-time-Black-Anandan",
            "title": {
                "fragments": [],
                "text": "Robust dynamic motion estimation over time"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A highly parallel incremental stochastic minimization algorithm is presented which has a number of advantages over previous approaches and the incremental nature of the scheme makes it dynamic and permits the detection of occlusion and disocclusion boundaries."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713941"
                        ],
                        "name": "C. Zach",
                        "slug": "C.-Zach",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Zach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Zach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730097"
                        ],
                        "name": "T. Pock",
                        "slug": "T.-Pock",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Pock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15250191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c",
            "isKey": false,
            "numCitedBy": 1505,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Variational methods are among the most successful approaches to calculate the optical flow between two image frames. A particularly appealing formulation is based on total variation (TV) regularization and the robust L1 norm in the data fidelity term. This formulation can preserve discontinuities in the flow field and offers an increased robustness against illumination changes, occlusions and noise. In this work we present a novel approach to solve the TV-L1 formulation. Our method results in a very efficient numerical scheme, which is based on a dual formulation of the TV energy and employs an efficient point-wise thresholding step. Additionally, our approach can be accelerated by modern graphics processing units. We demonstrate the real-time performance (30 fps) of our approach for video inputs at a resolution of 320 \u00d7 240 pixels."
            },
            "slug": "A-Duality-Based-Approach-for-Realtime-TV-L1-Optical-Zach-Pock",
            "title": {
                "fragments": [],
                "text": "A Duality Based Approach for Realtime TV-L1 Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a novel approach to solve the TV-L1 formulation, which is based on a dual formulation of the TV energy and employs an efficient point-wise thresholding step."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145865631"
                        ],
                        "name": "L. \u00c1lvarez",
                        "slug": "L.-\u00c1lvarez",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "\u00c1lvarez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. \u00c1lvarez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143757530"
                        ],
                        "name": "Javier S\u00e1nchez P\u00e9rez",
                        "slug": "Javier-S\u00e1nchez-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Javier",
                            "lastName": "P\u00e9rez",
                            "middleNames": [
                                "S\u00e1nchez"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Javier S\u00e1nchez P\u00e9rez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18560227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e06ea3d5c3047aa41eebd2b6e2d265c4b87e057",
            "isKey": false,
            "numCitedBy": 351,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we show that a classic optical flow technique by Nagel and Enkelmann (1986, IEEE Trans. Pattern Anal. Mach. Intell., Vol. 8, pp. 565\u2013593) can be regarded as an early anisotropic diffusion method with a diffusion tensor. We introduce three improvements into the model formulation that (i) avoid inconsistencies caused by centering the brightness term and the smoothness term in different images, (ii) use a linear scale-space focusing strategy from coarse to fine scales for avoiding convergence to physically irrelevant local minima, and (iii) create an energy functional that is invariant under linear brightness changes. Applying a gradient descent method to the resulting energy functional leads to a system of diffusion\u2013reaction equations. We prove that this system has a unique solution under realistic assumptions on the initial data, and we present an efficient linear implicit numerical scheme in detail. Our method creates flow fields with 100 % density over the entire image domain, it is robust under a large range of parameter variations, and it can recover displacement fields that are far beyond the typical one-pixel limits which are characteristic for many differential methods for determining optical flow. We show that it performs better than the optical flow methods with 100 % density that are evaluated by Barron et al. (1994, Int. J. Comput. Vision, Vol. 12, pp. 43\u201347). Our software is available from the Internet."
            },
            "slug": "Reliable-Estimation-of-Dense-Optical-Flow-Fields-\u00c1lvarez-Weickert",
            "title": {
                "fragments": [],
                "text": "Reliable Estimation of Dense Optical Flow Fields with Large Displacements"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper shows that a classic optical flow technique by Nagel and Enkelmann can be regarded as an early anisotropic diffusion method with a diffusion tensor, and introduces three improvements into the model formulation that avoid inconsistencies caused by centering the brightness term and the smoothness term in different images."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144031005"
                        ],
                        "name": "Andr\u00e9s Bruhn",
                        "slug": "Andr\u00e9s-Bruhn",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Bruhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Bruhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1427844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1da22684dd1ff5f577b1acf7a5f6f481ab3c43f8",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Although variational methods are among the most accurate techniques for estimating the optical flow, they have not yet entered the field of real-time vision. Main reason is the great popularity of standard numerical schemes that are easy to implement, however, at the expense of being too slow for real-time performance. In our paper we address this problem in two ways: (i) we present an improved version of the highly accurate technique of Brox et al. (2004). Thereby we show that a separate robustification of the constancy assumptions is very useful, in particular if the I-norm is used as penalizer. As a result, a method is obtained that yields the lowest angular errors in the literature, (ii) We develop an efficient numerical scheme for the proposed approach that allows real-time performance for sequences of size 160 /spl times/ 720. To this end, we combine two hierarchical strategies: a coarse-to-fine warping strategy as implementation of a fixed point iteration for a non-convex optimisation problem and a nonlinear full multigrid method - a so called full approximation scheme (FAS) - for solving the highly nonlinear equation systems at each warping level. In the experimental section the advantage of the proposed approach becomes obvious: Outperforming standard numerical schemes by two orders of magnitude frame rates of six high quality flow fields per second are obtained on a 3.06 GHz Pentium4 PC."
            },
            "slug": "Towards-ultimate-motion-estimation:-combining-with-Bruhn-Weickert",
            "title": {
                "fragments": [],
                "text": "Towards ultimate motion estimation: combining highest accuracy with real-time performance"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An improved version of the highly accurate technique of Brox et al. (2004) is presented and it is shown that a separate robustification of the constancy assumptions is very useful, in particular if the I-norm is used as penalizer and a method is obtained that yields the lowest angular errors in the literature."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98661254"
                        ],
                        "name": "C. Lei",
                        "slug": "C.-Lei",
                        "structuredName": {
                            "firstName": "Cheng",
                            "lastName": "Lei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35964920"
                        ],
                        "name": "Yee-Hong Yang",
                        "slug": "Yee-Hong-Yang",
                        "structuredName": {
                            "firstName": "Yee-Hong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Hong Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 286,
                                "start": 282
                            }
                        ],
                        "text": "\u2026Published by the IEEE Computer Society\nThe basic idea is to support the continuation method, which is responsible for estimating large displacements in classic warping methods, by another technique that is well known for its ability to estimate arbitrarily large displacements: descriptor matching."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6978040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f17ef1fbce97d082b480e160d837a17ff9f5cc41",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a new region-based method for accurate motion estimation using discrete optimization. In particular, the input image is represented as a tree of over-segmented regions and the optical flow is estimated by optimizing an energy function defined on such a region-tree using dynamic programming. To accommodate the sampling-inefficiency problem intrinsic to discrete optimization compared to the continuous optimization based methods, both spatial and solution domain coarse-to-fine (C2F) strategies are used. That is, multiple region-trees are built using different over-segmentation granularities. Starting from a global displacement label discretization, optical flow estimation on the coarser level region-tree is used for defining region-wise finer displacement samplings for finer level region-trees. Furthermore, cross-checking based occlusion detection and correction and continuous optimization are also used to improve accuracy. Extensive experiments using the Middlebury benchmark datasets have shown that our proposed method can produce top-ranking results."
            },
            "slug": "Optical-flow-estimation-on-coarse-to-fine-using-Lei-Yang",
            "title": {
                "fragments": [],
                "text": "Optical flow estimation on coarse-to-fine region-trees using discrete optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new region-based method for accurate motion estimation using discrete optimization of over-segmented regions and the optical flow is estimated by optimizing an energy function defined on a region-tree using dynamic programming."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143814637"
                        ],
                        "name": "Berthold K. P. Horn",
                        "slug": "Berthold-K.-P.-Horn",
                        "structuredName": {
                            "firstName": "Berthold",
                            "lastName": "Horn",
                            "middleNames": [
                                "K.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berthold K. P. Horn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717435"
                        ],
                        "name": "B. G. Schunck",
                        "slug": "B.-G.-Schunck",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Schunck",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. G. Schunck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1371968,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a3229dc33ecb80c59a75b906c46b586dd059b781",
            "isKey": false,
            "numCitedBy": 11343,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical flow cannot be computed locally, since only one independent measurement is available from the image sequence at a point, while the flow velocity has two components. A second constraint is needed. A method for finding the optical flow pattern is presented which assumes that the apparent velocity of the brightness pattern varies smoothly almost everywhere in the image. An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences. The algorithm is robust in that it can handle image sequences that are quantized rather coarsely in space and time. It is also insensitive to quantization of brightness levels and additive noise. Examples are included where the assumption of smoothness is violated at singular points or along lines in the image."
            },
            "slug": "Determining-Optical-Flow-Horn-Schunck",
            "title": {
                "fragments": [],
                "text": "Determining Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences and is robust in that it can handle image sequences that are quantified rather coarsely in space and time."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144422657"
                        ],
                        "name": "I. Cohen",
                        "slug": "I.-Cohen",
                        "structuredName": {
                            "firstName": "Isaac",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16315199,
            "fieldsOfStudy": [
                "Mathematics",
                "Physics"
            ],
            "id": "b559ff9a3863a80a5c08c8c8cbfc23ecb2cb606f",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for optical flow computation based on the minimization of a non-quadratic functional. The solution of the obtained nonlinear differential equations is done with a time dependent approach leading to the successive solutions of linear systems. This new method allows to compute optical flow fields while insuring a unique solution and preserving the flow discontinuities. This method seems to be more appropriate since it does not enforce the optical flow to be smooth in the boundaries of moving objects and reconstruct the optical flow discontinuities without any specific processing of these points. We have applied the model on synthetical and real image sequences which illustrate the properties of this approach. Finally we give an interesting application which merges optical flow field and snake models for boundaries tracking."
            },
            "slug": "Nonlinear-Variational-Method-for-Optical-Flow-Cohen",
            "title": {
                "fragments": [],
                "text": "Nonlinear Variational Method for Optical Flow Computation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145920814"
                        ],
                        "name": "S. Roth",
                        "slug": "S.-Roth",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740145"
                        ],
                        "name": "V. Lempitsky",
                        "slug": "V.-Lempitsky",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lempitsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lempitsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 276
                            }
                        ],
                        "text": "\u2026Published by the IEEE Computer Society\nThe basic idea is to support the continuation method, which is responsible for estimating large displacements in classic warping methods, by another technique that is well known for its ability to estimate arbitrarily large displacements: descriptor matching."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52852218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bedb724d72acae17869895cb441d7d943661ce23",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The accurate estimation of optical flow is a challenging task, which is often posed as an energy minimization problem. Most top-performing methods approach this using continuous optimization algorithms. In many cases, the employed models are assumed to be convex to ensure tractability of the optimization problem. This is in contrast to the related problem of narrow-baseline stereo matching, where the top-performing methods employ powerful discrete optimization algorithms such as graph cuts and message-passing to optimize highly non-convex energies. \n \nIn this chapter, we demonstrate how similar non-convex energies can be formulated and optimized in the context of optical flow estimation using a combination of discrete and continuous techniques. Starting with a set of candidate solutions that are produced by either fast continuous flow estimation algorithms or sparse feature matching, the proposed method iteratively fuses these candidate solutions by the computation of minimum cuts on graphs. The obtained continuous-valued result is then further improved using local gradient descent. Experimentally, we demonstrate that the proposed energy is an accurate model and that the proposed discrete-continuous optimization scheme not only finds lower energy solutions than traditional discrete or continuous optimization techniques, but also leads to very accurate flow estimates."
            },
            "slug": "Discrete-Continuous-Optimization-for-Optical-Flow-Roth-Lempitsky",
            "title": {
                "fragments": [],
                "text": "Discrete-Continuous Optimization for Optical Flow Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This chapter demonstrates how similar non-convex energies can be formulated and optimized in the context of optical flow estimation using a combination of discrete and continuous techniques and finds lower energy solutions than traditional discrete or continuous optimization techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Statistical and Geometrical Approaches to Visual Motion Analysis"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3026603"
                        ],
                        "name": "Yana Momchilova Mileva",
                        "slug": "Yana-Momchilova-Mileva",
                        "structuredName": {
                            "firstName": "Yana",
                            "lastName": "Mileva",
                            "middleNames": [
                                "Momchilova"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yana Momchilova Mileva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144031005"
                        ],
                        "name": "Andr\u00e9s Bruhn",
                        "slug": "Andr\u00e9s-Bruhn",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Bruhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Bruhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1227268,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1c5ae1289cd81b341430b67e976b9a5711e4c8c",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Since years variational methods belong to the most accurate techniques for computing the optical flow in image sequences. However, if based on the grey value constancy assumption only, such techniques are not robust enough to cope with typical illumination changes in real-world data. In our paper we tackle this problem in two ways: First we discuss different photometric invariants for the design of illumination-robust variational optical flow methods. These invariants are based on colour information and include such concepts as spherical/ conical transforms, normalisation strategies and the differentiation of logarithms. Secondly, we embed them into a suitable multichannel generalisation of the highly accurate variational optical flow technique of Brox et al. This in turn allows us to access the true potential of such invariants for estimating the optical flow. Experiments with synthetic and real-world data demonstrate the success of combining accuracy and robustness: Even under strongly varying illumination, reliable and precise results are obtained."
            },
            "slug": "Illumination-Robust-Variational-Optical-Flow-with-Mileva-Bruhn",
            "title": {
                "fragments": [],
                "text": "Illumination-Robust Variational Optical Flow with Photometric Invariants"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Different photometric invariants for the design of illumination-robust variational optical flow methods are discussed, based on colour information and include such concepts as spherical/ conical transforms, normalisation strategies and the differentiation of logarithms."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709053"
                        ],
                        "name": "Daniel Scharstein",
                        "slug": "Daniel-Scharstein",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Scharstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Scharstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153024876"
                        ],
                        "name": "J. P. Lewis",
                        "slug": "J.-P.-Lewis",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Lewis",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. P. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145920814"
                        ],
                        "name": "S. Roth",
                        "slug": "S.-Roth",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 316800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "804836b8ad86ef8042e3dcbd45442a52f031ee03",
            "isKey": false,
            "numCitedBy": 2377,
            "numCiting": 107,
            "paperAbstract": {
                "fragments": [],
                "text": "The quantitative evaluation of optical flow algorithms by Barron et al. (1994) led to significant advances in performance. The challenges for optical flow algorithms today go beyond the datasets and evaluation methods proposed in that paper. Instead, they center on problems associated with complex natural scenes, including nonrigid motion, real sensor noise, and motion discontinuities. We propose a new set of benchmarks and evaluation methods for the next generation of optical flow algorithms. To that end, we contribute four types of data to test different aspects of optical flow algorithms: (1)\u00a0sequences with nonrigid motion where the ground-truth flow is determined by tracking hidden fluorescent texture, (2)\u00a0realistic synthetic sequences, (3)\u00a0high frame-rate video used to study interpolation error, and (4)\u00a0modified stereo sequences of static scenes. In addition to the average angular error used by Barron et\u00a0al., we compute the absolute flow endpoint error, measures for frame interpolation error, improved statistics, and results at motion discontinuities and in textureless regions. In October 2007, we published the performance of several well-known methods on a preliminary version of our data to establish the current state of the art. We also made the data freely available on the web at http://vision.middlebury.edu/flow/. Subsequently a number of researchers have uploaded their results to our website and published papers using the data. A significant improvement in performance has already been achieved. In this paper we analyze the results obtained to date and draw a large number of conclusions from them."
            },
            "slug": "A-Database-and-Evaluation-Methodology-for-Optical-Baker-Scharstein",
            "title": {
                "fragments": [],
                "text": "A Database and Evaluation Methodology for Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a new set of benchmarks and evaluation methods for the next generation of optical flow algorithms and analyzes the results obtained to date to draw a large number of conclusions."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740145"
                        ],
                        "name": "V. Lempitsky",
                        "slug": "V.-Lempitsky",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lempitsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lempitsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145920814"
                        ],
                        "name": "S. Roth",
                        "slug": "S.-Roth",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6857929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43de2e3389e6a75e4beb0b575a90c07f796ee9d2",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Accurate estimation of optical flow is a challenging task, which often requires addressing difficult energy optimization problems. To solve them, most top-performing methods rely on continuous optimization algorithms. The modeling accuracy of the energy in this case is often traded for its tractability. This is in contrast to the related problem of narrow-baseline stereo matching, where the top-performing methods employ powerful discrete optimization algorithms such as graph cuts and message-passing to optimize highly non-convex energies. In this paper, we demonstrate how similar non-convex energies can be formulated and optimized discretely in the context of optical flow estimation. Starting with a set of candidate solutions that are produced by fast continuous flow estimation algorithms, the proposed method iteratively fuses these candidate solutions by the computation of minimum cuts on graphs. The obtained continuous-valued fusion result is then further improved using local gradient descent. Experimentally, we demonstrate that the proposed energy is an accurate model and that the proposed discrete-continuous optimization scheme not only finds lower energy solutions than traditional discrete or continuous optimization techniques, but also leads to flow estimates that outperform the current state-of-the-art."
            },
            "slug": "FusionFlow:-Discrete-continuous-optimization-for-Lempitsky-Roth",
            "title": {
                "fragments": [],
                "text": "FusionFlow: Discrete-continuous optimization for optical flow estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is demonstrated how similar non-convex energies can be formulated and optimized discretely in the context of optical flow estimation and that the proposed discrete-continuous optimization scheme not only finds lower energy solutions than traditional discrete or continuous optimization techniques, but also leads to flow estimates that outperform the current state-of-the-art."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3232265"
                        ],
                        "name": "Deqing Sun",
                        "slug": "Deqing-Sun",
                        "structuredName": {
                            "firstName": "Deqing",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deqing Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145920814"
                        ],
                        "name": "S. Roth",
                        "slug": "S.-Roth",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153024876"
                        ],
                        "name": "J. P. Lewis",
                        "slug": "J.-P.-Lewis",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Lewis",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. P. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 969406,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad61eebde119131f845dc902e1c8f7a4c6d66233",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Assumptions of brightness constancy and spatial smoothness underlie most optical flow estimation methods. In contrast to standard heuristic formulations, we learn a statistical model of both brightness constancy error and the spatial properties of optical flow using image sequences with associated ground truth flow fields. The result is a complete probabilistic model of optical flow. Specifically, the ground truth enables us to model how the assumption of brightness constancy is violated in naturalistic sequences, resulting in a probabilistic model of \"brightness inconstancy\". We also generalize previous high-order constancy assumptions, such as gradient constancy, by modeling the constancy of responses to various linear filters in a high-order random field framework. These filters are free variables that can be learned from training data. Additionally we study the spatial structure of the optical flow and how motion boundaries are related to image intensity boundaries. Spatial smoothness is modeled using a Steerable Random Field, where spatial derivatives of the optical flow are steered by the image brightness structure. These models provide a statistical motivation for previous methods and enable the learning of all parameters from training data. All proposed models are quantitatively compared on the Middlebury flow dataset."
            },
            "slug": "Learning-Optical-Flow-Sun-Roth",
            "title": {
                "fragments": [],
                "text": "Learning Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The ground truth enables us to model how the assumption of brightness constancy is violated in naturalistic sequences, resulting in a probabilistic model of \"brightness inconstancy\", and generalize previous high- order constancy assumptions by modeling the constancy of responses to various linear filters in a high-order random field framework."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144398147"
                        ],
                        "name": "L. Sigal",
                        "slug": "L.-Sigal",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Sigal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sigal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12299303,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22d70d143135af112b7852416e416bbd02d093db",
            "isKey": false,
            "numCitedBy": 444,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "While research on articulated human motion and pose estimation has progressed rapidly in the last few years, there has been no systematic quantitative evaluation of competing methods to establish the current state of the art. Current algorithms make many different choices about how to model the human body, how to exploit image evidence and how to approach the inference problem. We argue that there is a need for common datasets that allow fair comparison between different methods and their design choices. Until recently gathering ground-truth data for evaluation of results (especially in 3D) was challenging. In this report we present a novel dataset obtained using a unique setup for capturing synchronized video and ground-truth 3D motion. Data was captured simultaneously using a calibrated marker-based motion capture system and multiple high-speed video capture systems. The video and motion capture streams were synchronized in software using a direct optimization method. The resulting HumanEvaI dataset contains multiple subjects performing a set of predefined actions with a number of repetitions. On the order of 50,000 frames of synchronized motion capture and video was collected at 60 Hz with an additional 37,000 frames of pure motion capture data. The data is partitioned into training, validation, and testing sub-sets. A standard set of error metrics is defined that can be used for evaluation of both 2D and 3D pose estimation and tracking algorithms. Support software and an on-line evaluation system for quantifying results using the test data is being made available to the community. This report provides an overview of the dataset and evaluation metrics and provides pointers into the dataset for additional details. It is our hope that HumanEva-I will become a standard dataset for the evaluation of articulated human motion and pose estimation."
            },
            "slug": "HumanEva:-Synchronized-Video-and-Motion-Capture-for-Sigal-Black",
            "title": {
                "fragments": [],
                "text": "HumanEva: Synchronized Video and Motion Capture Dataset for Evaluation of Articulated Human Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "There is a need for common datasets that allow fair comparison between different methods and their design choices to establish the current state of the art, and it is argued that HumanEva-I will become a standard dataset for the evaluation of articulated human motion and pose estimation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145965041"
                        ],
                        "name": "A. Shekhovtsov",
                        "slug": "A.-Shekhovtsov",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Shekhovtsov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shekhovtsov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145460870"
                        ],
                        "name": "Ivan Kovtun",
                        "slug": "Ivan-Kovtun",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Kovtun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivan Kovtun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752515"
                        ],
                        "name": "V. Hlav\u00e1c",
                        "slug": "V.-Hlav\u00e1c",
                        "structuredName": {
                            "firstName": "V\u00e1clav",
                            "lastName": "Hlav\u00e1c",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hlav\u00e1c"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "Although the original Horn and Schunck model reveals many limitations in practice, many of them have been tackled by subsequent modifications and extensions of the original model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7603254,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1638554e1ae47ba8d3401342638b48c39bda7382",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Efficient-MRF-Deformation-Model-for-Non-Rigid-Image-Shekhovtsov-Kovtun",
            "title": {
                "fragments": [],
                "text": "Efficient MRF Deformation Model for Non-Rigid Image Matching"
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2188270"
                        ],
                        "name": "N. Papenberg",
                        "slug": "N.-Papenberg",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Papenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Papenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144031005"
                        ],
                        "name": "Andr\u00e9s Bruhn",
                        "slug": "Andr\u00e9s-Bruhn",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Bruhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Bruhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2915154"
                        ],
                        "name": "Stephan Didas",
                        "slug": "Stephan-Didas",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Didas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephan Didas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 169
                            }
                        ],
                        "text": "While SIFT flow considers all possible matches at each pixel when introducing the regularity constraint, our scheme only considers the best matches and checks their consistency with the regularity constraint and the other image features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1998629,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "396749086172f824ec555adca5daf0d40e0723ef",
            "isKey": false,
            "numCitedBy": 471,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we suggest a variational model for optic flow computation based on non-linearised and higher order constancy assumptions. Besides the common grey value constancy assumption, also gradient constancy, as well as the constancy of the Hessian and the Laplacian are proposed. Since the model strictly refrains from a linearisation of these assumptions, it is also capable to deal with large displacements. For the minimisation of the rather complex energy functional, we present an efficient numerical scheme employing two nested fixed point iterations. Following a coarse-to-fine strategy it turns out that there is a theoretical foundation of so-called warping techniques hitherto justified only on an experimental basis. Since our algorithm consists of the integration of various concepts, ranging from different constancy assumptions to numerical implementation issues, a detailed account of the effect of each of these concepts is included in the experimental section. The superior performance of the proposed method shows up by significantly smaller estimation errors when compared to previous techniques. Further experiments also confirm excellent robustness under noise and insensitivity to parameter variations."
            },
            "slug": "Highly-Accurate-Optic-Flow-Computation-with-Warping-Papenberg-Bruhn",
            "title": {
                "fragments": [],
                "text": "Highly Accurate Optic Flow Computation with Theoretically Justified Warping"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A variational model for optic flow computation based on non-linearised and higher order constancy assumptions, including the common grey value constancy assumption, as well as the constancy of the Hessian and the Laplacian are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145774177"
                        ],
                        "name": "J. Weber",
                        "slug": "J.-Weber",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "It is of great importance for grouping and visual learning, the perception of structure, and for self-localization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1452702,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd4b2552f00b27e4b020b48e4cc8d33410864ff1",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a new algorithm for computing optical flow in a differential framework. The image sequence is first convolved with a set of linear, separable spatiotemporal filter kernels similar to those that have been used in other early vision problems such as texture and stereopsis. The brightness constancy constraint can then be applied to each of the resulting images, giving us, in general, an overdetermined system of equations for the optical flow at each pixel. There are three principal sources of error: (a) stochastic error due to sensor noise (b) systematic errors in the presence of large displacements and (c) errors due to failure of the brightness constancy model. Our analysis of these errors leads us to develop an algorithm based on a robust version of total least squares. Each optical flow vector computed has an associated reliability measure which can be used in subsequent processing. The performance of the algorithm on the data set used by Barron et al. (IJCV 1994) compares favorably with other techniques. In addition to being separable, the filters used are also causal, incorporating only past time frames. The algorithm is fully parallel and has been implemented on a multiple processor machine."
            },
            "slug": "Robust-computation-of-optical-flow-in-a-multi-scale-Weber-Malik",
            "title": {
                "fragments": [],
                "text": "Robust computation of optical flow in a multi-scale differential framework"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A new algorithm for computing optical flow in a differential framework based on a robust version of total least squares is developed, incorporating only past time frames."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405719070"
                        ],
                        "name": "H. Zimmer",
                        "slug": "H.-Zimmer",
                        "structuredName": {
                            "firstName": "Henning",
                            "lastName": "Zimmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Zimmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144031005"
                        ],
                        "name": "Andr\u00e9s Bruhn",
                        "slug": "Andr\u00e9s-Bruhn",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Bruhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Bruhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797649"
                        ],
                        "name": "Levi Valgaerts",
                        "slug": "Levi-Valgaerts",
                        "structuredName": {
                            "firstName": "Levi",
                            "lastName": "Valgaerts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Levi Valgaerts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2531425"
                        ],
                        "name": "A. D. L. Nuez",
                        "slug": "A.-D.-L.-Nuez",
                        "structuredName": {
                            "firstName": "Agust\u00edn",
                            "lastName": "Nuez",
                            "middleNames": [
                                "Salgado",
                                "de",
                                "la"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. D. L. Nuez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779035"
                        ],
                        "name": "B. Rosenhahn",
                        "slug": "B.-Rosenhahn",
                        "structuredName": {
                            "firstName": "Bodo",
                            "lastName": "Rosenhahn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rosenhahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145156858"
                        ],
                        "name": "H. Seidel",
                        "slug": "H.-Seidel",
                        "structuredName": {
                            "firstName": "Hans-Peter",
                            "lastName": "Seidel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seidel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12858219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "614feffdcac35006e0c2870e9215911e6dff60cb",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the concept of complementarity between data and smoothness term in modern variational optic flow methods. First we design a sophisticated data term that incorporates HSV colour representation with higher order constancy assumptions, completely separate robust penalisation, and constraint normalisation. Our anisotropic smoothness term reduces smoothing in the data constraint direction instead of the image edge direction, while enforcing a strong filling-in effect orthogonal to it. This allows optimal complementarity between both terms and avoids undesirable interference. The high quality of our complementary optic flow (COF) approach is demonstrated by the current top ranking result at the Middlebury benchmark."
            },
            "slug": "Complementary-Optic-Flow-Zimmer-Bruhn",
            "title": {
                "fragments": [],
                "text": "Complementary Optic Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work designs a sophisticated data term that incorporates HSV colour representation with higher order constancy assumptions, completely separate robust penalisation, and constraint normalisation and introduces the concept of complementarity between data and smoothness term in modern variational optic flow methods."
            },
            "venue": {
                "fragments": [],
                "text": "EMMCVPR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144398147"
                        ],
                        "name": "L. Sigal",
                        "slug": "L.-Sigal",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Sigal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sigal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2364013"
                        ],
                        "name": "A. O. Balan",
                        "slug": "A.-O.-Balan",
                        "structuredName": {
                            "firstName": "Alexandru",
                            "lastName": "Balan",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. O. Balan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11279201,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7722159088c18c9998a27047a2b18d8cce313935",
            "isKey": false,
            "numCitedBy": 956,
            "numCiting": 142,
            "paperAbstract": {
                "fragments": [],
                "text": "While research on articulated human motion and pose estimation has progressed rapidly in the last few years, there has been no systematic quantitative evaluation of competing methods to establish the current state of the art. We present data obtained using a hardware system that is able to capture synchronized video and ground-truth 3D motion. The resulting HumanEva datasets contain multiple subjects performing a set of predefined actions with a number of repetitions. On the order of 40,000 frames of synchronized motion capture and multi-view video (resulting in over one quarter million image frames in total) were collected at 60\u00a0Hz with an additional 37,000 time instants of pure motion capture data. A standard set of error measures is defined for evaluating both 2D and 3D pose estimation and tracking algorithms. We also describe a baseline algorithm for 3D articulated tracking that uses a relatively standard Bayesian framework with optimization in the form of Sequential Importance Resampling and Annealed Particle Filtering. In the context of this baseline algorithm we explore a variety of likelihood functions, prior models of human motion and the effects of algorithm parameters. Our experiments suggest that image observation models and motion priors play important roles in performance, and that in a multi-view laboratory environment, where initialization is available, Bayesian filtering tends to perform well. The datasets and the software are made available to the research community. This infrastructure will support the development of new articulated motion and pose estimation algorithms, will provide a baseline for the evaluation and comparison of new methods, and will help establish the current state of the art in human pose estimation and tracking."
            },
            "slug": "HumanEva:-Synchronized-Video-and-Motion-Capture-and-Sigal-Balan",
            "title": {
                "fragments": [],
                "text": "HumanEva: Synchronized Video and Motion Capture Dataset and Baseline Algorithm for Evaluation of Articulated Human\u00a0Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A baseline algorithm for 3D articulated tracking that uses a relatively standard Bayesian framework with optimization in the form of Sequential Importance Resampling and Annealed Particle Filtering is described, and a variety of likelihood functions, prior models of human motion and the effects of algorithm parameters are explored."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681442"
                        ],
                        "name": "Ce Liu",
                        "slug": "Ce-Liu",
                        "structuredName": {
                            "firstName": "Ce",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ce Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143738177"
                        ],
                        "name": "Jenny Yuen",
                        "slug": "Jenny-Yuen",
                        "structuredName": {
                            "firstName": "Jenny",
                            "lastName": "Yuen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jenny Yuen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "The predominant way to estimate dense optical flow in today\u2019s computer vision literature is by variational methods, as introduced in the seminal work by Horn and Schunck [18], where a local, gradient-based matching of pixel gray values is combined with a global smoothness assumption."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1181823,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae01610370105f87eeb0d4a90aa723c43f4393bc",
            "isKey": false,
            "numCitedBy": 665,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "While image registration has been studied in different areas of computer vision, aligning images depicting different scenes remains a challenging problem, closer to recognition than to image matching. Analogous to optical flow, where an image is aligned to its temporally adjacent frame, we propose SIFT flow, a method to align an image to its neighbors in a large image collection consisting of a variety of scenes. For a query image, histogram intersection on a bag-of-visual-words representation is used to find the set of nearest neighbors in the database. The SIFT flow algorithm then consists of matching densely sampled SIFT features between the two images, while preserving spatial discontinuities. The use of SIFT features allows robust matching across different scene/object appearances and the discontinuity-preserving spatial model allows matching of objects located at different parts of the scene. Experiments show that the proposed approach is able to robustly align complicated scenes with large spatial distortions. We collect a large database of videos and apply the SIFT flow algorithm to two applications: (i) motion field prediction from a single static image and (ii) motion synthesis via transfer of moving objects."
            },
            "slug": "SIFT-Flow:-Dense-Correspondence-across-Different-Liu-Yuen",
            "title": {
                "fragments": [],
                "text": "SIFT Flow: Dense Correspondence across Different Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method to align an image to its neighbors in a large image collection consisting of a variety of scenes, and applies the SIFT flow algorithm to two applications: motion field prediction from a single static image and motion synthesis via transfer of moving objects."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681442"
                        ],
                        "name": "Ce Liu",
                        "slug": "Ce-Liu",
                        "structuredName": {
                            "firstName": "Ce",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ce Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143738177"
                        ],
                        "name": "Jenny Yuen",
                        "slug": "Jenny-Yuen",
                        "structuredName": {
                            "firstName": "Jenny",
                            "lastName": "Yuen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jenny Yuen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 566387,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef2448cf2eae2bc2fc1d83f1da0fbaba188ecec7",
            "isKey": false,
            "numCitedBy": 361,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a novel nonparametric approach for object recognition and scene parsing using dense scene alignment. Given an input image, we retrieve its best matches from a large database with annotated images using our modified, coarse-to-fine SIFT flow algorithm that aligns the structures within two images. Based on the dense scene correspondence obtained from the SIFT flow, our system warps the existing annotations, and integrates multiple cues in a Markov random field framework to segment and recognize the query image. Promising experimental results have been achieved by our nonparametric scene parsing system on a challenging database. Compared to existing object recognition approaches that require training for each object category, our system is easy to implement, has few parameters, and embeds contextual information naturally in the retrieval/alignment procedure."
            },
            "slug": "Nonparametric-scene-parsing:-Label-transfer-via-Liu-Yuen",
            "title": {
                "fragments": [],
                "text": "Nonparametric scene parsing: Label transfer via dense scene alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Compared to existing object recognition approaches that require training for each object category, the proposed nonparametric scene parsing system is easy to implement, has few parameters, and embeds contextual information naturally in the retrieval/alignment procedure."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783337"
                        ],
                        "name": "P. H\u00e9as",
                        "slug": "P.-H\u00e9as",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "H\u00e9as",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. H\u00e9as"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49843309"
                        ],
                        "name": "\u00c9. M\u00e9min",
                        "slug": "\u00c9.-M\u00e9min",
                        "structuredName": {
                            "firstName": "\u00c9tienne",
                            "lastName": "M\u00e9min",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. M\u00e9min"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517111"
                        ],
                        "name": "N. Papadakis",
                        "slug": "N.-Papadakis",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Papadakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Papadakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3216560"
                        ],
                        "name": "A. Szantai",
                        "slug": "A.-Szantai",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Szantai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Szantai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "Manuscript received 10 Sept. 2009; revised 22 Jan. 2010; accepted 16 Mar. 2010; published online 10 Aug. 2010."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2995695,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "8a615076b4958c0648d473e30a4f9b7245fb9c30",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of estimating mesoscale dynamics of atmospheric layers from satellite image sequences. Due to the great deal of spatial and temporal distortions of cloud patterns and because of the sparse 3-D nature of cloud observations, standard dense-motion field-estimation techniques used in computer vision are not well adapted to satellite images. Relying on a physically sound vertical decomposition of the atmosphere into layers, we propose a dense-motion estimator dedicated to the extraction of multilayer horizontal wind fields. This estimator is expressed as the minimization of a global function including data and spatio-temporal smoothness terms. A robust data term relying on the integrated-continuity equation mass-conservation model is proposed to fit sparse-transmittance observations related to each layer. A novel spatio-temporal smoother derived from large eddy prediction of a shallow-water momentum-conservation model is used to build constraints for large-scale temporal coherence. These constraints are combined in a global smoothing framework with a robust second-order smoother, preserving divergent and vorticity structures of the flow. For optimization, a two-stage motion estimation scheme is proposed to overcome multiresolution limitations when capturing the dynamics of mesoscale structures. This alternative approach relies on the combination of correlation and optical-flow observations in a variational context. An exhaustive evaluation of the novel method is first performed on a scalar image sequence generated by direct numerical simulation of a turbulent 2-D flow. By qualitative comparisons, the method is then assessed on a METEOSAT image sequence."
            },
            "slug": "Layered-Estimation-of-Atmospheric-Mesoscale-From-H\u00e9as-M\u00e9min",
            "title": {
                "fragments": [],
                "text": "Layered Estimation of Atmospheric Mesoscale Dynamics From Satellite Imagery"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes a dense-motion estimator dedicated to the extraction of multilayer horizontal wind fields based on a physically sound vertical decomposition of the atmosphere into layers, and proposes a two-stage motion estimation scheme to overcome multiresolution limitations when capturing the dynamics of mesoscale structures."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Geoscience and Remote Sensing"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "The common coarse-to-fine warping scheme relaxes this problem as initial estimates are computed at coarser resolution levels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6055435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12c7fc38debaf3589e712973642246bd54fe63b3",
            "isKey": false,
            "numCitedBy": 956,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We approach recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points. This algorithm sets up correspondence as an integer quadratic programming problem, where the cost function has terms based on similarity of corresponding geometric blur point descriptors as well as the geometric distortion between pairs of corresponding feature points. The algorithm handles outliers, and thus enables matching of exemplars to query images in the presence of occlusion and clutter. Given the correspondences, we estimate an aligning transform, typically a regularized thin plate spline, resulting in a dense correspondence between the two shapes. Object recognition is then handled in a nearest neighbor framework where the distance between exemplar and query is the matching cost between corresponding points. We show results on two datasets. One is the Caltech 101 dataset (Fei-Fei, Fergus and Perona), an extremely challenging dataset with large intraclass variation. Our approach yields a 48% correct classification rate, compared to Fei-Fei et al 's 16%. We also show results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "slug": "Shape-matching-and-object-recognition-using-low-Berg-Berg",
            "title": {
                "fragments": [],
                "text": "Shape matching and object recognition using low distortion correspondences"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work approaches recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points, and shows results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143991676"
                        ],
                        "name": "I. Laptev",
                        "slug": "I.-Laptev",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Laptev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Laptev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3502855"
                        ],
                        "name": "Marcin Marszalek",
                        "slug": "Marcin-Marszalek",
                        "structuredName": {
                            "firstName": "Marcin",
                            "lastName": "Marszalek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcin Marszalek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3261451"
                        ],
                        "name": "Benjamin Rozenfeld",
                        "slug": "Benjamin-Rozenfeld",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Rozenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Rozenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12365014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f86767732f76f478d5845f2e59f99ba106e9265",
            "isKey": false,
            "numCitedBy": 3595,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The aim of this paper is to address recognition of natural human actions in diverse and realistic video settings. This challenging but important subject has mostly been ignored in the past due to several problems one of which is the lack of realistic and annotated video datasets. Our first contribution is to address this limitation and to investigate the use of movie scripts for automatic annotation of human actions in videos. We evaluate alternative methods for action retrieval from scripts and show benefits of a text-based classifier. Using the retrieved action samples for visual learning, we next turn to the problem of action classification in video. We present a new method for video classification that builds upon and extends several recent ideas including local space-time features, space-time pyramids and multi-channel non-linear SVMs. The method is shown to improve state-of-the-art results on the standard KTH action dataset by achieving 91.8% accuracy. Given the inherent problem of noisy labels in automatic annotation, we particularly investigate and show high tolerance of our method to annotation errors in the training set. We finally apply the method to learning and classifying challenging action classes in movies and show promising results."
            },
            "slug": "Learning-realistic-human-actions-from-movies-Laptev-Marszalek",
            "title": {
                "fragments": [],
                "text": "Learning realistic human actions from movies"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new method for video classification that builds upon and extends several recent ideas including local space-time features,space-time pyramids and multi-channel non-linear SVMs is presented and shown to improve state-of-the-art results on the standard KTH action dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12650942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af220e04f193ed2a44e89e2cfd45a4e28ab35a52",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of finding point correspondences in images by way of an approach to template matching that is robust under affine distortions. This is achieved by applying \"geometric blur\" to both the template and the image, resulting in a fall-off in similarity that is close to linear in the norm of the distortion between the template and the image. Results in wide baseline stereo correspondence, face detection, and feature correspondence are included."
            },
            "slug": "Geometric-blur-for-template-matching-Berg-Malik",
            "title": {
                "fragments": [],
                "text": "Geometric blur for template matching"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work addresses the problem of finding point correspondences in images by way of an approach to template matching that is robust under affine distortions by applying \"geometric blur\" to both the template and the image, resulting in a fall-off in similarity."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": false,
            "numCitedBy": 29266,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084269"
                        ],
                        "name": "H. Chui",
                        "slug": "H.-Chui",
                        "structuredName": {
                            "firstName": "Haili",
                            "lastName": "Chui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Chui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145257017"
                        ],
                        "name": "Anand Rangarajan",
                        "slug": "Anand-Rangarajan",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Rangarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Rangarajan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "The authors are with the Computer Science Division, Department of Electrical Engineering and Computer Science, University of California at Berkeley, Berkeley, CA 94720."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7442835,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9511b4e7a3d64b9737ea25b5c268478e3d248209",
            "isKey": false,
            "numCitedBy": 1574,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-new-point-matching-algorithm-for-non-rigid-Chui-Rangarajan",
            "title": {
                "fragments": [],
                "text": "A new point matching algorithm for non-rigid registration"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588702"
                        ],
                        "name": "B. D. Lucas",
                        "slug": "B.-D.-Lucas",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lucas",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2121536,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd",
            "isKey": false,
            "numCitedBy": 13329,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between the images than existing techniques Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show how our technique can be adapted tor use in a stereo vision system."
            },
            "slug": "An-Iterative-Image-Registration-Technique-with-an-Lucas-Kanade",
            "title": {
                "fragments": [],
                "text": "An Iterative Image Registration Technique with an Application to Stereo Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration, and can be generalized to handle rotation, scaling and shearing."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778133"
                        ],
                        "name": "Pablo Arbel\u00e1ez",
                        "slug": "Pablo-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15291355,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "779dea9b105d8f48c9bc86f479b91f9c1d3c5963",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a generic grouping algorithm that constructs a hierarchy of regions from the output of any contour detector. Our method consists of two steps, an oriented watershed transform (OWT) to form initial regions from contours, followed by construction of an ultra-metric contour map (UCM) defining a hierarchical segmentation. We provide extensive experimental evaluation to demonstrate that, when coupled to a high-performance contour detector, the OWT-UCM algorithm produces state-of-the-art image segmentations. These hierarchical segmentations can optionally be further refined by user-specified annotations."
            },
            "slug": "From-contours-to-regions:-An-empirical-evaluation-Arbel\u00e1ez-Maire",
            "title": {
                "fragments": [],
                "text": "From contours to regions: An empirical evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work provides extensive experimental evaluation to demonstrate that, when coupled to a high-performance contour detector, the OWT-UCM algorithm produces state-of-the-art image segmentations."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490189"
                        ],
                        "name": "Gregory Shakhnarovich",
                        "slug": "Gregory-Shakhnarovich",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Shakhnarovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Shakhnarovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688317"
                        ],
                        "name": "P. Indyk",
                        "slug": "P.-Indyk",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Indyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Indyk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9680583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2323173a0bddac0dd2586b17a2f3ac33f401c45c",
            "isKey": false,
            "numCitedBy": 563,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Regression and classification methods based on similarity of the input to stored examples have not been widely used in applications involving very large sets of high-dimensional data. Recent advances in computational geometry and machine learning, however, may alleviate the problems in using these methods on large data sets. This volume presents theoretical and practical discussions of nearest-neighbor (NN) methods in machine learning and examines computer vision as an application domain in which the benefit of these advanced methods is often dramatic. It brings together contributions from researchers in theory of computation, machine learning, and computer vision with the goals of bridging the gaps between disciplines and presenting state-of-the-art methods for emerging applications.The contributors focus on the importance of designing algorithms for NN search, and for the related classification, regression, and retrieval tasks, that remain efficient even as the number of points or the dimensionality of the data grows very large. The book begins with two theoretical chapters on computational geometry and then explores ways to make the NN approach practicable in machine learning applications where the dimensionality of the data and the size of the data sets make the naive methods for NN search prohibitively expensive. The final chapters describe successful applications of an NN algorithm, locality-sensitive hashing (LSH), to vision tasks."
            },
            "slug": "Nearest-Neighbor-Methods-in-Learning-and-Vision:-Shakhnarovich-Darrell",
            "title": {
                "fragments": [],
                "text": "Nearest-Neighbor Methods in Learning and Vision: Theory and Practice (Neural Information Processing)"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This volume presents theoretical and practical discussions of nearest-neighbor (NN) methods in machine learning and examines computer vision as an application domain in which the benefit of these advanced methods is often dramatic."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25505,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 208784962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ff65ac698013cdd9d61326cab49a1d75404e001",
            "isKey": false,
            "numCitedBy": 18721,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Editors",
            "title": {
                "fragments": [],
                "text": "Editors"
            },
            "venue": {
                "fragments": [],
                "text": "Brain Research Bulletin"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13115760,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "048e3a0904f7d964a0ade5da031a585dadc5a92f",
            "isKey": false,
            "numCitedBy": 1908,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Visual-Reconstruction-Blake-Zisserman",
            "title": {
                "fragments": [],
                "text": "Visual Reconstruction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 218479160,
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Coordinated Adaptive Robust Contouring Control of an Industrial Biaxial Precision Gantry with C"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "From Pixels to Regions: Partial Differential Equations in Image Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "From Pixels to Regions: Partial Differential Equations in Image Analysis"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "The authors are with the Computer Science Division, Department of Electrical Engineering and Computer Science, University of California at Berkeley, Berkeley, CA 94720."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Feature Based Method for Determining Dense Long Range Correspondences"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. European Conf. Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. Int'l Workshop Enery Minimization Methods in Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Workshop Enery Minimization Methods in Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "LNCS"
            },
            "venue": {
                "fragments": [],
                "text": "LNCS"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Illumination-Invariant Variational Optical Flow with Photometric Invariants"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Ann. Symp. German Assoc. Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib"
            },
            "venue": {
                "fragments": [],
                "text": "For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 46,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Large-Displacement-Optical-Flow:-Descriptor-in-Brox-Malik/ffd97ed7408fa75b86d4c8e4280f8d730ffa2cf0?sort=total-citations"
}