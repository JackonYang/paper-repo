{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054787633"
                        ],
                        "name": "Raymond Lau",
                        "slug": "Raymond-Lau",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Lau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond Lau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 52
                            }
                        ],
                        "text": "This has been tried, with moderate success only, by Lau et al. (1993b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57374179,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e58b5f825df9fb0b00465a66598f302c30b080a",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Ongoing efforts at adaptive statistical language modeling are described. To extract information from the document history, trigger pairs are used as the basic information-bearing elements. To combine statistical evidence from multiple triggers, the principle of maximum entropy (ME) is used. To combine the trigger-based model with the static model, the latter is absorbed into the ME formalism. Given consistent statistical evidence, a unique ME solution is guaranteed to exist, and an iterative algorithm exists which is guaranteed to converge to it. Among the advantages of this approach are its simplicity, generality, and incremental nature. Among its disadvantages are its computational requirements. The model described here was trained on five million words of Wall Street Journal text. It used some 40000 unigram constraints, 200000 bigram constraints, 200000 trigram constraints, and 60000 trigger constraints. After 13 iterations, it produced a language model whose perplexity was 12% lower than that of a conventional trigram, as measured on independent data.<<ETX>>"
            },
            "slug": "Trigger-based-language-models:-a-maximum-entropy-Lau-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Trigger-based language models: a maximum entropy approach"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The model described here was trained on five million words of Wall Street Journal text and produced a language model whose perplexity was 12% lower than that of a conventional trigram, as measured on independent data."
            },
            "venue": {
                "fragments": [],
                "text": "1993 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 91
                            }
                        ],
                        "text": "This in turn results in faster convergence of the Generalized Iterative Scaling algorithm (Rosenfeld, 1994b: p. 53)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 63
                            }
                        ],
                        "text": "For a more detailed discussion of recognition experiments, see [Rosenfeld 94b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 4
                            }
                        ],
                        "text": "See [Rosenfeld 94b] for a more detailed exposition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 52
                            }
                        ],
                        "text": "See Jelinek and Mercer (1980) for more details, and Rosenfeld (1994b) for further exposition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 172
                            }
                        ],
                        "text": "We have created an interpolate program that takes any number of probability streams, and an optional bin-partitioning stream, and runs the EM algorithm to convergence (see Rosenfeld, 1994b: appendix B)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 4
                            }
                        ],
                        "text": "See Rosenfeld (1994b) for more details."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 50
                            }
                        ],
                        "text": "See [Jelinek and Mercer 80] for more details, and [Rosenfeld 94b] for further exposition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 134
                            }
                        ],
                        "text": "(1) Generalized Iterative Scaling is computationally very expensive [for more on this problem, and on methods for coping with it, see Rosenfeld (1994b): section 5.7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 4
                            }
                        ],
                        "text": "See Rosenfeld (1994b) for a more detailed exposition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1735632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b26fa1b848ed808a0511db34bce2426888f0b68",
            "isKey": false,
            "numCitedBy": 417,
            "numCiting": 120,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Language modeling is the attempt to characterize, capture and exploit regularities in natural language. In statistical language modeling, large amounts of text are used to automatically determine the model's parameters. Language modeling is useful in automatic speech recognition, machine translation, and any other application that processes natural language with incomplete knowledge. In this thesis, I view language as an information source which emits a stream of symbols from a finite alphabet (the vocabulary). The goal of language modeling is then to identify and exploit sources of information in the language stream, so as to minimize its perceived entropy. Most existing statistical language models exploit the immediate past only. To extract information from further back in the document's history, I use trigger pairs as the basic information bearing elements. This allows the model to adapt its expectations to the topic of discourse. Next, statistical evidence from many sources must be combined. Traditionally, linear interpolation and its variants have been used, but these are shown here to be seriously deficient. Instead, I apply the principle of Maximum Entropy (ME). Each information source gives rise to a set of constraints, to be imposed on the combined estimate. The intersection of these constraints is the set of probability functions which are consistent with all the information sources. The function with the highest entropy within that set is the NE solution. Language modeling, Adaptive language modeling, Statistical language modeling, Maximum entropy, Speech recognition."
            },
            "slug": "Adaptive-Statistical-Language-Modeling;-A-Maximum-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Adaptive Statistical Language Modeling; A Maximum Entropy Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This thesis views language as an information source which emits a stream of symbols from a finite alphabet (the vocabulary), and applies the principle of Maximum Entropy to identify and exploit sources of information in the language stream, so as to minimize its perceived entropy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054787633"
                        ],
                        "name": "Raymond Lau",
                        "slug": "Raymond-Lau",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Lau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond Lau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 52
                            }
                        ],
                        "text": "This has been tried, with moderate success only, by Lau et al. (1993b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7536384,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49b2862ab73be40bf69ac3f457039f18d12df0ae",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe our ongoing efforts at adaptive statistical language modeling. Central to our approach is the Maximum Entropy (ME) Principle, allowing us to combine evidence from multiple sources, such as long-distance triggers and conventional short-distance trigrams. Given consistent statistical evidence, a unique ME solution is guaranteed to exist, and an iterative algorithm exists which is guaranteed to converge to it. Among the advantages of this approach are its simplicity, its generality, and its incremental nature. Among its disadvantages are its computational requirements. We describe a succession of ME models, culminating in our current Maximum Likelihood/Maximum Entropy (ML/ME) model. Preliminary results with the latter show a 27% perplexity reduction as compared to a conventional trigram model."
            },
            "slug": "Adaptive-Language-Modeling-Using-the-Maximum-Lau-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Adaptive Language Modeling Using the Maximum Entropy Principle"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A succession of ME models are described, culminating in the current Maximum Likelihood/Maximum Entropy (ML/ME) model, which shows a 27% perplexity reduction as compared to a conventional trigram model."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14289498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eadf7d20852caa92310d0cb582269b94226b1e58",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present an algorithm to adapt a n-gram language model to a document as it is dictated. The observed partial document is used to estimate a unigram distribution for the words that already occurred. Then, they find the closest n-gram distribution to the static n-gram distribution (using the discrimination information distance measure) that satisfies the marginal constraints derived from the document. The resulting minimum discrimination information model results in a perplexity of 208 instead of 290 for the static trigram model on a document of 321 words.<<ETX>>"
            },
            "slug": "Adaptive-Language-Modeling-Using-Minimum-Estimation-Pietra-Pietra",
            "title": {
                "fragments": [],
                "text": "Adaptive Language Modeling Using Minimum Discriminant Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The authors present an algorithm to adapt a n-gram language model to a document as it is dictated that results in a perplexity of 208 instead of 290 for the static trigram model on a document of 321 words."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "Ronald Rosenfeld",
                        "slug": "Ronald-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 91
                            }
                        ],
                        "text": "This in turn results in faster convergence of the Generalized Iterative Scaling algorithm (Rosenfeld, 1994b: p. 53)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 52
                            }
                        ],
                        "text": "See Jelinek and Mercer (1980) for more details, and Rosenfeld (1994b) for further exposition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 172
                            }
                        ],
                        "text": "We have created an interpolate program that takes any number of probability streams, and an optional bin-partitioning stream, and runs the EM algorithm to convergence (see Rosenfeld, 1994b: appendix B)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 4
                            }
                        ],
                        "text": "See Rosenfeld (1994b) for more details."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 134
                            }
                        ],
                        "text": "(1) Generalized Iterative Scaling is computationally very expensive [for more on this problem, and on methods for coping with it, see Rosenfeld (1994b): section 5.7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 4
                            }
                        ],
                        "text": "See Rosenfeld (1994b) for a more detailed exposition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 70704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be9d87d39517729ba7e24c5fa46ed263e5b2f627",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe our latest attempt at adaptive language modeling. At the heart of our approach is a Maximum Entropy (ME) model, which incorporates many knowledge sources in a consistent manner. The other components are a selective unigram cache, a conditional bigram cache, and a conventional static trigram. We describe the knowledge sources used to build such a model with ARPA's official WSJ corpus, and report on perplexity and word error rate results obtained with it. Then, three different adaptation paradigms are discussed, and an additional experiment, based on AP wire data, is used to compare them."
            },
            "slug": "A-Hybrid-Approach-to-Adaptive-Statistical-Language-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "A Hybrid Approach to Adaptive Statistical Language Modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This work describes the knowledge sources used to build a Maximum Entropy model, which incorporates many knowledge sources in a consistent manner with ARPA's official WSJ corpus, and reports on perplexity and word error rate results obtained with it."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144531812"
                        ],
                        "name": "Xuedong Huang",
                        "slug": "Xuedong-Huang",
                        "structuredName": {
                            "firstName": "Xuedong",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuedong Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 39
                            }
                        ],
                        "text": "As another, more detailed, example, in Rosenfeld and Huang (1992) we report on our early work on trigger models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 41
                            }
                        ],
                        "text": "This problem was discussed and solved in Rosenfeld and Huang (1992), and the solution used in a speech recognition system in Chase et al. (1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 4
                            }
                        ],
                        "text": "See Rosenfeld and Huang (1992) for details\nTest set Trigram PP Trigram+triggers PP Improvement\n70KW (WSJ) 170 153 10%\nresult will carry over."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8058984,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "914b06746d7305bcb5a38b6b4234e1b08f30a94b",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe two attempt to improve our stochastic language models. In the first, we identify a systematic overestimation in the traditional backoff model, and use statistical reasoning to correct it. Our modification results in up to 6% reduction in the perplexity of various tasks. Although the improvement is modest, it is achieved with hardly any increase in the complexity of the model. Both analysis and empirical data suggest that the modification is most suitable when training data is sparse.In the second attempt, we propose a new type of adaptive language model. Existing adaptive models use a dynamic cache, based on the history of the document seen up to that point. But another source of information in the history, within-document word sequence correlations, has not yet been tapped. We describe a model that attempts to capture this information, using a framework where one word sequence triggers another, causing its estimated probability to be raised. We discuss various issues in the design of such a model, and describe our first attempt at building one. Our preliminary results include a perplexity reduction of between 10% and 32%, depending on the test set."
            },
            "slug": "Improvements-in-Stochastic-Language-Modeling-Rosenfeld-Huang",
            "title": {
                "fragments": [],
                "text": "Improvements in Stochastic Language Modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Two attempt to improve stochastic language models are described, and a new type of adaptive language model is proposed, using a framework where one word sequence triggers another, causing its estimated probability to be raised."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686820"
                        ],
                        "name": "B. M\u00e9rialdo",
                        "slug": "B.-M\u00e9rialdo",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "M\u00e9rialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. M\u00e9rialdo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73158308"
                        ],
                        "name": "M. Strauss",
                        "slug": "M.-Strauss",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Strauss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Strauss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11601499,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0687165a9f0360bde0469fd401d966540e0897c3",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "In the case of a trigram language model, the probability of the next word conditioned on the previous two words is estimated from a large corpus of text. The resulting static trigram language model (STLM) has fixed probabilities that are independent of the document being dictated. To improve the language model (LM), one can adapt the probabilities of the trigram language model to match the current document more closely. The partially dictated document provides significant clues about what words are more likely to be used next. Of many methods that can be used to adapt the LM, we describe in this paper a simple model based on the trigram frequencies estimated from the partially dictated document. We call this model a cache trigram language model (CTLM) since we are caching the recent history of words. We have found that the CTLM reduces the perplexity of a dictated document by 23%. The error rate of a 20,000-word isolated word recognizer decreases by about 5% at the beginning of a document and by about 24% after a few hundred words."
            },
            "slug": "A-Dynamic-Language-Model-for-Speech-Recognition-Jelinek-M\u00e9rialdo",
            "title": {
                "fragments": [],
                "text": "A Dynamic Language Model for Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This model is called a cache trigram language model (CTLM) since it is caching the recent history of words and it is found that the CTLM reduces the perplexity of a dictated document by 23%."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795942"
                        ],
                        "name": "Reinhard Kneser",
                        "slug": "Reinhard-Kneser",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Kneser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Reinhard Kneser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61164891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01a9a9686d45a3dc8182f59a1a77f1ac4f233761",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In statistical language modelling there is always a problem of sparse data. A way to reduce this problem is to form groups of words in order to get equivalence classes. In this paper we present a clustering algorithm that builds abstract word equivalence classes. The algorithm finds a local optimum according to a maximum-likelihood criterion. Experiments were made on an English 1.1-million word corpus and a German 100,000-word corpus. Compared to a word bigram model, the use of clustered equivalence classes in a bigram class model leads to a significant improvement, as measured by the perplexity. Depending on the size of the training material, the automatically clustered word classes are even better than manually determined categories."
            },
            "slug": "Forming-Word-Classes-by-Statistical-Clustering-for-Kneser-Ney",
            "title": {
                "fragments": [],
                "text": "Forming Word Classes by Statistical Clustering for Statistical Language Modelling"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a clustering algorithm that builds abstract word equivalence classes that finds a local optimum according to a maximum-likelihood criterion and shows good results depending on the size of the training material."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143937779"
                        ],
                        "name": "R. Kuhn",
                        "slug": "R.-Kuhn",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Kuhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kuhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714393"
                        ],
                        "name": "R. Mori",
                        "slug": "R.-Mori",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Mori",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 64296899,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "c4dbdc3ef532c5b10e2e2de317371bcdec68be05",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-cache-based-natural-lan-guage-model-for-speech-Kuhn-Mori",
            "title": {
                "fragments": [],
                "text": "A cache based natural lan-guage model for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35229948"
                        ],
                        "name": "S. Katz",
                        "slug": "S.-Katz",
                        "structuredName": {
                            "firstName": "Slava",
                            "lastName": "Katz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Katz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6555412,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0130277677e5b915d5cd86b3afafd77fd08eb2e",
            "isKey": false,
            "numCitedBy": 1908,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The description of a novel type of m-gram language model is given. The model offers, via a nonlinear recursive procedure, a computation and space efficient solution to the problem of estimating probabilities from sparse data. This solution compares favorably to other proposed methods. While the method has been developed for and successfully implemented in the IBM Real Time Speech Recognizers, its generality makes it applicable in other areas where the problem of estimating probabilities from sparse data arises."
            },
            "slug": "Estimation-of-probabilities-from-sparse-data-for-of-Katz",
            "title": {
                "fragments": [],
                "text": "Estimation of probabilities from sparse data for the language model component of a speech recognizer"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The model offers, via a nonlinear recursive procedure, a computation and space efficient solution to the problem of estimating probabilities from sparse data, and compares favorably to other proposed methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143937779"
                        ],
                        "name": "R. Kuhn",
                        "slug": "R.-Kuhn",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Kuhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kuhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714393"
                        ],
                        "name": "R. Mori",
                        "slug": "R.-Mori",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Mori",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31924166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be1fed9544830df1137e72b1d2396c40d3e18365",
            "isKey": false,
            "numCitedBy": 580,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech-recognition systems must often decide between competing ways of breaking up the acoustic input into strings of words. Since the possible strings may be acoustically similar, a language model is required; given a word string, the model returns its linguistic probability. Several Markov language models are discussed. A novel kind of language model which reflects short-term patterns of word use by means of a cache component (analogous to cache memory in hardware terminology) is presented. The model also contains a 3g-gram component of the traditional type. The combined model and a pure 3g-gram model were tested on samples drawn from the Lancaster-Oslo/Bergen (LOB) corpus of English text. The relative performance of the two models is examined, and suggestions for the future improvements are made. >"
            },
            "slug": "A-Cache-Based-Natural-Language-Model-for-Speech-Kuhn-Mori",
            "title": {
                "fragments": [],
                "text": "A Cache-Based Natural Language Model for Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A novel kind of language model which reflects short-term patterns of word use by means of a cache component (analogous to cache memory in hardware terminology) is presented and contains a 3g-gram component of the traditional type."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107569404"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": "Often, the perplexity ([Jelinek et al. 77]) of the text with regard to the model is reported."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 23
                            }
                        ],
                        "text": "Often, the perplexity (Jelinek et al., 1977) of the text with regard to the model is reported."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121680873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d350f2d767a70d55275a17d0b3dfcc80b2e0fee",
            "isKey": false,
            "numCitedBy": 213,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Using counterexamples, we show that vocabulary size and static and dynamic branching factors are all inadequate as measures of speech recognition complexity of finite state grammars. Information theoretic arguments show that perplexity (the logarithm of which is the familiar entropy) is a more appropriate measure of equivalent choice. It too has certain weaknesses which we discuss. We show that perplexity can also be applied to languages having no obvious statistical description, since an entropy\u2010maximizing probability assignment can be found for any finite\u2010state grammar. Table I shows perplexity values for some well\u2010known speech recognition tasks. Perplexity Vocabulary Dynamic Phone Word size branching factorIBM\u2010Lasers 2.14 21.11 1000 1000IBM\u2010Raleigh 1.69 7.74 250 7.32CMU\u2010AIX05 1.52 6.41 1011 35"
            },
            "slug": "Perplexity\u2014a-measure-of-the-difficulty-of-speech-Jelinek-Mercer",
            "title": {
                "fragments": [],
                "text": "Perplexity\u2014a measure of the difficulty of speech recognition tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "Using counterexamples, it is shown that vocabulary size and static and dynamic branching factors are all inadequate as measures of speech recognition complexity of finite state grammars and that perplexity is a more appropriate measure of equivalent choice."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145165877"
                        ],
                        "name": "P. Hanks",
                        "slug": "P.-Hanks",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Hanks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hanks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9558665,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "9e2caa39ac534744a180972a30a320ad0ae41ea3",
            "isKey": false,
            "numCitedBy": 4363,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The term word association is used in a very particular sense in the psycholinguistic literature. (Generally speaking, subjects respond quicker than normal to the word nurse if it follows a highly associated word such as doctor. ) We will extend the term to provide the basis for a statistical description of a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type (content word/content word) to lexico-syntactic co-occurrence constraints between verbs and prepositions (content word/function word). This paper will propose an objective measure based on the information theoretic notion of mutual information, for estimating word association norms from computer readable corpora. (The standard method of obtaining word association norms, testing a few thousand subjects on a few hundred words, is both costly and unreliable.) The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "slug": "Word-Association-Norms,-Mutual-Information-and-Church-Hanks",
            "title": {
                "fragments": [],
                "text": "Word Association Norms, Mutual Information and Lexicography"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143937779"
                        ],
                        "name": "R. Kuhn",
                        "slug": "R.-Kuhn",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Kuhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kuhn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 37
                            }
                        ],
                        "text": "N-gram caches were first reported by [Kuhn 88] and [Kupiec 89]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1295335,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "491566891addc26134c617ab026f5548de39401a",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech recognition systems incorporate a language model which, at each stage of the recognition task, assigns a probability of occurrence to each word in the vocabulary. A class of Markov language models identified by Jelinek has achieved considerable success in this domain. A modification of the Markov approach, which assigns higher probabilities to recently used words, is proposed and tested against a pure Markov model. Parameter calculation and comparison of the two models both involve use of the LOB Corpus of tagged modern English."
            },
            "slug": "Speech-Recognition-and-the-Frequency-of-Recently-A-Kuhn",
            "title": {
                "fragments": [],
                "text": "Speech Recognition and the Frequency of Recently Used Words: A Modified Markov Model for Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A modification of the Markov approach, which assigns higher probabilities to recently used words, is proposed and tested against a pure Markov model."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114846464"
                        ],
                        "name": "R. C. King",
                        "slug": "R.-C.-King",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "King",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. C. King"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12493947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "130b1c7786328bf8f4ebea56e6d2f1cb992404ab",
            "isKey": false,
            "numCitedBy": 208,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "In his original paper on the subject, Shannon found upper and lower bounds for the entropy of printed English based on the number of trials required for a subject to guess subsequent symbols in a given text. The guessing approach precludes asymptotic consistency of either the upper or lower bounds except for degenerate ergodic processes. Shannon's technique of guessing the next symbol is altered by having the subject place sequential bets on the next symbol of text. If S_{n} denotes the subject's capital after n bets at 27 for 1 odds, and if it is assumed that the subject knows the underlying probability distribution for the process X , then the entropy estimate is \\hat{H}_{n}(X)=(1-(1/n) \\log_{27}S_{n}) \\log_{2} 27 bits/symbol. If the subject does not know the true probability distribution for the stochastic process, then \\hat{H}_{n}(X) is an asymptotic upper bound for the true entropy. If X is stationary, E\\hat{H}_{n}(X)\\rightarrowH(X), H(X) being the true entropy of the process. Moreover, if X is ergodic, then by the Shannon-McMillan-Breiman theorem \\hat{H}_{n}(X)\\rightarrowH(X) with probability one. Preliminary indications are that English text has an entropy of approximately 1.3 bits/symbol, which agrees well with Shannon's estimate. In his original paper on the subject, Shannon found upper and lower bounds for the entropy of printed English based on the number of trials required for a subject to guess subsequent symbols in a given text. The guessing approach precludes asymptotic consistency of either the upper or lower bounds except for degenerate ergodic processes. Shannon's technique of guessing the next symbol is altered by having the subject place sequential bets on the next symbol of text. If S_{n} denotes the subject's capital after n bets at 27 for 1 odds, and if it is assumed that the subject knows the underlying probability distribution for the process X , then the entropy estimate is \\hat{H}_{n}(X)=(1-(1/n) \\log_{27}S_{n}) \\log_{2} 27 bits/symbol. If the subject does not know the true probability distribution for the stochastic process, then \\hat{H}_{n}(X) is an asymptotic upper bound for the true entropy. If X is stationary, E\\hat{H}_{n}(X)\\rightarrowH(X), H(X) being the true entropy of the process. Moreover, if X is ergodic, then by the Shannon-McMillan-Breiman theorem \\hat{H}_{n}(X)\\rightarrowH(X) with probability one. Preliminary indications are that English text has an entropy of approximately 1.3 bits/symbol, which agrees well with Shannon's estimate. In his original paper on the subject, Shannon found upper and lower bounds for the entropy of printed English based on the number of trials required for a subject to guess subsequent symbols in a given text. The guessing approach precludes asymptotic consistency of either the upper or lower bounds except for degenerate ergodic processes. Shannon's technique of guessing the next symbol is altered by having the subject place sequential bets on the next symbol of text. If S_{n} denotes the subject's capital after n bets at 27 for 1 odds, and if it is assumed that the subject knows the underlying probability distribution for the process X , then the entropy estimate is \\hat{H}_{n}(X)=(1-(1/n) \\log_{27}S_{n}) \\log_{2} 27 bits/symbol. If the subject does not know the true probability distribution for the stochastic process, then \\hat{H}_{n}(X) is an asymptotic upper bound for the true entropy. If X is stationary, E\\hat{H}_{n}(X)\\rightarrowH(X), H(X) being the true entropy of the process.Moreover, if X is ergodic, then by the Shannon-McMillan-Breiman theorem \\hat{H}_{n}(X)\\rightarrowH(X) with probability one. Preliminary indications are that English text has an entropy of approximately 1.3 bits/symbol, which agrees well with Shannon's estimate. In his original paper on the subject, Shannon found upper and lower bounds for the entropy of printed English based on the number of trials required for a subject to guess subsequent symbols in a given text. The guessing approach precludes asymptotic consistency of either the upper or lower bounds except for degenerate ergodic processes. Shannon's technique of guessing the next symbol is altered by having the subject place sequential bets on the next symbol of text. If S_{n} denotes the subject's capital after n bets at 27 for 1 odds, and if it is assumed that the subject knows the underlying probability distribution for the process X , then the entropy estimate is \\hat{H}_{n}(X)=(1-(1/n) \\log_{27}S_{n}) \\log_{2} 27 bits/symbol. If the subject does not know the true probability distribution for the stochastic process, then \\hat{H}_{n}(X) is an asymptotic upper bound for the true entropy. If X is stationary, E\\hat{H}_{n}(X)\\rightarrowH(X), H(X) being the true entropy of the process. Moreover, if X is ergodic, then by the Shannon-McMillan-Breiman theorem \\hat{H}_{n}(X)\\rightarrowH(X) with probability one. Preliminary indications are that English text has an entropy of approximately 1.3 bits/symbol, which agrees well with Shannon's estimate."
            },
            "slug": "A-convergent-gambling-estimate-of-the-entropy-of-Cover-King",
            "title": {
                "fragments": [],
                "text": "A convergent gambling estimate of the entropy of English"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "In his original paper on the subject, Shannon found upper and lower bounds for the entropy of printed English based on the number of trials required for a subject to guess subsequent symbols in a given text by the Shannon-McMillan-Breiman theorem."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144461837"
                        ],
                        "name": "C. Shannon",
                        "slug": "C.-Shannon",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Shannon",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Shannon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "93]) and Shannon-style games ([Shannon 51])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 80
                            }
                        ],
                        "text": "Worse, the quantity H is not directly measurable (though it can be bounded, see Shannon (1951), Cover and King (1978) and Jelinek (1989))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 219
                            }
                        ],
                        "text": "In this work, several different methods were used for doing so, including mutual information (Abramson, 1963), training-set perplexity [perplexity of the training data, see Huang et al. (1993)] and Shannon-style games (Shannon, 1951)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9101213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1e3f2d537e50e0d5263e4731ab6c7983acd6687",
            "isKey": false,
            "numCitedBy": 2530,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of estimating the entropy and redundancy of a language is described. This method exploits the knowledge of the language statistics possessed by those who speak the language, and depends on experimental results in prediction of the next letter when the preceding text is known. Results of experiments in prediction are given, and some properties of an ideal predictor are developed."
            },
            "slug": "Prediction-and-entropy-of-printed-English-Shannon",
            "title": {
                "fragments": [],
                "text": "Prediction and entropy of printed English"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A new method of estimating the entropy and redundancy of a language is described, which exploits the knowledge of the language statistics possessed by those who speak the language, and depends on experimental results in prediction of the next letter when the preceding text is known."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1951
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1866226"
                        ],
                        "name": "W. Ward",
                        "slug": "W.-Ward",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Ward",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Ward"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 47
                            }
                        ],
                        "text": "Another possibility is loose semantic parsing (Ward, 1990, 1991), extracting syntactic-semantic information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17635179,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ab4cd374e1c15842ecc2eb3759c13d0800fc7d8",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The CMU Phoenix system is an experiment in understanding spontaneous speech. It has been implemented for the Air Travel Information Service task. In this task, casual users are asked to obtain information from a database of air travel information. Users are not given a vocabulary, grammar or set of sentences to read. They compose queries themselves in a spontaneous manner. This task presents speech recognizers with many new problems compared to the Resource Management task. Not only is the speech not fluent, but the vocabulary and grammar are open. Also, the task is not just to produce a transcription, but to produce an action, retrieve data from the database. Taking such actions requires parsing and \"understanding\" the utterance. Word error rate is not as important as utterance understanding rate.Phoenix attempts to deal with phenomena that occur in spontaneous speech. Unknown words, restarts, repeats, and poorly formed or unusual grammar are common is spontaneous speech and are very disruptive to standard recognizers. These events lead to misrecognitions which often cause a total parse failure. Our strategy is to apply grammatical constraints at the phrase level and to use semantic rather than lexical grammars. Semantics provide more constraint than parts of speech and must ultimately be delt with in order to take actions. Applying constraints at the phrase level is more flexible than recognizing sentences as a whole while providing much more constraint than word-spotting. Restarts and repeats are most often between phase occurences, so individual phrases can still be recognized correctly. Poorly constructed grammar often consists of well-formed phrases, and is often semantically well-formed. It is only syntactically incorrect. We associate phrases by frame-based semantics. Phrases represent word strings that can fill slots in frames. The slots represent information which the frame is able to act on.The current Phoenix system uses a bigram language model with the Sphinx speech recognition system. The top-scoring word string is passed to a flexible frame-based parser. The parser assigns phrases (word strings) from the input to slots in frames. The slots represent information content needed for the frame. A beam of frame hypotheses is produced and the best scoring one is used to produce an SQL query."
            },
            "slug": "Evaluation-of-the-CMU-ATIS-System-Ward",
            "title": {
                "fragments": [],
                "text": "Evaluation of the CMU ATIS System"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The CMU Phoenix system is an experiment in understanding spontaneous speech that uses a bigram language model with the Sphinx speech recognition system and applies grammatical constraints at the phrase level and to use semantic rather than lexical grammars."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 10
                            }
                        ],
                        "text": "An N-gram (Bahl et al., 1983) uses the last N-1 words of the history as its sole information source."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 52
                            }
                        ],
                        "text": "Short-term history (conventional N-gram)\nAn N-gram (Bahl et al., 1983) uses the last N-1 words of the history as its sole information source."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 4
                            }
                        ],
                        "text": "See Bahl et al. (1983) for more details."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14789841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4775e2f0d27e8be4aae7b5b5c2560b96ce2eb58",
            "isKey": false,
            "numCitedBy": 1403,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech recognition is formulated as a problem of maximum likelihood decoding. This formulation requires statistical models of the speech production process. In this paper, we describe a number of statistical models for use in speech recognition. We give special attention to determining the parameters for such models from sparse data. We also describe two decoding methods, one appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks. To illustrate the usefulness of the methods described, we review a number of decoding results that have been obtained with them."
            },
            "slug": "A-Maximum-Likelihood-Approach-to-Continuous-Speech-Bahl-Jelinek",
            "title": {
                "fragments": [],
                "text": "A Maximum Likelihood Approach to Continuous Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper describes a number of statistical models for use in speech recognition, with special attention to determining the parameters for such models from sparse data, and describes two decoding methods appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3853032"
                        ],
                        "name": "J. Lai",
                        "slug": "J.-Lai",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Lai",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 61
                            }
                        ],
                        "text": "(3) Data Driven Clustering (Jelinek, 1989: appendices C & D; Brown et al., 1990b;\nKneser & Ney, 1991; Suhm & Waibel, 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10986188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3de5d40b60742e3dfa86b19e7f660962298492af",
            "isKey": false,
            "numCitedBy": 3318,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of predicting a word from previous words in a sample of text. In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words. We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics."
            },
            "slug": "Class-Based-n-gram-Models-of-Natural-Language-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "Class-Based n-gram Models of Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work addresses the problem of predicting a word from previous words in a sample of text and discusses n-gram models based on classes of words, finding that these models are able to extract classes that have the flavor of either syntactically based groupings or semanticallybased groupings, depending on the nature of the underlying statistics."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32326549"
                        ],
                        "name": "J. Kupiec",
                        "slug": "J.-Kupiec",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Kupiec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kupiec"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14679951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "343c8af478f7703459b0e390e888efe723f15e31",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes two complementary models that represent dependencies between words in local and non-local contexts. The type of local dependencies considered are sequences of part of speech categories for words. The non-local context of word dependency considered here is that of word recurrence, which is typical in a text. Both are models of phenomena that are to a reasonable extent domain independent, and thus are useful for doing prediction in systems using large vocabularies."
            },
            "slug": "Probabilistic-Models-of-Short-and-Long-Distance-in-Kupiec",
            "title": {
                "fragments": [],
                "text": "Probabilistic Models of Short and Long Distance Word Dependencies in Running Text"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "Two complementary models that represent dependencies between words in local and non-local contexts are described, which are useful for doing prediction in systems using large vocabularies."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795942"
                        ],
                        "name": "Reinhard Kneser",
                        "slug": "Reinhard-Kneser",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Kneser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Reinhard Kneser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 10
                            }
                        ],
                        "text": "Recently, Kneser and Ney (1995) used a similar observation to motivate their own modification to the backoff scheme, with similar results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9685476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9548ac30c113562a51e603dbbc8e9fa651cfd3ab",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In stochastic language modeling, backing-off is a widely used method to cope with the sparse data problem. In case of unseen events this method backs off to a less specific distribution. In this paper we propose to use distributions which are especially optimized for the task of backing-off. Two different theoretical derivations lead to distributions which are quite different from the probability distributions that are usually used for backing-off. Experiments show an improvement of about 10% in terms of perplexity and 5% in terms of word error rate."
            },
            "slug": "Improved-backing-off-for-M-gram-language-modeling-Kneser-Ney",
            "title": {
                "fragments": [],
                "text": "Improved backing-off for M-gram language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes to use distributions which are especially optimized for the task of back-off, which are quite different from the probability distributions that are usually used for backing-off."
            },
            "venue": {
                "fragments": [],
                "text": "1995 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145631743"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "Janet",
                            "lastName": "Baker",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2618014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8648dbfff9662fa9c62a95622712dd2951b5b3a3",
            "isKey": false,
            "numCitedBy": 1278,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The DARPA Spoken Language System (SLS) community has long taken a leadership position in designing, implementing, and globally distributing significant speech corpora widely used for advancing speech recognition research. The Wall Street Journal (WSJ) CSR Corpus described here is the newest addition to this valuable set of resources. In contrast to previous corpora, the WSJ corpus will provide DARPA its first general-purpose English, large vocabulary, natural language, high perplexity, corpus containing significant quantities of both speech data (400 hrs.) and text data (47M words), thereby providing a means to integrate speech recognition and natural language processing in application domains with high potential practical value. This paper presents the motivating goals, acoustic data design, text processing steps, lexicons, and testing paradigms incorporated into the multi-faceted WSJ CSR Corpus."
            },
            "slug": "The-Design-for-the-Wall-Street-Journal-based-CSR-Paul-Baker",
            "title": {
                "fragments": [],
                "text": "The Design for the Wall Street Journal-based CSR Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents the motivating goals, acoustic data design, text processing steps, lexicons, and testing paradigms incorporated into the multi-faceted WSJ CSR Corpus, a corpus containing significant quantities of both speech data and text data."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785148"
                        ],
                        "name": "F. Kubala",
                        "slug": "F.-Kubala",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Kubala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kubala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748407"
                        ],
                        "name": "J. Bellegarda",
                        "slug": "J.-Bellegarda",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Bellegarda",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bellegarda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670760"
                        ],
                        "name": "Jordan Cohen",
                        "slug": "Jordan-Cohen",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jordan Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786370"
                        ],
                        "name": "D. Pallett",
                        "slug": "D.-Pallett",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pallett",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pallett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070362866"
                        ],
                        "name": "Mike Phillips",
                        "slug": "Mike-Phillips",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Phillips",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809498"
                        ],
                        "name": "R. Rajasekaran",
                        "slug": "R.-Rajasekaran",
                        "structuredName": {
                            "firstName": "Raja",
                            "lastName": "Rajasekaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rajasekaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145625133"
                        ],
                        "name": "F. Richardson",
                        "slug": "F.-Richardson",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Richardson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Richardson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428168"
                        ],
                        "name": "M. Riley",
                        "slug": "M.-Riley",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Riley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057273535"
                        ],
                        "name": "Bob Roth",
                        "slug": "Bob-Roth",
                        "structuredName": {
                            "firstName": "Bob",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bob Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744182"
                        ],
                        "name": "M. Weintraub",
                        "slug": "M.-Weintraub",
                        "structuredName": {
                            "firstName": "Mitch",
                            "lastName": "Weintraub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Weintraub"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6941365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86c939c553edeb4f5e040ae4d4d4578e118a7d9c",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we introduce the new paradigm used in the most recent ARPA-sponsored Continuous Speech Recognition (CSR) evaluation and then discuss the important features of the test design.The 1993 CSR evaluation was organized in a novel fashion in an attempt to accomodate research over a broad variety of important problems in CSR while maintaining a clear program-wide research focus. Furthermore, each test component in the evaluation was designed as an experiment to extract as much information as possible from the results.The evaluation was centered around a large vocabulary speaker-independent (SI) baseline test, which was required of every participating site. This test was dubbed the 'Hub' since it was common to all sites and formed the basis for controlled inter-system comparisons.The Hub test was augmented with a variety of problem-specific optional tests designed to explore a variety of important problems in CSR, mostly involving some kind of mismatch between the training and test conditions. These tests were known as the 'Spokes' since they all could be informatively compared to the Hub, but were otherwise independent.In the first trial of this evaluation paradigm in November, 1993, 11 research groups participated, yielding a rich array of comparative and contrastive results, all calibrated to the current state of the art in large vocabulary CSR."
            },
            "slug": "The-Hub-and-Spoke-Paradigm-for-CSR-Evaluation-Kubala-Bellegarda",
            "title": {
                "fragments": [],
                "text": "The Hub and Spoke Paradigm for CSR Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "The new paradigm used in the most recent ARPA-sponsored Continuous Speech Recognition (CSR) evaluation is introduced and then the important features of the test design are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2687013"
                        ],
                        "name": "A. Derouault",
                        "slug": "A.-Derouault",
                        "structuredName": {
                            "firstName": "Anne-Marie",
                            "lastName": "Derouault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Derouault"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686820"
                        ],
                        "name": "B. M\u00e9rialdo",
                        "slug": "B.-M\u00e9rialdo",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "M\u00e9rialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. M\u00e9rialdo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 3173459,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "85da46e840ab8ea85759f4308aa195bde2aaadab",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper relates different kinds of language modeling methods that can be applied to the linguistic decoding part of a speech recognition system with a very large vocabulary. These models are studied experimentally on a pseudophonetic input arising from French stenotypy. We propose a model which combines the advantages of a statistical modeling with information theoretic tools, and those of a grammatical approach."
            },
            "slug": "Natural-Language-Modeling-for-Phoneme-to-Text-Derouault-M\u00e9rialdo",
            "title": {
                "fragments": [],
                "text": "Natural Language Modeling for Phoneme-to-Text Transcription"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper relates different kinds of language modeling methods that can be applied to the linguistic decoding part of a speech recognition system with a very large vocabulary and proposes a model which combines the advantages of a statistical modeling with information theoretic tools, and those of a grammatical approach."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70444551"
                        ],
                        "name": "X. Alleva",
                        "slug": "X.-Alleva",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Alleva",
                            "middleNames": [
                                "Huang",
                                "E"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Alleva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62001836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fd5d338e98282071d2e7f152709cc286938b212",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This 'paper presents improvements in acoustic and language modeling for automatic speech recognition. Specifically, semi-continuous HMMs (SCHMMs) with phonedependent VQ codehooks are presented and incorporated into the SPHINX-IIspeech recognition system. The phonedependent VQ codebooks relax the density-tying constraint in SCHMMs in order to obtain more detailed models. A 6%' error rate reduction was achieved on the speakerindependent 20,000-word Wall Street Journal (WSJ) task. Dynamic adaptation of the language model in the context of long documents is also explored. A maximum entropy framework is used to exploit long distance trigrams and trigger effects. A 10% -- 15% word error rate reduction is reported on the same WSJ task using the adaptive language modeling technique."
            },
            "slug": "Improving-Speech-Recognition-Performance-via-VQ-and-Alleva",
            "title": {
                "fragments": [],
                "text": "Improving Speech Recognition Performance via Phone-Dependent VQ Codebooks and Adaptive Language Models in SPHINX-I1 M. Hwang R. Rosenfeld E. Thayer R. Mosur L. Chase R. Weide"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "Improvements in acoustic and language modeling for automatic speech recognition are presented and semi-continuous HMMs (SCHMMs) with phonedependent VQ codehooks are incorporated into the SPHINX-IIspeech recognition system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793475"
                        ],
                        "name": "A. Ratnaparkhi",
                        "slug": "A.-Ratnaparkhi",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ratnaparkhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ratnaparkhi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2046487"
                        ],
                        "name": "Jeffrey C. Reynar",
                        "slug": "Jeffrey-C.-Reynar",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Reynar",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey C. Reynar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 129886,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "00f20179b9087fbf24b6656008a9380c590d9ec9",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A parser for natural language must often choose between two or more equally grammatical parses for the same sentence. Often the correct parse can be determined from the lexical properties of certain key words or from the context in which the sentence occurs. For example in the sentence."
            },
            "slug": "A-Maximum-Entropy-Model-for-Prepositional-Phrase-Ratnaparkhi-Reynar",
            "title": {
                "fragments": [],
                "text": "A Maximum Entropy Model for Prepositional Phrase Attachment"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A parser for natural language must often choose between two or more equally grammatical parses for the same sentence."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35206065"
                        ],
                        "name": "E. Jaynes",
                        "slug": "E.-Jaynes",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Jaynes",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Jaynes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 168
                            }
                        ],
                        "text": "In this section we discuss an alternative method of combining knowledge sources, which is based on the Maximum Entropy approach advocated by E. T. Jaynes in the 1950\u2019s (Jaynes, 1957)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 36
                            }
                        ],
                        "text": "The Maximum Entropy (ME) Principle (Jaynes, 1957; Kullback, 1959) can be stated as follows."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17870175,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "08b67692bc037eada8d3d7ce76cc70994e7c8116",
            "isKey": false,
            "numCitedBy": 10876,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Treatment of the predictive aspect of statistical mechanics as a form of statistical inference is extended to the density-matrix formalism and applied to a discussion of the relation between irreversibility and information loss. A principle of \"statistical complementarity\" is pointed out, according to which the empirically verifiable probabilities of statistical mechanics necessarily correspond to incomplete predictions. A preliminary discussion is given of the second law of thermodynamics and of a certain class of irreversible processes, in an approximation equivalent to that of the semiclassical theory of radiation."
            },
            "slug": "Information-Theory-and-Statistical-Mechanics-Jaynes",
            "title": {
                "fragments": [],
                "text": "Information Theory and Statistical Mechanics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786370"
                        ],
                        "name": "D. Pallett",
                        "slug": "D.-Pallett",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pallett",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pallett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3241934"
                        ],
                        "name": "J. Fiscus",
                        "slug": "J.-Fiscus",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Fiscus",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fiscus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144982775"
                        ],
                        "name": "W. Fisher",
                        "slug": "W.-Fisher",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Fisher",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2467151"
                        ],
                        "name": "John S. Garofolo",
                        "slug": "John-S.-Garofolo",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Garofolo",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John S. Garofolo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6752118,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "4b04d2f1f7e0d4eb51937e8980b01b5ed8876bd0",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper documents benchmark tests implemented within the DARPA Spoken Language Program during the period November, 1992 - January, 1993. Tests were conducted using the Wall Street Journal-based Continuous Speech Recognition (WSJ-CSR) corpus and the Air Travel Information System (ATIS) corpus collected by the Multi-site ATIS Data COllection Working (MADCOW) Group. The WSJ-CSR tests consist of tests of large vocabulary (lexicons of 5,000 to more than 20,000 words) continuous speech recognition systems. The ATIS tests consist of tests of (1) ATIS-domain spontaneous speech (lexicons typically less than 2,000 words), (2) natural language understanding, and (3) spoken language understanding. These tests were reported on and discussed in detail at the Spoken Language Systems Technology Workshop held at the Massachusetts Institute of Technology, January 20-22, 1993."
            },
            "slug": "Benchmark-Tests-for-the-DARPA-Spoken-Language-Pallett-Fiscus",
            "title": {
                "fragments": [],
                "text": "Benchmark Tests for the DARPA Spoken Language Program"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "These tests were reported on and discussed in detail at the Spoken Language Systems Technology Workshop held at the Massachusetts Institute of Technology, January 20-22, 1993."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48892185"
                        ],
                        "name": "J. Teahan",
                        "slug": "J.-Teahan",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Teahan",
                            "middleNames": [
                                "K"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Teahan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752317"
                        ],
                        "name": "J. Cleary",
                        "slug": "J.-Cleary",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cleary",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cleary"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6633939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d36910319d11359b995ff5413696aa9e9995e163",
            "isKey": false,
            "numCitedBy": 369,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "\\A new data structure for cumulative probability tables\". Soft-\\The zero-frequency problem: estimating the probabilities of novel events in adaptive text compression\"."
            },
            "slug": "\\self-organized-Language-Modeling-for-Speech-In-Teahan-Cleary",
            "title": {
                "fragments": [],
                "text": "\\self-organized Language Modeling for Speech Recognition\". In"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The zero-frequency problem: estimating the probabilities of novel events in adaptive text compression and a new data structure for cumulative probability tables are studied."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705598"
                        ],
                        "name": "B. Suhm",
                        "slug": "B.-Suhm",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Suhm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Suhm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 102
                            }
                        ],
                        "text": "(3) Data Driven Clustering (Jelinek, 1989: appendices C & D; Brown et al., 1990b;\nKneser & Ney, 1991; Suhm & Waibel, 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10312477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9dd1e37157df40356c4c7cbcf73d4f736b0c5715",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In our eeort to build a speech{to{speech translation system for spontaneous spoken dialogs we have developed several methods to improve the language models of the speech decoder of the system. We attempt to take advantage of natural equivalence word classes, frequently occur-ing word phrases, and discourse structure. Each of these methods was tested on spontaneous English, German and Spanish human{human dialogs."
            },
            "slug": "Towards-better-language-models-for-spontaneous-Suhm-Waibel",
            "title": {
                "fragments": [],
                "text": "Towards better language models for spontaneous speech"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "Several methods to improve the language models of the speech decoder of thespeech translation system for spontaneous spoken dialogs attempt to take advantage of natural equivalence word classes, frequently occur-ing word phrases, and discourse structure."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786370"
                        ],
                        "name": "D. Pallett",
                        "slug": "D.-Pallett",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pallett",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pallett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3241934"
                        ],
                        "name": "J. Fiscus",
                        "slug": "J.-Fiscus",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Fiscus",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fiscus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144982775"
                        ],
                        "name": "W. Fisher",
                        "slug": "W.-Fisher",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Fisher",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2467151"
                        ],
                        "name": "John S. Garofolo",
                        "slug": "John-S.-Garofolo",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Garofolo",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John S. Garofolo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061874374"
                        ],
                        "name": "Bruce A. Lund",
                        "slug": "Bruce-A.-Lund",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lund",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bruce A. Lund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2282719"
                        ],
                        "name": "Mark A. Przybocki",
                        "slug": "Mark-A.-Przybocki",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Przybocki",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark A. Przybocki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "94], [Pallet et al. 94], [Hwang et al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 30485956,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "71a286f8e6eeb611bd216f07bb749d3cc04ed2b7",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports results obtained in benchmark tests conducted within the ARPA Spoken Language program in November and December of 1993. In addition to ARPA contractors, participants included a number of \"volunteers\", including foreign participants from Canada, France, Germany, and the United Kingdom. The body of the paper is limited to an outline of the structure of the tests and presents highlights and discussion of selected results. Detailed tabulations of reported \"official\" results, and additional explanatory text appears in the Appendix."
            },
            "slug": "1993-Benchmark-Tests-for-the-ARPA-Spoken-Language-Pallett-Fiscus",
            "title": {
                "fragments": [],
                "text": "1993 Benchmark Tests for the ARPA Spoken Language Program"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This paper reports results obtained in benchmark tests conducted within the ARPA Spoken Language program in November and December of 1993, including foreign participants from Canada, France, Germany, and the United Kingdom."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144461837"
                        ],
                        "name": "C. Shannon",
                        "slug": "C.-Shannon",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Shannon",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Shannon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "According to Shannon\u2019s theorem ([Shannon 48]), any encoding of L must use at least H bits per word, on average."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 31
                            }
                        ],
                        "text": "According to Shannon\u2019s theorem (Shannon, 1948), any encoding of L must use at least H bits per word, on average."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 55379485,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a54194422c56399b2923b2ad706b8175c8c48258",
            "isKey": false,
            "numCitedBy": 34823,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "In this final installment of the paper we consider the case where the signals or the messages or both are continuously variable, in contrast with the discrete nature assumed until now. To a considerable extent the continuous case can be obtained through a limiting process from the discrete case by dividing the continuum of messages and signals into a large but finite number of small regions and calculating the various parameters involved on a discrete basis. As the size of the regions is decreased these parameters in general approach as limits the proper values for the continuous case. There are, however, a few new effects that appear and also a general change of emphasis in the direction of specialization of the general results to particular cases."
            },
            "slug": "A-mathematical-theory-of-communication-Shannon",
            "title": {
                "fragments": [],
                "text": "A mathematical theory of communication"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This final installment of the paper considers the case where the signals or the messages or both are continuously variable, in contrast with the discrete nature assumed until now."
            },
            "venue": {
                "fragments": [],
                "text": "MOCO"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144531812"
                        ],
                        "name": "Xuedong Huang",
                        "slug": "Xuedong-Huang",
                        "structuredName": {
                            "firstName": "Xuedong",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuedong Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47429521"
                        ],
                        "name": "F. Alleva",
                        "slug": "F.-Alleva",
                        "structuredName": {
                            "firstName": "Fil",
                            "lastName": "Alleva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Alleva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144091892"
                        ],
                        "name": "M. Hwang",
                        "slug": "M.-Hwang",
                        "structuredName": {
                            "firstName": "Mei-Yuh",
                            "lastName": "Hwang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hwang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 41
                            }
                        ],
                        "text": "For example, in Section 2.4 we discussed Huang et al. (1993a), and reported our conclusion that a significant amount of information exists in long-distance bigrams, up to distance 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 15
                            }
                        ],
                        "text": "4 we discussed Huang et al. (1993a), and reported our conclusion that a significant amount of information exists in long-distance bigrams, up to distance 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 82
                            }
                        ],
                        "text": "The previous section discusses the experiment on longdistance bigrams reported in Huang et al. (1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 173
                            }
                        ],
                        "text": "In this work, several different methods were used for doing so, including mutual information (Abramson, 1963), training-set perplexity [perplexity of the training data, see Huang et al. (1993)] and Shannon-style games (Shannon, 1951)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 3
                            }
                        ],
                        "text": "In Huang et al. (1993a) we attempted to estimate the amount of information in longdistance bigrams."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 82
                            }
                        ],
                        "text": "The previous section discusses the experiment on longdistance bigrams reported in Huang et al. (1993). As mentioned, training-set perplexity was found to be low for the conventional bigram (d=1), and to increase significantly as one moved through d=2, 3, 4 and 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32276,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "5d0824748a096482f1bc33664d1b91710c54cb05",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In the past year at Carnegie Mellon steady progress has been made in the area of acoustic and language modeling. The result has been a dramatic reduction in speech recognition errors in the SPHINX-II system. In this paper, we review SPHINX-II and summarize our recent efforts on improved speech recognition. Recently SPHINX-II achieved the lowest error rate in the November 1992 DARPA evaluations. For 5000-word, speaker-independent, continuous, speech recognition, the error rate was reduced to 5%."
            },
            "slug": "An-Overview-of-the-SPHINX-II-Speech-Recognition-Huang-Alleva",
            "title": {
                "fragments": [],
                "text": "An Overview of the SPHINX-II Speech Recognition System"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The SPHINX-II system, which achieved the lowest error rate in the November 1992 DARPA evaluations, is reviewed and recent efforts on improved speech recognition are summarized."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781325"
                        ],
                        "name": "J. Daugman",
                        "slug": "J.-Daugman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Daugman",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Daugman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 137
                            }
                        ],
                        "text": "A good measure of the expected benefit provided by A0 in predicting B is the average mutual information between the two (see for example Abramson, 1963: p. 106):\nI(A0: B)=P(A0, B) log P(B|A0)\nP(B) +P(A0, B) log P(B|A0) P(B\u0304)\n+P(A0, B) log P(B|A0)\nP(B) +P(A0, B) log P(B|A0) P(B\u0304)\n(5)\nIn a related\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 93
                            }
                        ],
                        "text": "In this work, several different methods were used for doing so, including mutual information (Abramson, 1963), training-set perplexity [perplexity of the training data, see Huang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 94
                            }
                        ],
                        "text": "In this work, several different methods were used for doing so, including mutual information (Abramson, 1963), training-set perplexity [perplexity of the training data, see Huang et al. (1993)] and Shannon-style games (Shannon, 1951). See Rosenfeld (1994b) for more details."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 94
                            }
                        ],
                        "text": "In this work, several different methods were used for doing so, including mutual information (Abramson, 1963), training-set perplexity [perplexity of the training data, see Huang et al. (1993)] and Shannon-style games (Shannon, 1951)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 48
                            }
                        ],
                        "text": "Language is considered an information source L (Abramson, 1963), which emits a sequence of symbols wi from a finite alphabet (the vocabulary)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1477649,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "2038e45ef000eeab67ea987d9f148ab13aa0e4b4",
            "isKey": true,
            "numCitedBy": 434,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Introducing a new hobby for other people may inspire them to join with you. Reading, as one of mutual hobby, is considered as the very easy hobby to do. But, many people are not interested in this hobby. Why? Boring is the reason of why. However, this feel actually can deal with the book and time of you reading. Yeah, one that we will refer to break the boredom in reading is choosing information theory and coding as the reading material."
            },
            "slug": "Information-Theory-and-Coding-Daugman",
            "title": {
                "fragments": [],
                "text": "Information Theory and Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "One that the authors will refer to break the boredom in reading is choosing information theory and coding as the reading material."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1866226"
                        ],
                        "name": "W. Ward",
                        "slug": "W.-Ward",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Ward",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Ward"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18001615,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6bb6a722041f5744d440ef47c7b5cd87ddf9f702",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Understanding spontaneous speech presents several problems not found in processing read speech input. Spontaneous speech is often not fluent. It contains stutters, filled pauses, restarts, repeats, interjections, etc. Casual users do not know the lexicon and grammar used by the system. It is therefore very difficult for a speech understanding system to achieve good coverage of the lexicon and grammar that subjects might use."
            },
            "slug": "The-CMU-Air-Travel-Information-Service:-Spontaneous-Ward",
            "title": {
                "fragments": [],
                "text": "The CMU Air Travel Information Service: Understanding Spontaneous Speech"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Understanding spontaneous speech presents several problems not found in processing read speech input, and it is very difficult for a speech understanding system to achieve good coverage of the lexicon and grammar that subjects might use."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 48
                            }
                        ],
                        "text": "An Estimation\u2013Maximization (EM) type algorithm (Dempster et al., 1977) is typically used to determine these weights. The result is a set of weights that is provably optimal with regard to the data used for its optimization. See Jelinek and Mercer (1980) for more details, and Rosenfeld (1994b) for further exposition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 47
                            }
                        ],
                        "text": "An Estimation\u2013Maximization (EM) type algorithm (Dempster et al., 1977) is typically used to determine these weights."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144531812"
                        ],
                        "name": "Xuedong Huang",
                        "slug": "Xuedong-Huang",
                        "structuredName": {
                            "firstName": "Xuedong",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuedong Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47429521"
                        ],
                        "name": "F. Alleva",
                        "slug": "F.-Alleva",
                        "structuredName": {
                            "firstName": "Fil",
                            "lastName": "Alleva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Alleva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145058181"
                        ],
                        "name": "H. Hon",
                        "slug": "H.-Hon",
                        "structuredName": {
                            "firstName": "Hsiao-Wuen",
                            "lastName": "Hon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144091892"
                        ],
                        "name": "M. Hwang",
                        "slug": "M.-Hwang",
                        "structuredName": {
                            "firstName": "Mei-Yuh",
                            "lastName": "Hwang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hwang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 3
                            }
                        ],
                        "text": "In [Huang et al. 93] we attempted to estimate the amount of information in long-distance bigrams."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 15
                            }
                        ],
                        "text": "4 we discussed [Huang et al. 93], and reported our conclusion that a significant amount of information exists in long-distance bigrams, up to distance 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 41
                            }
                        ],
                        "text": "For example, in Section 2.4 we discussed Huang et al. (1993a), and reported our conclusion that a significant amount of information exists in long-distance bigrams, up to distance 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 83
                            }
                        ],
                        "text": "The previous section discusses the experiment on long-distance bigrams reported in [Huang et al. 93]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 172
                            }
                        ],
                        "text": "In this work, several different methods were used for doing so, including mutual information ([Abramson 63]), training-set perplexity (perplexity of the training data, see [Huang et al. 93]) and Shannon-style games ([Shannon 51])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 26
                            }
                        ],
                        "text": "The version of SPHINX-II ([Huang et al. 93]) used for this experiment had gender-dependent 10K senone acoustic models (see [Huang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 82
                            }
                        ],
                        "text": "The previous section discusses the experiment on longdistance bigrams reported in Huang et al. (1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 173
                            }
                        ],
                        "text": "In this work, several different methods were used for doing so, including mutual information (Abramson, 1963), training-set perplexity [perplexity of the training data, see Huang et al. (1993)] and Shannon-style games (Shannon, 1951)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 3
                            }
                        ],
                        "text": "In Huang et al. (1993a) we attempted to estimate the amount of information in longdistance bigrams."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16717715,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "230c16805ff9129afd37c91ba1509d122ea7573b",
            "isKey": false,
            "numCitedBy": 460,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In order for speech recognizers to deal with increased task perplexity, speaker variation, and environment variation, improved speech recognition is critical. Steady progress has been made along these three dimensions at Carnegie Mellon. In this paper, we review the SPHINX-II speech recognition system and summarize our recent efforts on improved speech recognition."
            },
            "slug": "The-SPHINX-II-speech-recognition-system:-an-Huang-Alleva",
            "title": {
                "fragments": [],
                "text": "The SPHINX-II speech recognition system: an overview"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The SPHINX-II speech recognition system is reviewed and recent efforts on improved speech recognition are summarized."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48258694"
                        ],
                        "name": "P. Price",
                        "slug": "P.-Price",
                        "structuredName": {
                            "firstName": "Patti",
                            "lastName": "Price",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Price"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 36
                            }
                        ],
                        "text": "(2) Clustering by Domain Knowledge (Price, 1990)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "(1) Generalized Iterative Scaling is computationally very expensive [for more on this problem, and on methods for coping with it, see Rosenfeld (1994b): section 5."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3047811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8df509919b31397e225280962c59384fbe83144e",
            "isKey": false,
            "numCitedBy": 426,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Progress can be measured and encouraged via standards for comparison and evaluation. Though qualitative assessments can be useful in initial stages, quantifiable measures of systems under the same conditions are essential for comparing results and assessing claims. This paper will address the emerging standards for evaluation of spoken language systems."
            },
            "slug": "Evaluation-of-Spoken-Language-Systems:-the-ATIS-Price",
            "title": {
                "fragments": [],
                "text": "Evaluation of Spoken Language Systems: the ATIS Domain"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper will address the emerging standards for evaluation of spoken language systems with quantifiable measures essential for comparing results and assessing claims."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 41
                            }
                        ],
                        "text": "For example, in Section 2.4 we discussed Huang et al. (1993a), and reported our conclusion that a significant amount of information exists in long-distance bigrams, up to distance 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 83
                            }
                        ],
                        "text": "93]) used for this experiment had gender-dependent 10K senone acoustic models (see [Huang et al. 93c])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 82
                            }
                        ],
                        "text": "The previous section discusses the experiment on longdistance bigrams reported in Huang et al. (1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 173
                            }
                        ],
                        "text": "In this work, several different methods were used for doing so, including mutual information (Abramson, 1963), training-set perplexity [perplexity of the training data, see Huang et al. (1993)] and Shannon-style games (Shannon, 1951)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 3
                            }
                        ],
                        "text": "In Huang et al. (1993a) we attempted to estimate the amount of information in longdistance bigrams."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "published as Human Language Technology"
            },
            "venue": {
                "fragments": [],
                "text": "pages 81\u201386. Morgan Kaufmann, March"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 23
                            }
                        ],
                        "text": "In our second attempt ([Rosenfeld and Huang 92]), we combined evidence from multiple triggers using several variants of linear interpolation, then interpolated the result with a conventional backoff trigram."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 39
                            }
                        ],
                        "text": "As another, more detailed, example, in [Rosenfeld and Huang 92] we report on our early work on trigger models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 41
                            }
                        ],
                        "text": "This problem was discussed and solved in [Rosenfeld and Huang 92], and the solution used in a speech recognition system in [Chase et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "published by Morgan Kaufmann"
            },
            "venue": {
                "fragments": [],
                "text": "pages 107\u2013111, February"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145179124"
                        ],
                        "name": "I. Good",
                        "slug": "I.-Good",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Good",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Good"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 123298174,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "602084417015618f112c796828786a6af72bf7d9",
            "isKey": false,
            "numCitedBy": 412,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Maximum-Entropy-for-Hypothesis-Formulation,-for-Good",
            "title": {
                "fragments": [],
                "text": "Maximum Entropy for Hypothesis Formulation, Especially for Multidimensional Contingency Tables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49223598"
                        ],
                        "name": "J. Darroch",
                        "slug": "J.-Darroch",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Darroch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Darroch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12360582"
                        ],
                        "name": "D. Ratcliff",
                        "slug": "D.-Ratcliff",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Ratcliff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ratcliff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120862597,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "37c931cbaa9217b829596dd196520a838562a109",
            "isKey": false,
            "numCitedBy": 1329,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generalized-Iterative-Scaling-for-Log-Linear-Models-Darroch-Ratcliff",
            "title": {
                "fragments": [],
                "text": "Generalized Iterative Scaling for Log-Linear Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 4
                            }
                        ],
                        "text": "See Jelinek and Mercer (1980) for more details, and Rosenfeld (1994b) for further exposition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61012010,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a923c9f89ed53b6e835b3807c0c1bd8d532687b",
            "isKey": false,
            "numCitedBy": 1037,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Interpolated-estimation-of-Markov-source-parameters-Jelinek",
            "title": {
                "fragments": [],
                "text": "Interpolated estimation of Markov source parameters from sparse data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59710768,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6d096d6fa1b39aeeca0a9114b3b3ecdeb960a38",
            "isKey": false,
            "numCitedBy": 230,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Self-organizing-language-modeling-for-speech-Jelinek",
            "title": {
                "fragments": [],
                "text": "Self-organizing language modeling for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2167881"
                        ],
                        "name": "L. Chase",
                        "slug": "L.-Chase",
                        "structuredName": {
                            "firstName": "Lin",
                            "lastName": "Chase",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Chase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "Ronald Rosenfeld",
                        "slug": "Ronald-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1866226"
                        ],
                        "name": "W. Ward",
                        "slug": "W.-Ward",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Ward",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Ward"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 125
                            }
                        ],
                        "text": "This problem was discussed and solved in Rosenfeld and Huang (1992), and the solution used in a speech recognition system in Chase et al. (1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28913788,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "141930fe8fab5c298091f91731f8fb247f9ff9ca",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Error-responsive-modifications-to-speech-negative-Chase-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Error-responsive modifications to speech recognizers: negative n-grams"
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143937779"
                        ],
                        "name": "R. Kuhn",
                        "slug": "R.-Kuhn",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Kuhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kuhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714393"
                        ],
                        "name": "R. Mori",
                        "slug": "R.-Mori",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Mori",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mori"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42004750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da07676ba55662ba37b2cef3e8305409682b8a0a",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Corrections-to-\"A-Cache-Based-Language-Model-for-Kuhn-Mori",
            "title": {
                "fragments": [],
                "text": "Corrections to \"A Cache-Based Language Model for Speech Recognition\""
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145179124"
                        ],
                        "name": "I. Good",
                        "slug": "I.-Good",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Good",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Good"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 58
                            }
                        ],
                        "text": "For example, we may choose to use Good\u2013Turing discounting (Good, 1953) (as we have indeed done in this work), or else the constraints may be derived from other data, or be externally imposed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11945361,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b2986b25f50babd536dd0ecf2237d9eabf5843c2",
            "isKey": false,
            "numCitedBy": 3274,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-POPULATION-FREQUENCIES-OF-SPECIES-AND-THE-OF-Good",
            "title": {
                "fragments": [],
                "text": "THE POPULATION FREQUENCIES OF SPECIES AND THE ESTIMATION OF POPULATION PARAMETERS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1953
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 72
                            }
                        ],
                        "text": "The Maximum Entropy principle was first applied to language modeling by [DellaPietra et al. 92]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 29
                            }
                        ],
                        "text": "In a precursor to this work, [DellaPietra et al. 92] used the history of a document to construct a unigram."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages I-633\u2013636"
            },
            "venue": {
                "fragments": [],
                "text": "San Francisco, March 1992. Also published in Proceedings of the DARPA Workshop on Speech and Natural Language, Morgan Kaufmann, pages 103\u2013106, February"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Personal communication Benchmark Tests for the ARPA spoken Language Program"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the ARPA Workshop on Human Language Technology"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 48
                            }
                        ],
                        "text": "This has been tried, with moderate success only [Lau et al. 93b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 52
                            }
                        ],
                        "text": "This has been tried, with moderate success only, by Lau et al. (1993b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "published as Human Language Technology"
            },
            "venue": {
                "fragments": [],
                "text": "pages 108\u2013113. Morgan Kaufmann, March"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Xuedong Huang and Fil Alleva. Improved Acoustic and Adaptive Language Models for Continuous Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the ARPA Spoken Language Technologies Workshop"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improved Acoustic and Adaptive Language Models for ContinuousSpeech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mercer and Salim Roukos"
            },
            "venue": {
                "fragments": [],
                "text": "Personal communication."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Xuedong Huang and Fil Alleva. Improved Acoustic and Adaptive Language Models for ContinuousSpeech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the ARPA Spoken Language Technologies Workshop"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 48
                            }
                        ],
                        "text": "Language is considered an information source L ([Abramson 63]), which emits a sequence of symbols wi from a finite alphabet (the vocabulary)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 94
                            }
                        ],
                        "text": "In this work, several different methods were used for doing so, including mutual information ([Abramson 63]), training-set perplexity (perplexity of the training data, see [Huang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "McGraw-Hill"
            },
            "venue": {
                "fragments": [],
                "text": "New-York,"
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 23
                            }
                        ],
                        "text": "Often, the perplexity (Jelinek et al., 1977) of the text with regard to the model is reported."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perplexity \u2014 a measure of di ffi culty of speech recognition tasks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 63
                            }
                        ],
                        "text": "But in much smaller tasks it could be employed (see forexample [Ratnaparkhi and Roukos 94])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 242\u2013 242e"
            },
            "venue": {
                "fragments": [],
                "text": "March"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Correction to a cache-based natural language model for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1.8 million sentences (only 2 sentences/paragraph, on average)"
            },
            "venue": {
                "fragments": [],
                "text": "1.8 million sentences (only 2 sentences/paragraph, on average)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The most frequent trigram in the training data occurred 14,283 times. It was: <s> IN THE References [Abramson 63] Norman Abramson. Information Theory and Coding"
            },
            "venue": {
                "fragments": [],
                "text": "The most frequent trigram in the training data occurred 14,283 times. It was: <s> IN THE References [Abramson 63] Norman Abramson. Information Theory and Coding"
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 88
                            }
                        ],
                        "text": "Subsequently, most of the data was further processed by Doug Paul at MIT\u2019s Lincoln Labs [Paul and Baker 92], and conditioned for use in speech recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proceedings of the DARPA SLS Workshop"
            },
            "venue": {
                "fragments": [],
                "text": "February"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 38
                            }
                        ],
                        "text": "A better method was later proposed by Brown et al. (1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum penalized entropy construction of conditional log - linear language and translation models using learned features and a generalized csiszar algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 23
                            }
                        ],
                        "text": "Often, the perplexity (Jelinek et al., 1977) of the text with regard to the model is reported."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perplexity\u2014a measure of difficulty of speech recognition tasks. 94th Meeting of the Acoustic Society"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Following are all the bigrams which occurred more than 65,535 times in the corpus"
            },
            "venue": {
                "fragments": [],
                "text": "Following are all the bigrams which occurred more than 65,535 times in the corpus"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 23
                            }
                        ],
                        "text": "In the backoff method ([Katz 87]), the different information sources are ranked in order of detail or specificity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "volume ASSP-35"
            },
            "venue": {
                "fragments": [],
                "text": "pages 400\u2013401, March"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 61
                            }
                        ],
                        "text": "(3) Data Driven Clustering (Jelinek, 1989: appendices C & D; Brown et al., 1990b;\nKneser & Ney, 1991; Suhm & Waibel, 1994)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mercer . Class - Based Ngram Models of Natural Language"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IBM Natural Language ITL , March"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proceedings of the 1st QUALICO Conference"
            },
            "venue": {
                "fragments": [],
                "text": "Trier, Germany, September"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 21
                            }
                        ],
                        "text": "[Kuhn and De Mori 90][Kuhn and De Mori 90b] employed a POS-based bigram cache to improve the performance of their static bigram."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "volume PAMI-14"
            },
            "venue": {
                "fragments": [],
                "text": "number 6, pages 691\u2013692, June"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Arthur Nadas and Salim Roukos. A Maximum Penalized Entropy Construction of Conditional Log-Linear Language and Translation Models Using Learned Features and a Generalized Csiszar Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Arthur Nadas and Salim Roukos. A Maximum Penalized Entropy Construction of Conditional Log-Linear Language and Translation Models Using Learned Features and a Generalized Csiszar Algorithm"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 4
                            }
                        ],
                        "text": "See [Jelinek and Mercer 80] for more details, and [Rosenfeld 94b] for further exposition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kanal (editors)"
            },
            "venue": {
                "fragments": [],
                "text": "pages 381\u2013402. North Holland, Amsterdam,"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 11
                            }
                        ],
                        "text": "An N-gram ([Bahl et al. 83]) uses the last N-1 words of the history as its sole information source."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 52
                            }
                        ],
                        "text": "Short-term history (conventional N-gram)\nAn N-gram (Bahl et al., 1983) uses the last N-1 words of the history as its sole information source."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 4
                            }
                        ],
                        "text": "See Bahl et al. (1983) for more details."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "volume PAMI-5"
            },
            "venue": {
                "fragments": [],
                "text": "number 2, pages 179\u2013190, March"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "[Kuhn and De Mori 90][Kuhn and De Mori 90b] employed a POS-based bigram cache to improve the performance of their static bigram."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "volume PAMI-12"
            },
            "venue": {
                "fragments": [],
                "text": "number 6, pages 570\u2013583, June"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Volume IT-24"
            },
            "venue": {
                "fragments": [],
                "text": "number 4, pages 413\u2013421, July"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Baker . The Design for the Wall Street Journalbased CSR Corpus"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 76\u201381"
            },
            "venue": {
                "fragments": [],
                "text": "March"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 139
                            }
                        ],
                        "text": "For the special case of constraints derived from marginal probabilities, it is equivalent to assuming a lack of higher-order interactions (Good, 1963)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 138
                            }
                        ],
                        "text": "For the special case of constraints derived from marginal probabilities, it is equivalent to assuming a lack of higher-order interactions [Good 63]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum Entropy for Hypothesis Formulation"
            },
            "venue": {
                "fragments": [],
                "text": "Especially for Multidimensional Contingency Tables. Annals of Mathematical Statistics, Volume 34, pages 911\u2013934"
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood maximum entropy trigger language model"
            },
            "venue": {
                "fragments": [],
                "text": "Bachelor\u2019s Thesis,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rudnicky 94] Alexander Rudnicky. Personal communication"
            },
            "venue": {
                "fragments": [],
                "text": "Rudnicky 94] Alexander Rudnicky. Personal communication"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 61
                            }
                        ],
                        "text": "(3) Data Driven Clustering (Jelinek, 1989: appendices C & D; Brown et al., 1990b;\nKneser & Ney, 1991; Suhm & Waibel, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 76
                            }
                        ],
                        "text": "Data Driven Clustering ([Jelinek 89, appendix C], [Jelinek 89, appendix D], [Brown et al. 90b], [Kneser and Ney 91], [Suhm and Waibel 94])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proceedings of the IBM Natural Language ITL"
            },
            "venue": {
                "fragments": [],
                "text": "March"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Correction to A CacheBased Natural Language Model for Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proceedings of the ARPA Spoken Language Technologies Workshop"
            },
            "venue": {
                "fragments": [],
                "text": "March"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum Likelihood Maximum Entropy Trigger Language Model. Bachelor's Thesis"
            },
            "venue": {
                "fragments": [],
                "text": "Maximum Likelihood Maximum Entropy Trigger Language Model. Bachelor's Thesis"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 38
                            }
                        ],
                        "text": "A better method was later proposed by Brown et al. (1994). Let P(h, w) be the desired probability estimate, and let P\u0303(h, w) be the empirical distribution of the training data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 38
                            }
                        ],
                        "text": "A better method was later proposed by Brown et al. (1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum penalized entropy construction of conditional log-linear language and translation models using learned features and a generalized csiszar algorithm. Unpublished IBM research report"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 10
                            }
                        ],
                        "text": "Recently, Kneser and Ney (1995) used a similar observation to motivate their own modification to the backoff scheme, with similar results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improved smoothing for M-gram language modeling"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Conference on Acoustics, Speech and Signal Processing,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 51
                            }
                        ],
                        "text": "N-gram caches were first reported by [Kuhn 88] and [Kupiec 89]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 290\u2013295"
            },
            "venue": {
                "fragments": [],
                "text": "February"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mercer and Salim Roukos . Personal communication"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Volume PAMI-8"
            },
            "venue": {
                "fragments": [],
                "text": "number 6, pages 742\u2013749, November"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 67
                            }
                        ],
                        "text": "x PT(x) log PM(x) (2) H0(PT; PM) has also been called the logprob ([Jelinek 89])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 101
                            }
                        ],
                        "text": "If the new source is not useful, it will simply be assigned a very small weight by the EM algorithm ([Jelinek 89])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Alex Waibel and Kai-Fu Lee (Editors)"
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages"
            },
            "venue": {
                "fragments": [],
                "text": "101\u2013105, February"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "[Jelinek et al. 91] incorporated a trigram cache into a speech recognizer and reported reduced error rates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 293\u2013295"
            },
            "venue": {
                "fragments": [],
                "text": "February"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 178
                            }
                        ],
                        "text": "To evaluate recognition error rate reduction under the within-domain adaptation paradigm, we used the ARPA CSR (Continuous Speech Recognition) S1 evaluation set of November 1993 (Hwang et al., 1994; Kubala et al., 1994; Pallet et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improved Acoustic and Adaptive Language Models for Continuous Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the ARPA Spoken Language Technologies Workshop,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "38 million words (some 450 words/article, on average"
            },
            "venue": {
                "fragments": [],
                "text": "38 million words (some 450 words/article, on average"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 66
                            }
                        ],
                        "text": "They are very powerful, and surprisingly difficult to improve on (Jelinek, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Up from trigrams! Eurospeech"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A CacheBased Natural Language Model for Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Recognition and the Frequency of Recently Used Words : A Modified Markov Model for Natural Language . 12 th International Conference on Computational Linguistics [ COLING 88 ] , pages 348350 , Budapest , August"
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 25,
            "methodology": 33
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 94,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/A-maximum-entropy-approach-to-adaptive-statistical-Rosenfeld/076fa8d095c37c657f2aff39cf90bc2ea883b7cb?sort=total-citations"
}