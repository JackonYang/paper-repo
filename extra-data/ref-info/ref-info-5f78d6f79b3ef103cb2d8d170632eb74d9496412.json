{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144356748"
                        ],
                        "name": "J. Catlett",
                        "slug": "J.-Catlett",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Catlett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Catlett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5319590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b69e0cce79eb288ffb43ad7ae3b99b8dea9ac5ac",
            "isKey": false,
            "numCitedBy": 1095,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Heterogeneous-Uncertainty-Sampling-for-Supervised-Lewis-Catlett",
            "title": {
                "fragments": [],
                "text": "Heterogeneous Uncertainty Sampling for Supervised Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113685509"
                        ],
                        "name": "Yoav Preund",
                        "slug": "Yoav-Preund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Preund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Preund"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 86
                            }
                        ],
                        "text": "A simple version of QBC, which was analyzed in (Fre-und et al., 1993) (summarized in (Freund, 1994)), usesthe following selection algorithm:1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2810909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92ccb8c1aef61610248e311b8c84e24e86c7f1cc",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss two types of algorithms for selecting relevant examples that have been developed in the context of computation learning theory. The examples are selected out of a stream of examples that are generated independently at random. The first two algorithms are the so-called \"boosting\" algorithms of Sehapire [Schapire, 1990] and Freund [Freund, 1990], and the Query-by-Committee algorithm of Seung [Seung et al., 1992]. We describe the algorithms and some of their proven properties, point to some of their commonalities, and suggest some possible future implications."
            },
            "slug": "Sifting-informative-examples-from-a-random-source.-Preund",
            "title": {
                "fragments": [],
                "text": "Sifting informative examples from a random source."
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "Two types of algorithms for selecting relevant examples that have been developed in the context of computation learning theory are discussed and some of their proven properties are pointed to and some possible future implications are suggested."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1865251"
                        ],
                        "name": "M. Plutowski",
                        "slug": "M.-Plutowski",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Plutowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Plutowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149702798"
                        ],
                        "name": "H. White",
                        "slug": "H.-White",
                        "structuredName": {
                            "firstName": "Halbert",
                            "lastName": "White",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. White"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 139
                            }
                        ],
                        "text": "The rstuses membership queries, in which the learner con-structs examples and asks a teacher to label them (An-gluin, 1988; MacKay, 1992b; Plutowski and White,1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6936422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e06680314e1cf32706686e6520107976fdb7064",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors derive a method for selecting exemplars for training a multilayer feedforward network architecture to estimate an unknown (deterministic) mapping from clean data, i.e., data measured either without error or with negligible error. The objective is to minimize the data requirement of learning. The authors choose a criterion for selecting training examples that works well in conjunction with the criterion used for learning, here, least squares. They proceed sequentially, selecting an example that, when added to the previous set of training examples and learned, maximizes the decrement of network squared error over the input space. When dealing with clean data and deterministic relationships, concise training sets that minimize the integrated squared bias (ISB) are desired. The ISB is used to derive a selection criterion for evaluating individual training examples, the DISB, that is maximized to select new exemplars. They conclude with graphical illustrations of the method, and demonstrate its use during network training. Experimental results indicate that training upon exemplars selected in this fashion can save computation in general purpose use as well."
            },
            "slug": "Selecting-concise-training-sets-from-clean-data-Plutowski-White",
            "title": {
                "fragments": [],
                "text": "Selecting concise training sets from clean data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results indicate that training upon exemplars selected in this fashion can save computation in general purpose use as well, and its use during network training is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686820"
                        ],
                        "name": "B. M\u00e9rialdo",
                        "slug": "B.-M\u00e9rialdo",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "M\u00e9rialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. M\u00e9rialdo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61014458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a9b6828c5e4339025bb78af6b025d21b4830800",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Experiments on the use of a probabilistic model to tag English text, that is, to assign to each word the correct tag (part of speech) in the context of the sentence, are presented. A simple triclass Markov model is used, and the best way to estimate the parameters of this model, depending on the kind and amount of training data that is provided, is found. Two approaches are compared: the use of text that has been tagged by hand and comparing relative frequency counts; and use text without tags and training the model as a hidden Markov process, according to a maximum likelihood principle. Experiments show that the best training is obtained by using as much tagged text as is available, a maximum likelihood training may improve the accuracy of the tagging.<<ETX>>"
            },
            "slug": "Tagging-text-with-a-probabilistic-model-M\u00e9rialdo",
            "title": {
                "fragments": [],
                "text": "Tagging text with a probabilistic model"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experiments show that the best training is obtained by using as much tagged text as is available, and a maximum likelihood training may improve the accuracy of the tagging."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 124
                            }
                        ],
                        "text": "The rstuses membership queries, in which the learner con-structs examples and asks a teacher to label them (An-gluin, 1988; MacKay, 1992b; Plutowski and White,1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 153
                            }
                        ],
                        "text": "Explicit calculation of the expected informa-tion gain, on the other hand, is complex and is spe-ci c to the particular type of classi cation model used(MacKay, 1992b; MacKay, 1992a; Cohn, Ghahramani,and Jordan, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6530745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7abda1941534d3bb558dd959025d67f1df526303",
            "isKey": false,
            "numCitedBy": 792,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Three Bayesian ideas are presented for supervised adaptive classifiers. First, it is argued that the output of a classifier should be obtained by marginalizing over the posterior distribution of the parameters; a simple approximation to this integral is proposed and demonstrated. This involves a \"moderation\" of the most probable classifier's outputs, and yields improved performance. Second, it is demonstrated that the Bayesian framework for model comparison described for regression models in MacKay (1992a,b) can also be applied to classification problems. This framework successfully chooses the magnitude of weight decay terms, and ranks solutions found using different numbers of hidden units. Third, an information-based data selection criterion is derived and demonstrated within this framework."
            },
            "slug": "The-Evidence-Framework-Applied-to-Classification-Mackay",
            "title": {
                "fragments": [],
                "text": "The Evidence Framework Applied to Classification Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is demonstrated that the Bayesian framework for model comparison described for regression models in MacKay (1992a,b) can also be applied to classification problems and an information-based data selection criterion is derived and demonstrated within this framework."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11873053,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "225331d1700a9544545cc7c54a63c1b485269ce7",
            "isKey": false,
            "numCitedBy": 2037,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-Regular-Sets-from-Queries-and-Angluin",
            "title": {
                "fragments": [],
                "text": "Learning Regular Sets from Queries and Counterexamples"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720547"
                        ],
                        "name": "H. Sompolinsky",
                        "slug": "H.-Sompolinsky",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Sompolinsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sompolinsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7869993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "941ef255d31b5becbf0a3281bcf7ac0122e4c833",
            "isKey": false,
            "numCitedBy": 1619,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an algorithm called query by commitee, in which a committee of students is trained on the same data set. The next query is chosen according to the principle of maximal disagreement. The algorithm is studied for two toy models: the high-low game and perceptron learning of another perceptron. As the number of queries goes to infinity, the committee algorithm yields asymptotically finite information gain. This leads to generalization error that decreases exponentially with the number of examples. This in marked contrast to learning from randomly chosen inputs, for which the information gain approaches zero and the generalization error decreases with a relatively slow inverse power law. We suggest that asymptotically finite information gain may be an important characteristic of good query algorithms."
            },
            "slug": "Query-by-committee-Seung-Opper",
            "title": {
                "fragments": [],
                "text": "Query by committee"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is suggested that asymptotically finite information gain may be an important characteristic of good query algorithms, in which a committee of students is trained on the same data set."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 227
                            }
                        ],
                        "text": "Inthis eld, probabilistic classi ers are often used to se-lect a preferred analysis of the linguistic structure of atext (for example, its syntactic structure (Black et al.,1993), word categories (Church, 1988), or word senses(Gale, Church, and Yarowsky, 1993))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17567112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf35ed0864ff6cf524a24f0a65aa6951f9d6f214",
            "isKey": false,
            "numCitedBy": 657,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Word sense disambiguation has been recognized as a major problem in natural language processing research for over forty years. Both quantitive and qualitative methods have been tried, but much of this work has been stymied by difficulties in acquiring appropriate lexical resources. The availability of this testing and training material has enabled us to develop quantitative disambiguation methods that achieve 92% accuracy in discriminating between two very distinct senses of a noun. In the training phase, we collect a number of instances of each sense of the polysemous noun. Then in the testing phase, we are given a new instance of the noun, and are asked to assign the instance to one of the senses. We attempt to answer this question by comparing the context of the unknown instance with contexts of known instances using a Bayesian argument that has been applied successfully in related tasks such as author identification and information retrieval. The proposed method is probably most appropriate for those aspects of sense disambiguation that are closest to the information retrieval task. In particular, the proposed method was designed to disambiguate senses that are usually associated with different topics."
            },
            "slug": "A-method-for-disambiguating-word-senses-in-a-large-Gale-Church",
            "title": {
                "fragments": [],
                "text": "A method for disambiguating word senses in a large corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The proposed method was designed to disambiguate senses that are usually associated with different topics using a Bayesian argument that has been applied successfully in related tasks such as author identification and information retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Humanit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 70
                            }
                        ],
                        "text": "Fur-5We used the lexicon provided with Brill's part-of-speech tagger (Brill, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5216592,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe30dc915eefa40755b25a363813fcc575536661",
            "isKey": false,
            "numCitedBy": 1715,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic part of speech tagging is an area of natural language processing where statistical techniques have been more successful than rule-based methods. In this paper, we present a simple rule-based part of speech tagger which automatically acquires its rules and tags with accuracy comparable to stochastic taggers. The rule-based tagger has many advantages over these taggers, including: a vast reduction in stored information required, the perspicuity of a small set of meaningful rules, ease of finding and implementing improvements to the tagger, and better portability from one tag set, corpus genre or language to another. Perhaps the biggest contribution of this work is in demonstrating that the stochastic method is not the only viable method for part of speech tagging. The fact that a simple rule-based tagger that automatically learns its rules can perform so well should offer encouragement for researchers to further explore rule-based tagging, searching for a better and more expressive set of rule templates and other variations on the simple but effective theme described below."
            },
            "slug": "A-Simple-Rule-Based-Part-of-Speech-Tagger-Brill",
            "title": {
                "fragments": [],
                "text": "A Simple Rule-Based Part of Speech Tagger"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents a simple rule-based part of speech tagger which automatically acquires its rules and tags with accuracy comparable to stochastic taggers, demonstrating that the stochastics method is not the only viable method for part ofspeech tagging."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818123"
                        ],
                        "name": "E. Black",
                        "slug": "E.-Black",
                        "structuredName": {
                            "firstName": "Ezra",
                            "lastName": "Black",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5598810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0ccae6c9f33e41de9c00053aac0bc6c615c7b4a",
            "isKey": false,
            "numCitedBy": 282,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a generative probabilistic model of natural language, which we call HBG, that takes advantage of detailed linguistic information to resolve ambiguity. HBG incorporates lexical, syntactic, semantic, and structural information from the parse tree into the disambiguation process in a novel way. We use a corpus of bracketed sentences, called a Treebank, in combination with decision tree building to tease out the relevant aspects of a parse tree that will determine the correct parse of a sentence. This stands in contrast to the usual approach of further grammar tailoring via the usual linguistic introspection in the hope of generating the correct parse. In head-to-head tests against one of the best existing robust probabilistic parsing models, which we call P-CFG, the HBG model significantly outperforms P-CFG, increasing the parsing accuracy rate from 60% to 75%, a 37% reduction in error."
            },
            "slug": "Towards-History-based-Grammars:-Using-Richer-Models-Black-Jelinek",
            "title": {
                "fragments": [],
                "text": "Towards History-based Grammars: Using Richer Models for Probabilistic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "HBG incorporates lexical, syntactic, semantic, and structural information from the parse tree into the disambiguation process in a novel way and significantly outperforms P-CFG, increasing the parsing accuracy rate from 60% to 75%, a 37% reduction in error."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18584918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a0bcbcdf6d069682432bddd26b3d75a0d7495d4",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we present some improvements and extensions to previous work on boosting weak learners [Sch90, Fre90]. Our main result is an improvement of the boosting-by-majority algorithm. One implication of the performance of this algorithm is that if a concept class can be learned in the PAC model to within some fixed error smaller than 1/2, then it can be learned to within an arbitrarily small error \u03b5 > 0 with time complexity 0((1/\u03b5)(log 1/\u03b5)2) (fixing the sample space and concept class and the required reliability). We show that the majority rule is the optimal rule for combining general weak learners. We also extend the boosting algorithm to concept classes that give multi-valued labels and real-valued labels."
            },
            "slug": "An-improved-boosting-algorithm-and-its-implications-Freund",
            "title": {
                "fragments": [],
                "text": "An improved boosting algorithm and its implications on learning complexity"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The main result is an improvement of the boosting-by-majority algorithm, which shows that the majority rule is the optimal rule for combining general weak learners and extends the boosting algorithm to concept classes that give multi-valued labels and real-valuedlabel."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808760"
                        ],
                        "name": "S. Omohundro",
                        "slug": "S.-Omohundro",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Omohundro",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Omohundro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 99
                            }
                        ],
                        "text": "In the context of learning HMMs,this approach could be pro tably applied to learningHMM structure (Stolcke and Omohundro, 1992), inaddition to estimating HMM parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2798755,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "837fcdfe8fdcc9c7f2f8a8c58b2afd7e64b43ee0",
            "isKey": false,
            "numCitedBy": 317,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a technique for learning both the number of states and the topology of Hidden Markov Models from examples. The induction process starts with the most specific model consistent with the training data and generalizes by successively merging states. Both the choice of states to merge and the stopping criterion are guided by the Bayesian posterior probability. We compare our algorithm with the Baum-Welch method of estimating fixed-size models, and find that it can induce minimal HMMs from data in cases where fixed estimation does not converge or requires redundant parameters to converge."
            },
            "slug": "Hidden-Markov-Model}-Induction-by-Bayesian-Model-Stolcke-Omohundro",
            "title": {
                "fragments": [],
                "text": "Hidden Markov Model} Induction by Bayesian Model Merging"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The algorithm is compared with the Baum-Welch method of estimating fixed-size models, and it is found that it can induce minimal HMMs from data in cases where fixed estimation does not converge or requires redundant parameters to converge."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2976268"
                        ],
                        "name": "D. Cohn",
                        "slug": "D.-Cohn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cohn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9242771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1150f9289c6151506e3f7cf0e6ebbcfd49f1dace",
            "isKey": false,
            "numCitedBy": 2057,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "For many types of learners one can compute the statistically \"optimal\" way to select data. We review how these techniques have been used with feedforward neural networks [MacKay, 1992; Cohn, 1994]. We then show how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression. While the techniques for neural networks are expensive and approximate, the techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate."
            },
            "slug": "Active-Learning-with-Statistical-Models-Cohn-Ghahramani",
            "title": {
                "fragments": [],
                "text": "Active Learning with Statistical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work shows how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 124
                            }
                        ],
                        "text": "The rstuses membership queries, in which the learner con-structs examples and asks a teacher to label them (An-gluin, 1988; MacKay, 1992b; Plutowski and White,1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 153
                            }
                        ],
                        "text": "Explicit calculation of the expected informa-tion gain, on the other hand, is complex and is spe-ci c to the particular type of classi cation model used(MacKay, 1992b; MacKay, 1992a; Cohn, Ghahramani,and Jordan, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15819455,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2046412fecff64e095cc5190b69172055afd2094",
            "isKey": false,
            "numCitedBy": 1202,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning can be made more efficient if we can actively select particularly salient data points. Within a Bayesian learning framework, objective functions are discussed that measure the expected informativeness of candidate measurements. Three alternative specifications of what we want to gain information about lead to three different criteria for data selection. All these criteria depend on the assumption that the hypothesis space is correct, which may prove to be their main weakness."
            },
            "slug": "Information-Based-Objective-Functions-for-Active-Mackay",
            "title": {
                "fragments": [],
                "text": "Information-Based Objective Functions for Active Data Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Within a Bayesian learning framework, objective functions are discussed that measure the expected informativeness of candidate measurements that depend on the assumption that the hypothesis space is correct."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1870604"
                        ],
                        "name": "E. Shamir",
                        "slug": "E.-Shamir",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Shamir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Shamir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6191578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7789158665db67295e2758aa4b1c11c3372f0e31",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze the \"query by committee\" algorithm, a method for filtering informative queries from a random stream of inputs. We show that if the two-member committee algorithm achieves information gain with positive lower bound, then the prediction error decreases exponentially with the number of queries. We show that, in particular, this exponential decrease holds for query learning of thresholded smooth functions."
            },
            "slug": "Information,-Prediction,-and-Query-by-Committee-Freund-Seung",
            "title": {
                "fragments": [],
                "text": "Information, Prediction, and Query by Committee"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "It is shown that if the two-member committee algorithm achieves information gain with positive lower bound, then the prediction error decreases exponentially with the number of queries, and this exponential decrease holds for query learning of thresholded smooth functions."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3166885,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7e084fe51a40eeaaf79bf0b78e837d5bc4a8e10",
            "isKey": false,
            "numCitedBy": 1058,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A program that tags each word in an input sentence with the most likely part of speech has been written. The program uses a linear-time dynamic programming algorithm to find an assignment of parts of speech to words that optimizes the product of (a) lexical probabilities (probability of observing part of speech i given word i) and (b) contextual probabilities (probability of observing part of speech i given n following parts of speech). Program performance is encouraging; a 400-word sample is presented and is judged to be 99.5% correct.<<ETX>>"
            },
            "slug": "A-Stochastic-Parts-Program-and-Noun-Phrase-Parser-Church",
            "title": {
                "fragments": [],
                "text": "A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A program that tags each word in an input sentence with the most likely part of speech has been written and performance is encouraging; a 400-word sample is presented and is judged to be 99.5% correct."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 150
                            }
                        ],
                        "text": "\u2026assumption inmany other cases.4 HMMS AND PART-OF-SPEECHTAGGINGA rst-order Hidden Markov Model (HMM) is a prob-abilistic nite-state string generator (Rabiner, 1989),de ned as a set of states Q = fqig, a set of outputsymbols , a set of transition probabilities P (qi!qj)of each transition between\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 276
                            }
                        ],
                        "text": "\u2026of generating the tag t2 given that the pre-vious tag is t1, constituting a weak syntactic model1An alternative classi cation scheme is to compute themost likely state for each individual character (instead ofthe most likely state sequence) by the Forward-Backwardalgorithm (Rabiner, 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 334,
                                "start": 309
                            }
                        ],
                        "text": "The transition probabilities, P (t1!t2), give theprobability of generating the tag t2 given that the pre-vious tag is t1, constituting a weak syntactic model1An alternative classi cation scheme is to compute themost likely state for each individual character (instead ofthe most likely state sequence) by the Forward-Backwardalgorithm (Rabiner, 1989)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": true,
            "numCitedBy": 24804,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52052145"
                        ],
                        "name": "Van Nostrand",
                        "slug": "Van-Nostrand",
                        "structuredName": {
                            "firstName": "Van",
                            "lastName": "Nostrand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Van Nostrand"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 170
                            }
                        ],
                        "text": "Then, givena string for classi cation, we assume that it was gen-erated by the HMM and compute the most likely statesequence for the string, using the Viterbi algorithm1(Viterbi, 1967)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 124355301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b5c1d0844714588cf59629cbbc8e5f2e01f4a15",
            "isKey": false,
            "numCitedBy": 1882,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Error-Bounds-for-Convolutional-Codes-and-an-Optimum-Nostrand",
            "title": {
                "fragments": [],
                "text": "Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 125
                            }
                        ],
                        "text": "Note that property 1 is not addressed whenuncertainty in classi cation is only judged relative toa single model (as in, eg, (Lewis and Gale, 1994))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 278
                            }
                        ],
                        "text": "\u2026second type of active learning, selective sampling,can be applied: The learner examines many unlabeledexamples, and selects only the most informative forlearning (Seung, Opper, and Sompolinsky, 1992; Fre-und et al., 1993; Cohn, Atlas, and Ladner, 1994; Lewisand Catlett, 1994; Lewis and Gale, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Training text classiers by uncertainty sampling"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ACM- SIGIR Conference on Information Retrieval"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1992a. The evidence framework"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A stochastic parts"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning regular sets from"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sifting informative examples"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tagging text with a prob"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 170
                            }
                        ],
                        "text": "Then, givena string for classi cation, we assume that it was gen-erated by the HMM and compute the most likely statesequence for the string, using the Viterbi algorithm1(Viterbi, 1967)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 171
                            }
                        ],
                        "text": "Then, given a string for classi cation, we assume that it was generated by the HMM and compute the most likely state sequence for the string, using the Viterbi algorithm1 (Viterbi, 1967)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Error bounds for convolutional"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Committee-Based-Sampling-For-Training-Probabilistic-Dagan-Argamon/5f78d6f79b3ef103cb2d8d170632eb74d9496412?sort=total-citations"
}