{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 53
                            }
                        ],
                        "text": "Some of the results presented here were published in Leung and Malik (1999)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 20
                            }
                        ],
                        "text": "In Section 2, we show an operationalization of finding 2D textons from images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2166325,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "191c3c15cc4c957ee3437fc27ba3178bae292e7f",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the recognition of surfaces made from different materials such as concrete, rug, marble or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions. Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions."
            },
            "slug": "Recognizing-surfaces-using-three-dimensional-Leung-Malik",
            "title": {
                "fragments": [],
                "text": "Recognizing surfaces using three-dimensional textons"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A unified model to address both the reflectance and surface normal aspects of natural texture and to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties is provided."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 249
                            }
                        ],
                        "text": "\u20263D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 422,
                                "start": 204
                            }
                        ],
                        "text": "The complexity in the relationship between the image intensity values to the viewing/lighting settings and the properties of 3D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14729783,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f66b58c3c1a660500be7367c863891bf58238f28",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Almost all work on texture in the computer vision and graphics communities has modeled the texture as tangential, i.e. lying in the tangent plane to the surface. This is equivalent to thinking of the texture as a pattern painted on the surface. Three-dimensional textures, where the elements may point out of the surface, have largely been ignored. We study a special class of 3D textures, perpendicular textures where we can model the elements as being normal to the surface. The perspective projection of perpendicularly textured surfaces results in several interesting phenomena, which do not occur in the much-studied tangential texture case. These include occlusion, foreshortening and illumination. In this paper, we study the geometry of the problem, modeling the locations of the elements of the texture as being a realization of a spatial point process. Relations between slant and tilt of the surface, density and height of elements and occlusions are derived. Occlusions can now be used as a cue to infer shape, instead of being treated as a source of error."
            },
            "slug": "On-perpendicular-texture-or:-Why-do-we-see-more-in-Leung-Malik",
            "title": {
                "fragments": [],
                "text": "On perpendicular texture or: Why do we see more flowers in the distance?"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The geometry of the problem is studied, modeling the locations of the elements of the texture as being a realization of a spatial point process, and Relations between slant and tilt of the surface, density and height of elements and occlusions are derived."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 105
                            }
                        ],
                        "text": "PCA is in fact a very popular approach for object and texture\nrecognition (Belhumeur and Kriegman, 1998; Dana and Nayar,1999a; Georghiades et al., 1998; Murase and Nayar, 1995; Sirovitch and Kirby, 1987; Turk and Pentland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 150
                            }
                        ],
                        "text": "\u20263D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 422,
                                "start": 204
                            }
                        ],
                        "text": "The complexity in the relationship between the image intensity values to the viewing/lighting settings and the properties of 3D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17056703,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "7cbaf0f7d65686c5829fc08daa940eb8e3d3b21b",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "While an exact definition of texture is somewhat elusive, texture can be qualitatively described as a distribution of color, albedo or local normal on a surface. In the literature, the word texture is often used to describe a color or albedo variation on a smooth surface. We refer to such texture as 2D texture. In real world scenes, texture is often due to surface height variations and can be termed 3D texture. Because of local foreshortening and masking, oblique views of 3D texture are not simple transformations of the frontal view. Consequently, texture representations such as the correlation function or power spectrum are also affected by local foreshortening and masking. This work presents a correlation model for a particular class of 3D textures. The model characterizes the spatial relationship among neighboring pixels in an image of 3D texture and the change of this spatial relationship with viewing direction."
            },
            "slug": "Correlation-model-for-3D-texture-Dana-Nayar",
            "title": {
                "fragments": [],
                "text": "Correlation model for 3D texture"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work presents a correlation model for a particular class of 3D textures that characterizes the spatial relationship among neighboring pixels in an image of3D texture and the change of this spatial relationship with viewing direction."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 150
                            }
                        ],
                        "text": "\u2026and the properties of 3D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 422,
                                "start": 204
                            }
                        ],
                        "text": "The complexity in the relationship between the image intensity values to the viewing/lighting settings and the properties of 3D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1744493,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd2ef7dbd1dbe42e2dfeefa6b03f3b689a8f3f08",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Image texture can arise not only from surface albedo variations (2D texture) but also from surface height variations (3D texture). Since the appearance of 3D texture depends on the illumination and viewing direction in a complicated manner, such image texture can be called a bidirectional texture function. A fundamental representation of image texture is the histogram of pixel intensities. Since the histogram of 3D texture also depends on the illumination and viewing directions in a complex fashion, we refer to it as a bidirectional histogram. In this work, we present a concise analytical model for the bidirectional histogram of Lambertian, isotropic, randomly rough surfaces, which are common in real-world scenes. We demonstrate the accuracy of the histogram model by fitting to several samples from the Columbia-Utrecht texture database. The parameters obtained from the model fits are roughness measures which can be used in texture recognition schemes. In addition, the model has potential application in estimating illumination direction in scenes where surfaces of known tilt and roughness are visible. We demonstrate the usefulness of our model by employing it in a novel 3D texture synthesis procedure."
            },
            "slug": "Histogram-model-for-3D-textures-Dana-Nayar",
            "title": {
                "fragments": [],
                "text": "Histogram model for 3D textures"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents a concise analytical model for the bidirectional histogram of Lambertian, isotropic, randomly rough surfaces, which are common in real-world scenes and demonstrates the usefulness of the model by employing it in a novel 3D texture synthesis procedure."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 64
                            }
                        ],
                        "text": "For more discussions on 2D textons, the readers\nare referred to Malik et al. (1999), where we applied the idea of textons to the problem of image segmentation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: 3D texture, texture recognition, texture synthesis, natural material recognition"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10617783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b3dbc36ae4d8171f9a4179001e37299554f1652",
            "isKey": false,
            "numCitedBy": 344,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper makes two contributions: it provides (1) an operational definition of textons, the putative elementary units of texture perception, and (2) an algorithm for partitioning the image into disjoint regions of coherent brightness and texture, where boundaries of regions are defined by peaks in contour orientation energy and differences in texton densities across the contour. B. Julesz (1981) introduced the term texton, analogous to a phoneme in speech recognition, but did not provide an operational definition for gray-level images. We re-invent textons as frequently co-occurring combinations of oriented linear filter outputs. These can be learned using a K-means approach. By mapping each pixel to its nearest texton, the image can be analyzed into texton channels, each of which is a point set where discrete techniques such as Voronoi diagrams become applicable. Local histograms of texton frequencies can be used with a /spl chi//sup 2/ test for significant differences to find texture boundaries. Natural images contain both textured and untextured regions, so we combine this cue with that of the presence of peaks of contour energy derived from outputs of odd- and even-symmetric oriented Gaussian derivative filters. Each of these cues has a domain of applicability, so to facilitate cue combination we introduce a gating operator based on a statistical test for isotropy of Delaunay neighbors. Having obtained a local measure of how likely two nearby pixels are to belong to the same region, we use the spectral graph theoretic framework of normalized cuts to find partitions of the image into regions of coherent texture and brightness. Experimental results on a wide range of images are shown."
            },
            "slug": "Textons,-contours-and-regions:-cue-integration-in-Malik-Belongie",
            "title": {
                "fragments": [],
                "text": "Textons, contours and regions: cue integration in image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "An operational definition of textons, the putative elementary units of texture perception, and an algorithm for partitioning the image into disjoint regions of coherent brightness and texture, where boundaries of regions are defined by peaks in contour orientation energy and differences in texton densities across the contour."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 195
                            }
                        ],
                        "text": "Notice that work in the literature have attempted to show that 3\u20136 images will be able to completely characterize a structure in all lighting and viewing conditions (Belhumeur and Kriegman, 1998; Shashua, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15626102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2493447f8b17180dde5b1423376b815cd958cf0",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the problem of recognition under changing illumination conditions and changing viewing positions from a computational and human vision perspective. On the computational side we focus on the mathematical problems of creating an equivalence class for images of the same 3D object undergoing certain groups of transformations\u2014mostly those due to changing illumination, and briefly discuss those due to changing viewing positions. The computational treatment culminates in proposing a simple scheme for recognizing, via alignment, an image of a familiar object taken from a novel viewing position and a novel illumination condition. On the human vision aspect, the paper is motivated by empirical evidence inspired by Mooney images of faces that suggest a relatively high level of visual processing is involved in compensating for photometric sources of variability, and furthermore, that certain limitations on the admissible representations of image information may exist. The psychophysical observations and the computational results that follow agree in several important respects, such as the same (apparent) limitations on image representations."
            },
            "slug": "On-Photometric-Issues-in-3D-Visual-Recognition-from-Shashua",
            "title": {
                "fragments": [],
                "text": "On Photometric Issues in 3D Visual Recognition from a Single 2D Image"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The paper is motivated by empirical evidence inspired by Mooney images of faces that suggest a relatively high level of visual processing is involved in compensating for photometric sources of variability, and furthermore, that certain limitations on the admissible representations of image information may exist."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8038506"
                        ],
                        "name": "B. Ginneken",
                        "slug": "B.-Ginneken",
                        "structuredName": {
                            "firstName": "Bram",
                            "lastName": "Ginneken",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ginneken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 79
                            }
                        ],
                        "text": "All the images used in this paper are taken from the Columbia-Utrecht dataset (Dana et al., 1999) (http://www.cs.columbia.edu/CAVE/curet/)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 78
                            }
                        ],
                        "text": "All the images used in this paper are taken from the Columbia-Utrecht dataset (Dana et al., 1999)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 60
                            }
                        ],
                        "text": "Some natural 3D textures from the Columbia-Utrecht database (Dana et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 422,
                                "start": 204
                            }
                        ],
                        "text": "The complexity in the relationship between the image intensity values to the viewing/lighting settings and the properties of 3D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 173
                            }
                        ],
                        "text": "\u20263D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 622815,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "16ba88cb3c3a0438bd9e5ace9096f9655ddc63df",
            "isKey": true,
            "numCitedBy": 1074,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we investigate the visual appearance of real-world surfaces and the dependence of appearance on imaging conditions. We present a BRDF (bidirectional reflectance distribution function) database with reflectance measurements for over 60 different samples, each observed with over 200 different combinations of viewing and source directions. We fit the BRDF measurements to two recent models to obtain a BRDF parameter database. These BRDF parameters can be directly used for both image analysis and image synthesis. Finally, we present a BTF (bidirectional texture function) database with image textures from over 60 different samples, each observed with over 200 different combinations of viewing and source directions. Each of these unique databases has important implications for a variety of vision algorithms and each is made publicly available."
            },
            "slug": "Reflectance-and-texture-of-real-world-surfaces-Dana-Ginneken",
            "title": {
                "fragments": [],
                "text": "Reflectance and texture of real-world surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The visual appearance of real-world surfaces and the dependence of appearance on imaging conditions is investigated and a BRDF (bidirectional reflectance distribution function) database with reflectance measurements for over 60 different samples, each observed with over 200 different combinations of viewing and source directions is presented."
            },
            "venue": {
                "fragments": [],
                "text": "TOGS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230391"
                        ],
                        "name": "A. Georghiades",
                        "slug": "A.-Georghiades",
                        "structuredName": {
                            "firstName": "Athinodoros",
                            "lastName": "Georghiades",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Georghiades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 127
                            }
                        ],
                        "text": "PCA is in fact a very popular approach for object and texture\nrecognition (Belhumeur and Kriegman, 1998; Dana and Nayar,1999a; Georghiades et al., 1998; Murase and Nayar, 1995; Sirovitch and Kirby, 1987; Turk and Pentland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "recognition (Belhumeur and Kriegman, 1998; Dana and Nayar,1999a;  Georghiades et al., 1998;  Murase and Nayar, 1995; Sirovitch and Kirby, 1987; Turk and Pentland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 761294,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a7401db2d9c664bb5500e79e7a5d9d97f6829711",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Due to illumination variability, the same object can appear dramatically different even when viewed in fixed pose. To handle this variability, an object recognition system must employ a representation that is either invariant to, or models this variability. This paper presents an appearance-based method for modeling the variability due to illumination in the images of objects. The method differs from past appearance-based methods, however, in that a small set of training images is used to generate a representation-the illumination cone-which models the complete set of images of an object with Lambertian reflectance map under an arbitrary combination of point light sources at infinity. This method is both an implementation and extension (an extension in that it models cast shadows) of the illumination cone representation proposed in Belhumeur and Kriegman (1996). The method is tested on a database of 660 images of 10 faces, and the results exceed those of popular existing methods."
            },
            "slug": "Illumination-cones-for-recognition-under-variable-Georghiades-Kriegman",
            "title": {
                "fragments": [],
                "text": "Illumination cones for recognition under variable lighting: faces"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This method is both an implementation and extension (an extension in that it models cast shadows) of the illumination cone representation proposed in Belhumeur and Kriegman (1996), and the results exceed those of popular existing methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 153
                            }
                        ],
                        "text": "PCA is in fact a very popular approach for object and texture\nrecognition (Belhumeur and Kriegman, 1998; Dana and Nayar,1999a; Georghiades et al., 1998; Murase and Nayar, 1995; Sirovitch and Kirby, 1987; Turk and Pentland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "recognition (Belhumeur and Kriegman, 1998; Dana and Nayar,1999a; Georghiades et al., 1998; Murase and Nayar, 1995; Sirovitch and Kirby, 1987; Turk and Pentland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6611218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef768a5c9bd0aaeddafea1d56b08b0c8180760c0",
            "isKey": false,
            "numCitedBy": 1493,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of automatically learning object models for recognition and pose estimation is addressed. In contrast to the traditional approach, the recognition problem is formulated as one of matching appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties and constant for a rigid object, pose and illumination vary from scene to scene. A compact representation of object appearance is proposed that is parametrized by pose and illumination. For each object of interest, a large set of images is obtained by automatically varying pose and illumination. This image set is compressed to obtain a low-dimensional subspace, called the eigenspace, in which the object is represented as a manifold. Given an unknown input image, the recognition system projects the image to eigenspace. The object is recognized based on the manifold it lies on. The exact position of the projection on the manifold determines the object's pose in the image.A variety of experiments are conducted using objects with complex appearance characteristics. The performance of the recognition and pose estimation algorithms is studied using over a thousand input images of sample objects. Sensitivity of recognition to the number of eigenspace dimensions and the number of learning samples is analyzed. For the objects used, appearance representation in eigenspaces with less than 20 dimensions produces accurate recognition results with an average pose estimation error of about 1.0 degree. A near real-time recognition system with 20 complex objects in the database has been developed. The paper is concluded with a discussion on various issues related to the proposed learning and recognition methodology."
            },
            "slug": "Visual-learning-and-recognition-of-3-d-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Visual learning and recognition of 3-d objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A near real-time recognition system with 20 complex objects in the database has been developed and a compact representation of object appearance is proposed that is parametrized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 105
                            }
                        ],
                        "text": "PCA is in fact a very popular approach for object and texture\nrecognition (Belhumeur and Kriegman, 1998; Dana and Nayar,1999a; Georghiades et al., 1998; Murase and Nayar, 1995; Sirovitch and Kirby, 1987; Turk and Pentland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 150
                            }
                        ],
                        "text": "\u20263D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "We study the recognition of surfaces made from different materials such as concrete, rug, marble, or leather on the basis of their textural appearance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13122842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e398149727d497d2b31d98e9f93788fa2a97918",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Because object geometry varies at many scales, it is often convenient to distinguish shape from texture. While shape is a deterministic macroscopic description, texture is a finer scale geometric description with some repetitive or random component. The distinction between texture and shape is important when developing object recognition systems. Acquiring fine scale geometry is difficult due to local occlusions and limited resolution of imaging systems. Also, the complexities in geometric detail make geometric modeling of texture particularly challenging. Consequently, appearance is a convenient description for surfaces. A useful integration may entail geometry-based recognition for shape and appearance-based recognition for surface detail. We discuss our work on investigating and modeling surface detail using the framework of the BRDF (bidirectional reflectance distribution function) and the BTF (bidirectional texture function)."
            },
            "slug": "3D-Textured-Surface-Modeling-Dana-Nayar",
            "title": {
                "fragments": [],
                "text": "3D Textured Surface Modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The work on investigating and modeling surface detail using the framework of the BRDF (bidirectional reflectance distribution function) and the BTF (biddirectional texture function) is discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7977369"
                        ],
                        "name": "A. Doorn",
                        "slug": "A.-Doorn",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Doorn",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doorn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The complexity in the relationship between the image intensity values to the viewing/lighting settings and the properties of 3D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999;  Koenderink and van Doorn, 1996;  Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122895910,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "50c2835852d5f0d3a746446198a0893ed6f872aa",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the illuminance texture due to three-dimensional surface mesostructure. In the conventional rendering algorithms various methods of approximate photometry are used whose domains of validity have been ill defined. We introduce the necessary photometric concepts and do a comparative study of rendering algorithms. In the computer graphics/vision literature the physically distinct causes of illuminance variation, namely, the obliqueness of surface elements and the effects of vignetting of extended sources, are thoroughly confused. This leads to serious errors when expressions are used in contexts outside their original realm. The treatment of the texture that is due to the illumination of surface mesostructure is an example. Erroneous results are obtained when simple expressions for the illuminance of convex bodies are interpreted in terms of equivalent sources and when these again are used in calculations involving different geometrical structures. We classify current methods in terms of the approximations (often implicitly) made and compare results for a large class of applications: that of surface mesostructure on convex objects. Large differences among the various approximative methods are found. We discuss simple methods that might be used to produce more realistic results at reasonable computational cost."
            },
            "slug": "Illuminance-texture-due-to-surface-mesostructure-Koenderink-Doorn",
            "title": {
                "fragments": [],
                "text": "Illuminance texture due to surface mesostructure"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The necessary photometric concepts are introduced, current methods in terms of the approximations made are classified and results for a large class of applications are compared: that of surface mesostructure on convex objects."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145316994"
                        ],
                        "name": "S. Chatterjee",
                        "slug": "S.-Chatterjee",
                        "structuredName": {
                            "firstName": "Shankar",
                            "lastName": "Chatterjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chatterjee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 62
                            }
                        ],
                        "text": "Two of the representative techniques are Markov random fields (Chellappa and Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 63
                            }
                        ],
                        "text": "Two of the representative techniques are Markov random fields (Chellappa and Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain\n\u2217Present address: Compaq Cambridge Research Laboratory.\nand Farrokhsia,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12503745,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "e2134f8e70426fe392d95e1d0b91a61d850e6331",
            "isKey": false,
            "numCitedBy": 550,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of texture classification arises in several disciplines such as remote sensing, computer vision, and image analysis. In this paper we present two feature extraction methods for the classification of textures using two-dimensional (2-D) Markov random field (MRF) models. It is assumed that the given M \u00d7 M texture is generated by a Gaussian MRF model. In the first method, the least square (LS) estimates of model parameters are used as features. In the second method, using the notion of sufficient statistics, it is shown that the sample correlations over a symmetric window including the origin are optimal features for classification. Simple minimum distance classifiers using these two feature sets yield good classification accuracies for a seven class problem."
            },
            "slug": "Classification-of-textures-using-Gaussian-Markov-Chellappa-Chatterjee",
            "title": {
                "fragments": [],
                "text": "Classification of textures using Gaussian Markov random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Two feature extraction methods for the classification of textures using two-dimensional Markov random field (MRF) models are presented and it is shown that the sample correlations over a symmetric window including the origin are optimal features for classification."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1869519"
                        ],
                        "name": "G. R. Cross",
                        "slug": "G.-R.-Cross",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Cross",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. R. Cross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 62
                            }
                        ],
                        "text": "Two of the representative techniques are Markov random fields (Chellappa and Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 95
                            }
                        ],
                        "text": "Two of the representative techniques are Markov random fields (Chellappa and Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain\n\u2217Present address: Compaq Cambridge Research Laboratory.\nand Farrokhsia,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19038308,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7862fc4099b31f0a21fcf681403c2e594c2dd5bc",
            "isKey": false,
            "numCitedBy": 1501,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a texture to be a stochastic, possibly periodic, two-dimensional image field. A texture model is a mathematical procedure capable of producing and describing a textured image. We explore the use of Markov random fields as texture models. The binomial model, where each point in the texture has a binomial distribution with parameter controlled by its neighbors and ``number of tries'' equal to the number of gray levels, was taken to be the basic model for the analysis. A method of generating samples from the binomial model is given, followed by a theoretical and practical analysis of the method's convergence. Examples show how the parameters of the Markov random field control the strength and direction of the clustering in the image. The power of the binomial model to produce blurry, sharp, line-like, and blob-like textures is demonstrated. Natural texture samples were digitized and their parameters were estimated under the Markov random field model. A hypothesis test was used for an objective assessment of goodness-of-fit under the Markov random field model. Overall, microtextures fit the model well. The estimated parameters of the natural textures were used as input to the generation procedure. The synthetic microtextures closely resembled their real counterparts, while the regular and inhomogeneous textures did not."
            },
            "slug": "Markov-Random-Field-Texture-Models-Cross-Jain",
            "title": {
                "fragments": [],
                "text": "Markov Random Field Texture Models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The power of the binomial model to produce blurry, sharp, line-like, and blob-like textures is demonstrated and the synthetic microtextures closely resembled their real counterparts, while the regular and inhomogeneous textures did not."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144677513"
                        ],
                        "name": "David G. Jones",
                        "slug": "David-G.-Jones",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jones",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David G. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 101
                            }
                        ],
                        "text": "Each of the Pk can be obtained by multiplying the appearance vector ck with the pseudo-inverse of F (Jones and Malik, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 359416,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ff22944d8a76831867d902570ed85a7e0e3cac6",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a computational framework for stereopsis based on the outputs of linear spatial filters tuned to a range of orientations and scales. This approach goes beyond edge-based and area-based approaches by using a richer image description and incorporating several stereo cues that previously have been neglected in the computer vision literature. A technique based on using the pseudo-inverse is presented for characterizing the information present in a vector of filter responses. We show how in our framework viewing geometry can be recovered to determine the locations of epipolar lines. An assumption that visible surfaces in the scene are piecewise smooth leads to differential treatment of image regions corresponding to binocularly visible surfaces, surface boundaries, and occluded regions that are only monocularly visible. The constraints imposed by viewing geometry and piecewise smoothness are incorporated into an iterative algorithm that gives good results on random-dot stereograms, artificially generated scenes, and natural grey-level images."
            },
            "slug": "A-Computational-Framework-for-Determining-Stereo-a-Jones-Malik",
            "title": {
                "fragments": [],
                "text": "A Computational Framework for Determining Stereo Correspondence from a Set of Linear Spatial Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A computational framework for stereopsis based on the outputs of linear spatial filters tuned to a range of orientations and scales is presented and a technique based on using the pseudo-inverse is presented for characterizing the information present in a vector of filter responses."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39092098"
                        ],
                        "name": "Y. Wu",
                        "slug": "Y.-Wu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Wu",
                            "middleNames": [
                                "Nian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 62
                            }
                        ],
                        "text": "Two of the representative techniques are Markov random fields (Chellappa and Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 47
                            }
                        ],
                        "text": "Rubner and Tomasi, 1999), as well as synthesis (de Bonet and Viola, 1998; Heeger and Bergen, 1995; Zhu et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 237
                            }
                        ],
                        "text": "This approach has proved to be useful for segmentation (Fogel and Sagi, 1989; Malik and Perona, 1990), recognition (Puzicha et al., 1997;\nRubner and Tomasi, 1999), as well as synthesis (de Bonet and Viola, 1998; Heeger and Bergen, 1995; Zhu et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 147
                            }
                        ],
                        "text": "\u2026representative techniques are Markov random fields (Chellappa and Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain\n\u2217Present address: Compaq Cambridge Research Laboratory.\nand Farrokhsia, 1991;\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2171181,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a5f775f7490f410692bb224ff021da97d5e0ddc",
            "isKey": true,
            "numCitedBy": 583,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a statistical theory for texture modeling. This theory combines filtering theory and Markov random field modeling through the maximum entropy principle, and interprets and clarifies many previous concepts and methods for texture analysis and synthesis from a unified point of view. Our theory characterizes the ensemble of images I with the same texture appearance by a probability distribution f(I) on a random field, and the objective of texture modeling is to make inference about f(I), given a set of observed texture examples.In our theory, texture modeling consists of two steps. (1) A set of filters is selected from a general filter bank to capture features of the texture, these filters are applied to observed texture images, and the histograms of the filtered images are extracted. These histograms are estimates of the marginal distributions of f( I). This step is called feature extraction. (2) The maximum entropy principle is employed to derive a distribution p(I), which is restricted to have the same marginal distributions as those in (1). This p(I) is considered as an estimate of f( I). This step is called feature fusion. A stepwise algorithm is proposed to choose filters from a general filter bank. The resulting model, called FRAME (Filters, Random fields And Maximum Entropy), is a Markov random field (MRF) model, but with a much enriched vocabulary and hence much stronger descriptive ability than the previous MRF models used for texture modeling. Gibbs sampler is adopted to synthesize texture images by drawing typical samples from p(I), thus the model is verified by seeing whether the synthesized texture images have similar visual appearances to the texture images being modeled. Experiments on a variety of 1D and 2D textures are described to illustrate our theory and to show the performance of our algorithms. These experiments demonstrate that many textures which are previously considered as from different categories can be modeled and synthesized in a common framework."
            },
            "slug": "Filters,-Random-Fields-and-Maximum-Entropy-(FRAME):-Zhu-Wu",
            "title": {
                "fragments": [],
                "text": "Filters, Random Fields and Maximum Entropy (FRAME): Towards a Unified Theory for Texture Modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The resulting model, called FRAME (Filters, Random fields And Maximum Entropy), is a Markov random field (MRF) model, but with a much enriched vocabulary and hence much stronger descriptive ability than the previous MRF models used for texture modeling."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722325"
                        ],
                        "name": "J. Bonet",
                        "slug": "J.-Bonet",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Bonet",
                            "middleNames": [
                                "S.",
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bonet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 186
                            }
                        ],
                        "text": "This approach has proved to be useful for segmentation (Fogel and Sagi, 1989; Malik and Perona, 1990), recognition (Puzicha et al., 1997;\nRubner and Tomasi, 1999), as well as synthesis (de Bonet and Viola, 1998; Heeger and Bergen, 1995; Zhu et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15951006,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science",
                "Mathematics"
            ],
            "id": "0adfcdc1af6ad2f3a118d851533d86a8281206e3",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a technique for using the joint occurrence of local features at multiple resolutions to measure the similarity between texture images. Though superficially similar to a number of \"Gabor\" style techniques, which recognize textures through the extraction of multi-scale feature vectors, our approach is derived from an accurate generative model of texture, which is explicitly multiscale and non-parametric. The resulting recognition procedure is similarly non-parametric, and can model complex non-homogeneous textures. We report results on publicly available texture databases. In addition, experiments indicate that this approach may have sufficient discrimination power to perform target detection in synthetic aperture radar images (SAR)."
            },
            "slug": "Texture-recognition-using-a-non-parametric-model-Bonet-Viola",
            "title": {
                "fragments": [],
                "text": "Texture recognition using a non-parametric multi-scale statistical model"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A technique for using the joint occurrence of local features at multiple resolutions to measure the similarity between texture images, derived from an accurate generative model of texture, which is explicitly multiscale and non-parametric."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 75
                            }
                        ],
                        "text": "PCA is in fact a very popular approach for object and texture\nrecognition (Belhumeur and Kriegman, 1998; Dana and Nayar,1999a; Georghiades et al., 1998; Murase and Nayar, 1995; Sirovitch and Kirby, 1987; Turk and Pentland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 165
                            }
                        ],
                        "text": "Notice that work in the literature have attempted to show that 3\u20136 images will be able to completely characterize a structure in all lighting and viewing conditions (Belhumeur and Kriegman, 1998; Shashua, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1730916,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ef6b01d9031416dd2d53ea651260e2e82cb1f8b7",
            "isKey": false,
            "numCitedBy": 508,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "The appearance of an object depends on both the viewpoint from which it is observed and the light sources by which it is illuminated. If the appearance of two objects is never identical for any pose or lighting conditions, then\u2013in theory\u2013the objects can always be distinguished or recognized. The question arises: What is the set of images of an object under all lighting conditions and pose? In this paper, we consider only the set of images of an object under variable illumination, including multiple, extended light sources and shadows. We prove that the set of n-pixel images of a convex object with a Lambertian reflectance function, illuminated by an arbitrary number of point light sources at infinity, forms a convex polyhedral cone in IRn and that the dimension of this illumination cone equals the number of distinct surface normals. Furthermore, the illumination cone can be constructed from as few as three images. In addition, the set of n-pixel images of an object of any shape and with a more general reflectance function, seen under all possible illumination conditions, still forms a convex cone in IRn. Extensions of these results to color images are presented. These results immediately suggest certain approaches to object recognition. Throughout, we present results demonstrating the illumination cone representation."
            },
            "slug": "What-Is-the-Set-of-Images-of-an-Object-Under-All-Belhumeur-Kriegman",
            "title": {
                "fragments": [],
                "text": "What Is the Set of Images of an Object Under All Possible Illumination Conditions?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that the set of n-pixel images of a convex object with a Lambertian reflectance function, illuminated by an arbitrary number of point light sources at infinity, forms a conveX polyhedral cone in IRn and that the dimension of this illumination cone equals the number of distinct surface normals."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 204
                            }
                        ],
                        "text": "PCA is in fact a very popular approach for object and texture\nrecognition (Belhumeur and Kriegman, 1998; Dana and Nayar,1999a; Georghiades et al., 1998; Murase and Nayar, 1995; Sirovitch and Kirby, 1987; Turk and Pentland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "recognition (Belhumeur and Kriegman, 1998; Dana and Nayar,1999a; Georghiades et al., 1998; Murase and Nayar, 1995; Sirovitch and Kirby, 1987; Turk and Pentland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14954,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1413369599"
                        ],
                        "name": "I. Fogel",
                        "slug": "I.-Fogel",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Fogel",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Fogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144737366"
                        ],
                        "name": "D. Sagi",
                        "slug": "D.-Sagi",
                        "structuredName": {
                            "firstName": "Dov",
                            "lastName": "Sagi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sagi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 150
                            }
                        ],
                        "text": "\u2026random fields (Chellappa and Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain\n\u2217Present address: Compaq Cambridge Research Laboratory.\nand Farrokhsia, 1991; Malik and Perona, 1990; Puzicha et al.,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 56
                            }
                        ],
                        "text": "This approach has proved to be useful for segmentation (Fogel and Sagi, 1989; Malik and Perona, 1990), recognition (Puzicha et al., 1997;\nRubner and Tomasi, 1999), as well as synthesis (de Bonet and Viola, 1998; Heeger and Bergen, 1995; Zhu et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 55
                            }
                        ],
                        "text": "This approach has proved to be useful for segmentation (Fogel and Sagi, 1989; Malik and Perona, 1990), recognition (Puzicha et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14952808,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9799ac67b77289a51337edf90ac3ae08ec039184",
            "isKey": false,
            "numCitedBy": 545,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "The present paper presents a model for texture discrimination based on Gabor functions. In this model the Gabor power spectrum of the micropatterns corresponding to different textures is calculated. A function that measures the difference between the spectrum of two micropatterns is introduced and its values are correlated with human performance in preattentive detection tasks. In addition, a two stage algorithm for texture segregation is presented. In the first stage the input image is transformed via Gabor filters into a representation image that allows discrimination between features by means of intensity differences. In the second stage the borders between areas of different textures are found using a Laplacian of Gaussian operator. This algorithm is sensitive to energy differences, rotation and spatial frequency and is insensitive to local translation. The model was tested by means of several simulations and was found to be in good correlation with known psychophysical characteristics as texton based texture segregation and micropattern density sensitivity. However, this simple model fails to predict human performance in discrimination tasks based on differences in the density of \u201cterminators\u201d. In this case human performance is better than expected."
            },
            "slug": "Gabor-filters-as-texture-discriminator-Fogel-Sagi",
            "title": {
                "fragments": [],
                "text": "Gabor filters as texture discriminator"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The model was found to be in good correlation with known psychophysical characteristics as texton based texture segregation and micropattern density sensitivity, however, this simple model fails to predict human performance in discrimination tasks based on differences in the density of \u201cterminators\u201d."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360881"
                        ],
                        "name": "D. Heeger",
                        "slug": "D.-Heeger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heeger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heeger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116003860"
                        ],
                        "name": "J. Bergen",
                        "slug": "J.-Bergen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 47
                            }
                        ],
                        "text": "Rubner and Tomasi, 1999), as well as synthesis (de Bonet and Viola, 1998; Heeger and Bergen, 1995; Zhu et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 212
                            }
                        ],
                        "text": "This approach has proved to be useful for segmentation (Fogel and Sagi, 1989; Malik and Perona, 1990), recognition (Puzicha et al., 1997;\nRubner and Tomasi, 1999), as well as synthesis (de Bonet and Viola, 1998; Heeger and Bergen, 1995; Zhu et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 106
                            }
                        ],
                        "text": "The reconstruction task is trivial for orthogonal or self-inverting filter banks (Burt and Adelson, 1983; Heeger and Bergen, 1995; Vaidyanathan, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 47266338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38850b393d7132dc14141f7d643aca4cb9c321da",
            "isKey": false,
            "numCitedBy": 843,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method for synthesizing images that match the texture appearance of a given digitized sample. This synthesis is completely automatic and requires only the \"target\" texture as input. It allows generation of as much texture as desired so that any object can be covered. The approach is based on a model of human texture perception, and has potential to be a practically useful tool for image processing and graphics applications."
            },
            "slug": "Pyramid-based-texture-analysis/synthesis-Heeger-Bergen",
            "title": {
                "fragments": [],
                "text": "Pyramid-based texture analysis/synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper describes a method for synthesizing images that match the texture appearance of a given digitized sample that is based on a model of human texture perception, and has potential to be a practically useful tool for image processing and graphics applications."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., International Conference on Image Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 18
                            }
                        ],
                        "text": "The basic idea of Efros and Leung (1999) is to synthesize texture by growing pixels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 26
                            }
                        ],
                        "text": "The algorithm proposed in Efros and Leung (1999) is particularly promising."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 221583955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bba3264d6794538381687ad6e151a7f42f3872a9",
            "isKey": false,
            "numCitedBy": 1647,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A non-parametric method for texture synthesis is proposed. The texture synthesis process grows a new image outward from an initial seed, one pixel at a time. A Markov random field model is assumed, and the conditional distribution of a pixel given all its neighbors synthesized so far is estimated by querying the sample image and finding all similar neighborhoods. The degree of randomness is controlled by a single perceptually intuitive parameter. The method aims at preserving as much local structure as possible and produces good results for a wide variety of synthetic and real-world textures."
            },
            "slug": "Texture-synthesis-by-non-parametric-sampling-Efros-Leung",
            "title": {
                "fragments": [],
                "text": "Texture synthesis by non-parametric sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A non-parametric method for texture synthesis that aims at preserving as much local structure as possible and produces good results for a wide variety of synthetic and real-world textures."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829696"
                        ],
                        "name": "Y. Rubner",
                        "slug": "Y.-Rubner",
                        "structuredName": {
                            "firstName": "Yossi",
                            "lastName": "Rubner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rubner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "and Farrokhsia, 1991; Malik and Perona, 1990; Puzicha et al., 1997;  Rubner and Tomasi, 1999 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 138
                            }
                        ],
                        "text": "This approach has proved to be useful for segmentation (Fogel and Sagi, 1989; Malik and Perona, 1990), recognition (Puzicha et al., 1997;\nRubner and Tomasi, 1999), as well as synthesis (de Bonet and Viola, 1998; Heeger and Bergen, 1995; Zhu et al., 1998)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 271
                            }
                        ],
                        "text": "\u2026Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain\n\u2217Present address: Compaq Cambridge Research Laboratory.\nand Farrokhsia, 1991; Malik and Perona, 1990; Puzicha et al., 1997; Rubner and Tomasi, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": " Rubner and Tomasi, 1999 ), as well as synthesis (de Bonet and Viola, 1998; Heeger and Bergen, 1995; Zhu et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12427914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c82d70ca7bedf750707b92781d0a48b991f7156",
            "isKey": true,
            "numCitedBy": 60,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Image segmentation is not only hard and unnecessary for texture-based image retrieval, but can even be harmful. Images of either individual or multiple textures are best described by distributions of spatial frequency descriptors, rather than single descriptor vectors over presegmented regions. A retrieval method based on the earth movers distance with an appropriate ground distance is shown to handle both complete and partial multi-textured queries. As an illustration, different images of the same type of animal are easily retrieved together. At the same time, animals with subtly different coats, like cheetahs and leopards, are properly distinguished."
            },
            "slug": "Texture-based-image-retrieval-without-segmentation-Rubner-Tomasi",
            "title": {
                "fragments": [],
                "text": "Texture-based image retrieval without segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A retrieval method based on the earth movers distance with an appropriate ground distance is shown to handle both complete and partial multi-textured queries."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712844"
                        ],
                        "name": "M. Chantler",
                        "slug": "M.-Chantler",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Chantler",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chantler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704787"
                        ],
                        "name": "G. McGunnigle",
                        "slug": "G.-McGunnigle",
                        "structuredName": {
                            "firstName": "Ged",
                            "lastName": "McGunnigle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. McGunnigle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 149
                            }
                        ],
                        "text": "\u2026the viewing/lighting settings and the properties of 3D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al.,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 422,
                                "start": 204
                            }
                        ],
                        "text": "The complexity in the relationship between the image intensity values to the viewing/lighting settings and the properties of 3D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62247358,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a274280f328d898d21297c2c6acd7273633bd91b",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper uses theory and laboratory experiment, to show that directional illumination used during the image acquisition process, acts as a directional filter of three dimensional texture. It is shown that the directional characteristics of image texture are not intrinsic to the physical texture being imaged, as they are affected by the direction of the illumination. The implications of this to texture classification are then investigated using a set of Laws' [1980] operators. Finally, a scheme for the compensation of effects caused by changes in illuminant orientation is proposed and evaluated."
            },
            "slug": "Compensation-of-illuminant-tilt-variation-for-Chantler-McGunnigle",
            "title": {
                "fragments": [],
                "text": "Compensation of illuminant tilt variation for texture classification"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "It is shown that directional illumination used during the image acquisition process, acts as a directional filter of three dimensional texture, and the implications to texture classification are investigated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064076416"
                        ],
                        "name": "B. van Ginneken",
                        "slug": "B.-van-Ginneken",
                        "structuredName": {
                            "firstName": "Bram",
                            "lastName": "van Ginneken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. van Ginneken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121368"
                        ],
                        "name": "M. Stavridi",
                        "slug": "M.-Stavridi",
                        "structuredName": {
                            "firstName": "Marigo",
                            "lastName": "Stavridi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stavridi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44505138,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d0050917db488b35c5ad3644469ec054e0cac55f",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a reflection model for isotropic rough surfaces that have both specular and diffuse components. The surface is assumed to have a normal distribution of heights. Parameters of the model are the surface roughness given by the rms slope, the albedo, and the balance between diffuse and specular reflection. The effect of roughness on diffuse reflection is taken into account, instead of our modeling this component as a constant Lambertian term. The model includes geometrical effects such as masking and shadowing. The model is compared with experimental data obtained from goniophotometric measurements on samples of tiles and bricks. The model fits well to samples with very different reflection properties. Measurements of the sample profiles performed with a laser profilometer to determine the rms slope show that the assumed surface model is realistic. The model could therefore be used in machine vision and computer graphics to approximate reflection characteristics of surfaces. It could also be used to predict the texture of surfaces as a function of illumination and viewing angles."
            },
            "slug": "Diffuse-and-specular-reflectance-from-rough-Ginneken-Stavridi",
            "title": {
                "fragments": [],
                "text": "Diffuse and specular reflectance from rough surfaces."
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A reflection model for isotropic rough surfaces that have both specular and diffuse components that fits well to samples with very different reflection properties and could be used in machine vision and computer graphics to approximate reflection characteristics of surfaces."
            },
            "venue": {
                "fragments": [],
                "text": "Applied optics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065554001"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 78
                            }
                        ],
                        "text": "This approach has proved to be useful for segmentation (Fogel and Sagi, 1989; Malik and Perona, 1990), recognition (Puzicha et al., 1997;\nRubner and Tomasi, 1999), as well as synthesis (de Bonet and Viola, 1998; Heeger and Bergen, 1995; Zhu et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 55
                            }
                        ],
                        "text": "This approach has proved to be useful for segmentation (Fogel and Sagi, 1989; Malik and Perona, 1990), recognition (Puzicha et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 225
                            }
                        ],
                        "text": "\u2026Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain\n\u2217Present address: Compaq Cambridge Research Laboratory.\nand Farrokhsia, 1991; Malik and Perona, 1990; Puzicha et al., 1997; Rubner and Tomasi, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5601682,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "29cb9c230d999a2175c31969f0d90fcae3fb4efe",
            "isKey": false,
            "numCitedBy": 1083,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model of human preattentive texture perception. This model consists of three stages: (1) convolution of the image with a bank of even-symmetric linear filters followed by half-wave rectification to give a set of responses modeling outputs of V1 simple cells, (2) inhibition, localized in space, within and among the neural-response profiles that results in the suppression of weak responses when there are strong responses at the same or nearby locations, and (3) texture-boundary detection by using wide odd-symmetric mechanisms. Our model can predict the salience of texture boundaries in any arbitrary gray-scale image. A computer implementation of this model has been tested on many of the classic stimuli from psychophysical literature. Quantitative predictions of the degree of discriminability of different texture pairs match well with experimental measurements of discriminability in human observers."
            },
            "slug": "Preattentive-texture-discrimination-with-early-Malik-Perona",
            "title": {
                "fragments": [],
                "text": "Preattentive texture discrimination with early vision mechanisms."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A model of human preattentive texture perception that can predict the salience of texture boundaries in any arbitrary gray-scale image and Quantitative predictions of the degree of discriminability of different texture pairs match well with experimental measurements of discriminateability in human observers."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7977369"
                        ],
                        "name": "A. Doorn",
                        "slug": "A.-Doorn",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Doorn",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doorn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "What this means is that pixels with the same label will look different under different lighting and viewing conditions: (1) the albedo change varies according to the cosine of the lighting angle (assuming a Lambertian surface); (2) the location of the shadow boundary changes according to the direction of the light; and (3) the deep groove remains the same for a wide range of lighting and viewing conditions (Haddon and Forsyth, 1998;  Koenderink ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120192969,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "cbd5fb9fc78fc6eba7ed331177fe7ffc3b6ce669",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "An attempt is made to identify the structural invariants of the field of isophotes on lambertian surfaces of arbitrary shape under arbitrary illumination. It is a priori clear that such invariants play an important part in the perception of solid shape by means of chiaroscuro. We have found several such invariants. The topological structure of the field of isophotes is determined by the collection of nested, closed parabolic curves on the surface. An important class of stationary points of the field clings to these parabolic lines. The isophotes cut the parabolic lines at a constant angle, irrespective of the location of the light sources. For certain canonical surface undulations the field of isophotes is explicitly given."
            },
            "slug": "Photometric-Invariants-Related-to-Solid-Shape-Koenderink-Doorn",
            "title": {
                "fragments": [],
                "text": "Photometric Invariants Related to Solid Shape"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 82
                            }
                        ],
                        "text": "The reconstruction task is trivial for orthogonal or self-inverting filter banks (Burt and Adelson, 1983; Heeger and Bergen, 1995; Vaidyanathan, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8018433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83074157d165b6245915508d891b2d0cd066f3ad",
            "isKey": false,
            "numCitedBy": 6693,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a technique for image encoding in which local operators of many scales but identical shape serve as the basis functions. The representation differs from established techniques in that the code elements are localized in spatial frequency as well as in space. Pixel-to-pixel correlations are first removed by subtracting a lowpass filtered copy of the image from the image itself. The result is a net data compression since the difference, or error, image has low variance and entropy, and the low-pass filtered image may represented at reduced sample density. Further data compression is achieved by quantizing the difference image. These steps are then repeated to compress the low-pass image. Iteration of the process at appropriately expanded scales generates a pyramid data structure. The encoding process is equivalent to sampling the image with Laplacian operators of many scales. Thus, the code tends to enhance salient image features. A further advantage of the present code is that it is well suited for many image analysis tasks as well as for image compression. Fast algorithms are described for coding and decoding."
            },
            "slug": "The-Laplacian-Pyramid-as-a-Compact-Image-Code-Burt-Adelson",
            "title": {
                "fragments": [],
                "text": "The Laplacian Pyramid as a Compact Image Code"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A technique for image encoding in which local operators of many scales but identical shape serve as the basis functions, which tends to enhance salient image features and is well suited for many image analysis tasks as well as for image compression."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326060"
                        ],
                        "name": "F. Farrokhnia",
                        "slug": "F.-Farrokhnia",
                        "structuredName": {
                            "firstName": "Farshid",
                            "lastName": "Farrokhnia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Farrokhnia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21804891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e468e08612b1448c7e814e3d32c4384a06cfbe3c",
            "isKey": false,
            "numCitedBy": 2456,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "A texture segmentation algorithm inspired by the multichannel filtering theory for visual information processing in the early stages of the human visual system is presented. The channels are characterized by a bank of Gabor filters that nearly uniformly covers the spatial-frequency domain. A systematic filter selection scheme based on reconstruction of the input image from the filtered images is proposed. Texture features are obtained by subjecting each (selected) filtered image to a nonlinear transformation and computing a measure of energy in a window around each pixel. An unsupervised square-error clustering algorithm is then used to integrate the feature images and produce a segmentation. A simple procedure to incorporate spatial adjacency information in the clustering process is proposed. Experiments on images with natural textures as well as artificial textures with identical second and third-order statistics are reported. The algorithm appears to perform as predicted by preattentive texture discrimination by a human.<<ETX>>"
            },
            "slug": "Unsupervised-texture-segmentation-using-Gabor-Jain-Farrokhnia",
            "title": {
                "fragments": [],
                "text": "Unsupervised texture segmentation using Gabor filters"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A texture segmentation algorithm inspired by the multichannel filtering theory for visual information processing in the early stages of the human visual system is presented and appears to perform as predicted by preattentive texture discrimination by a human."
            },
            "venue": {
                "fragments": [],
                "text": "1990 IEEE International Conference on Systems, Man, and Cybernetics Conference Proceedings"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 116
                            }
                        ],
                        "text": "This approach has proved to be useful for segmentation (Fogel and Sagi, 1989; Malik and Perona, 1990), recognition (Puzicha et al., 1997;\nRubner and Tomasi, 1999), as well as synthesis (de Bonet and Viola, 1998; Heeger and Bergen, 1995; Zhu et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 249
                            }
                        ],
                        "text": "\u2026Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain\n\u2217Present address: Compaq Cambridge Research Laboratory.\nand Farrokhsia, 1991; Malik and Perona, 1990; Puzicha et al., 1997; Rubner and Tomasi, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This approach has proved to be useful for segmentation (Fogel and Sagi, 1989; Malik and Perona, 1990), recognition ( Puzicha et al., 1997; 32  Leung and Malik"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "and Farrokhsia, 1991; Malik and Perona, 1990;  Puzicha et al., 1997;  Rubner and Tomasi, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6050914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a7cee3ce1db1d62e93f74a6e01b22e63f5a90d1",
            "isKey": true,
            "numCitedBy": 301,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose and examine non-parametric statistical tests to define similarity and homogeneity measures for textures. The statistical tests are applied to the coefficients of images filtered by a multi-scale Gabor filter bank. We demonstrate that these similarity measures are useful for both, texture based image retrieval and for unsupervised texture segmentation, and hence offer a unified approach to these closely related tasks. We present results on Brodatz-like micro-textures and a collection of real-word images."
            },
            "slug": "Non-parametric-similarity-measures-for-unsupervised-Puzicha-Hofmann",
            "title": {
                "fragments": [],
                "text": "Non-parametric similarity measures for unsupervised texture segmentation and image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper proposes and examines non-parametric statistical tests to define similarity and homogeneity measures for textures and demonstrates that these similarity measures are useful for both, texture based image retrieval and for unsupervised texture segmentation, and hence offer a unified approach to these closely related tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326400"
                        ],
                        "name": "B. Julesz",
                        "slug": "B.-Julesz",
                        "structuredName": {
                            "firstName": "B\u00e9la",
                            "lastName": "Julesz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Julesz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 17
                            }
                        ],
                        "text": "Julesz\u2019s textons (Julesz, 1981)\u2014 orientation elements, crossings and terminators\u2014fell"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 17
                            }
                        ],
                        "text": "Julesz\u2019s textons (Julesz, 1981)\u2014 orientation elements, crossings and terminators\u2014fell\ninto disuse as they did not have a precise definition for gray level images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4327694,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "8999355e47248bc60f5768fc2168fd28295b5f27",
            "isKey": false,
            "numCitedBy": 1772,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Research with texture pairs having identical second-order statistics has revealed that the pre-attentive texture discrimination system cannot globally process third- and higher-order statistics, and that discrimination is the result of a few local conspicuous features, called textons. It seems that only the first-order statistics of these textons have perceptual significance, and the relative phase between textons cannot be perceived without detailed scrutiny by focal attention."
            },
            "slug": "Textons,-the-elements-of-texture-perception,-and-Julesz",
            "title": {
                "fragments": [],
                "text": "Textons, the elements of texture perception, and their interactions"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Research with texture pairs having identical second-order statistics has revealed that the pre-attentive texture discrimination system cannot globally process third- and higher- order statistics, and that discrimination is the result of a few local conspicuous features, called textons."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712844"
                        ],
                        "name": "M. Chantler",
                        "slug": "M.-Chantler",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Chantler",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chantler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 143
                            }
                        ],
                        "text": "\u2026values to the viewing/lighting settings and the properties of 3D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 422,
                                "start": 204
                            }
                        ],
                        "text": "The complexity in the relationship between the image intensity values to the viewing/lighting settings and the properties of 3D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124699111,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "046e92962f62b938c30e3fe3c08789ca17cbfabc",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides a short overview of work recently performed by the author into the effects of illuminant variation on texture classification, and proposes one method to reduce misclassifications caused by such variations. The paper first presents a model of image texture originally introduced by Kube and Pentland and further developed by the author. The effect of variation in the tilt angle of the illuminant is high-lighted. A set of tilt-compensation filters is developed from the model. The filters are used to pre-process texture images used in training and classification sessions. >"
            },
            "slug": "Towards-illuminant-invariant-texture-classification-Chantler",
            "title": {
                "fragments": [],
                "text": "Towards illuminant invariant texture classification"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A model of image texture originally introduced by Kube and Pentland and further developed by the author is presented, showing the effect of variation in the tilt angle of the illuminant on texture classification."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040323"
                        ],
                        "name": "J. Haddon",
                        "slug": "J.-Haddon",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Haddon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Haddon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 468,
                                "start": 410
                            }
                        ],
                        "text": "What this means is that pixels with the same label will look different under different lighting and viewing conditions: (1) the albedo change varies according to the cosine of the lighting angle (assuming a Lambertian surface); (2) the location of the shadow boundary changes according to the direction of the light; and (3) the deep groove remains the same for a wide range of lighting and viewing conditions (Haddon and Forsyth, 1998; Koenderink and van Doorn, 1980)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 239
                            }
                        ],
                        "text": "\u2026of the lighting angle (assuming a Lambertian surface); (2) the location of the shadow boundary changes according to the direction of the light; and (3) the deep groove remains the same for a wide range of lighting and viewing conditions (Haddon and Forsyth, 1998; Koenderink and van Doorn, 1980)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8762569,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "405e4b83f8210e8724f1a1f883eb2a494a5b3e33",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Diffuse interreflections cause effects that make current theories of shape from shading unsatisfactory. We show that distant radiating surfaces produce radiosity effects at low spatial frequencies. This means that, if a shading pattern has a small region of support, unseen surfaces in the environment can only produce effects that vary slowly over the support region. It is therefore relatively easy to construct matching processes for such patterns that are robust to interreflections. We call regions with these patterns \"shading primitives\". Folds and grooves on surfaces provide two examples of shading primitives; the shading pattern is relatively independent of surface shape at a fold or a groove, and the pattern is localised. We show that the pattern of shading can be predicted accurately by a simple model, and derive a matching process from this model. Both groove and fold matchers are shown to work well on images of real scenes."
            },
            "slug": "Shading-primitives:-finding-folds-and-shallow-Haddon-Forsyth",
            "title": {
                "fragments": [],
                "text": "Shading primitives: finding folds and shallow grooves"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that the pattern of shading can be predicted accurately by a simple model, and a matching process from this model is derived, which is shown to work well on images of real scenes."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 119
                            }
                        ],
                        "text": "MCMC algorithms have been applied to computer vision for a long time, most well-known in the paper by Geman and Geman (Geman and Geman, 1984), where the problem of image restoration is studied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18706,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7977369"
                        ],
                        "name": "A. Doorn",
                        "slug": "A.-Doorn",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Doorn",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doorn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 224
                            }
                        ],
                        "text": "\u20263D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 422,
                                "start": 204
                            }
                        ],
                        "text": "The complexity in the relationship between the image intensity values to the viewing/lighting settings and the properties of 3D textures led to recent interest in building explicit models for 3D textures (Chantler, 1994; Chantler and McGunnigle, 1995; Dana and Nayar, 1998; Dana and Nayar, 1999b; Dana et al., 1999; Koenderink and van Doorn, 1996; Koenderink et al., 1999; Leung and Malik, 1997; van Ginneken et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14489428,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "3abfd03c050f03e8bcd900340fab76c6c00f2d8f",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive the BRDF (Bidirectional Reflection Distribution Function) at the mega scale of opaque surfaces that are rough on the macro and micro scale. The roughness at the micro scale is modeled as a uniform, isotropically scattering, Lambertian surface. At the macro scale the roughness is modeled by way of a distribution of spherical concavities. These pits influence the BRDF via vignetting, cast shadow, interreflection and interposition, causing it to differ markedly from Lambertian. Pitted surfaces show strong backward scattering (so called \u201copposition effect\u201d). When we assume that the macro scale can be resolved, the radiance histogram and the spatial structure of the textons of the textured surface (at the mega scale) can be calculated. This is the main advantage of the model over previous ones: One can do exact (numerical) calculations for a surface geometry that is physically realizable."
            },
            "slug": "Bidirectional-Reflection-Distribution-Function-of-Koenderink-Doorn",
            "title": {
                "fragments": [],
                "text": "Bidirectional Reflection Distribution Function of Thoroughly Pitted Surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The BRDF (Bidirectional Reflection Distribution Function) at the mega scale of opaque surfaces that are rough on the macro and micro scale is derived, which means one can do exact calculations for a surface geometry that is physically realizable."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4723637"
                        ],
                        "name": "J. Mao",
                        "slug": "J.-Mao",
                        "structuredName": {
                            "firstName": "Jianchang",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 62
                            }
                        ],
                        "text": "Two of the representative techniques are Markov random fields (Chellappa and Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 117
                            }
                        ],
                        "text": "Two of the representative techniques are Markov random fields (Chellappa and Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain\n\u2217Present address: Compaq Cambridge Research Laboratory.\nand Farrokhsia,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11686184,
            "fieldsOfStudy": [
                "Mathematics",
                "Environmental Science",
                "Computer Science"
            ],
            "id": "0b1c14ccf1aad87f215bfa5c6678d975d44ffb3a",
            "isKey": false,
            "numCitedBy": 795,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Texture-classification-and-segmentation-using-Mao-Jain",
            "title": {
                "fragments": [],
                "text": "Texture classification and segmentation using multiresolution simultaneous autoregressive models"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16685021"
                        ],
                        "name": "G. Sebestyen",
                        "slug": "G.-Sebestyen",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Sebestyen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sebestyen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 70
                            }
                        ],
                        "text": "Steps 2 to 4 can be viewed as finding an initialization for the final K-means step in 5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 15
                            }
                        ],
                        "text": "Similarly, the K-means centers will also encode albedo change vs. geometric 3D features, as well as reflectance properties (e.g. shiny vs. dull)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 21
                            }
                        ],
                        "text": "Quite naturally, the K-means algorithm will cluster them together."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The K-means algorithm is applied again on samples from all the images to achieve a local minimum."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "K-means is a greedy algorithm which iteratively performs the following two operations: (1) assign data vectors to the nearest of the K centers; (2) update each of the K centers to the mean of the data vectors assigned to it."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 20
                            }
                        ],
                        "text": "Thus, we call these K-means centers 3D textons, and the corresponding Nf il Nvl filter response vectors, the appearance vectors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "The textons (K-means cluster centers) are reconstructed and shown in (b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 185
                            }
                        ],
                        "text": "These vectors are clustered using a vector quantization algorithm, in particular K-means (Ball and Hall, 1967; Duda and Hart, 1973; Gersho and Gray, 1992; MacQueen, 1967; Ripley, 1996; Sebestyen, 1962)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 93
                            }
                        ],
                        "text": "A schematic diagram illustrating the steps of filtering, concatenating filter responses, and K-means clustering is shown in Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The K-means algorithm finds a local minimum of the following sum-of-square distance error:\nErr = N\u2211\ni=1 K\u2211 k=1 qik\u2016xi \u2212 ck\u20162\nwhere\nqik = 1 if \u2016xi \u2212 ck\u20162 < \u2016xi \u2212 c j\u20162 \u2200 j = 1, . . . , K and j = k qik = 0 otherwise\nN denotes the number of pixels; xi is the concatenated filter response vector of the i th pixel and ck is the appearance vector for the kth center."
                    },
                    "intents": []
                }
            ],
            "corpusId": 35957733,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9bca53122f2fc1806032603adda66a35242548db",
            "isKey": true,
            "numCitedBy": 71,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A pattern recognition technique is described in which a parametric representation of input signals or stimuli is employed. An input is considered as a vector, while the stimulus class is a multivariate process in the vector space. An adaptive sample set construction technique is described through which the conditional joint probability density of a class is approximated by the sum of Gaussian densities. The mean of each such density is an adaptively chosen \"typical\" sample of the class, and the set of samples so chosen are contained in the region of the space in which samples of the class are most populous. The decision process using the typical samples partitions the space into regions that envelop the chosen samples of a class. Arbitrary shaped and multiply connected regions can be constructed in this way, and multimodal probability densities can be approximated with a computationally simple procedure. Decision making on an incomplete set of parameters and on multiple observations of the input stimulus are discussed. This technique was successfully applied to the automatic recognition of speaker identity regardless of the spoken test. Experimental results are given."
            },
            "slug": "Pattern-recognition-by-an-adaptive-process-of-set-Sebestyen",
            "title": {
                "fragments": [],
                "text": "Pattern recognition by an adaptive process of sample set construction"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A pattern recognition technique is described in which a parametric representation of input signals or stimuli is employed and was successfully applied to the automatic recognition of speaker identity regardless of the spoken test."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104537710"
                        ],
                        "name": "J. MacQueen",
                        "slug": "J.-MacQueen",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "MacQueen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacQueen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 70
                            }
                        ],
                        "text": "Steps 2 to 4 can be viewed as finding an initialization for the final K-means step in 5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 15
                            }
                        ],
                        "text": "Similarly, the K-means centers will also encode albedo change vs. geometric 3D features, as well as reflectance properties (e.g. shiny vs. dull)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 21
                            }
                        ],
                        "text": "Quite naturally, the K-means algorithm will cluster them together."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The K-means algorithm is applied again on samples from all the images to achieve a local minimum."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "K-means is a greedy algorithm which iteratively performs the following two operations: (1) assign data vectors to the nearest of the K centers; (2) update each of the K centers to the mean of the data vectors assigned to it."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 20
                            }
                        ],
                        "text": "Thus, we call these K-means centers 3D textons, and the corresponding Nf il Nvl filter response vectors, the appearance vectors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "The textons (K-means cluster centers) are reconstructed and shown in (b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 155
                            }
                        ],
                        "text": "These vectors are clustered using a vector quantization algorithm, in particular K-means (Ball and Hall, 1967; Duda and Hart, 1973; Gersho and Gray, 1992; MacQueen, 1967; Ripley, 1996; Sebestyen, 1962)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 93
                            }
                        ],
                        "text": "A schematic diagram illustrating the steps of filtering, concatenating filter responses, and K-means clustering is shown in Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The K-means algorithm finds a local minimum of the following sum-of-square distance error:\nErr = N\u2211\ni=1 K\u2211 k=1 qik\u2016xi \u2212 ck\u20162\nwhere\nqik = 1 if \u2016xi \u2212 ck\u20162 < \u2016xi \u2212 c j\u20162 \u2200 j = 1, . . . , K and j = k qik = 0 otherwise\nN denotes the number of pixels; xi is the concatenated filter response vector of the i th pixel and ck is the appearance vector for the kth center."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6278891,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ac8ab51a86f1a9ae74dd0e4576d1a019f5e654ed",
            "isKey": true,
            "numCitedBy": 24203,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The main purpose of this paper is to describe a process for partitioning an N-dimensional population into k sets on the basis of a sample. The process, which is called 'k-means,' appears to give partitions which are reasonably efficient in the sense of within-class variance. That is, if p is the probability mass function for the population, S = {S1, S2, * *, Sk} is a partition of EN, and ui, i = 1, 2, * , k, is the conditional mean of p over the set Si, then W2(S) = ff=ISi f z u42 dp(z) tends to be low for the partitions S generated by the method. We say 'tends to be low,' primarily because of intuitive considerations, corroborated to some extent by mathematical analysis and practical computational experience. Also, the k-means procedure is easily programmed and is computationally economical, so that it is feasible to process very large samples on a digital computer. Possible applications include methods for similarity grouping, nonlinear prediction, approximating multivariate distributions, and nonparametric tests for independence among several variables. In addition to suggesting practical classification methods, the study of k-means has proved to be theoretically interesting. The k-means concept represents a generalization of the ordinary sample mean, and one is naturally led to study the pertinent asymptotic behavior, the object being to establish some sort of law of large numbers for the k-means. This problem is sufficiently interesting, in fact, for us to devote a good portion of this paper to it. The k-means are defined in section 2.1, and the main results which have been obtained on the asymptotic behavior are given there. The rest of section 2 is devoted to the proofs of these results. Section 3 describes several specific possible applications, and reports some preliminary results from computer experiments conducted to explore the possibilities inherent in the k-means idea. The extension to general metric spaces is indicated briefly in section 4. The original point of departure for the work described here was a series of problems in optimal classification (MacQueen [9]) which represented special"
            },
            "slug": "Some-methods-for-classification-and-analysis-of-MacQueen",
            "title": {
                "fragments": [],
                "text": "Some methods for classification and analysis of multivariate observations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "recognition (Belhumeur and Kriegman, 1998; Dana and Nayar,1999a; Georghiades et al., 1998; Murase and Nayar, 1995; Sirovitch and Kirby, 1987; Turk and Pentland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 982857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a62d0cca2fabf1d6f6ee15e4c14cef415b657d1",
            "isKey": false,
            "numCitedBy": 2592,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is presented for the representation of (pictures of) faces. Within a specified framework the representation is ideal. This results in the characterization of a face, to within an error bound, by a relatively low-dimensional vector. The method is illustrated in detail by the use of an ensemble of pictures taken for this purpose."
            },
            "slug": "Low-dimensional-procedure-for-the-characterization-Sirovich-Kirby",
            "title": {
                "fragments": [],
                "text": "Low-dimensional procedure for the characterization of human faces."
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A method is presented for the representation of faces that results in the characterization of a face, to within an error bound, by a relatively low-dimensional vector."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 111
                            }
                        ],
                        "text": "These vectors are clustered using a vector quantization algorithm, in particular K-means (Ball and Hall, 1967; Duda and Hart, 1973; Gersho and Gray, 1992; MacQueen, 1967; Ripley, 1996; Sebestyen, 1962)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16925,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144677513"
                        ],
                        "name": "David G. Jones",
                        "slug": "David-G.-Jones",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jones",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David G. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 101
                            }
                        ],
                        "text": "Each of the Pk can be obtained by multiplying the appearance vector ck with the pseudo-inverse of F (Jones and Malik, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In this representation, convolution with the filter bank is equivalent to multiplying each local image patch with F. Each of the Pk can be obtained by multiplying the appearance vector ck with the pseudo-inverse of F ( Jones and Malik, 1992 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13573519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef4da68443bd6fa826b05196f4fccdb62588a426",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computational-framework-for-determining-stereo-from-Jones-Malik",
            "title": {
                "fragments": [],
                "text": "Computational framework for determining stereo correspondence from a set of linear spatial filters"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608771"
                        ],
                        "name": "A. Gersho",
                        "slug": "A.-Gersho",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gersho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gersho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These vectors are clustered using a vector quantization algorithm, in particular K-means (Ball and Hall, 1967; Duda and Hart, 1973;  Gersho and Gray, 1992;  MacQueen, 1967; Ripley, 1996; Sebestyen, 1962)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118950728,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c564aa7639a08c280423489e52b6e32055c9aa7f",
            "isKey": false,
            "numCitedBy": 7027,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Introduction.- 1.1 Signals, Coding, and Compression.- 1.2 Optimality.- 1.3 How to Use this Book.- 1.4 Related Reading.- I Basic Tools.- 2 Random Processes and Linear Systems.- 2.1 Introduction.- 2.2 Probability.- 2.3 Random Variables and Vectors.- 2.4 Random Processes.- 2.5 Expectation.- 2.6 Linear Systems.- 2.7 Stationary and Ergodic Properties.- 2.8 Useful Processes.- 2.9 Problems.- 3 Sampling.- 3.1 Introduction.- 3.2 Periodic Sampling.- 3.3 Noise in Sampling.- 3.4 Practical Sampling Schemes.- 3.5 Sampling Jitter.- 3.6 Multidimensional Sampling.- 3.7 Problems.- 4 Linear Prediction.- 4.1 Introduction.- 4.2 Elementary Estimation Theory.- 4.3 Finite-Memory Linear Prediction.- 4.4 Forward and Backward Prediction.- 4.5 The Levinson-Durbin Algorithm.- 4.6 Linear Predictor Design from Empirical Data.- 4.7 Minimum Delay Property.- 4.8 Predictability and Determinism.- 4.9 Infinite Memory Linear Prediction.- 4.10 Simulation of Random Processes.- 4.11 Problems.- II Scalar Coding.- 5 Scalar Quantization I.- 5.1 Introduction.- 5.2 Structure of a Quantizer.- 5.3 Measuring Quantizer Performance.- 5.4 The Uniform Quantizer.- 5.5 Nonuniform Quantization and Companding.- 5.6 High Resolution: General Case.- 5.7 Problems.- 6 Scalar Quantization II.- 6.1 Introduction.- 6.2 Conditions for Optimality.- 6.3 High Resolution Optimal Companding.- 6.4 Quantizer Design Algorithms.- 6.5 Implementation.- 6.6 Problems.- 7 Predictive Quantization.- 7.1 Introduction.- 7.2 Difference Quantization.- 7.3 Closed-Loop Predictive Quantization.- 7.4 Delta Modulation.- 7.5 Problems.- 8 Bit Allocation and Transform Coding.- 8.1 Introduction.- 8.2 The Problem of Bit Allocation.- 8.3 Optimal Bit Allocation Results.- 8.4 Integer Constrained Allocation Techniques.- 8.5 Transform Coding.- 8.6 Karhunen-Loeve Transform.- 8.7 Performance Gain of Transform Coding.- 8.8 Other Transforms.- 8.9 Sub-band Coding.- 8.10 Problems.- 9 Entropy Coding.- 9.1 Introduction.- 9.2 Variable-Length Scalar Noiseless Coding.- 9.3 Prefix Codes.- 9.4 Huffman Coding.- 9.5 Vector Entropy Coding.- 9.6 Arithmetic Coding.- 9.7 Universal and Adaptive Entropy Coding.- 9.8 Ziv-Lempel Coding.- 9.9 Quantization and Entropy Coding.- 9.10 Problems.- III Vector Coding.- 10 Vector Quantization I.- 10.1 Introduction.- 10.2 Structural Properties and Characterization.- 10.3 Measuring Vector Quantizer Performance.- 10.4 Nearest Neighbor Quantizers.- 10.5 Lattice Vector Quantizers.- 10.6 High Resolution Distortion Approximations.- 10.7 Problems.- 11 Vector Quantization II.- 11.1 Introduction.- 11.2 Optimality Conditions for VQ.- 11.3 Vector Quantizer Design.- 11.4 Design Examples.- 11.5 Problems.- 12 Constrained Vector Quantization.- 12.1 Introduction.- 12.2 Complexity and Storage Limitations.- 12.3 Structurally Constrained VQ.- 12.4 Tree-Structured VQ.- 12.5 Classified VQ.- 12.6 Transform VQ.- 12.7 Product Code Techniques.- 12.8 Partitioned VQ.- 12.9 Mean-Removed VQ.- 12.10 Shape-Gain VQ.- 12.11 Multistage VQ.- 12.12 Constrained Storage VQ.- 12.13 Hierarchical and Multiresolution VQ.- 12.14 Nonlinear Interpolative VQ.- 12.15 Lattice Codebook VQ.- 12.16 Fast Nearest Neighbor Encoding.- 12.17 Problems.- 13 Predictive Vector Quantization.- 13.1 Introduction.- 13.2 Predictive Vector Quantization.- 13.3 Vector Linear Prediction.- 13.4 Predictor Design from Empirical Data.- 13.5 Nonlinear Vector Prediction.- 13.6 Design Examples.- 13.7 Problems.- 14 Finite-State Vector Quantization.- 14.1 Recursive Vector Quantizers.- 14.2 Finite-State Vector Quantizers.- 14.3 Labeled-States and Labeled-Transitions.- 14.4 Encoder/Decoder Design.- 14.5 Next-State Function Design.- 14.6 Design Examples.- 14.7 Problems.- 15 Tree and Trellis Encoding.- 15.1 Delayed Decision Encoder.- 15.2 Tree and Trellis Coding.- 15.3 Decoder Design.- 15.4 Predictive Trellis Encoders.- 15.5 Other Design Techniques.- 15.6 Problems.- 16 Adaptive Vector Quantization.- 16.1 Introduction.- 16.2 Mean Adaptation.- 16.3 Gain-Adaptive Vector Quantization.- 16.4 Switched Codebook Adaptation.- 16.5 Adaptive Bit Allocation.- 16.6 Address VQ.- 16.7 Progressive Code Vector Updating.- 16.8 Adaptive Codebook Generation.- 16.9 Vector Excitation Coding.- 16.10 Problems.- 17 Variable Rate Vector Quantization.- 17.1 Variable Rate Coding.- 17.2 Variable Dimension VQ.- 17.3 Alternative Approaches to Variable Rate VQ.- 17.4 Pruned Tree-Structured VQ.- 17.5 The Generalized BFOS Algorithm.- 17.6 Pruned Tree-Structured VQ.- 17.7 Entropy Coded VQ.- 17.8 Greedy Tree Growing.- 17.9 Design Examples.- 17.10 Bit Allocation Revisited.- 17.11 Design Algorithms.- 17.12 Problems."
            },
            "slug": "Vector-quantization-and-signal-compression-Gersho-Gray",
            "title": {
                "fragments": [],
                "text": "Vector quantization and signal compression"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The author explains the design and implementation of the Levinson-Durbin Algorithm, which automates the very labor-intensive and therefore time-heavy and expensive process of designing and implementing a Quantizer."
            },
            "venue": {
                "fragments": [],
                "text": "The Kluwer international series in engineering and computer science"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144615207"
                        ],
                        "name": "G. Ball",
                        "slug": "G.-Ball",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Ball",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ball"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082341438"
                        ],
                        "name": "D. J. Hall",
                        "slug": "D.-J.-Hall",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hall",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. J. Hall"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 70
                            }
                        ],
                        "text": "Steps 2 to 4 can be viewed as finding an initialization for the final K-means step in 5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 15
                            }
                        ],
                        "text": "Similarly, the K-means centers will also encode albedo change vs. geometric 3D features, as well as reflectance properties (e.g. shiny vs. dull)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 21
                            }
                        ],
                        "text": "Quite naturally, the K-means algorithm will cluster them together."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The K-means algorithm is applied again on samples from all the images to achieve a local minimum."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "K-means is a greedy algorithm which iteratively performs the following two operations: (1) assign data vectors to the nearest of the K centers; (2) update each of the K centers to the mean of the data vectors assigned to it."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 20
                            }
                        ],
                        "text": "Thus, we call these K-means centers 3D textons, and the corresponding Nf il Nvl filter response vectors, the appearance vectors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "The textons (K-means cluster centers) are reconstructed and shown in (b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 90
                            }
                        ],
                        "text": "These vectors are clustered using a vector quantization algorithm, in particular K-means (Ball and Hall, 1967; Duda and Hart, 1973; Gersho and Gray, 1992; MacQueen, 1967; Ripley, 1996; Sebestyen, 1962)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 93
                            }
                        ],
                        "text": "A schematic diagram illustrating the steps of filtering, concatenating filter responses, and K-means clustering is shown in Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The K-means algorithm finds a local minimum of the following sum-of-square distance error:\nErr = N\u2211\ni=1 K\u2211 k=1 qik\u2016xi \u2212 ck\u20162\nwhere\nqik = 1 if \u2016xi \u2212 ck\u20162 < \u2016xi \u2212 c j\u20162 \u2200 j = 1, . . . , K and j = k qik = 0 otherwise\nN denotes the number of pixels; xi is the concatenated filter response vector of the i th pixel and ck is the appearance vector for the kth center."
                    },
                    "intents": []
                }
            ],
            "corpusId": 27174749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7d04596a7a0e6e6b8c9199ce4aba2d2a6f3dbc6",
            "isKey": true,
            "numCitedBy": 915,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Scientific measurements frequently involve large numbers of variables whose complex interactions are not easily found. A practical computing method termed ISODATA, which finds the cluster structure of such data, is described. The resulting description of the data provides a fit to the data of a set of cluster centers that tends to minimize the sum of the squared distances of each data point from its closest cluster center. An application to the grouping or clustering of the answers of 209 people to an 80-question sociological survey illustrates the utility of the method."
            },
            "slug": "A-clustering-technique-for-summarizing-multivariate-Ball-Hall",
            "title": {
                "fragments": [],
                "text": "A clustering technique for summarizing multivariate data."
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A practical computing method termed ISODATA, which finds the cluster structure of such data, is described and provides a fit to the data of a set of cluster centers that tends to minimize the sum of the squared distances of each data point from its closest cluster center."
            },
            "venue": {
                "fragments": [],
                "text": "Behavioral science"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 70
                            }
                        ],
                        "text": "Steps 2 to 4 can be viewed as finding an initialization for the final K-means step in 5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 15
                            }
                        ],
                        "text": "Similarly, the K-means centers will also encode albedo change vs. geometric 3D features, as well as reflectance properties (e.g. shiny vs. dull)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 21
                            }
                        ],
                        "text": "Quite naturally, the K-means algorithm will cluster them together."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The K-means algorithm is applied again on samples from all the images to achieve a local minimum."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "K-means is a greedy algorithm which iteratively performs the following two operations: (1) assign data vectors to the nearest of the K centers; (2) update each of the K centers to the mean of the data vectors assigned to it."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 20
                            }
                        ],
                        "text": "Thus, we call these K-means centers 3D textons, and the corresponding Nf il Nvl filter response vectors, the appearance vectors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "The textons (K-means cluster centers) are reconstructed and shown in (b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 171
                            }
                        ],
                        "text": "These vectors are clustered using a vector quantization algorithm, in particular K-means (Ball and Hall, 1967; Duda and Hart, 1973; Gersho and Gray, 1992; MacQueen, 1967; Ripley, 1996; Sebestyen, 1962)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 93
                            }
                        ],
                        "text": "A schematic diagram illustrating the steps of filtering, concatenating filter responses, and K-means clustering is shown in Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The K-means algorithm finds a local minimum of the following sum-of-square distance error:\nErr = N\u2211\ni=1 K\u2211 k=1 qik\u2016xi \u2212 ck\u20162\nwhere\nqik = 1 if \u2016xi \u2212 ck\u20162 < \u2016xi \u2212 c j\u20162 \u2200 j = 1, . . . , K and j = k qik = 0 otherwise\nN denotes the number of pixels; xi is the concatenated filter response vector of the i th pixel and ck is the appearance vector for the kth center."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9584248,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "877a887e7af7daebcb685e4d7b5e80f764035581",
            "isKey": true,
            "numCitedBy": 4041,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Title Type pattern recognition with neural networks in c++ PDF pattern recognition and neural networks PDF neural networks for pattern recognition advanced texts in econometrics PDF neural networks for applied sciences and engineering from fundamentals to complex pattern recognition PDF an introduction to biological and artificial neural networks for pattern recognition spie tutorial text vol tt04 tutorial texts in optical engineering PDF"
            },
            "slug": "Pattern-Recognition-and-Neural-Networks-LeCun-Bengio",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition and Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48590121"
                        ],
                        "name": "S. Teukolsky",
                        "slug": "S.-Teukolsky",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Teukolsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teukolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608024"
                        ],
                        "name": "W. Vetterling",
                        "slug": "W.-Vetterling",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Vetterling",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Vetterling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35046585"
                        ],
                        "name": "B. Flannery",
                        "slug": "B.-Flannery",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Flannery",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flannery"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 52
                            }
                        ],
                        "text": "P(\u03c72 | \u03bd) is given by the incomplete gamma function (Press et al., 1988):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 51
                            }
                        ],
                        "text": "P(\u03c72 | \u03bd) is given by the incomplete gamma function (Press et al., 1988):\nP(\u03c72 | \u03bd) = Q(\u03bd/2, \u03c72/2) and (2)\nQ(a, x) = 1 (a) \u222b x 0 e\u2212t ta\u22121 dt\nwhere (a) is the gamma function."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61769312,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "ca2832d2c30287a9ee5b8584cc498d2b1cb14753",
            "isKey": false,
            "numCitedBy": 16689,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Note: Includes bibliographical references, 3 appendixes and 2 indexes.- Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08"
            },
            "slug": "Numerical-recipes-in-C-Press-Teukolsky",
            "title": {
                "fragments": [],
                "text": "Numerical recipes in C"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121473402"
                        ],
                        "name": "P. Vaidyanathan",
                        "slug": "P.-Vaidyanathan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Vaidyanathan",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vaidyanathan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The reconstruction task is trivial for orthogonal or self-inverting filter banks (Burt and Adelson, 1983; Heeger and Bergen, 1995;  Vaidyanathan, 1993 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 106661662,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "018b485106f9af2df689e0841f342e81121c8949",
            "isKey": false,
            "numCitedBy": 3536,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction 2. Review of Discrete-Time Systems 3. Review of Digital Filters 4. Fundamentals of Multirate Systems 5. Maximally Decimated Filter Banks 6. Paraunitary Perfect Reconstruction Filter Banks 7. Linear Phase Perfect Reconstruction QMF Banks 8. Cosine Modulated Filter Banks 9. Finite Word Length Effects 10. Multirate Filter Bank Theory and Related Topics 11. The Wavelet Transform and Relation to Multirate Filter Banks 12. Multidimensional Multirate Systems 13. Review of Discrete-Time Multi-Input Multi-Output LTI Systems 14. Paraunitary and Lossless Systems Appendices Bibliography Index"
            },
            "slug": "Multirate-Systems-And-Filter-Banks-Vaidyanathan",
            "title": {
                "fragments": [],
                "text": "Multirate Systems And Filter Banks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089883"
                        ],
                        "name": "W. Gilks",
                        "slug": "W.-Gilks",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Gilks",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gilks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50130827"
                        ],
                        "name": "S. Richardson",
                        "slug": "S.-Richardson",
                        "structuredName": {
                            "firstName": "Sylvia",
                            "lastName": "Richardson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Richardson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 221894711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fbcff06339605696423609c0f3c02737c9e91e4",
            "isKey": false,
            "numCitedBy": 4093,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "INTRODUCING MARKOV CHAIN MONTE CARLO Introduction The Problem Markov Chain Monte Carlo Implementation Discussion HEPATITIS B: A CASE STUDY IN MCMC METHODS Introduction Hepatitis B Immunization Modelling Fitting a Model Using Gibbs Sampling Model Elaboration Conclusion MARKOV CHAIN CONCEPTS RELATED TO SAMPLING ALGORITHMS Markov Chains Rates of Convergence Estimation The Gibbs Sampler and Metropolis-Hastings Algorithm INTRODUCTION TO GENERAL STATE-SPACE MARKOV CHAIN THEORY Introduction Notation and Definitions Irreducibility, Recurrence, and Convergence Harris Recurrence Mixing Rates and Central Limit Theorems Regeneration Discussion FULL CONDITIONAL DISTRIBUTIONS Introduction Deriving Full Conditional Distributions Sampling from Full Conditional Distributions Discussion STRATEGIES FOR IMPROVING MCMC Introduction Reparameterization Random and Adaptive Direction Sampling Modifying the Stationary Distribution Methods Based on Continuous-Time Processes Discussion IMPLEMENTING MCMC Introduction Determining the Number of Iterations Software and Implementation Output Analysis Generic Metropolis Algorithms Discussion INFERENCE AND MONITORING CONVERGENCE Difficulties in Inference from Markov Chain Simulation The Risk of Undiagnosed Slow Convergence Multiple Sequences and Overdispersed Starting Points Monitoring Convergence Using Simulation Output Output Analysis for Inference Output Analysis for Improving Efficiency MODEL DETERMINATION USING SAMPLING-BASED METHODS Introduction Classical Approaches The Bayesian Perspective and the Bayes Factor Alternative Predictive Distributions How to Use Predictive Distributions Computational Issues An Example Discussion HYPOTHESIS TESTING AND MODEL SELECTION Introduction Uses of Bayes Factors Marginal Likelihood Estimation by Importance Sampling Marginal Likelihood Estimation Using Maximum Likelihood Application: How Many Components in a Mixture? Discussion Appendix: S-PLUS Code for the Laplace-Metropolis Estimator MODEL CHECKING AND MODEL IMPROVEMENT Introduction Model Checking Using Posterior Predictive Simulation Model Improvement via Expansion Example: Hierarchical Mixture Modelling of Reaction Times STOCHASTIC SEARCH VARIABLE SELECTION Introduction A Hierarchical Bayesian Model for Variable Selection Searching the Posterior by Gibbs Sampling Extensions Constructing Stock Portfolios With SSVS Discussion BAYESIAN MODEL COMPARISON VIA JUMP DIFFUSIONS Introduction Model Choice Jump-Diffusion Sampling Mixture Deconvolution Object Recognition Variable Selection Change-Point Identification Conclusions ESTIMATION AND OPTIMIZATION OF FUNCTIONS Non-Bayesian Applications of MCMC Monte Carlo Optimization Monte Carlo Likelihood Analysis Normalizing-Constant Families Missing Data Decision Theory Which Sampling Distribution? Importance Sampling Discussion STOCHASTIC EM: METHOD AND APPLICATION Introduction The EM Algorithm The Stochastic EM Algorithm Examples GENERALIZED LINEAR MIXED MODELS Introduction Generalized Linear Models (GLMs) Bayesian Estimation of GLMs Gibbs Sampling for GLMs Generalized Linear Mixed Models (GLMMs) Specification of Random-Effect Distributions Hyperpriors and the Estimation of Hyperparameters Some Examples Discussion HIERARCHICAL LONGITUDINAL MODELLING Introduction Clinical Background Model Detail and MCMC Implementation Results Summary and Discussion MEDICAL MONITORING Introduction Modelling Medical Monitoring Computing Posterior Distributions Forecasting Model Criticism Illustrative Application Discussion MCMC FOR NONLINEAR HIERARCHICAL MODELS Introduction Implementing MCMC Comparison of Strategies A Case Study from Pharmacokinetics-Pharmacodynamics Extensions and Discussion BAYESIAN MAPPING OF DISEASE Introduction Hypotheses and Notation Maximum Likelihood Estimation of Relative Risks Hierarchical Bayesian Model of Relative Risks Empirical Bayes Estimation of Relative Risks Fully Bayesian Estimation of Relative Risks Discussion MCMC IN IMAGE ANALYSIS Introduction The Relevance of MCMC to Image Analysis Image Models at Different Levels Methodological Innovations in MCMC Stimulated by Imaging Discussion MEASUREMENT ERROR Introduction Conditional-Independence Modelling Illustrative examples Discussion GIBBS SAMPLING METHODS IN GENETICS Introduction Standard Methods in Genetics Gibbs Sampling Approaches MCMC Maximum Likelihood Application to a Family Study of Breast Cancer Conclusions MIXTURES OF DISTRIBUTIONS: INFERENCE AND ESTIMATION Introduction The Missing Data Structure Gibbs Sampling Implementation Convergence of the Algorithm Testing for Mixtures Infinite Mixtures and Other Extensions AN ARCHAEOLOGICAL EXAMPLE: RADIOCARBON DATING Introduction Background to Radiocarbon Dating Archaeological Problems and Questions Illustrative Examples Discussion Index"
            },
            "slug": "Markov-Chain-Monte-Carlo-in-Practice-Gilks-Richardson",
            "title": {
                "fragments": [],
                "text": "Markov Chain Monte Carlo in Practice"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The Markov Chain Monte Carlo Implementation Results Summary and Discussion MEDICAL MONITORING Introduction Modelling Medical Monitoring Computing Posterior Distributions Forecasting Model Criticism Illustrative Application Discussion MCMC for NONLINEAR HIERARCHICAL MODELS."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 70
                            }
                        ],
                        "text": "Steps 2 to 4 can be viewed as finding an initialization for the final K-means step in 5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 15
                            }
                        ],
                        "text": "Similarly, the K-means centers will also encode albedo change vs. geometric 3D features, as well as reflectance properties (e.g. shiny vs. dull)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 21
                            }
                        ],
                        "text": "Quite naturally, the K-means algorithm will cluster them together."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The K-means algorithm is applied again on samples from all the images to achieve a local minimum."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "K-means is a greedy algorithm which iteratively performs the following two operations: (1) assign data vectors to the nearest of the K centers; (2) update each of the K centers to the mean of the data vectors assigned to it."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 20
                            }
                        ],
                        "text": "Thus, we call these K-means centers 3D textons, and the corresponding Nf il Nvl filter response vectors, the appearance vectors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "The textons (K-means cluster centers) are reconstructed and shown in (b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 111
                            }
                        ],
                        "text": "These vectors are clustered using a vector quantization algorithm, in particular K-means (Ball and Hall, 1967; Duda and Hart, 1973; Gersho and Gray, 1992; MacQueen, 1967; Ripley, 1996; Sebestyen, 1962)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 93
                            }
                        ],
                        "text": "A schematic diagram illustrating the steps of filtering, concatenating filter responses, and K-means clustering is shown in Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The K-means algorithm finds a local minimum of the following sum-of-square distance error:\nErr = N\u2211\ni=1 K\u2211 k=1 qik\u2016xi \u2212 ck\u20162\nwhere\nqik = 1 if \u2016xi \u2212 ck\u20162 < \u2016xi \u2212 c j\u20162 \u2200 j = 1, . . . , K and j = k qik = 0 otherwise\nN denotes the number of pixels; xi is the concatenated filter response vector of the i th pixel and ck is the appearance vector for the kth center."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pattern Classification and Scene Analysis, John Wiley & Sons"
            },
            "venue": {
                "fragments": [],
                "text": "New York, N.Y."
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 70
                            }
                        ],
                        "text": "Steps 2 to 4 can be viewed as finding an initialization for the final K-means step in 5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 15
                            }
                        ],
                        "text": "Similarly, the K-means centers will also encode albedo change vs. geometric 3D features, as well as reflectance properties (e.g. shiny vs. dull)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 21
                            }
                        ],
                        "text": "Quite naturally, the K-means algorithm will cluster them together."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The K-means algorithm is applied again on samples from all the images to achieve a local minimum."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "K-means is a greedy algorithm which iteratively performs the following two operations: (1) assign data vectors to the nearest of the K centers; (2) update each of the K centers to the mean of the data vectors assigned to it."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 20
                            }
                        ],
                        "text": "Thus, we call these K-means centers 3D textons, and the corresponding Nf il Nvl filter response vectors, the appearance vectors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "The textons (K-means cluster centers) are reconstructed and shown in (b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 132
                            }
                        ],
                        "text": "These vectors are clustered using a vector quantization algorithm, in particular K-means (Ball and Hall, 1967; Duda and Hart, 1973; Gersho and Gray, 1992; MacQueen, 1967; Ripley, 1996; Sebestyen, 1962)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 93
                            }
                        ],
                        "text": "A schematic diagram illustrating the steps of filtering, concatenating filter responses, and K-means clustering is shown in Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The K-means algorithm finds a local minimum of the following sum-of-square distance error:\nErr = N\u2211\ni=1 K\u2211 k=1 qik\u2016xi \u2212 ck\u20162\nwhere\nqik = 1 if \u2016xi \u2212 ck\u20162 < \u2016xi \u2212 c j\u20162 \u2200 j = 1, . . . , K and j = k qik = 0 otherwise\nN denotes the number of pixels; xi is the concatenated filter response vector of the i th pixel and ck is the appearance vector for the kth center."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vector Quantization and Signal Compression, Kluwer Academic Publishers"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 131
                            }
                        ],
                        "text": "The reconstruction task is trivial for orthogonal or self-inverting filter banks (Burt and Adelson, 1983; Heeger and Bergen, 1995; Vaidyanathan, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multirate Systems and Filter Banks, PrenticeHall: Englewood Cliffs, N.J"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 62
                            }
                        ],
                        "text": "Two of the representative techniques are Markov random fields (Chellappa and Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 137
                            }
                        ],
                        "text": "Two of the representative techniques are Markov random fields (Chellappa and Chatterjee, 1985; Cross and Jain, 1983; Mao and Jain, 1992; Yuan and Rao, 1993; Zhu et al., 1998) and filter responses (Fogel and Sagi, 1989; Jain\n\u2217Present address: Compaq Cambridge Research Laboratory.\nand Farrokhsia,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Spectral estimation for random fields with applications to Markov modeling and texture classification"
            },
            "venue": {
                "fragments": [],
                "text": "Markov Random Fields: Theory and Application, R. Chellappa and A. Jain (Eds.). Academic Press."
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 30,
            "methodology": 26,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 50,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Representing-and-Recognizing-the-Visual-Appearance-Leung-Malik/90d6e7f2202f754d8588f9536e3f5b4a24701f24?sort=total-citations"
}