{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143991676"
                        ],
                        "name": "I. Laptev",
                        "slug": "I.-Laptev",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Laptev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Laptev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2619278,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f90d79809325d2b78e35a79ecb372407f81b3993",
            "isKey": false,
            "numCitedBy": 2381,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Local image features or interest points provide compact and abstract representations of patterns in an image. We propose to extend the notion of spatial interest points into the spatio-temporal domain and show how the resulting features often reflect interesting events that can be used for a compact representation of video data as well as for its interpretation. To detect spatio-temporal events, we build on the idea of the Harris and Forstner interest point operators and detect local structures in space-time where the image values have significant local variations in both space and time. We then estimate the spatio-temporal extents of the detected events and compute their scale-invariant spatio-temporal descriptors. Using such descriptors, we classify events and construct video representation in terms of labeled space-time points. For the problem of human motion analysis, we illustrate how the proposed method allows for detection of walking people in scenes with occlusions and dynamic backgrounds."
            },
            "slug": "Space-time-interest-points-Laptev-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Space-time interest points"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work builds on the idea of the Harris and Forstner interest point operators and detects local structures in space-time where the image values have significant local variations in both space and time to detect spatio-temporal events."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143991676"
                        ],
                        "name": "I. Laptev",
                        "slug": "I.-Laptev",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Laptev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Laptev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3781038,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "ca8cdcfe78424e27fc1cc96415a99326fd2655a0",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Several types of interest point detectors have been proposed for spatial images. This paper investigates how this notion can be generalised to the detection of interesting events in space-time data. Moreover, we develop a mechanism for spatio-temporal scale selection and detect events at scales corresponding to their extent in both space and time. \n \nTo detect spatio-temporal events, we build on the idea of the Harris and Forstner interest point operators and detect regions in space-time where the image structures have significant local variations in both space and time. In this way, events that correspond to curved space-time structures are emphasised, while structures with locally constant motion are disregarded. \n \nTo construct this operator, we start from a multi-scale windowed second moment matrix in space-time, and combine the determinant and the trace in a similar way as for the spatial Harris operator. All spacetime maxima of this operator are then adapted to characteristic scales by maximising a scale-normalised space-time Laplacian operator over both spatial scales and temporal scales. The motivation for performing temporal scale selection as a complement to previous approaches of spatial scale selection is to be able to robustly capture spatio-temporal events of different temporal extent. It is shown that the resulting approach is truly scale invariant with respect to both spatial scales and temporal scales. The proposed concept is tested on synthetic and real image sequences. \n \nIt is shown that the operator responds to distinct and stable points in space-time that often correspond to interesting events. The potential applications of the method are discussed."
            },
            "slug": "Interest-Point-Detection-and-Scale-Selection-in-Laptev-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Interest Point Detection and Scale Selection in Space-Time"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A mechanism for spatio-temporal scale selection and detect events at scales corresponding to their extent in both space and time, and it is shown that the resulting approach is truly scale invariant with respect to both spatial scales and temporal scales."
            },
            "venue": {
                "fragments": [],
                "text": "Scale-Space"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143991676"
                        ],
                        "name": "I. Laptev",
                        "slug": "I.-Laptev",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Laptev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Laptev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 264
                            }
                        ],
                        "text": "\u2026as the current scheme of event detection is not invariant under Galilean transformations, future work should investigate the possibilities of including such invariance and making the approach independent of the relative camera motion (Laptev and Lindeberg, 2002; Laptev and Lindeberg, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10876296,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43060ead33fbbeb7baf79c1557ceee97fb4f49aa",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The notion of local features in space-time has recently been proposed to capture and describe local events in video. When computing space-time descriptors, however, the result may strongly depend on the relative motion between the object and the camera. To compensate for this variation, we present a method that automatically adapts the features to the local velocity of the image pattern and, hence, results in a video representation that is stable with respect to different amounts of camera motion. Experimentally we show that the use of velocity adaptation substantially increases the repeatability of interest points as well as the stability of their associated descriptors. Moreover, for an application to human action recognition we demonstrate how velocity-adapted features enable recognition of human actions in situations with unknown camera motion and complex, non-stationary backgrounds."
            },
            "slug": "Velocity-adaptation-of-space-time-interest-points-Laptev-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Velocity adaptation of space-time interest points"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents a method that automatically adapts the features to the local velocity of the image pattern and results in a video representation that is stable with respect to different amounts of camera motion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145517633"
                        ],
                        "name": "A. Akbarzadeh",
                        "slug": "A.-Akbarzadeh",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Akbarzadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Akbarzadeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143991676"
                        ],
                        "name": "I. Laptev",
                        "slug": "I.-Laptev",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Laptev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Laptev"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118247938,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "49d1ad30516d6fe32a348fc7a8cb97d66154af07",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a set of image operators for detecting regions in space-time where interesting events occur. To define such regions of interest, we compute a spatio-temporal secondmoment matrix from a spatio-temporal scale-space representation, and diagonalize this matrix locally, using a local Galilean transformation in space-time, optionally combined with a spatial rotation, so as to make the Galilean invariant degrees of freedom explicit. From the Galilean-diagonalized descriptor so obtained, we then formulate different types of space-time interest operators, and illustrate their properties on different types of image sequences."
            },
            "slug": "Galilean-corrected-spatio-temporal-interest-Lindeberg-Akbarzadeh",
            "title": {
                "fragments": [],
                "text": "Galilean-corrected spatio-temporal interest operators"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143991676"
                        ],
                        "name": "I. Laptev",
                        "slug": "I.-Laptev",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Laptev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Laptev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 300,
                                "start": 244
                            }
                        ],
                        "text": "Moreover, as the current scheme of event detection is not invariant under Galilean transformations, future work should investigate the possibilities of including such invariance and making the approach independent of the relative camera motion (Laptev and Lindeberg, 2002; Laptev and Lindeberg, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 236
                            }
                        ],
                        "text": "\u2026as the current scheme of event detection is not invariant under Galilean transformations, future work should investigate the possibilities of including such invariance and making the approach independent of the relative camera motion (Laptev and Lindeberg, 2002; Laptev and Lindeberg, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1760419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e52966380c60a2002e461d87e37f659d71c397d",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Velocity-adaptation-of-spatio-temporal-receptive-of-Laptev-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Velocity adaptation of spatio-temporal receptive fields for direct recognition of activities: an experimental study"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 13309452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7219632109afdc5f5dc43c1580defd0ad3be7aed",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a theory for constructing and computing velocity-adapted scale-space filters for spatio-temporal image data. Starting from basic criteria in terms of time-causality, time-recursivity, locality and adaptivity with respect to motion estimates, a family of spatio-temporal recursive filters is proposed and analysed. An important property of the proposed family of smoothing kernels is that the spatio-temporal covariance matrices of the discrete kernels obey similar transformation properties under Galilean transformations as for continuous smoothing kernels on continuous domains. Moreover, the proposed theory provides an efficient way to compute and generate nonseparable scale-space representations without need for explicit external warping mechanisms or keeping extended temporal buffers of the past. The approach can thus be seen as a natural extension of recursive scale-space filters from pure temporal data to spatio-temporal domains."
            },
            "slug": "Time-Recursive-Velocity-Adapted-Spatio-Temporal-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Time-Recursive Velocity-Adapted Spatio-Temporal Scale-Space Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The proposed theory provides an efficient way to compute and generate nonseparable scale-space representations without need for explicit external warping mechanisms or keeping extended temporal buffers of the past."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398327241"
                        ],
                        "name": "Lihi Zelnik-Manor",
                        "slug": "Lihi-Zelnik-Manor",
                        "structuredName": {
                            "firstName": "Lihi",
                            "lastName": "Zelnik-Manor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lihi Zelnik-Manor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144611617"
                        ],
                        "name": "M. Irani",
                        "slug": "M.-Irani",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Irani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Irani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 67
                            }
                        ],
                        "text": "As events often have characteristic extents in both space and time (Koenderink, 1988; Lindeberg and Fagerstr\u00f6m, 1996; Florack, 1997; Lindeberg, 1997; Chomat et al., 2000b; Zelnik-Manor and Irani, 2001), we investigate the behavior of interest points in spatiotemporal scale-space and adapt both the spatial and the temporal scales of the detected features in Section 3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 150
                            }
                        ],
                        "text": "\u2026extents in both space and time (Koenderink, 1988; Lindeberg and Fagerstro\u0308m, 1996; Florack, 1997; Lindeberg, 1997; Chomat, Martin and Crowley, 2000b; Zelnik-Manor and Irani, 2001), we investigate the behavior of interest points in spatio-temporal scale-space and adapt both the spatial and the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 86361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cef1a7aab17a1e4c7e7abdc027c7706287d6edad",
            "isKey": false,
            "numCitedBy": 457,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Dynamic events can be regarded as long-term temporal objects, which are characterized by spatio-temporal features at multiple temporal scales. Based on this, we design a simple statistical distance measure between video sequences (possibly of different lengths) based on their behavioral content. This measure is non-parametric and can thus handle a wide range of dynamic events. We use this measure for isolating and clustering events within long continuous video sequences. This is done without prior knowledge of the types of events, their models, or their temporal extent. An outcome of such a clustering process is a temporal segmentation of long video sequences into event-consistent sub-sequences, and their grouping into event-consistent clusters. Our event representation and associated distance measure can also be used for event-based indexing into long video sequences, even when only one short example-clip is available. However, when multiple example-clips of the same event are available (either as a result of the clustering process, or given manually), these can be used to refine the event representation, the associated distance measure, and accordingly the quality of the detection and clustering process."
            },
            "slug": "Event-based-analysis-of-video-Zelnik-Manor-Irani",
            "title": {
                "fragments": [],
                "text": "Event-based analysis of video"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A simple statistical distance measure between video sequences based on their behavioral content that can handle a wide range of dynamic events and be used for isolating and clustering events within long continuous video sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 106
                            }
                        ],
                        "text": "In real-time situations, when using causal scalespace representation based on recursive temporal filters (Lindeberg and Fagerstro\u0308m, 1996; Lindeberg, 2002), only a fixed set of discrete temporal scales is available at any moment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 83
                            }
                        ],
                        "text": "For real-time implementation, time-causal scale-space filters thus have to be used (Koenderink, 1988; Lindeberg and Fagerstr\u00f6m, 1996; Florack, 1997; Lindeberg, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 86
                            }
                        ],
                        "text": "As events often have characteristic extents in both space and time (Koenderink, 1988; Lindeberg and Fagerstro\u0308m, 1996; Florack, 1997; Lindeberg, 1997; Chomat, Martin and Crowley, 2000b; Zelnik-Manor and Irani, 2001), we investigate the behavior of interest points in spatio-temporal scale-space and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 102
                            }
                        ],
                        "text": "For real-time implementation, time-causal scale-space filters thus have to be used (Koenderink, 1988; Lindeberg and Fagerstro\u0308m, 1996; Florack, 1997; Lindeberg, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 67
                            }
                        ],
                        "text": "As events often have characteristic extents in both space and time (Koenderink, 1988; Lindeberg and Fagerstr\u00f6m, 1996; Florack, 1997; Lindeberg, 1997; Chomat, Martin and Crowley, 2000b; Zelnik-Manor and Irani, 2001), we investigate the behavior of interest points in spatio-temporal scale-space and adapt both the spatial and the temporal scales of the detected features in section 3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 105
                            }
                        ],
                        "text": "In real-time situations, when using causal scalespace representation based on recursive temporal filters (Lindeberg and Fagerstr\u00f6m, 1996; Lindeberg, 2002), only a fixed set of discrete temporal scales is available at any moment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12178902,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d0ba750c8f006dd56f5a03e8b5d2828e6ddb2050",
            "isKey": true,
            "numCitedBy": 50,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a theory for multi-scale representation of temporal data. Assuming that a real-time vision system should represent the incoming data at di erent time scales, an additional causality constraint arises compared to traditional scale-space theory|we can only use what has occurred in the past for computing representations at coarser time scales. Based on a previously developed scale-space theory in terms of noncreation of local maxima with increasing scale, a complete classi cation is given of the scale-space kernels that satisfy this property of non-creation of structure and respect the time direction as causal . It is shown that the cases of continuous and discrete time are inherently di erent. For continuous time, there is no non-trivial time-causal semi-group structure. Hence, the time-scale parameter must be discretized, and the only way to construct a linear multi-time-scale representation is by (cascade) convolution with truncated exponential functions having (possibly) di erent time constants. For discrete time, there is a canonical semi-group structure allowing for a continuous temporal scale parameter. It gives rise to a Poisson-type temporal scale-space. In addition, geometric moving average kernels and time-delayed generalized binomial kernels satisfy temporal causality and allow for highly e cient implementations. It is shown that temporal derivatives and derivative approximations can be obtained directly as linear combinations of the temporal channels in the multi-time-scale representation. Hence, to maintain a representation of temporal derivatives at multiple time scales, there is no need for other time bu ers than the temporal channels in the multi-time-scale representation. The framework presented constitutes a useful basis for expressing a large class of algorithms for computer vision, image processing and coding."
            },
            "slug": "Scale-space-with-Causal-Time-Direction-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Scale-space with Causal Time Direction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 130
                            }
                        ],
                        "text": "Highly successful applications of interest points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe, 1999; Hall et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 145
                            }
                        ],
                        "text": "\u2026applications of interest points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8571961,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9c7a96155f10f152cae0866102c061cdf6da02e8",
            "isKey": false,
            "numCitedBy": 1683,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images."
            },
            "slug": "An-Affine-Invariant-Interest-Point-Detector-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "An Affine Invariant Interest Point Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel approach for detecting affine invariant interest points that can deal with significant affine transformations including large scale changes and shows an excellent performance in the presence of large perspective transformations including significant scale changes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Other approaches use spatio-temporal image cues such as optical flow (Black et al., 1997) or motion templates (Baumberg and Hogg, 1996;  Efros et al., 2003 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1350374,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "804d86dd7ab3498266922244e73a88c1add5a6ab",
            "isKey": false,
            "numCitedBy": 1470,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Our goal is to recognize human action at a distance, at resolutions where a whole person may be, say, 30 pixels tall. We introduce a novel motion descriptor based on optical flow measurements in a spatiotemporal volume for each stabilized human figure, and an associated similarity measure to be used in a nearest-neighbor framework. Making use of noisy optical flow measurements is the key challenge, which is addressed by treating optical flow not as precise pixel displacements, but rather as a spatial pattern of noisy measurements which are carefully smoothed and aggregated to form our spatiotemporal motion descriptor. To classify the action being performed by a human figure in a query sequence, we retrieve nearest neighbor(s) from a database of stored, annotated video sequences. We can also use these retrieved exemplars to transfer 2D/3D skeletons onto the figures in the query sequence, as well as two forms of data-based action synthesis \"do as I do\" and \"do as I say\". Results are demonstrated on ballet, tennis as well as football datasets."
            },
            "slug": "Recognizing-action-at-a-distance-Efros-Berg",
            "title": {
                "fragments": [],
                "text": "Recognizing action at a distance"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A novel motion descriptor based on optical flow measurements in a spatiotemporal volume for each stabilized human figure is introduced, and an associated similarity measure to be used in a nearest-neighbor framework is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830945"
                        ],
                        "name": "L. Bretzner",
                        "slug": "L.-Bretzner",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Bretzner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bretzner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 254
                            }
                        ],
                        "text": "During recent years, the problem of automatic scale selection has been addressed in several different ways, based on the maximization of normalized derivative expressions over scale, or the behavior of entropy measures or error measures over scales (see Lindeberg and Bretzner (2003) for a review)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2462997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8c2eba9147d22a9687ba741397cdcf21d1a9e3f",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Local scale information extracted from visual data in a bottom-up manner constitutes an important cue for a large number of visual tasks. This article presents a framework for how the computation of such scale descriptors can be performed in real time on a standard computer. \n \nThe proposed scale selection framework is expressed within a novel type of multi-scale representation, referred to as hybrid multi-scale representation, which aims at integrating and providing variable trade-offs between the relative advantages of pyramids and scale-space representation, in terms of computational efficiency and computational accuracy. Starting from binomial scale-space kernels of different widths, we describe a family pyramid representations, in which the regular pyramid concept and the regular scale-space representation constitute limiting cases. In particular, the steepness of the pyramid as well as the sampling density in the scale direction can be varied. \n \nIt is shown how the definition of \u03b3-normalized derivative operators underlying the automatic scale selection mechanism can be transferred from a regular scale-space to a hybrid pyramid, and two alternative definitions are studied in detail, referred to as variance normalization and lp-normalization. The computational accuracy of these two schemes is evaluated, and it is shown how the choice of sub-sampling rate provides a trade-off between the computational efficiency and the accuracy of the scale descriptors. Experimental evaluations are presented for both synthetic and real data. In a simplified form, this scale selection mechanism has been running for two years, in a real-time computer vision system."
            },
            "slug": "Real-Time-Scale-Selection-in-Hybrid-Multi-scale-Lindeberg-Bretzner",
            "title": {
                "fragments": [],
                "text": "Real-Time Scale Selection in Hybrid Multi-scale Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A framework for how the computation of such scale descriptors can be performed in real time on a standard computer is presented, expressed within a novel type of multi-scale representation, referred to as hybrid multi- scale representation, which aims at integrating and providing variable trade-offs between the relative advantages of pyramids and scale-space representation."
            },
            "venue": {
                "fragments": [],
                "text": "Scale-Space"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 155
                            }
                        ],
                        "text": "\u2026low frequency result in interest points with long temporal extent as shown in figure 9b.\n3Here, we used the scale-adapted Harris interest point detector (Mikolajczyk and Schmid, 2001) that detects maxima of Hsp (4) in space and extrema of normalized Laplacian operator over scales (Lindeberg, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 63
                            }
                        ],
                        "text": "Here, we used the scale-adapted Harris interest point detector (Mikolajczyk and Schmid, 2001) that detects maxima of Hsp (4) in space and extrema of normalized Laplacian operator over scales (Lindeberg, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 15
                            }
                        ],
                        "text": "In particular, Mikolajczyk and Schmid (2001) combined the\nHarris interest point operator with the normalized Laplace operator and derived a scaleinvariant Harris-Laplace interest point detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2326264,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6647f56413722e812cb084fbb3597ba18ceada36",
            "isKey": false,
            "numCitedBy": 759,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new method for detecting scale invariant interest points. The method is based on two recent results on scale space: (1) Interest points can be adapted to scale and give repeatable results (geometrically stable). (2) Local extrema over scale of normalized derivatives indicate the presence of characteristic local structures. Our method first computes a multi-scale representation for the Harris interest point detector. We then select points at which a local measure (the Laplacian) is maximal over scales. This allows a selection of distinctive points for which the characteristic scale is known. These points are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. For indexing, the image is characterized by a set of scale invariant points; the scale associated with each point allows the computation of a scale invariant descriptor. Our descriptors are, in addition, invariant to image rotation, of affine illumination changes and robust to small perspective deformations. Experimental results for indexing show an excellent performance up to a scale factor of 4 for a database with more than 5000 images."
            },
            "slug": "Indexing-based-on-scale-invariant-interest-points-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Indexing Based on Scale Invariant Interest Points"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This paper presents a new method for detecting scale invariant interest points based on two recent results on scale space: 1) Interest points can be adapted to scale and give repeatable results (geometrically stable); 2) local extrema over scale of normalized derivatives indicate the presence of characteristic local structures."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830945"
                        ],
                        "name": "L. Bretzner",
                        "slug": "L.-Bretzner",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Bretzner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bretzner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 148
                            }
                        ],
                        "text": "\u2026(Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe, 1999; Hall, de Verdiere and Crowley, 2000; Fergus, Perona and Zisserman, 2003;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 306,
                                "start": 253
                            }
                        ],
                        "text": "Highly successful applications of interest points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe, 1999; Hall, de Verdiere and Crowley, 2000; Fergus, Perona and Zisserman, 2003; Wallraven, Caputo and Graf, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14084708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c702415fede5f2d8470880b0f83ed03894439554",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "When observing a dynamic world, the size of image structures may vary over time. This article emphasizes the need for including explicit mechanisms for automatic scale selection in feature tracking algorithms in order to: (i) adapt the local scale of processing to the local image structure, and (ii) adapt to the size variations that may occur over time. The problems of corner detection and blob detection are treated in detail, and a combined framework for feature tracking is presented. The integrated tracking algorithm overcomes some of the inherent limitations of exposing fixed-scale tracking methods to image sequences in which the size variations are large. It is also shown how the stability over time of scale descriptors can be used as a part of a multi-cue similarity measure for matching. Experiments on real-world sequences are presented showing the performance of the algorithm when applied to (individual) tracking of corners and blobs."
            },
            "slug": "Feature-Tracking-with-Automatic-Selection-of-Scales-Bretzner-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Feature Tracking with Automatic Selection of Spatial Scales"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The problems of corner detection and blob detection are treated in detail, and a combined framework for feature tracking is presented, which overcomes some of the inherent limitations of exposing fixed-scale tracking methods to image sequences in which the size variations are large."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2399320"
                        ],
                        "name": "Daniel Fagerstr\u00f6m",
                        "slug": "Daniel-Fagerstr\u00f6m",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Fagerstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Fagerstr\u00f6m"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 102
                            }
                        ],
                        "text": "For real-time implementation, time-causal scale-space filters thus have to be used (Koenderink, 1988; Lindeberg and Fagerstro\u0308m, 1996; Florack, 1997; Lindeberg, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 106
                            }
                        ],
                        "text": "In real-time situations, when using causal scalespace representation based on recursive temporal filters (Lindeberg and Fagerstro\u0308m, 1996; Lindeberg, 2002), only a fixed set of discrete temporal scales is available at any moment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "During recent years, the problem of automatic scale selection has been addressed in several different ways, based on the maximization of normalized derivative expressions over scale, or the behavior of entropy measures or error measures over scales (see  Lindeberg and Bretzner (2003)  for a review)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 86
                            }
                        ],
                        "text": "As events often have characteristic extents in both space and time (Koenderink, 1988; Lindeberg and Fagerstro\u0308m, 1996; Florack, 1997; Lindeberg, 1997; Chomat, Martin and Crowley, 2000b; Zelnik-Manor and Irani, 2001), we investigate the behavior of interest points in spatio-temporal scale-space and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31164658,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b71a4d1316fb70a84fca04ddf41669b13e7fba65",
            "isKey": true,
            "numCitedBy": 52,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a theory for multi-scale representation of temporal data. Assuming that a real-time vision system should represent the incoming data at different time scales, an additional causality constraint arises compared to traditional scale-space theory\u2014we can only use what has occurred in the past for computing representations at coarser time scales. Based on a previously developed scale-space theory in terms of noncreation of local maxima with increasing scale, a complete classification is given of the scale-space kernels that satisfy this property of non-creation of structure and respect the time direction as causal. It is shown that the cases of continuous and discrete time are inherently different."
            },
            "slug": "Scale-Space-with-Casual-Time-Direction-Lindeberg-Fagerstr\u00f6m",
            "title": {
                "fragments": [],
                "text": "Scale-Space with Casual Time Direction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A complete classification is given of the scale-space kernels that satisfy this property of non-creation of structure and respect the time direction as causal in the cases of continuous and discrete time."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 141
                            }
                        ],
                        "text": "To estimate the spatio-temporal extent of an event in\nspace-time, we follow works on local scale selection proposed in the spatial domain by Lindeberg (1998) as well as in the temporal domain (Lindeberg, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 133
                            }
                        ],
                        "text": "In the spatial domain, points with a significant local variation of image intensities have been extensively investigated in the past (F\u00f6rstner and G\u00fclch, 1987; Harris and Stephens, 1988; Lindeberg, 1998; Schmid, Mohr and Bauckhage, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 149
                            }
                        ],
                        "text": "\u2026and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe, 1999; Hall, de Verdiere and Crowley, 2000; Fergus, Perona and Zisserman, 2003; Wallraven, Caputo and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 283
                            }
                        ],
                        "text": "\u2026low frequency result in interest points with long temporal extent as shown in figure 9b.\n3Here, we used the scale-adapted Harris interest point detector (Mikolajczyk and Schmid, 2001) that detects maxima of Hsp (4) in space and extrema of normalized Laplacian operator over scales (Lindeberg, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 187
                            }
                        ],
                        "text": "In the spatial domain, points with a significant local variation of image intensities have been extensively investigated in the past (Fo\u0308rstner and Gu\u0308lch, 1987; Harris and Stephens, 1988; Lindeberg, 1998; Schmid, Mohr and Bauckhage, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 189
                            }
                        ],
                        "text": "Here, we used the scale-adapted Harris interest point detector (Mikolajczyk and Schmid, 2001) that detects maxima of H (4) in space and extrema of normalized Laplacian operator over scales (Lindeberg, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 112
                            }
                        ],
                        "text": "Local scale estimation using the normalized Laplace operator has shown to be very useful in the spatial domain (Lindeberg, 1998; Almansa and Lindeberg, 2000; Chomat, de Verdiere, Hall and Crowley, 2000a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 723210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b02f474196fb9bd61fa3d418a7ba8ac500e8d422",
            "isKey": true,
            "numCitedBy": 2940,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of \u03b3-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure.Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation.In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments."
            },
            "slug": "Feature-Detection-with-Automatic-Scale-Selection-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Feature Detection with Automatic Scale Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation and how it can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 57
                            }
                        ],
                        "text": "Interesting solutions to this problem have been proposed (Niyogi, 1995; Fleet et al., 1998; Hoey and Little, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6470613,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "2e6b807009b35a3f561e7b111f7fd27f04f71260",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The estimation and detection of occlusion boundaries and moving bars are important and challenging problems in image sequence analysis. Here, we model such motion features as linear combinations of steerable basis flow fields. These models constrain the interpretation of image motion, and are used in the same way as translational or affine motion models. We estimate the subspace coefficients of the motion feature models directly from spatiotemporal image derivatives using a robust regression method. From the subspace coefficients we detect the presence of a motion feature and solve for the orientation of the feature and the relative velocities of the surfaces. Our method does not require the prior computation of optical flow and recovers accurate estimates of orientation and velocity."
            },
            "slug": "Motion-feature-detection-using-steerable-flow-Fleet-Black",
            "title": {
                "fragments": [],
                "text": "Motion feature detection using steerable flow fields"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work estimates the subspace coefficients of the motion feature models directly from spatiotemporal image derivatives using a robust regression method and solves for the orientation of the feature and the relative velocities of the surfaces."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40316280"
                        ],
                        "name": "Dennis Tell",
                        "slug": "Dennis-Tell",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Tell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dennis Tell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 150
                            }
                        ],
                        "text": "\u2026points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32487961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "835ddd57d615cc7e93a2b7589bbcbe49992ad14d",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of establishing image-to-image correspondences is fundamental in computer vision. Recently, several wide baseline matching algorithms capable of handling large changes of viewpoint have appeared. By computing feature values from image data, these algorithms mainly use appearance as a cue for matching. Topological information, i.e. spatial relations between features, has also been used, but not nearly to the same extent as appearance. In this paper, we incorporate topological constraints into an existing matching algorithm [1] which matches image intensity profiles between interest points. We show that the algorithm can be improved by exploiting the constraint that the intensity profiles around each interest point should be cyclically ordered. String matching techniques allows for an efficient implementation of the ordering constraint. Experiments with real data indicate that the modified algorithm indeed gives superior results to the original one. The method of enforcing the spatial constraints is not limited to the presented case, but can be used on any algorithm where interest point correspondences are sought."
            },
            "slug": "Combining-Appearance-and-Topology-for-Wide-Baseline-Tell-Carlsson",
            "title": {
                "fragments": [],
                "text": "Combining Appearance and Topology for Wide Baseline Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper incorporates topological constraints into an existing matching algorithm which matches image intensity profiles between interest points, and shows that the algorithm can be improved by exploiting the constraint that the intensity profiles around each interest point should be cyclically ordered."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3260234"
                        ],
                        "name": "J. G\u00e5rding",
                        "slug": "J.-G\u00e5rding",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "G\u00e5rding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. G\u00e5rding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 15548916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9e58a5b063d4252a15fd94c0613f83a4fdb780e",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of computing cues to the three-dimensional structure of surfaces in the world directly from the local structure of the brightness pattern of either a single monocular image or a binocular image pair.It is shown that starting from Gaussian derivatives of order up to two at a range of scales in scale-space, local estimates of (i) surface orientation from monocular texture foreshortening, (ii) surface orientation from monocular texture gradients, and (iii) surface orientation from the binocular disparity gradient can be computed without iteration or search, and by using essentially the same basic mechanism.The methodology is based on a multi-scale descriptor of image structure called the windowed second moment matrix, which is computed with adaptive selection of both scale levels and spatial positions. Notably, this descriptor comprises two scale parameters; a local scale parameter describing the amount of smoothing used in derivative computations, and an integration scale parameter determining over how large a region in space the statistics of regional descriptors is accumulated.Experimental results for both synthetic and natural images are presented, and the relation with models of biological vision is briefly discussed."
            },
            "slug": "Direct-computation-of-shape-cues-using-spatial-G\u00e5rding-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Direct computation of shape cues using scale-adapted spatial derivative operators"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of computing cues to the three-dimensional structure of surfaces in the world directly from the local structure of the brightness pattern of either a single monocular image or a binocular image pair using a multi-scale descriptor of image structure called the windowed second moment matrix."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775110"
                        ],
                        "name": "J. Big\u00fcn",
                        "slug": "J.-Big\u00fcn",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Big\u00fcn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Big\u00fcn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2498129"
                        ],
                        "name": "G. Granlund",
                        "slug": "G.-Granlund",
                        "structuredName": {
                            "firstName": "G\u00f6sta",
                            "lastName": "Granlund",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Granlund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144576270"
                        ],
                        "name": "J. Wiklund",
                        "slug": "J.-Wiklund",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Wiklund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiklund"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 149
                            }
                        ],
                        "text": "For a given scale of observation \u03c3 2 l , such points can be found using a second moment matrix integrated over a Gaussian window with variance \u03c3 2 i (F\u00f6rstner and G\u00fclch, 1987; Big\u00fcn et al., 1991; G\u00e5rding and Lindeberg, 1996):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19321254,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2029b44afbede69daf0491cc114c18da6e6eee6d",
            "isKey": false,
            "numCitedBy": 583,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of detection of orientation in finite dimensional Euclidean spaces is solved in the least squares sense. The theory is developed for the case when such orientation computations are necessary at all local neighborhoods of the n-dimensional Euclidean space. Detection of orientation is shown to correspond to fitting an axis or a plane to the Fourier transform of an n-dimensional structure. The solution of this problem is related to the solution of a well-known matrix eigenvalue problem. The computations can be performed in the spatial domain without actually doing a Fourier transformation. Along with the orientation estimate, a certainty measure, based on the error of the fit, is proposed. Two applications in image analysis are considered: texture segmentation and optical flow. The theory is verified by experiments which confirm accurate orientation estimates and reliable certainty measures in the presence of noise. The comparative results indicate that the theory produces algorithms computing robust texture features as well as optical flow. >"
            },
            "slug": "Multidimensional-Orientation-Estimation-with-to-and-Big\u00fcn-Granlund",
            "title": {
                "fragments": [],
                "text": "Multidimensional Orientation Estimation with Applications to Texture Analysis and Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The theory is developed for the case when orientation computations are necessary at all local neighborhoods of the n-dimensional Euclidean space and a certainty measure, based on the error of the fit, is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1894358"
                        ],
                        "name": "Olivier Chomat",
                        "slug": "Olivier-Chomat",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chomat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olivier Chomat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2481445"
                        ],
                        "name": "V. Verdi\u00e8re",
                        "slug": "V.-Verdi\u00e8re",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Verdi\u00e8re",
                            "middleNames": [
                                "Colin",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Verdi\u00e8re"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859042"
                        ],
                        "name": "D. Hall",
                        "slug": "D.-Hall",
                        "structuredName": {
                            "firstName": "Daniela",
                            "lastName": "Hall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687022"
                        ],
                        "name": "J. Crowley",
                        "slug": "J.-Crowley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Crowley",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Crowley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 79
                            }
                        ],
                        "text": "In the spatio-temporal domain, local descriptors have been previously used by (Chomat et al., 2000b) and others."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Local scale estimation using the normalized Laplace operator has shown to be very useful in the spatial domain (Lindeberg, 1998; Almansa and Lindeberg, 2000;  Chomat et al., 2000a )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35023938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba1fdb59772f10766632c57e942d1757ff0a44c3",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of the local scale parameter selection for recognition techniques based on Gaussian derivatives. Patterns are described in a feature space of which each dimension is a scale and orientation normalized receptive field (a unit composed of normalized Gaussian-based filters). \n \nScale invariance is obtained by automatic selection of an appropriate local scale [Lin98b] and followed by normalisation of the receptive field to the appropriate scale. Orientation invariance is obtained by the determination of the dominant local orientation and by steering the receptive fields to this orientation. \n \nData is represented structurally in a feature space that is designed for the recognition of static object configurations. In this space an image is modeled by the vectorial representation of the receptive field responses at each pixel, forming a surface in the feature space. Recognition is achieved by measuring the distance between the vector of normalized receptive fields responses of an observed neighborhood and the surface point of the image model. \n \nThe power of a scale equivariant feature space is validated by experimental results for point correspondences in images of different scales and the recognition of objects under different view points."
            },
            "slug": "Local-Scale-Selection-for-Gaussian-Based-Techniques-Chomat-Verdi\u00e8re",
            "title": {
                "fragments": [],
                "text": "Local Scale Selection for Gaussian Based Description Techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The power of a scale equivariant feature space is validated by experimental results for point correspondences in images of different scales and the recognition of objects under different view points."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3260234"
                        ],
                        "name": "J. G\u00e5rding",
                        "slug": "J.-G\u00e5rding",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "G\u00e5rding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. G\u00e5rding"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 148
                            }
                        ],
                        "text": "\u2026found using a second moment matrix integrated over a Gaussian window with\nvariance \u03c32i (Fo\u0308rstner and Gu\u0308lch, 1987; Bigu\u0308n, Granlund and Wiklund, 1991; Lindeberg and Garding, 1997):\n\u00b5sp(\u00b7; \u03c32l , \u03c32i ) = gsp(\u00b7; \u03c32i ) \u2217 ( (\u2207L(\u00b7; \u03c32l ))(\u2207L(\u00b7; \u03c32l ))T ) = gsp(\u00b7; \u03c32i ) \u2217 ( (Lspx )2 L sp x L sp y\nLspx\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "variance \u03c32 i (F\u00f6rstner and G\u00fclch, 1987; Big\u00fcn, Granlund and Wiklund, 1991; Lindeberg and Garding, 1997):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18264626,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f87bcdf4a0dc79f85e171ec26733424d0e459cd2",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Shape-adapted-smoothing-in-estimation-of-3-D-shape-Lindeberg-G\u00e5rding",
            "title": {
                "fragments": [],
                "text": "Shape-adapted smoothing in estimation of 3-D shape cues from affine deformations of local 2-D brightness structure"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 79
                            }
                        ],
                        "text": "Interesting solutions to this problem have been proposed (Niyogi, 1995; Fleet, Black and Jepson, 1998; Hoey and Little, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 63
                            }
                        ],
                        "text": "Model-based solutions for this problem have been presented by (Black and Jepson, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 96
                            }
                        ],
                        "text": "Other approaches use spatio-temporal image cues such as optical flow (Black, Yacoob, Jepson and\nFleet, 1997) or motion templates (Baumberg and Hogg, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 218
                            }
                        ],
                        "text": "Some of the works rely on pure spatial image features while using sophisticated body models and tracking schemes to constrain the interpretation (Baumberg and Hogg, 1996; Bregler and Malik, 1998; Sidenbladh, Black and Fleet, 2000)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Model-based solutions for this problem have been presented by ( Black and Jepson, 1998 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 572947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9158048426a7f673bcc513e074e76b0b7e435b7",
            "isKey": true,
            "numCitedBy": 1297,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an approach for tracking rigid and articulated objects using a view-based representation. The approach builds on and extends work on eigenspace representations, robust estimation techniques, and parameterized optical flow estimation. First, we note that the least-squares image reconstruction of standard eigenspace techniques has a number of problems and we reformulate the reconstruction problem as one of robust estimation. Second we define a \u201csubspace constancy assumption\u201d that allows us to exploit techniques for parameterized optical flow estimation to simultaneously solve for the view of an object and the affine transformation between the eigenspace and the image. To account for large affine transformations between the eigenspace and the image we define a multi-scale eigenspace representation and a coarse-to-fine matching strategy. Finally, we use these techniques to track objects over long image sequences in which the objects simultaneously undergo both affine image motions and changes of view. In particular we use this \u201cEigenTracking\u201d technique to track and recognize the gestures of a moving hand."
            },
            "slug": "EigenTracking:-Robust-Matching-and-Tracking-of-a-Black-Jepson",
            "title": {
                "fragments": [],
                "text": "EigenTracking: Robust Matching and Tracking of Articulated Objects Using a View-Based Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A \u201csubspace constancy assumption\u201d is defined that allows techniques for parameterized optical flow estimation to simultaneously solve for the view of an object and the affine transformation between the eigenspace and the image."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1894358"
                        ],
                        "name": "Olivier Chomat",
                        "slug": "Olivier-Chomat",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chomat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olivier Chomat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110132354"
                        ],
                        "name": "J\u00e9r\u00f4me Martin",
                        "slug": "J\u00e9r\u00f4me-Martin",
                        "structuredName": {
                            "firstName": "J\u00e9r\u00f4me",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J\u00e9r\u00f4me Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687022"
                        ],
                        "name": "J. Crowley",
                        "slug": "J.-Crowley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Crowley",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Crowley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 67
                            }
                        ],
                        "text": "As events often have characteristic extents in both space and time (Koenderink, 1988; Lindeberg and Fagerstr\u00f6m, 1996; Florack, 1997; Lindeberg, 1997; Chomat et al., 2000b; Zelnik-Manor and Irani, 2001), we investigate the behavior of interest points in spatiotemporal scale-space and adapt both the spatial and the temporal scales of the detected features in Section 3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 79
                            }
                        ],
                        "text": "In the spatio-temporal domain, local descriptors have been previously used by (Chomat et al., 2000b) and others."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6167708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53cd2b8ea7296220e6981041bacf27a7c0285a5f",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new technique for the perception and recognition of activities using statistical descriptions of their spatio-temporal properties. A set of motion energy receptive fields is designed in order to sample the power spectrum of a moving texture. Their structure relates to the spatio-temporal energy models of Adelson and Bergen where measures of local visual motion information are extracted by comparing the outputs of a triad of Gabor energy filters. Then the probability density function required for Bayes rule is estimated for each class of activity by computing multi-dimensional histograms from the outputs from the set of receptive fields. The perception of activities is achieved according to Bayes rule. The result at each instant of time is the map of the conditional probabilities that each pixel belongs to each one of the activities of the training set. Since activities are perceived over a short integration time, a temporal analysis of outputs is done using Hidden Markov Models. \n \nThe approach is validated with experiments in the perception and recognition of activities of people walking in visual surveillance scenari. The presented work is in progress and preliminary results are encouraging, since recognition is robust to variations in illumination conditions, to partial occlusions and to changes in texture. It is shown that it constitute a powerful early vision tool for human behaviors analysis for smart-environnements."
            },
            "slug": "A-Probabilistic-Sensor-for-the-Perception-and-of-Chomat-Martin",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Sensor for the Perception and Recognition of Activities"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Preliminary results are encouraging, since recognition is robust to variations in illumination conditions, to partial occlusions and to changes in texture, and it is shown that it constitute a powerful early vision tool for human behaviors analysis for smart-environnements."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7977369"
                        ],
                        "name": "A. Doorn",
                        "slug": "A.-Doorn",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Doorn",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doorn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 80
                            }
                        ],
                        "text": "Using derivatives, we define event descriptors from the third order local jet4 (Koenderink and van Doorn, 1987) computed at spatio-temporal scales determined from the detection scales of the corresponding interest points\nj = (Lx, Ly, Lt, Lxx, ..., Lttt) \u2223\u2223\u2223 \u03c32=\u03c3\u03032i ,\u03c4 2=\u03c4\u03032i\n(16)\nTo compare two\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Using derivatives, we define event descriptors from the third order local jet 4 ( Koenderink and van Doorn, 1987 ) computed at spatio-temporal scales determined from the detection scales of the corresponding interest points"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 24284500,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "00aa5220d49f3fcf357c1b64ac14f24cd8afb76d",
            "isKey": false,
            "numCitedBy": 626,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that a convolution with certain reasonable receptive field (RF) profiles yields the exact partial derivatives of the retinal illuminance blurred to a specified degree. Arbitrary concatenations of such RF profiles yield again similar ones of higher order and for a greater degree of blurring.By replacing the illuminance with its third order jet extension we obtain position dependent geometries. It is shown how such a representation can function as the substrate for \u201cpoint processors\u201d computing geometrical features such as edge curvature. We obtain a clear dichotomy between local and multilocal visual routines. The terms of the truncated Taylor series representing the jets are partial derivatives whose corresponding RF profiles closely mimic the well known units in the primary visual cortex. Hence this description provides a novel means to understand and classify these units.Taking the receptive field outputs as the basic input data one may devise visual routines that compute geometric features on the basis of standard differential geometry exploiting the equivalence with the local jets (partial derivatives with respect to the space coordinates)."
            },
            "slug": "Representation-of-local-geometry-in-the-visual-Koenderink-Doorn",
            "title": {
                "fragments": [],
                "text": "Representation of local geometry in the visual system"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "It is shown that a convolution with certain reasonable receptive field (RF) profiles yields the exact partial derivatives of the retinal illuminance blurred to a specified degree and how this representation can function as the substrate for \u201cpoint processors\u201d computing geometrical features such as edge curvature."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679389"
                        ],
                        "name": "A. Baumberg",
                        "slug": "A.-Baumberg",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Baumberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Baumberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 145
                            }
                        ],
                        "text": "Some of the works rely on pure spatial image features while using sophisticated body models and tracking schemes to constrain the interpretation (Baumberg and Hogg, 1996; Bregler and Malik, 1998; Sidenbladh et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 130
                            }
                        ],
                        "text": "Other approaches use spatio-temporal image cues such as optical flow (Black, Yacoob, Jepson and\nFleet, 1997) or motion templates (Baumberg and Hogg, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 146
                            }
                        ],
                        "text": "Some of the works rely on pure spatial image features while using sophisticated body models and tracking schemes to constrain the interpretation (Baumberg and Hogg, 1996; Bregler and Malik, 1998; Sidenbladh, Black and Fleet, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11869396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74862958d42e4e1f73287c1efced119db2c0ace1",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work on contour tracking has shown the benefits of using learned dynamic models for robust curve tracking. In this paper, we extend this work by using a physically based framework to learn physically plausible, constrained dynamic models of deforming objects. Traditional physically based vibration modes have been shown to provide a useful mechanism for describing non-rigid motions of articulated and deformable objects. The standard approach relies on assumptions being made about the elastic properties of an object to generate a compact set of real, orthogonal shape parameters which can then be used for tracking and data approximation. We present a method for automatically generating an improved physically based model using a training set of examples of the object deforming, tuning the elastic properties of the object to reflect how the object actually deforms. The resulting model provides a low dimensional shape description that allows accurate temporal extrapolation at low computational cost based on the training motions. Results are shown in which the method is applied to an automatically acquired training set of the outline of a walking pedestrian."
            },
            "slug": "Generating-Spatiotemporal-Models-from-Examples-Baumberg-Hogg",
            "title": {
                "fragments": [],
                "text": "Generating spatiotemporal models from examples"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a method for automatically generating an improved physically based model using a training set of examples of the object deforming, tuning the elastic properties of theobject to reflect how the object actually deforms, which provides a low dimensional shape description that allows accurate temporal extrapolation at low computational cost based on the training motions."
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 165
                            }
                        ],
                        "text": "Feature trackers often assume a constant appearance of image patches over time and may hence fail when the appearance changes, for example, in situations when two objects in the image merge or split."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 131
                            }
                        ],
                        "text": "Highly successful applications of interest points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 552096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ad20e6f6f89631caf6960516bb9939b9430bba0",
            "isKey": false,
            "numCitedBy": 568,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "\u2018Invariant regions\u2019 are image patches that automatically deform with changing viewpoint as to keep on covering identical physical parts of a scene. Such regions are then described by a set of invariant features, which makes it relatively easy to match them between views and under changing illumination. In previous work, we have presented invariant regions that are based on a combination of corners and edges. The application discussed then was image database retrieval. Here, an alternative method for extracting (affinely) invariant regions is given, that does not depend on the presence of edges or corners in the image but is purely intensity-based. Also, we demonstrate the use of such regions for another application, which is wide baseline stereo matching. As a matter of fact, the goal is to build an opportunistic system that exploits several types of invariant regions as it sees fit. This yields more correspondences and a system that can deal with a wider range of images. To increase the robustness of the system even further, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric). They allow to test the consistency of correspondences and hence to reject falsely matched regions."
            },
            "slug": "Wide-Baseline-Stereo-Matching-based-on-Local,-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Wide Baseline Stereo Matching based on Local, Affinely Invariant Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents an alternative method for extracting invariant regions that does not depend on the presence of edges or corners in the image but is purely intensity-based, and demonstrates the use of such regions for another application, which is wide baseline stereo matching."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 407,
                                "start": 331
                            }
                        ],
                        "text": "Highly successful applications of interest points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe, 1999; Hall et al., 2000; Fergus et al., 2003; Wallraven et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 177
                            }
                        ],
                        "text": "\u20262000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe, 1999; Hall, de Verdiere and Crowley, 2000; Fergus, Perona and Zisserman, 2003; Wallraven, Caputo and Graf, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": false,
            "numCitedBy": 16258,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157788337"
                        ],
                        "name": "Stephen M. Smith",
                        "slug": "Stephen-M.-Smith",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smith",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen M. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Image structures in video are not restricted to constant velocity and/or constant appearance over time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 85
                            }
                        ],
                        "text": "To represent the detected events, we then compute local, spatio-temporal, scale-invariant N -jets and classify each event with respect to its jet descriptor."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 146
                            }
                        ],
                        "text": "Traditional approaches for motion analysis mainly involve the computation of optic flow (Barron, Fleet and Beauchemin, 1994) or feature tracking (Smith and Brady, 1995; Blake and Isard, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 148
                            }
                        ],
                        "text": "\u20261997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe, 1999; Hall, de Verdiere and Crowley, 2000; Fergus, Perona and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5231875,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "0a16248f02326df66b1a030b68f72071f3f9b5c4",
            "isKey": true,
            "numCitedBy": 214,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes how image sequences taken by a moving video camera may be processed to detect and track moving objects against a moving background in real-time. The motion segmentation and shape tracking system as known as ASSET-2-A Scene Segmenter Establishing Tracking, Version 2. Motion is found by tracking image features, and segmentation is based on first-order (i.e., six parameter) flow fields. Shape tracking is performed using two dimensional radial map representation. The system runs in real-time, and is accurate and reliable. It requires no camera calibration and no knowledge of the camera's motion.<<ETX>>"
            },
            "slug": "ASSET-2:-real-time-motion-segmentation-and-shape-Smith",
            "title": {
                "fragments": [],
                "text": "ASSET-2: Real-Time Motion Segmentation and Shape Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The paper describes how image sequences taken by a moving video camera may be processed to detect and track moving objects against a moving background in real-time."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145803385"
                        ],
                        "name": "J. Hoey",
                        "slug": "J.-Hoey",
                        "structuredName": {
                            "firstName": "Jesse",
                            "lastName": "Hoey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hoey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710980"
                        ],
                        "name": "J. Little",
                        "slug": "J.-Little",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Little",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Little"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 103
                            }
                        ],
                        "text": "Interesting solutions to this problem have been proposed (Niyogi, 1995; Fleet, Black and Jepson, 1998; Hoey and Little, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 33
                            }
                        ],
                        "text": "\u2217The support from the Swedish Research Council and from the Royal Swedish Academy of Sciences as well as the Knut and Alice Wallenberg Foundation is gratefully acknowledged."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7349540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c3f19401a8ba19e0f0df82878a34d7cff1c4ef7",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The quest for a vision system capable of representing and recognizing arbitrary motions benefits from a low dimensional, non-specific representation of flow fields, to be used in high level classification tasks. We present Zernike polynomials as an ideal candidate for such a representation. The basis of Zernike polynomials is complete and orthogonal and can be used for describing many types of motion at many scales. Starting from image sequences, locally smooth image velocities are derived using a robust estimation procedure, from which are computed compact representations of the flow using the Zernike basis. Continuous density hidden Markov models are trained using the temporal sequences of vectors thus obtained, and are used for subsequent classification. We present results of our method applied to image sequences of facial expressions both with and without significant rigid head motion and to sequences of lip motion from a known database. We demonstrate that the Zernike representation yields results competitive with those obtained using principal components, while not committing to specific types of motion. It is therefore ideal as a fundamental building block for a vision system capable of classifying arbitrary motion types."
            },
            "slug": "Representation-and-recognition-of-complex-human-Hoey-Little",
            "title": {
                "fragments": [],
                "text": "Representation and recognition of complex human motion"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is demonstrated that the Zernike representation yields results competitive with those obtained using principal components, while not committing to specific types of motion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 83
                            }
                        ],
                        "text": "Thus clustering of spatio-temporal neighborhoods is similar to the idea of textons (Malik et al., 1999) used to describe image texture as well as to detect object parts for spatial recognition (Weber et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 113
                            }
                        ],
                        "text": "A similar approach has proven to be highly successful in the spatial domain for the task of image representation (Malik et al., 1999)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 84
                            }
                        ],
                        "text": "Thus clustering of spatio-temporal neighborhoods is similar to the idea of textons (Malik et al., 1999) used to describe image texture as well as to detect object parts for spatial recognition (Weber et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10617783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b3dbc36ae4d8171f9a4179001e37299554f1652",
            "isKey": false,
            "numCitedBy": 344,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper makes two contributions: it provides (1) an operational definition of textons, the putative elementary units of texture perception, and (2) an algorithm for partitioning the image into disjoint regions of coherent brightness and texture, where boundaries of regions are defined by peaks in contour orientation energy and differences in texton densities across the contour. B. Julesz (1981) introduced the term texton, analogous to a phoneme in speech recognition, but did not provide an operational definition for gray-level images. We re-invent textons as frequently co-occurring combinations of oriented linear filter outputs. These can be learned using a K-means approach. By mapping each pixel to its nearest texton, the image can be analyzed into texton channels, each of which is a point set where discrete techniques such as Voronoi diagrams become applicable. Local histograms of texton frequencies can be used with a /spl chi//sup 2/ test for significant differences to find texture boundaries. Natural images contain both textured and untextured regions, so we combine this cue with that of the presence of peaks of contour energy derived from outputs of odd- and even-symmetric oriented Gaussian derivative filters. Each of these cues has a domain of applicability, so to facilitate cue combination we introduce a gating operator based on a statistical test for isotropy of Delaunay neighbors. Having obtained a local measure of how likely two nearby pixels are to belong to the same region, we use the spectral graph theoretic framework of normalized cuts to find partitions of the image into regions of coherent texture and brightness. Experimental results on a wide range of images are shown."
            },
            "slug": "Textons,-contours-and-regions:-cue-integration-in-Malik-Belongie",
            "title": {
                "fragments": [],
                "text": "Textons, contours and regions: cue integration in image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "An operational definition of textons, the putative elementary units of texture perception, and an algorithm for partitioning the image into disjoint regions of coherent brightness and texture, where boundaries of regions are defined by peaks in contour orientation energy and differences in texton densities across the contour."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704879"
                        ],
                        "name": "H. Kjellstr\u00f6m",
                        "slug": "H.-Kjellstr\u00f6m",
                        "structuredName": {
                            "firstName": "Hedvig",
                            "lastName": "Kjellstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kjellstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 145
                            }
                        ],
                        "text": "Some of the works rely on pure spatial image features while using sophisticated body models and tracking schemes to constrain the interpretation (Baumberg and Hogg, 1996; Bregler and Malik, 1998; Sidenbladh et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46737148,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49ec1434331e16ad91550c8fb8906bf2c1031b98",
            "isKey": false,
            "numCitedBy": 837,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "A probabilistic method for tracking 3D articulated human figures in monocular image sequences is presented. Within a Bayesian framework, we define a generative model of image appearance, a robust likelihood function based on image graylevel differences, and a prior probability distribution over pose and joint angles that models how humans move. The posterior probability distribution over model parameters is represented using a discrete set of samples and is propagated over time using particle filtering. The approach extends previous work on parameterized optical flow estimation to exploit a complex 3D articulated motion model. It also extends previous work on human motion tracking by including a perspective camera model, by modeling limb self occlusion, and by recovering 3D motion from a monocular sequence. The explicit posterior probability distribution represents ambiguities due to image matching, model singularities, and perspective projection. The method relies only on a frame-to-frame assumption of brightness constancy and hence is able to track people under changing viewpoints, in grayscale image sequences, and with complex unknown backgrounds."
            },
            "slug": "Stochastic-Tracking-of-3D-Human-Figures-Using-2D-Kjellstr\u00f6m-Black",
            "title": {
                "fragments": [],
                "text": "Stochastic Tracking of 3D Human Figures Using 2D Image Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A probabilistic method for tracking 3D articulated human figures in monocular image sequences that relies only on a frame-to-frame assumption of brightness constancy and hence is able to track people under changing viewpoints, in grayscale image sequences, and with complex unknown backgrounds."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693446"
                        ],
                        "name": "L. Florack",
                        "slug": "L.-Florack",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Florack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Florack"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 118
                            }
                        ],
                        "text": "As events often have characteristic extents in both space and time (Koenderink, 1988; Lindeberg and Fagerstro\u0308m, 1996; Florack, 1997; Lindeberg, 1997; Chomat, Martin and Crowley, 2000b; Zelnik-Manor and Irani, 2001), we investigate the behavior of interest points in spatio-temporal scale-space and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 134
                            }
                        ],
                        "text": "For real-time implementation, time-causal scale-space filters thus have to be used (Koenderink, 1988; Lindeberg and Fagerstro\u0308m, 1996; Florack, 1997; Lindeberg, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 180
                            }
                        ],
                        "text": "Such image points are\nfrequently referred to as \u201cinterest points\u201d and are attractive due to their high information contents and relative stability with respect to perspective transformations of the data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 109
                            }
                        ],
                        "text": "In the spatial domain, we can model an image f sp : R2 \u2192 R by its linear scale-space representation (Witkin, 1983; Koenderink and van Doorn, 1992; Lindeberg, 1994; Florack, 1997) Lt : R2 \u00d7 R+ \u2192 R\nLsp(x, y; \u03c32l ) = g sp(x, y; \u03c32l ) \u2217 f sp(x, y), (1)\ndefined by the convolution of f sp with Gaussian\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 148
                            }
                        ],
                        "text": "\u2026domain, we can model an image f sp : R2 \u2192 R by its linear scale-space representation (Witkin, 1983; Koenderink and van Doorn, 1992; Lindeberg, 1994; Florack, 1997) Lt : R2 \u00d7 R+ \u2192 R\nLsp(x, y; \u03c32l ) = g sp(x, y; \u03c32l ) \u2217 f sp(x, y), (1)\ndefined by the convolution of f sp with Gaussian kernels of\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1168647,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "24cc563378d992214ee082f8af4e746316a575e7",
            "isKey": true,
            "numCitedBy": 292,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "notation: A = {F, </>}. In sloppy form: A = J dx f (x) </>( x). Samples are always finite, as opposed to point values of the underlying source field. Apart from this they may be positive, zero, or negative. A positive sample does not imply positivity of the underlying source field; a source is positive if all samples obtained by positive definite detectors tum out positive. If we want to compare different samples, we have to gauge our detectors by a conventional normalisation. For the moment we will require neither positivity nor normalisation. Since Definition 3.1 claims to define a local sample, we have to be able to tell what its base point is. In order to do so we need an explicit definition of a projection map 7r : ~ -+ M which associates each detector element </> E ~ with its corresponding base point x = 7r[</>]. This in tum assumes that we can perceive of ~ as a \"bundle\" of local device spaces ~x, comprising one \"fibre\" for each base point: ~ = UxEM~x' The inverse image 7r1(x) of a base point x is, by definition, the entire local device space ~x at that point. A local state space ~x is then established as the physical degrees of freedom probed by a local device space ~x, i.e. \"what we are looking at\" with a localised detector. We will return to a precise definition of 7r in Section 3.9. For the moment it suffices to think of the base point as a the \"centre of gravity\" for the filter </>. The base point we would like to attribute to a sample is of course the one corresponding to the detector, but note that there is no way of telling from the value of a local sample \"where it's at\"; the geometric notion of a base point is established as an extrinsic detector property (a label). Obviously, local samples are obtained at finite resolution. Again, being a spatiotemporal property, resolution cannot be inferred from a sample's value, only 3.1 Local Samples 41 from its underlying aperture. A precise definition of the resolution of a local detector requires us to define a notion of extent or inner scale for that detector. A definition of inner scale will also be postponed until Section 3.9; think of it for the moment as the width of a central region, containing the filter's base point, where most of the filter's weight is concentrated (it is clearly not very useful to relate inner scale to detector support, since by construction this may be all of spacetime). See also Problem 3.2. We can consider the transformation (push forward) of a detector under an arbitrary spacetime automorphism, i.e. a \"warping\", or a smooth transformation of spacetime with smooth inverse. Definition 3.2 (Push Forward) Let () : M -t M : x 1-+ ()(x) be a smooth spacetime automorphism. The push forward of a filter is then defined as the mapping with Jacobian determinant J'X. == I det Vx I\u00b7 This induces a natural, so-called pull back (also called \"reciprocal image\") of the source. Definition 3.3 (Pull Back) With the automorphism () and its push forward ()* as defined in Definition 3.2, the pull back of the source is defined as the mapping ()* : Eo(x) -t Ex : F 1-+ ()* F defined by ()* F[\u00a2] ~f F[()*\u00a2]. In sloppy form this states that ()* f == f 0 (), which physicists tend to refer to as \"scalar field transformation\" (Problem 3.3). Note that if \u00a2 lives at base point x, then its push forward ()*\u00a2 is associated with the mapped point ()(x), which explains its name. Naturally, pull back works the other way around. Push forward and pull back are instances of a so-called\" carry along\" principle. If we have two communicating objects-i.c. sources plus detectors producing a response-then a change of either will in general be reflected in the output. Reversely, a given change in output can be explained as being caused by a change in either object. For example, shifting a patient underneath a scanner will have the same effect as moving the scanner in opposite sense over a stationary patient. This principle generalises to arbitrary deformations beyond rigid transformations (at least conceptually: one of the options is not necessarily in the interest of the patient). The idea is that at least one of these dual views is practicable and legitimate (e.g. processing scanner output). It would be formally more correct to attach base points to sources and detectors matching the labels of E and tl in Definitions 3.2 and 3.3, but that would yield rather cumbersome notations. There ought to be no confusion if we simply 42 Local Samples and Images keep in mind the following commutative diagram:"
            },
            "slug": "Image-Structure-Florack",
            "title": {
                "fragments": [],
                "text": "Image Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This chapter considers the transformation (push forward) of a detector under an arbitrary spacetime automorphism, i.e. a \"warping\", or a smooth transformation of spacetime with smooth inverse, since by construction this may be all of Spacetime."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Imaging and Vision"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 145
                            }
                        ],
                        "text": "Some of the works rely on pure spatial image features while using sophisticated body models and tracking schemes to constrain the interpretation (Baumberg and Hogg, 1996; Bregler and Malik, 1998; Sidenbladh et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 171
                            }
                        ],
                        "text": "Some of the works rely on pure spatial image features while using sophisticated body models and tracking schemes to constrain the interpretation (Baumberg and Hogg, 1996; Bregler and Malik, 1998; Sidenbladh, Black and Fleet, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2751624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f6a3dea66b539d75c30fb24ecefe627bbb0c3a9",
            "isKey": false,
            "numCitedBy": 882,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper demonstrates a new visual motion estimation technique that is able to recover high degree-of-freedom articulated human body configurations in complex video sequences. We introduce the use of a novel mathematical technique, the product of exponential maps and twist motions, and its integration into a differential motion estimation. This results in solving simple linear systems, and enables us to recover robustly the kinematic degrees-of-freedom in noise and complex self occluded configurations. We demonstrate this on several image sequences of people doing articulated full body movements, and visualize the results in re-animating an artificial 3D human model. We are also able to recover and re-animate the famous movements of Eadweard Muybridge's motion studies from the last century. To the best of our knowledge, this is the first computer vision based system that is able to process such challenging footage and recover complex motions with such high accuracy."
            },
            "slug": "Tracking-people-with-twists-and-exponential-maps-Bregler-Malik",
            "title": {
                "fragments": [],
                "text": "Tracking people with twists and exponential maps"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper demonstrates a new visual motion estimation technique that is able to recover high degree-of-freedom articulated human body configurations in complex video sequences, and is the first computer vision based system able to process such challenging footage and recover complex motions with such high accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2874997"
                        ],
                        "name": "S. Niyogi",
                        "slug": "S.-Niyogi",
                        "structuredName": {
                            "firstName": "Sourabh",
                            "lastName": "Niyogi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Niyogi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 58
                            }
                        ],
                        "text": "Interesting solutions to this problem have been proposed (Niyogi, 1995; Fleet, Black and Jepson, 1998; Hoey and Little, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 57
                            }
                        ],
                        "text": "Interesting solutions to this problem have been proposed (Niyogi, 1995; Fleet et al., 1998; Hoey and Little, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2609684,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "11e7a05250174fef41fe35e5a0748fadeb2c1f48",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual motion boundaries provide a powerful cue for the perceptual organization of scenes. Motion boundaries are present when surfaces in motion occlude one another. Conventional approaches to motion analysis have relied on assumptions of data conservation and smoothness, which has made analysis of motion boundaries difficult. We show that a common source of motion boundary, kinetic occlusion, can be detected using spatiotemporal junction analysis. Junction analysis is accomplished by utilizing distributed representations of motion used in models of human visual motion sensing. By detecting changes in the direction of motion in these representations, spatiotemporal junctions are detected in a manner which differentiates accretion from deletion. We demonstrate successful occlusion detection on spatiotemporal imagery containing occluding surfaces in motion.<<ETX>>"
            },
            "slug": "Detecting-kinetic-occlusion-Niyogi",
            "title": {
                "fragments": [],
                "text": "Detecting kinetic occlusion"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that a common source of motion boundary, kinetic occlusion, can be detected using spatiotemporal junction analysis, and successful occlusions detection is demonstrated on spatiotmporal imagery containing occluding surfaces in motion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809905"
                        ],
                        "name": "A. Witkin",
                        "slug": "A.-Witkin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Witkin",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Witkin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 49
                            }
                        ],
                        "text": "R 2 \u2192 R by its linear scale-space representation (Witkin, 1983; Koenderink and van Doorn, 1992; Lindeberg, 1994; Florack, 1997) Lsp: R2 \u00d7 R+ \u2192 R"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 99
                            }
                        ],
                        "text": "In the spatial domain, we can model an image f sp : R2 \u2192 R by its linear scale-space representation (Witkin, 1983; Koenderink and van Doorn, 1992; Lindeberg, 1994; Florack, 1997) Lt : R2 \u00d7 R+ \u2192 R\nLsp(x, y; \u03c32l ) = g sp(x, y; \u03c32l ) \u2217 f sp(x, y), (1)\ndefined by the convolution of f sp with Gaussian\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7096897,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a26f893c224ed6e3df1f37479de0e774a4cae237",
            "isKey": false,
            "numCitedBy": 2873,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Scale-Space-Filtering-Witkin",
            "title": {
                "fragments": [],
                "text": "Scale-Space Filtering"
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859042"
                        ],
                        "name": "D. Hall",
                        "slug": "D.-Hall",
                        "structuredName": {
                            "firstName": "Daniela",
                            "lastName": "Hall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2481445"
                        ],
                        "name": "V. Verdi\u00e8re",
                        "slug": "V.-Verdi\u00e8re",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Verdi\u00e8re",
                            "middleNames": [
                                "Colin",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Verdi\u00e8re"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687022"
                        ],
                        "name": "J. Crowley",
                        "slug": "J.-Crowley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Crowley",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Crowley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 90
                            }
                        ],
                        "text": "Image structures in video are not restricted to constant velocity and/or constant appearance over time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 202
                            }
                        ],
                        "text": "A similar approach has proven to be highly successful in the spatial domain for the task of image representation (Malik, Belongie, Shi and Leung, 1999) indexing (Schmid and Mohr, 1997) and recognition (Hall et al., 2000; Weber, Welling and Perona, 2000; Leung and Malik, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 868624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a881611042fa91b72689d90307fefd84c28dd5fc",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an extension of a technique for the recognition and tracking of every day objects in cluttered scenes. The goal is to build a system in which ordinary desktop objects serve as physical icons in a vision based system for man-machine interaction. In such a system, the manipulation of objects replaces user commands. \n \nA view-variant recognition technique, developed by the second author, has been adapted by the first author for a problem of recognising and tracking objects on a cluttered background in the presence of occlusions. This method is based on sampling a local appearance function at discrete viewpoints by projecting it onto a vector of receptive fields which have been normalised to local scale and orientation. This paper reports on the experimental validation of the approach, and of its extension to the use of receptive fields based on colour. The experimental results indicate that the second author's technique does indeed provide a method for building a fast and robust recognition technique. Furthermore, the extension to coloured receptive fields provides a greater degree of local discrimination and an enhanced robustness to variable background conditions. \n \nThe approach is suitable for the recognition of general objects as physical icons in an augmented reality."
            },
            "slug": "Object-Recognition-Using-Coloured-Receptive-Fields-Hall-Verdi\u00e8re",
            "title": {
                "fragments": [],
                "text": "Object Recognition Using Coloured Receptive Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results indicate that the second author's technique does indeed provide a method for building a fast and robust recognition technique, and its extension to the use of receptive fields based on colour provides a greater degree of local discrimination and an enhanced robustness to variable background conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "indexing (Schmid and Mohr, 1997) and recognition (Hall et al., 2000; Weber et al., 2000;  Leung and Malik, 2001 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 254
                            }
                        ],
                        "text": "A similar approach has proven to be highly successful in the spatial domain for the task of image representation (Malik, Belongie, Shi and Leung, 1999) indexing (Schmid and Mohr, 1997) and recognition (Hall et al., 2000; Weber, Welling and Perona, 2000; Leung and Malik, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14915716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90d6e7f2202f754d8588f9536e3f5b4a24701f24",
            "isKey": false,
            "numCitedBy": 1713,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the recognition of surfaces made from different materials such as concrete, rug, marble, or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof. Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions.Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions. We also illustrate how the 3D texton model can be used to predict the appearance of materials under novel conditions."
            },
            "slug": "Representing-and-Recognizing-the-Visual-Appearance-Leung-Malik",
            "title": {
                "fragments": [],
                "text": "Representing and Recognizing the Visual Appearance of Materials using Three-dimensional Textons"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A unified model to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions is provided."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 69
                            }
                        ],
                        "text": "Other approaches use spatio-temporal image cues such as optical flow (Black et al., 1997) or motion templates (Baumberg and Hogg, 1996; Efros et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 403007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24cde5de8abd1ebf70b9439dc4cf8cf545e73e45",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A framework for learning parameterized models of optical flow from image sequences is presented. A class of motions is represented by a set of orthogonal basis flow fields that are computed from a training set using principal component analysis. Many complex image motions can be represented by a linear combination of a small number of these basis flows. The learned motion models may be used for optical flow estimation and for model-based recognition. For optical flow estimation we describe a robust, multi-resolution scheme for directly computing the parameters of the learned flow models from image derivatives. As examples we consider learning motion discontinuities, non-rigid motion of human mouths, and articulated human motion."
            },
            "slug": "Learning-parameterized-models-of-image-motion-Black-Yacoob",
            "title": {
                "fragments": [],
                "text": "Learning parameterized models of image motion"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A framework for learning parameterized models of optical flow from image sequences is presented and a robust, multi-resolution scheme for directly computing the parameters of the learned flow models from image derivatives is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 84
                            }
                        ],
                        "text": "For real-time implementation, time-causal scale-space filters thus have to be used (Koenderink, 1988; Lindeberg and Fagerstro\u0308m, 1996; Florack, 1997; Lindeberg, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 130
                            }
                        ],
                        "text": "Such image points are\nfrequently referred to as \u201cinterest points\u201d and are attractive due to their high information contents and relative stability with respect to perspective transformations of the data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 68
                            }
                        ],
                        "text": "As events often have characteristic extents in both space and time (Koenderink, 1988; Lindeberg and Fagerstro\u0308m, 1996; Florack, 1997; Lindeberg, 1997; Chomat, Martin and Crowley, 2000b; Zelnik-Manor and Irani, 2001), we investigate the behavior of interest points in spatio-temporal scale-space and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 209034116,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "ee3b7c2082cd273a221fe2541c93ef76fe2ae7db",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A conceptually simple and logically consistent version of \u201cscale-space\u201d for the temporal domain is proposed. The method does not violate temporal causality, yet conserves causality in the resolution domain at any given moment in time. The filter kernels are not Gaussians (that would certainly lead to a violation of temporal causality) but are related to the Gaussians via a simple transformation of the time axis. They depend on a pair of parameters, one that has the character of a temporal delay and one that specifies the temporal resolution. In the limit for long delays (but fixed resolution) these kernels asymptotically approach the Gaussian again. Extensions of the theory towards a scale space-time are discussed."
            },
            "slug": "Scale-time-Koenderink",
            "title": {
                "fragments": [],
                "text": "Scale-time"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A conceptually simple and logically consistent version of \u201cscale-space\u201d for the temporal domain is proposed, which does not violate temporal causality, yet conserves causality in the resolution domain at any given moment in time."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40309692"
                        ],
                        "name": "C. G. Harris",
                        "slug": "C.-G.-Harris",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Harris",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40365651"
                        ],
                        "name": "M. Stephens",
                        "slug": "M.-Stephens",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Stephens",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stephens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 160
                            }
                        ],
                        "text": "In the spatial domain, points with a significant local variation of image intensities have been extensively investigated in the past (Fo\u0308rstner and Gu\u0308lch, 1987; Harris and Stephens, 1988; Lindeberg, 1998; Schmid, Mohr and Bauckhage, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2217The support from the Swedish Research Council and from the Royal Swedish Academy of Sciences as well as the Knut and Alice Wallenberg Foundation is gratefully acknowledged."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 117
                            }
                        ],
                        "text": "To detect spatio-temporal interest points, we build on the idea of the Harris and Fo\u0308rstner interest point operators (Harris and Stephens, 1988; Fo\u0308rstner and Gu\u0308lch, 1987) and describe the detection method in section 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 23
                            }
                        ],
                        "text": "To detect such points, Harris and Stephens (1988) proposed to detect positive maxima of the corner function\nHsp = det(\u00b5sp)\u2212 k trace2(\u00b5sp) = \u03bb1\u03bb2 \u2212 k(\u03bb1 + \u03bb2)2."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1694378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6818668fb895d95861a2eb9673ddc3a41e27b3b3",
            "isKey": true,
            "numCitedBy": 14112,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed."
            },
            "slug": "A-Combined-Corner-and-Edge-Detector-Harris-Stephens",
            "title": {
                "fragments": [],
                "text": "A Combined Corner and Edge Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem the authors are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work."
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2217The support from the Swedish Research Council and from the Royal Swedish Academy of Sciences as well as the Knut and Alice Wallenberg Foundation is gratefully acknowledged."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5745749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62837ab473124ea43cb8d7c6a4b4ee0f6f14e8c5",
            "isKey": false,
            "numCitedBy": 2487,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "slug": "Object-class-recognition-by-unsupervised-learning-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "Object class recognition by unsupervised scale-invariant learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7977369"
                        ],
                        "name": "A. Doorn",
                        "slug": "A.-Doorn",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Doorn",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doorn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 60
                            }
                        ],
                        "text": "In the spatial domain, we can model an image f sp : R2 \u2192 R by its linear scale-space representation (Witkin, 1983; Koenderink and van Doorn, 1992; Lindeberg, 1994; Florack, 1997) Lt : R2 \u00d7 R+ \u2192 R\nLsp(x, y; \u03c32l ) = g sp(x, y; \u03c32l ) \u2217 f sp(x, y), (1)\ndefined by the convolution of f sp with Gaussian\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42555882,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "050bb36fc18c3e93497850d3b664799959c91058",
            "isKey": false,
            "numCitedBy": 243,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A method that treats linear neighborhood operators within a unified framework that enables linear combinations, concatenations, resolution changes, or rotations of operators to be treated in a canonical manner is presented. Various families of operators with special kinds of symmetries (such as translation, rotation, magnification) are explicitly constructed in 1-D, 2-D, and 3-D. A concept of 'order' is defined, and finite orthonormal bases of functions closely connected with the operators of various orders are constructed. Linear transformations between the various representations are considered. The method is based on two fundamental assumptions: a decrease of resolution should not introduce spurious detail, and the local operators should be self-similar under changes of resolution. These assumptions merely sum up the even more general need for homogeneity isotropy, scale invariance, and separability of independent dimensions of front-end processing in the absence of a priori information. >"
            },
            "slug": "Generic-Neighborhood-Operators-Koenderink-Doorn",
            "title": {
                "fragments": [],
                "text": "Generic Neighborhood Operators"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A method that treats linear neighborhood operators within a unified framework that enables linear combinations, concatenations, resolution changes, or rotations of operators to be treated in a canonical manner is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076817912"
                        ],
                        "name": "P. Pritchett",
                        "slug": "P.-Pritchett",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Pritchett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pritchett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46527015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4da91ba2e80a4d8deb597b1c884cda890f086653",
            "isKey": false,
            "numCitedBy": 351,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically. This facilitates matching between quite disparate views-wide baseline stereo. Two extensions are made to the current small baseline algorithms: first, and most importantly, a viewpoint invariant measure is developed for assessing the affinity of corner neighbourhoods over image pairs; second, algorithms are given for generating putative corner matches between image pairs using local homographies. Two novel infrastructure developments are also described: the automatic generation of local homographies, and the combination of possibly conflicting sets of matches prior to RANSAC estimation. The wide baseline matching algorithm is demonstrated on a number of image pairs with varying relative motion, and for different scene types. All processing is automatic."
            },
            "slug": "Wide-baseline-stereo-matching-Pritchett-Zisserman",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo matching"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically, and to facilitate matching between quite disparate views-wide baseline stereo."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793750"
                        ],
                        "name": "C. Wallraven",
                        "slug": "C.-Wallraven",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Wallraven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wallraven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144813423"
                        ],
                        "name": "Arnulf B. A. Graf",
                        "slug": "Arnulf-B.-A.-Graf",
                        "structuredName": {
                            "firstName": "Arnulf",
                            "lastName": "Graf",
                            "middleNames": [
                                "B.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnulf B. A. Graf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 26
                            }
                        ],
                        "text": "On the contrary, many interesting events in video are characterized by strong variations in the data along both the spatial and the temporal dimensions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4573035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c393b31ca71e8c4dd7c8c5a11653b18447c90466",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments in computer vision have shown that local features can provide efficient representations suitable for robust object recognition. Support vector machines have been established as powerful learning algorithms with good generalization capabilities. We combine these two approaches and propose a general kernel method for recognition with local features. We show that the proposed kernel satisfies the Mercer condition and that it is, suitable for many established local feature frameworks. Large-scale recognition results are presented on three different databases, which demonstrate that SVMs with the proposed kernel perform better than standard matching techniques on local features. In addition, experiments on noisy and occluded images show that local feature representations significantly outperform global approaches."
            },
            "slug": "Recognition-with-local-features:-the-kernel-recipe-Wallraven-Caputo",
            "title": {
                "fragments": [],
                "text": "Recognition with local features: the kernel recipe"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Large-scale recognition results are presented, which demonstrate that SVMs with the proposed kernel perform better than standard matching techniques on local features and that local feature representations significantly outperform global approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110604335"
                        ],
                        "name": "Markus Weber",
                        "slug": "Markus-Weber",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 194
                            }
                        ],
                        "text": "Thus clustering of spatio-temporal neighborhoods is similar to the idea of textons (Malik et al., 1999) used to describe image texture as well as to detect object parts for spatial recognition (Weber et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8970876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cf1527807ebb16020b04d4166e7ba8d27652302",
            "isKey": false,
            "numCitedBy": 757,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition. We focus on a particular type of model where objects are represented as flexible constellations of rigid parts (features). The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors. In a first stage, the method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator. It then learns the statistical shape model using expectation maximization. The method achieves very good classification results on human faces and rear views of cars."
            },
            "slug": "Unsupervised-Learning-of-Models-for-Recognition-Weber-Welling",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Models for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method to learn object class models from unlabeled and unsegmented cluttered cluttered scenes for the purpose of visual object recognition that achieves very good classification results on human faces and rear views of cars."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692283"
                        ],
                        "name": "C. Bauckhage",
                        "slug": "C.-Bauckhage",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bauckhage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bauckhage"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 133
                            }
                        ],
                        "text": "In the spatial domain, points with a significant local variation of image intensities have been extensively investigated in the past (F\u00f6rstner and G\u00fclch, 1987; Harris and Stephens, 1988; Lindeberg, 1998; Schmid et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14571093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2713e7a59105a832e20c01c3c202b9dcd2b5f889",
            "isKey": false,
            "numCitedBy": 1730,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Many different low-level feature detectors exist and it is widely agreed that the evaluation of detectors is important. In this paper we introduce two evaluation criteria for interest points' repeatability rate and information content. Repeatability rate evaluates the geometric stability under different transformations. Information content measures the distinctiveness of features. Different interest point detectors are compared using these two criteria. We determine which detector gives the best results and show that it satisfies the criteria well."
            },
            "slug": "Evaluation-of-Interest-Point-Detectors-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Evaluation of Interest Point Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two evaluation criteria for interest points' repeatability rate and information content are introduced and different interest point detectors are compared using these two criteria."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400165226"
                        ],
                        "name": "J. Andrade-Cetto",
                        "slug": "J.-Andrade-Cetto",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Andrade-Cetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Andrade-Cetto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 407,
                                "start": 331
                            }
                        ],
                        "text": "Highly successful applications of interest points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe, 1999; Hall et al., 2000; Fergus et al., 2003; Wallraven et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 49
                            }
                        ],
                        "text": "indexing (Schmid and Mohr, 1997) and recognition (Hall et al., 2000; Weber et al., 2000; Leung and Malik, 2001)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 202
                            }
                        ],
                        "text": "A similar approach has proven to be highly successful in the spatial domain for the task of image representation (Malik, Belongie, Shi and Leung, 1999) indexing (Schmid and Mohr, 1997) and recognition (Hall et al., 2000; Weber, Welling and Perona, 2000; Leung and Malik, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 83903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0d2f046362515a8597673c6d5cc30a7eecdab47",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "Object recognition is a subproblem of the more general problem of perception, and can be defined as follows. Given a scene consisting of one or more objects, can we identify and localize those objects that are sufficiently visible to the sensory system? It is generally assumed that a description of each object to be recognized is available to the computer and can be used to facilitate the task of identification and localization. These descriptions can either be model-based or appearance-based, or a combination of both. Model-based object representation is based on geometric features, whereas appearance-based representation uses a large set of images for training but does not require any insight on the geometric structure of the objects. Object recognition is a key component of many intelligent vision systems, such as those used in hand-eye coordination for bin picking, inspection, and mobile robotics."
            },
            "slug": "Object-Recognition-Andrade-Cetto",
            "title": {
                "fragments": [],
                "text": "Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Object recognition is a key component of many intelligent vision systems, such as those used in hand-eye coordination for bin picking, inspection, and mobile robotics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713633"
                        ],
                        "name": "Andr\u00e9s Almansa",
                        "slug": "Andr\u00e9s-Almansa",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Almansa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Almansa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 129
                            }
                        ],
                        "text": "Local scale estimation using the normalized Laplace operator has shown to be very useful in the spatial domain (Lindeberg, 1998; Almansa and Lindeberg, 2000; Chomat, de Verdiere, Hall and Crowley, 2000a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14480964,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "154db6db5772ec009e376a03ce22b12175dffd0a",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "This work presents two mechanisms for processing fingerprint images; shape-adapted smoothing based on second moment descriptors and automatic scale selection based on normalized derivatives. The shape adaptation procedure adapts the smoothing operation to the local ridge structures, which allows interrupted ridges to be joined without destroying essential singularities such as branching points and enforces continuity of their directional fields. The scale selection procedure estimates local ridge width and adapts the amount of smoothing to the local amount of noise. In addition, a ridgeness measure is defined, which reflects how well the local image structure agrees with a qualitative ridge model, and is used for spreading the results of shape adaptation into noisy areas. The combined approach makes it possible to resolve fine scale structures in clear areas while reducing the risk of enhancing noise in blurred or fragmented areas. The result is a reliable and adaptively detailed estimate of the ridge orientation field and ridge width, as well as a smoothed grey-level version of the input image. We propose that these general techniques should be of interest to developers of automatic fingerprint identification systems as well as in other applications of processing related types of imagery."
            },
            "slug": "Fingerprint-enhancement-by-shape-adaptation-of-with-Almansa-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Fingerprint enhancement by shape adaptation of scale-space operators with automatic scale selection"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This work presents two mechanisms for processing fingerprint images; shape-adapted smoothing based on second moment descriptors and automatic scale selection based on normalized derivatives, which makes it possible to resolve fine scale structures in clear areas while reducing the risk of enhancing noise in blurred or fragmented areas."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Traditional approaches for motion analysis mainly involve the computation of optic flow (Barron et al., 1994) or feature tracking (Smith and Brady, 1995;  Blake and Isard, 1998 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6821810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "963dddc907f56bd1d6c98dd40f560eb8786e49ea",
            "isKey": false,
            "numCitedBy": 5523,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of tracking curves in dense visual clutter is challenging. Kalman filtering is inadequate because it is based on Gaussian densities which, being unimo dal, cannot represent simultaneous alternative hypotheses. The Condensation algorithm uses \u201cfactored sampling\u201d, previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set. Condensation uses learned dynamical models, together with visual observations, to propagate the random set over time. The result is highly robust tracking of agile motion. Notwithstanding the use of stochastic methods, the algorithm runs in near real-time."
            },
            "slug": "CONDENSATION\u2014Conditional-Density-Propagation-for-Isard-Blake",
            "title": {
                "fragments": [],
                "text": "CONDENSATION\u2014Conditional Density Propagation for Visual Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Condensation algorithm uses \u201cfactored sampling\u201d, previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 90
                            }
                        ],
                        "text": "Highly successful applications of interest points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 89
                            }
                        ],
                        "text": "Highly successful applications of interest points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe, 1999; Hall et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 9
                            }
                        ],
                        "text": "indexing (Schmid and Mohr, 1997) and recognition (Hall et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 162
                            }
                        ],
                        "text": "A similar approach has proven to be highly successful in the spatial domain for the task of image representation (Malik, Belongie, Shi and Leung, 1999) indexing (Schmid and Mohr, 1997) and recognition (Hall et al., 2000; Weber, Welling and Perona, 2000; Leung and Malik, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": true,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15808204"
                        ],
                        "name": "J. Barron",
                        "slug": "J.-Barron",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Barron",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Barron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46818737"
                        ],
                        "name": "S. Beauchemin",
                        "slug": "S.-Beauchemin",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Beauchemin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Beauchemin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 88
                            }
                        ],
                        "text": "Traditional approaches for motion analysis mainly involve the computation of optic flow (Barron et al., 1994) or feature tracking (Smith and Brady, 1995; Blake and Isard, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1290100,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "400f4afb2a055d95483d83c4bedab10281a8639d",
            "isKey": false,
            "numCitedBy": 4068,
            "numCiting": 125,
            "paperAbstract": {
                "fragments": [],
                "text": "While different optical flow techniques continue to appear, there has been a lack of quantitative evaluation of existing methods. For a common set of real and synthetic image sequences, we report the results of a number of regularly cited optical flow techniques, including instances of differential, matching, energy-based, and phase-based methods. Our comparisons are primarily empirical, and concentrate on the accuracy, reliability, and density of the velocity measurements; they show that performance can differ significantly among the techniques we implemented."
            },
            "slug": "Performance-of-optical-flow-techniques-Barron-Fleet",
            "title": {
                "fragments": [],
                "text": "Performance of optical flow techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "These comparisons are primarily empirical, and concentrate on the accuracy, reliability, and density of the velocity measurements; they show that performance can differ significantly among the techniques the authors implemented."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2874997"
                        ],
                        "name": "S. Niyogi",
                        "slug": "S.-Niyogi",
                        "structuredName": {
                            "firstName": "Sourabh",
                            "lastName": "Niyogi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Niyogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The work of  Niyogi and Adelson (1994)  concerns the structure of the spatiotemporal gait pattern and is closer to ours."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 12
                            }
                        ],
                        "text": "The work of Niyogi and Adelson (1994) concerns the structure of the spatio-temporal gait pattern and is closer to ours."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18566850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57854a0e8309af7ad6f5d9612e20e2ba1a171a96",
            "isKey": false,
            "numCitedBy": 661,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel algorithm for gait analysis. A person walking frontoparallel to the image plane generates a characteristic \"braided\" pattern in a spatiotemporal (XYT) volume. Our algorithm detects this pattern, and fits it with a set of spatiotemporal snakes. The snakes can be used to find the bounding contours of the walker. The contours vary over time in a manner characteristic of each walker. Individual gaits can be recognized by applying standard pattern recognition techniques to the contour signals.<<ETX>>"
            },
            "slug": "Analyzing-and-recognizing-walking-figures-in-XYT-Niyogi-Adelson",
            "title": {
                "fragments": [],
                "text": "Analyzing and recognizing walking figures in XYT"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A novel algorithm for gait analysis that fits a characteristic \"braided\" pattern in a spatiotemporal volume, and fits it with a set of spatiotsemporal snakes that can be used to find the bounding contours of the walker."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 193
                            }
                        ],
                        "text": "To estimate the spatio-temporal extent of an event in\nspace-time, we follow works on local scale selection proposed in the spatial domain by Lindeberg (1998) as well as in the temporal domain (Lindeberg, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 20
                            }
                        ],
                        "text": "Interesting solutions to this problem have been proposed (Niyogi, 1995; Fleet, Black and Jepson, 1998; Hoey and Little, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 196
                            }
                        ],
                        "text": "In that case an approximate estimate of temporal scale can still be found by choosing interest points that maximize (\u22072normL)2 in a local neighborhood of the spatio-temporal scale-space; see also (Lindeberg, 1997) for a treatment of automatic scale selection for time-causal scale-spaces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 133
                            }
                        ],
                        "text": "As events often have characteristic extents in both space and time (Koenderink, 1988; Lindeberg and Fagerstro\u0308m, 1996; Florack, 1997; Lindeberg, 1997; Chomat, Martin and Crowley, 2000b; Zelnik-Manor and Irani, 2001), we investigate the behavior of interest points in spatio-temporal scale-space and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2217The support from the Swedish Research Council and from the Royal Swedish Academy of Sciences as well as the Knut and Alice Wallenberg Foundation is gratefully acknowledged."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12712205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "511b7acdcda08e3f425e98eb9161b5cfd1632a35",
            "isKey": true,
            "numCitedBy": 27,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines a general framework for automatic selection in temporal scale-space representations, and shows how the suggested theory applies to motion detection and motion estimation."
            },
            "slug": "On-Automatic-Selection-of-Temporal-Scales-in-Lindeberg",
            "title": {
                "fragments": [],
                "text": "On Automatic Selection of Temporal Scales in Time-Causal Scale-Space"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper outlines a general framework for automatic selection in temporal scale-space representations, and shows how the suggested theory applies to motion detection and motion estimation."
            },
            "venue": {
                "fragments": [],
                "text": "AFPAC"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 160
                            }
                        ],
                        "text": "In the spatial domain, points with a significant local variation of image intensities have been extensively investigated in the past (Fo\u0308rstner and Gu\u0308lch, 1987; Harris and Stephens, 1988; Lindeberg, 1998; Schmid, Mohr and Bauckhage, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 77
                            }
                        ],
                        "text": "Although very effective for many tasks, both of these techniques have limitations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 117
                            }
                        ],
                        "text": "To detect spatio-temporal interest points, we build on the idea of the Harris and Fo\u0308rstner interest point operators (Harris and Stephens, 1988; Fo\u0308rstner and Gu\u0308lch, 1987) and describe the detection method in section 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 23
                            }
                        ],
                        "text": "To detect such points, Harris and Stephens (1988) proposed to detect positive maxima of the corner function\nHsp = det(\u00b5sp)\u2212 k trace2(\u00b5sp) = \u03bb1\u03bb2 \u2212 k(\u03bb1 + \u03bb2)2."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 116
                            }
                        ],
                        "text": "To detect spatio-temporal interest points, we build on the idea of the Harris and F\u00f6rstner interest point operators (Harris and Stephens, 1988; F\u00f6rstner and G\u00fclch, 1987) and describe the detection method in Section 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 144
                            }
                        ],
                        "text": "For a given scale of observation \u03c32l , such points can be found using a second moment matrix integrated over a Gaussian window with\nvariance \u03c32i (Fo\u0308rstner and Gu\u0308lch, 1987; Bigu\u0308n, Granlund and Wiklund, 1991; Lindeberg and Garding, 1997):\n\u00b5sp(\u00b7; \u03c32l , \u03c32i ) = gsp(\u00b7; \u03c32i ) \u2217 ( (\u2207L(\u00b7; \u03c32l ))(\u2207L(\u00b7;\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 133
                            }
                        ],
                        "text": "In the spatial domain, points with a significant local variation of image intensities have been extensively investigated in the past (F\u00f6rstner and G\u00fclch, 1987; Harris and Stephens, 1988; Lindeberg, 1998; Schmid et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 134
                            }
                        ],
                        "text": "In the spatial domain, points with a significant local variation of image intensities have been extensively investigated in the past (Fo\u0308rstner and Gu\u0308lch, 1987; Harris and Stephens, 1988; Lindeberg, 1998; Schmid, Mohr and Bauckhage, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 149
                            }
                        ],
                        "text": "For a given scale of observation \u03c3 2 l , such points can be found using a second moment matrix integrated over a Gaussian window with variance \u03c3 2 i (F\u00f6rstner and G\u00fclch, 1987; Big\u00fcn et al., 1991; G\u00e5rding and Lindeberg, 1996):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 144
                            }
                        ],
                        "text": "To detect spatio-temporal interest points, we build on the idea of the Harris and Fo\u0308rstner interest point operators (Harris and Stephens, 1988; Fo\u0308rstner and Gu\u0308lch, 1987) and describe the detection method in section 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A fast operator for detection and precise location of distinct points, corners and centers of circular features"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Intercommission Workshop of the"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 67
                            }
                        ],
                        "text": "As events often have characteristic extents in both space and time (Koenderink, 1988; Lindeberg and Fagerstr\u00f6m, 1996; Florack, 1997; Lindeberg, 1997; Chomat et al., 2000b; Zelnik-Manor and Irani, 2001), we investigate the behavior of interest points in spatiotemporal scale-space and adapt both the spatial and the temporal scales of the detected features in Section 3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 104
                            }
                        ],
                        "text": "To solve this problem, time-causal scale-space filters can be used to satisfy the causality constraints (Koenderink, 1988; Lindeberg and Fagerstr\u00f6m, 1996; Florack, 1997; Lindeberg, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 118
                            }
                        ],
                        "text": "As events often have characteristic extents in both space and time (Koenderink, 1988; Lindeberg and Fagerstro\u0308m, 1996; Florack, 1997; Lindeberg, 1997; Chomat, Martin and Crowley, 2000b; Zelnik-Manor and Irani, 2001), we investigate the behavior of interest points in spatio-temporal scale-space and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 49
                            }
                        ],
                        "text": "R 2 \u2192 R by its linear scale-space representation (Witkin, 1983; Koenderink and van Doorn, 1992; Lindeberg, 1994; Florack, 1997) Lsp: R2 \u00d7 R+ \u2192 R"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 134
                            }
                        ],
                        "text": "For real-time implementation, time-causal scale-space filters thus have to be used (Koenderink, 1988; Lindeberg and Fagerstro\u0308m, 1996; Florack, 1997; Lindeberg, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 148
                            }
                        ],
                        "text": "\u2026domain, we can model an image f sp : R2 \u2192 R by its linear scale-space representation (Witkin, 1983; Koenderink and van Doorn, 1992; Lindeberg, 1994; Florack, 1997) Lt : R2 \u00d7 R+ \u2192 R\nLsp(x, y; \u03c32l ) = g sp(x, y; \u03c32l ) \u2217 f sp(x, y), (1)\ndefined by the convolution of f sp with Gaussian kernels of\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Structure, Kluwer Academic Publishers, Dordrecht, Netherlands"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84365189"
                        ],
                        "name": "Richard G. Kurial",
                        "slug": "Richard-G.-Kurial",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Kurial",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard G. Kurial"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125549744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d667186caad725d1931d12b3b55d3f0a019b17a5",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Representation-and-recognition-Kurial",
            "title": {
                "fragments": [],
                "text": "Representation and recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586918"
                        ],
                        "name": "D. Stork",
                        "slug": "D.-Stork",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stork",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stork"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 196008710,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78053512af13466c569e5946acfc3953bbfc9d36",
            "isKey": false,
            "numCitedBy": 18023,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pattern-Classification-Hart-Duda",
            "title": {
                "fragments": [],
                "text": "Pattern Classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 160
                            }
                        ],
                        "text": "In the spatial domain, points with a significant local variation of image intensities have been extensively investigated in the past (Fo\u0308rstner and Gu\u0308lch, 1987; Harris and Stephens, 1988; Lindeberg, 1998; Schmid, Mohr and Bauckhage, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 117
                            }
                        ],
                        "text": "To detect spatio-temporal interest points, we build on the idea of the Harris and Fo\u0308rstner interest point operators (Harris and Stephens, 1988; Fo\u0308rstner and Gu\u0308lch, 1987) and describe the detection method in section 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 23
                            }
                        ],
                        "text": "To detect such points, Harris and Stephens (1988) proposed to detect positive maxima of the corner function\nHsp = det(\u00b5sp)\u2212 k trace2(\u00b5sp) = \u03bb1\u03bb2 \u2212 k(\u03bb1 + \u03bb2)2."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A combined corner and edge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 146
                            }
                        ],
                        "text": "Traditional approaches for motion analysis mainly involve the computation of optic flow (Barron, Fleet and Beauchemin, 1994) or feature tracking (Smith and Brady, 1995; Blake and Isard, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 306,
                                "start": 253
                            }
                        ],
                        "text": "Highly successful applications of interest points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe, 1999; Hall et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 148
                            }
                        ],
                        "text": "\u20261997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe, 1999; Hall, de Verdiere and Crowley, 2000; Fergus, Perona and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ASSET-2: Real-time motion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 150
                            }
                        ],
                        "text": "\u2026points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 130
                            }
                        ],
                        "text": "Highly successful applications of interest points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe, 1999; Hall et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combining topology and appearance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 49
                            }
                        ],
                        "text": "indexing (Schmid and Mohr, 1997) and recognition (Hall et al., 2000; Weber et al., 2000; Leung and Malik, 2001)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 254
                            }
                        ],
                        "text": "A similar approach has proven to be highly successful in the spatial domain for the task of image representation (Malik, Belongie, Shi and Leung, 1999) indexing (Schmid and Mohr, 1997) and recognition (Hall et al., 2000; Weber, Welling and Perona, 2000; Leung and Malik, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Representing and recognizing the vi"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 254
                            }
                        ],
                        "text": "During recent years, the problem of automatic scale selection has been addressed in several different ways, based on the maximization of normalized derivative expressions over scale, or the behavior of entropy measures or error measures over scales (see Lindeberg and Bretzner (2003) for a review)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Real-time scale selection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 149
                            }
                        ],
                        "text": "For a given scale of observation \u03c3 2 l , such points can be found using a second moment matrix integrated over a Gaussian window with variance \u03c3 2 i (F\u00f6rstner and G\u00fclch, 1987; Big\u00fcn et al., 1991; G\u00e5rding and Lindeberg, 1996):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Direct computation of shape"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Interest points in space-time"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . Ninth International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 244
                            }
                        ],
                        "text": "Moreover, as the current scheme of event detection is not invariant under Galilean transformations, future work should investigate the possibilities of including such invariance and making the approach independent of the relative camera motion (Laptev and Lindeberg, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 236
                            }
                        ],
                        "text": "\u2026as the current scheme of event detection is not invariant under Galilean transformations, future work should investigate the possibilities of including such invariance and making the approach independent of the relative camera motion (Laptev and Lindeberg, 2002; Laptev and Lindeberg, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Velocity-Adaptation of Spatio"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scale-space with causal time"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Interest Point Detection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 150
                            }
                        ],
                        "text": "\u2026points have been presented for image indexing (Schmid and Mohr, 1997), stereo matching (Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Tell and Carlsson, 2002), optic flow estimation and tracking (Smith and Brady, 1995; Bretzner and Lindeberg, 1998), and object recognition (Lowe,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 26
                            }
                        ],
                        "text": "Model-based solutions for this problem have been presented by (Black and Jepson, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combining topology and appearance for wide baseline matching"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . Seventh European Conference on Computer Vision"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 97
                            }
                        ],
                        "text": ", 1999) used to describe image texture as well as to detect object parts for spatial recognition (Weber et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 194
                            }
                        ],
                        "text": "Thus clustering of spatio-temporal neighborhoods is similar to the idea of textons (Malik et al., 1999) used to describe image texture as well as to detect object parts for spatial recognition (Weber et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Unsupervised learning of models for visual object class recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . Sixth European Conference on Computer Vision"
            },
            "year": 2000
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 46,
            "methodology": 35
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 70,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/On-Space-Time-Interest-Points-Laptev/d2fb2fa53021b2776da0fb8b53c54820ed3982cc?sort=total-citations"
}