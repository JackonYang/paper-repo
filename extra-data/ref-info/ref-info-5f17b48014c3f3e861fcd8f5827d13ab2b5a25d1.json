{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2652428"
                        ],
                        "name": "R. Polana",
                        "slug": "R.-Polana",
                        "structuredName": {
                            "firstName": "Ramprasad",
                            "lastName": "Polana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Polana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31614700"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randal",
                            "lastName": "Nelson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 19
                            }
                        ],
                        "text": "A pre-vious paper [Polana and Nelson, 1992] describes this."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 1
                            }
                        ],
                        "text": "[Polana and Nelson, 1992] R. Polana and R.C. Nel-son."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5688093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77a1edc187a28758d09c1d0d887d687bcb1759fa",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of visual motion recognition applicable to a range of naturally occurring motions that are characterized by spatial and temporal uniformity is described. The underlying motivation is the observation that, for objects that typically move, it is frequently easier to identify them when they are moving than when they are stationary. Specifically, it is shown that certain statistical spatial and temporal features that can be derived from approximations to the motion field have invariant properties, and can be used to classify regional activities such as windblown trees, ripples on water, or chaotic fluid flow, that are characterized by complex, non-rigid motion. The technique is referred to as temporal texture analysis, in analogy to the techniques developed to classify gray-scale textures. The techniques are demonstrated on a number of real-world image sequences containing complex movement. The work has practical application in monitoring and surveillance, and as a component of a sophisticated visual system.<<ETX>>"
            },
            "slug": "Recognition-of-motion-from-temporal-texture-Polana-Nelson",
            "title": {
                "fragments": [],
                "text": "Recognition of motion from temporal texture"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that certain statistical spatial and temporal features that can be derived from approximations to the motion field have invariant properties, and can be used to classify regional activities such as windblown trees, ripples on water, or chaotic fluid flow, that are characterized by complex, non-rigid motion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107784547"
                        ],
                        "name": "C. H. Anderson",
                        "slug": "C.-H.-Anderson",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Anderson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. H. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "134039691"
                        ],
                        "name": "G. S. van der Wal",
                        "slug": "G.-S.-van-der-Wal",
                        "structuredName": {
                            "firstName": "Gooitzen",
                            "lastName": "van der Wal",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. S. van der Wal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62139375,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a72b3b869ac537ee893e86365dc45021eef00da0",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "An automated, or \"smart\", surveillance system must be sensitive to small object motion wherever it may occur within a large field of view. The system must also be capable of distinguishing changes of interest from other image activity or noise. Yet the data processing capabilities of practical systems is often quite limited. To achieve these performance objectives at a low data rate, a pyramid based image preprocessor has been constructed that can compute frequency tuned \"change energy\" measures in real time. A microprocessor then examines a relatively small set of these measures and follows a foveal search strategy to isolate moving objects for tracking or for more detailed analysis."
            },
            "slug": "Change-Detection-and-Tracking-Using-Pyramid-Anderson-Burt",
            "title": {
                "fragments": [],
                "text": "Change Detection and Tracking Using Pyramid Transform Techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A pyramid based image preprocessor has been constructed that can compute frequency tuned \"change energy\" measures in real time and follows a foveal search strategy to isolate moving objects for tracking or for more detailed analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052391642"
                        ],
                        "name": "J. O'Rourke",
                        "slug": "J.-O'Rourke",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "O'Rourke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Rourke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699200"
                        ],
                        "name": "N. Badler",
                        "slug": "N.-Badler",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Badler",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Badler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 50
                            }
                        ],
                        "text": "The jointangles and angular velocities are invariant to rotationin the image plane, scale and translation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15680007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9df0428c30b8aab4f7e6f367e70126efdfb8fc45",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "A system capable of analyzing image sequences of human motion is described. The system is structured as a feedback loop between high and low levels: predictions are made at the semantic level and verifications are sought at the image level. The domain of human motion lends itself to a model-driven analysis, and the system includes a detailed model of the human body. All information extracted from the image is interpreted through a constraint network based on the structure of the human model. A constraint propagation operator is defined and its theoretical properties outlined. An implementation of this operator is described, and results of the analysis system for short image sequences are presented."
            },
            "slug": "Model-based-image-analysis-of-human-motion-using-O'Rourke-Badler",
            "title": {
                "fragments": [],
                "text": "Model-based image analysis of human motion using constraint propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A system capable of analyzing image sequences of human motion is described, structured as a feedback loop between high and low levels: predictions are made at the semantic level and verifications are sought at the image level."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053178525"
                        ],
                        "name": "G. Johansson",
                        "slug": "G.-Johansson",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "Johansson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Johansson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 133
                            }
                        ],
                        "text": "This biological use ofmotion probably re ects the fact that for certain tasks,visual motion provides more e ective cues than othermodes of visual perception."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54046837,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "58ea2fa0580b2117618be6e1cc9658a5c9531dba",
            "isKey": false,
            "numCitedBy": 4094,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports the first phase of a research program on visual perception of motion patterns characteristic of living organisms in locomotion. Such motion patterns in animals and men are termed here as biological motion. They are characterized by a far higher degree of complexity than the patterns of simple mechanical motions usually studied in our laboratories. In everyday perceptions, the visual information from biological motion and from the corresponding figurative contour patterns (the shape of the body) are intermingled. A method for studying information from the motion pattern per se without interference with the form aspect was devised. In short, the motion of the living body was represented by a few bright spots describing the motions of the main joints. It is found that 10\u201312 such elements in adequate motion combinations in proximal stimulus evoke a compelling impression of human walking, running, dancing, etc. The kinetic-geometric model for visual vector analysis originally developed in the study of perception of motion combinations of the mechanical type was applied to these biological motion patterns. The validity of this model in the present context was experimentally tested and the results turned out to be highly positive."
            },
            "slug": "Visual-perception-of-biological-motion-and-a-model-Johansson",
            "title": {
                "fragments": [],
                "text": "Visual perception of biological motion and a model for its analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The kinetic-geometric model for visual vector analysis originally developed in the study of perception of motion combinations of the mechanical type was applied to biological motion patterns and the results turned out to be highly positive."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70440848"
                        ],
                        "name": "Kristine Gould",
                        "slug": "Kristine-Gould",
                        "structuredName": {
                            "firstName": "Kristine",
                            "lastName": "Gould",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristine Gould"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20465039,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "204441958131c7d828a338274e922455a2641625",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Conventional approaches to dynamic scene analysis do not use motion itself explicitly for recognition. The authors propose a different approach for the use of motion in a computer vision system which uses the motion characteristics of moving objects without actually recovering the structure. In this approach, the extended trajectories followed by the objects are considered. It is argued that in many cases, where an object has a fixed and predefined motion, the trajectory of several points may serve to uniquely identify the object. In this approach, the trajectories are analyzed at multiple scales to identify important events corresponding to discontinuities in direction, speed, and acceleration using scale space. These important events are recorded in a presentation called trajectory primal sketch. Experimental results are presented graphically, demonstrating the potential value of this approach.<<ETX>>"
            },
            "slug": "The-trajectory-primal-sketch:-a-multi-scale-scheme-Gould-Shah",
            "title": {
                "fragments": [],
                "text": "The trajectory primal sketch: a multi-scale scheme for representing motion characteristics"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A different approach is proposed for the use of motion in a computer vision system which uses the motion characteristics of moving objects without actually recovering the structure, and the extended trajectories followed by the objects are considered."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR '89: IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47656315"
                        ],
                        "name": "Dieter Koller",
                        "slug": "Dieter-Koller",
                        "structuredName": {
                            "firstName": "Dieter",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dieter Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49342756"
                        ],
                        "name": "N. Heinze",
                        "slug": "N.-Heinze",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Heinze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Heinze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144721252"
                        ],
                        "name": "H. Nagel",
                        "slug": "H.-Nagel",
                        "structuredName": {
                            "firstName": "Hans-Hellmut",
                            "lastName": "Nagel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 53
                            }
                        ],
                        "text": "This was not generalized to other motionfeatures or more sophisticated recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30763631,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96d429be5feb846bb46e8d649f023c0d54ac6e64",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Images of vehicles which move in traffic scenes recorded by a stationary camera have been detected and tracked without operator intervention. The resulting vehicle trajectories were projected from the image plane onto the street plane. A suitable system internal representation of about 90 German motion verbs was then exploited in order to automatically characterize trajectory segments in terms of natural language concepts. A multiresolution approach for feature matching has been developed which is robust enough to track vehicle images across hundreds of frames, despite considerable variations in size and projected velocity. Results from experiments with image sequences from real-world traffic scenes are presented.<<ETX>>"
            },
            "slug": "Algorithmic-characterization-of-vehicle-from-image-Koller-Heinze",
            "title": {
                "fragments": [],
                "text": "Algorithmic characterization of vehicle trajectories from image sequences by motion verbs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A multiresolution approach for feature matching has been developed which is robust enough to track vehicle images across hundreds of frames, despite considerable variations in size and projected velocity."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854767"
                        ],
                        "name": "A. Chun",
                        "slug": "A.-Chun",
                        "structuredName": {
                            "firstName": "Andy",
                            "lastName": "Chun",
                            "middleNames": [
                                "Hon",
                                "Wai"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 15
                            }
                        ],
                        "text": "A modest amount of this work ad-dresses more complicated motion recognition issues[Johansson, 1973, Cutting, 1981, Ho man and Flinch-buagh, 1982, Hildreth and Koch, 1987], but the mod-els and descriptions have typically not been imple-mented."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17365587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0252a7261a7bee036794f84bee84dea38e34f12",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the major representational problems in massively parallel or connectionist models is the difficulty of representing temporal constraints. Temporal constraints are important and crucial sources of information for event perception in general. This paper describes a novel scheme which provides massively parallel models with the ability to represent and recognize temporal constraints such as sequence and duration by exploiting link to link interactions. This relatively unexplored yet powerful mechanism is used to represent rule-like constraints and behaviors. The temporal sequence of a set of nodes is defined as the constraints or the temporal context in which these nodes should be activated. This representation is quite robust in the sense that it captures subtleties in both the strength and scope (order) of temporal constraints. Duration is also represented using a similar mechanism. The duration of a concept is represented as a memory trace of the activation of this concept. The state of this trace can be used to generate a fuzzy set like classification of the duration."
            },
            "slug": "A-Representation-for-Temporal-Sequence-and-Duration-Chun",
            "title": {
                "fragments": [],
                "text": "A Representation for Temporal Sequence and Duration in Massively Parallel Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This paper describes a novel scheme which provides massively parallel models with the ability to represent and recognize temporal constraints such as sequence and duration by exploiting link to link interactions."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31857045"
                        ],
                        "name": "E. Hildreth",
                        "slug": "E.-Hildreth",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Hildreth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hildreth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10635743,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "8feeb052c55c56769dbf4d00a25e52ccdcca4f77",
            "isKey": false,
            "numCitedBy": 321,
            "numCiting": 228,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reviews a number of aspects of visual motion analysis in biological systems from a computational perspective. We illustrate the kinds of insights that have been gained through computational studies and how these observations can be integrated with experimental studies from psychology and the neurosciences to understand the particular computations used by biological systems to analyze motion. The particular areas of motion analysis that we discuss include early motion detection and measurement, the optical flow computation, motion correspondence, the detection of motion discontinuities, and the recovery of three-dimensional structure from motion."
            },
            "slug": "The-analysis-of-visual-motion:-from-computational-Hildreth-Koch",
            "title": {
                "fragments": [],
                "text": "The analysis of visual motion: from computational theory to neuronal mechanisms."
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The kinds of insights that have been gained through computational studies are illustrated and how these observations can be integrated with experimental studies from psychology and the neurosciences to understand the particular computations used by biological systems to analyze motion."
            },
            "venue": {
                "fragments": [],
                "text": "Annual review of neuroscience"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 76
                            }
                        ],
                        "text": "Pent-land [Pentland and Mase, 1989] considered lip read-ing, and implemented a system that could recognizespoken digits with 70%-90% accuracy over 5 speak-ers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15553242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "436f38dc28ca25af965b202ebe0e27c747888da6",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a signal modeling technique based upon finite mixture autoregressive probabilistic functions of Markov chains is developed and applied to the problem of speech recognition, particularly speaker-independent recognition of isolated digits. Two types of mixture probability densities are investigated: finite mixtures of Gaussian autoregressive densities (GAM) and nearest-neighbor partitioned finite mixtures of Gaussian autoregressive densities (PGAM). In the former (GAM), the observation density in each Markov state is simply a (stochastically constrained) weighted sum of Gaussian autoregressive densities, while in the latter (PGAM) it involves nearest-neighbor decoding which in effect, defines a set of partitions on the observation space. In this paper we discuss the signal modeling methodology and give experimental results on speaker independent recognition of isolated digits. We also discuss the potential use of the modeling technique for other applications."
            },
            "slug": "Mixture-autoregressive-hidden-Markov-models-for-Juang-Rabiner",
            "title": {
                "fragments": [],
                "text": "Mixture autoregressive hidden Markov models for speech signals"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The signal modeling methodology is discussed and experimental results on speaker independent recognition of isolated digits are given and the potential use of the modeling technique for other applications are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 125
                            }
                        ],
                        "text": "Pent-land [Pentland and Mase, 1989] considered lip read-ing, and implemented a system that could recognizespoken digits with 70%-90% accuracy over 5 speak-ers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2763403,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "668087f0ae7ce1de6e0bd0965dbb480c08103260",
            "isKey": false,
            "numCitedBy": 9863,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction."
            },
            "slug": "Finding-Structure-in-Time-Elman",
            "title": {
                "fragments": [],
                "text": "Finding Structure in Time"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory and suggests a method for representing lexical categories and the type/token distinction is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2165973"
                        ],
                        "name": "J. Feldman",
                        "slug": "J.-Feldman",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Feldman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Feldman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 27
                            }
                        ],
                        "text": "A modest amount of this work ad-dresses more complicated motion recognition issues[Johansson, 1973, Cutting, 1981, Ho man and Flinch-buagh, 1982, Hildreth and Koch, 1987], but the mod-els and descriptions have typically not been imple-mented."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 68045357,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "79a7486218681b7f857649d8517c2f575f4987c8",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 149,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Time,-Space-and-Form-in-Vision-Feldman",
            "title": {
                "fragments": [],
                "text": "Time, Space and Form in Vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516142"
                        ],
                        "name": "D. Tank",
                        "slug": "D.-Tank",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tank",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 101
                            }
                        ],
                        "text": "Pent-land [Pentland and Mase, 1989] considered lip read-ing, and implemented a system that could recognizespoken digits with 70%-90% accuracy over 5 speak-ers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 203175244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e570de6e8f260804a673dcb53f13b33c13a3014",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "CONCENTRATION-INFORMATION-IN-TIME:-ANALOG-NEURAL-TO-Tank-Hopfield",
            "title": {
                "fragments": [],
                "text": "CONCENTRATION INFORMATION IN TIME: ANALOG NEURAL NETWORKS WITH APPLICATIONS TO SPEECH RECOGNITION PROBLEMS."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2345416"
                        ],
                        "name": "J. Cutting",
                        "slug": "J.-Cutting",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cutting",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cutting"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39471458,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "f93771ffefeb6110ba069d5c867b528f9262a1fd",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Six-tenets-for-event-perception-Cutting",
            "title": {
                "fragments": [],
                "text": "Six tenets for event perception"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 61
                            }
                        ],
                        "text": "We de ne temporal textures to be the motion patternsof indeterminate spatial and temporal extent, activi-ties to be motion patterns which are temporally pe-riodic but are limited in spatial extent, and motionevents to be isolated simple motions that do not ex-hibit any temporal or spatial\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Temporal texture recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of CVPR"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "LIGHTS: A System for Interpretation of Moving Light Displays"
            },
            "venue": {
                "fragments": [],
                "text": "LIGHTS: A System for Interpretation of Moving Light Displays"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Acknowledgements This work is supported by contracts NSF IRI"
            },
            "venue": {
                "fragments": [],
                "text": "Acknowledgements This work is supported by contracts NSF IRI"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Representing and recognizing event sequences"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. AAAI Workshop on Neural Architectures for Computer Vision"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 78
                            }
                        ],
                        "text": "They propose the use of theresulting trajectory primal sketch in a motion recogni-tion system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lip reading: Automatic visual recognition of spoken words"
            },
            "venue": {
                "fragments": [],
                "text": "I.T. Media Lab Vision Science"
            },
            "year": 1989
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Detecting-activities-Polana-Nelson/5f17b48014c3f3e861fcd8f5827d13ab2b5a25d1?sort=total-citations"
}