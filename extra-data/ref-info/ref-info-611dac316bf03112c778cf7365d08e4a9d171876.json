{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746034"
                        ],
                        "name": "L. Getoor",
                        "slug": "L.-Getoor",
                        "structuredName": {
                            "firstName": "Lise",
                            "lastName": "Getoor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Getoor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50785579"
                        ],
                        "name": "N. Friedman",
                        "slug": "N.-Friedman",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Friedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10551607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cc1ce96bfa2ad8af16dbd0c2356a2cb5a476c24",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Most real-world data is stored in relational form. In contrast, most statistical learning methods work with \u201cflat\u201d data representations, forcing us to convert our data into a form that loses much of the relational structure. The recently introduced framework of probabilistic relational models (PRMs) allows us to represent probabilistic models over multiple entities that utilize the relations between them. In this paper, we propose the use of probabilistic models not only for the attributes in a relational model, but for the relational structure itself. We propose two mechanisms for modeling structural uncertainty: reference uncertainty and existence uncertainty. We describe the appropriate conditions for using each model and present learning algorithms for each. We present experimental results showing that the learned models can be used to predict relational structure and, moreover, the observed relational structure can be used to provide better predictions for the attributes in the model."
            },
            "slug": "Learning-Probabilistic-Models-of-Relational-Getoor-Friedman",
            "title": {
                "fragments": [],
                "text": "Learning Probabilistic Models of Relational Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proposes the use of probabilistic models not only for the attributes in a relational model, but for the relational structure itself, and proposes two mechanisms for modeling structural uncertainty: reference uncertainty and existence uncertainty."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746034"
                        ],
                        "name": "L. Getoor",
                        "slug": "L.-Getoor",
                        "structuredName": {
                            "firstName": "Lise",
                            "lastName": "Getoor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Getoor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50785579"
                        ],
                        "name": "N. Friedman",
                        "slug": "N.-Friedman",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Friedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14657886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0680445a1a21d56189d062d42cc19529d743eb77",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Most real-world data is stored in relational form. In contrast, most statistical learning methods, e.g., Bayesian network learning, work only with \u201cflat\u201d data representations, forcing us to convert our data into a form that loses much of the relational structure. The recently introduced framework of probabilistic relational models(PRMs) allow us to represent much richer dependency structures, involving multiple entities and the relations between them; they allow the properties of an entity to depend probabilistically on properties of related entities. Friedman et al. showed how to learn PRMs that model the attribute uncertainty in relational data, and presented techniques for learning both parameters and probabilistic dependency structure for the attributes in a relational model. In this work, we propose methods for handling structural uncertainty in PRMs. Structural uncertainty is uncertainty over which entities are related in our domain. We propose two mechanisms for modeling structural uncertainty: reference uncertaintyand existence uncertainty. We describe the appropriate conditions for using each model and present learning algorithms for each. We conclude with some preliminary experimental results comparing and contrasting the use of these mechanism for learning PRMs in domains with structural uncertainty."
            },
            "slug": "Learning-Probabilistic-Relational-Models-with-Getoor-Koller",
            "title": {
                "fragments": [],
                "text": "Learning Probabilistic Relational Models with Structural Uncertainty"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes two mechanisms for modeling structural uncertainty in PRMs: reference uncertainty and existence uncertainty, and describes the appropriate conditions for using each model and present learning algorithms for each."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46197142"
                        ],
                        "name": "D. Schmidt",
                        "slug": "D.-Schmidt",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Schmidt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Schmidt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 11
                            }
                        ],
                        "text": "Following [Friedman et al., 1999], which examines a similar approach in the context of learning Bayesian networks, we propose an iterative approach that starts with some structure (possibly one where each attribute does not have any parents), and select the sets Pot 7 ^ _ based on this structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 32
                            }
                        ],
                        "text": "Some of these are discussed in [Friedman et al., 1999] in the context of learning Bayesian networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61077853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "651ab8b629a190f42ac036d2e8e9a68448b2c2c4",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic relational models (PRMs) are a language for describing statistical models over typed relational domains. A PRM models the uncertainty over the attributes of objects in the domain and uncertainty over the relations between the objects. The model specifies, for each attribute of an object, its (probabilistic) dependence on other attributes of that object and on attributes of related objects. The dependence model is defined at the level of classes of objects. The class dependence model is instantiated for any object in the class, as appropriate to the particular context of the object (i.e., the relations between this objects and others). PRMs can also represent uncertainty over the relational structure itself, e.g., by specifying a (class-level) probability that two objects will be related to each other. PRMs provide a foundation for dealing with the noise and uncertainty encountered in most real-world domains. In this chapter, we show that the compact and natural representation of PRMs allows them to be learned directly form an existing relational database using well-founded statistical techniques. We give an introduction to PRMs and an overview of methods for learning them. We show that PRMs provide a new framework for relational data mining, and offer new challenges for the endeavor of learning relational models for real-world domains."
            },
            "slug": "Learning-probabilistic-relational-models-Schmidt",
            "title": {
                "fragments": [],
                "text": "Learning probabilistic relational models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This chapter shows that the compact and natural representation of PRMs allows them to be learned directly form an existing relational database using well-founded statistical techniques and offers new challenges for the endeavor of learning relational models for real-world domains."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145668856"
                        ],
                        "name": "A. Pfeffer",
                        "slug": "A.-Pfeffer",
                        "structuredName": {
                            "firstName": "Avi",
                            "lastName": "Pfeffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pfeffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13072151,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da94000d2def6235ab60b88a6da31876bc6c5fc3",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "First-order logic is the traditional basis for knowledge representation languages. However, its applicability to many real-world tasks is limited by its inability to represent uncertainty. Bayesian belief networks, on the other hand, are inadequate for complex KR tasks due to the limited expressivity of the underlying (prepositional) language. The need to incorporate uncertainty into an expressive language has led to a resurgence of work on first-order probabilistic Logic. This paper addresses one of the main objections to the incorporation of probabilities into the language: \"Where do the numbers come from?\" We present an approach that takes a knowledge base in an expressive rule-based first-order language, and leams the probabilistic parameters associated with those rules from data cases. Our approach, which is based on algorithms for learning in traditional Bayesian networks, can handle data cases where many of the relevant aspects of the situation are unobserved. It is also capable of utilizing a rich variety of data cases, including instances with varying causal structure, and even involving a varying number of individuals. These features allow the approach to be used for a wide range of tasks, such as learning genetic propagation models or learning first-order STRIPS planning operators with uncertain effects."
            },
            "slug": "Learning-Probabilities-for-Noisy-First-Order-Rules-Koller-Pfeffer",
            "title": {
                "fragments": [],
                "text": "Learning Probabilities for Noisy First-Order Rules"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An approach that takes a knowledge base in an expressive rule-based first-order language, and leams the probabilistic parameters associated with those rules from data cases, and can handle data cases where many of the relevant aspects of the situation are unobserved."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50785579"
                        ],
                        "name": "N. Friedman",
                        "slug": "N.-Friedman",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Friedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2402326"
                        ],
                        "name": "I. Nachman",
                        "slug": "I.-Nachman",
                        "structuredName": {
                            "firstName": "Iftach",
                            "lastName": "Nachman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Nachman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397424343"
                        ],
                        "name": "D. Pe\u2019er",
                        "slug": "D.-Pe\u2019er",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Pe\u2019er",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pe\u2019er"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 11
                            }
                        ],
                        "text": "Following [Friedman et al., 1999], which examines a similar approach in the context of learning Bayesian networks, we propose an iterative approach that starts with some structure (possibly one where each attribute does not have any parents), and select the sets Pot 7 ^ _ based on this structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 32
                            }
                        ],
                        "text": "Some of these are discussed in [Friedman et al., 1999] in the context of learning Bayesian networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6268910,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "863a5e02d003dfc3bffc2484ae3ff665ba8a21a9",
            "isKey": false,
            "numCitedBy": 629,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning Bayesian networks is often cast as an optimization problem, where the computational task is to find a structure that maximizes a statistically motivated score. By and large, existing learning tools address this optimization problem using standard heuristic search techniques. Since the search space is extremely large, such search procedures can spend most of the time examining candidates that are extremely unreasonable. This problem becomes critical when we deal with data sets that are large either in the number of instances, or the number of attributes. \n \nIn this paper. we introduce an algorithm that achieves faster learning by restricting the search space. This iterative algorithm restricts the parents of each variable to belong to a small subset of candidates. We then search for a network that satisfies these constraints. The learned network is then used for selecting better candidates for the next iteration. We evaluate this algorithm both on synthetic and real-life data. Our results show that it is significantly faster than alternative search procedures without loss of quality in the learned structures"
            },
            "slug": "Learning-Bayesian-Network-Structure-from-Massive-Friedman-Nachman",
            "title": {
                "fragments": [],
                "text": "Learning Bayesian Network Structure from Massive Datasets: The \"Sparse Candidate\" Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An algorithm that achieves faster learning by restricting the search space, which restricts the parents of each variable to belong to a small subset of candidates and is evaluated both on synthetic and real-life data."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144557047"
                        ],
                        "name": "M. Craven",
                        "slug": "M.-Craven",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Craven",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Craven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2922396"
                        ],
                        "name": "Dan DiPasquo",
                        "slug": "Dan-DiPasquo",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "DiPasquo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan DiPasquo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682522"
                        ],
                        "name": "Se\u00e1n Slattery",
                        "slug": "Se\u00e1n-Slattery",
                        "structuredName": {
                            "firstName": "Se\u00e1n",
                            "lastName": "Slattery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Se\u00e1n Slattery"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 180
                            }
                        ],
                        "text": "In another case, we may be interested in classifying web pages as belonging to a student, a faculty member, a project, etc., using attributes of the web page and of related pages [Craven et al., 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2312137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8446830f3c05b97c4d12a0751c022d1ae6a5115b",
            "isKey": false,
            "numCitedBy": 800,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "The World Wide Web is a vast source of information accessible to computers, but understandable only to humans. The goal of the research described here is to automatically create a computer understandable world wide knowledge base whose content mirrors that of the World Wide Web. Such a knowledge base would enable much more effective retrieval of Web information, and promote new uses of the Web to support knowledge-based inference and problem solving. Our approach is to develop a trainable information extraction system that takes two inputs: an ontology defining the classes and relations of interest, and a set of training data consisting of labeled regions of hypertext representing instances of these classes and relations. Given these inputs, the system learns to extract information from other pages and hyperlinks on the Web. This paper describes our general approach, several machine learning algorithms for this task, and promising initial results with a prototype system."
            },
            "slug": "Learning-to-Extract-Symbolic-Knowledge-from-the-Web-Craven-DiPasquo",
            "title": {
                "fragments": [],
                "text": "Learning to Extract Symbolic Knowledge from the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The goal of the research described here is to automatically create a computer understandable world wide knowledge base whose content mirrors that of the World Wide Web, and several machine learning algorithms for this task are described."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144594306"
                        ],
                        "name": "Wai Lam",
                        "slug": "Wai-Lam",
                        "structuredName": {
                            "firstName": "Wai",
                            "lastName": "Lam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wai Lam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736882"
                        ],
                        "name": "F. Bacchus",
                        "slug": "F.-Bacchus",
                        "structuredName": {
                            "firstName": "Fahiem",
                            "lastName": "Bacchus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bacchus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This work has as a starting point the framework of Probabilistic Relational Models, introduced in [5, 7]. We adapt and extend the machinery that has been developed over the years for learning Bayesian networks from data [1, 4,  6 ] to the task of learning PRMs from structured data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 622909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3ada89151b8f2582f48dd2c086f56727f4693fd",
            "isKey": false,
            "numCitedBy": 861,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "A new approach for learning Bayesian belief networks from raw data is presented. The approach is based on Rissanen's minimal description length (MDL) principle, which is particularly well suited for this task. Our approach does not require any prior assumptions about the distribution being learned. In particular, our method can learn unrestricted multiply\u2010connected belief networks. Furthermore, unlike other approaches our method allows us to trade off accuracy and complexity in the learned model. This is important since if the learned model is very complex (highly connected) it can be conceptually and computationally intractable. In such a case it would be preferable to use a simpler model even if it is less accurate. The MDL principle offers a reasoned method for making this trade\u2010off. We also show that our method generalizes previous approaches based on Kullback cross\u2010entropy. Experiments have been conducted to demonstrate the feasibility of the approach."
            },
            "slug": "LEARNING-BAYESIAN-BELIEF-NETWORKS:-AN-APPROACH-ON-Lam-Bacchus",
            "title": {
                "fragments": [],
                "text": "LEARNING BAYESIAN BELIEF NETWORKS: AN APPROACH BASED ON THE MDL PRINCIPLE"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A new approach for learning Bayesian belief networks from raw data is presented, based on Rissanen's minimal description length (MDL) principle, which can learn unrestricted multiply\u2010connected belief networks and allows for trade off accuracy and complexity in the learned model."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724065"
                        ],
                        "name": "D. M. Chickering",
                        "slug": "D.-M.-Chickering",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chickering",
                            "middleNames": [
                                "Maxwell"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Chickering"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 58
                            }
                        ],
                        "text": "For Bayesian networks, we know that this task is NP-Hard [Chickering, 1996]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14226732,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fb874a1c8106a5b2b2779ee8e1433149109ba00",
            "isKey": false,
            "numCitedBy": 1055,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms for learning Bayesian networks from data have two components: a scoring metric and a search procedure. The scoring metric computes a score reflecting the goodness-of-fit of the structure to the data. The search procedure tries to identify network structures with high scores. Heckerman et al. (1995) introduce a Bayesian metric, called the BDe metric, that computes the relative posterior probability of a network structure given data. In this paper, we show that the search problem of identifying a Bayesian network\u2014among those where each node has at most K parents\u2014that has a relative posterior probability greater than a given constant is NP-complete, when the BDe metric is used."
            },
            "slug": "Learning-Bayesian-Networks-is-NP-Complete-Chickering",
            "title": {
                "fragments": [],
                "text": "Learning Bayesian Networks is NP-Complete"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that the search problem of identifying a Bayesian network\u2014among those where each node has at most K parents\u2014that has a relative posterior probability greater than a given constant is NP-complete, when the BDe metric is used."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145668856"
                        ],
                        "name": "A. Pfeffer",
                        "slug": "A.-Pfeffer",
                        "structuredName": {
                            "firstName": "Avi",
                            "lastName": "Pfeffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pfeffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15856377,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b97ec7b4f8b3cd921bd44b962be00dbb199499be",
            "isKey": false,
            "numCitedBy": 360,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Two of the most important threads of work in knowledge representation today are frame-based representation systems (FRS's) and Bayesian networks (BNs). FRS's provide an excellent representation for the organizational structure of large complex domains, but their applicability is limited because of their inability to deal with uncertainty and noise. BNs provide an intuitive and coherent probabilistic representation of our uncertainty, but are very limited in their ability to handle complex structured domains. In this paper, we provide a language that cleanly integrates these approaches, preserving the advantages of both. Our approach allows us to provide natural and compact definitions of probability models for a class, in a way that is local to the class frame. These models can be instantiated for any set of interconnected instances, resulting in a coherent probability distribution over the instance properties. Our language also allows us to represent important types of uncertainty that cannot be accomodated within the framework of traditional BNs: uncertainty over the set of entities present in our model, and uncertainty about the relationships between these entities. We provide an inference algorithm for our language via a reduction to inference in standard Bayesian networks. We describe an implemented system that allows most of the main frame systems in existence today to annotate their knowledge bases with probabilistic information, and to use that information in answering probabilistic queries."
            },
            "slug": "Probabilistic-Frame-Based-Systems-Koller-Pfeffer",
            "title": {
                "fragments": [],
                "text": "Probabilistic Frame-Based Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper provides a language that cleanly integrates frame-based representation systems and Bayesian networks, and describes an implemented system that allows most of the main frame systems in existence today to annotate their knowledge bases with Probabilistic information, and to use that information in answering probabilistic queries."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51987873"
                        ],
                        "name": "A. Pfeffer",
                        "slug": "A.-Pfeffer",
                        "structuredName": {
                            "firstName": "Avrom",
                            "lastName": "Pfeffer",
                            "middleNames": [
                                "Jacob"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pfeffer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This work has as a starting point the framework of Probabilistic Relational Models, introduced in [5,  7 ]. We adapt and extend the machinery that has been developed over the years for learning Bayesian networks from data [1, 4, 6] to the task of learning PRMs from structured data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53752318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8bdbd6b5d35285b92f816990963e20e99888f661",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Reasoning under uncertainty is a central issue in artificial intelligence. Real-world agents must deal with noisy sensor information, non-deterministic effects of actions, and unpredictable exogenous events. Probabilistic reasoning methods, and Bayesian networks (BNs) in particular, have emerged as an effective and principled method for reasoning under uncertainty. BNs exploit conditional independence relationships to create natural and compact domain models, thereby supporting useful reasoning patterns, and providing effective probabilistic inference and learning algorithms. However, BNs are inherently limited by their attribute-based nature, making it difficult to apply them to large, complex domains. \nThis thesis addresses the issue of representing and reasoning about probabilistic models of complex systems. We believe that the key to reasoning effectively about complex systems is to provide a language that supports the expression of system structure. We present a powerful object-based representation language, that integrates logical and probabilistic representations. Our language provides the ability to create structured, modular probabilistic models. The language maintains the key advantages of BNs, exploiting conditional independence relationships. In addition, it is capable of representing other aspects of system structure not represented in BNs. In particular, it supports the decomposition of complex systems into weakly interacting subsystems, and the reuse of models for many different components of a system. \nAnother key benefit of our language is that it is very flexible. The same probabilistic representations can be applied in many different situations, with very different configurations. In fact, our language can even represent uncertainty over the system configuration itself, and integrate that uncertainty directly with uncertainty over the basic properties of objects in the system. Our framework also supports the representation of powerful recursive probability models. \nWe present inference algorithms for our language that exploit the structure that can be expressed in it\u2014not only the conditional independence structure normally exploited by BN algorithms, but also encapsulation, reuse of computation and symmetry resulting from the object-based representation. We describe an implemented system that supports representation and reasoning with models in our language, and provide experimental results demonstrating the advantages of exploiting structure in inference."
            },
            "slug": "Probabilistic-reasoning-for-complex-systems-Koller-Pfeffer",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning for complex systems"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This thesis presents a powerful object-based representation language, that integrates logical and probabilistic representations, and presents inference algorithms for the language that exploit the structure that can be expressed in it\u2014not only the conditional independence structure normally exploited by BN algorithms, but also encapsulation, reuse of computation and symmetry resulting from the object- based representation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50785579"
                        ],
                        "name": "N. Friedman",
                        "slug": "N.-Friedman",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Friedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1495878,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bfd1c958b525fdeee6c7efaa3becc42072c75a72",
            "isKey": false,
            "numCitedBy": 496,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years there has been a flurry of works on learning probabilistic belief networks. Current state of the art methods have been shown to be successful for two learning scenarios: learning both network structure and parameters from complete data, and learning parameters for a fixed network from incomplete data\u2014that is, in the presence of missing values or hidden variables. However, no method has yet been demonstrated to effectively learn network structure from incomplete data. In this paper, we propose a new method for learning network structure from incomplete data. This method is based on an extension of the Expectation-Maximization (EM) algorithm for model selection problems that performs search for the best structure inside the EM procedure. We prove the convergence of this algorithm, and adapt it for learning belief networks. We then describe how to learn networks in two scenarios: when the data contains missing values, and in the presence of hidden variables. We provide experimental results that show the effectiveness of our procedure in both scenarios."
            },
            "slug": "Learning-Belief-Networks-in-the-Presence-of-Missing-Friedman",
            "title": {
                "fragments": [],
                "text": "Learning Belief Networks in the Presence of Missing Values and Hidden Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a new method for learning network structure from incomplete data based on an extension of the Expectation-Maximization (EM) algorithm for model selection problems that performs search for the best structure inside the EM procedure."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065321832"
                        ],
                        "name": "L. Ngo",
                        "slug": "L.-Ngo",
                        "structuredName": {
                            "firstName": "Liem",
                            "lastName": "Ngo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ngo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681109"
                        ],
                        "name": "P. Haddawy",
                        "slug": "P.-Haddawy",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Haddawy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haddawy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16211249,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a59ce04b6a0d923cd60dc1c16b6b7d99a60bffb",
            "isKey": false,
            "numCitedBy": 199,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Answering-Queries-from-Context-Sensitive-Knowledge-Ngo-Haddawy",
            "title": {
                "fragments": [],
                "text": "Answering Queries from Context-Sensitive Probabilistic Knowledge Bases"
            },
            "venue": {
                "fragments": [],
                "text": "Theor. Comput. Sci."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778725"
                        ],
                        "name": "J. Breese",
                        "slug": "J.-Breese",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Breese",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Breese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772349"
                        ],
                        "name": "C. Kadie",
                        "slug": "C.-Kadie",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Kadie",
                            "middleNames": [
                                "Myers"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kadie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2885948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36b4a92c8eca6fd6d1b8588fc1fd0e3f89a16623",
            "isKey": false,
            "numCitedBy": 5604,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Collaborative filtering or recommender systems use a database about user preferences to predict additional topics or products a new user might like. In this paper we describe several algorithms designed for this task, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods. We compare the predictive accuracy of the various methods in a set of representative problem domains. We use two basic classes of evaluation metrics. The first characterizes accuracy over a set of individual predictions in terms of average absolute deviation. The second estimates the utility of a ranked list of suggested items. This metric uses an estimate of the probability that a user will see a recommendation in an ordered list. \n \nExperiments were run for datasets associated with 3 application areas, 4 experimental protocols, and the 2 evaluation metr rics for the various algorithms. Results indicate that for a wide range of conditions, Bayesian networks with decision trees at each node and correlation methods outperform Bayesian-clustering and vector-similarity methods. Between correlation and Bayesian networks, the preferred method depends on the nature of the dataset, nature of the application (ranked versus one-by-one presentation), and the availability of votes with which to make predictions. Other considerations include the size of database, speed of predictions, and learning time."
            },
            "slug": "Empirical-Analysis-of-Predictive-Algorithms-for-Breese-Heckerman",
            "title": {
                "fragments": [],
                "text": "Empirical Analysis of Predictive Algorithms for Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Several algorithms designed for collaborative filtering or recommender systems are described, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods, to compare the predictive accuracy of the various methods in a set of representative problem domains."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726406"
                        ],
                        "name": "G. Cooper",
                        "slug": "G.-Cooper",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Cooper",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cooper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43363498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed5324bb3a19f0dcc2e90e482c06373b934fc28c",
            "isKey": false,
            "numCitedBy": 2047,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Computational-Complexity-of-Probabilistic-Using-Cooper",
            "title": {
                "fragments": [],
                "text": "The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145147566"
                        ],
                        "name": "S. Muggleton",
                        "slug": "S.-Muggleton",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Muggleton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Muggleton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18138316,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "487f444c7a0ae2492df641a7220eb60172be9837",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic Logic Programs (SLPs) have been shown be a generalisation of Hidden Markov Models (HMMs), stochastic context-free grammars, and directed Bayes\u2019 nets. A stochastic logic program consists of a set of labelled clauses p:C where p is in the interval [0,1] and C is a first-order range-restricted definite clause. This paper summarises the syntax, distributional semantics and proof techniques for SLPs and then discusses how a standard Inductive Logic Programming (ILP) system, Progol, has been modified to support learning of SLPs. The resulting system 1) finds an SLP with uniform probability labels on each definition and near-maximal Bayes posterior probability and then 2) alters the probability labels to further increase the posterior probability. Stage 1) is implemented within CProgol4.5, which differs from previous versions of Progol by allowing user-defined evaluation functions written in Prolog. It is shown that maximising the Bayesian posterior function involves finding SLPs with short derivations of the examples. Search pruning with the Bayesian evaluation function is carried out in the same way as in previous versions of CProgol. The system is demonstrated with worked examples involving the learning of probability distributions over sequences as well as the learning of simple forms of uncertain knowledge."
            },
            "slug": "Learning-Stochastic-Logic-Programs-Muggleton",
            "title": {
                "fragments": [],
                "text": "Learning Stochastic Logic Programs"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper discusses how a standard Inductive Logic Programming (ILP) system, Progol, has been modified to support learning of SLPs and shows that maximising the Bayesian posterior function involves finding SLPs with short derivations of the examples."
            },
            "venue": {
                "fragments": [],
                "text": "Electron. Trans. Artif. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744430"
                        ],
                        "name": "J. Cussens",
                        "slug": "J.-Cussens",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cussens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cussens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1816018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "555bbd43bc82725a96e029f79db8d4d003721dbb",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work on loglinear models in probabilistic constraint logic programming is applied to first-order probabilistic reasoning. Probabilities are defined directly on the proofs of atomic formulae, and by marginalisation on the atomic formulae themselves. We use Stochastic Logic Programs (SLPs) composed of labelled and unlabelled definite clauses to define the proof probabilities. We have a conservative extension of first-order reasoning, so that, for example, there is a one-one mapping between logical and random variables. We show how, in this framework, Inductive Logic Programming (ILP) can be used to induce the features of a loglinear model from data. We also compare the presented framework with other approaches to first-order probabilistic reasoning."
            },
            "slug": "Loglinear-models-for-first-order-probabilistic-Cussens",
            "title": {
                "fragments": [],
                "text": "Loglinear models for first-order probabilistic reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work shows how, in this framework, Inductive Logic Programming (ILP) can be used to induce the features of a loglinear model from data and compares the presented framework with other approaches to first-order probabilistic reasoning."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796536"
                        ],
                        "name": "Michael P. Wellman",
                        "slug": "Michael-P.-Wellman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wellman",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael P. Wellman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778725"
                        ],
                        "name": "J. Breese",
                        "slug": "J.-Breese",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Breese",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Breese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2473054"
                        ],
                        "name": "R. Goldman",
                        "slug": "R.-Goldman",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Goldman",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Goldman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 85
                            }
                        ],
                        "text": "This construction is reminiscent of the knowledge-based model construction approach [Wellman et al., 1992]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6385392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8089729d8711b3ef0de37eb6016ca3a311b491b5",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years there has been a growing interest among AI researchers in probabilistic and decision modelling, spurred by significant advances in representation and computation with network modelling formalisms. In applying these techniques to decision support tasks, fixed network models have proven to be inadequately expressive when a broad range of situations must be handled. Hence many researchers have sought to combine the strengths of flexible knowledge representation languages with the normative status and well-understood computational properties of decision-modelling formalisms and algorithms. One approach is to encode general knowledge in an expressive language, then dynamically construct a decision model for each particular situation or problem instance. We have developed several systems adopting this approach, which illustrate a variety of interesting techniques and design issues."
            },
            "slug": "From-knowledge-bases-to-decision-models-Wellman-Breese",
            "title": {
                "fragments": [],
                "text": "From knowledge bases to decision models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Several systems adopting this approach to encode general knowledge in an expressive language, then dynamically construct a decision model for each particular situation or problem instance are developed."
            },
            "venue": {
                "fragments": [],
                "text": "Knowl. Eng. Rev."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143648560"
                        ],
                        "name": "P. Spirtes",
                        "slug": "P.-Spirtes",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Spirtes",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Spirtes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3058012"
                        ],
                        "name": "C. Glymour",
                        "slug": "C.-Glymour",
                        "structuredName": {
                            "firstName": "Clark",
                            "lastName": "Glymour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Glymour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2758080"
                        ],
                        "name": "R. Scheines",
                        "slug": "R.-Scheines",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Scheines",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Scheines"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 117765107,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b3b9fe128e6849d59a26d7ceda57baad2524815",
            "isKey": false,
            "numCitedBy": 3255,
            "numCiting": 154,
            "paperAbstract": {
                "fragments": [],
                "text": "What assumptions and methods allow us to turn observations into causal knowledge, and how can even incomplete causal knowledge be used in planning and prediction to influence and control our environment? In this book Peter Spirtes, Clark Glymour, and Richard Scheines address these questions using the formalism of Bayes networks, with results that have been applied in diverse areas of research in the social, behavioral, and physical sciences. The authors show that although experimental and observational study designs may not always permit the same inferences, they are subject to uniform principles. They axiomatize the connection between causal structure and probabilistic independence, explore several varieties of causal indistinguishability, formulate a theory of manipulation, and develop asymptotically reliable procedures for searching over equivalence classes of causal models, including models of categorical data and structural equation models with and without latent variables. The authors show that the relationship between causality and probability can also help to clarify such diverse topics in statistics as the comparative power of experimentation versus observation, Simpson's paradox, errors in regression models, retrospective versus prospective sampling, and variable selection. The second edition contains a new introduction and an extensive survey of advances and applications that have appeared since the first edition was published in 1993."
            },
            "slug": "Causation,-prediction,-and-search-Spirtes-Glymour",
            "title": {
                "fragments": [],
                "text": "Causation, prediction, and search"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The authors axiomatize the connection between causal structure and probabilistic independence, explore several varieties of causal indistinguishability, formulate a theory of manipulation, and develop asymptotically reliable procedures for searching over equivalence classes of causal models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 218
                            }
                        ],
                        "text": "There are some preliminary answers to this question in the context of Bayesian networks [Friedman, 1997], in the context of ILP [Lavrac\u0306 and Dz\u0306eroski, 1994], and very recently in the context of simple binary relations [Hofmann et al., 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1312504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ad58ea541efaec494ea1ec6a5414ea01e236b04",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Dyadzc data refers to a domain with two finite sets of objects in which observations are made for dyads, i.e., pairs with one element from either set. This type of data arises naturally in many application ranging from computational linguistics and information retrieval to preference analysis and computer vision. In this paper, we present a systematic, domain-independent framework of learning from dyadic data by statistical mixture models. Our approach covers different models with fiat and hierarchical latent class structures. We propose an annealed version of the standard EM algorithm for model fitting which is empirically evaluated on a variety of data sets from different domains."
            },
            "slug": "Learning-from-Dyadic-Data-Hofmann-Puzicha",
            "title": {
                "fragments": [],
                "text": "Learning from Dyadic Data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes an annealed version of the standard EM algorithm for model fitting which is empirically evaluated on a variety of data sets from different domains."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143715817"
                        ],
                        "name": "D. Poole",
                        "slug": "D.-Poole",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Poole",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Poole"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11707680,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9ef7893ae7ee6826a43b5f58365092194c0e213",
            "isKey": false,
            "numCitedBy": 644,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-Horn-Abduction-and-Bayesian-Networks-Poole",
            "title": {
                "fragments": [],
                "text": "Probabilistic Horn Abduction and Bayesian Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746871"
                        ],
                        "name": "K. Kersting",
                        "slug": "K.-Kersting",
                        "structuredName": {
                            "firstName": "Kristian",
                            "lastName": "Kersting",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kersting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740042"
                        ],
                        "name": "L. D. Raedt",
                        "slug": "L.-D.-Raedt",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Raedt",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Raedt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145471896"
                        ],
                        "name": "Stefan Kramer",
                        "slug": "Stefan-Kramer",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Kramer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Kramer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118721718,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a704ae87c81d0dd4107d554751f34c6b75b33256",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Various proposals for combining first order logic with Bayesian nets exist. We introduce the formalism of Bayesian logic programs, which is basically a simplification and reformulation of Ngo and Haddawys probabilistic logic programs. However, Bayesian logic programs are sufficiently powerful to represent essentially the same knowledge in a more elegant manner. The elegance is illustrated by the fact that they can represent both Bayesian nets and definite clause programs (as in \"pure\" Prolog) and that their kernel in Prolog is actually an adaptation of an usual Prolog meta-interpreter."
            },
            "slug": "Interpreting-Bayesian-Logic-Programs-Kersting-Raedt",
            "title": {
                "fragments": [],
                "text": "Interpreting Bayesian Logic Programs"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The formalism of Bayesian logic programs is introduced, which is basically a simplification and reformulation of Ngo and Haddawys probabilistic logic programs to represent essentially the same knowledge in a more elegant manner."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122985977,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "2e67c0312b81b698834315ea33f8a23be6eed6eb",
            "isKey": false,
            "numCitedBy": 765,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-EM-algorithm-for-graphical-association-models-Lauritzen",
            "title": {
                "fragments": [],
                "text": "The EM algorithm for graphical association models with missing data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730104"
                        ],
                        "name": "N. Lavrac",
                        "slug": "N.-Lavrac",
                        "structuredName": {
                            "firstName": "Nada",
                            "lastName": "Lavrac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lavrac"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693549"
                        ],
                        "name": "S. D\u017eeroski",
                        "slug": "S.-D\u017eeroski",
                        "structuredName": {
                            "firstName": "Sa\u0161o",
                            "lastName": "D\u017eeroski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D\u017eeroski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36237350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58095bae1d836943bdaa52b76fa8d17cf77d06b3",
            "isKey": false,
            "numCitedBy": 931,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 Empirical inductive logic programming: introduction empirical ILP systems - an overview LINUS - using attribute-value learners in an ILP framework experiments in learning relations with LINUS ILP as search for program clauses. Part 2 Learning relations from imperfect data: handling imperfect data in ILP using heuristics to handle noise in ILP mFOIL - extending noise-handling in FOIL experiments in learning relations from noisy examples. Part 3 Applications of inductive logic programming: learning rules for early diagnosis of rheumatic diseases finite element mesh design an overview of selected ILP applications."
            },
            "slug": "Inductive-logic-programming-techniques-and-Lavrac-D\u017eeroski",
            "title": {
                "fragments": [],
                "text": "Inductive logic programming - techniques and applications"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Applications of inductive logic programming: learning rules for early diagnosis of rheumatic diseases finite element mesh design an overview of selected ILP applications."
            },
            "venue": {
                "fragments": [],
                "text": "Ellis Horwood series in artificial intelligence"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39416713"
                        ],
                        "name": "M. Degroot",
                        "slug": "M.-Degroot",
                        "structuredName": {
                            "firstName": "Morris",
                            "lastName": "Degroot",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Degroot"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We must determine which dependency structures are legal; we need to evaluate the \u201cgoodness\u201d of different candidate structures; and we need to define an effective search procedure that finds a good structure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 23
                            }
                        ],
                        "text": "(For more details see [DeGroot, 1970].)"
                    },
                    "intents": []
                }
            ],
            "corpusId": 119884967,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "81c8a5823de21d98ea395081cbfe647bfb456cd6",
            "isKey": false,
            "numCitedBy": 4236,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Foreword.Preface.PART ONE. SURVEY OF PROBABILITY THEORY.Chapter 1. Introduction.Chapter 2. Experiments, Sample Spaces, and Probability.2.1 Experiments and Sample Spaces.2.2 Set Theory.2.3 Events and Probability.2.4 Conditional Probability.2.5 Binomial Coefficients.Exercises.Chapter 3. Random Variables, Random Vectors, and Distributions Functions.3.1 Random Variables and Their Distributions.3.2 Multivariate Distributions.3.3 Sums and Integrals.3.4 Marginal Distributions and Independence.3.5 Vectors and Matrices.3.6 Expectations, Moments, and Characteristic Functions.3.7 Transformations of Random Variables.3.8 Conditional Distributions.Exercises.Chapter 4. Some Special Univariate Distributions.4.1 Introduction.4.2 The Bernoulli Distributions.4.3 The Binomial Distribution.4.4 The Poisson Distribution.4.5 The Negative Binomial Distribution.4.6 The Hypergeometric Distribution.4.7 The Normal Distribution.4.8 The Gamma Distribution.4.9 The Beta Distribution.4.10 The Uniform Distribution.4.11 The Pareto Distribution.4.12 The t Distribution.4.13 The F Distribution.Exercises.Chapter 5. Some Special Multivariate Distributions.5.1 Introduction.5.2 The Multinomial Distribution.5.3 The Dirichlet Distribution.5.4 The Multivariate Normal Distribution.5.5 The Wishart Distribution.5.6 The Multivariate t Distribution.5.7 The Bilateral Bivariate Pareto Distribution.Exercises.PART TWO. SUBJECTIVE PROBABILITY AND UTILITY.Chapter 6. Subjective Probability.6.1 Introduction.6.2 Relative Likelihood.6.3 The Auxiliary Experiment.6.4 Construction of the Probability Distribution.6.5 Verification of the Properties of a Probability Distribution.6.6 Conditional Likelihoods.Exercises.Chapter 7. Utility.7.1 Preferences Among Rewards.7.2 Preferences Among Probability Distributions.7.3 The Definitions of a Utility Function.7.4 Some Properties of Utility Functions.7.5 The Utility of Monetary Rewards.7.6 Convex and Concave Utility Functions.7.7 The Anxiomatic Development of Utility.7.8 Construction of the Utility Function.7.9 Verification of the Properties of a Utility Function.7.10 Extension of the Properties of a Utility Function to the Class ?E.Exercises.PART THREE. STATISTICAL DECISION PROBLEMS.Chapter 8. Decision Problems.8.1 Elements of a Decision Problem.8.2 Bayes Risk and Bayes Decisions.8.3 Nonnegative Loss Functions.8.4 Concavity of the Bayes Risk.8.5 Randomization and Mixed Decisions.8.6 Convex Sets.8.7 Decision Problems in Which ~2 and D Are Finite.8.8 Decision Problems with Observations.8.9 Construction of Bayes Decision Functions.8.10 The Cost of Observation.8.11 Statistical Decision Problems in Which Both ? and D contains Two Points.8.12 Computation of the Posterior Distribution When the Observations Are Made in More Than One Stage.Exercises.Chapter 9. Conjugate Prior Distributions.9.1 Sufficient Statistics.9.2 Conjugate Families of Distributions.9.3 Construction of the Conjugate Family.9.4 Conjugate Families for Samples from Various Standard Distributions.9.5 Conjugate Families for Samples from a Normal Distribution.9.6 Sampling from a Normal Distribution with Unknown Mean and Unknown Precision.9.7 Sampling from a Uniform Distribution.9.8 A Conjugate Family for Multinomial Observations.9.9 Conjugate Families for Samples from a Multivariate Normal Distribution.9.10 Multivariate Normal Distributions with Unknown Mean Vector and Unknown Precision matrix.9.11 The Marginal Distribution of the Mean Vector.9.12 The Distribution of a Correlation.9.13 Precision Matrices Having an Unknown Factor.Exercises.Chapter 10. Limiting Posterior Distributions.10.1 Improper Prior Distributions.10.2 Improper Prior Distributions for Samples from a Normal Distribution.10.3 Improper Prior Distributions for Samples from a Multivariate Normal Distribution.10.4 Precise Measurement.10.5 Convergence of Posterior Distributions.10.6 Supercontinuity.10.7 Solutions of the Likelihood Equation.10.8 Convergence of Supercontinuous Functions.10.9 Limiting Properties of the Likelihood Function.10.10 Normal Approximation to the Posterior Distribution.10.11 Approximation for Vector Parameters.10.12 Posterior Ratios.Exercises.Chapter 11. Estimation, Testing Hypotheses, and linear Statistical Models.11.1 Estimation.11.2 Quadratic Loss.11.3 Loss Proportional to the Absolute Value of the Error.11.4 Estimation of a Vector.11.5 Problems of Testing Hypotheses.11.6 Testing a Simple Hypothesis About the Mean of a Normal Distribution.11.7 Testing Hypotheses about the Mean of a Normal Distribution.11.8 Deciding Whether a Parameter Is Smaller or larger Than a Specific Value.11.9 Deciding Whether the Mean of a Normal Distribution Is Smaller or larger Than a Specific Value.11.10 Linear Models.11.11 Testing Hypotheses in Linear Models.11.12 Investigating the Hypothesis That Certain Regression Coefficients Vanish.11.13 One-Way Analysis of Variance.Exercises.PART FOUR. SEQUENTIAL DECISIONS.Chapter 12. Sequential Sampling.12.1 Gains from Sequential Sampling.12.2 Sequential Decision Procedures.12.3 The Risk of a Sequential Decision Procedure.12.4 Backward Induction.12.5 Optimal Bounded Sequential Decision procedures.12.6 Illustrative Examples.12.7 Unbounded Sequential Decision Procedures.12.8 Regular Sequential Decision Procedures.12.9 Existence of an Optimal Procedure.12.10 Approximating an Optimal Procedure by Bounded Procedures.12.11 Regions for Continuing or Terminating Sampling.12.12 The Functional Equation.12.13 Approximations and Bounds for the Bayes Risk.12.14 The Sequential Probability-ratio Test.12.15 Characteristics of Sequential Probability-ratio Tests.12.16 Approximating the Expected Number of Observations.Exercises.Chapter 13. Optimal Stopping.13.1 Introduction.13.2 The Statistician's Reward.13.3 Choice of the Utility Function.13.4 Sampling Without Recall.13.5 Further Problems of Sampling with Recall and Sampling without Recall.13.6 Sampling without Recall from a Normal Distribution with Unknown Mean.13.7 Sampling with Recall from a Normal Distribution with Unknown Mean.13.8 Existence of Optimal Stopping Rules.13.9 Existence of Optimal Stopping Rules for Problems of Sampling with Recall and Sampling without Recall.13.10 Martingales.13.11 Stopping Rules for Martingales.13.12 Uniformly Integrable Sequences of Random Variables.13.13 Martingales Formed from Sums and Products of Random Variables.13.14 Regular Supermartingales.13.15 Supermartingales and General Problems of Optimal Stopping.13.16 Markov Processes.13.17 Stationary Stopping Rules for Markov Processes.13.18 Entrance-fee Problems.13.19 The Functional Equation for a Markov Process.Exercises.Chapter 14. Sequential Choice of Experiments.14.1 Introduction.14.2 Markovian Decision Processes with a Finite Number of Stages.14.3 Markovian Decision Processes with an Infinite Number of Stages.14.4 Some Betting Problems.14.5 Two-armed-bandit Problems.14.6 Two-armed-bandit Problems When the Value of One Parameter Is Known.14.7 Two-armed-bandit Problems When the Parameters Are Dependent.14.8 Inventory Problems.14.9 Inventory Problems with an Infinite Number of Stages.14.10 Control Problems.14.11 Optimal Control When the Process Cannot Be Observed without Error.14.12 Multidimensional Control Problems.14.13 Control Problems with Actuation Errors.14.14 Search Problems.14.15 Search Problems with Equal Costs.14.16 Uncertainty Functions and Statistical Decision Problems.14.17 Sufficient Experiments.14.18 Examples of Sufficient Experiments.Exercises.References.Supplementary Bibliography.Name Index.Subject Index."
            },
            "slug": "Optimal-Statistical-Decisions-Degroot",
            "title": {
                "fragments": [],
                "text": "Optimal Statistical Decisions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107699593"
                        ],
                        "name": "M. Wilson",
                        "slug": "M.-Wilson",
                        "structuredName": {
                            "firstName": "M",
                            "lastName": "Wilson",
                            "middleNames": [
                                "A"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2855952"
                        ],
                        "name": "J. Derisi",
                        "slug": "J.-Derisi",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Derisi",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Derisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66958960"
                        ],
                        "name": "H. Kristensen",
                        "slug": "H.-Kristensen",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Kristensen",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kristensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50196758"
                        ],
                        "name": "P. Imboden",
                        "slug": "P.-Imboden",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Imboden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Imboden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144206746"
                        ],
                        "name": "S. Rane",
                        "slug": "S.-Rane",
                        "structuredName": {
                            "firstName": "Sangeeta",
                            "lastName": "Rane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32037613"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Brown",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108764"
                        ],
                        "name": "G. Schoolnik",
                        "slug": "G.-Schoolnik",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Schoolnik",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Schoolnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14359871,
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "id": "47794ebd167ca3b43a78d8c9b46fc666e0191c1a",
            "isKey": false,
            "numCitedBy": 557,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Tuberculosis is a chronic infectious disease that is transmitted by cough-propelled droplets that carry the etiologic bacterium, Mycobacterium tuberculosis. Although currently available drugs kill most isolates of M. tuberculosis, strains resistant to each of these have emerged, and multiply resistant strains are increasingly widespread. The growing problem of drug resistance combined with a global incidence of seven million new cases per year underscore the urgent need for new antituberculosis therapies. The recent publication of the complete sequence of the M. tuberculosis genome has made possible, for the first time, a comprehensive genomic approach to the biology of this organism and to the drug discovery process. We used a DNA microarray containing 97% of the ORFs predicted from this sequence to monitor changes in M. tuberculosis gene expression in response to the antituberculous drug isoniazid. Here we show that isoniazid induced several genes that encode proteins physiologically relevant to the drug's mode of action, including an operonic cluster of five genes encoding type II fatty acid synthase enzymes and fbpC, which encodes trehalose dimycolyl transferase. Other genes, not apparently within directly affected biosynthetic pathways, also were induced. These genes, efpA, fadE23, fadE24, and ahpC, likely mediate processes that are linked to the toxic consequences of the drug. Insights gained from this approach may define new drug targets and suggest new methods for identifying compounds that inhibit those targets."
            },
            "slug": "Exploring-drug-induced-alterations-in-gene-in-by-Wilson-Derisi",
            "title": {
                "fragments": [],
                "text": "Exploring drug-induced alterations in gene expression in Mycobacterium tuberculosis by microarray hybridization."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that isoniazid induced several genes that encode proteins physiologically relevant to the drug's mode of action, including an operonic cluster of five genes encoding type II fatty acid synthase enzymes and fbpC, which encodes trehalose dimycolyl transferase."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057064833"
                        ],
                        "name": "David Jensen",
                        "slug": "David-Jensen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jensen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 105
                            }
                        ],
                        "text": "We can extend standard techniques (such as Expectation Maximization for missing data)\nto this task (see [Koller and Pfeffer, 1997] for some preliminary work on related models.)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 31
                            }
                        ],
                        "text": "This contribution generalizes [Koller and Pfeffer, 1997]\u2019s preliminary work on this topic."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17101018,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "012248dd502ace444aae276bfb353c8c7821de1b",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A Case Study David Jensen Computer Science Department Campus Box 34610 LGRC University of Massachusetts Amherst, MA 01003-4610 j ensen\u00a9cs, umass, edu In September 1995, the Congressional Office of Technology Assessment completed a study of the potential for AI technologies to detect money laundering by screening wire transfers. The study, conducted at the request of the Senate Permanent Subcommittee on Investigations, evaluates the technical and public policy implications of widespread use of AI technologies by the Federal government for fraud detection. Its conclusions are relevant to many other uses of AI technologies for fraud detection in both the public and private sectors."
            },
            "slug": "Prospective-Assessment-of-AI-Technologies-for-Fraud-Jensen",
            "title": {
                "fragments": [],
                "text": "Prospective Assessment of AI Technologies for Fraud Detection: A Case Study"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A Case Study David Jensen Computer Science Department Campus Box 34610 LGRC University of Massachusetts Amherst, MA 01003-4610 j ensen\u00a9cs, umass, edu Its conclusions are relevant to many other uses of AI technologies for fraud detection in both the public and private sectors."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061377"
                        ],
                        "name": "M. Behr",
                        "slug": "M.-Behr",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Behr",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Behr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131482516"
                        ],
                        "name": "M. A. Wilson",
                        "slug": "M.-A.-Wilson",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Wilson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39343498"
                        ],
                        "name": "W. Gill",
                        "slug": "W.-Gill",
                        "structuredName": {
                            "firstName": "Wendy",
                            "lastName": "Gill",
                            "middleNames": [
                                "P"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3218140"
                        ],
                        "name": "H. Salamon",
                        "slug": "H.-Salamon",
                        "structuredName": {
                            "firstName": "Hugh",
                            "lastName": "Salamon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Salamon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108764"
                        ],
                        "name": "G. Schoolnik",
                        "slug": "G.-Schoolnik",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Schoolnik",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Schoolnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144206746"
                        ],
                        "name": "S. Rane",
                        "slug": "S.-Rane",
                        "structuredName": {
                            "firstName": "Sangeeta",
                            "lastName": "Rane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2034446"
                        ],
                        "name": "P. Small",
                        "slug": "P.-Small",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Small",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Small"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23067490,
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "id": "2f5a303052f6e9734daf9f916e8089efd4e3a4f1",
            "isKey": false,
            "numCitedBy": 1554,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Bacille Calmette-Gu\u00e9rin (BCG) vaccines are live attenuated strains of Mycobacterium bovis administered to prevent tuberculosis. To better understand the differences between M. tuberculosis, M. bovis, and the various BCG daughter strains, their genomic compositions were studied by performing comparative hybridization experiments on a DNA microarray. Regions deleted from BCG vaccines relative to the virulent M. tuberculosis H37Rv reference strain were confirmed by sequencing across the missing segment of the H37Rv genome. Eleven regions (encompassing 91 open reading frames) of H37Rv were found that were absent from one or more virulent strains of M. bovis. Five additional regions representing 38 open reading frames were present in M. bovis but absent from some or all BCG strains; this is evidence for the ongoing evolution of BCG strains since their original derivation. A precise understanding of the genetic differences between closely related Mycobacteria suggests rational approaches to the design of improved diagnostics and vaccines."
            },
            "slug": "Comparative-genomics-of-BCG-vaccines-by-DNA-Behr-Wilson",
            "title": {
                "fragments": [],
                "text": "Comparative genomics of BCG vaccines by whole-genome DNA microarray."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 168
                            }
                        ],
                        "text": "The second is the recent development of representations that extend the attribute-based BN representation to incorporate a much richer relational structure [Koller and Pfeffer, 1998; Ngo and Haddawy, 1996; Poole, 1993]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 232
                            }
                        ],
                        "text": "This generality allows our framework to be mapped into a variety of specific relational systems, including the probabilistic logic programs of [Ngo and Haddawy, 1996; Poole, 1993], and the probabilistic frame systems of [Koller and Pfeffer, 1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 50
                            }
                        ],
                        "text": "A richer class of PRMs (e.g., that of [Koller and Pfeffer, 1998]) would allow probabilities over the structure of the model; for example: uncertainty over the set of objects in the model, e.g., the number of children a couple has, or over the relations between objects, e.g., whose is the blood that\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic framebased systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Bayesiannetworks : The combinationof knowledgeandstatistical data"
            },
            "venue": {
                "fragments": [],
                "text": "MachineLearning"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chickering.LearningBayesiannetworks is NP-complete"
            },
            "venue": {
                "fragments": [],
                "text": "In D. FisherandH.-J.Lenz,editors,LearningfromData: Artificial IntelligenceandStatisticsV"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "andS.Dz\u0306eroski.InductiveLogic Programming:TechniquesandApplications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 11
                            }
                        ],
                        "text": "Following [Friedman et al., 1999], which examines a similar approach in the context of learning Bayesian networks, we propose an iterative approach that starts with some structure (possibly one where each attribute does not have any parents), and select the sets Pot 7 ^ _ based on this structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 32
                            }
                        ],
                        "text": "Some of these are discussed in [Friedman et al., 1999] in the context of learning Bayesian networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning of Bayesian network structure from massive datasets: The \u201csparse candidate"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 105
                            }
                        ],
                        "text": "The first is the deep understanding of the statistical learning problem in such models [Heckerman, 1998; Heckerman et al., 1995] and the role of structure in providing an appropriate bias for the learning task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 104
                            }
                        ],
                        "text": "In the case of Bayesian networks, there is a class of priors that can be described by a single network [Heckerman et al., 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Bayesian networks: The combination of knowledge and statistical data.Machine Learning, 20:197\u2013243"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learningbeliefnetworksin thepresenceof missing valuesandhiddenvariables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learningfrom dyadic data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Puzicha,andM. Jordan.Learningfrom dyadic data.In NIPS12, 1998.To"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "z\u0306eroski. Inductive Logic Programming: Techniques and Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 105
                            }
                        ],
                        "text": "The first is the deep understanding of the statistical learning problem in such models [Heckerman, 1998; Heckerman et al., 1995] and the role of structure in providing an appropriate bias for the learning task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 104
                            }
                        ],
                        "text": "In the case of Bayesian networks, there is a class of priors that can be described by a single network [Heckerman et al., 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Bayesiannetworks: The combinationof knowledgeandstatistical data.MachineLearning, 20:197\u2013243,1995"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 77
                            }
                        ],
                        "text": "This constructionis reminiscentof theknowledge-basedmodelconstructionapproach[Wellman et al., 1992]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 85
                            }
                        ],
                        "text": "This construction is reminiscent of the knowledge-based model construction approach [Wellman et al., 1992]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Goldman.Fromknowledge basesto decisionmodels.The Knowledge EngineeringReview, 7(1):35\u201353,1992"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 39,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-Probabilistic-Relational-Models-Getoor/611dac316bf03112c778cf7365d08e4a9d171876?sort=total-citations"
}