{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114422629"
                        ],
                        "name": "G. A. Miller",
                        "slug": "G.-A.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. A. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114531657"
                        ],
                        "name": "Noam Chomsky",
                        "slug": "Noam-Chomsky",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Chomsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam Chomsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 118165987,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f3695d5dd36bb0abd91c02d2725463fca556f46",
            "isKey": false,
            "numCitedBy": 886,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "been proposed to describe talkers and listeners to describe the users of language rather than the language itself. As m was pointed out at the beginning of Chapter 12, our language is not merely the collection of our linguistic responses, habits, or dispositions, just as our knowledge of arithmetic is not merely the collection of our arithmetic responses, habits, or dispositions. We must respect this distinction between the person's knowledge and his actual or even potential behavior; a formal characterization of some language is not simultaneously a model of the users of that"
            },
            "slug": "Finitary-models-of-language-users-Miller-Chomsky",
            "title": {
                "fragments": [],
                "text": "Finitary models of language users"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "It is proposed to describe talkers and listeners to describe the users of language rather than the language itself, just as the authors' knowledge of arithmetic is not merely the collection of their arithmetic responses, habits, or dispositions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740728360"
                        ],
                        "name": "James H. Martin",
                        "slug": "James-H.-Martin",
                        "structuredName": {
                            "firstName": "James H.",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James H. Martin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59634106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d100b48633ffe3ea8e774b37690300865403a79d",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Acquisition-of-Polysemy-Martin",
            "title": {
                "fragments": [],
                "text": "The Acquisition of Polysemy"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2006080"
                        ],
                        "name": "J. D. Gould",
                        "slug": "J.-D.-Gould",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Gould",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. D. Gould"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143666366"
                        ],
                        "name": "John Conti",
                        "slug": "John-Conti",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Conti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Conti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235018"
                        ],
                        "name": "Todd Hovanyecz",
                        "slug": "Todd-Hovanyecz",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Hovanyecz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Todd Hovanyecz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 52901253,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "1443f16dedbf99b4708856e0a9359b2683b4b767",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech recognition is not yet advanced enough to provide people with a reliable listening typewriter with which they could compose documents. The aim of this experiment was to determine if an imperfect listening typewriter would be useful. Participants dictated either in isolated words or in continuous speech, and used a simulated listening typewriter which recognized a limited vocabulary as well as one which recognized an unlimited one. Results suggest some versions may be at least as good as writing."
            },
            "slug": "Composing-Letters-with-a-Simulated-Listening-Gould-Conti",
            "title": {
                "fragments": [],
                "text": "Composing letters with a simulated listening typewriter"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Experiments suggest that some versions of a listening typewriter, even upon first using them, could be at least as good as traditional methods of handwriting and dictating."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114422629"
                        ],
                        "name": "G. A. Miller",
                        "slug": "G.-A.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. A. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87763195"
                        ],
                        "name": "J. Selfridge",
                        "slug": "J.-Selfridge",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Selfridge",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Selfridge"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 34743079,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "538d57646941b67e5b06e66eeae894d6e69a71b9",
            "isKey": false,
            "numCitedBy": 468,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Communicative behavior, perhaps more than any of man's other activities, depends upon patterning for its significance and usefulness. An accidental inversion of words or letters or sounds can produce grotesque alterations of a sentence, and to scramble the elements at random is to turn a sensible message into gibberish. No attack upon the problems of verbal behavior will be satisfactory if it does not take quantitative account of the patterns of verbal elements. We can dependably produce and distinguish only a small number of different letters or speech sounds. We must use these few elements to talk about millions of different things and situations. To stretch these few elements to cover these many needs, we are forced to combine the elements into patterns and to assign a different significance to each pattern. Since the number of possible patterns increases exponentially as the length of the pattern increases, this proves to be an efficient method of solving the problem."
            },
            "slug": "Verbal-context-and-the-recall-of-meaningful-Miller-Selfridge",
            "title": {
                "fragments": [],
                "text": "Verbal context and the recall of meaningful material."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Since the number of possible patterns increases exponentially as the length of the pattern increases, this proves to be an efficient method of solving the problem."
            },
            "venue": {
                "fragments": [],
                "text": "The American journal of psychology"
            },
            "year": 1950
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756977"
                        ],
                        "name": "S. Small",
                        "slug": "S.-Small",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Small",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Small"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144171250"
                        ],
                        "name": "M. Tanenhaus",
                        "slug": "M.-Tanenhaus",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tanenhaus",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tanenhaus"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59683898,
            "fieldsOfStudy": [
                "Psychology",
                "Linguistics"
            ],
            "id": "e34d37fbd055ecc3f61c680bf172be9de76da8c0",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lexical-ambiguity-resolution-Small-Cottrell",
            "title": {
                "fragments": [],
                "text": "Lexical ambiguity resolution"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705919"
                        ],
                        "name": "Chuck Wooters",
                        "slug": "Chuck-Wooters",
                        "structuredName": {
                            "firstName": "Chuck",
                            "lastName": "Wooters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chuck Wooters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1918411"
                        ],
                        "name": "G. Tajchman",
                        "slug": "G.-Tajchman",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Tajchman",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tajchman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069154640"
                        ],
                        "name": "Jonathan Segal",
                        "slug": "Jonathan-Segal",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Segal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Segal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398481836"
                        ],
                        "name": "E. Fosler-Lussier",
                        "slug": "E.-Fosler-Lussier",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Fosler-Lussier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fosler-Lussier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8241008,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6237bf81e36284ed74fca2803169964dca1b96b6",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the architecture and performance of the Berkeley Restaurant Project (BeRP), a medium-vocabulary, speaker-independent, spontaneous continuous speech understanding system currently under development at ICSI. BeRP serves as a testbed for a number of our speech-related research projects, including robust feature extraction, connectionist phonetic likelihood estimation, automatic induction of multiplepronunciation lexicons, foreign accent detection and modeling, advanced language models, and lip-reading. In addition, it has proved quite usable in its function as a database frontend, even though many of our subjects are non-native speakers of English."
            },
            "slug": "The-berkeley-restaurant-project-Jurafsky-Wooters",
            "title": {
                "fragments": [],
                "text": "The berkeley restaurant project"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "BeRP serves as a testbed for a number of speech-related research projects, including robust feature extraction, connectionist phonetic likelihood estimation, automatic induction of multiplepronunciation lexicons, foreign accent detection and modeling, advanced language models, and lip-reading."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58106824,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ce8cca19455e8d3055c57a9bafe882984c95a201",
            "isKey": false,
            "numCitedBy": 911,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "In computational linguistics, which began in the 1950's with machine translation, systems that are based mainly on the lexicon have a longer t r a d i t i o n than anything e l se f o r these purposes, twenty f i ve years must be allowed to count as a tradition. The bulk of many of the early translation systems was made up by a d ic t ionary whose ent r ies consisted of a rb i t ra ry ins t ruc t ions In machine language. In the early 60's, computational llnsulsts---at least those with theoretical pretentlons---abandoned this way of doing business for at least three related reasons:"
            },
            "slug": "Syntactic-Process-Kay",
            "title": {
                "fragments": [],
                "text": "Syntactic Process"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "In computational linguistics, which began in the 1950's with machine translation, systems that are based mainly on the lexicon have a longer lifespan than anything else, so twenty years must be allowed to count as a tradition."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2220523"
                        ],
                        "name": "G. Martins",
                        "slug": "G.-Martins",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Martins",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Martins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43606749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c49feaee361d90ada4bddb41a3740bc31c83bd5",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The MIND system is a single computer program incorporating an extensible set of fundamental linguistic processors that can be combined on command to carry out a great variety of tasks from grammar testing to question-answering and language translation. The program is controlled from a graphic display console from which the user can specify the sequence of operations, modify rules, edit texts and monitor the details of each operation to any desired extent. Presently available processors include morphological and syntactic analyzers, a semantic file processor, a transformational component, a morphological synthesizer, and an interactive disambiguator."
            },
            "slug": "The-MIND-System-Kay-Martins",
            "title": {
                "fragments": [],
                "text": "The MIND System"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The MIND system is a single computer program incorporating an extensible set of fundamental linguistic processors that can be combined on command to carry out a great variety of tasks from grammar testing to question-answering and language translation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403805311"
                        ],
                        "name": "B. Nash-webber",
                        "slug": "B.-Nash-webber",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Nash-webber",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Nash-webber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59634154,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "1fef8f21ec4fc8582b4329ff40294b870271913b",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-ROLE-OF-SEMANTICS-IN-AUTOMATIC-SPEECH-Nash-webber",
            "title": {
                "fragments": [],
                "text": "THE ROLE OF SEMANTICS IN AUTOMATIC SPEECH UNDERSTANDING"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50021941"
                        ],
                        "name": "M. Joos",
                        "slug": "M.-Joos",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Joos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Joos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121205709,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6c848f44e8122cebccff33ae3f364325f35ee0d9",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Physicists describe speech with continuous mathematics, such as Fourier analysis or the autocorrelation function. Linguists describe language instead, using a discontinuous or discrete mathematics called \u201clinguistics.\u201d The nature of this odd calculus is outlined and justified here. It treats speech communication as having a telegraphic structure. (Non\u2010linguists normally fail to orient themselves in this field because they treat speech as analogous to telephony.) The telegraph\u2010code structure of language is examined from top to bottom, and at each of its several levels of complexity (compared to the two levels of Morse code) its structure is shown to be defined by possibilities and impossibilities of combination among the units of that level. Above the highest level we find, instead of such absolute restrictions, conditional probabilities of occurrence: this is the semantic field, outside linguistics, where sociologists can work. Below the lowest level we find, instead of such absolute restrictions, conditional probabilities of phonetic quality: this is the phonetic field, outside linguistics, where physicists can work. Thus linguistics is peculiar among mathematical systems in that it abuts upon reality in two places instead of one. This statement is equivalent to defining a language as a symbolic system; that is, as a code."
            },
            "slug": "Description-of-Language-Design-Joos",
            "title": {
                "fragments": [],
                "text": "Description of Language Design"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1950
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722959"
                        ],
                        "name": "J. McCawley",
                        "slug": "J.-McCawley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McCawley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. McCawley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60770885,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "c526a1c5ff0c0d95476188e46544f34308a2c7c8",
            "isKey": false,
            "numCitedBy": 531,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This second edition of James D. McCawley's classic textbook offers in one volume a complete course in the syntactic structure of English. New to this edition are sections on appositive constructions, parasitic gaps, contrastive negation, and comparative conditional sentences, as well as expanded coverage of cleft sentences and free relatives. The presentation is coherent, comprehensive, and systematically organized, beginning with an overview of McCawley's approach to syntactic analysis and progressing through the major constructions and processes of English grammar. No prior special knowledge of syntax is presupposed, and the number and variety of exercises after each chapter have been increased."
            },
            "slug": "The-syntactic-phenomena-of-English-McCawley",
            "title": {
                "fragments": [],
                "text": "The syntactic phenomena of English"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "New to this edition are sections on appositive constructions, parasitic gaps, contrastive negation, and comparative conditional sentences, as well as expanded coverage of cleft sentences and free relatives."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895193"
                        ],
                        "name": "C. T. Hemphill",
                        "slug": "C.-T.-Hemphill",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Hemphill",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. T. Hemphill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34972608"
                        ],
                        "name": "J. Godfrey",
                        "slug": "J.-Godfrey",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Godfrey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Godfrey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862682"
                        ],
                        "name": "G. Doddington",
                        "slug": "G.-Doddington",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Doddington",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Doddington"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1094063,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "1d19708290ef3cc3f43c2c95b07acdd4f52f5cda",
            "isKey": false,
            "numCitedBy": 628,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech research has made tremendous progress in the past using the following paradigm:\u2022 define the research problem,\u2022 collect a corpus to objectively measure progress, and\u2022 solve the research problem.Natural language research, on the other hand, has typically progressed without the benefit of any corpus of data with which to test research hypotheses. We describe the Air Travel Information System (ATIS) pilot corpus, a corpus designed to measure progress in Spoken Language Systems that include both a speech and natural language component. This pilot marks the first full-scale attempt to collect such a corpus and provides guidelines for future efforts."
            },
            "slug": "The-ATIS-Spoken-Language-Systems-Pilot-Corpus-Hemphill-Godfrey",
            "title": {
                "fragments": [],
                "text": "The ATIS Spoken Language Systems Pilot Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This pilot marks the first full-scale attempt to collect a corpus to measure progress in Spoken Language Systems that include both a speech and natural language component and provides guidelines for future efforts."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818123"
                        ],
                        "name": "E. Black",
                        "slug": "E.-Black",
                        "structuredName": {
                            "firstName": "Ezra",
                            "lastName": "Black",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Black"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19859071,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "806f47862549c51f12c5539451abce2f6573236d",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of researchers in text processing have independently observed that people can consistently determine in which of several given senses a word is being used in text, simply by examining the half dozen or so words just before and just after the word in focus. The question arises whether the same task can be accomplished by mechanical means. Experimental results are presented which suggest an affirmative answer to this query. Three separate methods of discriminating English word senses are compared information-theoretically. Findings include a strong indication of the power of domain-specific content analysis of text, as opposed to domain-general approaches."
            },
            "slug": "An-Experiment-in-Computational-Discrimination-of-Black",
            "title": {
                "fragments": [],
                "text": "An Experiment in Computational Discrimination of English Word Senses"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "Experimental results are presented which suggest that people can consistently determine in which of several given senses a word is being used in text, simply by examining the half dozen or so words just before and just after the word in focus."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753394"
                        ],
                        "name": "D. Bobrow",
                        "slug": "D.-Bobrow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bobrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bobrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803660"
                        ],
                        "name": "R. Kaplan",
                        "slug": "R.-Kaplan",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Kaplan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kaplan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728478"
                        ],
                        "name": "D. Norman",
                        "slug": "D.-Norman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Norman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Norman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073432002"
                        ],
                        "name": "Henry S. Thompson",
                        "slug": "Henry-S.-Thompson",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Thompson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Henry S. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699245"
                        ],
                        "name": "T. Winograd",
                        "slug": "T.-Winograd",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Winograd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Winograd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35280186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2505e3f0e19d50bdd418ca9becf8cbb08f61dc1",
            "isKey": false,
            "numCitedBy": 359,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "GUS,-A-Frame-Driven-Dialog-System-Bobrow-Kaplan",
            "title": {
                "fragments": [],
                "text": "GUS, A Frame-Driven Dialog System"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 131886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fa28d8a77e438d58b3d3670028b4e4f5380732b",
            "isKey": false,
            "numCitedBy": 617,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "It is well-known that there are polysemous words like sentence whose \"meaning\" or \"sense\" depends on the context of use. We have recently reported on two new word-sense disambiguation systems, one trained on bilingual material (the Canadian Hansards) and the other trained on monolingual material (Roget's Thesaurus and Grolier's Encyclopedia). As this work was nearing completion, we observed a very strong discourse effect. That is, if a polysemous word such as sentence appears two or more times in a well-written discourse, it is extremely likely that they will all share the same sense. This paper describes an experiment which confirmed this hypothesis and found that the tendency to share sense in the same discourse is extremely strong (98%). This result can be used as an additional source of constraint for improving the performance of the word-sense disambiguation algorithm. In addition, it could also be used to help evaluate disambiguation algorithms that did not make use of the discourse constraint."
            },
            "slug": "One-Sense-Per-Discourse-Gale-Church",
            "title": {
                "fragments": [],
                "text": "One Sense Per Discourse"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An experiment confirmed the hypothesis that if a polysemous word such as sentence appears two or more times in a well-written discourse, it is extremely likely that they will all share the same sense and found that the tendency to share sense in the same discourse is extremely strong."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1872595"
                        ],
                        "name": "Robert Krovetz",
                        "slug": "Robert-Krovetz",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Krovetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Krovetz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1352870,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "a958e1c0713dee06e7333ef0e12a04ad2d24d33a",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous research has indicated that when a polysemous word appears two or more times in a discourse, it is extremely likely that they will all share the same sense [Gale et al. 92]. However, those results were based on a coarse-grained distinction between senses (e.g, sentence in the sense of a \u2018prison sentence\u2019 vs. a \u2018grammatical sentence\u2019). We report on an analysis of multiple senses within two sense-tagged corpora, Semcor and DSO. These corpora used WordNet for their sense inventory. We found significantly more occurrences of multiple-senses per discourse than reported in [Gale et al. 92] (33% instead of 4%). We also found classes of ambiguous words in which as many as 45% of the senses in the class co-occur within a document. We discuss the implications of these results for the task of word-sense tagging and for the way in which senses should be represented."
            },
            "slug": "More-than-One-Sense-Per-Discourse-Krovetz",
            "title": {
                "fragments": [],
                "text": "More than One Sense Per Discourse"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An analysis of multiple senses within two sense-tagged corpora, Semcor and DSO, found significantly more occurrences of multiple-senses per discourse than reported and found classes of ambiguous words in which as many as 45% of the senses in the class co-occur within a document."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35400286"
                        ],
                        "name": "Z. Harris",
                        "slug": "Z.-Harris",
                        "structuredName": {
                            "firstName": "Zellig",
                            "lastName": "Harris",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Harris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 145232322,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3dc4afd8e6dfabdb636f8b61ef7a4943f9b16dc1",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a formalized procedure for describing utterances directly in terms of sequences of morphemes rather than of single morphemes.1 It thus covers an important part of what is usually included under syntax. When applied in a particular language, the procedure yields a compact statement of what sequences of morphemes occur in the language, i. e. a formula for each utterance (sentence) structure in the language."
            },
            "slug": "From-Morpheme-to-Utterance-Harris",
            "title": {
                "fragments": [],
                "text": "From Morpheme to Utterance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1946
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746503"
                        ],
                        "name": "A. Kilgarriff",
                        "slug": "A.-Kilgarriff",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Kilgarriff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kilgarriff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6548779"
                        ],
                        "name": "Joseph Rosenzweig",
                        "slug": "Joseph-Rosenzweig",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Rosenzweig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Rosenzweig"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13942336,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6557bd2f2b6a2b95a381bd073561c75786406118",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Senseval was the first open, community-based evaluation exercisefor Word Sense Disambiguation programs. It adopted the quantitativeapproach to evaluation developed in MUC and other ARPA evaluationexercises. It took place in 1998. In this paper we describe thestructure, organisation and results of the SENSEVAL exercise forEnglish. We present and defend various design choices for theexercise, describe the data and gold-standard preparation, considerissues of scoring strategies and baselines, and present the resultsfor the 18 participating systems. The exercise identifies thestate-of-the-art for fine-grained word sense disambiguation, wheretraining data is available, as 74\u201378% correct, with a number ofalgorithms approaching this level of performance. For systems thatdid not assume the availability of training data, performance wasmarkedly lower and also more variable. Human inter-tagger agreementwas high, with the gold standard taggings being around 95%replicable."
            },
            "slug": "Framework-and-Results-for-English-SENSEVAL-Kilgarriff-Rosenzweig",
            "title": {
                "fragments": [],
                "text": "Framework and Results for English SENSEVAL"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The exercise identifies the state-of-the-art for fine-grained word sense disambiguation, where training data is available, as 74\u201378% correct, with a number of algorithms approaching this level of performance."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Humanit."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90061799"
                        ],
                        "name": "M. Baltin",
                        "slug": "M.-Baltin",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Baltin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Baltin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2708017"
                        ],
                        "name": "J. Bresnan",
                        "slug": "J.-Bresnan",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bresnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bresnan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 144919445,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "97c0cd0057a683ffad774a123670622dc6a07775",
            "isKey": false,
            "numCitedBy": 2054,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The editor of this volume, who is also author or coauthor of five of the contributions, has provided an introduction that not only affords an overview of the separate articles but also interrelates the basic issues in linguistics, psycholinguistics and cognitive studies that are addressed in this volume. The twelve articles are grouped into three sections, as follows: \"I. Lexical Representation: \" The Passive in Lexical Theory (J. Bresnan); On the Lexical Representation of Romance Reflexive Clitics (J. Grimshaw); and Polyadicity (J. Bresnan).\"II. Syntactic Representation: \" Lexical-Functional Grammar: A Formal Theory for Grammatical Representation (R. Kaplan and J. Bresnan); Control and Complementation (J. Bresnan); Case Agreement in Russian (C. Neidle); The Representation of Case in Icelandic (A. Andrews); Grammatical Relations and Clause Structure in Malayalam (K. P. Monahan); and Sluicing: A Lexical Interpretation Procedure (L. Levin).\"III. Cognitive Processing of Grammatical Representations: \" A Theory of the Acquisition of Lexical Interpretive Grammars (S. Pinker); Toward a Theory of Lexico-Syntactic Interactions in Sentence Perception (M. Ford, J. Bresnan, and R. Kaplan); and Sentence Planning Units: Implications for the Speaker's Representation of Meaningful Relations Underlying Sentences (M. Ford)."
            },
            "slug": "The-Mental-representation-of-grammatical-relations-Baltin-Bresnan",
            "title": {
                "fragments": [],
                "text": "The Mental representation of grammatical relations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2979211"
                        ],
                        "name": "Andr\u00e1s Kornai",
                        "slug": "Andr\u00e1s-Kornai",
                        "structuredName": {
                            "firstName": "Andr\u00e1s",
                            "lastName": "Kornai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e1s Kornai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52800035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ecaa05807265f7f4d3f9a7a5d33c451341e84b4",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In spite of the wide availability of more powerful (context free, mildly context sensitive, and even Turing-equivalent) formalisms, the bulk of the applied work on language and sublanguage modeling, especially for the purposes of recognition and topic search, is still performed by various finite state methods. In fact, the use of such methods in research labs as well as in applied work actually increased in the past five years. To bring together those developing and using extended finite state methods to text analysis, speech/OCR language modeling, and related CL and NLP tasks with those in AI and CS interested in analyzing and possibly extending the domain of finite state algorithms, a workshop was held in August 1996 in Budapest as part of the European Conference on Artificial Intelligence (ECAI'96)."
            },
            "slug": "Extended-finite-state-models-of-language-Kornai",
            "title": {
                "fragments": [],
                "text": "Extended finite state models of language"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "To bring together those developing and using extended finite state methods to text analysis, speech/OCR language modeling, and related CL and NLP tasks with those in AI and CS interested in analyzing and possibly extending the domain of finite state algorithms, a workshop was held in August 1996 in Budapest."
            },
            "venue": {
                "fragments": [],
                "text": "Nat. Lang. Eng."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2215426"
                        ],
                        "name": "J. Weizenbaum",
                        "slug": "J.-Weizenbaum",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Weizenbaum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weizenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1896290,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "a798bca71c8833e49ad9bac22da4b5c3503f1e6a",
            "isKey": false,
            "numCitedBy": 1749,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "ELIZA is a program operating within the MAC time-sharing system at MIT which makes certain kinds of natural language conversation between man and computer possible. Input sentences are analyzed on the basis of decomposition rules which are triggered by key words appearing in the input text. Responses are generated by reassembly rules associated with selected decomposition rules. The fundamental technical problems with which ELIZA is concerned are: (1) the identification of key words, (2) the discovery of minimal context, (3) the choice of appropriate transformations, (4) generation of responses in the absence of key words, and (5) the provision of an editing capability for ELIZA \"scripts\". A discussion of some psychological issues relevant to the ELIZA approach as well as of future developments concludes the paper."
            },
            "slug": "ELIZA\u2014a-computer-program-for-the-study-of-natural-Weizenbaum",
            "title": {
                "fragments": [],
                "text": "ELIZA\u2014a computer program for the study of natural language communication between man and machine"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "A discussion of some psychological issues relevant to the ELIZA approach as well as of future developments concludes the paper."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34093039"
                        ],
                        "name": "A. Newell",
                        "slug": "A.-Newell",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Newell",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Newell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46626086"
                        ],
                        "name": "Stefan Langer",
                        "slug": "Stefan-Langer",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Langer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Langer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34315688"
                        ],
                        "name": "M. Hickey",
                        "slug": "M.-Hickey",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Hickey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hickey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36925364,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "d6d7c78be84929a83930ee62acfec57ae6ab1691",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Alternative and Augmentative Communication (AAC) for people with speech and language disorders is an interesting and challenging application field for research in Natural Language Processing. Further advances in the development of AAC systems require robust language processing techniques and versatile linguistic knowledge bases. Also NLP research can benefit from studying the techniques used in this field and from the user-centred methodologies used to develop and evaluate AAC systems. Until recently, however, apart from some exceptions, there was little scientific exchange between the two research areas. This paper aims to make a contribution to closing this gap. We will argue that current interest in language use, which can be shown by the large amount of research on comprehensive dictionaries and on corpora processing, makes the results of NLP research more relevant to AAC. We will also show that the increasing interest of AAC researchers in NLP is having positive results. To situate research on communication aids, the first half of this paper gives an overview of the AAC research field. The second half is dedicated to an overview of research prototype systems and commercially available communication aids that specifically involve more advanced language processing techniques."
            },
            "slug": "The-r\u00f4le-of-natural-language-processing-in-and-Newell-Langer",
            "title": {
                "fragments": [],
                "text": "The r\u00f4le of natural language processing in alternative and augmentative communication"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is argued that current interest in language use makes the results of NLP research more relevant to AAC, and it is shown that the increasing interest of AAC researchers in NLP is having positive results."
            },
            "venue": {
                "fragments": [],
                "text": "Nat. Lang. Eng."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2971978"
                        ],
                        "name": "Y. Wilks",
                        "slug": "Y.-Wilks",
                        "structuredName": {
                            "firstName": "Yorick",
                            "lastName": "Wilks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wilks"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60537180,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "99c1ef49842f72ad07b5283ec41b924ddc4e6959",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes a system of semantic analysis and generation, programmed in LISP 1.5 and designed to pass from paragraph length input in English to French via an interlingual representation. A wide class of English input forms will be covered, but the vocabulary will initially be restricted to one of a few hundred words. With this subset working, and during the current year (71-72), it is also hoped to map the interlingual representation onto some predicate calculus notation so as to make possible the answering of very simple questions about the translated matter. The specification of the translation system itself is complete, and its main points of interest that distinguish it from other systems are: i) It translated phrase by phrase -- with facilities for reordering phrases and establishing essential semantic connectivities between them -- by mapping complex semantic structures of \"message\" onto each phrase. These constitute the interlingual representation to be translated. This matching is done without the explicit use of a conventional syntax analysis, by taking as the appropriate matched structure the \"most dense\" of the alternative structures derived. This method has been found highly successful in earlier versions of this analysis system. ii) The French output strings are generated without the explicit use of a generative grammar. That is done by means of STEREOTYPES: strings of French words, and functions evaluating to French words, which are attached to English word senses in the dictionary and built into the interlingual representation by the analysis routines. The generation program thus receives an interlingual representation that already contains both French output and implicit procedures for assembling the output, since the stereotypes are in effect recursive procedures specifying the content and production of the ouput word strings. Thus the generation program at no time consults a word dictionary or inventory of grammar rules. It is claimed that the system of notation and translation described is a convenient one for expressing and handling the items of semantic information that are ESSENTIAL to any effective MT system, I discuss in some detail the semantic information needed to ensure the correct choice of output prepositions in French, a vital matter inadequately treated by virtually all previous formalisms and projects."
            },
            "slug": "An-artificial-intelligence-approach-to-machine-Wilks",
            "title": {
                "fragments": [],
                "text": "An artificial intelligence approach to machine translation."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is claimed that the system of notation and translation described is a convenient one for expressing and handling the items of semantic information that are ESSENTIAL to any effective MT system and discusses in some detail the semantic information needed to ensure the correct choice of output prepositions in French."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153201"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61904772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c180f387357d9302a558bcd643209831744c639b",
            "isKey": false,
            "numCitedBy": 604,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system. DRAGON makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech. The model--that of a probabilistic function of a Markov process--is very flexible and leads to features which allow DRAGON to function despite high error rates from individual knowledge sources. Repeated use of a simple abstract model produces a system which is simple in structure, but powerful in capabilities."
            },
            "slug": "The-DRAGON-system--An-overview-Baker",
            "title": {
                "fragments": [],
                "text": "The DRAGON system--An overview"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system, which makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3095064"
                        ],
                        "name": "A. Wierzbicka",
                        "slug": "A.-Wierzbicka",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Wierzbicka",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wierzbicka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60376935,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "08f28bd8b28065f8923ad03877e2ee430075b386",
            "isKey": false,
            "numCitedBy": 555,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "To what extent are languages 'essentially the same'? Is every word in our language translatable into every other language or are some of our words and concepts 'culture specific'? In this innovative study, Wierzbicka ranges across a wide variety of languages and cultures, attempting to identify concepts which are truly universal, while at the same time arguing that every language constitutes a different 'guide to reality'. The lexicons of different languages, she shows, do indeed suggest different conceptual universes. Not everything that can be said in one language can be said in another, and this is not just a matter of certain things being easier to say in one language than in another. In the development of her argument, Wierzbicka focuses on the words for emotion, moral concepts, names, and titles."
            },
            "slug": "Semantics,-Culture,-and-Cognition:-Universal-Human-Wierzbicka",
            "title": {
                "fragments": [],
                "text": "Semantics, Culture, and Cognition: Universal Human Concepts in Culture-Specific Configurations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This innovative study ranges across a wide variety of languages and cultures, attempting to identify concepts which are truly universal, while at the same time arguing that every language constitutes a different 'guide to reality'."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6616065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd459cc59b09e612eeec5327d0690d1508ffe362",
            "isKey": false,
            "numCitedBy": 876,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Assume that the syntax of natural language can be parsed by a left-to-right deterministic mechanism without facilities for parallelism or backup. It will be shown that this 'determinism' hypothesis, explored within the context of the grammar of English, leads to a simple mechanism, a grammar interpreter. (Author)"
            },
            "slug": "A-theory-of-syntactic-recognition-for-natural-Marcus",
            "title": {
                "fragments": [],
                "text": "A theory of syntactic recognition for natural language"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It will be shown that this 'determinism' hypothesis, explored within the context of the grammar of English, leads to a simple mechanism, a grammar interpreter."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1144461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68dd4b89ce1407372a29d05ca9e4e1a2e0513617",
            "isKey": false,
            "numCitedBy": 5789,
            "numCiting": 210,
            "paperAbstract": {
                "fragments": [],
                "text": "How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched."
            },
            "slug": "A-Solution-to-Plato's-Problem:-The-Latent-Semantic-Landauer-Dumais",
            "title": {
                "fragments": [],
                "text": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686491"
                        ],
                        "name": "J. Polifroni",
                        "slug": "J.-Polifroni",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Polifroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Polifroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145148360"
                        ],
                        "name": "L. Hirschman",
                        "slug": "L.-Hirschman",
                        "structuredName": {
                            "firstName": "Lynette",
                            "lastName": "Hirschman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hirschman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745131"
                        ],
                        "name": "S. Seneff",
                        "slug": "S.-Seneff",
                        "structuredName": {
                            "firstName": "Stephanie",
                            "lastName": "Seneff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seneff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710543"
                        ],
                        "name": "V. Zue",
                        "slug": "V.-Zue",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Zue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zue"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2261254,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d10ae238c48f138ebec0084a8b0b5fcea2356f4",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "As the DARPA spoken language community moves towards developing useful systems for interactive problem solving, we must explore alternative evaluation procedures that measure whether these systems aid people in solving problems within the task domain. In this paper, we describe several experiments exploring new evaluation procedures. To look at end-to-end evaluation, we modified our data collection procedure slightly in order to experiment with several objective task completion measures. We found that the task completion time is well correlated with the number of queries used. We also explored log file evaluation, where evaluators were asked to judge the clarity of the query and the correctness of the response based on examination of the log file. Our results show that seven evaluators were unanimous on more than 80% of the queries, and that at least 6 out of 7 evaluators agreed over 90% of the time. Finally, we applied these new procedures to compare two systems, one system requiring a complete parse and the other using the more flexible robust parsing mechanism. We found that these metrics could distinguish between these systems: there were significant differences in ability to complete the task, number of queries required to complete the task, and score (as computed through a log file evaluation) between the robust and the non-robust modes."
            },
            "slug": "Experiments-in-Evaluating-Interactive-Spoken-Polifroni-Hirschman",
            "title": {
                "fragments": [],
                "text": "Experiments in Evaluating Interactive Spoken Language Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "To look at end-to-end evaluation, a data collection procedure was modified slightly in order to experiment with several objective task completion measures, and it was found that the task completion time is well correlated with the number of queries used."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2971978"
                        ],
                        "name": "Y. Wilks",
                        "slug": "Y.-Wilks",
                        "structuredName": {
                            "firstName": "Yorick",
                            "lastName": "Wilks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wilks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5968738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "88095a87def97e5920cc74759036c82a7559d75c",
            "isKey": false,
            "numCitedBy": 212,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes a working analysis and generation program for natural language, which handles paragraph length input. Its core is a system of preferential choice between deep semantic patterns, based on what we call \u201csemantic density.\u201d The system is contrasted:<list><item>with syntax oriented linguistic approaches, and\n</item> <item>with theorem proving approaches to the understanding problem.\n</item></list>"
            },
            "slug": "An-intelligent-analyzer-and-understander-of-English-Wilks",
            "title": {
                "fragments": [],
                "text": "An intelligent analyzer and understander of English"
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9880507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a5e619f2c5f4220438b1357e596db5b1578398d",
            "isKey": false,
            "numCitedBy": 643,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a parsing system based upon a language model for English that is, in turn, based upon assigning probabilities to possible parses for a sentence. This model is used in a parsing system by finding the parse for the sentence with the highest probability. This system outperforms previous schemes. As this is the third in a series of parsers by different authors that are similar enough to invite detailed comparisons but different enough to give rise to different levels of performance, we also report on some experiments designed to identify what aspects of these systems best explain their relative performance."
            },
            "slug": "Statistical-Parsing-with-a-Context-Free-Grammar-and-Charniak",
            "title": {
                "fragments": [],
                "text": "Statistical Parsing with a Context-Free Grammar and Word Statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A parsing system based upon a language model for English that is, in turn, based upon assigning probabilities to possible parses for a sentence that outperforms previous schemes is described."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35400286"
                        ],
                        "name": "Z. Harris",
                        "slug": "Z.-Harris",
                        "structuredName": {
                            "firstName": "Zellig",
                            "lastName": "Harris",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Harris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 86680084,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "decd9bc0385612bdf936928206d83730718e737e",
            "isKey": false,
            "numCitedBy": 2644,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "For the purposes of the present discussion, the term structure will be used in the following non-rigorous sense: A set of phonemes or a set of data is structured in respect to some feature, to the extent that we can form in terms of that feature some organized system of statements which describes the members of the set and their interrelations (at least up to some limit of complexity). In this sense, language can be structured in respect to various independent features. And whether it is structured (to more than a trivial extent) in respect to, say, regular historical change, social intercourse, meaning, or distribution - or to what extent it is structured in any of these respects - is a matter decidable by investigation. Here we will discuss how each language can be described in terms of a distributional structure, i.e. in terms of the occurrence of parts (ultimately sounds) relative to other parts, and how this description is complete without intrusion of other features such as history or meaning. It goes without saying that other studies of language - historical, psychological, etc.-are also possible, both in relation to distributional structure and independently of it."
            },
            "slug": "Distributional-Structure-Harris",
            "title": {
                "fragments": [],
                "text": "Distributional Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This discussion will discuss how each language can be described in terms of a distributional structure, i.e. in Terms of the occurrence of parts relative to other parts, and how this description is complete without intrusion of other features such as history or meaning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686074"
                        ],
                        "name": "Patrick Schone",
                        "slug": "Patrick-Schone",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Schone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick Schone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2547808,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30545fe538a773b57e06b4217cd495ef84230bc8",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an algorithm to automatically induce the morphology of inflectional languages using only text corpora and no human input. Our algorithm combines cues from orthography, semantics, and syntactic distributions to induce morphological relationships in German, Dutch, and English. Using CELEX as a gold standard for evaluation, we show our algorithm to be an improvement over any knowledge-free algorithm yet proposed."
            },
            "slug": "Knowledge-Free-Induction-of-Inflectional-Schone-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Knowledge-Free Induction of Inflectional Morphologies"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An algorithm to automatically induce the morphology of inflectional languages using only text corpora and no human input is proposed, showing it to be an improvement over any knowledge-free algorithm yet proposed."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150023694"
                        ],
                        "name": "A. N\u00e1das",
                        "slug": "A.-N\u00e1das",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "N\u00e1das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. N\u00e1das"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122661322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "226a6dff9ccc1c2db9f09db644b13eb9d04322e7",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The language model probabilities are estimated by an empirical Bayes approach in which a prior distribution for the unknown probabilities is itself estimated through a novel choice of data. The predictive power of the model thus fitted is compared by means of its experimental perplexity [1] to the model as fitted by the Jelinek-Mercer deleted estimator and as fitted by the Turing-Good formulas for probabilities of unseen or rarely seen events."
            },
            "slug": "Estimation-of-probabilities-in-the-language-model-N\u00e1das",
            "title": {
                "fragments": [],
                "text": "Estimation of probabilities in the language model of the IBM speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The predictive power of the model thus fitted is compared by means of its experimental perplexity to the model as fitted by the Jelinek-Mercer deleted estimator and by the Turing-Good formulas for probabilities of unseen or rarely seen events."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1893732"
                        ],
                        "name": "E. Ejerhed",
                        "slug": "E.-Ejerhed",
                        "structuredName": {
                            "firstName": "Eva",
                            "lastName": "Ejerhed",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ejerhed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1025468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffd2b7930210df0ad54d1fcc2846a116c95f34cc",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents and compares two different methods of parsing, a regular expression method and a stochastic method, with respect to their success in identifying basic clauses in unrestricted English text. These methods of parsing were developed in order to be applied to the task of improving the detection of large prosodic units in the Bell Labs text-to-speech system, and were so applied experimentally. The paper also discusses the notion of basic clause that was defined as the parsing target. The result of a comparison of the error rates of the two parsing methods in the recognition of basic clauses showed that there was a 13% error rate for the regular expression method and a 6.5% error rate for the stochastic method."
            },
            "slug": "Finding-Clauses-In-Unrestricted-Text-By-Finitary-Ejerhed",
            "title": {
                "fragments": [],
                "text": "Finding Clauses In Unrestricted Text By Finitary And Stochastic Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A comparison of the error rates of the two parsing methods in the recognition of basic clauses showed that there was a 13% error rates for the regular expression method and a 6.5% error rate for the stochastic method."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144628595"
                        ],
                        "name": "S. Argamon",
                        "slug": "S.-Argamon",
                        "structuredName": {
                            "firstName": "Shlomo",
                            "lastName": "Argamon",
                            "middleNames": [
                                "Engelson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Argamon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2349412"
                        ],
                        "name": "Yuval Krymolowski",
                        "slug": "Yuval-Krymolowski",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Krymolowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuval Krymolowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8074746,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "7fad831935254c9c9ec39ffb03752a3f736c3f76",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognizing shallow linguistic patterns, such as basic syntactic relationships between words, is a common task in applied natural language and text processing. The common practice for approaching this task is by tedious manual definition of possible pattern structures, often in the form of regular expressions or finite automata. This paper presents a novel memory-based learning method that recognizes shallow patterns in new text based on a bracketed training corpus. The training data are stored as-is, in efficient suffix-tree data structures. Generalization is performed on-line at recognition time by comparing subsequences of the new text to positive and negative evidence in the corpus. This way, no information in the training is lost, as can happen in other learning systems that construct a single generalized model at the time of training. The paper presents experimental results for recognizing noun phrase, subject-verb and verb-object patterns in English. Since the learning approach enables easy porting to new domains, we plan to apply it to syntactic patterns in other languages and to sub-language patterns for information extraction."
            },
            "slug": "A-Memory-Based-Approach-to-Learning-Shallow-Natural-Argamon-Dagan",
            "title": {
                "fragments": [],
                "text": "A Memory-Based Approach to Learning Shallow Natural Language Patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel memory-based learning method that recognizes shallow patterns in new text based on a bracketed training corpus that enables easy porting to new domains and to sub-language patterns for information extraction."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753394"
                        ],
                        "name": "D. Bobrow",
                        "slug": "D.-Bobrow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bobrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bobrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728478"
                        ],
                        "name": "D. Norman",
                        "slug": "D.-Norman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Norman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Norman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56549282,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "db5ee05ce77a6c43092e12b3dada21009f9313aa",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SOME-PRINCIPLES-OF-MEMORY-SCHEMATA-Bobrow-Norman",
            "title": {
                "fragments": [],
                "text": "SOME PRINCIPLES OF MEMORY SCHEMATA"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115311"
                        ],
                        "name": "R. Pieraccini",
                        "slug": "R.-Pieraccini",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Pieraccini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Pieraccini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8992604"
                        ],
                        "name": "E. Levin",
                        "slug": "E.-Levin",
                        "structuredName": {
                            "firstName": "Esther",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15886461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d115356bcb38514589fe56aac6d9fa220722284",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a model for a statistical representation of the conceptual structure in a restricted subset of spoken natural language. The model is used for segmenting a sentence into phrases and labeling them with concept relations (or cases). The model is trained using a corpus of annotated transcribed sentences. The performance of the model was assessed on two tasks, including DARPA ATIS class A sentences."
            },
            "slug": "Stochastic-Representation-of-Conceptual-Structure-Pieraccini-Levin",
            "title": {
                "fragments": [],
                "text": "Stochastic Representation of Conceptual Structure in the ATIS Task"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A model for a statistical representation of the conceptual structure in a restricted subset of spoken natural language used for segmenting a sentence into phrases and labeling them with concept relations (or cases) is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143745511"
                        ],
                        "name": "R. F. Simmons",
                        "slug": "R.-F.-Simmons",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Simmons",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. F. Simmons"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17660655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "587fbc4dd6657e245e6ffd5c452d419e9979099b",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Fifteen experimental English language question-answering I systems which are programmed and operating are described ) arid reviewed. The systems range from a conversation machine ~] to programs which make sentences about pictures and systems s~ which translate from English into logical calculi. Systems are ~ classified as list-structured data-based, graphic data-based, ~! text-based and inferential. Principles and methods of opera~4 tions are detailed and discussed. It is concluded that the data-base question-answerer has > passed from initial research into the early developmental ~.4 phase. The most difficult and important research questions for ~i~ the advancement of general-purpose language processors are seen to be concerned with measuring meaning, dealing with ambiguities, translating into formal languages and searching large tree structures."
            },
            "slug": "Answering-English-questions-by-computer:-a-survey-Simmons",
            "title": {
                "fragments": [],
                "text": "Answering English questions by computer: a survey"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is concluded that the data-base question-answerer has passed from initial research into the early developmental ~4 phase and the most difficult and important research questions for general-purpose language processors are seen to be concerned with measuring meaning, dealing with ambiguities, translating into formal languages and searching large tree structures."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145332819"
                        ],
                        "name": "Mark Steedman",
                        "slug": "Mark-Steedman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Steedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12352908,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ded3f3aaaef970030dffd2326be77024b48bac77",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Combinatory Categorial Grammar (CCG) offers a new approach to the theory of natural language grammar. Coordination, relativization, and related prosodic phenomena have been analyzed in CCG in terms of a radically revised notion of surface structure. CCG surface structures do not exhibit traditional notions of syntactic dominance and command, and do not constitute an autonomous level of representation. Instead, they reflect the computations by which a sentence may be realized or analyzed, to synchronously define a predicate-argument structure, or logical form. Surface Structure and Interpretation shows that binding and control can be captured at this level, preserving the advantages of CCG as an account of coordination and unbounded dependency.The core of the book is a detailed treatment of extraction, a focus of syntactic research since the early work of Chomsky and Ross. The topics addressed include the sources of subject-object asymmetries and phenomena attributed to the Empty Category Principle (ECP), asymmetric islands, parasitic gaps, and the relation of coordination and extraction, including their interactions with binding theory. In his conclusion, the author relates CCG to other categorial and type-driven approaches and to proposals for minimalism in linguistic theory.Linguistic Inquiry Monograph No. 30"
            },
            "slug": "Surface-structure-and-interpretation-Steedman",
            "title": {
                "fragments": [],
                "text": "Surface structure and interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The core of the book is a detailed treatment of extraction, a focus of syntactic research since the early work of Chomsky and Ross, and relates CCG to other categorial and type-driven approaches and to proposals for minimalism in linguistic theory."
            },
            "venue": {
                "fragments": [],
                "text": "Linguistic inquiry"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69960817"
                        ],
                        "name": "M. R. Quillian",
                        "slug": "M.-R.-Quillian",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Quillian",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. R. Quillian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15304609,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be02603f27853d3cf6ef10cadc64727ed505cc25",
            "isKey": false,
            "numCitedBy": 439,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The Teachable Language Comprehender (TLC) is a program designed to be capable of being taught to \u201ccomprehend\u201d English text. When text which the program has not seen before is input to it, it comprehends that text by correctly relating each (explicit or implicit) assertion of the new text to a large memory. This memory is a \u201csemantic network\u201d representing factual assertions about the world.\nThe program also creates copies of the parts of its memory which have been found to relate to the new text, adapting and combining these copies to represent the meaning of the new text. By this means, the meaning of all text the program successfully comprehends is encoded into the same format as that of the memory. In this form it can be added into the memory.\nBoth factual assertions for the memory and the capabilities for correctly relating text to the memory's prior content are to be taught to the program as they are needed. TLC presently contains a relatively small number of examples of such assertions and capabilities, but within the system, notations for expressing either of these are provided. Thus the program now corresponds to a general process for comprehending language, and it provides a methodology for adding the additional information this process requires to actually comprehend text of any particular kind.\nThe memory structure and comprehension process of TLC allow new factual assertions and capabilities for relating text to such stored assertions to generalize automatically. That is, once such an assertion or capability is put into the system, it becomes available to help comprehend a great many other sentences in the future. Thus the addition of a single factual assertion or linguistic capability will often provide a large increment in TLC's effective knowledge of the world and in its overall ability to comprehend text.\nThe program's strategy is presented as a general theory of"
            },
            "slug": "The-teachable-language-comprehender:-a-simulation-Quillian",
            "title": {
                "fragments": [],
                "text": "The teachable language comprehender: a simulation program and theory of language"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The memory structure and comprehension process of TLC allow new factual assertions and capabilities for relating text to such stored assertions to generalize automatically and provide a large increment in TLC's effective knowledge of the world and in its overall ability to comprehend text."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3226331"
                        ],
                        "name": "C. Leacock",
                        "slug": "C.-Leacock",
                        "structuredName": {
                            "firstName": "Claudia",
                            "lastName": "Leacock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leacock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804836"
                        ],
                        "name": "G. Towell",
                        "slug": "G.-Towell",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Towell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Towell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746656"
                        ],
                        "name": "E. Voorhees",
                        "slug": "E.-Voorhees",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Voorhees",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Voorhees"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2946526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b53b6b7ffd1435c2c6a1b6684f9975b73648d131",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The three corpus-based statistical sense resolution methods studied here attempt to infer the correct sense of a polysemous word by using knowledge about patterns of word cooccurrences. The techniques were based on Bayesian decision theory, neural, networks, and content vectors as used in information retrieval. To understand these methods better, we posed a very specific problem: given a set of contexts, each containing the noun line in a known sense, construct a classifier that selects the correct sense of line for new contexts. To see how the degree of polysemy affects performance, results from three- and six-sense tasks are compared.The results demonstrate that each of the techniques is able to distinguish six senses of line with an accuracy greater than 70%. Furthermore, the response patterns of the classifiers are, for the most part, statistically indistinguishable from one another. Comparison of the two tasks suggests that the degree of difficulty involved in resolving individual senses is a greater performance factor than the degree of polysemy."
            },
            "slug": "Corpus-Based-Statistical-Sense-Resolution-Leacock-Towell",
            "title": {
                "fragments": [],
                "text": "Corpus-Based Statistical Sense Resolution"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "Three corpus-based statistical sense resolution methods studied here attempt to infer the correct sense of a polysemous word by using knowledge about patterns of word cooccurrences, based on Bayesian decision theory, neural, networks, and content vectors."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707726"
                        ],
                        "name": "J. Pustejovsky",
                        "slug": "J.-Pustejovsky",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Pustejovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pustejovsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713574"
                        ],
                        "name": "B. Boguraev",
                        "slug": "B.-Boguraev",
                        "structuredName": {
                            "firstName": "Branimir",
                            "lastName": "Boguraev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boguraev"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60844010,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "454b1f84fea0a21b6a24a44d8ad3ecbd9a9e6cad",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Lexical ambiguity is one of the most intractable problems facing language processing studies and, not surprisingly, it is at the core of research in lexical semantics. The papers in this collection constitute not just a set of diverse yet related articles in this core area of research, but rather make up a unique collection of work on the relationship between logical polysemy, sense extension, and discourse structure. Each paper addresses the following questions: what is the representation of a lexical item such that it may assume different senses? What is it about the representation of a lexical item that gives rise to sense extensions and to the phenomenon of logical polysemy? Three major subthemes run through the papers: the role of pragmatics and discourse in lexical disambiguation; the analysis of logical polysemy as a compositional process; and the treament of sense extension and referential transfer phenomena."
            },
            "slug": "Lexical-Semantics:-The-Problem-of-Polysemy-Pustejovsky-Boguraev",
            "title": {
                "fragments": [],
                "text": "Lexical Semantics: The Problem of Polysemy"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The papers in this collection constitute not just a set of diverse yet related articles in this core area of research, but rather make up a unique collection of work on the relationship between logical polysemy, sense extension, and discourse structure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3095064"
                        ],
                        "name": "A. Wierzbicka",
                        "slug": "A.-Wierzbicka",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Wierzbicka",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wierzbicka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 145525724,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfdc0a762e5282fde800896167f0d29b28c0db7e",
            "isKey": false,
            "numCitedBy": 1036,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Conceptual primitives and semantic universals are the cornerstones of a semantic theory which Anna Wierzbicka has been developing for many years. Semantics: Primes and Universals is a major synthesis of her work, presenting a full and systematic exposition of that theory in a non-technical and readable way. It delineates a full set of universal concepts, as they have emerged from large-scale investigations across a wide range of languages undertaken by the author and her colleagues. On the basis of empirical cross-linguistic studies it vindicates the old notion of the 'psychic unity of mankind', while at the same time offering a framework for the rigorous description of different languages and cultures."
            },
            "slug": "Semantics:-Primes-and-Universals-Wierzbicka",
            "title": {
                "fragments": [],
                "text": "Semantics: Primes and Universals"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Semantics: Primes and Universals is a major synthesis of Anna Wierzbicka's work, presenting a full and systematic exposition of that theory in a non-technical and readable way, delineating a full set of universal concepts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145463410"
                        ],
                        "name": "P. Kay",
                        "slug": "P.-Kay",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912454"
                        ],
                        "name": "C. Fillmore",
                        "slug": "C.-Fillmore",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fillmore",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fillmore"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16686405,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "0b8fb343f979bf1bc48eed705cd1ada4075140de",
            "isKey": false,
            "numCitedBy": 817,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "Our goal is to present, by means of the detailed analysis of a single grammatical problem, some of the principal commitments and mechanisms of a grammatical theory that assigns a central role to the notion of GRAMMATICAL CONSTRUCTION . To adopt a constructional approach is to undertake a commitment in principle to account for the entirety of each language. This means that the relatively general patterns of the language, such as the one licensing the ordering of a finite auxiliary verb before its subject in English, often known as SAI, and the highly idiomatic patterns, like kick the bucket , stand on an equal footing as data for which the grammar must account. An explicit grammar that covers the full range of constructions must represent all constructions, of whatever degree of generality or idiomaticity, in a common notation and must provide an explicit account of how each sentence of a language is licensed by a subset of the leaves of the inheritance hierarchy of constructions which constitutes the grammar of that language. Language-internal generalizations are captured by inheritance relations among constructions. Cross-language generalizations are captured by the architecture of the representation system and by the sharing of abstract constructions across languages. The particular grammatical phenomenon used here to introduce construction grammar (CG) is the construction that licenses the surprising syntactic and semantic features of a sentence like What are they doing resuscitating constructions?"
            },
            "slug": "Grammatical-constructions-and-linguistic-The-What's-Kay-Fillmore",
            "title": {
                "fragments": [],
                "text": "Grammatical constructions and linguistic generalizations: The What's X doing Y? construction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145036961"
                        ],
                        "name": "Graeme Hirst",
                        "slug": "Graeme-Hirst",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Hirst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graeme Hirst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1213247,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a19c77ef0d000a61c9f26a2f9b96dc0d2379c48c",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The tasks of disambiguating words and determining case are similar and can usefully be combined. We present two cooperating mechanisms that each work on both tasks: MARKER PASSING finds connections between concepts in a system of frames, and POLAROID WORDS provide a protocol for negotiation between ambiguous words and cases. Examples of each in action are given. The cooperating mechanisms allow linguistic and world knowledge to be unified, frequently eliminate the need to use inference in disambiguation, and provide a usefully constrained model of disambiguation."
            },
            "slug": "Word-Sense-and-Case-Slot-Disambiguation-Hirst-Charniak",
            "title": {
                "fragments": [],
                "text": "Word Sense and Case Slot Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Two cooperating mechanisms that each work on both tasks: MARKER PASSING finds connections between concepts in a system of frames, and POLAROID WORDS provide a protocol for negotiation between ambiguous words and cases are presented."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9079926"
                        ],
                        "name": "W. Woods",
                        "slug": "W.-Woods",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Woods",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Woods"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1478831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09296827532a91527396edfac76461fb5e10377a",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Semantics-and-Quantification-in-Natural-Language-Woods",
            "title": {
                "fragments": [],
                "text": "Semantics and Quantification in Natural Language Question Answering"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 626195,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e78155b28b1f4db52a7c9076c89e81ac4b7d8ce",
            "isKey": false,
            "numCitedBy": 284,
            "numCiting": 100,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional natural language parsers are based on rewrite rule systems developed in an arduous, time-consuming manner by grammarians. A majority of the grammarian's efforts are devoted to the disambiguation process, first hypothesizing rules which dictate constituent categories and relationships among words in ambiguous sentences, and then seeking exceptions and corrections to these rules. \nIn this work, I propose an automatic method for acquiring a statistical parser from a set of parsed sentences which takes advantage of some initial linguistic input, but avoids the pitfalls of the iterative and seemingly endless grammar development process. Based on distributionally-derived and linguistically-based features of language, this parser acquires a set of statistical decision trees which assign a probability distribution on the space of parse trees given the input sentence. These decision trees take advantage of significant amount of contextual information, potentially including all of the lexical information in the sentence, to produce highly accurate statistical models of the disambiguation process. By basing the disambiguation criteria selection on entropy reduction rather than human intuition, this parser development method is able to consider more sentences than a human grammarian can when making individual disambiguation rules. \nIn experiments between a parser, acquired using this statistical framework, and a grammarian's rule-based parser, developed over a ten-year period, both using the same training material and test sentences, the decision tree parser significantly outperformed the grammar-based parser on the accuracy measure which the grammarian was trying to maximize, achieving an accuracy of 78% compared to the grammar-based parser's 69%."
            },
            "slug": "Natural-Language-Parsing-as-Statistical-Pattern-Magerman",
            "title": {
                "fragments": [],
                "text": "Natural Language Parsing as Statistical Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes an automatic method for acquiring a statistical parser from a set of parsed sentences which takes advantage of some initial linguistic input, but avoids the pitfalls of the iterative and seemingly endless grammar development process."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145002066"
                        ],
                        "name": "D. Younger",
                        "slug": "D.-Younger",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Younger",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Younger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 40504606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30da8ecce8b3ebc3e9344a79e5c2f8dc4c423bd2",
            "isKey": false,
            "numCitedBy": 1035,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recognition-and-Parsing-of-Context-Free-Languages-Younger",
            "title": {
                "fragments": [],
                "text": "Recognition and Parsing of Context-Free Languages in Time n^3"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1988103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "399da68d3b97218b6c80262df7963baa89dcc71b",
            "isKey": false,
            "numCitedBy": 4998,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "SRILM is a collection of C++ libraries, executable programs, and helper scripts designed to allow both production of and experimentation with statistical language models for speech recognition and other applications. SRILM is freely available for noncommercial purposes. The toolkit supports creation and evaluation of a variety of language model types based on N-gram statistics, as well as several related tasks, such as statistical tagging and manipulation of N-best lists and word lattices. This paper summarizes the functionality of the toolkit and discusses its design and implementation, highlighting ease of rapid prototyping, reusability, and combinability of tools."
            },
            "slug": "SRILM-an-extensible-language-modeling-toolkit-Stolcke",
            "title": {
                "fragments": [],
                "text": "SRILM - an extensible language modeling toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The functionality of the SRILM toolkit is summarized and its design and implementation is discussed, highlighting ease of rapid prototyping, reusability, and combinability of tools."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26325371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c0f99e72bd539171a4dedcffd0e0a424ad3aad6",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : A description is given of a sophisticated computer program for the syntactic analysis of natural languages. The study discusses the notation used to write rules and the extent to which these rules can be made to state the same linguistic facts as a transformational grammar. Whereas most existing programs apply context-free phrase-structure grammars, this new program can analyze sentences with context-sensitive grammars and with grammars of a class very similar to transformational grammars. The program, which is written for the IBM 7040/44 computer, is nondeterministic: The various interpretations of an ambiguous sentence are all worked on simultaneously; at no stage does the program develop one interpretation rather than another. If two interpretations differ only in some small part of a partial syntactic structure, then only one complete structure is stored with two versions of the ambiguous part. The unambiguous portion is worked on only once for both interpretations. Although the current version of the program is written in ALGOL, with very little regard for efficiency, the basic algorithm is inherently much more efficient than any of its competitors. (Author)"
            },
            "slug": "Experiments-With-a-Powerful-Parser-Kay",
            "title": {
                "fragments": [],
                "text": "Experiments With a Powerful Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The study discusses the notation used to write rules and the extent to which these rules can be made to state the same linguistic facts as a transformational grammar."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707726"
                        ],
                        "name": "J. Pustejovsky",
                        "slug": "J.-Pustejovsky",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Pustejovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pustejovsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7129257,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "cae22af9bb9b7a2cebe2b4ee0a0364004ab73491",
            "isKey": false,
            "numCitedBy": 3805,
            "numCiting": 161,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, I will discuss four major topics relating to current research in lexical semantics: methodology, descriptive coverage, adequacy of the representation, and the computational usefulness of representations. In addressing these issues, I will discuss what I think are some of the central problems facing the lexical semantics community, and suggest ways of best approaching these issues. Then, I will provide a method for the decomposition of lexical categories and outline a theory of lexical semantics embodying a notion of cocompositionality and type coercion, as well as several levels of semantic description, where the semantic load is spread more evenly throughout the lexicon. I argue that lexical decomposition is possible if it is performed generatively. Rather than assuming a fixed set of primitives. I will assume a fixed number of generative devices that can be seen as constructing semantic expressions. I develop a theory of Qualia Structure, a representation language for lexical items, which renders much lexical ambiguity in the lexicon unnecessary, while still explaining the systematic polysemy that words carry. Finally, I discuss how individual lexical structures can be integrated into the larger lexical knowledge base through a theory of lexical inheritance. This provides us with the necessary principles of global organization for the lexicon, enabling us to fully integrate our natural language lexicon into a conceptual whole."
            },
            "slug": "The-Generative-Lexicon-Pustejovsky",
            "title": {
                "fragments": [],
                "text": "The Generative Lexicon"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is argued that lexical decomposition is possible if it is performed generatively and a theory of lexical inheritance is outlined, which provides the necessary principles of global organization for the lexicon, enabling us to fully integrate the authors' natural language lexicon into a conceptual whole."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145043214"
                        ],
                        "name": "Jason Eisner",
                        "slug": "Jason-Eisner",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Eisner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Eisner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3262717,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "adfef97814b292a09520d8c78a141e7a4baf8726",
            "isKey": false,
            "numCitedBy": 728,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "After presenting a novel O(n3) parsing algorithm for dependency grammar, we develop three contrasting ways to stochasticize it. We propose (a) a lexical affinity model where words struggle to modify each other, (b) a sense tagging model where words fluctuate randomly in their selectional preferences, and (c) a generative model where the speaker fleshes out each word's syntactic and conceptual structure without regard to the implications for the hearer. We also give preliminary empirical results from evaluating the three models' parsing performance on annotated Wall Street Journal training text (derived from the Penn Treebank). In these results, the generative model performs significantly better than the others, and does about equally well at assigning part-of-speech tags."
            },
            "slug": "Three-New-Probabilistic-Models-for-Dependency-An-Eisner",
            "title": {
                "fragments": [],
                "text": "Three New Probabilistic Models for Dependency Parsing: An Exploration"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Preliminary empirical results from evaluating the three models' parsing performance on annotated Wall Street Journal training text (derived from the Penn Treebank) suggest the generative model performs significantly better than the others, and does about equally well at assigning part-of-speech tags."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2971978"
                        ],
                        "name": "Y. Wilks",
                        "slug": "Y.-Wilks",
                        "structuredName": {
                            "firstName": "Yorick",
                            "lastName": "Wilks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wilks"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20577265,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed57a5b47a16ed1e0d6f0b3d061a4af24dd5675f",
            "isKey": false,
            "numCitedBy": 390,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Preferential,-Pattern-Seeking,-Semantics-for-Wilks",
            "title": {
                "fragments": [],
                "text": "A Preferential, Pattern-Seeking, Semantics for Natural Language Inference"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14789841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4775e2f0d27e8be4aae7b5b5c2560b96ce2eb58",
            "isKey": false,
            "numCitedBy": 1403,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech recognition is formulated as a problem of maximum likelihood decoding. This formulation requires statistical models of the speech production process. In this paper, we describe a number of statistical models for use in speech recognition. We give special attention to determining the parameters for such models from sparse data. We also describe two decoding methods, one appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks. To illustrate the usefulness of the methods described, we review a number of decoding results that have been obtained with them."
            },
            "slug": "A-Maximum-Likelihood-Approach-to-Continuous-Speech-Bahl-Jelinek",
            "title": {
                "fragments": [],
                "text": "A Maximum Likelihood Approach to Continuous Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper describes a number of statistical models for use in speech recognition, with special attention to determining the parameters for such models from sparse data, and describes two decoding methods appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2393013"
                        ],
                        "name": "I. Sag",
                        "slug": "I.-Sag",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Sag",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144741427"
                        ],
                        "name": "C. Pollard",
                        "slug": "C.-Pollard",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Pollard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Pollard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14500645,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3cee61e41731adb3356233aed2a9b33c2280683b",
            "isKey": false,
            "numCitedBy": 4234,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This book presents the most complete exposition of the theory of head-driven phrase structure grammar (HPSG), introduced in the authors' \"Information-Based Syntax and Semantics.\" HPSG provides an integration of key ideas from the various disciplines of cognitive science, drawing on results from diverse approaches to syntactic theory, situation semantics, data type theory, and knowledge representation. The result is a conception of grammar as a set of declarative and order-independent constraints, a conception well suited to modelling human language processing. This self-contained volume demonstrates the applicability of the HPSG approach to a wide range of empirical problems, including a number which have occupied center-stage within syntactic theory for well over twenty years: the control of \"understood\" subjects, long-distance dependencies conventionally treated in terms of \"wh\"-movement, and syntactic constraints on the relationship between various kinds of pronouns and their antecedents. The authors make clear how their approach compares with and improves upon approaches undertaken in other frameworks, including in particular the government-binding theory of Noam Chomsky."
            },
            "slug": "Head-driven-phrase-structure-grammar-Sag-Pollard",
            "title": {
                "fragments": [],
                "text": "Head-driven phrase structure grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This book presents the most complete exposition of the theory of head-driven phrase structure grammar, introduced in the authors' \"Information-Based Syntax and Semantics,\" and demonstrates the applicability of the HPSG approach to a wide range of empirical problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6922975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cb09327e68400bf05e6f373e046a3a08e82510e",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In many applications of natural language processing it is necessary to determine the likelihood of a given word combination. For example, a speech recognizer may need to determine which of the two word combinations \"eat a peach\" and \"eat a beach\" is more likely. Statistical NLP methods determine the likelihood of a word combination according to its frequency in a training corpus. However, the nature of language is such that many word combinations are infrequent and do not occur in a given corpus. In this work we propose a method for estimating the probability of such previously unseen word combinations using available information on \"most similar\" words.We describe a probabilistic word association model based on distributional word similarity, and apply it to improving probability estimates for unseen word bigrams in a variant of Katz's back-off model. The similarity-based method yields a 20% perplexity improvement in the prediction of unseen bigrams and statistically significant reductions in speech-recognition error."
            },
            "slug": "Similarity-Based-Estimation-of-Word-Cooccurrence-Dagan-Pereira",
            "title": {
                "fragments": [],
                "text": "Similarity-Based Estimation of Word Cooccurrence Probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A probabilistic word association model based on distributional word similarity is described, and it is applied to improving probability estimates for unseen word bigrams in a variant of Katz's back-off model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47927070"
                        ],
                        "name": "A. H. Kawamoto",
                        "slug": "A.-H.-Kawamoto",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Kawamoto",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. H. Kawamoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118585972,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3107651f0f2ec7a6e6b713d820f5e083b6446c8d",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Distributed-Representations-of-Ambiguous-Words-and-Kawamoto",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Ambiguous Words and Their Resolution in a Connectionist Network"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054613249"
                        ],
                        "name": "Swaminathan Madhu",
                        "slug": "Swaminathan-Madhu",
                        "structuredName": {
                            "firstName": "Swaminathan",
                            "lastName": "Madhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Swaminathan Madhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2635086"
                        ],
                        "name": "D. Lytle",
                        "slug": "D.-Lytle",
                        "structuredName": {
                            "firstName": "Dean",
                            "lastName": "Lytle",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lytle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 40019750,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "066e1392a24c4faea32021bc736bc7c95e856ad1",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Ambiguity in language translation is due to the presence of words in the source language with multiple non-synonymous target equivalents. A contextual analysis is required whenever a grammatical analysis fails to resolve such ambiguity. In the case of scientific and engineering literature, clues to the context can be obtained from a knowledge of the varying degrees of probability with which words occur in different fields of science. A figure of merit is defined, which is calculated from the probability of word occurrences, and which leads to the choice of a particular target equivalent of a word as the most probably correct one. The results of applying the technique to a set of twenty one Russian sentences indicate that the technique can be successful in about 90% of the cases. The technique can easily be adapted for use by a computer."
            },
            "slug": "A-figure-of-merit-technique-for-the-resolution-of-Madhu-Lytle",
            "title": {
                "fragments": [],
                "text": "A figure of merit technique for the resolution of non-grammatical ambiguity"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The results of applying the technique to a set of twenty one Russian sentences indicate that the technique can be successful in about 90% of the cases and can easily be adapted for use by a computer."
            },
            "venue": {
                "fragments": [],
                "text": "Mech. Transl. Comput. Linguistics"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145036961"
                        ],
                        "name": "Graeme Hirst",
                        "slug": "Graeme-Hirst",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Hirst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graeme Hirst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6258799,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "2e460ca2dd591fdbd6c3310661896dd0a1c21fc0",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Resolving-Lexical-Ambiguity-Computationally-with-Hirst",
            "title": {
                "fragments": [],
                "text": "Resolving Lexical Ambiguity Computationally with Spreading Activation and Polaroid Words"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36037226"
                        ],
                        "name": "R\u00e9jean Ducharme",
                        "slug": "R\u00e9jean-Ducharme",
                        "structuredName": {
                            "firstName": "R\u00e9jean",
                            "lastName": "Ducharme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9jean Ducharme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120247189"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1909943744"
                        ],
                        "name": "Christian Janvin",
                        "slug": "Christian-Janvin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Janvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Janvin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 221275765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c2b28f9354f667cd5bd07afc0471d8334430da7",
            "isKey": false,
            "numCitedBy": 6014,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts."
            },
            "slug": "A-Neural-Probabilistic-Language-Model-Bengio-Ducharme",
            "title": {
                "fragments": [],
                "text": "A Neural Probabilistic Language Model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8089863"
                        ],
                        "name": "R. Cole",
                        "slug": "R.-Cole",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Cole",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47263765"
                        ],
                        "name": "D. Novick",
                        "slug": "D.-Novick",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Novick",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Novick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35941561"
                        ],
                        "name": "Pieter J. E. Vermeulen",
                        "slug": "Pieter-J.-E.-Vermeulen",
                        "structuredName": {
                            "firstName": "Pieter",
                            "lastName": "Vermeulen",
                            "middleNames": [
                                "J.",
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pieter J. E. Vermeulen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060185505"
                        ],
                        "name": "Stephen Sutton",
                        "slug": "Stephen-Sutton",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Sutton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681269"
                        ],
                        "name": "M. Fanty",
                        "slug": "M.-Fanty",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Fanty",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fanty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066621920"
                        ],
                        "name": "L. F. A. Wessels",
                        "slug": "L.-F.-A.-Wessels",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Wessels",
                            "middleNames": [
                                "F.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. F. A. Wessels"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73598336"
                        ],
                        "name": "J. Villiers",
                        "slug": "J.-Villiers",
                        "structuredName": {
                            "firstName": "Jacques",
                            "lastName": "Villiers",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Villiers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698491"
                        ],
                        "name": "J. Schalkwyk",
                        "slug": "J.-Schalkwyk",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Schalkwyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schalkwyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064554176"
                        ],
                        "name": "Brian Hansen",
                        "slug": "Brian-Hansen",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Hansen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Hansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40472905"
                        ],
                        "name": "D. Burnett",
                        "slug": "D.-Burnett",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Burnett",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burnett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 24072012,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2445ed8f63b3ff19eba812ae6e48e504263500c3",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Experiments-with-a-spoken-dialogue-system-for-the-Cole-Novick",
            "title": {
                "fragments": [],
                "text": "Experiments with a spoken dialogue system for taking the US census"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35371521"
                        ],
                        "name": "Kristina Toutanvoa",
                        "slug": "Kristina-Toutanvoa",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanvoa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanvoa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10807721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1504a9d5829033a8cb4cf37b8bb13dfd4baddc7b",
            "isKey": false,
            "numCitedBy": 1574,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents results for a maximum-entropy-based part of speech tagger, which achieves superior performance principally by enriching the information sources used for tagging. In particular, we get improved results by incorporating these features: (i) more extensive treatment of capitalization for unknown words; (ii) features for the disambiguation of the tense forms of verbs; (iii) features for disambiguating particles from prepositions and adverbs. The best resulting accuracy for the tagger on the Penn Treebank is 96.86% overall, and 86.91% on previously unseen words."
            },
            "slug": "Enriching-the-Knowledge-Sources-Used-in-a-Maximum-Toutanvoa-Manning",
            "title": {
                "fragments": [],
                "text": "Enriching the Knowledge Sources Used in a Maximum Entropy Part-of-Speech Tagger"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This paper presents results for a maximum-entropy-based part of speech tagger, which achieves superior performance principally by enriching the information sources used for tagging by incorporating these features: more extensive treatment of capitalization for unknown words, and features for the disambiguation of the tense forms of verbs."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52800448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "084c55d6432265785e3ff86a2e900a49d501c00a",
            "isKey": false,
            "numCitedBy": 7803,
            "numCiting": 294,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications."
            },
            "slug": "Foundations-of-statistical-natural-language-Manning-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Foundations of statistical natural language processing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear and provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050344"
                        ],
                        "name": "Lisa Stifelman",
                        "slug": "Lisa-Stifelman",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Stifelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lisa Stifelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1931458"
                        ],
                        "name": "B. Arons",
                        "slug": "B.-Arons",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Arons",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Arons"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729321"
                        ],
                        "name": "C. Schmandt",
                        "slug": "C.-Schmandt",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Schmandt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmandt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2492319"
                        ],
                        "name": "Eric A. Hulteen",
                        "slug": "Eric-A.-Hulteen",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Hulteen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric A. Hulteen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1629532,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "1a33971cf4a97e0d9bb0927650946703037e5a14",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "VoiceNotes is an application for a voice-controlled hand-held computer that allows the creation, management, and retrieval of user-authored voice notes\u2014small segments of digitized speech containing thoughts, ideas, reminders, or things to do. Iterative design and user testing helped to refine the initial user interface design. VoiceNotes explores the problem of capturing and retrieving spontaneous ideas, the use of speech as data, and the use of speech input and output in the user interface for a hand-held computer without a visual display. In addition, VoiceNotes serves as a step toward new uses of voice technology and interfaces for future portable devices."
            },
            "slug": "VoiceNotes:-a-speech-interface-for-a-hand-held-Stifelman-Arons",
            "title": {
                "fragments": [],
                "text": "VoiceNotes: a speech interface for a hand-held voice notetaker"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "VoiceNotes explores the problem of capturing and retrieving spontaneous ideas, the use of speech as data, and theUse of speech input and output in the user interface for a hand-held computer without a visual display."
            },
            "venue": {
                "fragments": [],
                "text": "CHI '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 252796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "isKey": false,
            "numCitedBy": 8177,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant."
            },
            "slug": "Building-a-Large-Annotated-Corpus-of-English:-The-Marcus-Santorini",
            "title": {
                "fragments": [],
                "text": "Building a Large Annotated Corpus of English: The Penn Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "As a result of this grant, the researchers have now published on CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, which includes a fully hand-parsed version of the classic Brown corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144461837"
                        ],
                        "name": "C. Shannon",
                        "slug": "C.-Shannon",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Shannon",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Shannon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9101213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1e3f2d537e50e0d5263e4731ab6c7983acd6687",
            "isKey": false,
            "numCitedBy": 2530,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of estimating the entropy and redundancy of a language is described. This method exploits the knowledge of the language statistics possessed by those who speak the language, and depends on experimental results in prediction of the next letter when the preceding text is known. Results of experiments in prediction are given, and some properties of an ideal predictor are developed."
            },
            "slug": "Prediction-and-entropy-of-printed-English-Shannon",
            "title": {
                "fragments": [],
                "text": "Prediction and entropy of printed English"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A new method of estimating the entropy and redundancy of a language is described, which exploits the knowledge of the language statistics possessed by those who speak the language, and depends on experimental results in prediction of the next letter when the preceding text is known."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1951
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2783947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "553fa529ba615e4bddea81e9a231ae19d5a870a4",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We have recently reported on two new word-sense disambiguation systems, one trained on bilingual material (the Canadian Hansards) and the other trained on monolingual material (Roget's Thesaurus and Grolier's Encyclopedia). After using both the monolingual and bilingual classifiers for a few months, we have convinced ourselves that the performance is remarkably good. Nevertheless, we would really like to be able to make a stronger statement, and therefore, we decided to try to develop some more objective evaluation measures. Although there has been a fair amount of literature on sense-disambiguation, the literature does not offer much guidance in how we might establish the success or failure of a proposed solution such as the two systems mentioned in the previous paragraph. Many papers avoid quantitative evaluations altogether, because it is so difficult to come up with credible estimates of performance.This paper will attempt to establish upper and lower bounds on the level of performance that can be expected in an evaluation. An estimate of the lower bound of 75% (averaged over ambiguous types) is obtained by measuring the performance produced by a baseline system that ignores context and simply assigns the most likely sense in all cases. An estimate of the upper bound is obtained by assuming that our ability to measure performance is largely limited by our ability obtain reliable judgments from human informants. Not surprisingly, the upper bound is very dependent on the instructions given to the judges. Jorgensen, for example, suspected that lexicographers tend to depend too much on judgments by a single informant and found considerable variation over judgments (only 68% agreement), as she had suspected. In our own experiments, we have set out to find word-sense disambiguation tasks where the judges can agree often enough so that we could show that they were outperforming the baseline system. Under quite different conditions, we have found 96.8% agreement over judges."
            },
            "slug": "Estimating-Upper-and-Lower-Bounds-on-the-of-Gale-Church",
            "title": {
                "fragments": [],
                "text": "Estimating Upper and Lower Bounds on the Performance of Word-Sense Disambiguation Programs"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper will attempt to establish upper and lower bounds on the level of performance that can be expected in an evaluation, and finds that the upper bound is very dependent on the instructions given to the judges."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121808836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef9190e7669ea5523c3ef61180b35385b0ea345f",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-comparison-of-the-enhanced-Good-Turing-and-for-of-Church-Gale",
            "title": {
                "fragments": [],
                "text": "A comparison of the enhanced Good-Turing and deleted estimation methods for estimating probabilities of English bigrams"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710580"
                        ],
                        "name": "A. Berger",
                        "slug": "A.-Berger",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Berger",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1085832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb486e03369a64de2d5b0df86ec0a7b55d3907db",
            "isKey": false,
            "numCitedBy": 3452,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The concept of maximum entropy can be traced back along multiple threads to Biblical times. Only recently, however, have computers become powerful enough to permit the widescale application of this concept to real world problems in statistical estimation and pattern recognition. In this paper, we describe a method for statistical modeling based on maximum entropy. We present a maximum-likelihood approach for automatically constructing maximum entropy models and describe how to implement this approach efficiently, using as examples several problems in natural language processing."
            },
            "slug": "A-Maximum-Entropy-Approach-to-Natural-Language-Berger-Pietra",
            "title": {
                "fragments": [],
                "text": "A Maximum Entropy Approach to Natural Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A maximum-likelihood approach for automatically constructing maximum entropy models is presented and how to implement this approach efficiently is described, using as examples several problems in natural language processing."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3530486"
                        ],
                        "name": "R. Darnell",
                        "slug": "R.-Darnell",
                        "structuredName": {
                            "firstName": "R\u00e9gna",
                            "lastName": "Darnell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Darnell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215102261,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "5839ad026ee43f3b72493c416dddb4203791714d",
            "isKey": false,
            "numCitedBy": 861,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "?well worth reproducing in English.?Edts., I. M. Gazette.] On the loss of the epithelium of the intestinal canal, consequent on the excessive secretion of fluid from its surface. We are all well acquainted with the fact, that in certain diseases the outer layers of the epithelial cells protecting the skin are thrown off in flakes ; and I believe that it is the same in Asiatic cholera as regards epithelial cells lining the surface of the jntestinal mucous membrane?a matter of greater pathological significance than that concerning the skin, because the intestinal epithelium is intended to guard more delicate and important structures than the cells that cover the cutis. The symptoms of cholera, however, are very much dependent on this desquamation of the epithelia?a fact which may be demonstrated by the aid of the microscope; but we are not to suppose that all parts of the intestinal canal are equally affected in cholera. The epithelium of the stomach suffers less than that of the intestines, and the upper part of the small intestines is not so deeply involved in the disease as the lower part of the ileum. In the duodenum, where the peristaltic action of the canal is not very strong, you often find the epithelial cells lining the mucous membrane ; the cells are loosened, but riot detached, because this part of the canal has less mechanical work to do than the lower portion of the gut. The valvulae conniventes (kerkring), which are large and closely approximated in the second part of the duodenum, protect by covering in the epithelial celh that lie between them, but on the surface of these folds wo shall observe the commencement of the desquamative process which is so marked in the ileum. We shall see with the naked eye that the epithelium, which should cover the valvulae conniventes, has disappeared in places, leaving small isolated patches of the denuded mucous membrane. In their early stages, these spots are distinguishable by their whiter colour, and by a soft velvet-like texture, which may be well demonstrated if a spot of this kind is isolates1, and fixed on a plate under the object glass of the microscope, little water being allowed to trickle over it. You may also in this way examine the villi, which are clearly denuded of epithelial cells in the patches of the valvulae conniventes above referred to. In some parts wo notice that a space evidently extends through the length of the villi, and externally the villi are covered"
            },
            "slug": "Translation-Darnell",
            "title": {
                "fragments": [],
                "text": "Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This chapter discusses the loss of the epithelium of the intestinal canal, consequent on the excessive secretion of fluid from its surface, and examines the villi, which are clearly denuded of epithelial cells in the patches of the valvulae conniventes above referred to."
            },
            "venue": {
                "fragments": [],
                "text": "The Indian medical gazette"
            },
            "year": 1873
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784519"
                        ],
                        "name": "Peter Norvig",
                        "slug": "Peter-Norvig",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Norvig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Norvig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7752112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "824124343b305f1423e354f3a1cb66856b2efb6d",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that a process similar to Earley's algorithm can be generated by a simple top-down backtracking parser, when augmented by automatic memoization. The memoized parser has the same complexity as Earley's algorithm, but parses constituents in a different order. Techniques for deriving memo functions are described, with a complete implementation in Common Lisp, and an outline of a macro-based approach for other languages. 1. Memoization The term memoization was coined by Donald Michie (1968) to refer to the process by which a function is made to automatically remember the results of previous computations. The idea has become more popular in recent years with the rise of functional languages; Field and Harrison (1988) devote a whole chapter to it. The basic idea is just to keep a table of previously computed input/result pairs. In Common Lisp one could write: 1"
            },
            "slug": "Techniques-for-Automatic-Memoization-with-to-Norvig",
            "title": {
                "fragments": [],
                "text": "Techniques for Automatic Memoization with Applications to Context-Free Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "It is shown that a process similar to Earley's algorithm can be generated by a simple top-down backtracking parser, when augmented by automatic memoization."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35551590"
                        ],
                        "name": "Steven P. Abney",
                        "slug": "Steven-P.-Abney",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Abney",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven P. Abney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9716882,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "56d7826f3afaa374077f87ca3529709b1ca7e044",
            "isKey": false,
            "numCitedBy": 992,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "I begin with an intuition: when I read a sentence, I read it a chunk at a time. For example, the previous sentence breaks up something like this: \n \n(1) \n \n[I begin] [with an intuition]: [when I read] [a sentence], [I read it] [a chunk] [at a time] \n \n \n \n \n \n \nThese chunks correspond in some way to prosodic patterns. It appears, for instance, that the strongest stresses in the sentence fall one to a chunk, and pauses are most likely to fall between chunks. Chunks also represent a grammatical watershed of sorts. The typical chunk consists of a single content word surrounded by a constellation of function words, matching a fixed template. A simple context-free grammar is quite adequate to describe the structure of chunks. By contrast, the relationships between chunks are mediated more by lexical selection than by rigid templates. Co-occurrence of chunks is determined not just by their syntactic categories, but is sensitive to the precise words that head them; and the order in which chunks occur is much more flexible than the order of words within chunks."
            },
            "slug": "Parsing-By-Chunks-Abney",
            "title": {
                "fragments": [],
                "text": "Parsing By Chunks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The typical chunk consists of a single content word surrounded by a constellation of function words, matching a fixed template, and the relationships between chunks are mediated more by lexical selection than by rigid templates."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708531"
                        ],
                        "name": "N. Yankelovich",
                        "slug": "N.-Yankelovich",
                        "structuredName": {
                            "firstName": "Nicole",
                            "lastName": "Yankelovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Yankelovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733034"
                        ],
                        "name": "Gina-Anne Levow",
                        "slug": "Gina-Anne-Levow",
                        "structuredName": {
                            "firstName": "Gina-Anne",
                            "lastName": "Levow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gina-Anne Levow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40464784"
                        ],
                        "name": "Matthew Marx",
                        "slug": "Matthew-Marx",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Marx",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Marx"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9313029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc0c476feb6fe1b3257f99b555f82f8ae51d2edf",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "SpeechActs is an experimental conversational speech system. Experience with redesigning the system based on user feedback indicates the importance of adhering to conversational conventions when designing speech interfaces, particularly in the face of speech recognition errors. Study results also suggest that speech-only interfaces should be designed from scratch rather than directly translated from their graphical counterparts. This paper examines a set of challenging issues facing speech interface designers and describes approaches to address some of these challenges."
            },
            "slug": "Designing-SpeechActs:-issues-in-speech-user-Yankelovich-Levow",
            "title": {
                "fragments": [],
                "text": "Designing SpeechActs: issues in speech user interfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A set of challenging issues facing speech interface designers is examined and approaches to address some of these challenges are described, including adhering to conversational conventions."
            },
            "venue": {
                "fragments": [],
                "text": "CHI '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35400286"
                        ],
                        "name": "Z. Harris",
                        "slug": "Z.-Harris",
                        "structuredName": {
                            "firstName": "Zellig",
                            "lastName": "Harris",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Harris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32164517,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "99eadd5e29a85f30cafef7f2c915f384715e3b89",
            "isKey": false,
            "numCitedBy": 986,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We may not be able to make you love reading, but mathematical structures of language will lead you to love reading starting from now. Book is the window to open the new world. The world that you want is in the better stage and level. World will always guide you to even the prestige stage of the life. You know, this is some of how reading will give you the kindness. In this case, more books you read more knowledge you know, but it can mean also the bore is full."
            },
            "slug": "Mathematical-structures-of-language-Harris",
            "title": {
                "fragments": [],
                "text": "Mathematical structures of language"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors may not be able to make you love reading, but mathematical structures of language will lead you to love reading starting from now."
            },
            "venue": {
                "fragments": [],
                "text": "Interscience tracts in pure and applied mathematics"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746503"
                        ],
                        "name": "A. Kilgarriff",
                        "slug": "A.-Kilgarriff",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Kilgarriff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kilgarriff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17882545,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "2cabf50c382d4dd5ee06e498d1de7daddb646ab1",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The English lexical sample task (adjectives and nouns) for SENSEVAL 2 was set up according to the same principles as for SENSEVAL-1, as reported in (Kilgarriff and Rosenzweig, 2000). (Adjectives and nouns only, because the data preparation for the verbs lexical sample was undertaken alongside that for the English all-words task, and is reported in Palmer et al (this volume). All discussion below up to the Results section covers only adjectives and nouns.)"
            },
            "slug": "English-Lexical-Sample-Task-Description-Kilgarriff",
            "title": {
                "fragments": [],
                "text": "English Lexical Sample Task Description"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The English lexical sample task (adjectives and nouns) for SenseVAL 2 was set up according to the same principles as for SENSEVAL-1, as reported in (Kilgarriff and Rosenzweig, 2000)."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744313"
                        ],
                        "name": "L. Ramshaw",
                        "slug": "L.-Ramshaw",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Ramshaw",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ramshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 725590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9c71db75046473f0e3d3229950d7c84c09afd5e",
            "isKey": false,
            "numCitedBy": 1530,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Transformation-based learning, a technique introduced by Eric Brill (1993b), has been shown to do part-of-speech tagging with fairly high accuracy. This same method can be applied at a higher level of textual interpretation for locating chunks in the tagged text, including non-recursive \u201cbaseNP\u201d chunks. For this purpose, it is convenient to view chunking as a tagging problem by encoding the chunk structure in new tags attached to each word. In automatic tests using Treebank-derived data, this technique achieved recall and precision rates of roughly 93% for baseNP chunks (trained on 950K words) and 88% for somewhat more complex chunks that partition the sentence (trained on 200K words). Working in this new application and with larger template and training sets has also required some interesting adaptations to the transformation-based learning approach."
            },
            "slug": "Text-Chunking-using-Transformation-Based-Learning-Ramshaw-Marcus",
            "title": {
                "fragments": [],
                "text": "Text Chunking using Transformation-Based Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work has shown that the transformation-based learning approach can be applied at a higher level of textual interpretation for locating chunks in the tagged text, including non-recursive \u201cbaseNP\u201d chunks."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612754"
                        ],
                        "name": "T. Kasami",
                        "slug": "T.-Kasami",
                        "structuredName": {
                            "firstName": "Tadao",
                            "lastName": "Kasami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kasami"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61491815,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af66165c454a0e94afbab36271fe3deaae0b421a",
            "isKey": false,
            "numCitedBy": 608,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : An efficient algorithm of recognition and syntaxanalysis for the full class of context-free languages without the difficulty of exponential growth of computing time with the length n of input sequence is presented. This algorithm makes use of the essential property of a context-free language as a multi-parenthesis system. It is shown in this paper that a context-free language is n cubed-recognizable in the sense of Hartmanis and Stearns ('Computational complexity of recursive sequences'. Proc. Fifth Annual Symposium of Switching Circuit Theory and Logical Design (Oct. 1964) p.82-90) by a double-tape or double-head single-tape Turing machine and it is n to the 4th power-recognizable by a single-head single-tape Turing machine. If we use a random-access memory whose size is proportional to n cubed, the computing time required for syntaxanalysis is upperbounded by C(1)n cubed + C(2)n squared N, where N denotes the number of nonequivalent valid derivation sequences for a given input sequence and C(i)'s are constants independent of input sequences. If we use a tape of length C(3)n cubed and one of length C(4)n squared as working memories, the computing time for syntax-analysis is upperbounded by C(5)n cubed (1 + N). The size of required memory can be reduced to the order of n squared, but the computing time rises to the order of n to the 4th power. (Author)"
            },
            "slug": "An-Efficient-Recognition-and-Syntax-Analysis-for-Kasami",
            "title": {
                "fragments": [],
                "text": "An Efficient Recognition and Syntax-Analysis Algorithm for Context-Free Languages"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown in this paper that a context-free language is n cubed-recognizable in the sense of Hartmanis and Stearns and it is n to the 4th power- Recognizable by a single-head single-tape Turing machine."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6713452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5eb328cf7e94995199e4c82a1f4d0696430a80b5",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data."
            },
            "slug": "Distributional-Clustering-of-English-Words-Pereira-Tishby",
            "title": {
                "fragments": [],
                "text": "Distributional Clustering of English Words"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deterministic annealing is used to find lowest distortion sets of clusters: as the annealed parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144756036"
                        ],
                        "name": "A. Radford",
                        "slug": "A.-Radford",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Radford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18221254,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "0fb41ae61b45c353be77ce448168b2c7ca42f320",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface 1. Principles and parameters 2. Categories and features 3. Syntactic structure 4. Empty categories 5. Checking 6. Head movement 7. Operator movement 8. A movement 9. VP shells 10. Agreement projections Glossary and list of abbreviations References Index."
            },
            "slug": "Syntactic-Theory-and-the-Structure-of-English:-A-Radford",
            "title": {
                "fragments": [],
                "text": "Syntactic Theory and the Structure of English: A Minimalist Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This chapter discusses categories, features, and operators of the VP shell, and some of the techniques used to derive these categories and features are described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16902271"
                        ],
                        "name": "H. P. Luhn",
                        "slug": "H.-P.-Luhn",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Luhn",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. P. Luhn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15879823,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "076077a5771747ad7355120f1ba64cfd603141c6",
            "isKey": false,
            "numCitedBy": 964,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Written communication of ideas is carried out on the basis of statistical probability in that a writer chooses that level of subject specificity and that combination of words which he feels will convey the most meaning. Since this process varies among individuals and since similar ideas are therefore relayed at different levels of specificity and by means of different words, the problem of literature searching by machines still presents major difficulties. A statistical approach to this problem will be outlined and the various steps of a system based on this approach will be described. Steps include the statistical analysis of a collection of documents in a field of interest, the establishment of a set of \"notions\" and the vocabulary by which they are expressed, the compilation of a thesaurus-type dictionary and index, the automatic encoding of documents by machine with the aid of such a dictionary, the encoding of topological notations (such as branched structures), the recording of the coded information, the establishment of a searching pattern for finding pertinent information, and the programming of appropriate machines to carry out a search."
            },
            "slug": "A-Statistical-Approach-to-Mechanized-Encoding-and-Luhn",
            "title": {
                "fragments": [],
                "text": "A Statistical Approach to Mechanized Encoding and Searching of Literary Information"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The problem of literature searching by machines still presents major difficulties and a statistical approach to this problem will be outlined and the various steps of a system based on this approach will be described."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3197827"
                        ],
                        "name": "E. Irons",
                        "slug": "E.-Irons",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Irons",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Irons"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15645135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "caa65e007e44346d790ae888e30b2e02e4b59502",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "i Th(~ disposition of lhe parentheses is computed by numberbig the m ull;iplication signs consecutively. If n is divisible /)y 2 k but, not; by 2 kw, then (;he nt,h multiplication sign is 1-),'ecedcd by k right pat'entheses, and followed by k left parentheses. If the lasi, multiplication sign is numbered m, then the entire expression is surrounded by k parentheses, whore 2 k ~\" Ill. The extension go negative integral expohen Ls is obvious. The rewritLen expressions are compiled in the normal manner, the equivalent subexpressions being a.tttotnat ically recognized. At~ operational translator would require additional tests at sew;ml points to detect s.ymbol strings not allowed by lhc language. Such tests are omitted here for the sake of clariLy in {,he flow charts. A C K N O W L E D G M E N T The author is indebted to Arthur Anger, presently at Harvard University, for many helpful criticisms and suggestions, and for coding the algorithm on the UNiwxc 1105. REFERENCES 1. ERs[~ov: I)roqrammi~q Programme for the BESM Computer. Pergamon, 1959. 2. WI,ZSG'r~N, J. It. From formulas to computer oriented bmguage. Comm. ACM 2 (Mar. 1959), 6-8. 3. Am)i~:N, B., and (]m~m~M, R. On GAT and the construction of trtmslators. Comm. ACM 2 (July 1959), 24-26. 4. KANNER, H. An algebraic translator. Comm. ACM 2 (Oct. 1959), 19-22, 5. SAMELSO~', K., and BA*mR, F. L. Sequential formula translation. Comm. ACM 3 (Feb. 1960), 76-83."
            },
            "slug": "A-syntax-directed-compiler-for-ALGOL-60-Irons",
            "title": {
                "fragments": [],
                "text": "A syntax directed compiler for ALGOL 60"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The author's algorithm is indebted to Arthur Anger, presently at Harvard University, for many helpful criticisms and suggestions, and for coding the algorithm on the UNiwxc 1105."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714374"
                        ],
                        "name": "A. Joshi",
                        "slug": "A.-Joshi",
                        "structuredName": {
                            "firstName": "Aravind",
                            "lastName": "Joshi",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Joshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6970661"
                        ],
                        "name": "Philip Hopely",
                        "slug": "Philip-Hopely",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Hopely",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip Hopely"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1520962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4bdf6c49c0f8b910bcb386ca1668ff51108eaea",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the key aspects of a parser developed at the University of Pennsylvania from 1958 to 1959. The parser is essentially a cascade of finite state transducers. To the best of our knowledge, this is the first application of finite state transducers to parsing. This parser was recently faithfully reconstructed from the original documentation. Many aspects of this program have a close relationship to some of the recent work on finite state transducers."
            },
            "slug": "A-parser-from-antiquity-Joshi-Hopely",
            "title": {
                "fragments": [],
                "text": "A parser from antiquity"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This paper describes the key aspects of a parser developed at the University of Pennsylvania from 1958 to 1959, which is essentially a cascade of finite state transducers."
            },
            "venue": {
                "fragments": [],
                "text": "Nat. Lang. Eng."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3123001"
                        ],
                        "name": "K. Colby",
                        "slug": "K.-Colby",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Colby",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Colby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47864374"
                        ],
                        "name": "S. Weber",
                        "slug": "S.-Weber",
                        "structuredName": {
                            "firstName": "Sylvia",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5981444"
                        ],
                        "name": "F. D. Hilf",
                        "slug": "F.-D.-Hilf",
                        "structuredName": {
                            "firstName": "Franklin",
                            "lastName": "Hilf",
                            "middleNames": [
                                "Dennis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. Hilf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9395521,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "93ae8b487a312fb6bce19d6db220a26e82623b60",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Artificial-Paranoia-Colby-Weber",
            "title": {
                "fragments": [],
                "text": "Artificial Paranoia"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1528142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e44937535d0849412e8042f4fddca5c9dde7da3e",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces context digests, high-dimensional real-valued representations for the typical left and right contexts of a word. Initial entries for the context digests are formed from the word\u2019s close left and right neighbors. A singular value decomposition reduces the dimensionality of the space to enable subsequent efficient processing. In contrast to similar techniques, no preprocessor such as a parser is required. Context digests summarize both syntagmatic and paradigmatic relations between words: how typical they are as neighbors and how well they are substitutable for each other. We apply context digests to identifying collocations, to assessing the similarity of the arguments of different verbs, and to clustering occurrences of adjectives and verbs according to the words they modify in context."
            },
            "slug": "A-Vector-Model-for-Syntagmatic-and-Paradigmatic-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "A Vector Model for Syntagmatic and Paradigmatic Relatedness"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This paper introduces context digests, high-dimensional real-valued representations for the typical left and right contexts of a word that apply to identifying collocations, assessing the similarity of the arguments of different verbs, and to clustering occurrences of adjectives and verbs according to the words they modify in context."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152676840"
                        ],
                        "name": "V. L. Smith",
                        "slug": "V.-L.-Smith",
                        "structuredName": {
                            "firstName": "Vicki",
                            "lastName": "Smith",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. L. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29224904"
                        ],
                        "name": "H. H. Clark",
                        "slug": "H.-H.-Clark",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Clark",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. H. Clark"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 144897050,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "37503a0a272949dd09f26fdf67757b49765fccfa",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract People responding to questions are sometimes uncertain, slow, or unable to answer. They handle these problems of self-presentation, we propose, by the way they respond. Twenty-five respondents were each asked 40 factual questions in a conversational setting. Later, they rated for each question their feeling that they would recognize the correct answer, then took a recognition test on all 40 questions. As found previously, the weaker their feeling of knowing, the slower their answers, the faster their nonanswers (\"I don\u2032t know\"), and the worse their recognition. But further, as proposed, the weaker their feeling of knowing, the more often they answered with rising intonation, used hedges such as \"I guess,\" responded \"I don\u2032t know\" instead of \"I can\u2032t remember,\" and added \"uh\" or \"um,\" self-talk, and other face-saving comments. They reliably used \"uh\" to signal brief delays and \"um\" longer ones."
            },
            "slug": "On-the-Course-of-Answering-Questions-Smith-Clark",
            "title": {
                "fragments": [],
                "text": "On the Course of Answering Questions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760530"
                        ],
                        "name": "M. Walker",
                        "slug": "M.-Walker",
                        "structuredName": {
                            "firstName": "Marilyn",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769629"
                        ],
                        "name": "C. Kamm",
                        "slug": "C.-Kamm",
                        "structuredName": {
                            "firstName": "Candace",
                            "lastName": "Kamm",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kamm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8194846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5940c8bfd16728c5f9bb66e807f78f43dc7a38e4",
            "isKey": false,
            "numCitedBy": 317,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The design of methods for performance evaluation is a major open research issue in the area of spoken language dialogue systems. This paper presents the PARADISE methodology for developing predictive models of spoken dialogue performance, and shows how to evaluate the predictive power and generalizability of such models. To illustrate the methodology, we develop a number of models for predicting system usability (as measured by user satisfaction), based on the application of PARADISE to experimental data from three different spoken dialogue systems. We then measure the extent to which the models generalize across different systems, different experimental conditions, and different user populations, by testing models trained on a subset of the corpus against a test set of dialogues. The results show that the models generalize well across the three systems, and are thus a first approximation towards a general performance model of system usability."
            },
            "slug": "Towards-developing-general-models-of-usability-with-Walker-Kamm",
            "title": {
                "fragments": [],
                "text": "Towards developing general models of usability with PARADISE"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A number of models for predicting system usability (as measured by user satisfaction), based on the application of PARADISE to experimental data from three different spoken dialogue systems, are developed and shown to generalize well."
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Engineering"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144954740"
                        ],
                        "name": "J. Earley",
                        "slug": "J.-Earley",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Earley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Earley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62ea2ef8b7d98cf3a3b912a62a7a42ee82650e6b",
            "isKey": false,
            "numCitedBy": 1339,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "A parsing algorithm which seems to be the most efficient general context-free algorithm known is described. It is similar to both Knuth's LR(<italic>k</italic>) algorithm and the familiar top-down algorithm. It has a time bound proportional to <italic>n</italic><supscrpt>3</supscrpt> (where <italic>n</italic> is the length of the string being parsed) in general; it has an <italic>n</italic><supscrpt>2</supscrpt> bound for unambiguous grammars; and it runs in linear time on a large class of grammars, which seems to include most practical context-free programming language grammars. In an empirical comparison it appears to be superior to the top-down and bottom-up algorithms studied by Griffiths and Petrick."
            },
            "slug": "An-efficient-context-free-parsing-algorithm-Earley",
            "title": {
                "fragments": [],
                "text": "An efficient context-free parsing algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A parsing algorithm which seems to be the most efficient general context-free algorithm known is described and appears to be superior to the top-down and bottom-up algorithms studied by Griffiths and Petrick."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47709773"
                        ],
                        "name": "H. Rubenstein",
                        "slug": "H.-Rubenstein",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Rubenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rubenstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1898344"
                        ],
                        "name": "J. Goodenough",
                        "slug": "J.-Goodenough",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Goodenough",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goodenough"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18309234,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7ef3ac14cdb484aaa2b039850093febd5cf73a21",
            "isKey": false,
            "numCitedBy": 1460,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Experimentol corroboration was obtained for the hypothesis that the proportion of words common to the contexts of word A and to the contexts of word B is a function of the degree to which A and B are similar in meaning. The tests were carried out for variously defined contexts. The shapes of the functions, however, indicate that similarity of context is reliable as criterion only for detecting pairs of words that are very similar in meaning."
            },
            "slug": "Contextual-correlates-of-synonymy-Rubenstein-Goodenough",
            "title": {
                "fragments": [],
                "text": "Contextual correlates of synonymy"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The shapes of the functions indicate that similarity of context is reliable as criterion only for detecting pairs of words that are very similar in meaning."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760530"
                        ],
                        "name": "M. Walker",
                        "slug": "M.-Walker",
                        "structuredName": {
                            "firstName": "Marilyn",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143965889"
                        ],
                        "name": "S. Whittaker",
                        "slug": "S.-Whittaker",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Whittaker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Whittaker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1006472,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "4e6795d8406bde57551d6acff131d4f47435bcb6",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Conversation between two people is usually of MIXED-INITIATIVE, with CONTROL over the conversation being transferred from one person to another. We apply a set of rules for the transfer of control to 4 sets of dialogues consisting of a total of 1862 turns. The application of the control rules lets us derive domain-independent discourse structures. The derived structures indicate that initiative plays a role in the structuring of discourse. In order to explore the relationship of control and initiative to discourse processes like centering, we analyze the distribution of four different classes of anaphora for two data sets. This distribution indicates that some control segments are hierarchically related to others. The analysis suggests that discourse participants often mutually agree to a change of topic. We also compared initiative in Task Oriented and Advice Giving dialogues and found that both allocation of control and the manner in which control is transferred is radically different for the two dialogue types. These differences can be explained in terms of collaborative planning principles."
            },
            "slug": "Mixed-Initiative-in-Dialogue:-An-Investigation-into-Walker-Whittaker",
            "title": {
                "fragments": [],
                "text": "Mixed Initiative in Dialogue: An Investigation into Discourse Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A set of rules for the transfer of control is applied to 4 sets of dialogues and it is found that both allocation of control and the manner in which control is transferred is radically different for the two dialogue types."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157221"
                        ],
                        "name": "E. T. K. Sang",
                        "slug": "E.-T.-K.-Sang",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sang",
                            "middleNames": [
                                "Tjong",
                                "Kim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. T. K. Sang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143667674"
                        ],
                        "name": "J. Veenstra",
                        "slug": "J.-Veenstra",
                        "structuredName": {
                            "firstName": "Jorn",
                            "lastName": "Veenstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Veenstra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1845735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "008a2291a257072f22764196a3acf0a394bf203a",
            "isKey": false,
            "numCitedBy": 392,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Dividing sentences in chunks of words is a useful preprocessing step for parsing, information extraction and information retrieval. (Ramshaw and Marcus, 1995) have introduced a \"convenient\" data representation for chunking by converting it to a tagging task. In this paper we will examine seven different data representations for the problem of recognizing noun phrase chunks. We will show that the the data representation choice has a minor influence on chunking performance. However, equipped with the most suitable data representation, our memory-based learning chunker was able to improve the best published chunking results for a standard data set."
            },
            "slug": "Representing-Text-Chunks-Sang-Veenstra",
            "title": {
                "fragments": [],
                "text": "Representing Text Chunks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the the data representation choice has a minor influence on chunking performance, however, equipped with the most suitable data representation, the memory-based learning chunker was able to improve the best published chunking results for a standard data set."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700007"
                        ],
                        "name": "Mona T. Diab",
                        "slug": "Mona-T.-Diab",
                        "structuredName": {
                            "firstName": "Mona",
                            "lastName": "Diab",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mona T. Diab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10091362,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "444dc7fe40b5702e79e908834ca2fcfdbc422cd2",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised method for word sense disambiguation that exploits translation correspondences in parallel corpora. The technique takes advantage of the fact that cross-language lexicalizations of the same concept tend to be consistent, preserving some core element of its semantics, and yet also variable, reflecting differing translator preferences and the influence of context. Working with parallel corpora introduces an extra complication for evaluation, since it is difficult to find a corpus that is both sense tagged and parallel with another language; therefore we use pseudo-translations, created by machine translation systems, in order to make possible the evaluation of the approach against a standard test set. The results demonstrate that word-level translation correspondences are a valuable source of information for sense disambiguation."
            },
            "slug": "An-Unsupervised-Method-for-Word-Sense-Tagging-using-Diab-Resnik",
            "title": {
                "fragments": [],
                "text": "An Unsupervised Method for Word Sense Tagging using Parallel Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "An unsupervised method for word sense disambiguation that exploits translation correspondences in parallel corpora is presented, using pseudo-translations, created by machine translation systems, in order to make possible the evaluation of the approach against a standard test set."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69438895"
                        ],
                        "name": "\u98ef\u5cf6 \u5468",
                        "slug": "\u98ef\u5cf6-\u5468",
                        "structuredName": {
                            "firstName": "\u98ef\u5cf6",
                            "lastName": "\u5468",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u98ef\u5cf6 \u5468"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60157325,
            "fieldsOfStudy": [
                "Linguistics",
                "Education"
            ],
            "id": "1f22bd125de0b4ddd76d9716150709ec40a0b839",
            "isKey": false,
            "numCitedBy": 1358,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Longman Student Grammar of Spoken and Written English March 13th, 2019 These tell us what choices are available in the grammar but we also need to understand how these choices are used to create discourse in different situations The year 1999 saw the publication of a large scale grammar of English with the aim of meeting the above needs the Longman ielts house net, longman student grammar of spoken and written english, longman grammar of spoken and written english roffel, longman student grammar of spoken and written english pdf, longman grammar of spoken and written english libros, longmans student grammar of spoken and written english, english longman grammar of spoken and written eng free, longman student grammar of spoken and written english, longman grammar of spoken and written english pdf web, lms2 vu edu pk, longman student grammar of spoken and written english, longman grammar of spoken and written english wikipedia, longman student grammar of spoken and written english, download pdf longman grammar of spoken and written, longman student grammar of spoken and written english, longman grammar of spoken and written english amazon co, longman student grammar of spoken and written english, longman grammar of spoken and written english edoc pub, the languagelab library longman student grammar of, longman grammar of spoken and written english scribd, longman grammar of spoken and written english free, the longman grammar of spoken and written english, longman grammar of spoken and written english epdf tips, grammars of spoken english new outcomes of corpus, longman grammar of spoken and written english tesl ej, book reviews longman grammar of spoken and written english, longman student grammar of spoken and written english, longman grammar of spoken and written english worldcat org, douglas biber et al longman grammar of spoken and, project muse longman grammar of spoken and written, longman grammar of spoken and written english oxford, 9780582237261 longman student grammar of spoken and, longman student grammar of spoken and written english, pdf longman grammar of spoken and written english, longman student grammar of spoken and written english, longman grammar of spoken and written english google books, student grammar of spoken and written english workbook, longman grammar of spoken and written english goodreads, longman student grammar of spoken and written english, longman student grammar of spoken and written english le, longman student grammar of spoken and written english, longman grammar of spoken and written english co construction, longman student grammar of spoken and written english, longman student grammar of spoken and written english by, longman student grammar of spoken and written english workbook, longman grammar of spoken and written english douglas"
            },
            "slug": "\u300c\u4f1a\u8a71\u306e\u6587\u6cd5\u300d\u306b\u95a2\u3059\u308b\u4e00\u8003\u5bdf-:-Longman-Grammar-of-Spoken-and-\u98ef\u5cf6",
            "title": {
                "fragments": [],
                "text": "\u300c\u4f1a\u8a71\u306e\u6587\u6cd5\u300d\u306b\u95a2\u3059\u308b\u4e00\u8003\u5bdf : Longman Grammar of Spoken and Written English\u306e\u5834\u5408"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 608,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0a14be7e7f5614b91d0f648ae5f2baafc6d7036",
            "isKey": false,
            "numCitedBy": 717,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic natural language parsers have shown themselves to be inadequate for processing highly-ambiguous large-vocabulary text, as is evidenced by their poor performance on domains like the Wall Street Journal, and by the movement away from parsing-based approaches to text-processing in general. In this paper, I describe SPATTER, a statistical parser based on decision-tree learning techniques which constructs a complete parse for every sentence and achieves accuracy rates far better than any published result. This work is based on the following premises: (1) grammars are too complex and detailed to develop manually for most interesting domains; (2) parsing models must rely heavily on lexical and contextual information to analyze sentences accurately; and (3) existing n-gram modeling techniques are inadequate for parsing models. In experiments comparing SPATTER with IBM's computer manuals parser, SPATTER significantly outperforms the grammar-based parser. Evaluating SPATTER against the Penn Treebank Wall Street Journal corpus using the PARSEVAL measures, SPATTER achieves 86% precision, 86% recall, and 1.3 crossing brackets per sentence for sentences of 40 words or less, and 91% precision, 90% recall, and 0.5 crossing brackets for sentences between 10 and 20 words in length."
            },
            "slug": "Statistical-Decision-Tree-Models-for-Parsing-Magerman",
            "title": {
                "fragments": [],
                "text": "Statistical Decision-Tree Models for Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "SPATTER is described, a statistical parser based on decision-tree learning techniques which constructs a complete parse for every sentence and achieves accuracy rates far better than any published result."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145632116"
                        ],
                        "name": "N. Coccaro",
                        "slug": "N.-Coccaro",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Coccaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Coccaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13185450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b888cae7e6e288b108f9d119fc23b84b4d447029",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a number of techniques designed to help integrate semantic knowledge with N-gram language models for automatic speech recognition. Our techniques allow us to integrate Latent Semantic Analysis (LSA), a word-similarity algorithm based on word co-occurrence information, with N-gram models. While LSA is good at predicting content words which are coherent with the rest of a text, it is a bad predictor of frequent words, has a low dynamic range, and is inaccurate when combined linearly with N-grams. We show that modifying the dynamic range, applying a per-word con \ufb01 dence metric, and using geometric rather than linear combinations with N-grams produces a more robust language model which has a lower perplexity on a Wall Street Journal test-set than a baseline N-gram model."
            },
            "slug": "Towards-better-integration-of-semantic-predictors-Coccaro-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Towards better integration of semantic predictors in statistical language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that modifying the dynamic range, applying a per-word con \ufb01 dence metric, and using geometric rather than linear combinations with N-grams produces a more robust language model which has a lower perplexity on a Wall Street Journal test-set than a baseline N- gram model."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2393013"
                        ],
                        "name": "I. Sag",
                        "slug": "I.-Sag",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Sag",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150325684"
                        ],
                        "name": "Thomas Wasov",
                        "slug": "Thomas-Wasov",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Wasov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Wasov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207622006,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "bbea6de2ca7db01a1913ac9f656d21164a71ad43",
            "isKey": false,
            "numCitedBy": 881,
            "numCiting": 156,
            "paperAbstract": {
                "fragments": [],
                "text": "This second edition of \"Syntactic Theory: A Formal Introduction\" expands and improves upon a truly unique introductory syntax textbook. Like the first edition its focus is on the development of precisely formulated grammars whose empirical predictions can be directly tested. There is also considerable emphasis on the prediction and evaluation of grammatical hypotheses, as well as on integrating syntactic hypotheses with matters of semantic analysis. The book covers the core areas of English syntax from the last quarter century, including complementation, control, \"raising constructions\", passives, the auxiliary system, and the analysis of long distance dependency constructions. \"Syntactic Theory's\" step-by-step introduction to a consistent grammar in these core areas is complemented by extensive problem sets drawing from a variety of languages. The book's theoretical perspective is presented in the context of current models of language processing, and the practical value of the constraint-based, lexicalist grammatical architecture proposed has already been demonstrated in computer language processing applications. This thoroughly reworked second edition includes revised and extended problems sets, updated analyses, additional examples and more detailed exposition throughout."
            },
            "slug": "Syntactic-Theory:-A-Formal-Introduction-Sag-Wasov",
            "title": {
                "fragments": [],
                "text": "Syntactic Theory: A Formal Introduction"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This second edition of \"Syntactic Theory: A Formal Introduction\" expands and improves upon a truly unique introductory syntax textbook, focusing on the development of precisely formulated grammars whose empirical predictions can be directly tested."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118415117"
                        ],
                        "name": "Michael P. Jones",
                        "slug": "Michael-P.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael P. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10796472"
                        ],
                        "name": "James H. Martin",
                        "slug": "James-H.-Martin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martin",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James H. Martin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8592573,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "232e66748382ded9d217de554574fbf70df0f6b6",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Contextual spelling errors are defined as the use of an incorrect, though valid, word in a particular sentence or context. Traditional spelling checkers flag misspelled words, but they do not typically attempt to identify words that are used incorrectly in a sentence. We explore the use of Latent Semantic Analysis for correcting these incorrectly used words and the results are compared to earlier work based on a Bayesian classifier."
            },
            "slug": "Contextual-Spelling-Correction-Using-Latent-Jones-Martin",
            "title": {
                "fragments": [],
                "text": "Contextual Spelling Correction Using Latent Semantic Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The use of Latent Semantic Analysis for correcting incorrectly used words is explored and the results are compared to earlier work based on a Bayesian classifier."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35104253"
                        ],
                        "name": "M. Danieli",
                        "slug": "M.-Danieli",
                        "structuredName": {
                            "firstName": "Morena",
                            "lastName": "Danieli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Danieli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2512649"
                        ],
                        "name": "Elisabetta Gerbino",
                        "slug": "Elisabetta-Gerbino",
                        "structuredName": {
                            "firstName": "Elisabetta",
                            "lastName": "Gerbino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elisabetta Gerbino"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8738472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a38faf8bfc7ff634a63d27999d16bab21858710f",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a set of metrics for the evaluation of different dialogue management strategies in an implemented real-time spoken language system. The set of metrics we propose tries to offer useful insights in evaluating how particular choices in the dialogue management can affect the overall quality of the man-machine dialogue. The evaluation makes use of established metrics: the transaction success, the contextual appropriateness of system answers, the calculation of normal and correction turns in a dialogue. We also define a new metric, the implicit recovery, which allows to measure the ability of a dialogue manager to deal with errors by different levels of analysis. We report evaluation data from several experiments, and we compare two different approaches to dialogue repair strategies using the set of metrics we argue for."
            },
            "slug": "Metrics-for-Evaluating-Dialogue-Strategies-in-a-Danieli-Gerbino",
            "title": {
                "fragments": [],
                "text": "Metrics for Evaluating Dialogue Strategies in a Spoken Language System"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new metric is defined, the implicit recovery, which allows to measure the ability of a dialogue manager to deal with errors by different levels of analysis and is compared to two different approaches to dialogue repair strategies."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142223"
                        ],
                        "name": "M. Lesk",
                        "slug": "M.-Lesk",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lesk",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lesk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11892605,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "76e4e034c20bea86edcc6e71bbaddb47fafeecbc",
            "isKey": false,
            "numCitedBy": 2124,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The meaning of an English word can vary widely depending on which sense is intended. Does a fireman feed fires or put them out? It depends on whether or not he is on a steam locomotive. I am trying to decide automatically which sense of a word is intended (in written English) by using machine readable dictionaries, and looking for words in the sense definitions that overlap words in the definition of nearby words. The problem of deciding which sense of a word was intended by the writer is an important problem in information retrieval systems. At present most retrieval systems rely on manual indexing; if this is to be replaced with automatic text processing, it would be very desirable to recognize the correct sense of each word as often as possible. Previous work has generally either suggested (a) detailed frames describing the particular word senses,t*\u2019 or (b) global statistics about the word occurrences.3 The first has not yet been made available in any real application, and the second may give the wrong answer in specific local instances. This procedure uses available dictionaries, so that it will process any text; and uses solely the immediate context. To consider the example in the title, look at the definition of pine in the Oxford Advanced Learner\u2019s Dictionary of Current English: there are, of course, two major senses. \u201ckind of evergreen tree with needle-shaped leaves.. .\u201d and \u201cwaste away through sorrow or illness...\u201d And cone has three separate definitions: \u201csolid body which narrows to a\u2019 point . . . . *\u2019 \u201csomething of this shape w-hether solid or hollow...,\u201d and \u201cfruit of certain evergreen trees...\u201d Note that both evergreen and tree are common to two of the sense definitions: thus a program could guess that if the two words pine cone appear together, the likely senses are those of the tree and its fruit"
            },
            "slug": "Automatic-sense-disambiguation-using-machine-how-to-Lesk",
            "title": {
                "fragments": [],
                "text": "Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This procedure uses available dictionaries, so that it will process any text; and uses solely the immediate context to decide which sense of a word is intended (in written English)."
            },
            "venue": {
                "fragments": [],
                "text": "SIGDOC '86"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799688"
                        ],
                        "name": "V. Hatzivassiloglou",
                        "slug": "V.-Hatzivassiloglou",
                        "structuredName": {
                            "firstName": "Vasileios",
                            "lastName": "Hatzivassiloglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hatzivassiloglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 158
                            }
                        ],
                        "text": "Learned sentiment lexicons such as the polarity lexicons of (Hatzivassiloglou and McKeown, 1997) were shown to be a useful feature in subjectivity detection (Hatzivassiloglou and Wiebe 2000, Wiebe 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 566696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a8d4fd2c30e5031a574bc25363c8639912b3bbd",
            "isKey": false,
            "numCitedBy": 752,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Subjectivity is a pragmatic, sentence-level feature that has important implications for text processing applications such as information extraction and information retrieval. We study the effects of dynamic adjectives, semantically oriented adjectives, and gradable adjectives on a simple subjectivity classifier, and establish that they are strong predictors of subjectivity. A novel trainable method that statistically combines two indicators of gradability is presented and evaluated, complementing existing automatic techniques for assigning orientation labels."
            },
            "slug": "Effects-of-Adjective-Orientation-and-Gradability-on-Hatzivassiloglou-Wiebe",
            "title": {
                "fragments": [],
                "text": "Effects of Adjective Orientation and Gradability on Sentence Subjectivity"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel trainable method that statistically combines two indicators of gradability is presented and evaluated, complementing existing automatic techniques for assigning orientation labels."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116073558"
                        ],
                        "name": "Grace Kim",
                        "slug": "Grace-Kim",
                        "structuredName": {
                            "firstName": "Grace",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Grace Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33353168"
                        ],
                        "name": "R. MacIntyre",
                        "slug": "R.-MacIntyre",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "MacIntyre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. MacIntyre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3212973"
                        ],
                        "name": "Ann Bies",
                        "slug": "Ann-Bies",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Bies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ann Bies"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054785529"
                        ],
                        "name": "Mark Ferguson",
                        "slug": "Mark-Ferguson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Ferguson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Ferguson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065702818"
                        ],
                        "name": "Karen Katz",
                        "slug": "Karen-Katz",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Katz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Katz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2537676"
                        ],
                        "name": "Britta Schasberger",
                        "slug": "Britta-Schasberger",
                        "structuredName": {
                            "firstName": "Britta",
                            "lastName": "Schasberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Britta Schasberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5151364,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59ce9cdbde13affc05a6c1f48a51ee7b0fcb154b",
            "isKey": false,
            "numCitedBy": 897,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The Penn Treebank has recently implemented a new syntactic annotation scheme, designed to highlight aspects of predicate-argument structure. This paper discusses the implementation of crucial aspects of this new annotation scheme. It incorporates a more consistent treatment of a wide range of grammatical phenomena, provides a set of coindexed null elements in what can be thought of as \"underlying\" position for phenomena such as wh-movement, passive, and the subjects of infinitival constructions, provides some non-context free annotational mechanism to allow the structure of discontinuous constituents to be easily recovered, and allows for a clear, concise tagging system for some semantic roles."
            },
            "slug": "The-Penn-Treebank:-Annotating-Predicate-Argument-Marcus-Kim",
            "title": {
                "fragments": [],
                "text": "The Penn Treebank: Annotating Predicate Argument Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The implementation of crucial aspects of this new syntactic annotation scheme incorporates a more consistent treatment of a wide range of grammatical phenomena, provides a set of coindexed null elements in what can be thought of as \"underlying\" position for phenomena such as wh-movement, passive, and the subjects of infinitival constructions."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114531657"
                        ],
                        "name": "Noam Chomsky",
                        "slug": "Noam-Chomsky",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Chomsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam Chomsky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60895438,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "39565a9a91eb563110c12304553552fb4cba23dc",
            "isKey": false,
            "numCitedBy": 954,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The work written by the noted American linguist two decades ago explains the basic principles of transformational generative grammar, its relation to the general structure of an adequate language theory, and its specific application to English."
            },
            "slug": "The-Logical-Structure-of-Linguistic-Theory-Chomsky",
            "title": {
                "fragments": [],
                "text": "The Logical Structure of Linguistic Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The work written by the noted American linguist two decades ago explains the basic principles of transformational generative grammar, its relation to the general structure of an adequate language theory, and its specific application to English."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721040"
                        ],
                        "name": "D. Sleator",
                        "slug": "D.-Sleator",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Sleator",
                            "middleNames": [
                                "Dominic"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sleator"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335864"
                        ],
                        "name": "D. Temperley",
                        "slug": "D.-Temperley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Temperley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Temperley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5118729,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "5752b8dcec5856b7ad6289bbe1177acce535fba4",
            "isKey": false,
            "numCitedBy": 1030,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We define a new formal grammatical system called a link grammar. A sequence of words is in the language of a link grammar if there is a way to draw links between words in such a way that (1) the local requirements of each word are satisfied, (2) the links do not cross, and (3) the words form a connected graph. We have encoded English grammar into such a system, and written a program (based on new algorithms) for efficiently parsing with a link grammar. The formalism is lexical and makes no explicit use of constituents and categories. The breadth of English phenomena that our system handles is quite large. A number of sophisticated and new techniques were used to allow efficient parsing of this very complex grammar. Our program is written in C, and the entire system may be obtained via anonymous ftp. Several other researchers have begun to use link grammars in their own research."
            },
            "slug": "Parsing-English-with-a-Link-Grammar-Sleator-Temperley",
            "title": {
                "fragments": [],
                "text": "Parsing English with a Link Grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This work has encoded English grammar into a new formal grammatical system called a link grammar, and written a program (based on new algorithms) for efficiently parsing with this very complex grammar."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31937023"
                        ],
                        "name": "R. A. Amsler",
                        "slug": "R.-A.-Amsler",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Amsler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. A. Amsler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18782721,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "c1ca849fc2c4dc984220c2263ff4293048a38acf",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The definition texts of a machine-readable pocket dictionary were analyzed to determine the disambiguated word sense of the kernel terms of each word sense being defined. The resultant sets of word pairs of defined and defining words were then computationally connected into two taxonomic semilattices (\"tangled hierarchies\") representing some 24,000 noun nodes and 11,000 verb nodes. The study of the nature of the \"topmost\" nodes in these hierarchies, and the structure of the trees reveal information about the nature of the dictionary's organization of the language, the concept of semantic primitives and other aspects of lexical semantics. The data proves that the dictionary offers a fundamentally consistent description of word meaning and may provide the basis for future research and applications in computational linguistic systems."
            },
            "slug": "A-Taxonomy-for-English-Nouns-and-Verbs-Amsler",
            "title": {
                "fragments": [],
                "text": "A Taxonomy for English Nouns and Verbs"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "The definition texts of a machine-readable pocket dictionary were analyzed to determine the disambiguated word sense of the kernel terms of each word sense being defined, proving that the dictionary offers a fundamentally consistent description of word meaning."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749194"
                        ],
                        "name": "Collin F. Baker",
                        "slug": "Collin-F.-Baker",
                        "structuredName": {
                            "firstName": "Collin",
                            "lastName": "Baker",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Collin F. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912454"
                        ],
                        "name": "C. Fillmore",
                        "slug": "C.-Fillmore",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fillmore",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fillmore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406118956"
                        ],
                        "name": "John B. Lowe",
                        "slug": "John-B.-Lowe",
                        "structuredName": {
                            "firstName": "John B.",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John B. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2505531,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "547f23597f9ec8a93f66cedaa6fbfb73960426b1",
            "isKey": false,
            "numCitedBy": 2883,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "FrameNet is a three-year NSF-supported project in corpus-based computational lexicography, now in its second year (NSF IRI-9618838, \"Tools for Lexicon Building\"). The project's key features are (a) a commitment to corpus evidence for semantic and syntactic generalizations, and (b) the representation of the valences of its target words (mostly nouns, adjectives, and verbs) in which the semantic portion makes use of frame semantics. The resulting database will contain (a) descriptions of the semantic frames underlying the meanings of the words described, and (b) the valence representation (semantic and syntactic) of several thousand words and phrases, each accompanied by (c) a representative collection of annotated corpus attestations, which jointly exemplify the observed linkings between \"frame elements\" and their syntactic realizations (e.g. grammatical function, phrase type, and other syntactic traits). This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work."
            },
            "slug": "The-Berkeley-FrameNet-Project-Baker-Fillmore",
            "title": {
                "fragments": [],
                "text": "The Berkeley FrameNet Project"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990190"
                        ],
                        "name": "P. Pantel",
                        "slug": "P.-Pantel",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Pantel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pantel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9548219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c384d9ee4fd8657b26a8165244eb4ad73df4f492",
            "isKey": false,
            "numCitedBy": 507,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose an unsupervised method for discovering inference rules from text, such as \u201cX is author of Y \u2248 X wrote Y\u201d, \u201cX solved Y \u2248 X found a solution to Y\u201d, and \u201cX caused Y \u2248 Y is triggered by X\u201d. Inference rules are extremely important in many fields such as natural language processing, information retrieval, and artificial intelligence in general. Our algorithm is based on an extended version of Harris\u2019 Distributional Hypothesis, which states that words that occurred in the same contexts tend to be similar. Instead of using this hypothesis on words, we apply it to paths in the dependency trees of a parsed corpus."
            },
            "slug": "DIRT-\u2013-Discovery-of-Inference-Rules-from-Text-Lin-Pantel",
            "title": {
                "fragments": [],
                "text": "DIRT \u2013 Discovery of Inference Rules from Text"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper proposes an unsupervised method for discovering inference rules from text, based on an extended version of Harris\u2019 Distributional Hypothesis, which states that words that occurred in the same contexts tend to be similar."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145091160"
                        ],
                        "name": "B. Levin",
                        "slug": "B.-Levin",
                        "structuredName": {
                            "firstName": "Beth",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Levin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62585813,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6cbc1eb25f4ab29a613418b3b0740e74141a0f17",
            "isKey": false,
            "numCitedBy": 3246,
            "numCiting": 246,
            "paperAbstract": {
                "fragments": [],
                "text": "In this rich reference work, Beth Levin classifies over 3,000 English verbs according to shared meaning and behavior. Levin starts with the hypothesis that a verb's meaning influences its syntactic behavior and develops it into a powerful tool for studying the English verb lexicon. She shows how identifying verbs with similar syntactic behavior provides an effective means of distinguishing semantically coherent verb classes, and isolates these classes by examining verb behavior with respect to a wide range of syntactic alternations that reflect verb meaning. The first part of the book sets out alternate ways in which verbs can express their arguments. The second presents classes of verbs that share a kernel of meaning and explores in detail the behavior of each class, drawing on the alternations in the first part. Levin's discussion of each class and alternation includes lists of relevant verbs, illustrative examples, comments on noteworthy properties, and bibliographic references. The result is an original, systematic picture of the organization of the verb inventory. Easy to use, \"English Verb Classes and Alternations\" sets the stage for further explorations of the interface between lexical semantics and syntax. It will prove indispensable for theoretical and computational linguists, psycholinguists, cognitive scientists, lexicographers, and teachers of English as a second language. Beth Levin is associate professor of linguistics at Northwestern University."
            },
            "slug": "English-Verb-Classes-and-Alternations:-A-Levin",
            "title": {
                "fragments": [],
                "text": "English Verb Classes and Alternations: A Preliminary Investigation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Beth Levin shows how identifying verbs with similar syntactic behavior provides an effective means of distinguishing semantically coherent verb classes, and isolates these classes by examining verb behavior with respect to a wide range of syntactic alternations that reflect verb meaning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1487550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "944cba683d10d8c1a902e05cd68e32a9f47b372e",
            "isKey": false,
            "numCitedBy": 2536,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations. The algorithm is based on two powerful constraints---that words tend to have one sense per discourse and one sense per collocation---exploited in an iterative bootstrapping procedure. Tested accuracy exceeds 96%."
            },
            "slug": "Unsupervised-Word-Sense-Disambiguation-Rivaling-Yarowsky",
            "title": {
                "fragments": [],
                "text": "Unsupervised Word Sense Disambiguation Rivaling Supervised Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3266388"
                        ],
                        "name": "N. Fraser",
                        "slug": "N.-Fraser",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Fraser",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fraser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39762878"
                        ],
                        "name": "N. Gilbert",
                        "slug": "N.-Gilbert",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Gilbert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gilbert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62599969,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "53fb49c7836698ae74b4559e78aeb34c7fe73a6a",
            "isKey": false,
            "numCitedBy": 443,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Simulating-speech-systems-Fraser-Gilbert",
            "title": {
                "fragments": [],
                "text": "Simulating speech systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146254443"
                        ],
                        "name": "Zhibiao Wu",
                        "slug": "Zhibiao-Wu",
                        "structuredName": {
                            "firstName": "Zhibiao",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhibiao Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12009057,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "0e3e3c3d8ae5cb7c4636870d69967c197484d3bb",
            "isKey": false,
            "numCitedBy": 3703,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper will focus on the semantic representation of verbs in computer systems and its impact on lexical selection problems in machine translation (MT). Two groups of English and Chinese verbs are examined to show that lexical selection must be based on interpretation of the sentences as well as selection restrictions placed on the verb arguments. A novel representation scheme is suggested, and is compared to representations with selection restrictions used in transfer-based MT. We see our approach as closely aligned with knowledge-based MT approaches (KBMT), and as a separate component that could be incorporated into existing systems. Examples and experimental results will show that, using this scheme, inexact matches can achieve correct lexical selection."
            },
            "slug": "Verb-Semantics-and-Lexical-Selection-Wu-Palmer",
            "title": {
                "fragments": [],
                "text": "Verb Semantics and Lexical Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This paper will focus on the semantic representation of verbs in computer systems and its impact on lexical selection problems in machine translation (MT), and sees the approach as closely aligned with knowledge-based MT approaches (KBMT), and as a separate component that could be incorporated into existing systems."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144451588"
                        ],
                        "name": "J. Backus",
                        "slug": "J.-Backus",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Backus",
                            "middleNames": [
                                "Warner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Backus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775998"
                        ],
                        "name": "F. L. Bauer",
                        "slug": "F.-L.-Bauer",
                        "structuredName": {
                            "firstName": "Friedrich",
                            "lastName": "Bauer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. L. Bauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2134869912"
                        ],
                        "name": "Julien Green",
                        "slug": "Julien-Green",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Green",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julien Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49257652"
                        ],
                        "name": "C. Katz",
                        "slug": "C.-Katz",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Katz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Katz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065378716"
                        ],
                        "name": "J. McCarthy",
                        "slug": "J.-McCarthy",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "McCarthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. McCarthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790022"
                        ],
                        "name": "A. Perlis",
                        "slug": "A.-Perlis",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Perlis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Perlis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145192245"
                        ],
                        "name": "H. Rutishauser",
                        "slug": "H.-Rutishauser",
                        "structuredName": {
                            "firstName": "Heinz",
                            "lastName": "Rutishauser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rutishauser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3261977"
                        ],
                        "name": "K. Samelson",
                        "slug": "K.-Samelson",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Samelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Samelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784830"
                        ],
                        "name": "B. Vauquois",
                        "slug": "B.-Vauquois",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Vauquois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Vauquois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48681841"
                        ],
                        "name": "J. Wegstein",
                        "slug": "J.-Wegstein",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Wegstein",
                            "middleNames": [
                                "Henry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wegstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8674722"
                        ],
                        "name": "A. V. Wijngaarden",
                        "slug": "A.-V.-Wijngaarden",
                        "structuredName": {
                            "firstName": "Adriaan",
                            "lastName": "Wijngaarden",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. V. Wijngaarden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11125381"
                        ],
                        "name": "M. Woodger",
                        "slug": "M.-Woodger",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Woodger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Woodger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 278290,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ca1bc5a9589aa90e040beea23cf95e32fb1da0c",
            "isKey": false,
            "numCitedBy": 486,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "After the publication of a preliminary report on the algorithmic language ALGOL,!' 2 as prepared at a conference in Zurich in 1958, much interest in the ALGOL language developed. As a result of an informal meeting held at Mainz in November 1958, about forty interested persons from several European countries held an ALGOL implementation conference in Copenhagen in February 1959. A \"hardware group\" was formed for working cooperatively right down to the level of the paper tape code. This conference also led to the publication by Regnecentralen, Copenhagen, of an ALGOL Bulletin, edited by Peter Naur, which served as a forum for further discussion. During the June 1959 ICIP Conference in Paris several meetings, both formal and informal ones, were held. These meetings revealed some misunderstandings as to the intent of the group which was primarily responsible for the formulation of the language, but at the same time made it clear that there exists a wide appreciation of the effort involved. As a result of the discussions it was decided to hold an international meeting in January 1960 for improving the ALGOL language and preparing a final report. At a European ALGOL Conference in Paris in November 1959 which was attended by about fifty people, seven European representatives were selected-to attend the January 1960 Conference, and they represent the following organizations: Association Francaise de Calcul, British Computer Society, Gesellschaft fur Angewandte Mathematik und . Mechanik, and Nederlands Rekenmachine Genootschap. The seven representatives held a final preparatory meeting at Mainz in December 1959. Meanwhile, in the United States, anyone who wished to suggest changes or corrections to ALGOL was requested to send his comments to the ACM Communications where they were published. These comments then became the basis of consideration for changes in the ALGOL language. Both the SHARE and USE organizations established ALGOL working groups, and both organizations were represented on the ACM Committee on Programming Languages. The ACM Committee met in Washington in November 1959 and considered all comments on ALGOL that had been sent to the ACM Communications. Also, seven representatives were selected to attend the January 1960 international conference. These seven representatives held a final preparatory meeting in Boston in December 1959."
            },
            "slug": "Report-on-the-algorithmic-language-ALGOL-60-Backus-Bauer",
            "title": {
                "fragments": [],
                "text": "Report on the algorithmic language ALGOL 60"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It was decided to hold an international meeting in January 1960 for improving the ALGOL language and preparing a final report, and seven representatives were selected to attend the January 1960 international conference."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1960
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17857497,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "7fd71b88b0ec248336410f58a4e37ed3fbe84698",
            "isKey": false,
            "numCitedBy": 297,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Selectional-constraints:-an-information-theoretic-Resnik",
            "title": {
                "fragments": [],
                "text": "Selectional constraints: an information-theoretic model and its computational realization"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35226330"
                        ],
                        "name": "B. Green",
                        "slug": "B.-Green",
                        "structuredName": {
                            "firstName": "Bert",
                            "lastName": "Green",
                            "middleNames": [
                                "F."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32223729"
                        ],
                        "name": "A. K. Wolf",
                        "slug": "A.-K.-Wolf",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "Wolf",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. K. Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6370361"
                        ],
                        "name": "C. Chomsky",
                        "slug": "C.-Chomsky",
                        "structuredName": {
                            "firstName": "Carol",
                            "lastName": "Chomsky",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chomsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94536391"
                        ],
                        "name": "Kenneth Laughery",
                        "slug": "Kenneth-Laughery",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Laughery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Laughery"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5867164,
            "fieldsOfStudy": [
                "Computer Science",
                "Education"
            ],
            "id": "89d025804988944d6fa4e95f49bff011b33d1418",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "<u>Baseball</u> is a computer program that answers questions phrased in ordinary English about stored data. The program reads the question from punched cards. After the words and idioms are looked up in a dictionary, the phrase structure and other syntactic facts are determined for a content analysis, which lists attribute-value pairs specifying the information given and the information requested. The requested information is then extracted from the data matching the specifications, and any necessary processing is done. Finally, the answer is printed. The program's present context is baseball games; it answers such questions as \"Where did each team play on July 7?\""
            },
            "slug": "Baseball:-an-automatic-question-answerer-Green-Wolf",
            "title": {
                "fragments": [],
                "text": "Baseball: an automatic question-answerer"
            },
            "venue": {
                "fragments": [],
                "text": "IRE-AIEE-ACM '61 (Western)"
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82323309"
                        ],
                        "name": "Karen Sparck Jones",
                        "slug": "Karen-Sparck-Jones",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Sparck Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Sparck Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5207282,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "be5406dcea7c9c734cdb1f6797712b71fcf71b79",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "356,302. Golf bags. DENT, L. M. E., 2, Porchester Gardens, Bayswater, and MACKENZIE, A., 38A, Northside, Clapham Common, both in London. June 10, 1930, No. 17844. [Class 132 (ii).] The reinforcing ring at the mouth of a golfclub bag is made in two or more parts so interconnected that they may be moved relatively to expand or contract the compass of the mouth. As shown in the Figure, the ring is composed of two bars 12, 13 h n ed together at their right-hand ends and pivoted at their other ends to links 17, 18 hinged together at 19. By pressing the links 17, 18 downwards the ends 12, 13 of the bars may be brought together and the links may be retained in this position by a catch. A rigid reinforcing ring may be provided at the base of the bag or a collapsable one similar to that at the mouth may be used. The bag is provided with flexible stiffeners 21, 22, carrying straps 26, 27, hood 25, dividing strap 24, and umbrella strap 31 and support 32."
            },
            "slug": "Synonymy-and-semantic-classification-Jones",
            "title": {
                "fragments": [],
                "text": "Synonymy and semantic classification"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "The reinforcing ring at the mouth of a golfclub bag is made in two or more parts so interconnected that they may be moved relatively to expand or contract the compass of the mouth."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 340173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b216a312c7b421748123a43eba9b45eb6418d7bb",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a heuristic approach to automatically identifying which senses of a machinereadable dictionary (MRD) headword are semantically related versus those which correspond to fundamentally different senses of the word. The inclusion of this information in a lexical database profoundly alters the nature of sense disambiguation: the appropriate \"sense\" of a polysemous word may now correspond to some set of related senses. Our technique offers benefits both for on-line semantic processing and for the challenging task of mapping word senses across multiple MRDs in creating a merged lexical database."
            },
            "slug": "Word-Sense-Ambiguation:-Clustering-Related-Senses-Dolan",
            "title": {
                "fragments": [],
                "text": "Word Sense Ambiguation: Clustering Related Senses"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A heuristic approach to automatically identifying which senses of a machinereadable dictionary (MRD) headword are semantically related versus those which correspond to fundamentally different senses of the word."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145528516"
                        ],
                        "name": "M. Mu\u00f1oz",
                        "slug": "M.-Mu\u00f1oz",
                        "structuredName": {
                            "firstName": "Marcia",
                            "lastName": "Mu\u00f1oz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mu\u00f1oz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474158"
                        ],
                        "name": "Vasin Punyakanok",
                        "slug": "Vasin-Punyakanok",
                        "structuredName": {
                            "firstName": "Vasin",
                            "lastName": "Punyakanok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vasin Punyakanok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2680974"
                        ],
                        "name": "Dav Zimak",
                        "slug": "Dav-Zimak",
                        "structuredName": {
                            "firstName": "Dav",
                            "lastName": "Zimak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dav Zimak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1599627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a31d6f597f78599c6df66dedf64cd5bc05c5327a",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A SNoW based learning approach to shallow parsing tasks is presented and studied experimentally. The approach learns to identify syntactic patterns by combining simple predictors to produce a coherent inference. Two instantiations of this approach are studied and experimental results for Noun-Phrases (NP) and Subject-Verb (SV) phrases that compare favorably with the best published results are presented. In doing that, we compare two ways of modeling the problem of learning to recognize patterns and suggest that shallow parsing patterns are better learned using open/close predictors than using inside/outside predictors.} thus contribute to the understanding of how to model shallow parsing tasks as learning problems."
            },
            "slug": "A-Learning-Approach-to-Shallow-Parsing-Mu\u00f1oz-Punyakanok",
            "title": {
                "fragments": [],
                "text": "A Learning Approach to Shallow Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work compares two ways of modeling the problem of learning to recognize patterns and suggests that shallow parsing patterns are better learned using open/close predictors than using inside/outside predictors and thus contribute to the understanding of how to model shallow parsing tasks as learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Wiebe (1994) began an influential line of work on detecting subjectivity in text,subjectivity beginning with the task of identifying subjective sentences and the subjective characters who are described in the text as holding private states, beliefs or attitudes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7580918,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "829d1090da72af223944f7e576bbedaba53417c7",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 130,
            "paperAbstract": {
                "fragments": [],
                "text": "Third-person fictional narrative text is composed not only of passages that objectively narrate events, but also of passages that present characters' thoughts, perceptions, and inner states. Such passages take a character's psychological point of view. A language understander must determine the current psychological point of view in order to distinguish the beliefs of the characters from the facts of the story, to correctly attribute beliefs and other attitudes to their sources, and to understand the discourse relations among sentences. Tracking the psychological point of view is not a trivial problem, because many sentences are not explicitly marked for point of view, and whether the point of view of a sentence is objective or that of a character (and if the latter, which character it is) often depends on the context in which the sentence appears. Tracking the psychological point of view is the problem addressed in this work. The approach is to seek, by extensive examinations of naturally occurring narrative, regularities in the ways that authors manipulate point of view, and to develop an algorithm that tracks point of view on the basis of the regularities found. This paper presents this algorithm, gives demonstrations of an implemented system, and describes the results of some preliminary empirical studies, which lend support to the algorithm."
            },
            "slug": "Tracking-Point-of-View-in-Narrative-Wiebe",
            "title": {
                "fragments": [],
                "text": "Tracking Point of View in Narrative"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents an algorithm to develop an algorithm that tracks point of view on the basis of the regularities found in naturally occurring narrative, and describes the results of some preliminary empirical studies, which lend support to the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145165877"
                        ],
                        "name": "P. Hanks",
                        "slug": "P.-Hanks",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Hanks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hanks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9558665,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "9e2caa39ac534744a180972a30a320ad0ae41ea3",
            "isKey": false,
            "numCitedBy": 4363,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The term word association is used in a very particular sense in the psycholinguistic literature. (Generally speaking, subjects respond quicker than normal to the word nurse if it follows a highly associated word such as doctor. ) We will extend the term to provide the basis for a statistical description of a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type (content word/content word) to lexico-syntactic co-occurrence constraints between verbs and prepositions (content word/function word). This paper will propose an objective measure based on the information theoretic notion of mutual information, for estimating word association norms from computer readable corpora. (The standard method of obtaining word association norms, testing a few thousand subjects on a few hundred words, is both costly and unreliable.) The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "slug": "Word-Association-Norms,-Mutual-Information-and-Church-Hanks",
            "title": {
                "fragments": [],
                "text": "Word Association Norms, Mutual Information and Lexicography"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765329"
                        ],
                        "name": "Taku Kudo",
                        "slug": "Taku-Kudo",
                        "structuredName": {
                            "firstName": "Taku",
                            "lastName": "Kudo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taku Kudo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681502"
                        ],
                        "name": "Yuji Matsumoto",
                        "slug": "Yuji-Matsumoto",
                        "structuredName": {
                            "firstName": "Yuji",
                            "lastName": "Matsumoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuji Matsumoto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9404516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6c043a4c9bb41fb155bc3485e80bb079ef61cb9",
            "isKey": false,
            "numCitedBy": 547,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a new statistical Japanese dependency parser using a cascaded chunking model. Conventional Japanese statistical dependency parsers are mainly based on a probabilistic model, which is not always efficient or scalable. We propose a new method that is simple and efficient, since it parses a sentence deterministically only deciding whether the current segment modifies the segment on its immediate right hand side. Experiments using the Kyoto University Corpus show that the method outperforms previous systems as well as improves the parsing and training efficiency."
            },
            "slug": "Japanese-Dependency-Analysis-using-Cascaded-Kudo-Matsumoto",
            "title": {
                "fragments": [],
                "text": "Japanese Dependency Analysis using Cascaded Chunking"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A new statistical Japanese dependency parser using a cascaded chunking model that is simple and efficient, since it parses a sentence deterministically only deciding whether the current segment modifies the segment on its immediate right hand side."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2001885"
                        ],
                        "name": "Ted Pedersen",
                        "slug": "Ted-Pedersen",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Pedersen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2614094"
                        ],
                        "name": "Rebecca F. Bruce",
                        "slug": "Rebecca-F.-Bruce",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Bruce",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rebecca F. Bruce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58116,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e50547416475df1716769f569e0c6f6f99293f77",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an experimental comparison of three unsupervised learning algorithms that distinguish the sense of an ambiguous word in untagged text. The methods described in this paper, McQuitty's similarity analysis, Ward's minimum-variance method, and the EM algorithm, assign each instance of an ambiguous word to a known sense definition based solely on the values of automatically identifiable features in text. These methods and feature sets are found to be more successful in disambiguating nouns rather than adjectives or verbs. Overall, the most accurate of these procedures is McQuitty's similarity analysis in combination with a high dimensional feature set. 1 I n t r o d u c t i o n Statistical methods for natural language processing are often dependent on the availability of costly knowledge sources such as manually annotated text or semantic networks. This limits the applicability of such approaches to domains where this hard to acquire knowledge is already available. This paper presents three unsupervised learning algorithms that are able to distinguish among the known senses (i.e., as defined in some dictionary) of a word, based only on features that can be automatically extracted from untagged text. The object of unsupervised learning is to determine the class membership of each observation (i.e. each object to be classified), in a sample without using training examples of correct classifications. We discuss three algorithms, McQuitty's similarity analysis (McQuitty, 1966), Ward's minimum-variance method (Ward, 1963) and the EM algorithm (Dempster, Laird, and Rubin, 1977), that can be used to distinguish among the known senses of an ambiguous word without the aid of disambiguated examples. The EM algorithm produces maximum likelihood estimates of the parameters of a probabilistic model, where that model has been specified in advance. Both Ward's and McQuitty's methods are agglomerative clustering algorithms that form classes of unlabeled observations that minimize their respective distance measures between class members. The rest of this paper is organized as follows. First, we present introductions to Ward's and McQuitty 's methods (Section 2) and the EM algorithm (Section 3). We discuss the thirteen words (Section 4) and the three feature sets (Section 5) used in our experiments. We present our experimental results (Section 6) and close with a discussion of related work (Section 7). 2 Agglomerat ive Clustering In general, clustering methods rely on the assumption that classes occupy distinct regions in the feature space. The distance between two points in a multi-dimensional space can be measured using any of a wide variety of metrics (see, e.g. (Devijver and Kittler, 1982)). Observations are grouped in the manner that minimizes the distance between the members of each class. Ward's and McQuitty's method are agglomerative clustering algorithms that differ primarily in how they compute the distance between clusters. All such algorithms begin by placing each observation in a unique cluster, i.e. a cluster of one. The two closest clusters are merged to form a new cluster that replaces the two merged clusters. Merging of the two closest clusters continues until only some specified number of clusters remain. However, our data does not immediately lend itself to a distance-based interpretation. Our features represent part-of-speech (POS) tags, morphological characteristics, and word co-occurrence; such features are nominal and their values do not have scale. Given a POS feature, for example, we could choose noun = 1, verb = 2, adjective = 3, and adverb = 4. That adverb is represented by a larger number than noun is purely coincidental and implies nothing about the relationship between nouns and adverbs. Thus, before we employ either clustering algo-"
            },
            "slug": "Distinguishing-Word-Senses-in-Untagged-Text-Pedersen-Bruce",
            "title": {
                "fragments": [],
                "text": "Distinguishing Word Senses in Untagged Text"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "An experimental comparison of three unsupervised learning algorithms that distinguish the sense of an ambiguous word in untagged text using McQuitty's similarity analysis, Ward's minimum-variance method, and the EM algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1847175"
                        ],
                        "name": "M. Minsky",
                        "slug": "M.-Minsky",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Minsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Minsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61610148,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "6d801505d744dff6bb787b284ded9c2ef901ebbc",
            "isKey": false,
            "numCitedBy": 6445,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-framework-for-representing-knowledge-Minsky",
            "title": {
                "fragments": [],
                "text": "A framework for representing knowledge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3123001"
                        ],
                        "name": "K. Colby",
                        "slug": "K.-Colby",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Colby",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Colby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5981444"
                        ],
                        "name": "F. D. Hilf",
                        "slug": "F.-D.-Hilf",
                        "structuredName": {
                            "firstName": "Franklin",
                            "lastName": "Hilf",
                            "middleNames": [
                                "Dennis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. Hilf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47864374"
                        ],
                        "name": "S. Weber",
                        "slug": "S.-Weber",
                        "structuredName": {
                            "firstName": "Sylvia",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1921060"
                        ],
                        "name": "H. Kraemer",
                        "slug": "H.-Kraemer",
                        "structuredName": {
                            "firstName": "Helena",
                            "lastName": "Kraemer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kraemer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31542633,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "da173b19205747eceb603e7d2618307415e3e706",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Turing-like-Indistinguishability-Tests-for-the-of-a-Colby-Hilf",
            "title": {
                "fragments": [],
                "text": "Turing-like Indistinguishability Tests for the Calidation of a Computer Simulation of Paranoid Processes"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 179
                            }
                        ],
                        "text": "Learned sentiment lexicons such as the polarity lexicons of (Hatzivassiloglou and McKeown, 1997) were shown to be a useful feature in subjectivity detection (Hatzivassiloglou and Wiebe 2000, Wiebe 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14170522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5581992944c66522dd1b11f8a6150aeef2d95b7a",
            "isKey": false,
            "numCitedBy": 598,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Subjectivity tagging is distinguishing sentences used to present opinions and evaluations from sentences used to objectively present factual information. There are numerous applications for which subjectivity tagging is relevant, including information extraction and information retrieval. This paper identifies strong clues of subjectivity using the results of a method for clustering words according to distributional similarity (Lin 1998), seeded by a small amount of detailed manual annotation. These features are then further refined with the addition of lexical semantic features of adjectives, specifically polarity and gradability (Hatzivassiloglou & McKeown 1997), which can be automatically learned from corpora. In 10-fold cross validation experiments, features based on both similarity clusters and the lexical semantic features are shown to have higher precision than features based on each alone."
            },
            "slug": "Learning-Subjective-Adjectives-from-Corpora-Wiebe",
            "title": {
                "fragments": [],
                "text": "Learning Subjective Adjectives from Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper identifies strong clues of subjectivity using the results of a method for clustering words according to distributional similarity (Lin 1998), seeded by a small amount of detailed manual annotation."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2614094"
                        ],
                        "name": "Rebecca F. Bruce",
                        "slug": "Rebecca-F.-Bruce",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Bruce",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rebecca F. Bruce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 942975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98c5a252475fce36934e6c3d4710af1aa08a382b",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Most probabilistic classifiers used for word-sense disambiguation have either been based on only one contextual feature or have used a model that is simply assumed to characterize the interdependencies among multiple contextual features. In this paper, a different approach to formulating a probabilistic model is presented along with a case study of the performance of models produced in this manner for the disambiguation of the noun interest. We describe a method for formulating probabilistic models that use multiple contextual features for word-sense disambiguation, without requiring untested assumptions regarding the form of the model. Using this approach, the joint distribution of all variables is described by only the most systematic variable interactions, thereby limiting the number of parameters to be estimated, supporting computational efficiency, and providing an understanding of the data."
            },
            "slug": "Word-Sense-Disambiguation-Using-Decomposable-Models-Bruce-Wiebe",
            "title": {
                "fragments": [],
                "text": "Word-Sense Disambiguation Using Decomposable Models"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper describes a method for formulating probabilistic models that use multiple contextual features for word-sense disambiguation, without requiring untested assumptions regarding the form of the model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48777451"
                        ],
                        "name": "J. Katz",
                        "slug": "J.-Katz",
                        "structuredName": {
                            "firstName": "Jerrold",
                            "lastName": "Katz",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Katz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38663378"
                        ],
                        "name": "J. Fodor",
                        "slug": "J.-Fodor",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Fodor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fodor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9860676,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "7adb3c40ef03a458d35a3851fa66046936211cc3",
            "isKey": false,
            "numCitedBy": 1848,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.. Linguistic Society of America is collaborating with JSTOR to digitize, preserve and extend access to Language. 1. Introduction. This paperl does not attempt to present a semantic theory of a natural language, but rather to characterize the form of such a theory. A semantic theory of a natural language is part of a linguistic description of that language. Our problem, on the other hand, is part of the general theory of language, fully on a par with the problem of characterizing the structure of grammars of natural languages. A characterization of the abstract form of a semantic theory is given by a metatheory which answers such questions as these: What is the domain of a semantic theory? What are the descriptive and explanatory goals of a semantic theory? What mechanisms are employed in pursuit of these goals? What are the empirical and methodological constraints upon a semantic theory? The present paper approaches the problem of characterizing the form of semantic theories by describing the structure of a semantic theory of English. There can be little doubt but that the results achieved will apply directly to semantic theories of languages closely related to English. The question of their applicability to semantic theories of more distant languages will be left for subsequent investigations to explore. Nevertheless, the present investigation will provide results that can be applied to semantic theories of languages unrelated to English and suggestions about how to proceed with the construction of such theories. We may put our problem this way: What form should a semantic theory of a natural language take to accommodate in the most revealing way the facts about the semantic structure of that language supplied by descriptive research? This question is of primary importance at the present stage of the development of semantics because semantics suffers not from a dearth of facts about meanings and meaning relations in natural languages, but rather from the lack of an adequate theory to organize, systematize, and generalize these facts. Facts about the semantics of natural languages have been contributed in abundance by many diverse fields, including philosophy, linguistics, philology, and \u2026"
            },
            "slug": "The-structure-of-a-semantic-theory-Katz-Fodor",
            "title": {
                "fragments": [],
                "text": "The structure of a semantic theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144497046"
                        ],
                        "name": "N. Nilsson",
                        "slug": "N.-Nilsson",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Nilsson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nilsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1028275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b886f2c097b635ee9550ca29fff7dcbbb7727ff7",
            "isKey": false,
            "numCitedBy": 5912,
            "numCiting": 271,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a survey of Artifici'al Intelligence (AI). It divides the field into four cor~ topics (embodying the base fo\u00b7r a science of intelligence) and eight applications topics (in which research has been contributing to core ideas).. The paper discusses the history, the major landmarks, and some of the controversies in each of these twelve topics. Each topic is represented by a chart citing the major references. These references are contained in an extensive bibliography. The paper concludes with a discussion of some of the criticisms of 'AI and with some predictions about the course of future research."
            },
            "slug": "Artificial-Intelligence-Nilsson",
            "title": {
                "fragments": [],
                "text": "Artificial Intelligence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The history, the major landmarks, and some of the controversies in each of these twelve topics are discussed, as well as some predictions about the course of future research."
            },
            "venue": {
                "fragments": [],
                "text": "IFIP Congress"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8150809,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29053eab305c2b585bcfbb713243b05646e7d62d",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A criterion for pruning parameters from N-gram backoff language models is developed, based on the relative entropy between the original and the pruned model. It is shown that the relative entropy resulting from pruning a single N-gram can be computed exactly and efficiently for backoff models. The relative entropy measure can be expressed as a relative change in training set perplexity. This leads to a simple pruning criterion whereby all N-grams that change perplexity by less than a threshold are removed from the model. Experiments show that a production-quality Hub4 LM can be reduced to 26% its original size without increasing recognition error. We also compare the approach to a heuristic pruning criterion by Seymore and Rosenfeld (1996), and show that their approach can be interpreted as an approximation to the relative entropy criterion. Experimentally, both approaches select similar sets of N-grams (about 85% overlap), with the exact relative entropy criterion giving marginally better performance."
            },
            "slug": "Entropy-based-Pruning-of-Backoff-Language-Models-Stolcke",
            "title": {
                "fragments": [],
                "text": "Entropy-based Pruning of Backoff Language Models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that the relative entropy resulting from pruning a single N-gram can be computed exactly and efficiently for backoff models and shown that a production-quality Hub4 LM can be reduced to 26% its original size without increasing recognition error."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793475"
                        ],
                        "name": "A. Ratnaparkhi",
                        "slug": "A.-Ratnaparkhi",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ratnaparkhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ratnaparkhi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54c846ee00c6132d70429cc279e8577f63ed05e4",
            "isKey": false,
            "numCitedBy": 291,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a statistical parser for natural language that obtains a parsing accuracy---roughly 87% precision and 86% recall---which surpasses the best previously published results on the Wall St. Journal domain. The parser itself requires very little human intervention, since the information it uses to make parsing decisions is specified in a concise and simple manner, and is combined in a fully automatic way under the maximum entropy framework. The observed running time of the parser on a test sentence is linear with respect to the sentence length. Furthermore, the parser returns several scored parses for a sentence, and this paper shows that a scheme to pick the best parse from the 20 highest scoring parses could yield a dramatically higher accuracy of 93% precision and recall."
            },
            "slug": "A-Linear-Observed-Time-Statistical-Parser-Based-on-Ratnaparkhi",
            "title": {
                "fragments": [],
                "text": "A Linear Observed Time Statistical Parser Based on Maximum Entropy Models"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A statistical parser for natural language that obtains a parsing accuracy that surpasses the best previously published results on the Wall St. Journal domain, and it is shown that a scheme to pick the best parse from the 20 highest scoring parses could yield a dramatically higher accuracy of 93% precision and recall."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3777984"
                        ],
                        "name": "D. Saumier",
                        "slug": "D.-Saumier",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Saumier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Saumier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114187679"
                        ],
                        "name": "H. Chertkow",
                        "slug": "H.-Chertkow",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Chertkow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Chertkow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14184578,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7bc73f7a102ba29780eae9648c2e099e9f002fa2",
            "isKey": false,
            "numCitedBy": 923,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "Our concepts about objects, states, and events are stored in a cognitive structure termed semantic memory. There are several types of neurologic disorders that may cause impairments of semantic memory. Clinical evaluations of these impairments are complex, because semantic memory is linked to other cognitive systems that, when damaged, may produce related syndromes or difficulties. In an attempt to gain further understanding of these breakdown patterns, we review data from both neuropsychologic and brain activity research that have been concerned with how object concepts are represented and localized in the brain. Although these data have spawned varying and controversial views regarding the content and organization of semantic knowledge, converging evidence suggests that semantic memory is mainly localized in the posterior region of the left temporal lobe, and that particular categories of knowledge may be represented in different but overlapping regions within this area."
            },
            "slug": "Semantic-memory-Saumier-Chertkow",
            "title": {
                "fragments": [],
                "text": "Semantic memory"
            },
            "venue": {
                "fragments": [],
                "text": "Current neurology and neuroscience reports"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799688"
                        ],
                        "name": "V. Hatzivassiloglou",
                        "slug": "V.-Hatzivassiloglou",
                        "structuredName": {
                            "firstName": "Vasileios",
                            "lastName": "Hatzivassiloglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hatzivassiloglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 38
                            }
                        ],
                        "text": "The more sophisticated method used by Hatzivassiloglou and McKeown (1997) is to build a supervised classifier that predicts whether two words are of the same or different polarity, by using these 3 features (occurrence with and, occurrence with but, and morphological negations)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 61
                            }
                        ],
                        "text": "Learned sentiment lexicons such as the polarity lexicons of (Hatzivassiloglou and McKeown, 1997) were shown to be a useful feature in subjectivity detection (Hatzivassiloglou and Wiebe 2000, Wiebe 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 150
                            }
                        ],
                        "text": "\u2026et al., 2005) has 2718 positive and 4912 negative words drawn from a combination of sources, including the General Inquirer lists, the output of the Hatzivassiloglou and McKeown (1997) system described below, and a bootstrapped list of subjective words and phrases (Riloff and Wiebe, 2003) that was\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 55
                            }
                        ],
                        "text": "18.2.1 Using seed words and adjective coordination The Hatzivassiloglou and McKeown (1997) algorithm for labeling the polarity of adjectives is the same semi-supervised architecture described above."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 120
                            }
                        ],
                        "text": "All begin with a seed set of positive and negative words, as small as 2 words (Turney, 2002) or as large as a thousand (Hatzivassiloglou and McKeown, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 28
                            }
                        ],
                        "text": "Some sample output from the Hatzivassiloglou and McKeown (1997) algorithm is shown below, showing system errors in red."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8162001,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b62b80384f402d38c3425db6a99899d1cb9c50c6",
            "isKey": true,
            "numCitedBy": 1301,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We identify and validate from a large corpus constraints from conjunctions on the positive or negative semantic orientation of the conjoined adjectives. A log-linear regression model uses these constraints to predict whether conjoined adjectives are of same or different orientations, achieving 82% accuracy in this task when each conjunction is considered independently. Combining the constraints across many adjectives, a clustering algorithm separates the adjectives into groups of different orientations, and finally, adjectives are labeled positive or negative. Evaluations on real data and simulation experiments indicate high levels of performance: classification precision is more than 90% for adjectives that occur in a modest number of conjunctions in the corpus."
            },
            "slug": "Predicting-the-Semantic-Orientation-of-Adjectives-Hatzivassiloglou-McKeown",
            "title": {
                "fragments": [],
                "text": "Predicting the Semantic Orientation of Adjectives"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A log-linear regression model uses constraints from conjunctions to predict whether conjoined adjectives are of same or different orientations, achieving 82% accuracy in this task when each conjunction is considered independently."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18817171,
            "fieldsOfStudy": [
                "Law"
            ],
            "id": "54859dd7fcfd9112e01eded68a29cd26611d66e8",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Table 1: Sample Concordances of duty (split into two senses) Sense Examples (from Canadian Hansards) tax fewer cases of companies paying duty and then claiming a refund and impose a countervailing duty of 29,1 per cent on candian exports of the united states imposed a duty on canadian salttish last year obligation it is my honour and duty to present a petition duly approved working well beyond the call of duty ? SENT i know what time they start in addition, it is my duty to present the government\u2019s comments"
            },
            "slug": "Work-on-Statistical-Methods-for-Word-Sense-Gale-Church",
            "title": {
                "fragments": [],
                "text": "Work on Statistical Methods for Word Sense Disambiguation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15379653"
                        ],
                        "name": "Ann A. Copestake",
                        "slug": "Ann-A.-Copestake",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Copestake",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ann A. Copestake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145693410"
                        ],
                        "name": "Ted Briscoe",
                        "slug": "Ted-Briscoe",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Briscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Briscoe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15902300,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "id": "8c50c2efeadf4ce085b988f0dfdb5c4d22567f1b",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Les AA. examinent les aspects de la polysemie systematique ou conventionnelle et leur traitement formel dans une approche (fondee sur les contraintes) de la representation linguistique. Ils distinguent deux classes de polysemie systematique: =la polysemie de construction, ou un sens unique assigne a une entree lexicale est contextuellement specialise; =l'extension du sens, qui renvoie a deux sens ou plus"
            },
            "slug": "Semi-productive-Polysemy-and-Sense-Extension-Copestake-Briscoe",
            "title": {
                "fragments": [],
                "text": "Semi-productive Polysemy and Sense Extension"
            },
            "venue": {
                "fragments": [],
                "text": "J. Semant."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710450"
                        ],
                        "name": "J. Zelle",
                        "slug": "J.-Zelle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Zelle",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 204
                            }
                        ],
                        "text": "Detecting the personality of a user\u2014such as whether the user is an extrovert or the extent to which they are open to experience\u2014 can help improve conversational agents, which seem to work better if they match users\u2019 personality expectations (Mairesse and Walker, 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 263135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7c0e47f8b768258b7d536c21b218e6c46ab8791",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural-language interface for database queries. CHILL treats parser acquisition as the learning of search-control rules within a logic program representing a shift-reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge. Starting with a general framework for constructing a suitable logical form, CHILL is able to train on a corpus comprising sentences paired with database queries and induce parsers that map subsequent sentences directly into executable queries. Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart. These results demonstrate the ability of a corpus-based system to produce more than purely syntactic representations. They also provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "slug": "Learning-to-Parse-Database-Queries-Using-Inductive-Zelle-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning to Parse Database Queries Using Inductive Logic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart, and provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 2"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "68994357"
                        ],
                        "name": "Hinrich Schfitze",
                        "slug": "Hinrich-Schfitze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Schfitze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Schfitze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19019672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "701d176a76d7337d0682c09011ea02bb12b5716b",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Tile representation of documents and queries as vectors in space is a well-known information retrieval paradigm (Salton and McGill, 1983). This paper suggests that the context or topic at a given point in a text can also be represented as a vector. A procedure for computing context vectors is introduced and applied to disambiguating ten English words with success rates between 89% and 95%. The structure of context space is analyzed. The paper argues that vectors with their potential for gradedness may be superior for some purposes to other representational schemes. Representing contexts as vectors Recently, there has been a lot of interest in measures of semantic relatedness such as mutual information (Church and Hanks, 1989). The main reason seems to be that for many tasks in language processing a rough measure of semantic similarity and association is needed. In this paper a new representational scheme is introduced that tries to provide a basis for determining closeness in meaning. The approach is motivated by work oil vector representations in information retrieval. In IR systems such as SMART and SIRE documents and queries are represented as vectors in term space (Salton and McGill, 1983). The assumption that two documents are similar to the extent that they contain the same words. An obvious extension of this methodology to the representation of contexts is to assign to each context the set of words that occur in close proximity, say in a window of fifty words. However, the same content can be expressed with very different words, so that in this simple scheme two contexts could have a similarity measure of 0 although they should be very close. The problem is that the absence or presence of a given word is very little information if we treat words as unanalyzed symbols or indices in term vectors. The lexical representations used for comparing contexts have to be enriched. The approach adopted here is to equate words with their patterns of usage in a large text corpus. Figure 1 shows how this can be done. The terms cash and sport are the dimensions of the space in which similarity is to be measured. The columns of the matrix represent the words bank, interest, and finals. Each entry in the matrix is a cooccurrence count. For instance, acash, bank = 300 encodes the fact that the words cash and bank cooccur 300 times in the corpus. Cooccurrence can be defined with respect to windows of a given size or on the basis of sentence boundaries. In information retrieval, the cosine function is one of the similarity measures used: COS(WORDi, WORDj) = ~=l(ak\u2019iak\u2019J) ~ n a 2 X-,n _2 k=l k,i /--~k=l t*k,j Applied to the three word vectors in Figure 1, we can compute the following correlation measures: cos(bank, interest) = 0.94, cos(interest, finals) = 0.92, cos(bank, finals) 0.74. These numbers can beint erpreted geometrically as shown in Figure 2. Terms are axes, words are vectors whose components on the various dimensions are determined by the cooccurrence counts in the collocation matrix. Similarity between vectors has then a straightforward visual equivalent: Closeness in the multidimensional space corresponding to the collocation matrix. In Figure 2 bank and finals are not very close to each other, but both are close to the vector interest between them. Now we are in a position to compute a representation of context that is more reliable than the bag-of-words method criticized above: The centroid of the vectors in a context can be seen as an approximation of its semantic content. If at least some of the words in the context are frequently used to describe what the current context is about then they will pull the centroid toward the direction of that content. It is possible to describe a content exclusively using words that norJbank interest finals cash 300 210 133 sport 75 140 200 Figure 1: A collocation matrix. 113 From: AAAI Technical Report FS-92-04. Copyright \u00a9 1992, AAAI (www.aaai.org). All rights reserved."
            },
            "slug": "Context-Space-Schfitze",
            "title": {
                "fragments": [],
                "text": "Context Space"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The paper argues that vectors with their potential for gradedness may be superior for some purposes to other representational schemes, and tries to provide a basis for determining closeness in meaning in contexts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144756036"
                        ],
                        "name": "A. Radford",
                        "slug": "A.-Radford",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Radford"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60800148,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "45f927eab68f6bb4712459284c86c428b16d4eb1",
            "isKey": false,
            "numCitedBy": 446,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Prologue Acknowledgments 1. Goals 2. Structure 3. Phrase-markers 4. Noun phrases 5. Other phrases 6. Clauses 7. The lexicon 8. Transformations 9. WH movement 10. Alpha movement Bibliographical background Bibliography Index."
            },
            "slug": "Transformational-Grammar:-A-First-Course-Radford",
            "title": {
                "fragments": [],
                "text": "Transformational Grammar: A First Course"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This chapter discusses the construction of the lexicon in the context of the WH movement and some of the phrases that formed part of that lexicon."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6089322,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "51f393365ad74d7e20db44325d96cd65cfea0e36",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Acknowledgements 1. Introduction 2. Syntactic categorisation 3. Semantic categorisation 4. Subcategorization 5. A look back 6. Appendix A: mathematical methods References."
            },
            "slug": "Ambiguity-resolution-in-language-learning-and-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Ambiguity resolution in language learning - computational and cognitive models"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a meta-analyses of semantic categorisation in the context of Wikipedia, which aims to provide a scaffolding for the future categorisation of Wikipedia into categories of \u201cfood\u201d and \u201cpeople\u201d."
            },
            "venue": {
                "fragments": [],
                "text": "CSLI lecture notes series"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112185508"
                        ],
                        "name": "F. R.",
                        "slug": "F.-R.",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "R.",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. R."
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14866811,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "9d63e2694de0d685b1d1f2ad60e475961ee230fa",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "In the world of computer science, networks are mathematical and computational structures composed of sets of nodes connected by directed arcs. A semantic network purports to represent concepts expressed by natural-language words and phrases as nodes connected to other such concepts by a particular set of arcs called semantic relations. Primitive concepts in this system of semantic networks are word-sense meanings. Primitive semantic relations are those that the verb of a sentence has with its subject, object, and prepositional phrase arguments in addition to those that underlie common lexical, classificational and modificational relations. A complete statement of semantic relations would include all those relations that would be required in the total classification of a natural language vocabulary. We consider the theory and model of semantic nets to be a computational theory of superficial verbal understanding in humans. W e conceive semantic nodes as representing human verbal concept structures and semantic relations connecting two such structures as representing the linguistic processes of thought that are used to combine them into natural-language descriptions of events. Some psycholin-guistic evidence supports this theory"
            },
            "slug": "Two-Semantic-Networks-:-Their-Computation-and-Use-F.",
            "title": {
                "fragments": [],
                "text": "Two Semantic Networks : Their Computation and Use for Understanding English Sentences"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The theory and model of semantic nets are considered to be a computational theory of superficial verbal understanding in humans and semantic nodes as representing human verbal concept structures and semantic relations connecting two such structures as representing the linguistic processes of thought that are used to combine them into natural-language descriptions of events."
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795942"
                        ],
                        "name": "Reinhard Kneser",
                        "slug": "Reinhard-Kneser",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Kneser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Reinhard Kneser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9685476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9548ac30c113562a51e603dbbc8e9fa651cfd3ab",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In stochastic language modeling, backing-off is a widely used method to cope with the sparse data problem. In case of unseen events this method backs off to a less specific distribution. In this paper we propose to use distributions which are especially optimized for the task of backing-off. Two different theoretical derivations lead to distributions which are quite different from the probability distributions that are usually used for backing-off. Experiments show an improvement of about 10% in terms of perplexity and 5% in terms of word error rate."
            },
            "slug": "Improved-backing-off-for-M-gram-language-modeling-Kneser-Ney",
            "title": {
                "fragments": [],
                "text": "Improved backing-off for M-gram language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes to use distributions which are especially optimized for the task of back-off, which are quite different from the probability distributions that are usually used for backing-off."
            },
            "venue": {
                "fragments": [],
                "text": "1995 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3853032"
                        ],
                        "name": "J. Lai",
                        "slug": "J.-Lai",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Lai",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10986188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3de5d40b60742e3dfa86b19e7f660962298492af",
            "isKey": false,
            "numCitedBy": 3318,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of predicting a word from previous words in a sample of text. In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words. We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics."
            },
            "slug": "Class-Based-n-gram-Models-of-Natural-Language-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "Class-Based n-gram Models of Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work addresses the problem of predicting a word from previous words in a sample of text and discusses n-gram models based on classes of words, finding that these models are able to extract classes that have the flavor of either syntactically based groupings or semanticallybased groupings, depending on the nature of the underlying statistics."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145036961"
                        ],
                        "name": "Graeme Hirst",
                        "slug": "Graeme-Hirst",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Hirst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graeme Hirst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 22052389,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "944dd4cce541c856a5e2ea5fb22962e760d015d2",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface 1. Introduction 2. Semantic interpretation 3. The Absity semantic interpreter 4. Lexical disambiguation 5. Polaroid words 6. Structural disambiguation 7. The semantic enquiry desk 8. Conclusion 9. Speculations, partially baked ideas, and exercises for the reader References Index of names Index of subjects."
            },
            "slug": "Semantic-Interpretation-and-the-Resolution-of-Hirst",
            "title": {
                "fragments": [],
                "text": "Semantic Interpretation and the Resolution of Ambiguity"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The Absity semantic interpreter helps clarify the role of language in semantic interpretation and provides a basis for future semantic interpreters to address language-based problems."
            },
            "venue": {
                "fragments": [],
                "text": "Studies in natural language processing"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1847175"
                        ],
                        "name": "M. Minsky",
                        "slug": "M.-Minsky",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Minsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Minsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14250548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8ff8c7ab23eb70d4179c15a8a6b0efa1a493b8b",
            "isKey": false,
            "numCitedBy": 1320,
            "numCiting": 142,
            "paperAbstract": {
                "fragments": [],
                "text": "The problems of heuristic programming-of making computers solve really difficult problems-are divided into five main areas: Search, Pattern-Recognition, Learning, Planning, and Induction. A computer can do, in a sense, only what it is told to do. But even when we do not know how to solve a certain problem, we may program a machine (computer) to Search through some large space of solution attempts. Unfortunately, this usually leads to an enormously inefficient process. With Pattern-Recognition techniques, efficiency can often be improved, by restricting the application of the machine's methods to appropriate problems. Pattern-Recognition, together with Learning, can be used to exploit generalizations based on accumulated experience, further reducing search. By analyzing the situation, using Planning methods, we may obtain a fundamental improvement by replacing the given search with a much smaller, more appropriate exploration. To manage broad classes of problems, machines will need to construct models of their environments, using some scheme for Induction. Wherever appropriate, the discussion is supported by extensive citation of the literature and by descriptions of a few of the most successful heuristic (problem-solving) programs constructed to date."
            },
            "slug": "Steps-toward-Artificial-Intelligence-Minsky",
            "title": {
                "fragments": [],
                "text": "Steps toward Artificial Intelligence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The discussion is supported by extensive citation of the literature and by descriptions of a few of the most successful heuristic (problem-solving) programs constructed to date."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IRE"
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15698938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd1901f34cc3673072264104885d70555b1a4cdc",
            "isKey": false,
            "numCitedBy": 1928,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Bootstrapping semantics from text is one of the greatest challenges in natural language learning. We first define a word similarity measure based on the distributional pattern of words. The similarity measure allows us to construct a thesaurus using a parsed corpus. We then present a new evaluation methodology for the automatically constructed thesaurus. The evaluation results show that the thesaurus is significantly closer to WordNet than Roget Thesaurus is."
            },
            "slug": "Automatic-Retrieval-and-Clustering-of-Similar-Words-Lin",
            "title": {
                "fragments": [],
                "text": "Automatic Retrieval and Clustering of Similar Words"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A word similarity measure based on the distributional pattern of words allows the automatically constructed thesaurus to be significantly closer to WordNet than Roget Thesaurus is."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748407"
                        ],
                        "name": "J. Bellegarda",
                        "slug": "J.-Bellegarda",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Bellegarda",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bellegarda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8238767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a90c1ca6c335de94721d7445bb01b723c3d9a840",
            "isKey": false,
            "numCitedBy": 390,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical language models used in large-vocabulary speech recognition must properly encapsulate the various constraints, both local and global, present in the language. While local constraints are readily captured through n-gram modeling, global constraints, such as long-term semantic dependencies, have been more difficult to handle within a data-driven formalism. This paper focuses on the use of latent semantic analysis, a paradigm that automatically uncovers the salient semantic relationships between words and documents in a given corpus. In this approach, (discrete) words and documents are mapped onto a (continuous) semantic vector space, in which familiar clustering techniques can be applied. This leads to the specification of a powerful framework for automatic semantic classification, as well as the derivation of several language model families with various smoothing properties. Because of their large-span nature, these language models are well suited to complement conventional n-grams. An integrative formulation is proposed for harnessing this synergy, in which the latent semantic information is used to adjust the standard n-gram probability. Such hybrid language modeling compares favorably with the corresponding n-gram baseline: experiments conducted on the Wall Street Journal domain show a reduction in average word error rate of over 20%. This paper concludes with a discussion of intrinsic tradeoffs, such as the influence of training data selection on the resulting performance."
            },
            "slug": "Exploiting-latent-semantic-information-in-language-Bellegarda",
            "title": {
                "fragments": [],
                "text": "Exploiting latent semantic information in statistical language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper focuses on the use of latent semantic analysis, a paradigm that automatically uncovers the salient semantic relationships between words and documents in a given corpus, and proposes an integrative formulation for harnessing this synergy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416786"
                        ],
                        "name": "Mats Rooth",
                        "slug": "Mats-Rooth",
                        "structuredName": {
                            "firstName": "Mats",
                            "lastName": "Rooth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mats Rooth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289329"
                        ],
                        "name": "S. Riezler",
                        "slug": "S.-Riezler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Riezler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riezler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2694275"
                        ],
                        "name": "D. Prescher",
                        "slug": "D.-Prescher",
                        "structuredName": {
                            "firstName": "Detlef",
                            "lastName": "Prescher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Prescher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3264213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d0c052eabed016faeb1fba49dcd8ef6c551a79c",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a technique for automatic induction of slot annotations for subcategorization frames, based on induction of hidden classes in the EM framework of statistical estimation. The models are empirically evaluated by a general decision test. Induction of slot labeling for subcategorization frames is accomplished by a further application of EM, and applied experimentally on frame observations derived from parsing large corpora. We outline an interpretation of the learned representations as theoretical-linguistic decompositional lexical entries."
            },
            "slug": "Inducing-a-Semantically-Annotated-Lexicon-via-Rooth-Riezler",
            "title": {
                "fragments": [],
                "text": "Inducing a Semantically Annotated Lexicon via EM-Based Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A technique for automatic induction of slot annotations for subcategorization frames, based on induction of hidden classes in the EM framework of statistical estimation, and an interpretation of the learned representations as theoretical-linguistic decompositional lexical entries are presented."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152187551"
                        ],
                        "name": "R. Quirk",
                        "slug": "R.-Quirk",
                        "structuredName": {
                            "firstName": "Randolph",
                            "lastName": "Quirk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Quirk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143998726"
                        ],
                        "name": "G. Leech",
                        "slug": "G.-Leech",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Leech",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Leech"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2867865"
                        ],
                        "name": "Jan Svartvik",
                        "slug": "Jan-Svartvik",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Svartvik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan Svartvik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59805466,
            "fieldsOfStudy": [
                "Education",
                "Linguistics"
            ],
            "id": "9998130785e57709fe9a7bbb92fed7daa4304faf",
            "isKey": false,
            "numCitedBy": 7567,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An indispensable store of information on the English language, written by some of the best-known grammarians in the world."
            },
            "slug": "A-__-comprehensive-grammar-of-the-English-language-Quirk-Leech",
            "title": {
                "fragments": [],
                "text": "A __ comprehensive grammar of the English language"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An indispensable store of information on the English language, written by some of the best-known grammarians in the world."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31408841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32a175b36ec7f2f08cb3dfac30ce141e144ec9e9",
            "isKey": false,
            "numCitedBy": 991,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical methods useful in automatic recognition of continuous speech are described. They concern modeling of a speaker and of an acoustic processor, extraction of the models' statistical parameters and hypothesis search procedures and likelihood computations of linguistic decoding. Experimental results are presented that indicate the power of the methods."
            },
            "slug": "Continuous-speech-recognition-by-statistical-Jelinek",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition by statistical methods"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Experimental results are presented that indicate the power of the methods and concern modeling of a speaker and of an acoustic processor, extraction of the models' statistical parameters and hypothesis search procedures and likelihood computations of linguistic decoding."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7311285,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04ce064505b1635583fa0d9cc07cac7e9ea993cc",
            "isKey": false,
            "numCitedBy": 3834,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work in text classification has used two different first-order probabilistic models for classification, both of which make the naive Bayes assumption. Some use a multi-variate Bernoulli model, that is, a Bayesian Network with no dependencies between words and binary word features (e.g. Larkey and Croft 1996; Koller and Sahami 1997). Others use a multinomial model, that is, a uni-gram language model with integer word counts (e.g. Lewis and Gale 1994; Mitchell 1997). This paper aims to clarify the confusion by describing the differences and details of these two models, and by empirically comparing their classification performance on five text corpora. We find that the multi-variate Bernoulli performs well with small vocabulary sizes, but that the multinomial performs usually performs even better at larger vocabulary sizes--providing on average a 27% reduction in error over the multi-variate Bernoulli model at any vocabulary size."
            },
            "slug": "A-comparison-of-event-models-for-naive-bayes-text-McCallum-Nigam",
            "title": {
                "fragments": [],
                "text": "A comparison of event models for naive bayes text classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is found that the multi-variate Bernoulli performs well with small vocabulary sizes, but that the multinomial performs usually performs even better at larger vocabulary sizes--providing on average a 27% reduction in error over the multi -variateBernoulli model at any vocabulary size."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 1998"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804633"
                        ],
                        "name": "G. Hendrix",
                        "slug": "G.-Hendrix",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Hendrix",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hendrix"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2703228"
                        ],
                        "name": "C. Thompson",
                        "slug": "C.-Thompson",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Thompson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763912"
                        ],
                        "name": "J. Slocum",
                        "slug": "J.-Slocum",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Slocum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Slocum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10422416,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "e3b835126d0f610ffc30eaa2b86b59f8e9da434d",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A natural language question answering system is presented. The system's parser maps semantic paraphrases into a single deep structure characterized by a canonical verb. A modeling scheme using semantic nets and STRIPS-like operators assimilates the sequence of input information. Natural language responses to questions are generated from a data base of semantic nets by \"parsing\" syntactic rules retrieved from the lexicon."
            },
            "slug": "Language-Processing-Via-Canonical-Verbs-and-Models-Hendrix-Thompson",
            "title": {
                "fragments": [],
                "text": "Language Processing Via Canonical Verbs and Semantic Models"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A natural language question answering system that generates natural language responses to questions by \"parsing\" syntactic rules retrieved from the lexicon using semantic nets and STRIPS-like operators."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3226331"
                        ],
                        "name": "C. Leacock",
                        "slug": "C.-Leacock",
                        "structuredName": {
                            "firstName": "Claudia",
                            "lastName": "Leacock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leacock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818801"
                        ],
                        "name": "Randee Tengi",
                        "slug": "Randee-Tengi",
                        "structuredName": {
                            "firstName": "Randee",
                            "lastName": "Tengi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Randee Tengi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144819917"
                        ],
                        "name": "R. Bunker",
                        "slug": "R.-Bunker",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Bunker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bunker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7231199,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "f9a25e0dc776857fc24ebc7115c980312f2719b1",
            "isKey": false,
            "numCitedBy": 726,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A semantic concordance is a textual corpus and a lexicon so combined that every substantive word in the text is linked to its appropriate sense in the lexicon. Thus it can be viewed either as a corpus in which words have been tagged syntactically and semantically, or as a lexicon in which example sentences can be found for many definitions. A semantic concordance is being constructed to use in studies of sense resolution in context (semantic disambiguation). The Brown Corpus is the text and WordNet is the lexicon. Semantic tags (pointers to WordNet synsets) are inserted in the text manually using an interface, ConText, that was designed to facilitate the task. Another interface supports searches of the tagged text. Some practical uses for semantic concordances am proposed."
            },
            "slug": "A-Semantic-Concordance-Miller-Leacock",
            "title": {
                "fragments": [],
                "text": "A Semantic Concordance"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A semantic concordance is a textual corpus and a lexicon so combined that every substantive word in the text is linked to its appropriate sense in the lexicon."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153901204"
                        ],
                        "name": "Xin Li",
                        "slug": "Xin-Li",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11039301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c8ac3e1f0edeed1fbd76813e61efdc384c319c7",
            "isKey": false,
            "numCitedBy": 1159,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In order to respond correctly to a free form factual question given a large collection of texts, one needs to understand the question to a level that allows determining some of the constraints the question imposes on a possible answer. These constraints may include a semantic classification of the sought after answer and may even suggest using different strategies when looking for and verifying a candidate answer.This paper presents a machine learning approach to question classification. We learn a hierarchical classifier that is guided by a layered semantic hierarchy of answer types, and eventually classifies questions into fine-grained classes. We show accurate results on a large collection of free-form questions used in TREC 10."
            },
            "slug": "Learning-Question-Classifiers-Li-Roth",
            "title": {
                "fragments": [],
                "text": "Learning Question Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A hierarchical classifier is learned that is guided by a layered semantic hierarchy of answer types, and eventually classifies questions into fine-grained classes."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143696281"
                        ],
                        "name": "David Mart\u00ednez",
                        "slug": "David-Mart\u00ednez",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mart\u00ednez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Mart\u00ednez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 612929,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "a8c40eea604e448ee278a33e88ed345ddc8a64f6",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Selectional preference learning methods have usually focused on word-to-class relations, e.g., a verb selects as its subject a given nominal class. This papers extends previous statistical models to class-to-class preferences, and presents a model that learns selectional preferences for classes of verbs. The motivation is twofold: different senses of a verb may have different preferences, and some classes of verbs can share preferences. The model is tested on a word sense disambiguation task which uses subject-verb and object-verb relationships extracted from a small sense-disambiguated corpus."
            },
            "slug": "Learning-class-to-class-selectional-preferences-Agirre-Mart\u00ednez",
            "title": {
                "fragments": [],
                "text": "Learning class-to-class selectional preferences"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A model that learns selectional preferences for classes of verbs is presented, which is tested on a word sense disambiguation task which uses subject-verb and object-verb relationships extracted from a small sense-disambiguated corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791311"
                        ],
                        "name": "U. Hermjakob",
                        "slug": "U.-Hermjakob",
                        "structuredName": {
                            "firstName": "Ulf",
                            "lastName": "Hermjakob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Hermjakob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064774858"
                        ],
                        "name": "Deepak Ravichandran",
                        "slug": "Deepak-Ravichandran",
                        "structuredName": {
                            "firstName": "Deepak",
                            "lastName": "Ravichandran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deepak Ravichandran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14222633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "612a793c8750dafcb20a451adba28d33fbd1e457",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we announce the release of ISI's QA Typology, which is being made available on the web to support the rapid construction of new QA systems. The Typology has been augmented with surface-level patterns associated with answer types, allowing systems to locate answers of the desired type in text by simple string matching. These patterns are extracted from the web automatically. We describe the process of their extraction, compression, and accuracy determination."
            },
            "slug": "A-question/answer-typology-with-surface-text-Hovy-Hermjakob",
            "title": {
                "fragments": [],
                "text": "A question/answer typology with surface text patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "In this paper, ISI's QA Typology has been augmented with surface-level patterns associated with answer types, allowing systems to locate answers of the desired type in text by simple string matching."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8754851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cd9fd8a36c8feb74bb20ae25817edb9c6a0518c",
            "isKey": false,
            "numCitedBy": 1401,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering. Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words."
            },
            "slug": "Automatic-Word-Sense-Discrimination-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Automatic Word Sense Discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering that demonstrates good performance of context- group discrimination for a sample of natural and artificial ambiguous words."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15165852,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf9bb11568744402f3d569a83093c58b9b58349b",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose to define selectional preference and semantic similarity as information-theoretic relationships involving conceptual classes, and we demonstrate the applicability of these definitions to the resolution of syntactic ambiguity. The space of classes is defined using WordNet [8], and conceptual relationships are determined by means of statistical analysis using parsed text in the Penn Treebank."
            },
            "slug": "Semantic-Classes-and-Syntactic-Ambiguity-Resnik",
            "title": {
                "fragments": [],
                "text": "Semantic Classes and Syntactic Ambiguity"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper proposes to define selectional preference and semantic similarity as information-theoretic relationships involving conceptual classes, and demonstrates the applicability of these definitions to the resolution of syntactic ambiguity."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 459591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51d1ecb07017402702feb38f2f881d6723297b2b",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Estimating word co-occurrence probabilities is a problem underlying many applications in statistical natural language processing. Distance-weighted (or similarityweighted) averaging has been shown to be a promising approach to the analysis of novel co-occurrences. Many measures of distributional similarity have been proposed for use in the distance-weighted averaging framework; here, we empirically study their stability properties, finding that similarity-based estimation appears to make more efficient use of more reliable portions of the training data. We also investigate properties of the skew divergence, a weighted version of the KullbackLeibler (KL) divergence; our results indicate that the skew divergence yields better results than the KL divergence even when the KL divergence is applied to more sophisticated probability estimates."
            },
            "slug": "On-the-effectiveness-of-the-skew-divergence-for-Lee",
            "title": {
                "fragments": [],
                "text": "On the effectiveness of the skew divergence for statistical language analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is found that similarity-based estimation appears to make more efficient use of more reliable portions of the training data, and the skew divergence yields better results than the KL divergence even when the Kuala Lumpur divergence is applied to more sophisticated probability estimates."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2944691"
                        ],
                        "name": "J. Justeson",
                        "slug": "J.-Justeson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Justeson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Justeson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35229948"
                        ],
                        "name": "S. Katz",
                        "slug": "S.-Katz",
                        "structuredName": {
                            "firstName": "Slava",
                            "lastName": "Katz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Katz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 26
                            }
                        ],
                        "text": "(Miller and Charles 1991, Justeson and Katz 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7003847,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ed4f7e0e3d8afdacf1adfaf706ab5f27a87816d8",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Charles and Miller propose that lexical associations between antonymous adjectives are formed via their co-occurences within the same sentence (the co-occurrence hypothesis), rather than via their syntatic substitutability (the substitutability hypothesis), and that such co-occurrences must take place more often than expected by chance. This paper provides empirical support for the co-occurrence hypothesis in a corpus analysis of all high-frequency adjectives and their antonyms and of a major group of morphologically derived antonyms (e.g., impossible, un-happy). We show that very high co-occurrence rates do appear to characterize all antonymous adjective pairs, supporting the precondition for the formation of the association; and we find that the syntactic contexts of these co-occurrences raise the intrinsic associability of antonyms when they do co-occur. We show that via one of these patterns, mutual substitution within otherwise repeated phrases in a sentence, the co-occurrences hypothesis captures the generalizations that were the basis for the substitutability hypothesis for the formation of antonymic associations."
            },
            "slug": "Co-Occurrences-of-Antonymous-Adjectives-and-Their-Justeson-Katz",
            "title": {
                "fragments": [],
                "text": "Co-Occurrences of Antonymous Adjectives and Their Contexts"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Empirical support is provided for the co-occurrences hypothesis in a corpus analysis of all high-frequency adjectives and their antonyms and of a major group of morphologically derived antonYms (e.g., impossible, un-happy)."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143745511"
                        ],
                        "name": "R. F. Simmons",
                        "slug": "R.-F.-Simmons",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Simmons",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. F. Simmons"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144268342"
                        ],
                        "name": "Sheldon Klein",
                        "slug": "Sheldon-Klein",
                        "structuredName": {
                            "firstName": "Sheldon",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sheldon Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51952328"
                        ],
                        "name": "Keren McConlogue",
                        "slug": "Keren-McConlogue",
                        "structuredName": {
                            "firstName": "Keren",
                            "lastName": "McConlogue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keren McConlogue"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62187750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dfa2a5e8aa5e18c6566cc41e4ab4885030e10dd",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a computer system which uses a combination of coordinate indexing and structure matching techniques to extract from English questions many criteria which can be used for selecting and recognizing answers. A complete index of all content words in text is first searched to find information-rich statements which may be answers to the question. Each of these statements is then dependency analyzed to determine if the words (or synonyms) which correspond to question words maintain the dependency relations holding in the question. A simple semantic evaluation of structurally acceptable answers follows. A human editor working with the computer system helps to resolve syntactic ambiguities which are otherwise a major stumbling block in question-answering systems."
            },
            "slug": "Indexing-and-dependency-logic-for-answering-english-Simmons-Klein",
            "title": {
                "fragments": [],
                "text": "Indexing and dependency logic for answering english questions"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A computer system which uses a combination of coordinate indexing and structure matching techniques to extract from English questions many criteria which can be used for selecting and recognizing answers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706504"
                        ],
                        "name": "J. Hopcroft",
                        "slug": "J.-Hopcroft",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopcroft",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopcroft"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31901407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41a88a490d7ba9e383ecb16c4290083413a08258",
            "isKey": false,
            "numCitedBy": 13820,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Introduction-to-Automata-Theory,-Languages-and-Hopcroft-Ullman",
            "title": {
                "fragments": [],
                "text": "Introduction to Automata Theory, Languages and Computation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854783"
                        ],
                        "name": "J. Pennebaker",
                        "slug": "J.-Pennebaker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Pennebaker",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pennebaker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50728710"
                        ],
                        "name": "L. King",
                        "slug": "L.-King",
                        "structuredName": {
                            "firstName": "Lynda",
                            "lastName": "King",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. King"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 20
                            }
                        ],
                        "text": "The essay corpus of Pennebaker and King (1999) consists of 2,479 essays (1.9 million words) from psychology students who were asked to \u201cwrite whatever comes into your mind\u201d for 20 minutes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 35
                            }
                        ],
                        "text": "For example, here are samples from Pennebaker and King (1999) from an essay written by someone on the neurotic end of the neurotic/emotionally stable scale,\nOne of my friends just barged in, and I jumped in my seat."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29567532,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "56cac19718d9e788e2cf19fcd9fef36450d0b783",
            "isKey": true,
            "numCitedBy": 1533,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Can language use reflect personality style? Studies examined the reliability, factor structure, and validity of written language using a word-based, computerized text analysis program. Daily diaries from 15 substance abuse inpatients, daily writing assignments from 35 students, and journal abstracts from 40 social psychologists demonstrated good internal consistency for over 36 language dimensions. Analyses of the best 15 language dimensions from essays by 838 students yielded 4 factors that replicated across written samples from another 381 students. Finally, linguistic profiles from writing samples were compared with Thematic Apperception Test coding, self-reports, and behavioral measures from 79 students and with self-reports of a 5-factor measure and health markers from more than 1,200 students. Despite modest effect sizes, the data suggest that linguistic style is an independent and meaningful way of exploring personality."
            },
            "slug": "Linguistic-styles:-language-use-as-an-individual-Pennebaker-King",
            "title": {
                "fragments": [],
                "text": "Linguistic styles: language use as an individual difference."
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The data suggest that linguistic style is an independent and meaningful way of exploring personality, and factor structure, and validity of written language using a word-based, computerized text analysis program."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of personality and social psychology"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784519"
                        ],
                        "name": "Peter Norvig",
                        "slug": "Peter-Norvig",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Norvig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Norvig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53142908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3524cdf7cf8344e7eb74886f71fcbb5c6732c337",
            "isKey": false,
            "numCitedBy": 26736,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logic. Logical Reasoning Systems. Practical Planning. Planning and Acting. Uncertainty. Probabilistic Reasoning Systems. Making Simple Decisions. Making Complex Decisions. Learning from Observations. Learning with Neural Networks. Reinforcement Learning. Knowledge in Learning. Agents that Communicate. Practical Communication in English. Perception. Robotics. For computer professionals, linguists, and cognitive scientists interested in artificial intelligence."
            },
            "slug": "Artificial-Intelligence:-A-Modern-Approach-Russell-Norvig",
            "title": {
                "fragments": [],
                "text": "Artificial Intelligence: A Modern Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144451588"
                        ],
                        "name": "J. Backus",
                        "slug": "J.-Backus",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Backus",
                            "middleNames": [
                                "Warner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Backus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 44764020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d075466245c0a58a6c2c98198ae2c6d937b0af11",
            "isKey": false,
            "numCitedBy": 398,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives a summary of the syntax and interpretation rules of the proposed international algebraic language put forward by the Zurich ACM-GAMM Conference, followed by a formal , complete presentation of the same information. Notations are presented for numbers, numerical variables, Boolean variables , relations, n-dimensional arrays, functions, operators and algebraic expressions. Means are provided in the language for the assignment of values to variables, conditional execution of statements , iterative procedures, formation of compound statements from sequences of statements, definition of new statements for arbitrary procedures, and the re-use and alteration of program segments. The proposed language is intended to provide convenient and concise means for expressing virtually all procedures of numerical computation while employing relatively few syntactical rules and types of statement. La syl1taxe et la semantique de langage algebraic international propose par la Conference de Zurich (ACM et GAMM). L'autcur caracterise brievement la syntaxe et les regles d'inter-pretation du langage algebrique international propose a la Conference de Zurich (ACM-GAMM) puis en donne un expose formel et complet. II indique les notations utilisees pour designer les nombres, les variables numeriques ou booIeennes, les relations, les agencements pluri-dimensionnels, les fonctions, les operateurs et les expressions algebriques. Ce langage permet d'exprimer difierentes operations: affectation de valeurs aux variables, execution conditionnelle des expressions, procedes iteratifs, formation d'expressions complexes a partir d'une suite d'expressions elementaires, definition de nouvelles expressions pour des operations arbitraires, reemploi et modification de certaines parties du programme. Le lang age envisage est conyu pour permettre d'exprimer la quasi totalite des procedes de calcul numerique de maniere com-mode et concise a l'aide d'un nombre relativement restreint de regles de syntaxe et d'expressions-types."
            },
            "slug": "The-syntax-and-semantics-of-the-proposed-algebraic-Backus",
            "title": {
                "fragments": [],
                "text": "The syntax and semantics of the proposed international algebraic language of the Zurich ACM-GAMM Conference"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A summary of the syntax and interpretation rules of the proposed international algebraic language put forward by the Zurich ACM-GAMM Conference, followed by a formal, complete presentation of the same information."
            },
            "venue": {
                "fragments": [],
                "text": "IFIP Congress"
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797292"
                        ],
                        "name": "K. VanLehn",
                        "slug": "K.-VanLehn",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "VanLehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. VanLehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730942"
                        ],
                        "name": "P. Jordan",
                        "slug": "P.-Jordan",
                        "structuredName": {
                            "firstName": "Pamela",
                            "lastName": "Jordan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35959897"
                        ],
                        "name": "C. Ros\u00e9",
                        "slug": "C.-Ros\u00e9",
                        "structuredName": {
                            "firstName": "Carolyn",
                            "lastName": "Ros\u00e9",
                            "middleNames": [
                                "Penstein"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ros\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2888266"
                        ],
                        "name": "Dumisizwe Bhembe",
                        "slug": "Dumisizwe-Bhembe",
                        "structuredName": {
                            "firstName": "Dumisizwe",
                            "lastName": "Bhembe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dumisizwe Bhembe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34612911"
                        ],
                        "name": "Michael B\u00f6ttner",
                        "slug": "Michael-B\u00f6ttner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "B\u00f6ttner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael B\u00f6ttner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47728940"
                        ],
                        "name": "A. Gaydos",
                        "slug": "A.-Gaydos",
                        "structuredName": {
                            "firstName": "Andy",
                            "lastName": "Gaydos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gaydos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2200378"
                        ],
                        "name": "M. Makatchev",
                        "slug": "M.-Makatchev",
                        "structuredName": {
                            "firstName": "Maxim",
                            "lastName": "Makatchev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Makatchev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2590575"
                        ],
                        "name": "Umarani Pappuswamy",
                        "slug": "Umarani-Pappuswamy",
                        "structuredName": {
                            "firstName": "Umarani",
                            "lastName": "Pappuswamy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Umarani Pappuswamy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2267026"
                        ],
                        "name": "M. Ringenberg",
                        "slug": "M.-Ringenberg",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ringenberg",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ringenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145753983"
                        ],
                        "name": "Antonio Roque",
                        "slug": "Antonio-Roque",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Roque",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antonio Roque"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2508756"
                        ],
                        "name": "S. Siler",
                        "slug": "S.-Siler",
                        "structuredName": {
                            "firstName": "Stephanie",
                            "lastName": "Siler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Siler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066943347"
                        ],
                        "name": "Ramesh Srivastava",
                        "slug": "Ramesh-Srivastava",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ramesh Srivastava"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1570932,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "06c60807c9e95ce47770e1caff7f592760eeb78a",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The Why2-Atlas system teaches qualitative physics by having students write paragraph-long explanations of simple mechanical phenomena. The tutor uses deep syntactic analysis and abductive theorem proving to convert the student's essay to a proof. The proof formalizes not only what was said, but the likely beliefs behind what was said. This allows the tutor to uncover misconceptions as well as to detect missing correct parts of the explanation. If the tutor finds such a flaw in the essay, it conducts a dialogue intended to remedy the missing or misconceived beliefs, then asks the student to correct the essay. It often takes several iterations of essay correction and dialogue to get the student to produce an acceptable explanation. Pilot subjects have been run, and an evaluation is in progress. After explaining the research questions that the system addresses, the bulk of the paper describes the system's architecture and operation."
            },
            "slug": "The-Architecture-of-Why2-Atlas:-A-Coach-for-Physics-VanLehn-Jordan",
            "title": {
                "fragments": [],
                "text": "The Architecture of Why2-Atlas: A Coach for Qualitative Physics Essay Writing"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The Why2-Atlas system teaches qualitative physics by having students write paragraph-long explanations of simple mechanical phenomena, and the tutor uses deep syntactic analysis and abductive theorem proving to convert the student's essay to a proof."
            },
            "venue": {
                "fragments": [],
                "text": "Intelligent Tutoring Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787816"
                        ],
                        "name": "C. Isbell",
                        "slug": "C.-Isbell",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Isbell",
                            "middleNames": [
                                "Lee"
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Isbell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "81338045"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683179"
                        ],
                        "name": "D. Kormann",
                        "slug": "D.-Kormann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kormann",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kormann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699868"
                        ],
                        "name": "Satinder Singh",
                        "slug": "Satinder-Singh",
                        "structuredName": {
                            "firstName": "Satinder",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Satinder Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144848112"
                        ],
                        "name": "P. Stone",
                        "slug": "P.-Stone",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Stone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2025191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e62711ba0e6385ee204b475a238c4e82811fc22",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe our development of Cobot, a software agent who lives in LambdaMOO, a popular virtual world frequented by hundreds of users. We present a detailed discussion of the functionality that has made him one of the objects most frequently interacted with in LambdaMOO, human or artificial."
            },
            "slug": "Cobot-in-LambdaMOO:-A-Social-Statistics-Agent-Isbell-Kearns",
            "title": {
                "fragments": [],
                "text": "Cobot in LambdaMOO: A Social Statistics Agent"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The development of Cobot, a software agent who lives in LambdaMOO, a popular virtual world frequented by hundreds of users, is described and a detailed discussion of the functionality that has made him one of the objects most frequently interacted with in LambDAMOO."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153201"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62138892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8cf661487d8708a3e9a74e9cc83ce290aa5355b8",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Stochastic-modeling-for-automatic-speech-Baker",
            "title": {
                "fragments": [],
                "text": "Stochastic modeling for automatic speech understanding"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144956443"
                        ],
                        "name": "F. Xia",
                        "slug": "F.-Xia",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Xia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Xia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7836606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbc3fd65c3d42a87dd5349743d8920f359724824",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Treebanks are of two types according to their annotation schemata: phrase-structure Treebanks such as the English Penn Treebank [8] and dependency Treebanks such as the Czech dependency Treebank [6]. Long before Treebanks were developed and widely used for natural language processing, there had been much discussion of comparison between dependency grammars and context-free phrase-structure grammars [5]. In this paper, we address the relationship between dependency structures and phrase structures from a practical perspective; namely, the exploration of different algorithms that convert dependency structures to phrase structures and the evaluation of their performance against an existing Treebank. This work not only provides ways to convert Treebanks from one type of representation to the other, but also clarifies the differences in representational coverage of the two approaches."
            },
            "slug": "Converting-Dependency-Structures-to-Phrase-Xia-Palmer",
            "title": {
                "fragments": [],
                "text": "Converting Dependency Structures to Phrase Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work not only provides ways to convert Treebanks from one type of representation to the other, but also clarifies the differences in representational coverage of the two approaches."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152220539"
                        ],
                        "name": "Sanjiv Ranjan Das",
                        "slug": "Sanjiv-Ranjan-Das",
                        "structuredName": {
                            "firstName": "Sanjiv Ranjan",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjiv Ranjan Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109211854"
                        ],
                        "name": "Mike Y. Chen",
                        "slug": "Mike-Y.-Chen",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Chen",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike Y. Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 60
                            }
                        ],
                        "text": "The term sentiment seems to have been introduced in 2001 by Das and Chen (2001), to describe the task of measuring market sentiment by looking at the words in stock trading message boards."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 18
                            }
                        ],
                        "text": "In the same paper Das and Chen (2001) also proposed\nthe use of a sentiment lexicon."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60674356,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e7d692f9f50281ad8600be1fa8f158157cf4be2",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The internet has made it feasible to tap a continuous stream of public sentiment from the world wide web, quite literally permitting one to \"feel the pulse\" of any issue under consideration. We present a methodology for real time sentiment extraction in the domain of finance. With the advent of the web, there has been a sharp increase in the influence of individuals on the stock market via web-based trading and the posting of sentiment to stock message boards. While it is importantto capture this \"sentiment\" of small investors, as yet, no index of sentiment has been compiled. This paper comprises (a) a technology for extracting small investor sentiment from web sources to create an index, and (b) illustrative applications of the methodology. We make use of computerized natural language and statistical algorithms for the automated classification of messages posted on the web. We design a suite of classification algorithms, each of different theoretical content, with a view to characterizing the sentiment of any single posting to a message board. The use of multiple methods allows imposition of voting rules in the classification process. It also enables elimination of \"fuzzy\" messages which are better off uninterpreted. A majority rule across algorithms vastly improves classification accuracy, but also leads to a natural increase in the number of messages classified as \"fuzzy\". The classifier achieves an accuracy of 62% (versus a random classification accuracy of 33%), and compares favorably against human agreement on message classification, which was 72%. The technology is computationally efficient, allowing the access and interpretations of thousands of messages within minutes. Our illustrative applications show evidence of a strong link between market movements and sentiment. Based on approximately 25,000 messages for the last quarter of 2000, we found evidence that sentiment is based on stock movements."
            },
            "slug": "Yahoo!-For-Amazon:-Sentiment-Parsing-from-Small-on-Das-Chen",
            "title": {
                "fragments": [],
                "text": "Yahoo! For Amazon: Sentiment Parsing from Small Talk on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A methodology for real time sentiment extraction in the domain of finance, using computerized natural language and statistical algorithms for the automated classification of messages posted on the web, finds evidence that sentiment is based on stock movements."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3374059"
                        ],
                        "name": "Jen-Nan Chen",
                        "slug": "Jen-Nan-Chen",
                        "structuredName": {
                            "firstName": "Jen-Nan",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jen-Nan Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778899"
                        ],
                        "name": "Jason J. S. Chang",
                        "slug": "Jason-J.-S.-Chang",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Chang",
                            "middleNames": [
                                "J.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason J. S. Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18074028,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fdc10c3694c6e4c9fd4b82e14945f652ec0db99d",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a heuristic approach capable of automatically clustering senses in a machine-readable dictionary (MRD). Including these clusters in the MRD-based lexical database offers several positive benefits for word sense disambiguation (WSD). First, the clusters can be used as a coarser sense division, so unnecessarily fine sense distinction can be avoided. The clustered entries in the MRD can also be used as materials for supervised training to develop a WSD system. Furthermore, if the algorithm is run on several MRDs, the clusters also provide a means of linking different senses across multiple MRDs to create an integrated lexical database. An implementation of the method for clustering definition sentences in the Longman Dictionary of Contemporary English (LDOCE) is described. To this end, the topical word lists and topical cross-references in the Longman Lexicon of Contemporary English (LLOCE) are used. Nearly half of the senses in the LDOCE can be linked precisely to a relevant LLOCE topic using a simple heuristic. With the definitions of senses linked to the same topic viewed as a document, topical clustering of the MRD senses bears a striking resemblance to retrieval of relevant documents for a given query in information retrieval (IR) research. Relatively well-established IR techniques of weighting terms and ranking document relevancy are applied to find the topical clusters that are most relevant to the definition of each MRD sense. Finally, we describe an implemented version of the algorithms for the LDOCE and the LLOCE and assess the performance of the proposed approach in a series of experiments and evaluations."
            },
            "slug": "Topical-Clustering-of-MRD-Senses-Based-on-Retrieval-Chen-Chang",
            "title": {
                "fragments": [],
                "text": "Topical Clustering of MRD Senses Based on Information Retrieval Techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A heuristic approach capable of automatically clustering senses in a machine-readable dictionary (MRD) and an implementation of the method for clustering definition sentences in the Longman Dictionary of Contemporary English (LDOCE) is described."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135004"
                        ],
                        "name": "K. Schuler",
                        "slug": "K.-Schuler",
                        "structuredName": {
                            "firstName": "Karin",
                            "lastName": "Schuler",
                            "middleNames": [
                                "Kipper"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Schuler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122755"
                        ],
                        "name": "H. Dang",
                        "slug": "H.-Dang",
                        "structuredName": {
                            "firstName": "Hoa",
                            "lastName": "Dang",
                            "middleNames": [
                                "Trang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Dang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13933518,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "031b4656032aad6699a642f62d993173b378b772",
            "isKey": false,
            "numCitedBy": 485,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to building a verb lexicon compatible with WordNet but with explicitly stated syntactic and semantic information, using Levin verb classes to systematically construct lexical entries. By using verb classes we capture generalizations about verb behavior and reduce the effort needed to construct the lexicon. The syntactic frames for the verb classes are represented by a Lexicalized Tree Adjoining Grammar augmented with semantic predicates, which allows a compositional interpretation."
            },
            "slug": "Class-Based-Construction-of-a-Verb-Lexicon-Schuler-Dang",
            "title": {
                "fragments": [],
                "text": "Class-Based Construction of a Verb Lexicon"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This work presents an approach to building a verb lexicon compatible with WordNet but with explicitly stated syntactic and semantic information, using Levin verb classes to systematically construct lexical entries."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15829786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e569d99f3a0fcfa038631dda2b44c73a6e8e97b8",
            "isKey": false,
            "numCitedBy": 454,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The representation of documents and queries as vectors in a high-dimensional space is well-established in information retrieval. The author proposes that the semantics of words and contexts in a text be represented as vectors. The dimensions of the space are words and the initial vectors are determined by the words occurring close to the entity to be represented, which implies that the space has several thousand dimensions (words). This makes the vector representations (which are dense) too cumbersome to use directly. Therefore, dimensionality reduction by means of a singular value decomposition is employed. The author analyzes the structure of the vector representations and applies them to word sense disambiguation and thesaurus induction. >"
            },
            "slug": "Dimensions-of-meaning-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Dimensions of meaning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author analyzes the structure of the vector representations and applies them to word sense disambiguation and thesaurus induction and finds that dimensionality reduction by means of a singular value decomposition is employed."
            },
            "venue": {
                "fragments": [],
                "text": "Supercomputing '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784211"
                        ],
                        "name": "S. Kuno",
                        "slug": "S.-Kuno",
                        "structuredName": {
                            "firstName": "Susumu",
                            "lastName": "Kuno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kuno"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16669681,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "f1a2c7757d110cc9e2b114de852f629dbaad4318",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Some of the characteristic features of a predictive analyzer, a system of syntactic analysis now operational at Harvard on an IBM 7094, are delineated. The advantages and disadvantages of the system are discussed in comparison to those of an immediate constituent analyzer, developed at the RAND Corporation with Robinson's English grammar. In addition, a new technique is described for repetitive path elimination for a predictive analyzer, which can now claim efficiency both in processing time and core storage requirement."
            },
            "slug": "The-predictive-analyzer-and-a-path-elimination-Kuno",
            "title": {
                "fragments": [],
                "text": "The predictive analyzer and a path elimination technique"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new technique is described for repetitive path elimination for a predictive analyzer, which can now claim efficiency both in processing time and core storage requirement."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2867844"
                        ],
                        "name": "Nancy A. Chinchor",
                        "slug": "Nancy-A.-Chinchor",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Chinchor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nancy A. Chinchor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145148360"
                        ],
                        "name": "L. Hirschman",
                        "slug": "L.-Hirschman",
                        "structuredName": {
                            "firstName": "Lynette",
                            "lastName": "Hirschman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hirschman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16857799,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "facef9d98129c394beb5de4e0a6a144e602b492d",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes and analyzes the results of the Third Message Understanding Conference (MUC-3). It reviews the purpose, history, and methodology of the conference, summarizes the participating systems, discusses issues of measuring system effectiveness, describes the linguistic phenomena tests, and provides a critical look at the evaluation in terms of the lessons learned. One of the common problems with evaluations is that the statistical significance of the results is unknown. In the discussion of system performance, the statistical significance of the evaluation results is reported and the use of approximate randomization to calculate the statistical significance of the results of MUC-3 is described."
            },
            "slug": "Evaluating-Message-Understanding-Systems:-An-of-the-Chinchor-Hirschman",
            "title": {
                "fragments": [],
                "text": "Evaluating Message Understanding Systems: An Analysis of the Third Message Understanding Conference (MUC-3)"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "The purpose, history, and methodology of the conference are reviewed, the participating systems are summarized, issues of measuring system effectiveness are discussed, the linguistic phenomena tests are described, and a critical look at the evaluation in terms of the lessons learned is provided."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2325236"
                        ],
                        "name": "Y. Niwa",
                        "slug": "Y.-Niwa",
                        "structuredName": {
                            "firstName": "Yoshiki",
                            "lastName": "Niwa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Niwa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806193"
                        ],
                        "name": "Y. Nitta",
                        "slug": "Y.-Nitta",
                        "structuredName": {
                            "firstName": "Yoshihiko",
                            "lastName": "Nitta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nitta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2646329,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c989e8aa08b24345419e4528198fe5ea17cc0160",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A comparison was made of vectors derived by using ordinary co-occurrence statistics from large text corpora and of vectors derived by measuring the interword distances in dictionary definitions. The precision of word sense disambiguation by using co-occurrence vectors from the 1987 Wall Street Journal (20M total words) was higher than that by using distance vectors from the Collins English Dictionary (60K head words + 1.6M definition words). However, other experimental results suggest that distance vectors contain some different semantic information from co-occurrence vectors."
            },
            "slug": "Co-Occurrence-Vectors-From-Corpora-vs.-Distance-Niwa-Nitta",
            "title": {
                "fragments": [],
                "text": "Co-Occurrence Vectors From Corpora vs. Distance Vectors From Dictionaries"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental results suggest that distance vectors contain some different semantic information from co-occurrence vectors, compared with other experimental results, which suggest that word sense disambiguation is affected by distance vectors."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48892185"
                        ],
                        "name": "J. Teahan",
                        "slug": "J.-Teahan",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Teahan",
                            "middleNames": [
                                "K"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Teahan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752317"
                        ],
                        "name": "J. Cleary",
                        "slug": "J.-Cleary",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cleary",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cleary"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6633939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d36910319d11359b995ff5413696aa9e9995e163",
            "isKey": false,
            "numCitedBy": 369,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "\\A new data structure for cumulative probability tables\". Soft-\\The zero-frequency problem: estimating the probabilities of novel events in adaptive text compression\"."
            },
            "slug": "\\self-organized-Language-Modeling-for-Speech-In-Teahan-Cleary",
            "title": {
                "fragments": [],
                "text": "\\self-organized Language Modeling for Speech Recognition\". In"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The zero-frequency problem: estimating the probabilities of novel events in adaptive text compression and a new data structure for cumulative probability tables are studied."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49769637"
                        ],
                        "name": "S. Cotton",
                        "slug": "S.-Cotton",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Cotton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Cotton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35438730"
                        ],
                        "name": "L. Delfs",
                        "slug": "L.-Delfs",
                        "structuredName": {
                            "firstName": "Lauren",
                            "lastName": "Delfs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Delfs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122755"
                        ],
                        "name": "H. Dang",
                        "slug": "H.-Dang",
                        "structuredName": {
                            "firstName": "Hoa",
                            "lastName": "Dang",
                            "middleNames": [
                                "Trang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Dang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 614607,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "885db4a98255479199751380caa80f13d22a5e7e",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe our experience in preparing the lexicon and sense-tagged corpora used in the English all-words and lexical sample tasks of Senseval-2."
            },
            "slug": "English-Tasks:-All-Words-and-Verb-Lexical-Sample-Palmer-Fellbaum",
            "title": {
                "fragments": [],
                "text": "English Tasks: All-Words and Verb Lexical Sample"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The experience in preparing the lexicon and sense-tagged corpora used in the English all-words and lexical sample tasks of Senseval-2 is described."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2197285"
                        ],
                        "name": "B. Rehder",
                        "slug": "B.-Rehder",
                        "structuredName": {
                            "firstName": "Bob",
                            "lastName": "Rehder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rehder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144029655"
                        ],
                        "name": "M. E. Schreiner",
                        "slug": "M.-E.-Schreiner",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Schreiner",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. E. Schreiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39952106"
                        ],
                        "name": "Michael B. W. Wolfe",
                        "slug": "Michael-B.-W.-Wolfe",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wolfe",
                            "middleNames": [
                                "B.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael B. W. Wolfe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2444937"
                        ],
                        "name": "Darrell Laham",
                        "slug": "Darrell-Laham",
                        "structuredName": {
                            "firstName": "Darrell",
                            "lastName": "Laham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Darrell Laham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1935697,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "a41a040d683c66d2e63ed9d5015e7dd8e9ddbb4b",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In another article (Wolfe et al., 1998/this issue) we showed how Latent Semantic Analysis (LSA) can be used to assess student knowledge\u2014how essays can be graded by LSA and how LSA can match students with appropriate instructional texts. We did this by comparing an essay written by a student with one or more target instructional texts in terms of the cosine between the vector representation of the student's essay and the instructional text in question. This simple method was effective for the purpose, but questions remain about how LSA achieves its results and how the results might be improved. Here, we address four such questions: (a) What role does the use of technical vocabulary play? (b) how long should the student essays be? (c) is the cosine the optimal measure of semantic relatedness? and (d) how does one deal with the directionality of knowledge in the high\u2010dimensional space?"
            },
            "slug": "Using-latent-semantic-analysis-to-assess-knowledge:-Rehder-Schreiner",
            "title": {
                "fragments": [],
                "text": "Using latent semantic analysis to assess knowledge: Some technical considerations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b951b9f78b98a186ba259027996a48e4189d37e5",
            "isKey": false,
            "numCitedBy": 1305,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a technique for constructing random fields from a set of training samples. The learning paradigm builds increasingly complex fields by allowing potential functions, or features, that are supported by increasingly large subgraphs. Each feature has a weight that is trained by minimizing the Kullback-Leibler divergence between the model and the empirical distribution of the training data. A greedy algorithm determines how features are incrementally added to the field and an iterative scaling algorithm is used to estimate the optimal values of the weights. The random field models and techniques introduced in this paper differ from those common to much of the computer vision literature in that the underlying random fields are non-Markovian and have a large number of parameters that must be estimated. Relations to other learning approaches, including decision trees, are given. As a demonstration of the method, we describe its application to the problem of automatic word classification in natural language processing."
            },
            "slug": "Inducing-Features-of-Random-Fields-Pietra-Pietra",
            "title": {
                "fragments": [],
                "text": "Inducing Features of Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The random field models and techniques introduced in this paper differ from those common to much of the computer vision literature in that the underlying random fields are non-Markovian and have a large number of parameters that must be estimated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5958691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d87ceda3042f781c341ac17109d1e94a717f5f60",
            "isKey": false,
            "numCitedBy": 13578,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet."
            },
            "slug": "WordNet-:-an-electronic-lexical-database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "WordNet : an electronic lexical database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The lexical database: nouns in WordNet, Katherine J. Miller a semantic network of English verbs, and applications of WordNet: building semantic concordances are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2006080"
                        ],
                        "name": "J. D. Gould",
                        "slug": "J.-D.-Gould",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Gould",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. D. Gould"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145961032"
                        ],
                        "name": "C. Lewis",
                        "slug": "C.-Lewis",
                        "structuredName": {
                            "firstName": "Clayton",
                            "lastName": "Lewis",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13865423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96e5e68087b38a0ea3c9b99145432ad99c9759ca",
            "isKey": false,
            "numCitedBy": 846,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Any system designed for people to use should be (a) easy to learn; (b) useful, i.e., contain functions people really need in their work; (c) easy to use; and (d) pleasant to use. In this note we present theoretical considerations and empirical data relevant to attaining these goals. First, we mention four principles for system design which we believe are necessary to attain these goals; Then we present survey results that demonstrate that our principles are not really all that obvious, but just seem obvious once presented. The responses of designers suggest they may sometimes think they are doing what we recommend when in fact they are not. This is consistent with the experience that systems designers do not often recommend or use them themselves. We contrast some of these responses with what we have in mind in order to provide a more useful description of our principles. Lastly, we consider why this might be so. These sections are summaries of those in a longer paper to appear elsewhere (Gould & Lewis, 1983). In that paper we elaborate on our four principles, showing how they form the basis for a general methodology of design, and we describe a successful example of using them in actual system design (IBM's Audio Distribution System)."
            },
            "slug": "Designing-for-usability\u2014key-principles-and-what-Gould-Lewis",
            "title": {
                "fragments": [],
                "text": "Designing for usability\u2014key principles and what designers think"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Any system designed for people to use should be (a) easy to learn; (b) useful, i.e., contain functions people really need in their work; (c)easy to use; and (d) pleasant to use."
            },
            "venue": {
                "fragments": [],
                "text": "CHI '83"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84527386"
                        ],
                        "name": "R. Plutchik",
                        "slug": "R.-Plutchik",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Plutchik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Plutchik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 30
                            }
                        ],
                        "text": "Another atomic theory is the (Plutchik, 1980) wheel of emotion, consisting of 8 basic emotions in four opposing pairs: joy\u2013sadness, anger\u2013fear, trust\u2013disgust, and anticipation\u2013surprise, together with the emotions derived from them, shown in Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 107
                            }
                        ],
                        "text": "The NRC Word-Emotion Association Lexicon, also called EmoLex (Moham-EmoLex mad and Turney, 2013), uses the Plutchik (1980) 8 basic emotions defined above."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 144721601,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b3b7b374eee3ea3c6fe35c1e7bdf9bf24c9456b0",
            "isKey": false,
            "numCitedBy": 1470,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-GENERAL-PSYCHOEVOLUTIONARY-THEORY-OF-EMOTION-Plutchik",
            "title": {
                "fragments": [],
                "text": "A GENERAL PSYCHOEVOLUTIONARY THEORY OF EMOTION"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689647"
                        ],
                        "name": "Peter D. Turney",
                        "slug": "Peter-D.-Turney",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Turney",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter D. Turney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 88
                            }
                        ],
                        "text": "The term sentiment, and the use of lexicons, caught on quite quickly (e.g., inter alia, Turney 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 125
                            }
                        ],
                        "text": "The PMI between two words w and s is then:\nPMI(w,s) = log2 1 kN hits(w NEAR s) 1 N hits(w) 1 N hits(s)\n(18.5)\nThe insight of Turney (2002) is then to define the polarity of a word by how much it occurs with the positive seeds and doesn\u2019t occur with the negative seeds:\nPolarity(w) =\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 14
                            }
                        ],
                        "text": "The method of Turney (2002) uses this method to assign polarity to both words and two-word phrases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 244
                            }
                        ],
                        "text": "\u2026= log2 P(x,y)\nP(x)P(y) (18.1)\nThis intuition can be applied to measure the co-occurrence of two words by defining the pointwise mutual information association between a seed word s and another word w as:\nPMI(w,s) = log2 P(w,s)\nP(w)P(s) (18.2)\nTurney (2002) estimated the probabilities needed by Eq."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 126
                            }
                        ],
                        "text": "\u2026hits(w)hits(\u201cpoor\u201d) hits(w NEAR \u201cpoor\u201d) ) = log2 ( hits(w NEAR \u201cexcellent\u201d) hits(\u201cpoor\u201d) hits(\u201cexcellent\u201d) hits(w NEAR \u201cpoor\u201d) ) (18.6)\nThe table below from Turney (2002) shows sample examples of phrases learned by the PMI method (from reviews of banking services), showing\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 79
                            }
                        ],
                        "text": "All begin with a seed set of positive and negative words, as small as 2 words (Turney, 2002) or as large as a thousand (Hatzivassiloglou and McKeown, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 484335,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e7c7853a16a378cc24a082153b282257a9675b7",
            "isKey": true,
            "numCitedBy": 5418,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a simple unsupervised learning algorithm for classifying reviews as recommended (thumbs up) or not recommended (thumbs down). The classification of a review is predicted by the average semantic orientation of the phrases in the review that contain adjectives or adverbs. A phrase has a positive semantic orientation when it has good associations (e.g., \"subtle nuances\") and a negative semantic orientation when it has bad associations (e.g., \"very cavalier\"). In this paper, the semantic orientation of a phrase is calculated as the mutual information between the given phrase and the word \"excellent\" minus the mutual information between the given phrase and the word \"poor\". A review is classified as recommended if the average semantic orientation of its phrases is positive. The algorithm achieves an average accuracy of 74% when evaluated on 410 reviews from Epinions, sampled from four different domains (reviews of automobiles, banks, movies, and travel destinations). The accuracy ranges from 84% for automobile reviews to 66% for movie reviews."
            },
            "slug": "Thumbs-Up-or-Thumbs-Down-Semantic-Orientation-to-of-Turney",
            "title": {
                "fragments": [],
                "text": "Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A simple unsupervised learning algorithm for classifying reviews as recommended (thumbs up) or not recommended (Thumbs down) if the average semantic orientation of its phrases is positive."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119142953"
                        ],
                        "name": "S. Khamis",
                        "slug": "S.-Khamis",
                        "structuredName": {
                            "firstName": "Samar",
                            "lastName": "Khamis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khamis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47976263"
                        ],
                        "name": "F. Mosteller",
                        "slug": "F.-Mosteller",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Mosteller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Mosteller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144087709"
                        ],
                        "name": "D. L. Wallace",
                        "slug": "D.-L.-Wallace",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wallace",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. L. Wallace"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124790138,
            "fieldsOfStudy": [
                "Sociology",
                "Computer Science",
                "Mathematics",
                "Political Science",
                "Philosophy"
            ],
            "id": "d6fb495cbb103c36608147a1eafa95988b75d2d2",
            "isKey": false,
            "numCitedBy": 700,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The 1964 publication of \"Inference and Disputed Authorship\" made the cover of \"Time\" magazine and drew the attention of academics and the public alike for its use of statistical methodology to solve one of American history's most notorious questions: the disputed authorship of the \"Federalist Papers\". Back in print for a new generation of readers, this classic volume applies mathematics, including the once-controversial Bayesian analysis, to the heart of a literary and historical problem by studying frequently used words in the texts. The reissue of this landmark book will be welcomed by anyone interested in the juncture of history, political science, and authorship."
            },
            "slug": "Inference-and-Disputed-Authorship:-The-Federalist-Khamis-Mosteller",
            "title": {
                "fragments": [],
                "text": "Inference and Disputed Authorship: The Federalist"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59167516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4471e3117cdac2fae74d305d54b237bb3addd749",
            "isKey": false,
            "numCitedBy": 873,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface. 1. Introduction. 2. Semantic Extraction. 3. Sextant. 4. Evaluation. 5. Applications. 6. Conclusion. 1: Preprocesors. 2. Webster Stopword List. 3: Similarity List. 4: Semantic Clustering. 5: Automatic Thesaurus Generation. 6. Corpora Treated. Index."
            },
            "slug": "Explorations-in-automatic-thesaurus-discovery-Grefenstette",
            "title": {
                "fragments": [],
                "text": "Explorations in automatic thesaurus discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The aim of this monograph is to provide a catalog of words and phrases used in ThesaurusGeneration, as well as some examples of other writers' work, which have been used in similar contexts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055976119"
                        ],
                        "name": "S. Marcus",
                        "slug": "S.-Marcus",
                        "structuredName": {
                            "firstName": "Shaul",
                            "lastName": "Marcus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2309269"
                        ],
                        "name": "Shaul Markovitch",
                        "slug": "Shaul-Markovitch",
                        "structuredName": {
                            "firstName": "Shaul",
                            "lastName": "Markovitch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaul Markovitch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1154960,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "8310a3f4ec3d6a37958c1c2aefe80b7b7badbca0",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In recent years there is much interest in word co-occurrence relations, such as n-grams, verb\u2013object combinations, or co-occurrence within a limited context. This paper discusses how to estimate the likelihood of co-occurrences that do not occur in the training data. We present a method that makes local analogies between each specific unobserved co-occurrence and other co-occurrences that contain similar words. These analogies are based on the assumption that similar word co-occurrences have similar values of mutual information. Accordingly, the word similarity metric captures similarities between vectors of mutual information values. Our evaluation suggests that this method performs better than existing, frequency-based, smoothing methods, and may provide an alternative to class-based models. A background survey is included, covering issues of lexical co-occurrence, data sparseness and smoothing, word similarity and clustering, and mutual information."
            },
            "slug": "Contextual-Word-Similarity-and-Estimation-From-Data-Dagan-Marcus",
            "title": {
                "fragments": [],
                "text": "Contextual Word Similarity and Estimation From Sparse Data"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The evaluation suggests that this method performs better than existing, frequency-based, smoothing methods, and may provide an alternative to class-based models."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144864352"
                        ],
                        "name": "M. Maron",
                        "slug": "M.-Maron",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Maron",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6692916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c390dbf06af49d3691bc7b906f5fd9b909c2f89b",
            "isKey": false,
            "numCitedBy": 519,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "This inquiry examines a technique for automatically classifying (indexing) documents according to their subject content. The task, in essence, is to have a computing machine read a document and on the basis of the occurrence of selected clue words decide to which of many subject categories the document in question belongs. This paper describes the design, execution and evaluation of a modest experimental study aimed at testing empirically one statistical technique for automatic indexing."
            },
            "slug": "Automatic-Indexing:-An-Experimental-Inquiry-Maron",
            "title": {
                "fragments": [],
                "text": "Automatic Indexing: An Experimental Inquiry"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The design, execution and evaluation of a modest experimental study aimed at testing empirically one statistical technique for automatic indexed documents according to their subject content are described."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 574041,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "656859af2ed88cfa23f2bd063c1816a8fc04c47e",
            "isKey": false,
            "numCitedBy": 1012,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes the use of maximum entropy techniques for text classification. Maximum entropy is a probability distribution estimation technique widely used for a variety of natural language tasks, such as language modeling, part-of-speech tagging, and text segmentation. The underlying principle of maximum entropy is that without external knowledge, one should prefer distributions that are uniform. Constraints on the distribution, derived from labeled training data, inform the technique where to be minimally non-uniform. The maximum entropy formulation has a unique solution which can be found by the improved iterative scaling algorithm. In this paper, maximum entropy is used for text classification by estimating the conditional distribution of the class variable given the document. In experiments on several text datasets we compare accuracy to naive Bayes and show that maximum entropy is sometimes significantly better, but also sometimes worse. Much future work remains, but the results indicate that maximum entropy is a promising technique for text classification."
            },
            "slug": "Using-Maximum-Entropy-for-Text-Classification-Nigam-Lafferty",
            "title": {
                "fragments": [],
                "text": "Using Maximum Entropy for Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This paper uses maximum entropy techniques for text classification by estimating the conditional distribution of the class variable given the document by comparing accuracy to naive Bayes and showing that maximum entropy is sometimes significantly better, but also sometimes worse."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 296750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90929a6aa901ba958eb4960aeeb594c752e08369",
            "isKey": false,
            "numCitedBy": 2230,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We compare discriminative and generative learning as typified by logistic regression and naive Bayes. We show, contrary to a widely-held belief that discriminative classifiers are almost always to be preferred, that there can often be two distinct regimes of performance as the training set size is increased, one in which each algorithm does better. This stems from the observation\u2014which is borne out in repeated experiments\u2014that while discriminative learning has lower asymptotic error, a generative classifier may also approach its (higher) asymptotic error much faster."
            },
            "slug": "On-Discriminative-vs.-Generative-Classifiers:-A-of-Ng-Jordan",
            "title": {
                "fragments": [],
                "text": "On Discriminative vs. Generative Classifiers: A comparison of logistic regression and naive Bayes"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "It is shown, contrary to a widely-held belief that discriminative classifiers are almost always to be preferred, that there can often be two distinct regimes of performance as the training set size is increased, one in which each algorithm does better."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50064811"
                        ],
                        "name": "L. Finkelstein",
                        "slug": "L.-Finkelstein",
                        "structuredName": {
                            "firstName": "Lev",
                            "lastName": "Finkelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Finkelstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718798"
                        ],
                        "name": "E. Gabrilovich",
                        "slug": "E.-Gabrilovich",
                        "structuredName": {
                            "firstName": "Evgeniy",
                            "lastName": "Gabrilovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gabrilovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745572"
                        ],
                        "name": "Y. Matias",
                        "slug": "Y.-Matias",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Matias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Matias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747801"
                        ],
                        "name": "E. Rivlin",
                        "slug": "E.-Rivlin",
                        "structuredName": {
                            "firstName": "Ehud",
                            "lastName": "Rivlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rivlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3316511"
                        ],
                        "name": "Zach Solan",
                        "slug": "Zach-Solan",
                        "structuredName": {
                            "firstName": "Zach",
                            "lastName": "Solan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zach Solan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073936"
                        ],
                        "name": "G. Wolfman",
                        "slug": "G.-Wolfman",
                        "structuredName": {
                            "firstName": "Gadi",
                            "lastName": "Wolfman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wolfman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779370"
                        ],
                        "name": "E. Ruppin",
                        "slug": "E.-Ruppin",
                        "structuredName": {
                            "firstName": "Eytan",
                            "lastName": "Ruppin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ruppin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12956853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0c01df98a6b633b25c96c1a99b713ac96f1c5be",
            "isKey": false,
            "numCitedBy": 1725,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Keyword-based search engines are in widespread use today as a popular means for Web-based information retrieval. Although such systems seem deceptively simple, a considerable amount of skill is required in order to satisfy non-trivial information needs. This paper presents a new conceptual paradigm for performing search in context, that largely automates the search process, providing even non-professional users with highly relevant results. This paradigm is implemented in practice in the IntelliZap system, where search is initiated from a text query marked by the user in a document she views, and is guided by the text surrounding the marked query in that document (\"the context\"). The context-driven information retrieval process involves semantic keyword extraction and clustering to automatically generate new, augmented queries. The latter are submitted to a host of general and domain-specific search engines. Search results are then semantically reranked, using context. Experimental results testify that using context to guide search, effectively offers even inexperienced users an advanced search tool on the Web."
            },
            "slug": "Placing-search-in-context:-the-concept-revisited-Finkelstein-Gabrilovich",
            "title": {
                "fragments": [],
                "text": "Placing search in context: the concept revisited"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new conceptual paradigm for performing search in context is presented, that largely automates the search process, providing even non-professional users with highly relevant results."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2559880"
                        ],
                        "name": "R. Valin",
                        "slug": "R.-Valin",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Valin",
                            "middleNames": [
                                "D.",
                                "Van"
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Valin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4312465"
                        ],
                        "name": "R. Lapolla",
                        "slug": "R.-Lapolla",
                        "structuredName": {
                            "firstName": "Randy",
                            "lastName": "Lapolla",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lapolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60719902,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "287fb9b7bbf530c8fc7d0378357561d769c60a12",
            "isKey": false,
            "numCitedBy": 1319,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. The goals of linguistic theory 2. Syntactic structure I: simple clauses and noun phrases 3. Semantic representation I: verbs and arguments 4. Semantic representation II: macroroles, the lexicon and noun phrases 5. Information structure 6. Grammatical relations 7. Linking syntax and semantics in simple sentences 8. Syntactic structure II: complex sentences and noun phrases 9. Linking syntax and semantics in complex sentences Epilogue: the goals of linguistic theory revisited Notes References."
            },
            "slug": "Syntax:-Structure,-Meaning,-and-Function-Valin-Lapolla",
            "title": {
                "fragments": [],
                "text": "Syntax: Structure, Meaning, and Function"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "The goals of linguistic theory revisited are revisited and a model for linking syntax and semantics in simple sentences and complex sentences is proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115651440"
                        ],
                        "name": "Daniel D. Lee",
                        "slug": "Daniel-D.-Lee",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lee",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel D. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4428232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29bae9472203546847ec1352a604566d0f602728",
            "isKey": false,
            "numCitedBy": 11315,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Is perception of the whole based on perception of its parts? There is psychological and physiological evidence for parts-based representations in the brain, and certain computational theories of object recognition rely on such representations. But little is known about how brains or computers might learn the parts of objects. Here we demonstrate an algorithm for non-negative matrix factorization that is able to learn parts of faces and semantic features of text. This is in contrast to other methods, such as principal components analysis and vector quantization, that learn holistic, not parts-based, representations. Non-negative matrix factorization is distinguished from the other methods by its use of non-negativity constraints. These constraints lead to a parts-based representation because they allow only additive, not subtractive, combinations. When non-negative matrix factorization is implemented as a neural network, parts-based representations emerge by virtue of two properties: the firing rates of neurons are never negative and synaptic strengths do not change sign."
            },
            "slug": "Learning-the-parts-of-objects-by-non-negative-Lee-Seung",
            "title": {
                "fragments": [],
                "text": "Learning the parts of objects by non-negative matrix factorization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm for non-negative matrix factorization is demonstrated that is able to learn parts of faces and semantic features of text and is in contrast to other methods that learn holistic, not parts-based, representations."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2339397"
                        ],
                        "name": "Michele Banko",
                        "slug": "Michele-Banko",
                        "structuredName": {
                            "firstName": "Michele",
                            "lastName": "Banko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michele Banko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5541486,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c99620d7511c83a402ff3b4b3a2348a669e61e3",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the architecture of the AskMSR question answering system and systematically evaluate contributions of different system components to accuracy. The system differs from most question answering systems in its dependency on data redundancy rather than sophisticated linguistic analyses of either questions or candidate answers. Because a wrong answer is often worse than no answer, we also explore strategies for predicting when the question answering system is likely to give an incorrect answer."
            },
            "slug": "An-Analysis-of-the-AskMSR-Question-Answering-System-Brill-Dumais",
            "title": {
                "fragments": [],
                "text": "An Analysis of the AskMSR Question-Answering System"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The architecture of the AskMSR question answering system is described and contributions of different system components to accuracy are evaluated and strategies for predicting when the question Answer system is likely to give an incorrect answer are explored."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83427261"
                        ],
                        "name": "T. Reichert",
                        "slug": "T.-Reichert",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Reichert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Reichert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37691174"
                        ],
                        "name": "D. N. Cohen",
                        "slug": "D.-N.-Cohen",
                        "structuredName": {
                            "firstName": "D",
                            "lastName": "Cohen",
                            "middleNames": [
                                "N"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. N. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064868866"
                        ],
                        "name": "A. K. Wong",
                        "slug": "A.-K.-Wong",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Wong",
                            "middleNames": [
                                "K.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. K. Wong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44517278,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "4530c7e1517924f5da50a894812689297f7ea4fe",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-application-of-information-theory-to-genetic-and-Reichert-Cohen",
            "title": {
                "fragments": [],
                "text": "An application of information theory to genetic mutations and the matching of polypeptide sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of theoretical biology"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110909951"
                        ],
                        "name": "Stanley F. Chen",
                        "slug": "Stanley-F.-Chen",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Chen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stanley F. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9826900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e9e66b55476bb0c58f23695c9a6554b6e74d906",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "In certain contexts, maximum entropy (ME) modeling can be viewed as maximum likelihood (ML) training for exponential models, and like other ML methods is prone to overfitting of training data. Several smoothing methods for ME models have been proposed to address this problem, but previous results do not make it clear how these smoothing methods compare with smoothing methods for other types of related models. In this work, we survey previous work in ME smoothing and compare the performance of several of these algorithms with conventional techniques for smoothing n-gram language models. Because of the mature body of research in n-gram model smoothing and the close connection between ME and conventional n-gram models, this domain is well-suited to gauge the performance of ME smoothing methods. Over a large number of data sets, we find that fuzzy ME smoothing performs as well as or better than all other algorithms under consideration. We contrast this method with previous n-gram smoothing methods to explain its superior performance."
            },
            "slug": "A-survey-of-smoothing-techniques-for-ME-models-Chen-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "A survey of smoothing techniques for ME models"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Over a large number of data sets, it is found that fuzzy ME smoothing performs as well as or better than all other algorithms under consideration."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9419406"
                        ],
                        "name": "I. Witten",
                        "slug": "I.-Witten",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Witten",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Witten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49014513"
                        ],
                        "name": "T. Bell",
                        "slug": "T.-Bell",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Bell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10314497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f5d21625f8264f455591b3c7cbdac18b983b3c0",
            "isKey": false,
            "numCitedBy": 848,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Approaches to the zero-frequency problem in adaptive text compression are discussed. This problem relates to the estimation of the likelihood of a novel event occurring. Although several methods have been used, their suitability has been on empirical evaluation rather than a well-founded model. The authors propose the application of a Poisson process model of novelty. Its ability to predict novel tokens is evaluated, and it consistently outperforms existing methods. It is applied to a practical statistical coding scheme, where a slight modification is required to avoid divergence. The result is a well-founded zero-frequency model that explains observed differences in the performance of existing methods, and offers a small improvement in the coding efficiency of text compression over the best method previously known. >"
            },
            "slug": "The-zero-frequency-problem:-Estimating-the-of-novel-Witten-Bell",
            "title": {
                "fragments": [],
                "text": "The zero-frequency problem: Estimating the probabilities of novel events in adaptive text compression"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The authors propose the application of a Poisson process model of novelty, which ability to predict novel tokens is evaluated, and it consistently outperforms existing methods and offers a small improvement in the coding efficiency of text compression over the best method previously known."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16678797"
                        ],
                        "name": "E. Goffman",
                        "slug": "E.-Goffman",
                        "structuredName": {
                            "firstName": "Erving",
                            "lastName": "Goffman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Goffman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143676803,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "da525524f4e112d68b8b19205399b189124fae93",
            "isKey": false,
            "numCitedBy": 11721,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Erving Goffman will influence the thinking and perceptions of generations to come. In Frame Analysis, the brilliant theorist writes about the ways in which people determine their answers to the questions What is going on here? and Under what circumstances do we think things are real? \""
            },
            "slug": "Frame-analysis:-An-essay-on-the-organization-of-Goffman",
            "title": {
                "fragments": [],
                "text": "Frame analysis: An essay on the organization of experience"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793218"
                        ],
                        "name": "D. Gildea",
                        "slug": "D.-Gildea",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gildea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gildea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62182406,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c274b8aac56e49e65a3827c570b2496b14429166",
            "isKey": false,
            "numCitedBy": 1099,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame. Various lexical and syntactic features are derived from parse trees and used to derive statistical classifiers from hand-annotated training data."
            },
            "slug": "Automatic-Labeling-of-Semantic-Roles-Gildea-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Automatic Labeling of Semantic Roles"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This work presents a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame, derived from parse trees and hand-annotated training data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081041134"
                        ],
                        "name": "Christus",
                        "slug": "Christus",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Christus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105126954"
                        ],
                        "name": "Wuksch",
                        "slug": "Wuksch",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Wuksch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wuksch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14836645,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "967f32841955b72f358190436baa5510839d9ab3",
            "isKey": false,
            "numCitedBy": 4320,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A computer adaptable method for finding similarities in the amino acid sequences of two proteins has been developed. From these findings it is possible to determine whether significant homology exists between the proteins. This information is used to trace their possible evolutionary development. The maximum match is a number dependent' upon the similarity of the sequences. One of its definitions is the largest number of amino acids of one protein that can be matched with those of a second protein allowing for all possible interruptions in either of the sequences. While the interruptions give rise to a very large number of comparisons, the method efficiently excludes from consideration those comparisons that cannot contribute to the maximum match. Comparisons are made from the smallest unit of significance, a pair of amino acids, one from each protein. All possible pairs are represented by a two-dimensional array, and all possible comparisons are representod by pathways through the array. For this maximum match only cerhain of the possible pathways must be evaluated. A numerical value, one in this case. is assigned to every cell in the array representing like amino acids. The maximum match is the largest number that would result from summing the cell values of every pathway. The amino acid sequences of a number of proteins have been compared to determine whether the relationships existing between them could have occurred by chance. Generally, these sequences are from proteins haring closely related functions and are so similar that simple visual comparisons can reveal sequence coincidence. Because the method of visual comparison is tedious and because the determination of the significance of a given result usually is left to intuitive rationalization, computer-based statistical approaches have been proposed (Fitch, 1966; Xeedleman 6 Blair, 1969). Direct comparison of two sequences, based on the presence in both of corresponding amino acids in a n identical array, is insuEcient to establish the full genetic relationships between the two proteins. Allowance for gaps (Braunitzer, 1965) greatly mnltiplies the number of comparisons t.hat can be made but int.roduces unnecessary and partial comparisons. The smallest unit of comparison is a pair of amino acids, one from each protein. The maximum match can be defined as the largest number of amino acids of one protein that can be matched with those of another protein while allowing for all possible deletions."
            },
            "slug": "A-General-Method-Applicable-to-the-Search-for-in-of-Christus-Wuksch",
            "title": {
                "fragments": [],
                "text": "A General Method Applicable to the Search for Similarities in the Amino Acid Sequence of Two Proteins"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A computer adaptable method for finding similarities in the amino acid sequences of two proteins has been developed and from these findings it is possible to determine whether significant homology exists between the proteins to trace their possible evolutionary development."
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708425"
                        ],
                        "name": "Jay J. Jiang",
                        "slug": "Jay-J.-Jiang",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Jiang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jay J. Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075147"
                        ],
                        "name": "D. Conrath",
                        "slug": "D.-Conrath",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Conrath",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Conrath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1359050,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b64e068a8face2540fc436af40dbcd2b0912bbf",
            "isKey": false,
            "numCitedBy": 3339,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach for measuring semantic similarity/distance between words and concepts. It combines a lexical taxonomy structure with corpus statistical information so that the semantic distance between nodes in the semantic space constructed by the taxonomy can be better quantified with the computational evidence derived from a distributional analysis of corpus data. Specifically, the proposed measure is a combined approach that inherits the edge-based approach of the edge counting scheme, which is then enhanced by the node-based approach of the information content calculation. When tested on a common data set of word pair similarity ratings, the proposed approach outperforms other computational models. It gives the highest correlation value (r = 0.828) with a benchmark based on human similarity judgements, whereas an upper bound (r = 0.885) is observed when human subjects replicate the same task."
            },
            "slug": "Semantic-Similarity-Based-on-Corpus-Statistics-and-Jiang-Conrath",
            "title": {
                "fragments": [],
                "text": "Semantic Similarity Based on Corpus Statistics and Lexical Taxonomy"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This paper presents a new approach for measuring semantic similarity/distance between words and concepts that combines a lexical taxonomy structure with corpus statistical information so that the semantic distance between nodes in the semantic space constructed by the taxonomy can be better quantified with the computational evidence derived from a distributional analysis of corpus data."
            },
            "venue": {
                "fragments": [],
                "text": "ROCLING/IJCLCLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145043214"
                        ],
                        "name": "Jason Eisner",
                        "slug": "Jason-Eisner",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Eisner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Eisner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5235197,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "dbafcda95fa3e7e9b5627472d6d4fb46454828ce",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper offers a detailed lesson plan on the forward-backward algorithm. The lesson is taught from a live, commented spreadsheet that implements the algorithm and graphs its behavior on a whimsical toy example. By experimenting with different inputs, one can help students develop intuitions about HMMs in particular and Expectation Maximization in general. The spreadsheet and a coordinated follow-up assignment are available."
            },
            "slug": "An-Interactive-Spreadsheet-for-Teaching-the-Eisner",
            "title": {
                "fragments": [],
                "text": "An Interactive Spreadsheet for Teaching the Forward-Backward Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper offers a detailed lesson plan on the forward-backward algorithm, a live, commented spreadsheet that implements the algorithm and graphs its behavior on a whimsical toy example to help students develop intuitions about HMMs in particular and Expectation Maximization in general."
            },
            "venue": {
                "fragments": [],
                "text": "ACL 2002"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643845523"
                        ],
                        "name": "F. ChenStanley",
                        "slug": "F.-ChenStanley",
                        "structuredName": {
                            "firstName": "F",
                            "lastName": "ChenStanley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. ChenStanley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643789739"
                        ],
                        "name": "GoodmanJoshua",
                        "slug": "GoodmanJoshua",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "GoodmanJoshua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "GoodmanJoshua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215842252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4e8bed3b50a035e1eabad614fe4218a34b3b178",
            "isKey": false,
            "numCitedBy": 2861,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "We survey the most widely-used algorithms for smoothing models for language n -gram modeling. We then present an extensive empirical comparison of several of these smoothing techniques, including t..."
            },
            "slug": "An-empirical-study-of-smoothing-techniques-for-ChenStanley-GoodmanJoshua",
            "title": {
                "fragments": [],
                "text": "An empirical study of smoothing techniques for language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A survey of the most widely-used algorithms for smoothing models for language n -gram modeling and an extensive empirical comparison of several of these smoothing techniques are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715952"
                        ],
                        "name": "A. Aho",
                        "slug": "A.-Aho",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Aho",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144281449"
                        ],
                        "name": "R. Sethi",
                        "slug": "R.-Sethi",
                        "structuredName": {
                            "firstName": "Ravi",
                            "lastName": "Sethi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sethi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 42981739,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7f33d55d94e75a554251fe7dc07f1d7b4db8e1a",
            "isKey": false,
            "numCitedBy": 9130,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Introduction 1.1 Language Processors 1.2 The Structure of a Compiler 1.3 The Evolution of Programming Languages 1.4 The Science of Building a Compiler 1.5 Applications of Compiler Technology 1.6 Programming Language Basics 1.7 Summary of Chapter 1 1.8 References for Chapter 1 2 A Simple Syntax-Directed Translator 2.1 Introduction 2.2 Syntax Definition 2.3 Syntax-Directed Translation 2.4 Parsing 2.5 A Translator for Simple Expressions 2.6 Lexical Analysis 2.7 Symbol Tables 2.8 Intermediate Code Generation 2.9 Summary of Chapter 2 3 Lexical Analysis 3.1 The Role of the Lexical Analyzer 3.2 Input Buffering 3.3 Specification of Tokens 3.4 Recognition of Tokens 3.5 The Lexical-Analyzer Generator Lex 3.6 Finite Automata 3.7 From Regular Expressions to Automata 3.8 Design of a Lexical-Analyzer Generator 3.9 Optimization of DFA-Based Pattern Matchers 3.10 Summary of Chapter 3 3.11 References for Chapter 3 4 Syntax Analysis 4.1 Introduction 4.2 Context-Free Grammars 4.3 Writing a Grammar 4.4 Top-Down Parsing 4.5 Bottom-Up Parsing 4.6 Introduction to LR Parsing: Simple LR 4.7 More Powerful LR Parsers 4.8 Using Ambiguous Grammars 4.9 Parser Generators 4.10 Summary of Chapter 4 4.11 References for Chapter 4 5 Syntax-Directed Translation 5.1 Syntax-Directed Definitions 5.2 Evaluation Orders for SDD's 5.3 Applications of Syntax-Directed Translation 5.4 Syntax-Directed Translation Schemes 5.5 Implementing L-Attributed SDD's 5.6 Summary of Chapter 5 5.7 References for Chapter 5 6 Intermediate-Code Generation 6.1 Variants of Syntax Trees 6.2 Three-Address Code 6.3 Types and Declarations 6.4 Translation of Expressions 6.5 Type Checking 6.6 Control Flow 6.7 Backpatching 6.8 Switch-Statements 6.9 Intermediate Code for Procedures 6.10 Summary of Chapter 6 6.11 References for Chapter 6 7 Run-Time Environments 7.1 Storage Organization 7.2 Stack Allocation of Space 7.3 Access to Nonlocal Data on the Stack 7.4 Heap Management 7.5 Introduction to Garbage Collection 7.6 Introduction to Trace-Based Collection 7.7 Short-Pause Garbage Collection 7.8 Advanced Topics in Garbage Collection 7.9 Summary of Chapter 7 7.10 References for Chapter 7 8 Code Generation 8.1 Issues in the Design of a Code Generator 8.2 The Target Language 8.3 Addresses in the Target Code 8.4 Basic Blocks and Flow Graphs 8.5 Optimization of Basic Blocks 8.6 A Simple Code Generator 8.7 Peephole Optimization 8.8 Register Allocation and Assignment 8.9 Instruction Selection by Tree Rewriting 8.10 Optimal Code Generation for Expressions 8.11 Dynamic Programming Code-Generation 8.12 Summary of Chapter 8 8.13 References for Chapter 8 9 Machine-Independent Optimizations 9.1 The Principal Sources of Optimization 9.2 Introduction to Data-Flow Analysis 9.3 Foundations of Data-Flow Analysis 9.4 Constant Propagation 9.5 Partial-Redundancy Elimination 9.6 Loops in Flow Graphs 9.7 Region-Based Analysis 9.8 Symbolic Analysis 9.9 Summary of Chapter 9 9.10 References for Chapter 9 10 Instruction-Level Parallelism 10.1 Processor Architectures 10.2 Code-Scheduling Constraints 10.3 Basic-Block Scheduling 10.4 Global Code Scheduling 10.5 Software Pipelining 10.6 Summary of Chapter 10 10.7 References for Chapter 10 11 Optimizing for Parallelism and Locality 11.1 Basic Concepts 11.2 Matrix Multiply: An In-Depth Example 11.3 Iteration Spaces 11.4 Affine Array Indexes 11.5 Data Reuse 11.6 Array Data-Dependence Analysis 11.7 Finding Synchronization-Free Parallelism 11.8 Synchronization Between Parallel Loops 11.9 Pipelining 11.10 Locality Optimizations 11.11 Other Uses of Affine Transforms 11.12 Summary of Chapter 11 11.13 References for Chapter 11 12 Interprocedural Analysis 12.1 Basic Concepts 12.2 Why Interprocedural Analysis? 12.3 A Logical Representation of Data Flow 12.4 A Simple Pointer-Analysis Algorithm 12.5 Context-Insensitive Interprocedural Analysis 12.6 Context-Sensitive Pointer Analysis 12.7 Datalog Implementation by BDD's 12.8 Summary of Chapter 12 12.9 References for Chapter 12 A A Complete Front End A.1 The Source Language A.2 Main A.3 Lexical Analyzer A.4 Symbol Tables and Types A.5 Intermediate Code for Expressions A.6 Jumping Code for Boolean Expressions A.7 Intermediate Code for Statements A.8 Parser A.9 Creating the Front End B Finding Linearly Independent Solutions Index"
            },
            "slug": "Compilers:-Principles,-Techniques,-and-Tools-Aho-Sethi",
            "title": {
                "fragments": [],
                "text": "Compilers: Principles, Techniques, and Tools"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This book discusses the design of a Code Generator, the role of the Lexical Analyzer, and other topics related to code generation and optimization."
            },
            "venue": {
                "fragments": [],
                "text": "Addison-Wesley series in computer science / World student series edition"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713428"
                        ],
                        "name": "S. Harabagiu",
                        "slug": "S.-Harabagiu",
                        "structuredName": {
                            "firstName": "Sanda",
                            "lastName": "Harabagiu",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Harabagiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724629"
                        ],
                        "name": "Marius Pasca",
                        "slug": "Marius-Pasca",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Pasca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marius Pasca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2248349"
                        ],
                        "name": "Steven J. Maiorano",
                        "slug": "Steven-J.-Maiorano",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Maiorano",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven J. Maiorano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5544341,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53073cf42228f7e1d23c513eb474c7e599f82c02",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the integration of several knowledge-based natural language processing techniques into a Question Answering system, capable of mining textual answers from large collections of texts. Surprizing quality is achieved when several lightweight knowledge-based NLP techniques complement mostly shallow, surface-based approaches."
            },
            "slug": "Experiments-with-Open-Domain-Textual-Question-Harabagiu-Pasca",
            "title": {
                "fragments": [],
                "text": "Experiments with Open-Domain Textual Question Answering"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper describes the integration of several knowledge-based natural language processing techniques into a Question Answering system, capable of mining textual answers from large collections of texts."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5083193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3ebcef26c22a373b6f26a67934213eb0582804e",
            "isKey": false,
            "numCitedBy": 5555,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a comparative study of feature selection methods in statistical learning of text categorization The focus is on aggres sive dimensionality reduction Five meth ods were evaluated including term selection based on document frequency DF informa tion gain IG mutual information MI a test CHI and term strength TS We found IG and CHI most e ective in our ex periments Using IG thresholding with a k nearest neighbor classi er on the Reuters cor pus removal of up to removal of unique terms actually yielded an improved classi cation accuracy measured by average preci sion DF thresholding performed similarly Indeed we found strong correlations between the DF IG and CHI values of a term This suggests that DF thresholding the simplest method with the lowest cost in computation can be reliably used instead of IG or CHI when the computation of these measures are too expensive TS compares favorably with the other methods with up to vocabulary reduction but is not competitive at higher vo cabulary reduction levels In contrast MI had relatively poor performance due to its bias towards favoring rare terms and its sen sitivity to probability estimation errors"
            },
            "slug": "A-Comparative-Study-on-Feature-Selection-in-Text-Yang-Pedersen",
            "title": {
                "fragments": [],
                "text": "A Comparative Study on Feature Selection in Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper finds strong correlations between the DF IG and CHI values of a term and suggests that DF thresholding the simplest method with the lowest cost in computation can be reliably used instead of IG or CHI when the computation of these measures are too expensive."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1451669581"
                        ],
                        "name": "T. Bayes",
                        "slug": "T.-Bayes",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bayes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bayes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12552294,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "bc9b8023d0a7f881c0dd29f7e206f3fc6c28669e",
            "isKey": false,
            "numCitedBy": 3421,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Problem Given the number of times in which an unknown event has happened and failed: Required the chance that the probability of its happening in a single trial lies somewhere between any two degrees of probability that can be named. SECTION 1 Definition 1. Several events are inconsistent, when if one of them happens, none of the rest can. 2. Two events are contrary when one, or other of them must; and both together cannot happen. 3. An event is said to fail, when it cannot happen; or, which comes to the same thing, when its contrary has happened. 4. An event is said to be determined when it has either happened or failed. 5. The probability of any event is the ratio between the value at which an expectation depending on the happening of the event ought to be computed, and the value of the thing expected upon it\u2019s 2 happening."
            },
            "slug": "An-essay-towards-solving-a-problem-in-the-doctrine-Bayes",
            "title": {
                "fragments": [],
                "text": "An essay towards solving a problem in the doctrine of chances"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The probability of any event is the ratio between the value at which an expectation depending on the happening of the event ought to be computed, and the value of the thing expected upon it\u2019s 2 happening."
            },
            "venue": {
                "fragments": [],
                "text": "M.D. computing : computers in medical practice"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761784"
                        ],
                        "name": "R. Tibshirani",
                        "slug": "R.-Tibshirani",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tibshirani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tibshirani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16162039,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b365b8e45b7d81f081de44ac8f9eadf9144f3ca5",
            "isKey": false,
            "numCitedBy": 36493,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY We propose a new method for estimation in linear models. The 'lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described."
            },
            "slug": "Regression-Shrinkage-and-Selection-via-the-Lasso-Tibshirani",
            "title": {
                "fragments": [],
                "text": "Regression Shrinkage and Selection via the Lasso"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A new method for estimation in linear models called the lasso, which minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant, is proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1752785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "265be00bf112c6cb2fa3e8176bff8394a114dbde",
            "isKey": false,
            "numCitedBy": 3890,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66)."
            },
            "slug": "Using-Information-Content-to-Evaluate-Semantic-in-a-Resnik",
            "title": {
                "fragments": [],
                "text": "Using Information Content to Evaluate Semantic Similarity in a Taxonomy"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content, which performs encouragingly well and is significantly better than the traditional edge counting approach."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144865353"
                        ],
                        "name": "B. Pang",
                        "slug": "B.-Pang",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Pang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Pang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066721"
                        ],
                        "name": "Shivakumar Vaithyanathan",
                        "slug": "Shivakumar-Vaithyanathan",
                        "structuredName": {
                            "firstName": "Shivakumar",
                            "lastName": "Vaithyanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shivakumar Vaithyanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Pang et al. (2002) first showed the power of using all the words without a sentiment lexicon; see also Wang and Manning (2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7105713,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12d0353ce8b41b7e5409e5a4a611110aee33c7bc",
            "isKey": false,
            "numCitedBy": 8512,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging."
            },
            "slug": "Thumbs-up-Sentiment-Classification-using-Machine-Pang-Lee",
            "title": {
                "fragments": [],
                "text": "Thumbs up? Sentiment Classification using Machine Learning Techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This work considers the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative, and concludes by examining factors that make the sentiment classification problem more challenging."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16928,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764547"
                        ],
                        "name": "M. Sahami",
                        "slug": "M.-Sahami",
                        "structuredName": {
                            "firstName": "Mehran",
                            "lastName": "Sahami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sahami"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145479841"
                        ],
                        "name": "E. Horvitz",
                        "slug": "E.-Horvitz",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Horvitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Horvitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5301578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "916177807ecbf0d78f2f64d756d4cecbaa3102a3",
            "isKey": false,
            "numCitedBy": 1598,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "In addressing the growing problem of junk E-mail on the Internet, we examine methods for the automated construction of filters to eliminate such unwanted messages from a user\u2019s mail stream. By casting this problem in a decision theoretic framework, we are able to make use of probabilistic learning methods in conjunction with a notion of differential misclassification cost to produce filters Which are especially appropriate for the nuances of this task. While this may appear, at first, to be a straight-forward text classification problem, we show that by considering domain-specific features of this problem in addition to the raw text of E-mail messages, we can produce much more accurate filters. Finally, we show the efficacy of such filters in a real world usage scenario, arguing that this technology is mature enough for deployment."
            },
            "slug": "A-Bayesian-Approach-to-Filtering-Junk-E-Mail-Sahami-Dumais",
            "title": {
                "fragments": [],
                "text": "A Bayesian Approach to Filtering Junk E-Mail"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This work examines methods for the automated construction of filters to eliminate such unwanted messages from a user\u2019s mail stream, and shows the efficacy of such filters in a real world usage scenario, arguing that this technology is mature enough for deployment."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 1998"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2614094"
                        ],
                        "name": "Rebecca F. Bruce",
                        "slug": "Rebecca-F.-Bruce",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Bruce",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rebecca F. Bruce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12514743"
                        ],
                        "name": "Tom O'Hara",
                        "slug": "Tom-O'Hara",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "O'Hara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom O'Hara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 151
                            }
                        ],
                        "text": "Affective meaning is closely related to subjectivity,subjectivity the study of a speaker or writer\u2019s evaluations, opinions, emotions, and speculations (Wiebe et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16161560,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4a974906a9f6c7380edc9e2281931bde78828b1",
            "isKey": false,
            "numCitedBy": 510,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a case study of analyzing and improving intercoder reliability in discourse tagging using statistical techniques. Bias-corrected tags are formulated and successfully used to guide a revision of the coding manual and develop an automatic classifier."
            },
            "slug": "Development-and-Use-of-a-Gold-Standard-Data-Set-for-Wiebe-Bruce",
            "title": {
                "fragments": [],
                "text": "Development and Use of a Gold-Standard Data Set for Subjectivity Classifications"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Bias-corrected tags are formulated and successfully used to guide a revision of the coding manual and develop an automatic classifier."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500689"
                        ],
                        "name": "A. Viterbi",
                        "slug": "A.-Viterbi",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Viterbi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Viterbi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15843983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "145c0b53514b02bdc3dadfb2e1cea124f2abd99b",
            "isKey": false,
            "numCitedBy": 5209,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as a function of the constraint length of the code. For all but pathological channels the bounds are asymptotically (exponentially) tight for rates above R_{0} , the computational cutoff rate of sequential decoding. As a function of constraint length the performance of optimal convolutional codes is shown to be superior to that of block codes of the same length, the relative improvement increasing with rate. The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "slug": "Error-bounds-for-convolutional-codes-and-an-optimum-Viterbi",
            "title": {
                "fragments": [],
                "text": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693256"
                        ],
                        "name": "D. Sankoff",
                        "slug": "D.-Sankoff",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Sankoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sankoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 22517630,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "8377fc1fff7eb8073015c2227aba98bd0c741db2",
            "isKey": false,
            "numCitedBy": 302,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Given two finite sequences, we wish to find the longest common subsequences satisfying certain deletion/insertion constraints. Consider two successive terms in the desired subsequence. The distance between their positions must be the same in the two original sequences for all but a limited number of such pairs of successive terms. Needleman and Wunsch gave an algorithm for finding longest common subsequences without constraints. This is improved from the viewpoint of computational economy. An economical algorithm is then elaborated for finding subsequences satisfying deletion/insertion constraints. This result is useful in the study of genetic homology based on nucleotide or amino-acid sequences."
            },
            "slug": "Matching-sequences-under-deletion-insertion-Sankoff",
            "title": {
                "fragments": [],
                "text": "Matching sequences under deletion-insertion constraints."
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "An economical algorithm is elaborated for finding subsequences satisfying deletion/insertion constraints and is useful in the study of genetic homology based on nucleotide or amino-acid sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103072546"
                        ],
                        "name": "J. Eagon",
                        "slug": "J.-Eagon",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Eagon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eagon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14153120,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "69fc8c03d21e22e30d6642824c37158b314f36c3",
            "isKey": false,
            "numCitedBy": 1122,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Summary. The object of this note is to prove the theorem below and sketch two applications, one to statistical estimation for (proba-bilistic) functions of Markov processes [l] and one to Blakley's model for ecology [4]. 2. Result. THEOREM. Let P(x)=P({xij}) be a polynomial with nonnegative coefficients homogeneous of degree d in its variables {##}. Let x= {##} be any point of the domain D: ## \u00a7:(), ]pLi ## = 1, i = l, \u2022 \u2022 \u2022 , p, j=l, \u2022 \u2022 \u2022 , q%. For x= {xij} \u00a3\u00a3> let 3(#) = 3{##} denote the point of D whose i, j coordinate is (dP\\ \\ f \u00ab dP 3(*)<i = (Xij 7\u2014) / 2* *<i \u2014 \\ dXij\\(X)// ,-i dXij (\u00bb> Then P(3(x))>P(x) unless 3(x)=x. Notation, fi will denote a doubly indexed array of nonnegative integers: fx= {M#}> i = l> \u2022 \u2022 \u2022 > <lu i=l, \u2022 \u2022 \u2022 , A #* then denotes Ilf-iH\u00ee-i^* Similarly, c M is an abbreviation for C[ MiJ }. The polynomial P({xij}) is then written P(x) = ]CM V^-In our notation : (1) 3(&)*i = (Z) \u00abWnys*) / JLH CpiiijX\u00bb."
            },
            "slug": "An-inequality-with-applications-to-statistical-for-Baum-Eagon",
            "title": {
                "fragments": [],
                "text": "An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "76949851"
                        ],
                        "name": "E. Vesterinen",
                        "slug": "E.-Vesterinen",
                        "structuredName": {
                            "firstName": "Eerik",
                            "lastName": "Vesterinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Vesterinen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 75
                            }
                        ],
                        "text": "We use the word \u2018affective\u2019, following the tradition in affective computing (Picard, 1995) to mean emotion, sentiment, personality, mood, and attitudes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1889656,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b85a01a87e4e0830886c9725e1c1c387433cf04",
            "isKey": false,
            "numCitedBy": 3005,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the intellectual framework and field of study of affective computing. This is a seminar paper written for course Tik-111.590 Digital media research seminar, spring 2001: \u201cSpace Odyssey 2001\u201d. The paper is based on a literature study of affective computing."
            },
            "slug": "Affective-Computing-Vesterinen",
            "title": {
                "fragments": [],
                "text": "Affective Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The intellectual framework and field of study of affective computing is described, based on a literature study of Affective computing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115282352"
                        ],
                        "name": "Joy A. Thomas",
                        "slug": "Joy-A.-Thomas",
                        "structuredName": {
                            "firstName": "Joy",
                            "lastName": "Thomas",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joy A. Thomas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 190432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dbdb4209626fd92d2436a058663206216036e68",
            "isKey": false,
            "numCitedBy": 42796,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface to the Second Edition. Preface to the First Edition. Acknowledgments for the Second Edition. Acknowledgments for the First Edition. 1. Introduction and Preview. 1.1 Preview of the Book. 2. Entropy, Relative Entropy, and Mutual Information. 2.1 Entropy. 2.2 Joint Entropy and Conditional Entropy. 2.3 Relative Entropy and Mutual Information. 2.4 Relationship Between Entropy and Mutual Information. 2.5 Chain Rules for Entropy, Relative Entropy, and Mutual Information. 2.6 Jensen's Inequality and Its Consequences. 2.7 Log Sum Inequality and Its Applications. 2.8 Data-Processing Inequality. 2.9 Sufficient Statistics. 2.10 Fano's Inequality. Summary. Problems. Historical Notes. 3. Asymptotic Equipartition Property. 3.1 Asymptotic Equipartition Property Theorem. 3.2 Consequences of the AEP: Data Compression. 3.3 High-Probability Sets and the Typical Set. Summary. Problems. Historical Notes. 4. Entropy Rates of a Stochastic Process. 4.1 Markov Chains. 4.2 Entropy Rate. 4.3 Example: Entropy Rate of a Random Walk on a Weighted Graph. 4.4 Second Law of Thermodynamics. 4.5 Functions of Markov Chains. Summary. Problems. Historical Notes. 5. Data Compression. 5.1 Examples of Codes. 5.2 Kraft Inequality. 5.3 Optimal Codes. 5.4 Bounds on the Optimal Code Length. 5.5 Kraft Inequality for Uniquely Decodable Codes. 5.6 Huffman Codes. 5.7 Some Comments on Huffman Codes. 5.8 Optimality of Huffman Codes. 5.9 Shannon-Fano-Elias Coding. 5.10 Competitive Optimality of the Shannon Code. 5.11 Generation of Discrete Distributions from Fair Coins. Summary. Problems. Historical Notes. 6. Gambling and Data Compression. 6.1 The Horse Race. 6.2 Gambling and Side Information. 6.3 Dependent Horse Races and Entropy Rate. 6.4 The Entropy of English. 6.5 Data Compression and Gambling. 6.6 Gambling Estimate of the Entropy of English. Summary. Problems. Historical Notes. 7. Channel Capacity. 7.1 Examples of Channel Capacity. 7.2 Symmetric Channels. 7.3 Properties of Channel Capacity. 7.4 Preview of the Channel Coding Theorem. 7.5 Definitions. 7.6 Jointly Typical Sequences. 7.7 Channel Coding Theorem. 7.8 Zero-Error Codes. 7.9 Fano's Inequality and the Converse to the Coding Theorem. 7.10 Equality in the Converse to the Channel Coding Theorem. 7.11 Hamming Codes. 7.12 Feedback Capacity. 7.13 Source-Channel Separation Theorem. Summary. Problems. Historical Notes. 8. Differential Entropy. 8.1 Definitions. 8.2 AEP for Continuous Random Variables. 8.3 Relation of Differential Entropy to Discrete Entropy. 8.4 Joint and Conditional Differential Entropy. 8.5 Relative Entropy and Mutual Information. 8.6 Properties of Differential Entropy, Relative Entropy, and Mutual Information. Summary. Problems. Historical Notes. 9. Gaussian Channel. 9.1 Gaussian Channel: Definitions. 9.2 Converse to the Coding Theorem for Gaussian Channels. 9.3 Bandlimited Channels. 9.4 Parallel Gaussian Channels. 9.5 Channels with Colored Gaussian Noise. 9.6 Gaussian Channels with Feedback. Summary. Problems. Historical Notes. 10. Rate Distortion Theory. 10.1 Quantization. 10.2 Definitions. 10.3 Calculation of the Rate Distortion Function. 10.4 Converse to the Rate Distortion Theorem. 10.5 Achievability of the Rate Distortion Function. 10.6 Strongly Typical Sequences and Rate Distortion. 10.7 Characterization of the Rate Distortion Function. 10.8 Computation of Channel Capacity and the Rate Distortion Function. Summary. Problems. Historical Notes. 11. Information Theory and Statistics. 11.1 Method of Types. 11.2 Law of Large Numbers. 11.3 Universal Source Coding. 11.4 Large Deviation Theory. 11.5 Examples of Sanov's Theorem. 11.6 Conditional Limit Theorem. 11.7 Hypothesis Testing. 11.8 Chernoff-Stein Lemma. 11.9 Chernoff Information. 11.10 Fisher Information and the Cram-er-Rao Inequality. Summary. Problems. Historical Notes. 12. Maximum Entropy. 12.1 Maximum Entropy Distributions. 12.2 Examples. 12.3 Anomalous Maximum Entropy Problem. 12.4 Spectrum Estimation. 12.5 Entropy Rates of a Gaussian Process. 12.6 Burg's Maximum Entropy Theorem. Summary. Problems. Historical Notes. 13. Universal Source Coding. 13.1 Universal Codes and Channel Capacity. 13.2 Universal Coding for Binary Sequences. 13.3 Arithmetic Coding. 13.4 Lempel-Ziv Coding. 13.5 Optimality of Lempel-Ziv Algorithms. Compression. Summary. Problems. Historical Notes. 14. Kolmogorov Complexity. 14.1 Models of Computation. 14.2 Kolmogorov Complexity: Definitions and Examples. 14.3 Kolmogorov Complexity and Entropy. 14.4 Kolmogorov Complexity of Integers. 14.5 Algorithmically Random and Incompressible Sequences. 14.6 Universal Probability. 14.7 Kolmogorov complexity. 14.9 Universal Gambling. 14.10 Occam's Razor. 14.11 Kolmogorov Complexity and Universal Probability. 14.12 Kolmogorov Sufficient Statistic. 14.13 Minimum Description Length Principle. Summary. Problems. Historical Notes. 15. Network Information Theory. 15.1 Gaussian Multiple-User Channels. 15.2 Jointly Typical Sequences. 15.3 Multiple-Access Channel. 15.4 Encoding of Correlated Sources. 15.5 Duality Between Slepian-Wolf Encoding and Multiple-Access Channels. 15.6 Broadcast Channel. 15.7 Relay Channel. 15.8 Source Coding with Side Information. 15.9 Rate Distortion with Side Information. 15.10 General Multiterminal Networks. Summary. Problems. Historical Notes. 16. Information Theory and Portfolio Theory. 16.1 The Stock Market: Some Definitions. 16.2 Kuhn-Tucker Characterization of the Log-Optimal Portfolio. 16.3 Asymptotic Optimality of the Log-Optimal Portfolio. 16.4 Side Information and the Growth Rate. 16.5 Investment in Stationary Markets. 16.6 Competitive Optimality of the Log-Optimal Portfolio. 16.7 Universal Portfolios. 16.8 Shannon-McMillan-Breiman Theorem (General AEP). Summary. Problems. Historical Notes. 17. Inequalities in Information Theory. 17.1 Basic Inequalities of Information Theory. 17.2 Differential Entropy. 17.3 Bounds on Entropy and Relative Entropy. 17.4 Inequalities for Types. 17.5 Combinatorial Bounds on Entropy. 17.6 Entropy Rates of Subsets. 17.7 Entropy and Fisher Information. 17.8 Entropy Power Inequality and Brunn-Minkowski Inequality. 17.9 Inequalities for Determinants. 17.10 Inequalities for Ratios of Determinants. Summary. Problems. Historical Notes. Bibliography. List of Symbols. Index."
            },
            "slug": "Elements-of-Information-Theory-Cover-Thomas",
            "title": {
                "fragments": [],
                "text": "Elements of Information Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author examines the role of entropy, inequality, and randomness in the design of codes and the construction of codes in the rapidly changing environment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3969220"
                        ],
                        "name": "J. M. Digman",
                        "slug": "J.-M.-Digman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Digman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Digman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 135
                            }
                        ],
                        "text": "Many theories of human personality are based around a small number of dimensions, such as various versions of the \u201cBig Five\u201d dimensions (Digman, 1990):\nExtroversion vs. Introversion: sociable, assertive, playful vs. aloof, reserved, shy\nEmotional stability vs. Neuroticism: calm, unemotional vs.\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 145634727,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ec1cec03d80cb6cf7330ba03f01d1d08ab5d598f",
            "isKey": false,
            "numCitedBy": 6120,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "L'auteur discute un modele a cinq facteurs de la personnalite qu'il confronte a d'autres systemes de la personnalite et dont les correlats des dimensions sont analyses ainsi que les problemes methodologiques"
            },
            "slug": "PERSONALITY-STRUCTURE:-EMERGENCE-OF-THE-FIVE-FACTOR-Digman",
            "title": {
                "fragments": [],
                "text": "PERSONALITY STRUCTURE: EMERGENCE OF THE FIVE-FACTOR MODEL"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784955"
                        ],
                        "name": "J. Nocedal",
                        "slug": "J.-Nocedal",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Nocedal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nocedal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9033333,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2aaf56fb183ad66d099ac6c9110c5c365ab27f3",
            "isKey": false,
            "numCitedBy": 2414,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We study how to use the BFGS quasi-Newton matrices to precondition minimization methods for problems where the storage is critical. We give an update formula which generates matrices using information from the last m iterations, where m is any number supplied by the user. The quasi-Newton matrix is updated at every iteration by dropping the oldest information and replacing it by the newest informa- tion. It is shown that the matrices generated have some desirable properties. The resulting algorithms are tested numerically and compared with several well- known methods. 1. Introduction. For the problem of minimizing an unconstrained function / of n variables, quasi-Newton methods are widely employed (4). They construct a se- quence of matrices which in some way approximate the hessian of /(or its inverse). These matrices are symmetric; therefore, it is necessary to have n(n + l)/2 storage locations for each one. For large dimensional problems it will not be possible to re- tain the matrices in the high speed storage of a computer, and one has to resort to other kinds of algorithms. For example, one could use the methods (Toint (15), Shanno (12)) which preserve the sparsity structure of the hessian, or conjugate gradient methods (CG) which only have to store 3 or 4 vectors. Recently, some CG algorithms have been developed which use a variable amount of storage and which do not require knowledge about the sparsity structure of the problem (2), (7), (8). A disadvantage of these methods is that after a certain number of iterations the quasi-Newton matrix is discarded, and the algorithm is restarted using an initial matrix (usually a diagonal matrix). We describe an algorithm which uses a limited amount of storage and where the quasi-Newton matrix is updated continuously. At every step the oldest information contained in the matrix is discarded and replaced by new one. In this way we hope to have a more up to date model of our function. We will concentrate on the BFGS method since it is considered to be the most efficient. We believe that similar algo- rithms cannot be developed for the other members of the Broyden 0-class (1). Let / be the function to be nnnimized, g its gradient and h its hessian. We define"
            },
            "slug": "Updating-Quasi-Newton-Matrices-With-Limited-Storage-Nocedal",
            "title": {
                "fragments": [],
                "text": "Updating Quasi-Newton Matrices With Limited Storage"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An update formula which generates matrices using information from the last m iterations, where m is any number supplied by the user, and the BFGS method is considered to be the most efficient."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24805,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5659557,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc0c3033ea7d4e19e1f5ac71934759507e126162",
            "isKey": false,
            "numCitedBy": 4466,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Similarity is an important and widely used concept. Previous definitions of similarity are tied to a particular application or a form of knowledge representation. We present an informationtheoretic definition of similarity that is applicable as long as there is a probabilistic model. We demonstrate how our definition can be used to measure the similarity in a number of different domains."
            },
            "slug": "An-Information-Theoretic-Definition-of-Similarity-Lin",
            "title": {
                "fragments": [],
                "text": "An Information-Theoretic Definition of Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work presents an informationtheoretic definition of similarity that is applicable as long as there is a probabilistic model and demonstrates how this definition can be used to measure the similarity in a number of different domains."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6305097,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6f3250ba47fdb413a0c113cc16d274517864f8ab",
            "isKey": false,
            "numCitedBy": 661,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We study distributional similarity measures for the purpose of improving probability estimation for unseen cooccurrences. Our contributions are three-fold: an empirical comparison of a broad range of measures; a classification of similarity functions based on the information that they incorporate; and the introduction of a novel function that is superior at evaluating potential proxy distributions."
            },
            "slug": "Measures-of-Distributional-Similarity-Lee",
            "title": {
                "fragments": [],
                "text": "Measures of Distributional Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents an empirical comparison of a broad range of measures; a classification of similarity functions based on the information that they incorporate; and the introduction of a novel function that is superior at evaluating potential proxy distributions."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2192001"
                        ],
                        "name": "P. Algoet",
                        "slug": "P.-Algoet",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Algoet",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Algoet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121232612,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d449d9966819a0a2fbfb324234ad2e27d85c4b30",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "On presente une preuve elementaire du theoreme de Shannon et Mc Millan-Breiman et une generalisation precedente pour prevoir le besoin de verifier les conditions d'integrabilite. Un argument sandwich reduit la preuve pour les applications directes du theoreme ergodique"
            },
            "slug": "A-sandwich-proof-of-the-Shannon-McMillan-Breiman-Algoet-Cover",
            "title": {
                "fragments": [],
                "text": "A sandwich proof of the Shannon-McMillan-Breiman theorem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2692987"
                        ],
                        "name": "Huaiyu Zhu",
                        "slug": "Huaiyu-Zhu",
                        "structuredName": {
                            "firstName": "Huaiyu",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huaiyu Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 116908168,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "87cbed883368d4a9efd42fdd91f47038f8d8fbe6",
            "isKey": false,
            "numCitedBy": 6006,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The information deviation between any two finite measures cannot be increased by any statistical operations (Markov morphisms). It is invarient if and only if the morphism is sufficient for these two measures"
            },
            "slug": "On-Information-and-Sufficiency-Zhu",
            "title": {
                "fragments": [],
                "text": "On Information and Sufficiency"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144448267"
                        ],
                        "name": "R. Byrd",
                        "slug": "R.-Byrd",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Byrd",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Byrd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2337678"
                        ],
                        "name": "P. Lu",
                        "slug": "P.-Lu",
                        "structuredName": {
                            "firstName": "Peihuang",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784955"
                        ],
                        "name": "J. Nocedal",
                        "slug": "J.-Nocedal",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Nocedal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nocedal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34728746"
                        ],
                        "name": "Ciyou Zhu",
                        "slug": "Ciyou-Zhu",
                        "structuredName": {
                            "firstName": "Ciyou",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ciyou Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6398414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47a9ab6f97ab05fcd49aaf2864c97538b55e6268",
            "isKey": false,
            "numCitedBy": 3770,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for solving large nonlinear optimization problems with simple bounds is described. It is based on the gradient projection method and uses a limited memory BFGS matrix to approximate the Hessian of the objective function. It is shown how to take advantage of the form of the limited memory approximation to implement the algorithm efficiently. The results of numerical tests on a set of large problems are reported."
            },
            "slug": "A-Limited-Memory-Algorithm-for-Bound-Constrained-Byrd-Lu",
            "title": {
                "fragments": [],
                "text": "A Limited Memory Algorithm for Bound Constrained Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "An algorithm for solving large nonlinear optimization problems with simple bounds is described, based on the gradient projection method and uses a limited memory BFGS matrix to approximate the Hessian of the objective function."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Sci. Comput."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736088"
                        ],
                        "name": "H. Gabow",
                        "slug": "H.-Gabow",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Gabow",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Gabow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694216"
                        ],
                        "name": "Z. Galil",
                        "slug": "Z.-Galil",
                        "structuredName": {
                            "firstName": "Zvi",
                            "lastName": "Galil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Galil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145022"
                        ],
                        "name": "T. Spencer",
                        "slug": "T.-Spencer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Spencer",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Spencer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721050"
                        ],
                        "name": "R. Tarjan",
                        "slug": "R.-Tarjan",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tarjan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tarjan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35618095,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93fd9a6ad790d4b1adb35efc41ef39c2030bba6b",
            "isKey": false,
            "numCitedBy": 518,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, Fredman and Tarjan invented a new, especially efficient form of heap (priority queue). Their data structure, theFibonacci heap (or F-heap) supports arbitrary deletion inO(logn) amortized time and other heap operations inO(1) amortized time. In this paper we use F-heaps to obtain fast algorithms for finding minimum spanning trees in undirected and directed graphs. For an undirected graph containingn vertices andm edges, our minimum spanning tree algorithm runs inO(m log\u03b2 (m, n)) time, improved fromO(m\u03b2(m, n)) time, where\u03b2(m, n)=min {i|log(i)n \u2266m/n}. Our minimum spanning tree algorithm for directed graphs runs inO(n logn + m) time, improved fromO(n log n +m log log log(m/n+2)n). Both algorithms can be extended to allow a degree constraint at one vertex."
            },
            "slug": "Efficient-algorithms-for-finding-minimum-spanning-Gabow-Galil",
            "title": {
                "fragments": [],
                "text": "Efficient algorithms for finding minimum spanning trees in undirected and directed graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "This paper uses F-heaps to obtain fast algorithms for finding minimum spanning trees in undirected and directed graphs and can be extended to allow a degree constraint at one vertex."
            },
            "venue": {
                "fragments": [],
                "text": "Comb."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414906"
                        ],
                        "name": "J. Nielsen",
                        "slug": "J.-Nielsen",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Nielsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nielsen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1052093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24be9600fa9b3cbb9cf1b9e3c0666a95afdb073d",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A practical usability engineering process that can be incorporated into the software product development process to ensure the usability of interactive computer products is presented. It is shown that the most basic elements in the usability engineering model are empirical user testing and prototyping, combined with iterative design. Usability activities are presented for three main phases of a software project: before, during, and after product design and implementation. Some of the recommended methods are not really single steps but should be used throughout the development process.<<ETX>>"
            },
            "slug": "The-usability-engineering-life-cycle-Nielsen",
            "title": {
                "fragments": [],
                "text": "The usability engineering life cycle"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that the most basic elements in the usability engineering model are empirical user testing and prototyping, combined with iterative design."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462740"
                        ],
                        "name": "K. Scherer",
                        "slug": "K.-Scherer",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Scherer",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Scherer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 42
                            }
                        ],
                        "text": "Another kind of affective meaning is what Scherer (2000) calls interpersonal stance, the \u2018affective stance taken toward another person in a specific interactioninterpersonalstance coloring the interpersonal exchange\u2019."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 56
                            }
                        ],
                        "text": "One influential typology of affective states comes from Scherer (2000), who defines each class of affective states by factors like its cognition realization and time course:\nWe can design extractors for each of these kinds of affective states."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 93
                            }
                        ],
                        "text": "18.5 Emotion and other classes\nOne of the most important affective classes is emotion, which Scherer (2000) definesemotion as a \u201crelatively brief episode of response to the evaluation of an external or internal event as being of major significance\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 135
                            }
                        ],
                        "text": "18.7 Affect Recognition\nDetection of emotion, personality, interactional stance, and the other kinds of affective meaning described by Scherer (2000) can be done by generalizing the algorithms described above for detecting sentiment."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 143219855,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "772a04d9becd81b3137d10dc575754f3c3b19ffc",
            "isKey": true,
            "numCitedBy": 487,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Psychological-models-of-emotion.-Scherer",
            "title": {
                "fragments": [],
                "text": "Psychological models of emotion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 42
                            }
                        ],
                        "text": "Another kind of affective meaning is what Scherer (2000) calls interpersonal stance, the \u2018affective stance taken toward another person in a specific interactioninterpersonalstance coloring the interpersonal exchange\u2019."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 56
                            }
                        ],
                        "text": "One influential typology of affective states comes from Scherer (2000), who defines each class of affective states by factors like its cognition realization and time course:\nWe can design extractors for each of these kinds of affective states."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 93
                            }
                        ],
                        "text": "18.5 Emotion and other classes\nOne of the most important affective classes is emotion, which Scherer (2000) definesemotion as a \u201crelatively brief episode of response to the evaluation of an external or internal event as being of major significance\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 135
                            }
                        ],
                        "text": "18.7 Affect Recognition\nDetection of emotion, personality, interactional stance, and the other kinds of affective meaning described by Scherer (2000) can be done by generalizing the algorithms described above for detecting sentiment."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Psychological models of emotion The neuropsychology of emotion"
            },
            "venue": {
                "fragments": [],
                "text": "Psychological models of emotion The neuropsychology of emotion"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69001234"
                        ],
                        "name": "W. Percival",
                        "slug": "W.-Percival",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Percival",
                            "middleNames": [
                                "Keith"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Percival"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 222372593,
            "fieldsOfStudy": [
                "History"
            ],
            "id": "d66436315690b6ae609a55240f5d74fce74720e1",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-Historical-Source-of-Immediate-Constituent-Percival",
            "title": {
                "fragments": [],
                "text": "On the Historical Source of Immediate Constituent Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144191879"
                        ],
                        "name": "J. Firth",
                        "slug": "J.-Firth",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Firth",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Firth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 208093066,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "88b3959b6f5333e5358eac43970a5fa29b54642c",
            "isKey": false,
            "numCitedBy": 1923,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Synopsis-of-Linguistic-Theory,-1930-1955-Firth",
            "title": {
                "fragments": [],
                "text": "A Synopsis of Linguistic Theory, 1930-1955"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31518792"
                        ],
                        "name": "J. Sammet",
                        "slug": "J.-Sammet",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Sammet",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sammet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 173079962,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "bb59a538319847ced2c4f0b4cfb4cc1067f079d2",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Transcript-of-question-and-answer-session-Sammet",
            "title": {
                "fragments": [],
                "text": "Transcript of question and answer session"
            },
            "venue": {
                "fragments": [],
                "text": "HOPL"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47263723"
                        ],
                        "name": "W. Wundt",
                        "slug": "W.-Wundt",
                        "structuredName": {
                            "firstName": "Wilhelm",
                            "lastName": "Wundt",
                            "middleNames": [
                                "Max"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wundt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 171051922,
            "fieldsOfStudy": [
                "Philosophy",
                "Psychology"
            ],
            "id": "2cf622228de23d7d0edb1b4c9677bb57155cd36c",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "V\u00f6lkerpsychologie-:-eine-Untersuchung-der-von-und-Wundt",
            "title": {
                "fragments": [],
                "text": "V\u00f6lkerpsychologie : eine Untersuchung der Entwicklungsgesetze von Sprache, Mythus und Sitte"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1900
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145607468"
                        ],
                        "name": "Jeffrey Gruber",
                        "slug": "Jeffrey-Gruber",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Gruber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Gruber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 154155047,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "5c79d503a1f38a92f5e8f3f8c5225d0967b59971",
            "isKey": false,
            "numCitedBy": 632,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Studies-in-lexical-relations-Gruber",
            "title": {
                "fragments": [],
                "text": "Studies in lexical relations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46367714"
                        ],
                        "name": "J. Russell",
                        "slug": "J.-Russell",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Russell",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Russell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 84
                            }
                        ],
                        "text": "The second class of emotion theories views emotion as a space in 2 or 3 dimensions (Russell, 1980)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 145278842,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "9bb28869d9808b12273c42229c2d1aa564e5bac8",
            "isKey": false,
            "numCitedBy": 11533,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-circumplex-model-of-affect.-Russell",
            "title": {
                "fragments": [],
                "text": "A circumplex model of affect."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14664289"
                        ],
                        "name": "P. Stone",
                        "slug": "P.-Stone",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Stone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39396941"
                        ],
                        "name": "D. Dunphy",
                        "slug": "D.-Dunphy",
                        "structuredName": {
                            "firstName": "Dexter",
                            "lastName": "Dunphy",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dunphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49826480"
                        ],
                        "name": "Marshall S. Smith",
                        "slug": "Marshall-S.-Smith",
                        "structuredName": {
                            "firstName": "Marshall",
                            "lastName": "Smith",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marshall S. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60936250,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "c13d3506f716fb9fb0c417b5132144db42f80dd4",
            "isKey": false,
            "numCitedBy": 1761,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-general-inquirer:-A-computer-approach-to-Stone-Dunphy",
            "title": {
                "fragments": [],
                "text": "The general inquirer: A computer approach to content analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84527386"
                        ],
                        "name": "R. Plutchik",
                        "slug": "R.-Plutchik",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Plutchik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Plutchik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 157
                            }
                        ],
                        "text": "In one family, emotions are viewed as fixed atomic units, limited in number, and from which others are generated, often called basic emotions (Tomkins 1962, Plutchik 1962)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 143902536,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "954449b805093b2c04e43bbf0ac6cedc6aff891f",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-emotions:-Facts,-theories-and-a-new-model.-Plutchik",
            "title": {
                "fragments": [],
                "text": "The emotions: Facts, theories and a new model."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52290445"
                        ],
                        "name": "E. Nida",
                        "slug": "E.-Nida",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Nida",
                            "middleNames": [
                                "Albert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Nida"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 142230083,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "814a53ca34959f9143a226ec3fdfcb5e0e82f0c3",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Componential-Analysis-of-Meaning:-An-Introduction-Nida",
            "title": {
                "fragments": [],
                "text": "A Componential Analysis of Meaning: An Introduction to Semantic Structures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2478950"
                        ],
                        "name": "Mark A. Boyer",
                        "slug": "Mark-A.-Boyer",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Boyer",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark A. Boyer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 142392277,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "12a193d0e003056f3e7b629661c4e89e522cee53",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-American-heritage-dictionary-Boyer",
            "title": {
                "fragments": [],
                "text": "The American heritage dictionary"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403310"
                        ],
                        "name": "R. Schank",
                        "slug": "R.-Schank",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Schank",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1948269"
                        ],
                        "name": "R. Abelson",
                        "slug": "R.-Abelson",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Abelson",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Abelson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141006767,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "8ba4429283b265c2e42139d39680524e6180d847",
            "isKey": false,
            "numCitedBy": 4923,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SCRIPTS,-PLANS,-GOALS,-AND-UNDERSTANDING-Schank-Abelson",
            "title": {
                "fragments": [],
                "text": "SCRIPTS, PLANS, GOALS, AND UNDERSTANDING"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47994881"
                        ],
                        "name": "S. Buckland",
                        "slug": "S.-Buckland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Buckland",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Buckland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70421692"
                        ],
                        "name": "E. Noreen",
                        "slug": "E.-Noreen",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Noreen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Noreen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125262802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "189e44489209454d363e6a0e272f3c5c80bbde1b",
            "isKey": false,
            "numCitedBy": 482,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Intensive-Methods-for-Testing-Hypotheses.-Buckland-Noreen",
            "title": {
                "fragments": [],
                "text": "Computer-Intensive Methods for Testing Hypotheses."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101417471"
                        ],
                        "name": "T. K. Vintsyuk",
                        "slug": "T.-K.-Vintsyuk",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Vintsyuk",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. K. Vintsyuk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123081024,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ade2cc4da5bd8cf447b8435340edcd8b8b10a90a",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speech-discrimination-by-dynamic-programming-Vintsyuk",
            "title": {
                "fragments": [],
                "text": "Speech discrimination by dynamic programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120208815,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "603bdbb17ba1f909280405a076455ac4f878fbf3",
            "isKey": false,
            "numCitedBy": 2773,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-Inference-for-Probabilistic-Functions-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "Statistical Inference for Probabilistic Functions of Finite State Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143716922"
                        ],
                        "name": "G. Lakoff",
                        "slug": "G.-Lakoff",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Lakoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lakoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116155535,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "f3eca665e21a5cc676324c850ad50640475e1111",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-The-Nature-Of-Syntactic-Irregularity-Lakoff",
            "title": {
                "fragments": [],
                "text": "On The Nature Of Syntactic Irregularity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145091160"
                        ],
                        "name": "B. Levin",
                        "slug": "B.-Levin",
                        "structuredName": {
                            "firstName": "Beth",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Levin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 108602045,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "2d1bd090f0e4eee50238bc80add2c8dd67ca0ef2",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mapping-Sentences-to-Case-Frames-Levin",
            "title": {
                "fragments": [],
                "text": "Mapping Sentences to Case Frames"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2779846"
                        ],
                        "name": "H. Sakoe",
                        "slug": "H.-Sakoe",
                        "structuredName": {
                            "firstName": "Hiroaki",
                            "lastName": "Sakoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sakoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35805230"
                        ],
                        "name": "S. Chiba",
                        "slug": "S.-Chiba",
                        "structuredName": {
                            "firstName": "Seibi",
                            "lastName": "Chiba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chiba"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 107516844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d2eb229c21269ffaa8a85b0961a2bda1116a6c7",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Dynamic-Programming-Approach-to-Continuous-Speech-Sakoe-Chiba",
            "title": {
                "fragments": [],
                "text": "A Dynamic Programming Approach to Continuous Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50381258"
                        ],
                        "name": "G. Barnard",
                        "slug": "G.-Barnard",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Barnard",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30021514"
                        ],
                        "name": "R. Fano",
                        "slug": "R.-Fano",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fano",
                            "middleNames": [
                                "Mario"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fano"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 67110416,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "6b6dc1167d8f6f44f230309e9c27e4268578f1f7",
            "isKey": false,
            "numCitedBy": 941,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Transmission-of-Information:-A-Statistical-Theory-Barnard-Fano",
            "title": {
                "fragments": [],
                "text": "Transmission of Information: A Statistical Theory of Communications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63164833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "634ec8cce662d1f67d9de909dd14b14042a3ee00",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Building-Semantic-Concordances-Fellbaum-Miller",
            "title": {
                "fragments": [],
                "text": "Building Semantic Concordances"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784211"
                        ],
                        "name": "S. Kuno",
                        "slug": "S.-Kuno",
                        "structuredName": {
                            "firstName": "Susumu",
                            "lastName": "Kuno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kuno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072770"
                        ],
                        "name": "A. Oettinger",
                        "slug": "A.-Oettinger",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Oettinger",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oettinger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62018241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a2258eabb6e6e38fbcaaedf42b6ec3e340bcd65",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multiple-path-syntactic-analyzer-Kuno-Oettinger",
            "title": {
                "fragments": [],
                "text": "Multiple-path syntactic analyzer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35096171"
                        ],
                        "name": "E. Kelly",
                        "slug": "E.-Kelly",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Kelly",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14664289"
                        ],
                        "name": "P. Stone",
                        "slug": "P.-Stone",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Stone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61812228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c59c1f2720b5fda6c70a3c78f3d63b7c523d6fa",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-recognition-of-English-word-senses-Kelly-Stone",
            "title": {
                "fragments": [],
                "text": "Computer recognition of English word senses"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756977"
                        ],
                        "name": "S. Small",
                        "slug": "S.-Small",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Small",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Small"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8902234"
                        ],
                        "name": "C. Rieger",
                        "slug": "C.-Rieger",
                        "structuredName": {
                            "firstName": "Chuck",
                            "lastName": "Rieger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rieger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60786034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b28ac42afda95193d37ee7d9480791a0dee0ab2e",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Parsing-and-comprehending-with-word-experts-(a-and-Small-Rieger",
            "title": {
                "fragments": [],
                "text": "Parsing and comprehending with word experts (a theory and its realization)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61012010,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a923c9f89ed53b6e835b3807c0c1bd8d532687b",
            "isKey": false,
            "numCitedBy": 1037,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Interpolated-estimation-of-Markov-source-parameters-Jelinek",
            "title": {
                "fragments": [],
                "text": "Interpolated estimation of Markov source parameters from sparse data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145557251"
                        ],
                        "name": "Rada Mihalcea",
                        "slug": "Rada-Mihalcea",
                        "structuredName": {
                            "firstName": "Rada",
                            "lastName": "Mihalcea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rada Mihalcea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40497400"
                        ],
                        "name": "D. Moldovan",
                        "slug": "D.-Moldovan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Moldovan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Moldovan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60893349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9462ed90e4480058d5b15e6bceb7b3cc3d13410b",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-generation-of-a-coarse-grained-WordNet-Mihalcea-Moldovan",
            "title": {
                "fragments": [],
                "text": "Automatic generation of a coarse grained WordNet"
            },
            "venue": {
                "fragments": [],
                "text": "HTL 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60804212,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "539036ab9e8f038c8a948596e77cc0dfcfa91fb3",
            "isKey": false,
            "numCitedBy": 1785,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-inequality-and-associated-maximization-technique-Baum",
            "title": {
                "fragments": [],
                "text": "An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912454"
                        ],
                        "name": "C. Fillmore",
                        "slug": "C.-Fillmore",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fillmore",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fillmore"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60712156,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "4165982754f451cc4c9b1e48505384546a2f3e36",
            "isKey": false,
            "numCitedBy": 1296,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Frames-and-the-semantics-of-understanding-Fillmore",
            "title": {
                "fragments": [],
                "text": "Frames and the semantics of understanding"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61113802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "939d409a615d4b88c0a84e1f9b99ed67a9053208",
            "isKey": false,
            "numCitedBy": 3147,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-SMART-Retrieval-System\u2014Experiments-in-Automatic-Salton",
            "title": {
                "fragments": [],
                "text": "The SMART Retrieval System\u2014Experiments in Automatic Document Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60951181,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a39359509c845457a193531d65ed0c790a03d52a",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithm-schemata-and-data-structures-in-syntactic-Kay",
            "title": {
                "fragments": [],
                "text": "Algorithm schemata and data structures in syntactic processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69334380"
                        ],
                        "name": "J. M. Kittross",
                        "slug": "J.-M.-Kittross",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Kittross",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Kittross"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59962008,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "30a3177646528a00f19d716a1a03946e3502fc9d",
            "isKey": false,
            "numCitedBy": 4075,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-measurement-of-meaning-Kittross",
            "title": {
                "fragments": [],
                "text": "The measurement of meaning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406078254"
                        ],
                        "name": "A. Phillips",
                        "slug": "A.-Phillips",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Phillips"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59758530,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "d5b2e2193db7fca06539d78d7aea4257df7f042b",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Question-Answering-Routine-Phillips",
            "title": {
                "fragments": [],
                "text": "A Question-Answering Routine"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1960
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3226331"
                        ],
                        "name": "C. Leacock",
                        "slug": "C.-Leacock",
                        "structuredName": {
                            "firstName": "Claudia",
                            "lastName": "Leacock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leacock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736799"
                        ],
                        "name": "M. Chodorow",
                        "slug": "M.-Chodorow",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Chodorow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chodorow"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59721988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54cd5ea7f987a23d663605640113859207490400",
            "isKey": false,
            "numCitedBy": 1053,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Combining-local-context-and-wordnet-similarity-for-Leacock-Chodorow",
            "title": {
                "fragments": [],
                "text": "Combining local context and wordnet similarity for word sense identification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714374"
                        ],
                        "name": "A. Joshi",
                        "slug": "A.-Joshi",
                        "structuredName": {
                            "firstName": "Aravind",
                            "lastName": "Joshi",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Joshi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58511817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a3a0d9c2f21f675f24e52e6e4f8cc5ee3522e54",
            "isKey": false,
            "numCitedBy": 453,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Natural-language-parsing:-Tree-adjoining-grammars:-Joshi",
            "title": {
                "fragments": [],
                "text": "Natural language parsing: Tree adjoining grammars: How much context-sensitivity is required to provide reasonable structural descriptions?"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87745558"
                        ],
                        "name": "P. Jaccard",
                        "slug": "P.-Jaccard",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Jaccard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jaccard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 85574559,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "5429bd2e98880ad677d2105efccd28549b910281",
            "isKey": false,
            "numCitedBy": 3104,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-DISTRIBUTION-OF-THE-FLORA-IN-THE-ALPINE-ZONE.1-Jaccard",
            "title": {
                "fragments": [],
                "text": "THE DISTRIBUTION OF THE FLORA IN THE ALPINE ZONE.1"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1912
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52122972"
                        ],
                        "name": "A. Glennie",
                        "slug": "A.-Glennie",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Glennie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Glennie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 54121965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37f0586951e55a31a6c9e1d93833fc8d036f3340",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ON-THE-SYNTAX-MACHINE-AND-THE-CONSTRUCTION-OF-A-Glennie",
            "title": {
                "fragments": [],
                "text": "ON THE SYNTAX MACHINE AND THE CONSTRUCTION OF A UNIVERSAL COMPILER"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1960
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123729051"
                        ],
                        "name": "L. M. M.-T.",
                        "slug": "L.-M.-M.-T.",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "M.-T.",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. M. M.-T."
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4036480,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f1f4386524be3ed96caaf05f661aacb94db1e566",
            "isKey": false,
            "numCitedBy": 5289,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theory-of-Probability-M.-T.",
            "title": {
                "fragments": [],
                "text": "Theory of Probability"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1929
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145148360"
                        ],
                        "name": "L. Hirschman",
                        "slug": "L.-Hirschman",
                        "structuredName": {
                            "firstName": "Lynette",
                            "lastName": "Hirschman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hirschman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145211865"
                        ],
                        "name": "Christine Pao",
                        "slug": "Christine-Pao",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Pao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christine Pao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30673362,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "966e3db3e6286339b2ac339108d4135e8cfb23db",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-cost-of-errors-in-a-spoken-language-system-Hirschman-Pao",
            "title": {
                "fragments": [],
                "text": "The cost of errors in a spoken language system"
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748407"
                        ],
                        "name": "J. Bellegarda",
                        "slug": "J.-Bellegarda",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Bellegarda",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bellegarda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12976399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2928de5400a920a6a29af41821c680cef5d35f91",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-latent-semantic-analysis-framework-for-large-Span-Bellegarda",
            "title": {
                "fragments": [],
                "text": "A latent semantic analysis framework for large-Span language modeling"
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "65971371"
                        ],
                        "name": "Y. Bar-Hillel",
                        "slug": "Y.-Bar-Hillel",
                        "structuredName": {
                            "firstName": "Yehoshua",
                            "lastName": "Bar-Hillel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Bar-Hillel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 147237352,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "cb75609c5e2a558e63880d12082067653f8c7dac",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Quasi-Arithmetical-Notation-for-Syntactic-Bar-Hillel",
            "title": {
                "fragments": [],
                "text": "A Quasi-Arithmetical Notation for Syntactic Description"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1953
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51981856"
                        ],
                        "name": "M. Masterman",
                        "slug": "M.-Masterman",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Masterman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Masterman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 21101681,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3c14fe0366b8045a3acba9bfd2396f0f99dc853",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-thesaurus-in-syntax-and-semantics-Masterman",
            "title": {
                "fragments": [],
                "text": "The thesaurus in syntax and semantics"
            },
            "venue": {
                "fragments": [],
                "text": "Mech. Transl. Comput. Linguistics"
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403310"
                        ],
                        "name": "R. Schank",
                        "slug": "R.-Schank",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Schank",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1948269"
                        ],
                        "name": "R. Abelson",
                        "slug": "R.-Abelson",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Abelson",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Abelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18113275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70bf67dd1c9052e8360d28bc73d9f3b559cc3e41",
            "isKey": false,
            "numCitedBy": 473,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a theoretical system intended to facilitate the use of knowledge In an understanding system. The notion of script is introduced to account for knowledge about mundane situations. A program, SAM, is capable of using scripts to understand. The notion of plans is introduced to account for general knowledge about novel situations."
            },
            "slug": "Scripts,-Plans-and-Knowledge-Schank-Abelson",
            "title": {
                "fragments": [],
                "text": "Scripts, Plans and Knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A theoretical system intended to facilitate the use of knowledge in an understanding system and the notion of script is introduced to account for knowledge about mundane situations."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3212973"
                        ],
                        "name": "Ann Bies",
                        "slug": "Ann-Bies",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Bies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ann Bies"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054785529"
                        ],
                        "name": "Mark Ferguson",
                        "slug": "Mark-Ferguson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Ferguson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Ferguson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065702818"
                        ],
                        "name": "Karen Katz",
                        "slug": "Karen-Katz",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Katz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Katz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33353168"
                        ],
                        "name": "R. MacIntyre",
                        "slug": "R.-MacIntyre",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "MacIntyre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. MacIntyre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59752771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b723d87aa184064f752ed70dcb47face44c1581d",
            "isKey": false,
            "numCitedBy": 380,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bracketing-Guidelines-For-Treebank-II-Style-Penn-Bies-Ferguson",
            "title": {
                "fragments": [],
                "text": "Bracketing Guidelines For Treebank II Style Penn Treebank Project"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50229247"
                        ],
                        "name": "B. Hubbell",
                        "slug": "B.-Hubbell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Hubbell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hubbell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60047034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05e2b18474f4f6abd6b722c946b41c1221557123",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-memory-limitations-in-natural-language-Hubbell",
            "title": {
                "fragments": [],
                "text": "On memory limitations in natural language processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chapter 18 \u2022 Lexicons for Sentiment and Affect Extraction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computational Linguistics: Special Issue on Word Sense Disambiguation"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics: Special Issue on Word Sense Disambiguation"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The correspondence fallacy in structural linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "Studies by Members of the English Department , Istanbul University ( 3 ) , reprinted in Readings in Linguistics II"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Noun classification from predicateargument structures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Es - timating upper and lower bounds on the performance of wordsense disambiguation programs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A sandwich proof of the ShannonMcMillanBreiman theorem"
            },
            "venue": {
                "fragments": [],
                "text": "The Annals of Probability"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Meaning of the Sentence in its Pragmatic Aspects"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Originally appeared in Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Originally appeared in Speech Recognition"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computing and the Humanities: Special Issue on SENSEVAL"
            },
            "venue": {
                "fragments": [],
                "text": "Computing and the Humanities: Special Issue on SENSEVAL"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "What is wrong with adding one?"
            },
            "venue": {
                "fragments": [],
                "text": "Corpus-Based Research into Language"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "-based N-gram Starting in the late 1990s, Chen and Goodman produced a highly influential series of papers with a comparison of different language models"
            },
            "venue": {
                "fragments": [],
                "text": "-based N-gram Starting in the late 1990s, Chen and Goodman produced a highly influential series of papers with a comparison of different language models"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The correspondence fallacy in structural linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "Studies by Members of the English Department reprinted in Readings in Linguistics II"
            },
            "year": 1952
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Affective computing. Tech. rep. 321, MIT Media Lab Perceputal Computing Technical Report"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "SemEval-15"
            },
            "venue": {
                "fragments": [],
                "text": "SemEval-15"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A latent semantic analysis framework for largespan language modeling"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum entropy partofspeech tagger"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An analysis of the AskMSR questionanswering system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Knowlege - free induction of morphology using latent semantic analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Indexing by latent semantics analysis"
            },
            "venue": {
                "fragments": [],
                "text": "JASIS"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum entropy approach to adaptive statistical language modeling"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Speech and Language"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer information retrieval using latent semantic structure: Us patent 4"
            },
            "venue": {
                "fragments": [],
                "text": "Computer information retrieval using latent semantic structure: Us patent 4"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The lunar sciences natural language information system: Final report"
            },
            "venue": {
                "fragments": [],
                "text": "The lunar sciences natural language information system: Final report"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and Historical Notes 21"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Syntax and the problem of multiple meaning"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Translation of Languages"
            },
            "year": 1955
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Important: 100% is impossible even for human annotators"
            },
            "venue": {
                "fragments": [],
                "text": "Important: 100% is impossible even for human annotators"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantic classes and syntactic ambigu"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the workshop on Human Language Technology"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comments on Joshi"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bootstrapping. In ACL-02"
            },
            "venue": {
                "fragments": [],
                "text": "Bootstrapping. In ACL-02"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "inter alia, for computational approaches to the representation of polysemy. Pustejovsky's theory of the generative lexicon"
            },
            "venue": {
                "fragments": [],
                "text": "inter alia, for computational approaches to the representation of polysemy. Pustejovsky's theory of the generative lexicon"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Similarity - based models of cooccurrence probabilities"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval. Butter- worths"
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval. Butter- worths"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A preferential , patternseeking , semantics for natural language inference"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The syntax and semantics of the proposed international algebraic language of the Zurich ACMGAMM Conference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "String Analysis of Sentence Structure. Mouton, The Hague"
            },
            "venue": {
                "fragments": [],
                "text": "String Analysis of Sentence Structure. Mouton, The Hague"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A general syntactic processor"
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Processing"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Noun homograph disambiguation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 7 th Conference of the University of Waterloo Centre for the New OED and Text Research"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "What is wrong with adding one ?"
            },
            "venue": {
                "fragments": [],
                "text": "Corpus - Based Research into Language"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A general syntactic processor"
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Processing"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Band II: Die Sprache, Zweiter Teil"
            },
            "venue": {
                "fragments": [],
                "text": "Band II: Die Sprache, Zweiter Teil"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "SRILM offers a wider range of options and types of discounting, while KenLM is optimized for speed and memory size, making it possible to build web-scale lan- Exercises 27"
            },
            "venue": {
                "fragments": [],
                "text": "SRILM offers a wider range of options and types of discounting, while KenLM is optimized for speed and memory size, making it possible to build web-scale lan- Exercises 27"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Similarity - based models of cooccurrence probabilities"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning classtoclass selectional preferences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Some principles of memory schemata Representation and Understanding"
            },
            "venue": {
                "fragments": [],
                "text": "Some principles of memory schemata Representation and Understanding"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "28 Chapter 4 @BULLET N-Grams"
            },
            "venue": {
                "fragments": [],
                "text": "28 Chapter 4 @BULLET N-Grams"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Similaritybased models of cooccurrence probabilities"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum entropy approach to natural language process"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The necessity of syntactic parsing for predicate argument recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Noun classification from predicateargument structures"
            },
            "venue": {
                "fragments": [],
                "text": "ACL-90"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Prologomena to a Theory of Language"
            },
            "venue": {
                "fragments": [],
                "text": "Prologomena to a Theory of Language"
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalized Phrase Structure Grammar From morpheme to utterance"
            },
            "venue": {
                "fragments": [],
                "text": "Language"
            },
            "year": 1946
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An overview of sequence comparison"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nouvelles recherches sur la distribution florale"
            },
            "venue": {
                "fragments": [],
                "text": "Bulletin de la Soci\u00e9t\u00e9 Vaudoise des Sciences Naturelles"
            },
            "year": 1908
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Syntactic Structures. Mouton, The Hague"
            },
            "venue": {
                "fragments": [],
                "text": "Syntactic Structures. Mouton, The Hague"
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Observations on context free parsing"
            },
            "venue": {
                "fragments": [],
                "text": "SMIL : Statistical Methods in Linguistics"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The lunar sciences natural language information system : Final report"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 143
                            }
                        ],
                        "text": "In one family, emotions are viewed as fixed atomic units, limited in number, and from which others are generated, often called basic emotions (Tomkins 1962, Plutchik 1962)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Affect, imagery, consciousness: Vol. I. The positive affects"
            },
            "venue": {
                "fragments": [],
                "text": "Affect, imagery, consciousness: Vol. I. The positive affects"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improved backingoff for Mgram language modeling"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimum branchings"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Research of the National Bureau of Standards B"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Syntax and the problem of multiple meaning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1955
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eval - uating Message Understanding systems : An analysis of the third Message Understanding Conference"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distributional structure The Structure of Language"
            },
            "venue": {
                "fragments": [],
                "text": "Papers in Structural and Transformational Linguistics, Reidel"
            },
            "year": 1954
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Getting the most out of transitionbased dependency parsing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Constituency and coordination in a combinatory grammar"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Building a userderived interface"
            },
            "venue": {
                "fragments": [],
                "text": "Communications of the ACM"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A proposal concerning english prepositions"
            },
            "venue": {
                "fragments": [],
                "text": "17 th annual Round Table . , Vol . 17 of Monograph Series on Language and Linguistics"
            },
            "year": 1966
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lectures on Government and Binding. Foris"
            },
            "venue": {
                "fragments": [],
                "text": "Lectures on Government and Binding. Foris"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tools for computer-aided corpus lexicography: The Hector project"
            },
            "venue": {
                "fragments": [],
                "text": "Acta Linguistica Hungarica"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Preference semantics The Formal Semantics of Natural Language"
            },
            "venue": {
                "fragments": [],
                "text": "Preference semantics The Formal Semantics of Natural Language"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Noun homograph disambiguation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 7th Conference of the University of Waterloo Centre for the New OED and Text Research"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Panda's Thumb. Penguin Group"
            },
            "venue": {
                "fragments": [],
                "text": "The Panda's Thumb. Penguin Group"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probability : deductive and inductive problems ( appendix to )"
            },
            "venue": {
                "fragments": [],
                "text": "Mind"
            },
            "year": 1932
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical decisiontree models for parsing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Formal properties of grammars"
            },
            "venue": {
                "fragments": [],
                "text": "Handbook of Mathematical Psychology"
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the shortest arborescence of a directed graph"
            },
            "venue": {
                "fragments": [],
                "text": "Science Sinica"
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A questionanswering routine"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1960
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tree adjoining grammars : How much contextsensitivity is required to provide reasonable structural descriptions ?"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contextual word similarity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Formal properties of grammars"
            },
            "venue": {
                "fragments": [],
                "text": "Handbook of Mathematical Psychology"
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Markov Chain for Weather 9/5/2013 Speech and Language Processing -Jurafsky and Martin 9/5/2013 Speech and Language Processing -Jurafsky and Martin"
            },
            "venue": {
                "fragments": [],
                "text": "Markov Chain for Weather 9/5/2013 Speech and Language Processing -Jurafsky and Martin 9/5/2013 Speech and Language Processing -Jurafsky and Martin"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The stringtostring correction problem"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Association for Computing Machinery"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Preference semantics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eval - uating Message Understanding systems : An analysis of the third Message Understanding Conference"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "What \u2019 s in a frame ? Surface evidence for underlying expectations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Observations on context free parsing. SMIL: Statistical Methods in Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "Observations on context free parsing. SMIL: Statistical Methods in Linguistics"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Preference semantics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum entropy approach to natural language process"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and Historical Notes"
            },
            "venue": {
                "fragments": [],
                "text": "and Historical Notes"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 1
                            }
                        ],
                        "text": "(Miller and Charles 1991, Justeson and Katz 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contextual correlates of semantics similarity"
            },
            "venue": {
                "fragments": [],
                "text": "Language and Cognitive Processes"
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 19,
            "methodology": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 356,
        "totalPages": 36
    },
    "page_url": "https://www.semanticscholar.org/paper/Speech-and-Language-Processing-Jurafsky-Martin/894149cb66e8af4a20c82840ea3f774888644fa6?sort=total-citations"
}