{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8551365"
                        ],
                        "name": "N. Kushmerick",
                        "slug": "N.-Kushmerick",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Kushmerick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kushmerick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913159"
                        ],
                        "name": "Robert B. Doorenbos",
                        "slug": "Robert-B.-Doorenbos",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Doorenbos",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert B. Doorenbos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5119155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9e7402ad740b73cc0bb64178f86df3478c3aaf5",
            "isKey": false,
            "numCitedBy": 1283,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Many Internet information resources present relational data|telephone directories, product catalogs, etc. Because these sites are formatted for people, mechanically extracting their content is di cult. Systems using such resources typically use hand-coded wrappers, procedures to extract data from information resources. We introduce wrapper induction, a method for automatically constructing wrappers, and identify hlrt, a wrapper class that is e ciently learnable, yet expressive enough to handle 48% of a recently surveyed sample of Internet resources. We use PAC analysis to bound the problem's sample complexity, and show that the system degrades gracefully with imperfect labeling knowledge."
            },
            "slug": "Wrapper-Induction-for-Information-Extraction-Kushmerick-Weld",
            "title": {
                "fragments": [],
                "text": "Wrapper Induction for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work introduces wrapper induction, a method for automatically constructing wrappers, and identifies hlrt, a wrapper class that is e ciently learnable, yet expressive enough to handle 48% of a recently surveyed sample of Internet resources."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144557047"
                        ],
                        "name": "M. Craven",
                        "slug": "M.-Craven",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Craven",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Craven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2922396"
                        ],
                        "name": "Dan DiPasquo",
                        "slug": "Dan-DiPasquo",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "DiPasquo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan DiPasquo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682522"
                        ],
                        "name": "Se\u00e1n Slattery",
                        "slug": "Se\u00e1n-Slattery",
                        "structuredName": {
                            "firstName": "Se\u00e1n",
                            "lastName": "Slattery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Se\u00e1n Slattery"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5303928,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10dfa97d41f17755257f3d653f4808a30fd7481b",
            "isKey": false,
            "numCitedBy": 526,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-to-construct-knowledge-bases-from-the-Wide-Craven-DiPasquo",
            "title": {
                "fragments": [],
                "text": "Learning to construct knowledge bases from the World Wide Web"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144557047"
                        ],
                        "name": "M. Craven",
                        "slug": "M.-Craven",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Craven",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Craven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2922396"
                        ],
                        "name": "Dan DiPasquo",
                        "slug": "Dan-DiPasquo",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "DiPasquo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan DiPasquo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682522"
                        ],
                        "name": "Se\u00e1n Slattery",
                        "slug": "Se\u00e1n-Slattery",
                        "structuredName": {
                            "firstName": "Se\u00e1n",
                            "lastName": "Slattery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Se\u00e1n Slattery"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2312137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8446830f3c05b97c4d12a0751c022d1ae6a5115b",
            "isKey": false,
            "numCitedBy": 800,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "The World Wide Web is a vast source of information accessible to computers, but understandable only to humans. The goal of the research described here is to automatically create a computer understandable world wide knowledge base whose content mirrors that of the World Wide Web. Such a knowledge base would enable much more effective retrieval of Web information, and promote new uses of the Web to support knowledge-based inference and problem solving. Our approach is to develop a trainable information extraction system that takes two inputs: an ontology defining the classes and relations of interest, and a set of training data consisting of labeled regions of hypertext representing instances of these classes and relations. Given these inputs, the system learns to extract information from other pages and hyperlinks on the Web. This paper describes our general approach, several machine learning algorithms for this task, and promising initial results with a prototype system."
            },
            "slug": "Learning-to-Extract-Symbolic-Knowledge-from-the-Web-Craven-DiPasquo",
            "title": {
                "fragments": [],
                "text": "Learning to Extract Symbolic Knowledge from the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The goal of the research described here is to automatically create a computer understandable world wide knowledge base whose content mirrors that of the World Wide Web, and several machine learning algorithms for this task are described."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983124"
                        ],
                        "name": "Cody C. T. Kwok",
                        "slug": "Cody-C.-T.-Kwok",
                        "structuredName": {
                            "firstName": "Cody",
                            "lastName": "Kwok",
                            "middleNames": [
                                "C.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cody C. T. Kwok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This notion of \u201credundancy-based extraction\u201d was introduced in Mulder [17] and further articulated in AskMSR [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Whereas search engines locate relevant documents in response to a query, web-based Question Answering (QA) systems such as Mulder [17], AskMSR [2], Radev\u2019s work [22], and others locate potentially relevant answers to individual questions but are not designed to compile large bodies of knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52096276,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7bdb08efd640311ad18466a80498c78267f886ca",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The wealth of information on the web makes it an attractive resource for seeking quick answers to simple, factual questions such as \\who was the rst American in space?\" or \\what is the second tallest mountain in the world?\" Yet today's most advanced web search services (e.g., Google and AskJeeves) make it surprisingly tedious to locate answers to such questions. In this paper, we extend question-answering techniques, rst studied in the information retrieval literature, to the web and experimentally evaluate their performance. First we introduce Mulder, which we believe to be the rst general-purpose, fully-automated questionanswering system available on the web. Second, we describe Mulder's architecture, which relies on multiple search-engine queries, natural-language parsing, and a novel voting procedure to yield reliable answers coupled with high recall. Finally, we compare Mulder's performance to that of Google and AskJeeves on questions drawn from the TREC-8 question track. We nd that Mulder's recall is more than a factor of three higher than that of AskJeeves. In addition, we nd that Google requires 6.6 times as much user e ort to achieve the same level of recall as Mulder."
            },
            "slug": "Scaling-question-answering-to-the-Web-Kwok-Etzioni",
            "title": {
                "fragments": [],
                "text": "Scaling question answering to the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Mulder is introduced, which is believed to be the first general-purpose, fully-automated questionanswering system available on the web, and its architecture is described, which relies on multiple search-engine queries, natural-language parsing, and a novel voting procedure to yield reliable answers coupled with high recall."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685296"
                        ],
                        "name": "Eugene Agichtein",
                        "slug": "Eugene-Agichtein",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Agichtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Agichtein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684012"
                        ],
                        "name": "L. Gravano",
                        "slug": "L.-Gravano",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Gravano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gravano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7579604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cee045e890270abae65455667b292db355d53728",
            "isKey": false,
            "numCitedBy": 1365,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Text documents often contain valuable structured data that is hidden Yin regular English sentences. This data is best exploited infavailable as arelational table that we could use for answering precise queries or running data mining tasks.We explore a technique for extracting such tables from document collections that requires only a handful of training examples from users. These examples are used to generate extraction patterns, that in turn result in new tuples being extracted from the document collection.We build on this idea and present our Snowball system. Snowball introduces novel strategies for generating patterns and extracting tuples from plain-text documents.At each iteration of the extraction process, Snowball evaluates the quality of these patterns and tuples without human intervention,and keeps only the most reliable ones for the next iteration. In this paper we also develop a scalable evaluation methodology and metrics for our task, and present a thorough experimental evaluation of Snowball and comparable techniques over a collection of more than 300,000 newspaper documents."
            },
            "slug": "Snowball:-extracting-relations-from-large-Agichtein-Gravano",
            "title": {
                "fragments": [],
                "text": "Snowball: extracting relations from large plain-text collections"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper develops a scalable evaluation methodology and metrics for the task, and presents a thorough experimental evaluation of Snowball and comparable techniques over a collection of more than 300,000 newspaper documents."
            },
            "venue": {
                "fragments": [],
                "text": "DL '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983124"
                        ],
                        "name": "Cody C. T. Kwok",
                        "slug": "Cody-C.-T.-Kwok",
                        "structuredName": {
                            "firstName": "Cody",
                            "lastName": "Kwok",
                            "middleNames": [
                                "C.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cody C. T. Kwok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5456456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "016e9cc85c658c6a69710b4c617609ad2a5d3a74",
            "isKey": false,
            "numCitedBy": 359,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "The wealth of information on the web makes it an attractive resource for seeking quick answers to simple, factual questions such as &quote;who was the first American in space?&quote; or &quote;what is the second tallest mountain in the world?&quote; Yet today's most advanced web search services (e.g., Google and AskJeeves) make it surprisingly tedious to locate answers to such questions. In this paper, we extend question-answering techniques, first studied in the information retrieval literature, to the web and experimentally evaluate their performance.First we introduce Mulder, which we believe to be the first general-purpose, fully-automated question-answering system available on the web. Second, we describe Mulder's architecture, which relies on multiple search-engine queries, natural-language parsing, and a novel voting procedure to yield reliable answers coupled with high recall. Finally, we compare Mulder's performance to that of Google and AskJeeves on questions drawn from the TREC-8 question answering track. We find that Mulder's recall is more than a factor of three higher than that of AskJeeves. In addition, we find that Google requires 6.6 times as much user effort to achieve the same level of recall as Mulder."
            },
            "slug": "Scaling-question-answering-to-the-web-Kwok-Etzioni",
            "title": {
                "fragments": [],
                "text": "Scaling question answering to the web"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Mulder is introduced, which is believed to be the first general-purpose, fully-automated question-answering system available on the web, and its architecture is described, which relies on multiple search-engine queries, natural-language parsing, and a novel voting procedure to yield reliable answers coupled with high recall."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35707712"
                        ],
                        "name": "Steve Dill",
                        "slug": "Steve-Dill",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Dill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve Dill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2098146"
                        ],
                        "name": "Nadav Eiron",
                        "slug": "Nadav-Eiron",
                        "structuredName": {
                            "firstName": "Nadav",
                            "lastName": "Eiron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadav Eiron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060104135"
                        ],
                        "name": "David Gibson",
                        "slug": "David-Gibson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Gibson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Gibson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2890298"
                        ],
                        "name": "D. Gruhl",
                        "slug": "D.-Gruhl",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gruhl",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gruhl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145615125"
                        ],
                        "name": "R. Guha",
                        "slug": "R.-Guha",
                        "structuredName": {
                            "firstName": "Ramanathan",
                            "lastName": "Guha",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Guha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779853"
                        ],
                        "name": "A. Jhingran",
                        "slug": "A.-Jhingran",
                        "structuredName": {
                            "firstName": "Anant",
                            "lastName": "Jhingran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jhingran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145941159"
                        ],
                        "name": "S. Rajagopalan",
                        "slug": "S.-Rajagopalan",
                        "structuredName": {
                            "firstName": "Sridhar",
                            "lastName": "Rajagopalan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rajagopalan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49365095"
                        ],
                        "name": "A. Tomkins",
                        "slug": "A.-Tomkins",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Tomkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tomkins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717630"
                        ],
                        "name": "J. Tomlin",
                        "slug": "J.-Tomlin",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tomlin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tomlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118829"
                        ],
                        "name": "J. Zien",
                        "slug": "J.-Zien",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Zien",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zien"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17741338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f60ff1e240be1b1e74c164d0ef4fb2d67f0cbdc3",
            "isKey": false,
            "numCitedBy": 582,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes Seeker, a platform for large-scale text analytics, and SemTag, an application written on the platform to perform automated semantic tagging of large corpora. We apply SemTag to a collection of approximately 264 million web pages, and generate approximately 434 million automatically disambiguated semantic tags, published to the web as a label bureau providing metadata regarding the 434 million annotations. To our knowledge, this is the largest scale semantic tagging effort to date.We describe the Seeker platform, discuss the architecture of the SemTag application, describe a new disambiguation algorithm specialized to support ontological disambiguation of large-scale data, evaluate the algorithm, and present our final results with information about acquiring and making use of the semantic tags. We argue that automated large scale semantic tagging of ambiguous content can bootstrap and accelerate the creation of the semantic web."
            },
            "slug": "SemTag-and-seeker:-bootstrapping-the-semantic-web-Dill-Eiron",
            "title": {
                "fragments": [],
                "text": "SemTag and seeker: bootstrapping the semantic web via automated semantic annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is argued that automated large scale semantic tagging of ambiguous content can bootstrap and accelerate the creation of the semantic web."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215251"
                        ],
                        "name": "Dragomir R. Radev",
                        "slug": "Dragomir-R.-Radev",
                        "structuredName": {
                            "firstName": "Dragomir",
                            "lastName": "Radev",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dragomir R. Radev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144464225"
                        ],
                        "name": "Hong Qi",
                        "slug": "Hong-Qi",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Qi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Qi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1849664"
                        ],
                        "name": "Zhiping Zheng",
                        "slug": "Zhiping-Zheng",
                        "structuredName": {
                            "firstName": "Zhiping",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiping Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403868620"
                        ],
                        "name": "Sasha Blair-Goldensohn",
                        "slug": "Sasha-Blair-Goldensohn",
                        "structuredName": {
                            "firstName": "Sasha",
                            "lastName": "Blair-Goldensohn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sasha Blair-Goldensohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51305348"
                        ],
                        "name": "Zhu Zhang",
                        "slug": "Zhu-Zhang",
                        "structuredName": {
                            "firstName": "Zhu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145631869"
                        ],
                        "name": "Weiguo Fan",
                        "slug": "Weiguo-Fan",
                        "structuredName": {
                            "firstName": "Weiguo",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weiguo Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30210546"
                        ],
                        "name": "J. Prager",
                        "slug": "J.-Prager",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Prager",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Prager"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Whereas search engines locate relevant documents in response to a query, web-based Question Answering (QA) systems such as Mulder [17], AskMSR [2], Radev\u2019s work [22], and others locate potentially relevant answers to individual questions but are not designed to compile large bodies of knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9624007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44e4081054990b613347d2d607ed218deee40c85",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "The web is now becoming one of the largest information and knowledge repositories. Many large scale search engines (Google, Fast, Northern Light, etc.) have emerged to help users find information. In this paper, we study how we can effectively use these existing search engines to mine the Web and discover the \"correct\" answers to factual natural language questions.We propose a probabilistic algorithm called QASM (Question Answering using Statistical Models) that learns the best query paraphrase of a natural language question. We validate our approach for both local and web search engines using questions from the TREC evaluation. We also show how this algorithm can be combined with another algorithm (AnSel) to produce precise answers to natural language questions."
            },
            "slug": "Mining-the-web-for-answers-to-natural-language-Radev-Qi",
            "title": {
                "fragments": [],
                "text": "Mining the web for answers to natural language questions"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A probabilistic algorithm called QASM (Question Answering using Statistical Models) that learns the best query paraphrase of a natural language question is proposed that can be combined with another algorithm to produce precise answers to natural language questions."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064774858"
                        ],
                        "name": "Deepak Ravichandran",
                        "slug": "Deepak-Ravichandran",
                        "structuredName": {
                            "firstName": "Deepak",
                            "lastName": "Ravichandran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deepak Ravichandran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 226541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbd0e0ad4e06902b10b6a157b9db92df577720f1",
            "isKey": false,
            "numCitedBy": 933,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we explore the power of surface text patterns for open-domain question answering systems. In order to obtain an optimal set of patterns, we have developed a method for learning such patterns automatically. A tagged corpus is built from the Internet in a bootstrapping process by providing a few hand-crafted examples of each question type to Altavista. Patterns are then automatically extracted from the returned documents and standardized. We calculate the precision of each pattern, and the average precision for each question type. These patterns are then applied to find answers to new questions. Using the TREC-10 question set, we report results for two cases: answers determined from the TREC-10 corpus and from the web."
            },
            "slug": "Learning-surface-text-patterns-for-a-Question-Ravichandran-Hovy",
            "title": {
                "fragments": [],
                "text": "Learning surface text patterns for a Question Answering System"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper has developed a method for learning an optimal set of surface text patterns automatically from a tagged corpus, and calculates the precision of each pattern, and the average precision for each question type."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786259"
                        ],
                        "name": "S. Brin",
                        "slug": "S.-Brin",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Brin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6075461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92575a3c554353a27b2c0263ad7f8487d9102301",
            "isKey": false,
            "numCitedBy": 1235,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The World Wide Web is a vast resource for information. At the same time it is extremely distributed. A particular type of data such as restaurant lists may be scattered across thousands of independent information sources in many different formats. In this paper, we consider the problem of extracting a relation for such a data type from all of these sources automatically. We present a technique which exploits the duality between sets of patterns and relations to grow the target relation starting from a small sample. To test our technique we use it to extract a relation of (author,title) pairs from the World Wide Web."
            },
            "slug": "Extracting-Patterns-and-Relations-from-the-World-Brin",
            "title": {
                "fragments": [],
                "text": "Extracting Patterns and Relations from the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a technique which exploits the duality between sets of patterns and relations to grow the target relation starting from a small sample and uses it to extract a relation of (author,title) pairs from the World Wide Web."
            },
            "venue": {
                "fragments": [],
                "text": "WebDB"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716902"
                        ],
                        "name": "Marti A. Hearst",
                        "slug": "Marti-A.-Hearst",
                        "structuredName": {
                            "firstName": "Marti",
                            "lastName": "Hearst",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marti A. Hearst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15763200,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "dbfd191afbbc8317577cbc44afe7156df546e143",
            "isKey": false,
            "numCitedBy": 3648,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for the automatic acquisition of the hyponymy lexical relation from unrestricted text. Two goals motivate the approach: (i) avoidance of the need for pre-encoded knowledge and (ii) applicability across a wide range of text. We identify a set of lexico-syntactic patterns that are easily recognizable, that occur frequently and across text genre boundaries, and that indisputably indicate the lexical relation of interest. We describe a method for discovering these patterns and suggest that other lexical relations will also be acquirable in this way. A subset of the acquisition algorithm is implemented and the results are used to augment and critique the structure of a large hand-built thesaurus. Extensions and applications to areas such as information retrieval are suggested."
            },
            "slug": "Automatic-Acquisition-of-Hyponyms-from-Large-Text-Hearst",
            "title": {
                "fragments": [],
                "text": "Automatic Acquisition of Hyponyms from Large Text Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A set of lexico-syntactic patterns that are easily recognizable, that occur frequently and across text genre boundaries, and that indisputably indicate the lexical relation of interest are identified."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2339397"
                        ],
                        "name": "Michele Banko",
                        "slug": "Michele-Banko",
                        "structuredName": {
                            "firstName": "Michele",
                            "lastName": "Banko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michele Banko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113773659"
                        ],
                        "name": "Eric Brili",
                        "slug": "Eric-Brili",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brili",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Brili"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145580839"
                        ],
                        "name": "Jimmy J. Lin",
                        "slug": "Jimmy-J.-Lin",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Lin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy J. Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8450456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e52521e4a8af2df84b2141dd4c326b26e7204f00",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The design of the AskMSR question answering system is motivated by recent observations in natural language processing that for many applications, significant improvements in accuracy can be attained simply by increasing the amount of data used for learning (e.g., Banko & Brill, 2001). By taking advantage of the vast amount of online text available via the worldwide web, rather than relying on an approach that depends heavily on natural language intensive techniques, we developed a simple but effective question answering system. Many groups working on question answering use a variety of linguistic resources \u2013 part-of-speech tagging, parsing, named entiry extraction, WordNet, etc. We chose instead to focus on the tremendous resource that the web provides simply as a gigantic data repository. The web, which is home to billions of pages of electronic text, is orders of magnitude larger than the TREC QA document collection, which consists of fewer than 1 million documents."
            },
            "slug": "AskMSR:-Question-Answering-Using-the-Worldwide-Web-Banko-Brili",
            "title": {
                "fragments": [],
                "text": "AskMSR: Question Answering Using the Worldwide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "By taking advantage of the vast amount of online text available via the worldwide web, rather than relying on an approach that depends heavily on natural language intensive techniques, this work has developed a simple but effective question answering system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144494993"
                        ],
                        "name": "R. Jones",
                        "slug": "R.-Jones",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1053009,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41e936981f5a2d55bfec0143e9a15e23ad96436b",
            "isKey": false,
            "numCitedBy": 890,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction systems usually require two dictionaries: a semantic lexicon and a dictionary of extraction patterns for the domain. We present a multilevel bootstrapping algorithm that generates both the semantic lexicon and extraction patterns simultaneously. As input, our technique requires only unannotated training texts and a handful of seed words for a category. We use a mutual bootstrapping technique to alternately select the best extraction pattern for the category and bootstrap its extractions into the semantic lexicon, which is the basis for selecting the next extraction pattern. To make this approach more robust, we add a second level of bootstrapping (metabootstrapping) that retains only the most reliable lexicon entries produced by mutual bootstrapping and then restarts the process. We evaluated this multilevel bootstrapping technique on a collection of corporate web pages and a corpus of terrorism news articles. The algorithm produced high-quality dictionaries for several semantic categories."
            },
            "slug": "Learning-Dictionaries-for-Information-Extraction-by-Riloff-Jones",
            "title": {
                "fragments": [],
                "text": "Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A multilevel bootstrapping algorithm is presented that generates both the semantic lexicon and extraction patterns simultaneously simultaneously and produces high-quality dictionaries for several semantic categories."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689647"
                        ],
                        "name": "Peter D. Turney",
                        "slug": "Peter-D.-Turney",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Turney",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter D. Turney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5509836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e517e1645708e7b050787bb4734002ea194a1958",
            "isKey": false,
            "numCitedBy": 1474,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a simple unsupervised learning algorithm for recognizing synonyms, based on statistical data acquired by querying a Web search engine. The algorithm, called PMI-IR, uses Pointwise Mutual Information (PMI) and Information Retrieval (IR) to measure the similarity of pairs of words. PMI-IR is empirically evaluated using 80 synonym test questions from the Test of English as a Foreign Language (TOEFL) and 50 synonym test questions from a collection of tests for students of English as a Second Language (ESL). On both tests, the algorithm obtains a score of 74%. PMI-IR is contrasted with Latent Semantic Analysis (LSA), which achieves a score of 64% on the same 80 TOEFL questions. The paper discusses potential applications of the new unsupervised learning algorithm and some implications of the results for LSA and LSI (Latent Semantic Indexing)."
            },
            "slug": "Mining-the-Web-for-Synonyms:-PMI-IR-versus-LSA-on-Turney",
            "title": {
                "fragments": [],
                "text": "Mining the Web for Synonyms: PMI-IR versus LSA on TOEFL"
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145262164"
                        ],
                        "name": "David Fisher",
                        "slug": "David-Fisher",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fisher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51080653"
                        ],
                        "name": "J. Aseltine",
                        "slug": "J.-Aseltine",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Aseltine",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aseltine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925215"
                        ],
                        "name": "W. Lehnert",
                        "slug": "W.-Lehnert",
                        "structuredName": {
                            "firstName": "Wendy",
                            "lastName": "Lehnert",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lehnert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9168228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8245f6099f547008522ebbe6fb813d8132085746",
            "isKey": false,
            "numCitedBy": 409,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the central knowledge sources of an information extraction (IE) system IS a dictionary of linguistic patterns that can be used to identify references to relevant information in a text Automatic creation of conceptual dictionaries is important for portability and scalability of an IE system This paper describes CRYSTAL, a system which automatically induces a dictionary of \"concept-node definitions\" sufficient to identify relevant information from a training corpus Each of these concept-node definitions is generalized as far as possible without producing errors, so that a minimum number of dictionary entries cover the positive training instances Because it tests the accuracy of each proposed definition, CRYSTAL can often surpass human intuitions in creating reliable extraction rules."
            },
            "slug": "CRYSTAL:-Inducing-a-Conceptual-Dictionary-Soderland-Fisher",
            "title": {
                "fragments": [],
                "text": "CRYSTAL: Inducing a Conceptual Dictionary"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "CRYSTAL is described, a system which automatically induces a dictionary of \"concept-node definitions\" sufficient to identify relevant information from a training corpus that can often surpass human intuitions in creating reliable extraction rules."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 167
                            }
                        ],
                        "text": "Much of the previous work on Information Extraction (IE) has focused on the use of supervised learning techniques such as hidden Markov Models [12, 25], rule learning [27, 26], or Conditional Random Fields [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8359747,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22fb3b3b2bdf768dd435eedfc5ef5155d3e56b1a",
            "isKey": false,
            "numCitedBy": 1071,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "A wealth of on-line text information can be made available to automatic processing by information extraction (IE) systems. Each IE application needs a separate set of rules tuned to the domain and writing style. WHISK helps to overcome this knowledge-engineering bottleneck by learning text extraction rules automatically.WHISK is designed to handle text styles ranging from highly structured to free text, including text that is neither rigidly formatted nor composed of grammatical sentences. Such semi-structured text has largely been beyond the scope of previous systems. When used in conjunction with a syntactic analyzer and semantic tagging, WHISK can also handle extraction from free text such as news stories."
            },
            "slug": "Learning-Information-Extraction-Rules-for-and-Free-Soderland",
            "title": {
                "fragments": [],
                "text": "Learning Information Extraction Rules for Semi-Structured and Free Text"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "WHISK is designed to handle text styles ranging from highly structured to free text, including text that is neither rigidly formatted nor composed of grammatical sentences, and can also handle extraction from free text such as news stories."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712352"
                        ],
                        "name": "B. Magnini",
                        "slug": "B.-Magnini",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Magnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Magnini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2138026"
                        ],
                        "name": "Matteo Negri",
                        "slug": "Matteo-Negri",
                        "structuredName": {
                            "firstName": "Matteo",
                            "lastName": "Negri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matteo Negri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145123169"
                        ],
                        "name": "R. Prevete",
                        "slug": "R.-Prevete",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Prevete",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Prevete"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2185304"
                        ],
                        "name": "Hristo Tanev",
                        "slug": "Hristo-Tanev",
                        "structuredName": {
                            "firstName": "Hristo",
                            "lastName": "Tanev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hristo Tanev"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7711544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d151cb226fd4235b04468fc620419cd0f48fbcb",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Answer Validation is an emerging topic in Question Answering, where open domain systems are often required to rank huge amounts of candidate answers. We present a novel approach to answer validation based on the intuition that the amount of implicit knowledge which connects an answer to a question can be quantitatively estimated by exploiting the redundancy of Web information. Experiments carried out on the TREC-2001 judged-answer collection show that the approach achieves a high level of performance (i.e. 81% success rate). The simplicity and the efficiency of this approach make it suitable to be used as a module in Question Answering systems."
            },
            "slug": "Is-It-the-Right-Answer-Exploiting-Web-Redundancy-Magnini-Negri",
            "title": {
                "fragments": [],
                "text": "Is It the Right Answer? Exploiting Web Redundancy for Answer Validation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents a novel approach to answer validation based on the intuition that the amount of implicit knowledge which connects an answer to a question can be quantitatively estimated by exploiting the redundancy of Web information."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746656"
                        ],
                        "name": "E. Voorhees",
                        "slug": "E.-Voorhees",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Voorhees",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Voorhees"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215762892,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "0d8bf6be792deb9b7e499b361a8332f0dce68089",
            "isKey": false,
            "numCitedBy": 536,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The TREC question answering track is an effort to bring the benefits of large-scale evaluation to bear on the question answering problem. The track contained two tasks in TREC 2002, the main task and the list task. Both tasks required that the answer strings returned by the systems consist of nothing more or less than an answer in contrast to the text snippets containing an answer allowed in previous years. A new evaluation measure in the main task, the confidence-weighted score, tested a system\u2019s ability to recognize when it has found a correct answer. The goal of the question answering (QA) track is to foster research on systems that retrieve answers rather than documents in response to a question, with particular emphasis on systems that can function in unrestricted domains. Now in its fourth year, the tasks in the track have evolved over the years to increase the realism of the task and to focus research on particular aspects of the problem deemed important to improving the state-of-the-art. All of the tasks have involved finding answers to closed-class questions within a large corpus of news text. This paper provides an overview of the TREC 2002 QA track. This year\u2019s track contained two tasks, the main task and the list task. Both tasks were also run in TREC 2001, but systems were required to return exact answers this year. That is, the text string returned by the system in response to a question was required to consist of a complete answer and nothing else, in contrast to earlier years where systems could return text strings that simply contained an answer. To make the paper self-contained, the first section recaps the tasks and evaluation procedures used in the first three tracks. The following sections then describe this year\u2019s tasks. 1 Evolution of the TREC QA Track The task in the first two QA tracks (TRECs 8 and 9) was the same. For each question in the question set, systems retrieved a ranked list of up to five text snippets that contained an answer to the question plus a document that supported the answer. The collection of documents from which the support was drawn was a large set of newswire and newspaper articles. The questions were restricted to factoid questions such as In what year did Joe DiMaggio compile his 56game hitting streak? and Name a film in which Jude Law acted. Each question was guaranteed to have at least one document in the collection that explicitly answered it. The maximum length of the text snippets was either 50 or 250 bytes, depending on the run type. Human assessors read each string and decided whether the string actually did contain an answer to the question in the context provided by the document. Given a set of judgments for the strings, the score computed for a submission was the mean reciprocal rank. An individual question received a score equal to the reciprocal of the rank at which the first correct response was returned, or zero if none of the five responses contained a correct answer. The score for a submission was then the mean of the individual questions\u2019 reciprocal ranks. The TREC-8 track both defined how answer strings were judged, and established that different assessors have different ideas as to what constitutes a correct answer even for the limited type of questions used in the track. A [document-id, answer-string] pair was judged correct if, in the opinion of the assessor, the answer-string contained an answer to the question, the answer-string was responsive to the question, and the document supported the answer. If the answer-string was responsive and contained a correct answer, but the document did not support that answer, the pair was judged \u201cNot supported\u201d. Otherwise, the pair was judged incorrect. Requiring that the answer string be responsive to the question addressed a variety of issues. Answer strings that contained multiple entities of the same semantic category as the correct answer but did not indicate which of those entities was the actual answer (e.g., a list of names in response to a who question) were judged as incorrect. Certain punctuation and units were also required. Thus \u201c5 5 billion\u2019\u2019 was not an acceptable substitute for \u201c5.5 billion\u201d, nor was \u201c500\u201d acceptable when the correct answer was \u201c$500\u201d. Finally, unless the question specifically stated otherwise, correct responses for questions about a famous entity had to refer to the famous entity and not to imitations, copies, etc. For example, two TREC-8 questions asked for the height of the Matterhorn (i.e., the Alp) and the replica of the Matterhorn at Disneyland. Correct responses for one of these questions were incorrect for the other. See [6] for a very detailed discussion of responsiveness. To test whether assessor opinions vary, each TREC-8 question was independently judged by three different assessors. The separate judgments were combined into a single judgment set through adjudication for the official track evaluation, but the individual judgments were used to measure the effect of differences in judgments on systems\u2019 scores. Assessors opinions did vary. For example, assessors differed on how much of a name was required and on the desired granularity of dates and locations. Fortunately, as with document retrieval evaluation, the relative mean reciprocal rank scores between QA systems remain stable despite differences in the judgments used to evaluate them [5]. The TREC 2001 track modified the main task to make it more realistic and introduced two new tasks, the list task and the context task. All runs were restricted to answer strings of maximum length 50 bytes since the results from the earlier tracks clearly demonstrated that allowing 250-byte answer strings was a much simpler problem. In the main task, the guarantee that a question had an answer in the document collection was eliminated. A system returned the string \u201cNIL\u201d to indicate its belief that there was no answer in the document collection. NIL was marked correct if there was no known answer for that question in the collection and incorrect otherwise. The list task required systems to assemble an answer from information located in multiple documents. Such questions are harder to answer than the questions used in the main task since information duplicated in the documents must be detected and reported only once. Each question in the list task specified a particular kind of information to be retrieved, such as Who are 6 actors who have played Tevye in \u201cFiddler on the Roof\u201d?. Systems returned an unordered list of [document-id, answer-string] pairs where each pair represented a single instance. Results were scored using mean accuracy, which is the ratio of the number of distinct correct responses retrieved to the target number of responses requested. The context task was a pilot evaluation for question answering within a particular scenario or context. The task was designed to represent the kind of dialog processing that a system would need to support an interactive user session. Questions were grouped into different series, and the QA system was expected to track the discourse objects across the individual questions of a series. Unfortunately, the results in the pilot were completely dominated by whether or not a system could answer the particular type of question: the ability to correctly answer questions later in a series was uncorrelated with the ability to correctly answer questions earlier in the series. Thus the task was not repeated in TREC 2002. 2 The TREC 2002 QA Track The TREC 2002 track repeated the main and list tasks from 2001, but with the major difference of requiring systems to return exact answers. The change to exact answers was motivated by the belief that a system\u2019s ability to recognize the precise extent of the answer is crucial to improving question answering technology. The problems with using text snippets containing the answer as responses were illustrated in the TREC 2001 track. For example, each of the answer strings shown in Figure 1 was judged correct for the question What river in the US is known as the Big Muddy?, yet earlier responses are clearly better than later ones. Judging only exact answers correct forces systems to demonstrate that they know precisely where the answer lies in such strings. What constitutes an \u201cexact answer\u201d? As with correctness, exactness is essentially a personal opinion. NIST provided guidelines to the assessors so that questions would be judged similarly, but in the end whether or not an answer was exact was up to the assessor. The guidelines given to the assessors are reproduced in Figure 2. Notice that even \u201cgood\u201d responses that contain a correct answer and justification for that answer were considered inexact for the purposes of this evaluation. A system response consisting of an [document-id, answer-string] pair was assigned exactly one judgment by a human assessor as follows: wrong: the answer string does not contain a correct answer or the answer is not responsive; not supported: the answer string contains a correct answer but the document returned does not support that answer; not exact: the answer string contains a correct answer and the document supports that answer, but the string contains more than just the answer (or is missing bits of the answer);"
            },
            "slug": "Overview-of-the-TREC-2002-Question-Answering-Track-Voorhees",
            "title": {
                "fragments": [],
                "text": "Overview of the TREC 2002 Question Answering Track"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper provides an overview of the TREC 2002 QA track, which defined how answer strings were judged, and established that different assessors have different ideas as to what constitutes a correct answer even for the limited type of questions used in the track."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804315"
                        ],
                        "name": "Z. Ives",
                        "slug": "Z.-Ives",
                        "structuredName": {
                            "firstName": "Zachary",
                            "lastName": "Ives",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Ives"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "streaming data [14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6453999,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8db48c6dee55a5d10e1c04c38bfb6780605f6cb7",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. XML has become the lingua franca for data exchange and integration across administrative and enterprise boundaries. Nearly all data providers are adding XML import or export capabilities, and standard XML Schemas and DTDs are being promoted for all types of data sharing. The ubiquity of XML has removed one of the major obstacles to integrating data from widely disparate sources - namely, the heterogeneity of data formats. However, general-purpose integration of data across the wide are a also requires a query processor that can query data sources on demand, receive streamed XML data from them, and combine and restructure the data into new XML output - while providing good performance for both batch-oriented and ad hoc, interactive queries. This is the goal of the Tukwila data integration system, the first system that focuses on network-bound, dynamic XML data sources. In contrast to previous approaches, which must read, parse, and often store entire XML objects before querying them, \nTukwila can return query results even as the data is streaming into the system. Tukwila is built with a new system architecture that extends adaptive query processing and relational-engine techniques into the XML realm, as facilitated by a pair of operators that incrementally evaluate a query's input path expressions as data is read. In this paper, we describe the Tukwila architecture and its novel aspects, and we experimentally demonstrate that Tukwila provides better overall query performance and faster initial answers than existing systems, and has excellent scalability."
            },
            "slug": "An-XML-query-engine-for-network-bound-data-Ives-Halevy",
            "title": {
                "fragments": [],
                "text": "An XML query engine for network-bound data"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Tukwila is built with a new system architecture that extends adaptive query processing and relational-engine techniques into the XML realm, as facilitated by a pair of operators that incrementally evaluate a query's input path expressions as data is read."
            },
            "venue": {
                "fragments": [],
                "text": "The VLDB Journal"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2339397"
                        ],
                        "name": "Michele Banko",
                        "slug": "Michele-Banko",
                        "structuredName": {
                            "firstName": "Michele",
                            "lastName": "Banko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michele Banko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6645623,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7628b62d64d2e5c33a13a5a473bc41b2391c1ebc",
            "isKey": false,
            "numCitedBy": 693,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The amount of readily available on-line text has reached hundreds of billions of words and continues to grow. Yet for most core natural language tasks, algorithms continue to be optimized, tested and compared after training on corpora consisting of only one million words or less. In this paper, we evaluate the performance of different learning methods on a prototypical natural language disambiguation task, confusion set disambiguation, when trained on orders of magnitude more labeled data than has previously been used. We are fortunate that for this particular application, correctly labeled training data is free. Since this will often not be the case, we examine methods for effectively exploiting very large corpora when labeled data comes at a cost."
            },
            "slug": "Scaling-to-Very-Very-Large-Corpora-for-Natural-Banko-Brill",
            "title": {
                "fragments": [],
                "text": "Scaling to Very Very Large Corpora for Natural Language Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper examines methods for effectively exploiting very large corpora when labeled data comes at a cost, and evaluates the performance of different learning methods on a prototypical natural language disambiguation task, confusion set disambigsuation."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3149586"
                        ],
                        "name": "Marios Skounakis",
                        "slug": "Marios-Skounakis",
                        "structuredName": {
                            "firstName": "Marios",
                            "lastName": "Skounakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marios Skounakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144557047"
                        ],
                        "name": "M. Craven",
                        "slug": "M.-Craven",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Craven",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Craven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145527877"
                        ],
                        "name": "Soumya Ray",
                        "slug": "Soumya-Ray",
                        "structuredName": {
                            "firstName": "Soumya",
                            "lastName": "Ray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumya Ray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60904798,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e704a33f74c2da4b65cb5db01b26f305f434bd4",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction can be defined as the task of automatically extracting instances of specified classes or relations from text. We consider the case of using machine learning methods to induce models for extracting relation instances from biomedical articles. We propose and evaluate an approach that is based on using hierarchical hidden Markov models to represent the grammatical structure of the sentences being processed. Our approach first uses a shallow parser to construct a multi-level representation of each sentence being processed. Then we train hierarchical HMMs to capture the regularities of the parses for both positive and negative sentences. We evaluate our method by inducing models to extract binary relations in three biomedical domains. Our experiments indicate that our approach results in more accurate models than several baseline HMM approaches."
            },
            "slug": "Hierarchical-Hidden-Markov-Models-for-Information-Skounakis-Craven",
            "title": {
                "fragments": [],
                "text": "Hierarchical Hidden Markov Models for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes and evaluates an approach that is based on using hierarchical hidden Markov models to represent the grammatical structure of the sentences being processed, which results in more accurate models than several baseline HMM approaches."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12309040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "733234e097dceb9011baa8914930861996eb0b5e",
            "isKey": false,
            "numCitedBy": 624,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Most recent research in trainable part of speech taggers has explored stochastic tagging. While these taggers obtain high accuracy, linguistic information is captured indirectly, typically in tens of thousands of lexical and contextual probabilities. In (Brill 1992), a trainable rule-based tagger was described that obtained performance comparable to that of stochastic taggers, but captured relevant linguistic information in a small number of simple non-stochastic rules. In this paper, we describe a number of extensions to this rule-based tagger. First, we describe a method for expressing lexical relations in tagging that stochastic taggers are currently unable to express. Next, we show a rule-based approach to tagging unknown words. Finally, we show how the tagger-can be extended into a k-best tagger, where multiple tags can be assigned to words in some cases of uncertainty."
            },
            "slug": "Some-Advances-in-Transformation-Based-Part-of-Brill",
            "title": {
                "fragments": [],
                "text": "Some Advances in Transformation-Based Part of Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method for expressing lexical relations in tagging that stochastic taggers are currently unable to express is described and how the tagger-can be extended into a k-best tagger, where multiple tags can be assigned to words in some cases of uncertainty."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704635"
                        ],
                        "name": "D. Lenat",
                        "slug": "D.-Lenat",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Lenat",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lenat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116698614"
                        ],
                        "name": "J. Brown",
                        "slug": "J.-Brown",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Brown",
                            "middleNames": [
                                "Seely"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our goal in ontology extension is akin to Doug Lenat\u2019s AM and Eurisko systems [18] that automatically extended their knowledge to new predicates using heuristic search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1800673,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "37ab31f586cdc1efc3bf0dcc9ba52f644077e466",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Why-AM-and-Eurisko-Appear-to-Work-Lenat-Brown",
            "title": {
                "fragments": [],
                "text": "Why AM and Eurisko Appear to Work"
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2429001"
                        ],
                        "name": "C. Forgy",
                        "slug": "C.-Forgy",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Forgy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Forgy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "applied to the problem of matching large sets of production rules against a working memory database [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62572191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "464eb245ff9822defa8db82c385ff1fd0b0b6ffe",
            "isKey": false,
            "numCitedBy": 1870,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Rete:-a-fast-algorithm-for-the-many-pattern/many-Forgy",
            "title": {
                "fragments": [],
                "text": "Rete: a fast algorithm for the many pattern/many object pattern match problem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17449687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b9217ac8d4fdd9528442389425b792b1ef0ad93",
            "isKey": false,
            "numCitedBy": 303,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov models (HMMs) are a powerful probabilistic tool for modeling time series data, and have been applied with success to many language-related tasks such as part of speech tagging, speech recognition, text segmentation and topic detection. This paper describes the application of HMMs to another language related task--information extraction--the problem of locating textual sub-segments that answer a particular information need. In our work, the HMM state transition probabilities and word emission probabilities are learned from labeled training data. As in many machine learning problems, however, the lack of sufficient labeled training data hinders the reliability of the model. The key contribution of this paper is the use of a statistical technique called \"shrinkage\" that significantly improves parameter estimation of the HMM emission probabilities in the face of sparse training data. In experiments on seminar announcements and Reuters acquisitions articles, shrinkage is shown to reduce error by up to 40%, and the resulting HMM outperforms a state-of-the-art rule-learning system."
            },
            "slug": "Information-Extraction-with-HMMs-and-Shrinkage-Freitag-McCallum",
            "title": {
                "fragments": [],
                "text": "Information Extraction with HMMs and Shrinkage"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A statistical technique called shrinkage is used that significantly improves parameter estimation of the HMM emission probabilities in the face of sparse training data and the resulting HMM outperforms a state-of-the-art rule-learning system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Much of the previous work on Information Extraction (IE) has focused on the use of supervised learning techniques such as hidden Markov Models [12, 25], rule learning [27, 26], or Conditional Random Fields [ 20 ]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9966171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34dc22dcbdf1e09fb48691ee1fc6fe4bb8f834c3",
            "isKey": false,
            "numCitedBy": 475,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Conditional Random Fields (CRFs) are undirected graphical models, a special case of which correspond to conditionally-trained finite state machines. A key advantage of CRFs is their great flexibility to include a wide variety of arbitrary, non-independent features of the input. Faced with this freedom, however, an important question remains: what features should be used? This paper presents an efficient feature induction method for CRFs. The method is founded on the principle of iteratively constructing feature conjunctions that would significantly increase conditional log-likelihood if added to the model. Automated feature induction enables not only improved accuracy and dramatic reduction in parameter count, but also the use of larger cliques, and more freedom to liberally hypothesize atomic input variables that may be relevant to a task. The method applies to linear-chain CRFs, as well as to more arbitrary CRF structures, such as Relational Markov Networks, where it corresponds to learning clique templates, and can also be understood as supervised structure learning. Experimental results on named entity extraction and noun phrase segmentation tasks are presented."
            },
            "slug": "Efficiently-Inducing-Features-of-Conditional-Random-McCallum",
            "title": {
                "fragments": [],
                "text": "Efficiently Inducing Features of Conditional Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents an efficient feature induction method for CRFs founded on the principle of iteratively constructing feature conjunctions that would significantly increase conditional log-likelihood if added to the model."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740213"
                        ],
                        "name": "Pedro M. Domingos",
                        "slug": "Pedro-M.-Domingos",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Domingos",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro M. Domingos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694780"
                        ],
                        "name": "M. Pazzani",
                        "slug": "M.-Pazzani",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Pazzani",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pazzani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "However, as [9] points out, the classifier is surprisingly effective because it only needs to make an ordinal judgment (which class is more likely) to classify instances correctly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "The features chosen are combined using a \u201cnaive Bayesian\u201d probability update [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 77139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "700666f0c59a4fedc8b08294424c47cb99a8e2ff",
            "isKey": false,
            "numCitedBy": 3124,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "The simple Bayesian classifier is known to be optimal when attributes are independent given the class, but the question of whether other sufficient conditions for its optimality exist has so far not been explored. Empirical results showing that it performs surprisingly well in many domains containing clear attribute dependences suggest that the answer to this question may be positive. This article shows that, although the Bayesian classifier's probability estimates are only optimal under quadratic loss if the independence assumption holds, the classifier itself can be optimal under zero-one loss (misclassification rate) even when this assumption is violated by a wide margin. The region of quadratic-loss optimality of the Bayesian classifier is in fact a second-order infinitesimal fraction of the region of zero-one optimality. This implies that the Bayesian classifier has a much greater range of applicability than previously thought. For example, in this article it is shown to be optimal for learning conjunctions and disjunctions, even though they violate the independence assumption. Further, studies in artificial domains show that it will often outperform more powerful classifiers for common training set sizes and numbers of attributes, even if its bias is a priori much less appropriate to the domain. This article's results also imply that detecting attribute dependence is not necessarily the best way to extend the Bayesian classifier, and this is also verified empirically."
            },
            "slug": "On-the-Optimality-of-the-Simple-Bayesian-Classifier-Domingos-Pazzani",
            "title": {
                "fragments": [],
                "text": "On the Optimality of the Simple Bayesian Classifier under Zero-One Loss"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The Bayesian classifier is shown to be optimal for learning conjunctions and disjunctions, even though they violate the independence assumption, and will often outperform more powerful classifiers for common training set sizes and numbers of attributes, even if its bias is a priori much less appropriate to the domain."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40497400"
                        ],
                        "name": "D. Moldovan",
                        "slug": "D.-Moldovan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Moldovan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Moldovan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713428"
                        ],
                        "name": "S. Harabagiu",
                        "slug": "S.-Harabagiu",
                        "structuredName": {
                            "firstName": "Sanda",
                            "lastName": "Harabagiu",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Harabagiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2469966"
                        ],
                        "name": "R. Girju",
                        "slug": "R.-Girju",
                        "structuredName": {
                            "firstName": "Roxana",
                            "lastName": "Girju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Girju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782712"
                        ],
                        "name": "Paul Morarescu",
                        "slug": "Paul-Morarescu",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Morarescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Morarescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143836304"
                        ],
                        "name": "V. Lacatusu",
                        "slug": "V.-Lacatusu",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Lacatusu",
                            "middleNames": [
                                "Finley"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lacatusu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2551141"
                        ],
                        "name": "Adrian Novischi",
                        "slug": "Adrian-Novischi",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Novischi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian Novischi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3154735"
                        ],
                        "name": "A. Badulescu",
                        "slug": "A.-Badulescu",
                        "structuredName": {
                            "firstName": "Adriana",
                            "lastName": "Badulescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Badulescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3251756"
                        ],
                        "name": "Orest Bolohan",
                        "slug": "Orest-Bolohan",
                        "structuredName": {
                            "firstName": "Orest",
                            "lastName": "Bolohan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Orest Bolohan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18837890,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "f649b57fac0b384dc8405dfc643f40824d54e2a0",
            "isKey": false,
            "numCitedBy": 226,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "\u00a2\u00a1\u00a4\u00a3`\u00a5T\u00a6 \u00a7\u00a9 \u0308/\u00a5 a\"\u00ab\u00ad\u00acg\u00ae\u008f \u0304\u00a9\u00b0M\u00b12\u00ac \u03013/\u03bc\u009c\u00ac \u0301\u00b6\u0091\u00b0M\u00b7] \u0327!1^o\u00bb\u00acM1\u20444\u00ad\u00ae\u00bb1\u20442a3\u20444j\u00b7/\u00bfW1\u204422\u00ab\u00ad\u00ac a\"\u00c0|\u00c1\u00c3\u00c2 \u00c4\u0082\u00c5\u00c7\u00c60\u00c8\u00ad\u00ac \u0301\u03bc21\u204422\u00ae\u00bb\u00b7] \u0304\u00a9\u03bc\"\u00b1~\u00ac \u0301\u00c60\u00c8\u00a9\u00ae\u00c9\u00b12\u00ac \u0301\u03bcn3/\u00b6\u00a9\u00ca 3/ \u0304\u00a9\u00b0M\u00ac \u0301\u00b6 1\u20442\u009c\u00acM1\u20444L1\u20442c1^\u00b12\u00b7 \u00cb \u00b0M\u00ac \u0301\u03bc~\u03bc2\u00ae\u00c9 \u0304\u00ad\u00ccD1\u20442\u009c\u00b7 \u00b7]o\u00c9\u03bcn1\u204422\u00ab\u00a93 1\u20442|\u00b1~\u00ac \u0301o\u00bb3\u20444\u00cd\u00b7] \u0304 \u0304\u00a93 1\u204422\u00c8\u00ad\u00b1H3/oRo\u00c93/ \u0304\u00ad\u00cc]\u00c8^3 \u00cc/\u00acA1\u00a9\u00b12\u00b7L\u00b0M\u00ac \u0301\u03bc2\u03bc2\u00ae\u008f \u0304\u00ad\u00ccD3/ \u0304\u00a9\u00b6j\u00ceL \u0304\u00ad\u00b7d\u00cf|o\u00bb\u00ac \u0301\u00b6\u00ad\u00cc/\u00acg\u00b12\u00ac \u03013/\u03bc\u009c\u00b7] \u0304\u00a9\u00ae\u00c9 \u0304\u00a9\u00cc\u00ad\u00d0\u00c3a|\u00ab\u00a9\u00ae\u00c9\u03bc 153 1@\u00ac`\u00b1 1\u00a9\u00b12\u00ac \u0301\u03bc\u009c\u00ac \u0301 \u030401\u204422\u03bcJ1\u204422\u00ab\u00ad\u00acn\u03bc~\u00c8\u00a9\u00ae\u00bb1\u20442\u009c\u00ac|\u00b7/\u00bfR1\u20442\u009c\u00b70\u00b7]o\u00c9\u03bc 1\u204422\u00ab\u00a93 1\u20442\u00c33/\u00b0`\u00b0M\u00b7]\u00c8\u00a9 \u030401\u20442J\u00bf,\u00b7/\u00b1J1\u204422\u00ab\u00ad\u00acn1-\u00ac`\u00b12\u00bf,\u00b7/\u00b1~ \u0327D3/ \u0304^\u00b0M\u00ac|\u00b7/\u00bf61\u204422\u00ab\u00ad\u00ac\u0082\u00d1\u00a4\u00b7T\u00cfJ\u00ac`\u00b1~\u00c5n \u0304^\u03bc\u009c\u00cf \u00ac`\u00b1 \u00c6 \u00c8\u00ad\u00ac \u0301\u03bc\u009c1\u204422\u00ae\u00c9\u00b7] \u0304 3/ \u0304\u00a9\u03bc2\u00cf \u00ac`\u00b1~\u00ae\u008f \u0304\u00ad\u00cc{\u03bc23\u20444 \u03bc\u009c1\u20442\u009c\u00ac \u0301 \u0327j\u00d0\u00d3\u00d2a1\u20442\u0082\u00ae\u00c9\u03bc\u0082\u03bc2\u00ab\u00ad\u00b7d\u00cf| \u0304V\u00ab\u00ad\u00b7T\u00cf \u00c6 \u00c8\u00ad\u00ac \u0301\u03bc\u009c1\u204422\u00ae\u00bb\u00b7] \u0304\u00a9\u03bc \u0301\u00d4-3/ \u0304^\u03bc\u009c\u00cf \u00ac`\u00b1H\u03bcc3/ \u0304^\u00b6 \u00cfJ\u00b7/\u00b1~o\u00c9\u00b6 \u00ceL \u0304\u00ad\u00b7T\u00cf|o\u00c9\u00ac \u0301\u00b6\u00ad\u00cc/\u00ac 3 \u00b1~\u00ac 1\u20442\u009c\u00b1~3/ \u0304\u00a9\u03bc2\u00bfE\u00b7/\u00b1~ \u0327D\u00ac \u0301\u00b6\u00d6\u00d5\u00a9\u00b1~\u03bc21\u20442\u00d7\u00ae\u00c9 \u0304\u00d8o\u00c9\u00b7/\u00cc]\u00ae\u00c9\u00b0\u00d9\u00b12\u00ac`1\u00a9\u00b1~\u00ac \u0301\u03bc\u009c\u00ac \u0301 \u0304\u00921\u2044223 1\u204422\u00ae\u00c9\u00b7] \u03046\u00d4\"\u00bf,\u00b7]o\u00c9o\u00bb\u00b7T\u00cfJ\u00ac \u0301\u00b6\u00d6\u00da 3\u20444\u00d63\\\u03bc23\u20444 \u03bc\u009c1\u20442\u009c\u00ac \u0301 \u0327\u00d73 1\u204422\u00ae\u00c9\u00b0 3/ \u0304^\u00b6\u00d6\u00b1~\u00ae\u00bb\u00cc/\u00b7/\u00b1~\u00b7]\u00c8\u00a9\u03bc o\u00c9\u00b7/\u00cc]\u00ae\u00c9\u00b0\u00cd1\u00a9\u00b12\u00b7 \u00b7/\u00bf|1\u204422\u00ab\u00a93 1\u20442\u00d7\u00ca 3/o\u00c9\u00ae\u008f\u00b6\u00a9o\u00bb3\u20444\\3/ \u0304\u00a9\u03bc2\u00cf \u00ac`\u00b1~\u03bc\u00d7\u00c60\u00c8\u00ad\u00ac \u0301\u03bc21\u204422\u00ae\u00bb\u00b7] \u0304\u00a9\u03bc 1-\u00b7]\u03bc\u009c\u00ac \u0301\u00b6 1\u20442\u009c\u00b7\u00db1\u204422\u00ab\u00a9\u00ac \u00c4\u0082\u00c5\u00dc\u03bc23\u20444 \u03bc\u009c1\u20442\u009c\u00ac \u0301 \u0327j\u00d0\u00d8\u00c5\u00c31\u20442\u00d7a\"\u00c0n\u00c1J\u00c2\u00dd\u00c4\u0082\u00c5 \u00de \u00df/\u00df]\u00de \u00d4\u00a9\u00d1\u00a4\u00b7d\u00cf \u00ac`\u00b1~\u00c5c \u0304\u00a9\u03bc\u009c\u00cfJ\u00ac`\u00b1 \u00b7/\u00da\u00a91\u2044223/\u00ae\u00c9 \u0304\u00a9\u00ac \u0301\u00b6\u00a23 \u00b0M\u00b7] \u0304\u00ad\u00d5^\u00b6\u00a9\u00ac \u0301 \u0304\u00a9\u00b0M\u00acM\u00cbG\u00cf \u00ac \u0301\u00ae\u00c9\u00cc]\u00ab\u00921\u20442\u009c\u00ac \u0301\u00b6\u00cd\u03bc2\u00b0M\u00b7/\u00b12\u00ac\u0082\u00b7/\u00bfR\u00dfL\u00d0\u00e1\u00e0/\u00e2/\u00e3 \u00d453/ \u0304\u00a9\u03bc\u009c\u00cfJ\u00ac`\u00b1~\u00ae\u00c9 \u0304\u00ad\u00cc8\u00b0M\u00b7/\u00b12\u00b12\u00ac \u0301\u00b0M1\u204422o\u00bb3\u20444 \u00e4\u00a9\u00e5 \u00e2!\u00b7]\u00c8\u00ad1\u20442\"\u00b7/\u00bfW\u00e2 \u00df/\u00dfD\u00c6 \u00c8\u00ad\u00ac \u0301\u03bc\u009c1\u204422\u00ae\u00bb\u00b7] \u0304\u00a9\u03bc \u0301\u00d0"
            },
            "slug": "LCC-Tools-for-Question-Answering-Moldovan-Harabagiu",
            "title": {
                "fragments": [],
                "text": "LCC Tools for Question Answering"
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782658"
                        ],
                        "name": "Kristina Lerman",
                        "slug": "Kristina-Lerman",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Lerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Lerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145293454"
                        ],
                        "name": "Steven Minton",
                        "slug": "Steven-Minton",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Minton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Minton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3276863"
                        ],
                        "name": "Ion Muslea",
                        "slug": "Ion-Muslea",
                        "structuredName": {
                            "firstName": "Ion",
                            "lastName": "Muslea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ion Muslea"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60902530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3c8ed0febb2028556a4b9e872e071fd918e6511",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A critical problem in developing information agents for the Web is accessing data that is formatted for human use. We have developed a set of tools for extracting data from web sites and transforming it into a structured data format, such as XML. The resulting data can then be used to build new applications without having to deal with unstructured data. The advantages of our wrapping technology over previous work are the the ability to learn highly accurate extraction rules, to verify the wrapper to ensure that the correct data continues to be extracted, and to automatically adapt to changes in the sites from which the data is being extracted."
            },
            "slug": "Accurately-and-Reliably-Extracting-Data-from-the-A-Knoblock-Lerman",
            "title": {
                "fragments": [],
                "text": "Accurately and Reliably Extracting Data from the Web: A Machine Learning Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A set of tools for extracting data from web sites and transforming it into a structured data format, such as XML, so that the resulting data can be used to build new applications without having to deal with unstructured data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Data Eng. Bull."
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Moving up the information food chain: softbots as information carnivores"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Thirteenth National Conference on Artificial Intelligence"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "The Extractor uses the Brill tagger [4] to assign part-of-speech tags and identifies noun phrases with regular expressions based on the part-of-speech tags."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Some advances in rule-based part of speech tagging"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Twelfth National Conference on Artificial Intelligence"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "We are currently implementing an algorithm for learning large numbers of domain-specific rules based on the work of [23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning surface text for a question answering system"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 3rd Annual Meeting of the North American Chapter of the Association for Computational Linguistics"
            },
            "year": 2002
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 32,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Web-scale-information-extraction-in-knowitall:-Etzioni-Cafarella/9ef07373873cc0f0b940512dcdde4e7b54b0cfb0?sort=total-citations"
}