{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50381660"
                        ],
                        "name": "A. Wong",
                        "slug": "A.-Wong",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ttribute pairs directly. We further evaluate our model on one and few-shot learning. There have been a few works in this area recently such as [2] which inverts the process that creates the input and [37] which learns new categories by \ufb01nding common patches between classes. Both evaluate on handwritten characters and it is unclear how well they would scale to realistic images. [36] improves few-shot c"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13468902,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7d3fca013d5bb578c341383c219669fd2bf52a5",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "The task of discriminating one object from another is almost trivial for a human being. However, this task is computationally taxing for most modern machine learning methods, whereas, we perform this task at ease given very few examples for learning. It has been proposed that the quick grasp of concept may come from the shared knowledge between the new example and examples previously learned. We believe that the key to one-shot learning is the sharing of common parts as each part holds immense amounts of information on how a visual concept is constructed. We propose an unsupervised method for learning a compact dictionary of image patches representing meaningful components of an objects. Using those patches as features, we build a compositional model that outperforms a number of popular algorithms on a one-shot learning task. We demonstrate the effectiveness of this approach on hand-written digits and show that this model generalizes to multiple datasets."
            },
            "slug": "One-Shot-Learning-via-Compositions-of-Meaningful-Wong-Yuille",
            "title": {
                "fragments": [],
                "text": "One Shot Learning via Compositions of Meaningful Patches"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes an unsupervised method for learning a compact dictionary of image patches representing meaningful components of an objects and builds a compositional model that outperforms a number of popular algorithms on a one-shot learning task."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787591"
                        ],
                        "name": "Christoph H. Lampert",
                        "slug": "Christoph-H.-Lampert",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Lampert",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoph H. Lampert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748758"
                        ],
                        "name": "H. Nickisch",
                        "slug": "H.-Nickisch",
                        "structuredName": {
                            "firstName": "Hannes",
                            "lastName": "Nickisch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nickisch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734990"
                        ],
                        "name": "S. Harmeling",
                        "slug": "S.-Harmeling",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Harmeling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Harmeling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7016601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9bc0295460089592d04e754a5fd427060b7bfa8c",
            "isKey": false,
            "numCitedBy": 1213,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of object recognition for categories for which we have no training examples, a task also called zero--data or zero-shot learning. This situation has hardly been studied in computer vision research, even though it occurs frequently; the world contains tens of thousands of different object classes, and image collections have been formed and suitably annotated for only a few of them. To tackle the problem, we introduce attribute-based classification: Objects are identified based on a high-level description that is phrased in terms of semantic attributes, such as the object's color or shape. Because the identification of each such property transcends the specific learning task at hand, the attribute classifiers can be prelearned independently, for example, from existing image data sets unrelated to the current task. Afterward, new classes can be detected based on their attribute representation, without the need for a new training phase. In this paper, we also introduce a new data set, Animals with Attributes, of over 30,000 images of 50 animal classes, annotated with 85 semantic attributes. Extensive experiments on this and two more data sets show that attribute-based classification indeed is able to categorize images without access to any training images of the target classes."
            },
            "slug": "Attribute-Based-Classification-for-Zero-Shot-Visual-Lampert-Nickisch",
            "title": {
                "fragments": [],
                "text": "Attribute-Based Classification for Zero-Shot Visual Object Categorization"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39717886"
                        ],
                        "name": "Xinlei Chen",
                        "slug": "Xinlei-Chen",
                        "structuredName": {
                            "firstName": "Xinlei",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinlei Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781242"
                        ],
                        "name": "Abhinav Shrivastava",
                        "slug": "Abhinav-Shrivastava",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Shrivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhinav Shrivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "Learning knowledge graphs [38, 4, 29] and using graphs for visual reasoning [39, 20] has recently been of interest to the vision community."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12350611,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53e4ab9730e983242a3409c7bf1af945041a6563",
            "isKey": false,
            "numCitedBy": 439,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose NEIL (Never Ending Image Learner), a computer program that runs 24 hours per day and 7 days per week to automatically extract visual knowledge from Internet data. NEIL uses a semi-supervised learning algorithm that jointly discovers common sense relationships (e.g., \"Corolla is a kind of/looks similar to Car\", \"Wheel is a part of Car\") and labels instances of the given visual categories. It is an attempt to develop the world's largest visual structured knowledge base with minimum human labeling effort. As of 10th October 2013, NEIL has been continuously running for 2.5 months on 200 core cluster (more than 350K CPU hours) and has an ontology of 1152 object categories, 1034 scene categories and 87 attributes. During this period, NEIL has discovered more than 1700 relationships and has labeled more than 400K visual instances."
            },
            "slug": "NEIL:-Extracting-Visual-Knowledge-from-Web-Data-Chen-Shrivastava",
            "title": {
                "fragments": [],
                "text": "NEIL: Extracting Visual Knowledge from Web Data"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "NEIL (Never Ending Image Learner), a computer program that runs 24 hours per day and 7 days per week to automatically extract visual knowledge from Internet data, is proposed in an attempt to develop the world's largest visual structured knowledge base with minimum human labeling effort."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Computer Vision"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302062"
                        ],
                        "name": "Yu-Xiong Wang",
                        "slug": "Yu-Xiong-Wang",
                        "structuredName": {
                            "firstName": "Yu-Xiong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-Xiong Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "eates the input and [37] which learns new categories by \ufb01nding common patches between classes. Both evaluate on handwritten characters and it is unclear how well they would scale to realistic images. [36] improves few-shot classi\ufb01- cation by training a network on a high-data image dataset and then learning a model-to-model transformation onto the new dataset. 3. Methodology 3.1. Graph Gated Neural Net"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10048432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4deb435bd9ddd9db30909abe9a20e85c4eced5f1",
            "isKey": true,
            "numCitedBy": 222,
            "numCiting": 105,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a conceptually simple but powerful approach that can learn novel categories from few annotated examples. In this approach, the experience with already learned categories is used to facilitate the learning of novel classes. Our insight is two-fold: (1) there exists a generic, category agnostic transformation from models learned from few samples to models learned from large enough sample sets, and (2) such a transformation could be effectively learned by high-capacity regressors. In particular, we automatically learn the transformation with a deep model regression network on a large collection of model pairs. Experiments demonstrate that encoding this transformation as prior knowledge greatly facilitates the recognition in the small sample size regime on a broad range of tasks, including domain adaptation, fine-grained recognition, action recognition, and scene classification."
            },
            "slug": "Learning-to-Learn:-Model-Regression-Networks-for-Wang-Hebert",
            "title": {
                "fragments": [],
                "text": "Learning to Learn: Model Regression Networks for Easy Small Sample Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A conceptually simple but powerful approach that can learn novel categories from few annotated examples that greatly facilitates the recognition in the small sample size regime on a broad range of tasks, including domain adaptation, fine-grained recognition, action recognition, and scene classification."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117748"
                        ],
                        "name": "Yuke Zhu",
                        "slug": "Yuke-Zhu",
                        "structuredName": {
                            "firstName": "Yuke",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuke Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50706340"
                        ],
                        "name": "A. Fathi",
                        "slug": "A.-Fathi",
                        "structuredName": {
                            "firstName": "Alireza",
                            "lastName": "Fathi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fathi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "For example, [38] collects a knowledge base and then queries this knowledge base to do first-order probabilistic reasoning to predict affordances."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5876698,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea8fe33cc1596b2e493ddd87f22cd21f563664e8",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Reasoning about objects and their affordances is a fundamental problem for visual intelligence. Most of the previous work casts this problem as a classification task where separate classifiers are trained to label objects, recognize attributes, or assign affordances. In this work, we consider the problem of object affordance reasoning using a knowledge base representation. Diverse information of objects are first harvested from images and other meta-data sources. We then learn a knowledge base (KB) using a Markov Logic Network (MLN). Given the learned KB, we show that a diverse set of visual inference tasks can be done in this unified framework without training separate classifiers, including zero-shot affordance prediction and object recognition given human poses."
            },
            "slug": "Reasoning-about-Object-Affordances-in-a-Knowledge-Zhu-Fathi",
            "title": {
                "fragments": [],
                "text": "Reasoning about Object Affordances in a Knowledge Base Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work learns a knowledge base (KB) using a Markov Logic Network (MLN) and shows that a diverse set of visual inference tasks can be done in this unified framework without training separate classifiers, including zero-shot affordance prediction and object recognition given human poses."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237361"
                        ],
                        "name": "Ranjay Krishna",
                        "slug": "Ranjay-Krishna",
                        "structuredName": {
                            "firstName": "Ranjay",
                            "lastName": "Krishna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ranjay Krishna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117748"
                        ],
                        "name": "Yuke Zhu",
                        "slug": "Yuke-Zhu",
                        "structuredName": {
                            "firstName": "Yuke",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuke Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50499889"
                        ],
                        "name": "O. Groth",
                        "slug": "O.-Groth",
                        "structuredName": {
                            "firstName": "Oliver",
                            "lastName": "Groth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Groth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115231104"
                        ],
                        "name": "Justin Johnson",
                        "slug": "Justin-Johnson",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Justin Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1382195702"
                        ],
                        "name": "K. Hata",
                        "slug": "K.-Hata",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Hata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40591424"
                        ],
                        "name": "J. Kravitz",
                        "slug": "J.-Kravitz",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Kravitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kravitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110910215"
                        ],
                        "name": "Stephanie Chen",
                        "slug": "Stephanie-Chen",
                        "structuredName": {
                            "firstName": "Stephanie",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephanie Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944225"
                        ],
                        "name": "Yannis Kalantidis",
                        "slug": "Yannis-Kalantidis",
                        "structuredName": {
                            "firstName": "Yannis",
                            "lastName": "Kalantidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yannis Kalantidis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760364"
                        ],
                        "name": "David A. Shamma",
                        "slug": "David-A.-Shamma",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Shamma",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Shamma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145879842"
                        ],
                        "name": "Michael S. Bernstein",
                        "slug": "Michael-S.-Bernstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bernstein",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael S. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "To this end, we chose the Visual Genome dataset [15] v1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4492210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d",
            "isKey": false,
            "numCitedBy": 2772,
            "numCiting": 142,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite progress in perceptual tasks such as image classification, computers still perform poorly on cognitive tasks such as image description and question answering. Cognition is core to tasks that involve not just recognizing, but reasoning about our visual world. However, models used to tackle the rich content in images for cognitive tasks are still being trained using the same datasets designed for perceptual tasks. To achieve success at cognitive tasks, models need to understand the interactions and relationships between objects in an image. When asked \u201cWhat vehicle is the person riding?\u201d, computers will need to identify the objects in an image as well as the relationships riding(man, carriage) and pulling(horse, carriage) to answer correctly that \u201cthe person is riding a horse-drawn carriage.\u201d In this paper, we present the Visual Genome dataset to enable the modeling of such relationships. We collect dense annotations of objects, attributes, and relationships within each image to learn these models. Specifically, our dataset contains over 108K images where each image has an average of $$35$$35 objects, $$26$$26 attributes, and $$21$$21 pairwise relationships between objects. We canonicalize the objects, attributes, relationships, and noun phrases in region descriptions and questions answer pairs to WordNet synsets. Together, these annotations represent the densest and largest dataset of image descriptions, objects, attributes, relationships, and question answer pairs."
            },
            "slug": "Visual-Genome:-Connecting-Language-and-Vision-Using-Krishna-Zhu",
            "title": {
                "fragments": [],
                "text": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The Visual Genome dataset is presented, which contains over 108K images where each image has an average of $$35$$35 objects, $$26$$26 attributes, and $$21$$21 pairwise relationships between objects, and represents the densest and largest dataset of image descriptions, objects, attributes, relationships, and question answer pairs."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2780262"
                        ],
                        "name": "Mathias Niepert",
                        "slug": "Mathias-Niepert",
                        "structuredName": {
                            "firstName": "Mathias",
                            "lastName": "Niepert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mathias Niepert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24931083"
                        ],
                        "name": "Mohamed Ahmed",
                        "slug": "Mohamed-Ahmed",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohamed Ahmed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712289"
                        ],
                        "name": "Konstantin Kutzkov",
                        "slug": "Konstantin-Kutzkov",
                        "structuredName": {
                            "firstName": "Konstantin",
                            "lastName": "Kutzkov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Konstantin Kutzkov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 98
                            }
                        ],
                        "text": "There has been a lot of work in end-to-end learning on graphs or neural network trained on graphs [31, 2, 6, 11, 25, 22, 9, 21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 283
                            }
                        ],
                        "text": "Several works treat graphs as a special case of a convolutional input where, instead of pixel inputs connected to pixels in a grid, we define the inputs as connected by an input graph, relying on either some global graph structure or doing some sort of pre-processing on graph edges [2, 6, 11, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1430801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c6de5a9e02a779e24504619050c6118f4eac181",
            "isKey": false,
            "numCitedBy": 1516,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Numerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient."
            },
            "slug": "Learning-Convolutional-Neural-Networks-for-Graphs-Niepert-Ahmed",
            "title": {
                "fragments": [],
                "text": "Learning Convolutional Neural Networks for Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This work proposes a framework for learning convolutional neural networks for arbitrary graphs that operate on locally connected regions of the input and demonstrates that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39713408"
                        ],
                        "name": "Mikael Henaff",
                        "slug": "Mikael-Henaff",
                        "structuredName": {
                            "firstName": "Mikael",
                            "lastName": "Henaff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikael Henaff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143627859"
                        ],
                        "name": "Joan Bruna",
                        "slug": "Joan-Bruna",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bruna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Bruna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 98
                            }
                        ],
                        "text": "There has been a lot of work in end-to-end learning on graphs or neural network trained on graphs [31, 2, 6, 11, 25, 22, 9, 21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 283
                            }
                        ],
                        "text": "Several works treat graphs as a special case of a convolutional input where, instead of pixel inputs connected to pixels in a grid, we define the inputs as connected by an input graph, relying on either some global graph structure or doing some sort of pre-processing on graph edges [2, 6, 11, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10443309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e49ff72d420c8d72e62a9353e3abc053445e59bd",
            "isKey": false,
            "numCitedBy": 1159,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Learning's recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions. However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities. \nIn this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains, which are typically unknown and need to be estimated from the data. In particular, we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure, that we test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate."
            },
            "slug": "Deep-Convolutional-Networks-on-Graph-Structured-Henaff-Bruna",
            "title": {
                "fragments": [],
                "text": "Deep Convolutional Networks on Graph-Structured Data"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper develops an extension of Spectral Networks which incorporates a Graph Estimation procedure, that is test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143627859"
                        ],
                        "name": "Joan Bruna",
                        "slug": "Joan-Bruna",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bruna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Bruna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3149531"
                        ],
                        "name": "Arthur D. Szlam",
                        "slug": "Arthur-D.-Szlam",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Szlam",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arthur D. Szlam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 98
                            }
                        ],
                        "text": "There has been a lot of work in end-to-end learning on graphs or neural network trained on graphs [31, 2, 6, 11, 25, 22, 9, 21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 283
                            }
                        ],
                        "text": "Several works treat graphs as a special case of a convolutional input where, instead of pixel inputs connected to pixels in a grid, we define the inputs as connected by an input graph, relying on either some global graph structure or doing some sort of pre-processing on graph edges [2, 6, 11, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17682909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e925a9f1e20df61d1e860a7aa71894b35a1c186",
            "isKey": false,
            "numCitedBy": 2788,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures."
            },
            "slug": "Spectral-Networks-and-Locally-Connected-Networks-on-Bruna-Zaremba",
            "title": {
                "fragments": [],
                "text": "Spectral Networks and Locally Connected Networks on Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper considers possible generalizations of CNNs to signals defined on more general domains without the action of a translation group, and proposes two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "We also concatenate this feature vector with fc7 layer (4096-dim) of a fine-tuned VGG-16 network [35] and top-score for each COCO category predicted by Faster R-CNN (80-dim)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14124313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb42cf88027de515750f230b23b1a057dc782108",
            "isKey": false,
            "numCitedBy": 62223,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision."
            },
            "slug": "Very-Deep-Convolutional-Networks-for-Large-Scale-Simonyan-Zisserman",
            "title": {
                "fragments": [],
                "text": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work investigates the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting using an architecture with very small convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144277218"
                        ],
                        "name": "Kun Duan",
                        "slug": "Kun-Duan",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Duan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Duan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153432684"
                        ],
                        "name": "Devi Parikh",
                        "slug": "Devi-Parikh",
                        "structuredName": {
                            "firstName": "Devi",
                            "lastName": "Parikh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Devi Parikh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2821130"
                        ],
                        "name": "David J. Crandall",
                        "slug": "David-J.-Crandall",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Crandall",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Crandall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794409"
                        ],
                        "name": "K. Grauman",
                        "slug": "K.-Grauman",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Grauman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grauman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 258
                            }
                        ],
                        "text": "Our work is also related to attribute approaches [8] to vision such as [16] which uses a fixed set of binary attributes to do zero-shot prediction, [34] which uses attributes shared across categories to prevent semantic drift in semi-supervised learning and [5] which automatically discovers attributes and uses them for fine-grained classification."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7708151,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0182d090478be67241392df90212d6cd0fb659e6",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Attributes are visual concepts that can be detected by machines, understood by humans, and shared across categories. They are particularly useful for fine-grained domains where categories are closely related to one other (e.g. bird species recognition). In such scenarios, relevant attributes are often local (e.g. \u201cwhite belly\u201d), but the question of how to choose these local attributes remains largely unexplored. In this paper, we propose an interactive approach that discovers local attributes that are both discriminative and semantically meaningful from image datasets annotated only with fine-grained category labels and object bounding boxes. Our approach uses a latent conditional random field model to discover candidate attributes that are detectable and discriminative, and then employs a recommender system that selects attributes likely to be semantically meaningful. Human interaction is used to provide semantic names for the discovered attributes. We demonstrate our method on two challenging datasets, Caltech-UCSD Birds-200-2011 and Leeds Butterflies, and find that our discovered attributes outperform those generated by traditional approaches."
            },
            "slug": "Discovering-localized-attributes-for-fine-grained-Duan-Parikh",
            "title": {
                "fragments": [],
                "text": "Discovering localized attributes for fine-grained recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This approach uses a latent conditional random field model to discover candidate attributes that are detectable and discriminative, and then employs a recommender system that selects attributes likely to be semantically meaningful from image datasets annotated only with fine-grained category labels and object bounding boxes."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117748"
                        ],
                        "name": "Yuke Zhu",
                        "slug": "Yuke-Zhu",
                        "structuredName": {
                            "firstName": "Yuke",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuke Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776014"
                        ],
                        "name": "Ce Zhang",
                        "slug": "Ce-Zhang",
                        "structuredName": {
                            "firstName": "Ce",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ce Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803218"
                        ],
                        "name": "Christopher R\u00e9",
                        "slug": "Christopher-R\u00e9",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "R\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher R\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "There has also been some work using a knowledge base for image retrieval [12] or answering visual queries [41], but these works are focused on building and then querying knowledge bases rather than using existing knowledge bases as side information for some vision task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1197661,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "131125a5aadb48ec3eceb404cedbff713c401feb",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "The complexity of the visual world creates significant challenges for comprehensive visual understanding. In spite of recent successes in visual recognition, today's vision systems would still struggle to deal with visual queries that require a deeper reasoning. We propose a knowledge base (KB) framework to handle an assortment of visual queries, without the need to train new classifiers for new tasks. Building such a large-scale multimodal KB presents a major challenge of scalability. We cast a large-scale MRF into a KB representation, incorporating visual, textual and structured data, as well as their diverse relations. We introduce a scalable knowledge base construction system that is capable of building a KB with half billion variables and millions of parameters in a few hours. Our system achieves competitive results compared to purpose-built models on standard recognition and retrieval tasks, while exhibiting greater flexibility in answering richer visual queries."
            },
            "slug": "Building-a-Large-scale-Multimodal-Knowledge-Base-Zhu-Zhang",
            "title": {
                "fragments": [],
                "text": "Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work introduces a scalable knowledge base construction system that is capable of building a KB with half billion variables and millions of parameters in a few hours, and achieves competitive results compared to purpose-built models on standard recognition and retrieval tasks, while exhibiting greater flexibility in answering richer visual queries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2192178"
                        ],
                        "name": "Olga Russakovsky",
                        "slug": "Olga-Russakovsky",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Russakovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olga Russakovsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144914140"
                        ],
                        "name": "Hao Su",
                        "slug": "Hao-Su",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2285165"
                        ],
                        "name": "J. Krause",
                        "slug": "J.-Krause",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Krause"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145031342"
                        ],
                        "name": "S. Satheesh",
                        "slug": "S.-Satheesh",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Satheesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Satheesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145423516"
                        ],
                        "name": "S. Ma",
                        "slug": "S.-Ma",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3109481"
                        ],
                        "name": "Zhiheng Huang",
                        "slug": "Zhiheng-Huang",
                        "structuredName": {
                            "firstName": "Zhiheng",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiheng Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2354728"
                        ],
                        "name": "A. Karpathy",
                        "slug": "A.-Karpathy",
                        "structuredName": {
                            "firstName": "Andrej",
                            "lastName": "Karpathy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Karpathy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2556428"
                        ],
                        "name": "A. Khosla",
                        "slug": "A.-Khosla",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Khosla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Khosla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145879842"
                        ],
                        "name": "Michael S. Bernstein",
                        "slug": "Michael-S.-Bernstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bernstein",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael S. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "The node level outputs can then just be computed as\nov = g(h (T ) v , xv) (7)\nwhere g is a fully connected network, the output network, and xv is the original annotation for the node."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our method significantly out-\nperforms baselines for multi-label classification both in full data and low-data settings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "There has been a lot of work in end-to-end learning on graphs or neural network trained on graphs [30, 3, 6, 11, 24, 22, 9, 21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2930547,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
            "isKey": false,
            "numCitedBy": 25491,
            "numCiting": 138,
            "paperAbstract": {
                "fragments": [],
                "text": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5\u00a0years of the challenge, and propose future directions and improvements."
            },
            "slug": "ImageNet-Large-Scale-Visual-Recognition-Challenge-Russakovsky-Deng",
            "title": {
                "fragments": [],
                "text": "ImageNet Large Scale Visual Recognition Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The creation of this benchmark dataset and the advances in object recognition that have been possible as a result are described, and the state-of-the-art computer vision accuracy with human accuracy is compared."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2373318"
                        ],
                        "name": "B. Lake",
                        "slug": "B.-Lake",
                        "structuredName": {
                            "firstName": "Brenden",
                            "lastName": "Lake",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "There have been a few works in this area recently such as [2] which inverts the process that creates the input and [37] which learns new categories by finding common patches between classes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1433222,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "357da8861465de56c05259aeb7bf2116f7e73d21",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "People can learn a new visual class from just one example, yet machine learning algorithms typically require hundreds or thousands of examples to tackle the same problems. Here we present a Hierarchical Bayesian model based on com-positionality and causality that can learn a wide range of natural (although simple) visual concepts, generalizing in human-like ways from just one image. We evaluated performance on a challenging one-shot classification task, where our model achieved a human-level error rate while substantially outperforming two deep learning models. We also tested the model on another conceptual task, generating new examples, by using a \"visual Turing test\" to show that our model produces human-like performance."
            },
            "slug": "One-shot-learning-by-inverting-a-compositional-Lake-Salakhutdinov",
            "title": {
                "fragments": [],
                "text": "One-shot learning by inverting a compositional causal process"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A Hierarchical Bayesian model based on com-positionality and causality that can learn a wide range of natural (although simple) visual concepts, generalizing in human-like ways from just one image."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3073217"
                        ],
                        "name": "G. Monfardini",
                        "slug": "G.-Monfardini",
                        "structuredName": {
                            "firstName": "Gabriele",
                            "lastName": "Monfardini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Monfardini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260481"
                        ],
                        "name": "F. Scarselli",
                        "slug": "F.-Scarselli",
                        "structuredName": {
                            "firstName": "Franco",
                            "lastName": "Scarselli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Scarselli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 98
                            }
                        ],
                        "text": "There has been a lot of work in end-to-end learning on graphs or neural network trained on graphs [31, 2, 6, 11, 25, 22, 9, 21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 257
                            }
                        ],
                        "text": "Several papers have found success using variants of Graph Neural Networks applied to various simple domains such as quantitative structureproperty relationship (QSPR) analysis in chemistry [22] and subgraph matching and other graph problems on toy datasets [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20480879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ca9f28676ad788d04ba24a51141a9a0a0df4d67",
            "isKey": false,
            "numCitedBy": 951,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In several applications the information is naturally represented by graphs. Traditional approaches cope with graphical data structures using a preprocessing phase which transforms the graphs into a set of flat vectors. However, in this way, important topological information may be lost and the achieved results may heavily depend on the preprocessing stage. This paper presents a new neural model, called graph neural network (GNN), capable of directly processing graphs. GNNs extends recursive neural networks and can be applied on most of the practically useful kinds of graphs, including directed, undirected, labelled and cyclic graphs. A learning algorithm for GNNs is proposed and some experiments are discussed which assess the properties of the model."
            },
            "slug": "A-new-model-for-learning-in-graph-domains-Gori-Monfardini",
            "title": {
                "fragments": [],
                "text": "A new model for learning in graph domains"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new neural model, called graph neural network (GNN), capable of directly processing graphs, which extends recursive neural networks and can be applied on most of the practically useful kinds of graphs, including directed, undirected, labelled and cyclic graphs."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806773"
                        ],
                        "name": "Ishan Misra",
                        "slug": "Ishan-Misra",
                        "structuredName": {
                            "firstName": "Ishan",
                            "lastName": "Misra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ishan Misra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699161"
                        ],
                        "name": "C. L. Zitnick",
                        "slug": "C.-L.-Zitnick",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Zitnick",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Zitnick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49501003"
                        ],
                        "name": "Margaret Mitchell",
                        "slug": "Margaret-Mitchell",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Mitchell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Margaret Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "We train and test in the multi-label setting [24], and evaluate on the minival set [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3039286,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a0a00380c13002b330c70be2802904c4f31064f",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "When human annotators are given a choice about what to label in an image, they apply their own subjective judgments on what to ignore and what to mention. We refer to these noisy \"human-centric\" annotations as exhibiting human reporting bias. Examples of such annotations include image tags and keywords found on photo sharing sites, or in datasets containing image captions. In this paper, we use these noisy annotations for learning visually correct image classifiers. Such annotations do not use consistent vocabulary, and miss a significant amount of the information present in an image, however, we demonstrate that the noise in these annotations exhibits structure and can be modeled. We propose an algorithm to decouple the human reporting bias from the correct visually grounded labels. Our results are highly interpretable for reporting \"what's in the image\" versus \"what's worth saying.\" We demonstrate the algorithm's efficacy along a variety of metrics and datasets, including MS COCO and Yahoo Flickr 100M.We show significant improvements over traditional algorithms for both image classification and image captioning, doubling the performance of existing methods in some cases."
            },
            "slug": "Seeing-through-the-Human-Reporting-Bias:-Visual-Misra-Zitnick",
            "title": {
                "fragments": [],
                "text": "Seeing through the Human Reporting Bias: Visual Classifiers from Noisy Human-Centric Labels"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes an algorithm to decouple the human reporting bias from the correct visually grounded labels, and shows significant improvements over traditional algorithms for both image classification and image captioning, doubling the performance of existing methods in some cases."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3253737"
                        ],
                        "name": "Fereshteh Sadeghi",
                        "slug": "Fereshteh-Sadeghi",
                        "structuredName": {
                            "firstName": "Fereshteh",
                            "lastName": "Sadeghi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fereshteh Sadeghi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2038685"
                        ],
                        "name": "S. Divvala",
                        "slug": "S.-Divvala",
                        "structuredName": {
                            "firstName": "Santosh",
                            "lastName": "Divvala",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Divvala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143787583"
                        ],
                        "name": "Ali Farhadi",
                        "slug": "Ali-Farhadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Farhadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Farhadi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 39
                            }
                        ],
                        "text": "Related Work Learning knowledge graphs [4, 3, 30] and using graphs for visual reasoning [37, 20] has recently been of interest to the vision community."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14422948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "495015d21c26eac9a6bd64c836ee3370283641ec",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "How can we know whether a statement about our world is valid. For example, given a relationship between a pair of entities e.g., `eat(horse, hay)', how can we know whether this relationship is true or false in general. Gathering such knowledge about entities and their relationships is one of the fundamental challenges in knowledge extraction. Most previous works on knowledge extraction have focused purely on text-driven reasoning for verifying relation phrases. In this work, we introduce the problem of visual verification of relation phrases and developed a Visual Knowledge Extraction system called VisKE. Given a verb-based relation phrase between common nouns, our approach assess its validity by jointly analyzing over text and images and reasoning about the spatial consistency of the relative configurations of the entities and the relation involved. Our approach involves no explicit human supervision thereby enabling large-scale analysis. Using our approach, we have already verified over 12000 relation phrases. Our approach has been used to not only enrich existing textual knowledge bases by improving their recall, but also augment open-domain question-answer reasoning."
            },
            "slug": "VisKE:-Visual-knowledge-extraction-and-question-by-Sadeghi-Divvala",
            "title": {
                "fragments": [],
                "text": "VisKE: Visual knowledge extraction and question answering by visual verification of relation phrases"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work introduces the problem of visual verification of relation phrases and developed a Visual Knowledge Extraction system called VisKE, which has been used to not only enrich existing textual knowledge bases by improving their recall, but also augment open-domain question-answer reasoning."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045340"
                        ],
                        "name": "Tomasz Malisiewicz",
                        "slug": "Tomasz-Malisiewicz",
                        "structuredName": {
                            "firstName": "Tomasz",
                            "lastName": "Malisiewicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomasz Malisiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[20] builds a graph of exemplars for different categories and uses the spatial relationships to perform contextual reasoning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 88
                            }
                        ],
                        "text": "Related Work Learning knowledge graphs [4, 3, 30] and using graphs for visual reasoning [37, 20] has recently been of interest to the vision community."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11928049,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "6f99696049ebb0df7a20dbaa099b41833e6dca17",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of context is critical for scene understanding in computer vision, where the recognition of an object is driven by both local appearance and the object's relationship to other elements of the scene (context). Most current approaches rely on modeling the relationships between object categories as a source of context. In this paper we seek to move beyond categories to provide a richer appearance-based model of context. We present an exemplar-based model of objects and their relationships, the Visual Memex, that encodes both local appearance and 2D spatial context between object instances. We evaluate our model on Torralba's proposed Context Challenge against a baseline category-based system. Our experiments suggest that moving beyond categories for context modeling appears to be quite beneficial, and may be the critical missing ingredient in scene understanding systems."
            },
            "slug": "Beyond-Categories:-The-Visual-Memex-Model-for-About-Malisiewicz-Efros",
            "title": {
                "fragments": [],
                "text": "Beyond Categories: The Visual Memex Model for Reasoning About Object Relationships"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An exemplar-based model of objects and their relationships is presented, the Visual Memex, that encodes both local appearance and 2D spatial context between object instances and may be the critical missing ingredient in scene understanding systems."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33493200"
                        ],
                        "name": "Tsung-Yi Lin",
                        "slug": "Tsung-Yi-Lin",
                        "structuredName": {
                            "firstName": "Tsung-Yi",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsung-Yi Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48966748"
                        ],
                        "name": "James Hays",
                        "slug": "James-Hays",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hays",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Hays"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699161"
                        ],
                        "name": "C. L. Zitnick",
                        "slug": "C.-L.-Zitnick",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Zitnick",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Zitnick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "The node level outputs can then just be computed as\nov = g(h (T ) v , xv) (7)\nwhere g is a fully connected network, the output network, and xv is the original annotation for the node."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our method significantly out-\nperforms baselines for multi-label classification both in full data and low-data settings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14113767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71b7178df5d2b112d07e45038cb5637208659ff7",
            "isKey": false,
            "numCitedBy": 19780,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model."
            },
            "slug": "Microsoft-COCO:-Common-Objects-in-Context-Lin-Maire",
            "title": {
                "fragments": [],
                "text": "Microsoft COCO: Common Objects in Context"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding by gathering images of complex everyday scenes containing common objects in their natural context."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143787583"
                        ],
                        "name": "Ali Farhadi",
                        "slug": "Ali-Farhadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Farhadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Farhadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831988"
                        ],
                        "name": "Ian Endres",
                        "slug": "Ian-Endres",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Endres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Endres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "Our work is also related to attribute approaches [8] to vision such as [16] which uses a fixed set of binary attributes to do zero-shot prediction, [34] which uses attributes shared across categories to prevent semantic drift in semi-supervised learning and [5] which automatically discovers attributes and uses them for fine-grained classification."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14940757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6a8aef1bf134294482d8088f982d5643347d2ff",
            "isKey": false,
            "numCitedBy": 1665,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose to shift the goal of recognition from naming to describing. Doing so allows us not only to name familiar objects, but also: to report unusual aspects of a familiar object (\u201cspotty dog\u201d, not just \u201cdog\u201d); to say something about unfamiliar objects (\u201chairy and four-legged\u201d, not just \u201cunknown\u201d); and to learn how to recognize new objects with few or no visual examples. Rather than focusing on identity assignment, we make inferring attributes the core problem of recognition. These attributes can be semantic (\u201cspotty\u201d) or discriminative (\u201cdogs have it but sheep do not\u201d). Learning attributes presents a major new challenge: generalization across object categories, not just across instances within a category. In this paper, we also introduce a novel feature selection method for learning attributes that generalize well across categories. We support our claims by thorough evaluation that provides insights into the limitations of the standard recognition paradigm of naming and demonstrates the new abilities provided by our attribute-based framework."
            },
            "slug": "Describing-objects-by-their-attributes-Farhadi-Endres",
            "title": {
                "fragments": [],
                "text": "Describing objects by their attributes"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper proposes to shift the goal of recognition from naming to describing, and introduces a novel feature selection method for learning attributes that generalize well across categories."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781242"
                        ],
                        "name": "Abhinav Shrivastava",
                        "slug": "Abhinav-Shrivastava",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Shrivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhinav Shrivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108498897"
                        ],
                        "name": "Saurabh Singh",
                        "slug": "Saurabh-Singh",
                        "structuredName": {
                            "firstName": "Saurabh",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saurabh Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2651840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3e629351f8da2f465f77d1a3efca828d1f25c03",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of semi-supervised bootstrap learning for scene categorization. Existing semi-supervised approaches are typically unreliable and face semantic drift because the learning task is under-constrained. This is primarily because they ignore the strong interactions that often exist between scene categories, such as the common attributes shared across categories as well as the attributes which make one scene different from another. The goal of this paper is to exploit these relationships and constrain the semi-supervised learning problem. For example, the knowledge that an image is an auditorium can improve labeling of amphitheaters by enforcing constraint that an amphitheater image should have more circular structures than an auditorium image. We propose constraints based on mutual exclusion, binary attributes and comparative attributes and show that they help us to constrain the learning problem and avoid semantic drift. We demonstrate the effectiveness of our approach through extensive experiments, including results on a very large dataset of one million images."
            },
            "slug": "Constrained-Semi-Supervised-Learning-Using-and-Shrivastava-Singh",
            "title": {
                "fragments": [],
                "text": "Constrained Semi-Supervised Learning Using Attributes and Comparative Attributes"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Constraints based on mutual exclusion, binary attributes and comparative attributes are proposed and show that they help to constrain the learning problem and avoid semantic drift."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2091768"
                        ],
                        "name": "Kelvin Guu",
                        "slug": "Kelvin-Guu",
                        "structuredName": {
                            "firstName": "Kelvin",
                            "lastName": "Guu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kelvin Guu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116337165"
                        ],
                        "name": "John Miller",
                        "slug": "John-Miller",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145419642"
                        ],
                        "name": "Percy Liang",
                        "slug": "Percy-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Percy Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "Using the subset of WordNet from [10], we first collect new nodes in WordNet not in our output label by including those which directly connect to our output labels and thus likely to be relevant and add them to a combined graph."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14170854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e745b0506f4133263633eb05e5006a8cff4129f0",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Path queries on a knowledge graph can be used to answer compositional questions such as \"What languages are spoken by people living in Lisbon?\". However, knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new \"compositional\" training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. On a standard knowledge base completion task, we also demonstrate that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results."
            },
            "slug": "Traversing-Knowledge-Graphs-in-Vector-Space-Guu-Miller",
            "title": {
                "fragments": [],
                "text": "Traversing Knowledge Graphs in Vector Space"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is demonstrated that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115231104"
                        ],
                        "name": "Justin Johnson",
                        "slug": "Justin-Johnson",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Justin Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237361"
                        ],
                        "name": "Ranjay Krishna",
                        "slug": "Ranjay-Krishna",
                        "structuredName": {
                            "firstName": "Ranjay",
                            "lastName": "Krishna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ranjay Krishna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144421225"
                        ],
                        "name": "Michael Stark",
                        "slug": "Michael-Stark",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Stark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Stark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760364"
                        ],
                        "name": "David A. Shamma",
                        "slug": "David-A.-Shamma",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Shamma",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Shamma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145879842"
                        ],
                        "name": "Michael S. Bernstein",
                        "slug": "Michael-S.-Bernstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bernstein",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael S. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "There has also been some work using a knowledge base for image retrieval [12] or answering visual queries [39], but these works are focused on building and then querying knowledge bases rather than using existing knowledge bases as side information for some vision task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16414666,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85ae705ef4353c6854f5be4a4664269d6317c66b",
            "isKey": false,
            "numCitedBy": 635,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops a novel framework for semantic image retrieval based on the notion of a scene graph. Our scene graphs represent objects (\u201cman\u201d, \u201cboat\u201d), attributes of objects (\u201cboat is white\u201d) and relationships between objects (\u201cman standing on boat\u201d). We use these scene graphs as queries to retrieve semantically related images. To this end, we design a conditional random field model that reasons about possible groundings of scene graphs to test images. The likelihoods of these groundings are used as ranking scores for retrieval. We introduce a novel dataset of 5,000 human-generated scene graphs grounded to images and use this dataset to evaluate our method for image retrieval. In particular, we evaluate retrieval using full scene graphs and small scene subgraphs, and show that our method outperforms retrieval methods that use only objects or low-level image features. In addition, we show that our full model can be used to improve object localization compared to baseline methods."
            },
            "slug": "Image-retrieval-using-scene-graphs-Johnson-Krishna",
            "title": {
                "fragments": [],
                "text": "Image retrieval using scene graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A conditional random field model that reasons about possible groundings of scene graphs to test images and shows that the full model can be used to improve object localization compared to baseline methods and outperforms retrieval methods that use only objects or low-level image features."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1914797"
                        ],
                        "name": "N. Lao",
                        "slug": "N.-Lao",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Lao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Approaches such as [17] use random walks on the graphs to learn patterns of edges while performing the walk and predict new edges in the knowledge graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1619841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2aea6cc6c42101b2615753c2933a33e57dd665f2",
            "isKey": false,
            "numCitedBy": 521,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of performing learning and inference in a large scale knowledge base containing imperfect knowledge with incomplete coverage. We show that a soft inference procedure based on a combination of constrained, weighted, random walks through the knowledge base graph can be used to reliably infer new beliefs for the knowledge base. More specifically, we show that the system can learn to infer different target relations by tuning the weights associated with random walks that follow different paths through the graph, using a version of the Path Ranking Algorithm (Lao and Cohen, 2010b). We apply this approach to a knowledge base of approximately 500,000 beliefs extracted imperfectly from the web by NELL, a never-ending language learner (Carlson et al., 2010). This new system improves significantly over NELL's earlier Horn-clause learning and inference method: it obtains nearly double the precision at rank 100, and the new learning method is also applicable to many more inference tasks."
            },
            "slug": "Random-Walk-Inference-and-Learning-in-A-Large-Scale-Lao-Mitchell",
            "title": {
                "fragments": [],
                "text": "Random Walk Inference and Learning in A Large Scale Knowledge Base"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a soft inference procedure based on a combination of constrained, weighted, random walks through the knowledge base graph can be used to reliably infer new beliefs for theknowledge base."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260481"
                        ],
                        "name": "F. Scarselli",
                        "slug": "F.-Scarselli",
                        "structuredName": {
                            "firstName": "Franco",
                            "lastName": "Scarselli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Scarselli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733691"
                        ],
                        "name": "A. Tsoi",
                        "slug": "A.-Tsoi",
                        "structuredName": {
                            "firstName": "Ah",
                            "lastName": "Tsoi",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784450"
                        ],
                        "name": "M. Hagenbuchner",
                        "slug": "M.-Hagenbuchner",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Hagenbuchner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hagenbuchner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3073217"
                        ],
                        "name": "G. Monfardini",
                        "slug": "G.-Monfardini",
                        "structuredName": {
                            "firstName": "Gabriele",
                            "lastName": "Monfardini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Monfardini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "This paper (an extension of Graph Neural Networks [31]) serves as the foundation for our Graph Search Neural Network (GSNN)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 71
                            }
                        ],
                        "text": "Our new architecture mitigates the computational issues with the Gated Graph Neural Networks for large graphs which allows our model to be efficiently trained for image tasks using large knowledge graphs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 52
                            }
                        ],
                        "text": "Several papers have found success using variants of Graph Neural Networks applied to various simple domains such as quantitative structureproperty relationship (QSPR) analysis in chemistry [22] and subgraph matching and other graph problems on toy datasets [9]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 98
                            }
                        ],
                        "text": "There has been a lot of work in end-to-end learning on graphs or neural network trained on graphs [31, 2, 6, 11, 25, 22, 9, 21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 35
                            }
                        ],
                        "text": "This paper (itself an extension of Graph Neural Networks [30]) serves as the foundation for our Graph Search Neural Network (GSNN)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206756462,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3efd851140aa28e95221b55fcc5659eea97b172d",
            "isKey": true,
            "numCitedBy": 3206,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities."
            },
            "slug": "The-Graph-Neural-Network-Model-Scarselli-Gori",
            "title": {
                "fragments": [],
                "text": "The Graph Neural Network Model"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains, and implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47002813"
                        ],
                        "name": "Yujia Li",
                        "slug": "Yujia-Li",
                        "structuredName": {
                            "firstName": "Yujia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yujia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725299"
                        ],
                        "name": "Daniel Tarlow",
                        "slug": "Daniel-Tarlow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Tarlow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Tarlow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107692"
                        ],
                        "name": "Marc Brockschmidt",
                        "slug": "Marc-Brockschmidt",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Brockschmidt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Brockschmidt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "An example of this is the Gated Graph Neural Network [18] which takes an arbitrary graph as input."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 65
                            }
                        ],
                        "text": "Our new architecture mitigates the computational issues with the Gated Graph Neural Networks for large graphs which allows our model to be efficiently trained for image tasks using large knowledge graphs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "Forward propagation on the standard GGNN isO(N2) to the number of nodesN and backward propagation is O(NT ) where T is the number of propagation steps."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "Li and Zemel present Graph Gated Neural Networks (GGNN) [18] which uses neural networks on graph structured data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "For instance, for the problem of graph reachability, GGNN is given a graph, a start node and end node, and the GGNN will have to output whether the end node is reachable from the start node."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In GGNN, the per-node output function g(h(T )v , xv) takes in the hidden state and initial annotation of the node v to compute its output."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "GGNN is a fully end-to-end network that takes as input a directed graph and outputs either a classification over the entire graph or an output for each node."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Clearly using GGNN out of the box is infeasible."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "We perform simple experiments on GGNNs on synthetic graphs and find that after more than about 500 nodes, a forward and backward pass takes over 1 second on a single instance, even when making generous parameter assumptions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "The idea of GGNN is that given a graph with N nodes, we want to produce some output which can either be an output for every graph node o1, o2, ...oN or a global output oG."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "The biggest problem in adapting GGNN for image tasks is computational scalability."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8393918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "492f57ee9ceb61fb5a47ad7aebfec1121887a175",
            "isKey": true,
            "numCitedBy": 1968,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract: Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures."
            },
            "slug": "Gated-Graph-Sequence-Neural-Networks-Li-Tarlow",
            "title": {
                "fragments": [],
                "text": "Gated Graph Sequence Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work studies feature learning techniques for graph-structured inputs and achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2032184078"
                        ],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "We train and test in the multi-label setting [24], and evaluate on the minival set [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 35
                            }
                        ],
                        "text": "For our experiments, we use Faster R-CNN [27] for each of the 80 COCO categories."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 157
                            }
                        ],
                        "text": "We also concatenate this feature vector with fc7 layer (4096-dim) of fine-tuned VGG-16 network [34] and top-score for each COCO category predicted by Faster R-CNN (80-dim)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "For our experiments, we use Faster R-CNN [28] for each of the 80 COCO categories."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10328909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
            "isKey": true,
            "numCitedBy": 32562,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available"
            },
            "slug": "Faster-R-CNN:-Towards-Real-Time-Object-Detection-Ren-He",
            "title": {
                "fragments": [],
                "text": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work introduces a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals and further merge RPN and Fast R-CNN into a single network by sharing their convolutionAL features."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34750387"
                        ],
                        "name": "V. Massa",
                        "slug": "V.-Massa",
                        "structuredName": {
                            "firstName": "Vincenzo",
                            "lastName": "Massa",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Massa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3073217"
                        ],
                        "name": "G. Monfardini",
                        "slug": "G.-Monfardini",
                        "structuredName": {
                            "firstName": "Gabriele",
                            "lastName": "Monfardini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Monfardini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608269"
                        ],
                        "name": "L. Sarti",
                        "slug": "L.-Sarti",
                        "structuredName": {
                            "firstName": "Lorenzo",
                            "lastName": "Sarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sarti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260481"
                        ],
                        "name": "F. Scarselli",
                        "slug": "F.-Scarselli",
                        "structuredName": {
                            "firstName": "Franco",
                            "lastName": "Scarselli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Scarselli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35251916"
                        ],
                        "name": "Marco Maggini",
                        "slug": "Marco-Maggini",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Maggini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Maggini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "Given some initialization (annotation specific to the task such as starting and ending node for shortest path), it learns how to propagate information and predict the output for every node in the graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15143034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a725e8cf01b687a1d61ba8d9b760f4e0c0a3c50d",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Recursive neural networks (RNNs) and graph neural networks (GNNs) are two connectionist models that can directly process graphs. RNNs and GNNs exploit a similar processing framework, but they can be applied to different input domains. RNNs require the input graphs to be directed and acyclic, whereas GNNs can process any kind of graphs. The aim of this paper consists in understanding whether such a difference affects the behaviour of the models on a real application. An experimental comparison on an image classification problem is presented, showing that GNNs outperforms RNNs. Moreover the main differences between the models are also discussed w.r.t. their input domains, their approximation capabilities and their learning algorithms."
            },
            "slug": "A-Comparison-between-Recursive-Neural-Networks-and-Massa-Monfardini",
            "title": {
                "fragments": [],
                "text": "A Comparison between Recursive Neural Networks and Graph Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An experimental comparison on an image classification problem is presented, showing that GNNs outperforms RNNs, and the main differences between the models are discussed w.r.t. their input domains, their approximation capabilities and their learning algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "The 2006 IEEE International Joint Conference on Neural Network Proceedings"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41231471"
                        ],
                        "name": "A. Micheli",
                        "slug": "A.-Micheli",
                        "structuredName": {
                            "firstName": "Alessio",
                            "lastName": "Micheli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Micheli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 98
                            }
                        ],
                        "text": "There has been a lot of work in end-to-end learning on graphs or neural network trained on graphs [31, 2, 6, 11, 25, 22, 9, 21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 189
                            }
                        ],
                        "text": "Several papers have found success using variants of Graph Neural Networks applied to various simple domains such as quantitative structureproperty relationship (QSPR) analysis in chemistry [22] and subgraph matching and other graph problems on toy datasets [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17486263,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec2b2569b3a0d70a5b45d48b041dec9060d85eb7",
            "isKey": false,
            "numCitedBy": 275,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach for learning in structured domains (SDs) using a constructive neural network for graphs (NN4G). The new model allows the extension of the input domain for supervised neural networks to a general class of graphs including both acyclic/cyclic, directed/undirected labeled graphs. In particular, the model can realize adaptive contextual transductions, learning the mapping from graphs for both classification and regression tasks. In contrast to previous neural networks for structures that had a recursive dynamics, NN4G is based on a constructive feedforward architecture with state variables that uses neurons with no feedback connections. The neurons are applied to the input graphs by a general traversal process that relaxes the constraints of previous approaches derived by the causality assumption over hierarchical input data. Moreover, the incremental approach eliminates the need to introduce cyclic dependencies in the definition of the system state variables. In the traversal process, the NN4G units exploit (local) contextual information of the graphs vertices. In spite of the simplicity of the approach, we show that, through the compositionality of the contextual information developed by the learning, the model can deal with contextual information that is incrementally extended according to the graphs topology. The effectiveness and the generality of the new approach are investigated by analyzing its theoretical properties and providing experimental results."
            },
            "slug": "Neural-Network-for-Graphs:-A-Contextual-Approach-Micheli",
            "title": {
                "fragments": [],
                "text": "Neural Network for Graphs: A Contextual Constructive Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The new model allows the extension of the input domain for supervised neural networks to a general class of graphs including both acyclic/cyclic, directed/undirected labeled graphs and can realize adaptive contextual transductions, learning the mapping from graphs for both classification and regression tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704657"
                        ],
                        "name": "D. Duvenaud",
                        "slug": "D.-Duvenaud",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Duvenaud",
                            "middleNames": [
                                "Kristjanson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Duvenaud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683298"
                        ],
                        "name": "D. Maclaurin",
                        "slug": "D.-Maclaurin",
                        "structuredName": {
                            "firstName": "Dougal",
                            "lastName": "Maclaurin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maclaurin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1422175619"
                        ],
                        "name": "J. Aguilera-Iparraguirre",
                        "slug": "J.-Aguilera-Iparraguirre",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Aguilera-Iparraguirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aguilera-Iparraguirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398336096"
                        ],
                        "name": "Rafael G\u00f3mez-Bombarelli",
                        "slug": "Rafael-G\u00f3mez-Bombarelli",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "G\u00f3mez-Bombarelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rafael G\u00f3mez-Bombarelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916942"
                        ],
                        "name": "Timothy D. Hirzel",
                        "slug": "Timothy-D.-Hirzel",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Hirzel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy D. Hirzel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1380248954"
                        ],
                        "name": "Al\u00e1n Aspuru-Guzik",
                        "slug": "Al\u00e1n-Aspuru-Guzik",
                        "structuredName": {
                            "firstName": "Al\u00e1n",
                            "lastName": "Aspuru-Guzik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Al\u00e1n Aspuru-Guzik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 292
                            }
                        ],
                        "text": "Several works treat graphs as a special case of a convolutional input where, instead of pixel inputs connected to pixels in a grid, we define the inputs as connected by an input graph, relying on either some global graph structure or doings some sort of pre-processing on graph edges [3, 6, 11, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Given some initialization (annotation specific to the task such as starting and ending node for shortest path), it learns how to propagate information and predict the output for every node in the graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1690180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d1bfeed240709725c78bc72ea40e55410b373dc",
            "isKey": false,
            "numCitedBy": 2232,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a convolutional neural network that operates directly on graphs. These networks allow end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape. The architecture we present generalizes standard molecular feature extraction methods based on circular fingerprints. We show that these data-driven features are more interpretable, and have better predictive performance on a variety of tasks."
            },
            "slug": "Convolutional-Networks-on-Graphs-for-Learning-Duvenaud-Maclaurin",
            "title": {
                "fragments": [],
                "text": "Convolutional Networks on Graphs for Learning Molecular Fingerprints"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A convolutional neural network that operates directly on graphs that allows end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32015491"
                        ],
                        "name": "Xiangxin Zhu",
                        "slug": "Xiangxin-Zhu",
                        "structuredName": {
                            "firstName": "Xiangxin",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangxin Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838674"
                        ],
                        "name": "Dragomir Anguelov",
                        "slug": "Dragomir-Anguelov",
                        "structuredName": {
                            "firstName": "Dragomir",
                            "lastName": "Anguelov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dragomir Anguelov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "While some visual concepts are very common such as person or car, most categories have many fewer examples, forming a long-tail distribution [37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 248
                            }
                        ],
                        "text": "For our experiments, we wanted to test on a dataset that represents the complex, noisy visual world with its many different kinds of objects, where labels are potentially ambiguous and overlapping, and categories fall into a long-tail distribution [37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 88
                            }
                        ],
                        "text": "Related Work Learning knowledge graphs [4, 3, 30] and using graphs for visual reasoning [37, 20] has recently been of interest to the vision community."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 338368,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45510f80bf9654e186e0ecab7c33daaf0b317d72",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We argue that object subcategories follow a long-tail distribution: a few subcategories are common, while many are rare. We describe distributed algorithms for learning large- mixture models that capture long-tail distributions, which are hard to model with current approaches. We introduce a generalized notion of mixtures (or subcategories) that allow for examples to be shared across multiple subcategories. We optimize our models with a discriminative clustering algorithm that searches over mixtures in a distributed, \"brute-force\" fashion. We used our scalable system to train tens of thousands of deformable mixtures for VOC objects. We demonstrate significant performance improvements, particularly for object classes that are characterized by large appearance variation."
            },
            "slug": "Capturing-Long-Tail-Distributions-of-Object-Zhu-Anguelov",
            "title": {
                "fragments": [],
                "text": "Capturing Long-Tail Distributions of Object Subcategories"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This work proposes distributed algorithms for learning large- mixture models that capture long-tail distributions, which are hard to model with current approaches, and introduces a generalized notion of mixtures (or subcategories) that allow for examples to be shared across multiple subc categories."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137679"
                        ],
                        "name": "Pinar Yanardag",
                        "slug": "Pinar-Yanardag",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Yanardag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pinar Yanardag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145713876"
                        ],
                        "name": "S. Vishwanathan",
                        "slug": "S.-Vishwanathan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Vishwanathan",
                            "middleNames": [
                                "V.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vishwanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "is also a substantial amount of work on various types of kernels de\ufb01ned for graphs [36] such as diffusion kernels [14], graphlet kernels [33], Weisfeiler-Lehman graph kernels [32], deep graph kernels [27], graph invariant kernels [26] and shortest-path kernels [1]. The methods have various ways of exploiting common graph structures, however, these approaches are only helpful for kernel-based approache"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207227372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00d736c540f80582279093cfc5ffe454a3226da9",
            "isKey": false,
            "numCitedBy": 760,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present Deep Graph Kernels, a unified framework to learn latent representations of sub-structures for graphs, inspired by latest advancements in language modeling and deep learning. Our framework leverages the dependency information between sub-structures by learning their latent representations. We demonstrate instances of our framework on three popular graph kernels, namely Graphlet kernels, Weisfeiler-Lehman subtree kernels, and Shortest-Path graph kernels. Our experiments on several benchmark datasets show that Deep Graph Kernels achieve significant improvements in classification accuracy over state-of-the-art graph kernels."
            },
            "slug": "Deep-Graph-Kernels-Yanardag-Vishwanathan",
            "title": {
                "fragments": [],
                "text": "Deep Graph Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A unified framework to learn latent representations of sub-structures for graphs, inspired by latest advancements in language modeling and deep learning, which achieves significant improvements in classification accuracy over state-of-the-art graph kernels."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704422"
                        ],
                        "name": "K. Borgwardt",
                        "slug": "K.-Borgwardt",
                        "structuredName": {
                            "firstName": "Karsten",
                            "lastName": "Borgwardt",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Borgwardt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688561"
                        ],
                        "name": "H. Kriegel",
                        "slug": "H.-Kriegel",
                        "structuredName": {
                            "firstName": "Hans-Peter",
                            "lastName": "Kriegel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kriegel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 268
                            }
                        ],
                        "text": "There is also a substantial amount of work on various types of kernels defined for graphs [36] such as diffusion kernels [14], graphlet kernels [33], Weisfeiler-Lehman graph kernels [32], deep graph kernels [27], graph invariant kernels [26] and shortest-path kernels [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1550330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ff05e93f4eaeef4b8b51ba4e11d1c4cdf856ca",
            "isKey": false,
            "numCitedBy": 798,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Data mining algorithms are facing the challenge to deal with an increasing number of complex objects. For graph data, a whole toolbox of data mining algorithms becomes available by defining a kernel function on instances of graphs. Graph kernels based on walks, subtrees and cycles in graphs have been proposed so far. As a general problem, these kernels are either computationally expensive or limited in their expressiveness. We try to overcome this problem by defining expressive graph kernels which are based on paths. As the computation of all paths and longest paths in a graph is NP-hard, we propose graph kernels based on shortest paths. These kernels are computable in polynomial time, retain expressivity and are still positive definite. In experiments on classification of graph models of proteins, our shortest-path kernels show significantly higher classification accuracy than walk-based kernels."
            },
            "slug": "Shortest-path-kernels-on-graphs-Borgwardt-Kriegel",
            "title": {
                "fragments": [],
                "text": "Shortest-path kernels on graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This work proposes graph kernels based on shortest paths, which are computable in polynomial time, retain expressivity and are still positive definite, and shows significantly higher classification accuracy than walk-based kernels."
            },
            "venue": {
                "fragments": [],
                "text": "Fifth IEEE International Conference on Data Mining (ICDM'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145713874"
                        ],
                        "name": "S. Vishwanathan",
                        "slug": "S.-Vishwanathan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Vishwanathan",
                            "middleNames": [
                                "V.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vishwanathan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739396"
                        ],
                        "name": "N. Schraudolph",
                        "slug": "N.-Schraudolph",
                        "structuredName": {
                            "firstName": "Nicol",
                            "lastName": "Schraudolph",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Schraudolph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2834541"
                        ],
                        "name": "R. Kondor",
                        "slug": "R.-Kondor",
                        "structuredName": {
                            "firstName": "Risi",
                            "lastName": "Kondor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kondor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704422"
                        ],
                        "name": "K. Borgwardt",
                        "slug": "K.-Borgwardt",
                        "structuredName": {
                            "firstName": "Karsten",
                            "lastName": "Borgwardt",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Borgwardt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "There is also a substantial amount of work on various types of kernels defined for graphs [36] such as diffusion kernels [14], graphlet kernels [33], Weisfeiler-Lehman graph kernels [32], deep graph kernels [27], graph invariant kernels [26] and shortest-path kernels [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1729012,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "0ed97826dec2ae59a10da5dd5b9bae8e0164b624",
            "isKey": false,
            "numCitedBy": 952,
            "numCiting": 241,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a unified framework to study graph kernels, special cases of which include the random walk (Gartner et al., 2003; Borgwardt et al., 2005) and marginalized (Kashima et al., 2003, 2004; Mahet al., 2004) graph kernels. Through reduction to a Sylvester equation we improve the time complexity of kernel computation between unlabeled graphs with n vertices from O(n6) to O(n3). We find a spectral decomposition approach even more efficient when computing entire kernel matrices. For labeled graphs we develop conjugate gradient and fixed-point methods that take O(dn3) time per iteration, where d is the size of the label set. By extending the necessary linear algebra to Reproducing Kernel Hilbert Spaces (RKHS) we obtain the same result for d-dimensional edge kernels, and O(n4) in the infinite-dimensional case; on sparse graphs these algorithms only take O(n2) time per iteration in all cases. Experiments on graphs from bioinformatics and other application domains show that these techniques can speed up computation of the kernel by an order of magnitude or more. We also show that certain rational kernels (Cortes et al., 2002, 2003, 2004) when specialized to graphs reduce to our random walk graph kernel. Finally, we relate our framework to R-convolution kernels (Haussler, 1999) and provide a kernel that is close to the optimal assignment kernel of kernel of Frohlich et al. (2006) yet provably positive semi-definite."
            },
            "slug": "Graph-Kernels-Vishwanathan-Schraudolph",
            "title": {
                "fragments": [],
                "text": "Graph Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A unified framework to study graph kernels is presented and a kernel that is close to the optimal assignment kernel of kernel of Frohlich et al. (2006) yet provably positive semi-definite is provided."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1898417"
                        ],
                        "name": "N. Shervashidze",
                        "slug": "N.-Shervashidze",
                        "structuredName": {
                            "firstName": "Nino",
                            "lastName": "Shervashidze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Shervashidze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31500557"
                        ],
                        "name": "Pascal Schweitzer",
                        "slug": "Pascal-Schweitzer",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Schweitzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Schweitzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711983"
                        ],
                        "name": "E. J. V. Leeuwen",
                        "slug": "E.-J.-V.-Leeuwen",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Leeuwen",
                            "middleNames": [
                                "Jan",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. J. V. Leeuwen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698752"
                        ],
                        "name": "K. Mehlhorn",
                        "slug": "K.-Mehlhorn",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Mehlhorn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mehlhorn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704422"
                        ],
                        "name": "K. Borgwardt",
                        "slug": "K.-Borgwardt",
                        "structuredName": {
                            "firstName": "Karsten",
                            "lastName": "Borgwardt",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Borgwardt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ogram veri\ufb01cation. There is also a substantial amount of work on various types of kernels de\ufb01ned for graphs [36] such as diffusion kernels [14], graphlet kernels [33], Weisfeiler-Lehman graph kernels [32], deep graph kernels [27], graph invariant kernels [26] and shortest-path kernels [1]. The methods have various ways of exploiting common graph structures, however, these approaches are only helpful f"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1797579,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "7e1874986cf6433fabf96fff93ef42b60bdc49f8",
            "isKey": false,
            "numCitedBy": 1217,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we propose a family of efficient kernels for large graphs with discrete node labels. Key to our method is a rapid feature extraction scheme based on the Weisfeiler-Lehman test of isomorphism on graphs. It maps the original graph to a sequence of graphs, whose node attributes capture topological and label information. A family of kernels can be defined based on this Weisfeiler-Lehman sequence of graphs, including a highly efficient kernel comparing subtree-like patterns. Its runtime scales only linearly in the number of edges of the graphs and the length of the Weisfeiler-Lehman graph sequence. In our experimental evaluation, our kernels outperform state-of-the-art graph kernels on several graph classification benchmark data sets in terms of accuracy and runtime. Our kernels open the door to large-scale applications of graph kernels in various disciplines such as computational biology and social network analysis."
            },
            "slug": "Weisfeiler-Lehman-Graph-Kernels-Shervashidze-Schweitzer",
            "title": {
                "fragments": [],
                "text": "Weisfeiler-Lehman Graph Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A family of efficient kernels for large graphs with discrete node labels based on the Weisfeiler-Lehman test of isomorphism on graphs that outperform state-of-the-art graph kernels on several graph classification benchmark data sets in terms of accuracy and runtime."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1898417"
                        ],
                        "name": "N. Shervashidze",
                        "slug": "N.-Shervashidze",
                        "structuredName": {
                            "firstName": "Nino",
                            "lastName": "Shervashidze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Shervashidze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145713876"
                        ],
                        "name": "S. Vishwanathan",
                        "slug": "S.-Vishwanathan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Vishwanathan",
                            "middleNames": [
                                "V.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vishwanathan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70590076"
                        ],
                        "name": "T. Petri",
                        "slug": "T.-Petri",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Petri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698752"
                        ],
                        "name": "K. Mehlhorn",
                        "slug": "K.-Mehlhorn",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Mehlhorn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mehlhorn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704422"
                        ],
                        "name": "K. Borgwardt",
                        "slug": "K.-Borgwardt",
                        "structuredName": {
                            "firstName": "Karsten",
                            "lastName": "Borgwardt",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Borgwardt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17557614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7fc751cd95bd1a409a26daaef69fc3aa8a35e0e",
            "isKey": false,
            "numCitedBy": 749,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art graph kernels do not scale to large graphs with hundreds of nodes and thousands of edges. In this article we propose to compare graphs by counting graphlets, i.e., subgraphs with k nodes where k \u2208 {3, 4, 5}. Exhaustive enumeration of all graphlets being prohibitively expensive, we introduce two theoretically grounded speedup schemes, one based on sampling and the second one specifically designed for bounded degree graphs. In our experimental evaluation, our novel kernels allow us to efficiently compare large graphs that cannot be tackled by existing graph kernels."
            },
            "slug": "Efficient-graphlet-kernels-for-large-graph-Shervashidze-Vishwanathan",
            "title": {
                "fragments": [],
                "text": "Efficient graphlet kernels for large graph comparison"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "In this article, two theoretically grounded speedup schemes are introduced, one based on sampling and the second specifically designed for bounded degree graphs, to efficiently compare large graphs that cannot be tackled by existing graph kernels."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "All models are trained with Stochastic Gradient Descent, except GSNN which is trained using ADAM [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "We train the models using ADAM [13] with an initial learning rate of 10\u22123 for all networks, except the pre-trained VGG where we use an initial learning rate of 10\u22124, and an initial momentum of 0.9, except the GSNN which used 0."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": true,
            "numCitedBy": 90064,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143818235"
                        ],
                        "name": "Andrew Carlson",
                        "slug": "Andrew-Carlson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Carlson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Carlson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31779043"
                        ],
                        "name": "J. Betteridge",
                        "slug": "J.-Betteridge",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Betteridge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Betteridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16411658"
                        ],
                        "name": "B. Kisiel",
                        "slug": "B.-Kisiel",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Kisiel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kisiel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717452"
                        ],
                        "name": "Burr Settles",
                        "slug": "Burr-Settles",
                        "structuredName": {
                            "firstName": "Burr",
                            "lastName": "Settles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Burr Settles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1842532"
                        ],
                        "name": "Estevam Hruschka",
                        "slug": "Estevam-Hruschka",
                        "structuredName": {
                            "firstName": "Estevam",
                            "lastName": "Hruschka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Estevam Hruschka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8423494,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7312b8568d63bbbb239583ed282f46cdc40978d",
            "isKey": false,
            "numCitedBy": 1739,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider here the problem of building a never-ending language learner; that is, an intelligent computer agent that runs forever and that each day must (1) extract, or read, information from the web to populate a growing structured knowledge base, and (2) learn to perform this task better than on the previous day. In particular, we propose an approach and a set of design principles for such an agent, describe a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs with an estimated precision of 74% after running for 67 days, and discuss lessons learned from this preliminary attempt to build a never-ending learning agent."
            },
            "slug": "Toward-an-Architecture-for-Never-Ending-Language-Carlson-Betteridge",
            "title": {
                "fragments": [],
                "text": "Toward an Architecture for Never-Ending Language Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This work proposes an approach and a set of design principles for an intelligent computer agent that runs forever and describes a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069989250"
                        ],
                        "name": "Francesco Orsini",
                        "slug": "Francesco-Orsini",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Orsini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francesco Orsini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740042"
                        ],
                        "name": "L. D. Raedt",
                        "slug": "L.-D.-Raedt",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Raedt",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Raedt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 237
                            }
                        ],
                        "text": "There is also a substantial amount of work on various types of kernels defined for graphs [36] such as diffusion kernels [14], graphlet kernels [33], Weisfeiler-Lehman graph kernels [32], deep graph kernels [27], graph invariant kernels [26] and shortest-path kernels [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15486265,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1a9154d9718ae255a614ba32bcd5d248c0df4924",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel kernel that upgrades the Weisfeiler-Lehman and other graph kernels to effectively exploit high-dimensional and continuous vertex attributes. Graphs are first decomposed into subgraphs. Vertices of the subgraphs are then compared by a kernel that combines the similarity of their labels and the similarity of their structural role, using a suitable vertex invariant. By changing this invariant we obtain a family of graph kernels which includes generalizations of Weisfeiler-Lehman, NSPDK, and propagation kernels. We demonstrate empirically that these kernels obtain state-of-the-art results on relational data sets."
            },
            "slug": "Graph-Invariant-Kernels-Orsini-Frasconi",
            "title": {
                "fragments": [],
                "text": "Graph Invariant Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel kernel is introduced that upgrades the Weisfeiler-Lehman and other graph kernels to effectively exploit high-dimensional and continuous vertex attributes and demonstrates empirically that these kernels obtain state-of-the-art results on relational data sets."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "The node level outputs can then just be computed as\nov = g(h (T ) v , xv) (7)\nwhere g is a fully connected network, the output network, and xv is the original annotation for the node."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61615905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a2ed19ac684022aa3186887cd4893484ab8f80c",
            "isKey": false,
            "numCitedBy": 2169,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006). Details of the challenge, data, and evaluation are presented. Participants in the challenge submitted descriptions of their methods, and these have been included verbatim. This document should be considered preliminary, and subject to change."
            },
            "slug": "The-PASCAL-visual-object-classes-challenge-2006-Everingham-Zisserman",
            "title": {
                "fragments": [],
                "text": "The PASCAL visual object classes challenge 2006 (VOC2006) results"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2834541"
                        ],
                        "name": "R. Kondor",
                        "slug": "R.-Kondor",
                        "structuredName": {
                            "firstName": "Risi",
                            "lastName": "Kondor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kondor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "There is also a substantial amount of work on various types of kernels defined for graphs [36] such as diffusion kernels [14], graphlet kernels [33], Weisfeiler-Lehman graph kernels [32], deep graph kernels [27], graph invariant kernels [26] and shortest-path kernels [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5525836,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6320770fe216ebbba769b9f0a006669b616a03d0",
            "isKey": false,
            "numCitedBy": 888,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of kernel-based learning algorithms has, so far, largely been confined to realvalued data and a few special data types, such as strings. In this paper we propose a general method of constructing natural families of kernels over discrete structures, based on the matrix exponentiation idea. In particular, we focus on generating kernels on graphs, for which we propose a special class of exponential kernels called diffusion kernels, which are based on the heat equation and can be regarded as the discretization of the familiar Gaussian kernel of Euclidean space."
            },
            "slug": "Diffusion-Kernels-on-Graphs-and-Other-Discrete-Kondor-Lafferty",
            "title": {
                "fragments": [],
                "text": "Diffusion Kernels on Graphs and Other Discrete Input Spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes a general method of constructing natural families of kernels over discrete structures, based on the matrix exponentiation idea, and focuses on generating kernels on graphs, for which a special class of exponential kernels called diffusion kernels are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "This suggests that including the outside semantic knowledge from WordNet and performing explicit reasoning on a knowledge graph allows our model to learn better representations compared to the other models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "There are also a number of human labeled knowledge bases such as WordNet [23], which was the starting point for the ImageNet [28] categories, and Visual Genome [15] which has human annotated scene graphs for each image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 78
                            }
                        ],
                        "text": "For our experiments, we also use another version of knowledge graph by fusing WordNet knowledge similar to VGML setting."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 69
                            }
                        ],
                        "text": "Using the subset of Wordnet from [10], we first collect new nodes in WordNet not in our output label by including those which directly connect to our output labels and thus likely to be relevant and add them to a combined graph."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "To address this, we also create a version of graph by fusing the Visual Genome Graphs with WordNet [23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 24
                            }
                        ],
                        "text": "We then take all of the WordNet edges between these nodes and add them to our combined graph (see Appendix for more details on these graphs)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1671874,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "68c03788224000794d5491ab459be0b2a2c38677",
            "isKey": true,
            "numCitedBy": 13888,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4]."
            },
            "slug": "WordNet:-A-Lexical-Database-for-English-Miller",
            "title": {
                "fragments": [],
                "text": "WordNet: A Lexical Database for English"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "WordNet1 provides a more effective combination of traditional lexicographic information and modern computing, and is an online lexical database designed for use under program control."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2127116590"
                        ],
                        "name": "Thomas de Quincey",
                        "slug": "Thomas-de-Quincey",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "de Quincey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas de Quincey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "There has also been some work using a knowledge base for image retrieval [12] or answering visual queries [39], but these works are focused on building and then querying knowledge bases rather than using existing knowledge bases as side information for some vision task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 239491155,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "927881a5602f430ffd145d44b8c35cf7a07b464d",
            "isKey": false,
            "numCitedBy": 69790,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In supernova (SN) spectroscopy relatively little attention has been given to the properties of optically thick spectral lines in epochs following the photosphere\u2019s recession. Most treatments and analyses of post-photospheric optical spectra of SNe assume that forbidden-line emission comprises most if not all spectral features. However, evidence exists that suggests that some spectra exhibit line profiles formed via optically thick resonance-scattering even months or years after the SN explosion. To explore this possibility, we present a geometrical approach to SN spectrum formation based on the \u201cElementary Supernova\u201d model, wherein we investigate the characteristics of resonance-scattering in optically thick lines while replacing the photosphere with a transparent central core emitting non-blackbody continuum radiation, akin to the optical continuum provided by decaying 56Co formed during the explosion. We develop the mathematical framework necessary for solving the radiative transfer equation under these conditions and calculate spectra for both isolated and blended lines. Our comparisons with analogous results from the Elementary Supernova code SYNOW reveal several marked differences in line formation. Most notably, resonance lines in these conditions form P Cygni-like profiles, but the emission peaks and absorption troughs shift redward and blueward, respectively, from the line\u2019s rest wavelength by a significant amount, despite the spherically symmetric distribution of the line optical depth in the ejecta. These properties and others that we find in this work could lead to misidentification of lines or misattribution of properties of line-forming material at post-photospheric times in SN optical spectra."
            },
            "slug": "[C]-Quincey",
            "title": {
                "fragments": [],
                "text": "[C]"
            },
            "venue": {
                "fragments": [],
                "text": "The Works of Thomas De Quincey, Vol. 1: Writings, 1799\u20131820"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2169667054"
                        ],
                        "name": "\u7d39\u4ecbRyan Dunch",
                        "slug": "\u7d39\u4ecbRyan-Dunch",
                        "structuredName": {
                            "firstName": "\u7d39\u4ecbRyan",
                            "lastName": "Dunch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u7d39\u4ecbRyan Dunch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2169671793"
                        ],
                        "name": "Fuzhou Protestants",
                        "slug": "Fuzhou-Protestants",
                        "structuredName": {
                            "firstName": "Fuzhou",
                            "lastName": "Protestants",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fuzhou Protestants"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "There are on average 21 labeled objects in an image, so compared to datasets such as ImageNet [29] or PASCAL [7], the scenes we are considering are far more complex."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 113
                            }
                        ],
                        "text": "There are on average 21 labeled objects in an image, so compared to datasets such as ImageNet [28], COCO [19] or PASCAL [7], the scenes we are considering are far more complex."
                    },
                    "intents": []
                }
            ],
            "corpusId": 240283508,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "032db195efd97fe2bcd20c4ad04628c70ff4e79c",
            "isKey": false,
            "numCitedBy": 34875,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "tobacco and products and use of tanning beds. Friends the biggest on predisposition to harmful habits."
            },
            "slug": "and-a-at-Dunch-Protestants",
            "title": {
                "fragments": [],
                "text": "and a at"
            },
            "venue": {
                "fragments": [],
                "text": "The William Makepeace Thackeray Library"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141732326"
                        ],
                        "name": "Jianguo Zhang",
                        "slug": "Jianguo-Zhang",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63925014,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "0ec48ac86456cea3d6d6172ca81ef68e98b21a61",
            "isKey": false,
            "numCitedBy": 3322,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-PASCAL-Visual-Object-Classes-Challenge-Zhang",
            "title": {
                "fragments": [],
                "text": "The PASCAL Visual Object Classes Challenge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "There is also a substantial amount of work on various types of kernels defined for graphs [35] such as diffusion kernels [14], graphlet kernels [32], Weisfeiler-Lehman graph kernels [31], deep graph kernels [26], graph invariant kernels [25] and shortest-path kernels [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Deep graph kernels. KDDM"
            },
            "venue": {
                "fragments": [],
                "text": "Deep graph kernels. KDDM"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combined Visual Genome Wordnet VGFS Graph Num Nodes: 1829"
            },
            "venue": {
                "fragments": [],
                "text": "Combined Visual Genome Wordnet VGFS Graph Num Nodes: 1829"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Category AP Comparison Figures Figures 11, 12, 13 and 14 show the category comparison analysis for the VGML full, 5k, 500 and the VGFS 1-shot experiments respectively"
            },
            "venue": {
                "fragments": [],
                "text": "Category AP Comparison Figures Figures 11, 12, 13 and 14 show the category comparison analysis for the VGML full, 5k, 500 and the VGFS 1-shot experiments respectively"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shortest-path kernels on graphs. ICDM"
            },
            "venue": {
                "fragments": [],
                "text": "Shortest-path kernels on graphs. ICDM"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combined Visual Genome Wordnet VGML Graph Num Nodes: 1101"
            },
            "venue": {
                "fragments": [],
                "text": "Combined Visual Genome Wordnet VGML Graph Num Nodes: 1101"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual Genome VGFS Graph Num Nodes"
            },
            "venue": {
                "fragments": [],
                "text": "Visual Genome VGFS Graph Num Nodes"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "NEIL [4] for example has over 2000 concepts, and NELL [3] has over 2M confident beliefs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 39
                            }
                        ],
                        "text": "Related Work Learning knowledge graphs [4, 3, 30] and using graphs for visual reasoning [37, 20] has recently been of interest to the vision community."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "NEIL [38] for example has over 2000 concepts, and NELL [4] has over 2M confident beliefs."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Toward an architecture for neverending language learning"
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Graph invariant kernels . IJCAI"
            },
            "venue": {
                "fragments": [],
                "text": "Graph invariant kernels . IJCAI"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "There is also a substantial amount of work on various types of kernels defined for graphs [35] such as diffusion kernels [14], graphlet kernels [32], Weisfeiler-Lehman graph kernels [31], deep graph kernels [26], graph invariant kernels [25] and shortest-path kernels [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Borgwardt. Graph kernels. JMLR"
            },
            "venue": {
                "fragments": [],
                "text": "Borgwardt. Graph kernels. JMLR"
            },
            "year": 2010
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 36,
            "methodology": 14
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 54,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/The-More-You-Know:-Using-Knowledge-Graphs-for-Image-Marino-Salakhutdinov/79baf8cf6be6510f69be8c515516136138678cf5?sort=total-citations"
}