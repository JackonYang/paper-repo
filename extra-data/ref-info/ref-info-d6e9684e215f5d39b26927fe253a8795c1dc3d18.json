{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2098101"
                        ],
                        "name": "S. Shimotsuji",
                        "slug": "S.-Shimotsuji",
                        "structuredName": {
                            "firstName": "Shigeyoshi",
                            "lastName": "Shimotsuji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shimotsuji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40162920"
                        ],
                        "name": "M. Asano",
                        "slug": "M.-Asano",
                        "structuredName": {
                            "firstName": "Mieko",
                            "lastName": "Asano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Asano"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 136
                            }
                        ],
                        "text": "Given a set of C reference images representing C different known classes, the discriminant power of a sub-image\n2\nof fixed size Icx,y on the reference image of class c, with respect to the rest of the classes can be computed as,\nrcx,y = min c\u2032 6=c\n\u2212wx\u2264i\u2264wx \u2212wy\u2264j\u2264wy\nd(Icx,y, I c\u2032 x+i,y+j), (1)\nwhere\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "Note that rcx,y represents the distance from I c x,y to the most similar sub-image found in any other reference image around (x, y)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5585402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd30d2052973e3212cb66acbf7fa2d154c39ca15",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new form document identification technique that uses the structure of cells in a form. The proposed method represents the cell structure by the location of the center points of each cell. This representation allows the form identification to be realized by a process of matching the points in an input image to the points in registered forms. We have implemented the point matching process using the two-dimensional hash table. This implementation enables the system to robustly identify an input form even if it is skewed or deformed by a scanning process, and to reduce the time for the identification. Moreover, the similarity between two forms defined by the implementation can be used to evaluate the identification ability when a set of registered forms is specified. Experimental results show the robustness and effectiveness of the proposed technique."
            },
            "slug": "Form-identification-based-on-cell-structure-Shimotsuji-Asano",
            "title": {
                "fragments": [],
                "text": "Form identification based on cell structure"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A new form document identification technique that uses the structure of cells in a form by the location of the center points of each cell, which enables the system to robustly identify an input form even if it is skewed or deformed by a scanning process, and to reduce the time for the identification."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2773029"
                        ],
                        "name": "Ryo Ohtera",
                        "slug": "Ryo-Ohtera",
                        "structuredName": {
                            "firstName": "Ryo",
                            "lastName": "Ohtera",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryo Ohtera"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122533395"
                        ],
                        "name": "T. Horiuchi",
                        "slug": "T.-Horiuchi",
                        "structuredName": {
                            "firstName": "Takahiko",
                            "lastName": "Horiuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Horiuchi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "The number of \u03b4-landmarks found in a document strongly depends on the similarity of the reference images, but, in practice, only a few of them are needed for classificacion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29564350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26000a0caa885ce1b2d35f600cb10f0906915c7f",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Ordering and charging goods have been increasingly treated with faxed forms. Although the FAXOCR system for specified forms is used practically, the performance to unspecified forms is not enough, because of the effect of noise on the faxed forms during the facsimile transmission. The final target of this study is to construct a practical FAXOCR system for unspecified forms. As the first stage, an identification method for unspecified faxed forms is proposed in this paper. In our approach, character separation and position adjustment are performed in the Hough-Space as pre-processing. Then the form identification is carried out by using vote histogram in the Hough-space. The performance of the proposed technique is verified experimentally by using actual faxed forms."
            },
            "slug": "Faxed-form-identification-using-histogram-of-the-Ohtera-Horiuchi",
            "title": {
                "fragments": [],
                "text": "Faxed form identification using histogram of the Hough-space"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The final target of this study is to construct a practical FAXOCR system for unspecified forms, and an identification method for unspecified faxed forms is proposed in this paper."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1957622"
                        ],
                        "name": "H. Sako",
                        "slug": "H.-Sako",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Sako",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sako"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2386732"
                        ],
                        "name": "M. Seki",
                        "slug": "M.-Seki",
                        "structuredName": {
                            "firstName": "Minenobu",
                            "lastName": "Seki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Seki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2353717"
                        ],
                        "name": "N. Furukawa",
                        "slug": "N.-Furukawa",
                        "structuredName": {
                            "firstName": "Naohiro",
                            "lastName": "Furukawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Furukawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2440116"
                        ],
                        "name": "H. Ikeda",
                        "slug": "H.-Ikeda",
                        "structuredName": {
                            "firstName": "Hisashi",
                            "lastName": "Ikeda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ikeda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32811532"
                        ],
                        "name": "Atsuhiro Imaizumi",
                        "slug": "Atsuhiro-Imaizumi",
                        "structuredName": {
                            "firstName": "Atsuhiro",
                            "lastName": "Imaizumi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Atsuhiro Imaizumi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 144
                            }
                        ],
                        "text": "The desirable robustness to local noise and distortions can be achieved by selecting a set of \u03b4-landmarks according to a certain criterion of spatial distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13457314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bfe4e6e91f8a21dc4227b55c77b43f2f6b8f264",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Form reading technology based on form-typeidentification and form-data recognition is proposed. Thistechnology can solve difficulties in variety for readingdifferent items on fairly large number of different types offorms. The form-type identification consists of two parts:(i) extraction of targets such as important keywords in aform by matching between recogised characters and wordstrings in a keyword dictionary, and (ii) analysis ofpositional or semantic relationship between the targets byconstellation matching between these targets and wordlocation information in the keyword dictionary. The formdatarecognition consists of two parts: (i) extraction of aregion of interest (ROI) contained a character string of theitem by using a layout knowledge of the very form-type,and (ii) character string recognition of the item by usingthe linguistic constraint which can be obtained from acontent knowledge of the form-type. A experiment using642 sample forms with 107 different types in totalconfirmed that the form-type identification method cancorrectly identify 97% of 642 form samples at a rejectionrate 3%. Another experiment confirmed that the form-data recognition method can correctly read 95% of thenumber of items on the form samples."
            },
            "slug": "Form-reading-based-on-form-type-identification-and-Sako-Seki",
            "title": {
                "fragments": [],
                "text": "Form reading based on form-type identification and form-data recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Form reading technology based on form-type identification and form- data recognition and character string recognition is proposed, which confirmed that the form-data recognition method can correctly read 95% of thenumber of items on the form samples."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595112"
                        ],
                        "name": "Sekhar Mandal",
                        "slug": "Sekhar-Mandal",
                        "structuredName": {
                            "firstName": "Sekhar",
                            "lastName": "Mandal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sekhar Mandal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105636642"
                        ],
                        "name": "S. Chowdhury",
                        "slug": "S.-Chowdhury",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Chowdhury",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chowdhury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152167018"
                        ],
                        "name": "Amit Kumar Das",
                        "slug": "Amit-Kumar-Das",
                        "structuredName": {
                            "firstName": "Amit Kumar",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amit Kumar Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784810"
                        ],
                        "name": "B. Chanda",
                        "slug": "B.-Chanda",
                        "structuredName": {
                            "firstName": "Bhabatosh",
                            "lastName": "Chanda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Chanda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 146
                            }
                        ],
                        "text": "Thus, those \u03b4landmarks having the highest values of rc can be selected for class c, since they represent the areas of the reference image having the highest disimilarity with reference images from other classes, and then, they can be used to describe its document class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 140
                            }
                        ],
                        "text": "The desirable robustness to local noise and distortions can be achieved by selecting a set of \u03b4-landmarks according to a certain criterion of spatial distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11979010,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d55c0d48987d806ae33074f6cf933affa7153c4a",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a fully automatic hierarchical method for identification of forms using global as well as local features. Moments of certain orders are considered as global shape features and are utilised to reduce the search space by selecting a subset of forms present in the database. The type of the candidate form is then identified within this subset through detail analysis using local geometrical and topological features. The candidate form is then segmented to extract the user-filled information."
            },
            "slug": "A-hierarchical-method-for-automated-identification-Mandal-Chowdhury",
            "title": {
                "fragments": [],
                "text": "A hierarchical method for automated identification and segmentation of forms"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A fully automatic hierarchical method for identification of forms using global as well as local features, which is utilised to reduce the search space by selecting a subset of forms present in the database."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1826457"
                        ],
                        "name": "P. H\u00e9roux",
                        "slug": "P.-H\u00e9roux",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "H\u00e9roux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. H\u00e9roux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15177643"
                        ],
                        "name": "S. Diana",
                        "slug": "S.-Diana",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Diana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Diana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2510130"
                        ],
                        "name": "Arnaud Ribert",
                        "slug": "Arnaud-Ribert",
                        "structuredName": {
                            "firstName": "Arnaud",
                            "lastName": "Ribert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnaud Ribert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35863204"
                        ],
                        "name": "\u00c9. Trupin",
                        "slug": "\u00c9.-Trupin",
                        "structuredName": {
                            "firstName": "\u00c9ric",
                            "lastName": "Trupin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. Trupin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 135
                            }
                        ],
                        "text": "The desirable robustness to local noise and distortions can be achieved by selecting a set of \u03b4-landmarks according to a certain criterion of spatial distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17264036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2ab8f9a8ec4b6e243a88260296811c306636809",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We present three classifiers used in automatic forms class identification. The first category of classifier includes the k-nearest neighbours (kNN) and the multilayer perceptron (MLP) classifiers. The second category corresponds to a new structural classifier based on tree comparison. The low level information based on a pyramidal decomposition of the document image is used by the kNN and the MLP classifiers, while the high level information represents the form content with a hierarchical structure used by the new structural classifier. Experimental results are presented. Some strategies of classifier co-operation are proposed."
            },
            "slug": "Classification-method-study-for-automatic-form-H\u00e9roux-Diana",
            "title": {
                "fragments": [],
                "text": "Classification method study for automatic form class identification"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "Two new structural classifiers based on tree comparison and the k-nearest neighbours and the multilayer perceptron classifiers are presented, which represent the form content with a hierarchical structure in automatic forms class identification."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31323486"
                        ],
                        "name": "T. Nagasaki",
                        "slug": "T.-Nagasaki",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Nagasaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nagasaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765131"
                        ],
                        "name": "K. Marukawa",
                        "slug": "K.-Marukawa",
                        "structuredName": {
                            "firstName": "Katsumi",
                            "lastName": "Marukawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Marukawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624031"
                        ],
                        "name": "T. Kagehiro",
                        "slug": "T.-Kagehiro",
                        "structuredName": {
                            "firstName": "Tatsuhiko",
                            "lastName": "Kagehiro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kagehiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1957622"
                        ],
                        "name": "H. Sako",
                        "slug": "H.-Sako",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Sako",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sako"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "Therefore, r is a good estimator of the minimum distance that is expected to be found when comparing Icx,y to any other image belonging to a known class except its own, suggesting that higher values of rcx,y give rise to a higher discriminant power of Icx,y ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30574999,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d441f164b9eb9f6ed99018c5ca292cf605f5fe53",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a coupon classification system based on image vector matching. This method features following two points. (1) Extract a feature vector from a gray-scale image using a feature map which is derived from training coupon images. (2) Classify a coupon image by adaptive mask distance to cope with the recognition difficulty such as partial cutting of coupon and putting stamp on it. We have implemented this method and experimented with collected samples. It achieved 100% of recognition rates, processing speed 11.76msec/sheet to 969 images for 42 kinds of coupon samples"
            },
            "slug": "A-Coupon-Classification-Method-Based-on-Adaptive-Nagasaki-Marukawa",
            "title": {
                "fragments": [],
                "text": "A Coupon Classification Method Based on Adaptive Image Vector Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A coupon classification system based on image vector matching that classifies a coupon image by adaptive mask distance to cope with the recognition difficulty such as partial cutting of coupon and putting stamp on it is described."
            },
            "venue": {
                "fragments": [],
                "text": "18th International Conference on Pattern Recognition (ICPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12666808"
                        ],
                        "name": "Antoine Ting",
                        "slug": "Antoine-Ting",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Ting",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Ting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890438"
                        ],
                        "name": "M. Leung",
                        "slug": "M.-Leung",
                        "structuredName": {
                            "firstName": "Maylor",
                            "lastName": "Leung",
                            "middleNames": [
                                "Karhang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 228
                            }
                        ],
                        "text": "Given the C class models L = {L1, L2, . . . LC}, consisting each of a set of \u03b4-landmarks, the following distance function is defined in order to measure the similarity of a test document J with respect to a class c,\nSc(J) = 1 \u2016Lc\u2016 \u2211 Icx,y\u2208Lc scx,y(J) rcx,y , (3)\nwhere,\nscx,y(J) = min\u2212wx\u2264i\u2264wx \u2212wy\u2264j\u2264wy d(Icx,y, Jx+i,y+j)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 128
                            }
                        ],
                        "text": "Given a set of C reference images representing C different known classes, the discriminant power of a sub-image\n2\nof fixed size Icx,y on the reference image of class c, with respect to the rest of the classes can be computed as,\nrcx,y = min c\u2032 6=c\n\u2212wx\u2264i\u2264wx \u2212wy\u2264j\u2264wy\nd(Icx,y, I c\u2032 x+i,y+j), (1)\nwhere d is a distance function used to measure dissimilarity between two sub-images, and w is the half size of the sampling window, which is an extension of the matching area around (x, y) needed to compensate for image distortions and translations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 101
                            }
                        ],
                        "text": "Therefore, r is a good estimator of the minimum distance that is expected to be found when comparing Icx,y to any other image belonging to a known class except its own, suggesting that higher values of rcx,y give rise to a higher discriminant power of Icx,y ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "The set of \u03b4-landmarks of a class c, Lc, is defined as the set of the sub-images Icx,y having a significant dissimilarity with respect to the rest of known classes,\nLc = {Icx,y | rcx,y > Tr}, (2)\nwhere the threshold Tr can be empirically set."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 131
                            }
                        ],
                        "text": "Given a set of C reference images representing C different known classes, the discriminant power of a sub-image\n2\nof fixed size Icx,y on the reference image of class c, with respect to the rest of the classes can be computed as,\nrcx,y = min c\u2032 6=c\n\u2212wx\u2264i\u2264wx \u2212wy\u2264j\u2264wy\nd(Icx,y, I c\u2032 x+i,y+j), (1)\nwhere\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41999557,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2e436d4e1dc5b1c3c9a86391c7938f8bbbc6723",
            "isKey": true,
            "numCitedBy": 12,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Business forms are \"linear\" documents which can be accurately described by a one-dimensional data structure. This paper proposes a novel approach for form identification using strings. This application can be used as a basis for extension to other \"linear\" documents such as logos or line drawings. A set of known blank forms is stored in a database and incoming forms are automatically matched to one of these. In addition, forms which are not in the database can also be detected. A novel and simple method is used for matching by considering a distinctive \"signature\" for each document. This takes the shape of a string which describes the elements present on the form. Included are the location and size of lines, corners and blocks of text, quantised as discrete symbols. A specially adapted and efficient string edit distance calculation is then applied for matching. Unregistered forms can be detected by examining the unmatched elements between two strings. This novel string format makes it possible to extend the conventional one-dimensional representation possibilities of strings to a richer \"one-and-a-half dimensional\" structure and requires no training."
            },
            "slug": "Business-form-classification-using-strings-Ting-Leung",
            "title": {
                "fragments": [],
                "text": "Business form classification using strings"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper proposes a novel approach for form identification using strings which makes it possible to extend the conventional one-dimensional representation possibilities of strings to a richer \"one-and-a-half dimensional\" structure and requires no training."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2691315"
                        ],
                        "name": "Nawei Chen",
                        "slug": "Nawei-Chen",
                        "structuredName": {
                            "firstName": "Nawei",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nawei Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 164
                            }
                        ],
                        "text": "Subsequently, \u03b4-landmarks can be used to classify, or reject, new images under a certain criterion, by matching each \u03b4-landmark against sub-images extracted from a corresponding window on the test image at the \u03b4-landmark location."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "For example, documents differing only on one character should not be processed using \u03b4-landmarks much bigger than the region enclosing one character."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2813627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb033a3dd89765bc14dfdef4ed081d358a305078",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image classification is an important step in Office Automation, Digital Libraries, and other document image analysis applications. There is great diversity in document image classifiers: they differ in the problems they solve, in the use of training data to construct class models, and in the choice of document features and classification algorithms. We survey this diverse literature using three components: the problem statement, the classifier architecture, and performance evaluation. This brings to light important issues in designing a document classifier, including the definition of document classes, the choice of document features and feature representation, and the choice of classification algorithm and learning mechanism. We emphasize techniques that classify single-page typeset document images without using OCR results. Developing a general, adaptable, high-performance classifier is challenging due to the great variety of documents, the diverse criteria used to define document classes, and the ambiguity that arises due to ill-defined or fuzzy document classes."
            },
            "slug": "A-survey-of-document-image-classification:-problem-Chen-Blostein",
            "title": {
                "fragments": [],
                "text": "A survey of document image classification: problem statement, classifier architecture and performance evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This work focuses on techniques that classify single-page typeset document images without using OCR results, and brings to light important issues in designing a document classifier, including the definition of document classes, the choices of document features and feature representation, and the choice of classification algorithm and learning mechanism."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143961578"
                        ],
                        "name": "Kuo-Chin Fan",
                        "slug": "Kuo-Chin-Fan",
                        "structuredName": {
                            "firstName": "Kuo-Chin",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kuo-Chin Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47235730"
                        ],
                        "name": "Mei-Lin Chang",
                        "slug": "Mei-Lin-Chang",
                        "structuredName": {
                            "firstName": "Mei-Lin",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mei-Lin Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "Given a set of C reference images representing C different known classes, the discriminant power of a sub-image\n2\nof fixed size Icx,y on the reference image of class c, with respect to the rest of the classes can be computed as,\nrcx,y = min c\u2032 6=c\n\u2212wx\u2264i\u2264wx \u2212wy\u2264j\u2264wy\nd(Icx,y, I c\u2032 x+i,y+j), (1)\nwhere\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31023244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b481dead5e727026824909291dab2d82cc398a2a",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel form recognition method by analyzing the line structure embedded in an input form document. First, all vertical and horizontal lines embedded in the form image are extracted. Experimental results demonstrate the feasibility and efficiency of our proposed method in recognizing form documents."
            },
            "slug": "Form-document-identification-using-line-structure-Fan-Chang",
            "title": {
                "fragments": [],
                "text": "Form document identification using line structure based features"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Experimental results demonstrate the feasibility and efficiency of the proposed method in recognizing form documents, and the line structure embedded in an input form document is analyzed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 9,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Identification-of-Very-Similar-Filled-in-Forms-with-Arlandis-P\u00e9rez-Cortes/d6e9684e215f5d39b26927fe253a8795c1dc3d18?sort=total-citations"
}