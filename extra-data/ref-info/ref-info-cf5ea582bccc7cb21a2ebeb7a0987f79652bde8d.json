{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2999447"
                        ],
                        "name": "Shangpu Jiang",
                        "slug": "Shangpu-Jiang",
                        "structuredName": {
                            "firstName": "Shangpu",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shangpu Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3021654"
                        ],
                        "name": "Daniel Lowd",
                        "slug": "Daniel-Lowd",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lowd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Lowd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721158"
                        ],
                        "name": "D. Dou",
                        "slug": "D.-Dou",
                        "structuredName": {
                            "firstName": "Dejing",
                            "lastName": "Dou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [23]) or continuous relaxations thereof (e."
                    },
                    "intents": []
                }
            ],
            "corpusId": 828421,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9520f78f645893b688ee42f6773ed649f7ed5dac",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of text mining and information extraction projects such as Text Runner and NELL seek to automatically build knowledge bases from the rapidly growing amount of information on the web. In order to scale to the size of the web, these projects often employ ad hoc heuristics to reason about uncertain and contradictory information rather than reasoning jointly about all candidate facts. In this paper, we present a Markov logic-based system for cleaning an extracted knowledge base. This allows a scalable system such as NELL to take advantage of joint probabilistic inference, or, conversely, allows Markov logic to be applied to a web scale problem. Our system uses only the ontological constraints and confidence values of the original system, along with human-labeled data if available. The labeled data can be used to calibrate the confidence scores from the original system or learn the effectiveness of individual extraction patterns. To achieve scalability, we introduce a neighborhood grounding method that only instantiates the part of the network most relevant to the given query. This allows us to partition the knowledge cleaning task into tractable pieces that can be solved individually. In experiments on NELL's knowledge base, we evaluate several variants of our approach and find that they improve both F1 and area under the precision-recall curve."
            },
            "slug": "Learning-to-Refine-an-Automatically-Extracted-Base-Jiang-Lowd",
            "title": {
                "fragments": [],
                "text": "Learning to Refine an Automatically Extracted Knowledge Base Using Markov Logic"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a Markov logic-based system for cleaning an extracted knowledge base that allows a scalable system such as NELL to take advantage of joint probabilistic inference, or, conversely, allowsMarkov logic to be applied to a web scale problem."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE 12th International Conference on Data Mining"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2634786"
                        ],
                        "name": "J. Pujara",
                        "slug": "J.-Pujara",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Pujara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pujara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145147227"
                        ],
                        "name": "Hui Miao",
                        "slug": "Hui-Miao",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Miao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Miao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746034"
                        ],
                        "name": "L. Getoor",
                        "slug": "L.-Getoor",
                        "structuredName": {
                            "firstName": "Lise",
                            "lastName": "Getoor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Getoor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [34]); (2) methods that use latent variables to model the correlations indirectly, using either discrete factors (e."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11564235,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2a090506264bc9706dc9bcc5d61b4965ae919e7",
            "isKey": false,
            "numCitedBy": 246,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Large-scale information processing systems are able to extract massive collections of interrelated facts, but unfortunately transforming these candidate facts into useful knowledge is a formidable challenge. In this paper, we show how uncertain extractions about entities and their relations can be transformed into a knowledge graph. The extractions form an extraction graph and we refer to the task of removing noise, inferring missing information, and determining which candidate facts should be included into a knowledge graph as knowledge graph identification. In order to perform this task, we must reason jointly about candidate facts and their associated extraction confidences, identify co-referent entities, and incorporate ontological constraints. Our proposed approach uses probabilistic soft logic (PSL), a recently introduced probabilistic modeling framework which easily scales to millions of facts. We demonstrate the power of our method on a synthetic Linked Data corpus derived from the MusicBrainz music community and a real-world set of extractions from the NELL project containing over 1M extractions and 70K ontological relations. We show that compared to existing methods, our approach is able to achieve improved AUC and F1 with significantly lower running time."
            },
            "slug": "Knowledge-Graph-Identification-Pujara-Miao",
            "title": {
                "fragments": [],
                "text": "Knowledge Graph Identification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows how uncertain extractions about entities and their relations can be transformed into a knowledge graph and shows that compared to existing methods, the proposed approach is able to achieve improved AUC and F1 with significantly lower running time."
            },
            "venue": {
                "fragments": [],
                "text": "SEMWEB"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1914797"
                        ],
                        "name": "N. Lao",
                        "slug": "N.-Lao",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Lao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our PRA model is similar to the method described in [24], except it is trained on Freebase instead of on NELL."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", [31, 11, 20, 37]); and (3) methods that approximate the correlation using algorithmic approaches, such as random walks [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "One way to perform link prediction is to use the path ranking algorithm of [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1619841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2aea6cc6c42101b2615753c2933a33e57dd665f2",
            "isKey": false,
            "numCitedBy": 521,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of performing learning and inference in a large scale knowledge base containing imperfect knowledge with incomplete coverage. We show that a soft inference procedure based on a combination of constrained, weighted, random walks through the knowledge base graph can be used to reliably infer new beliefs for the knowledge base. More specifically, we show that the system can learn to infer different target relations by tuning the weights associated with random walks that follow different paths through the graph, using a version of the Path Ranking Algorithm (Lao and Cohen, 2010b). We apply this approach to a knowledge base of approximately 500,000 beliefs extracted imperfectly from the web by NELL, a never-ending language learner (Carlson et al., 2010). This new system improves significantly over NELL's earlier Horn-clause learning and inference method: it obtains nearly double the precision at rank 100, and the new learning method is also applicable to many more inference tasks."
            },
            "slug": "Random-Walk-Inference-and-Learning-in-A-Large-Scale-Lao-Mitchell",
            "title": {
                "fragments": [],
                "text": "Random Walk Inference and Learning in A Large Scale Knowledge Base"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a soft inference procedure based on a combination of constrained, weighted, random walks through the knowledge base graph can be used to reliably infer new beliefs for theknowledge base."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3115592"
                        ],
                        "name": "Ndapandula Nakashole",
                        "slug": "Ndapandula-Nakashole",
                        "structuredName": {
                            "firstName": "Ndapandula",
                            "lastName": "Nakashole",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ndapandula Nakashole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144530424"
                        ],
                        "name": "M. Theobald",
                        "slug": "M.-Theobald",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Theobald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Theobald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751591"
                        ],
                        "name": "G. Weikum",
                        "slug": "G.-Weikum",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Weikum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Weikum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 420,
                                "start": 416
                            }
                        ],
                        "text": "This literature can be clustered into 4 main groups: (1) approaches such as YAGO [37], YAGO2 [18], DBpedia [3], and Freebase [4], which are built on Wikipedia infoboxes and other structured data sources; (2) approaches such as Reverb [11], OLLIE [24], and PRISMATIC [12], which use open information (schema-less) extraction techniques applied to the entire web; (3) approaches such as NELL/ ReadTheWeb [8], PROSPERA [28], and DeepDive/ Elementary [30], which extract information from the entire web, but use a fixed ontology/ schema; and (4) approaches such as Probase [44], which construct taxonomies (is-a hierarchies), as opposed to general KBs with multiple types of predicates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1064204,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af7191977af0b69cde3f17dd698a7f1e7a805f61",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Harvesting relational facts from Web sources has received great attention for automatically constructing large knowledge bases. Stateof-the-art approaches combine pattern-based gathering of fact candidates with constraint-based reasoning. However, they still face major challenges regarding the trade-offs between precision, recall, and scalability. Techniques that scale well are susceptible to noisy patterns that degrade precision, while techniques that employ deep reasoning for high precision cannot cope with Web-scale data.\n This paper presents a scalable system, called PROSPERA, for high-quality knowledge harvesting. We propose a new notion of ngram-itemsets for richer patterns, and use MaxSat-based constraint reasoning on both the quality of patterns and the validity of fact candidates.We compute pattern-occurrence statistics for two benefits: they serve to prune the hypotheses space and to derive informative weights of clauses for the reasoner. The paper shows how to incorporate these building blocks into a scalable architecture that can parallelize all phases on a Hadoop-based distributed platform. Our experiments with the ClueWeb09 corpus include comparisons to the recent ReadTheWeb experiment. We substantially outperform these prior results in terms of recall, with the same precision, while having low run-times."
            },
            "slug": "Scalable-knowledge-harvesting-with-high-precision-Nakashole-Theobald",
            "title": {
                "fragments": [],
                "text": "Scalable knowledge harvesting with high precision and high recall"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A new notion of ngram-itemsets for richer patterns is proposed, and MaxSat-based constraint reasoning is used on both the quality of patterns and the validity of fact candidates, to use in a scalable system for high-quality knowledge harvesting."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM '11"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751591"
                        ],
                        "name": "G. Weikum",
                        "slug": "G.-Weikum",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Weikum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Weikum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144530424"
                        ],
                        "name": "M. Theobald",
                        "slug": "M.-Theobald",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Theobald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Theobald"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2582146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2ab43ebd1861cd89f442ba29cebfe192378a5fc",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 160,
            "paperAbstract": {
                "fragments": [],
                "text": "There are major trends to advance the functionality of search engines to a more expressive semantic level. This is enabled by the advent of knowledge-sharing communities such as Wikipedia and the progress in automatically extracting entities and relationships from semistructured as well as natural-language Web sources. Recent endeavors of this kind include DBpedia, EntityCube, KnowItAll, ReadTheWeb, and our own YAGO-NAGA project (and others). The goal is to automatically construct and maintain a comprehensive knowledge base of facts about named entities, their semantic classes, and their mutual relations as well as temporal contexts, with high precision and high recall. This tutorial discusses state-of-the-art methods, research opportunities, and open challenges along this avenue of knowledge harvesting."
            },
            "slug": "From-information-to-knowledge:-harvesting-entities-Weikum-Theobald",
            "title": {
                "fragments": [],
                "text": "From information to knowledge: harvesting entities and relationships from web sources"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This tutorial discusses state-of-the-art methods, research opportunities, and open challenges along this avenue of knowledge harvesting, to automatically construct and maintain a comprehensive knowledge base of facts about named entities, their semantic classes, and their mutual relations as well as temporal contexts, with high precision and high recall."
            },
            "venue": {
                "fragments": [],
                "text": "PODS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47657030"
                        ],
                        "name": "Feng Niu",
                        "slug": "Feng-Niu",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Niu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Niu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776014"
                        ],
                        "name": "Ce Zhang",
                        "slug": "Ce-Zhang",
                        "structuredName": {
                            "firstName": "Ce",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ce Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114485554"
                        ],
                        "name": "C. R\u00e9",
                        "slug": "C.-R\u00e9",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "R\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. R\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734317"
                        ],
                        "name": "J. Shavlik",
                        "slug": "J.-Shavlik",
                        "structuredName": {
                            "firstName": "Jude",
                            "lastName": "Shavlik",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shavlik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 248401011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e431ce6566124923df5ea0ca585390649671aad9",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers have approached knowledge-base construction (KBC) with a wide range of data resources and techniques. The authors present Elementary, a prototype KBC system that is able to combine diverse resources and different KBC techniques via machine learning and statistical inference to construct knowledge bases. Using Elementary, they have implemented a solution to the TAC-KBP challenge with quality comparable to the state of the art, as well as an end-to-end online demonstration that automatically and continuously enriches Wikipedia with structured data by reading millions of webpages on a daily basis. The authors describe several challenges and their solutions in designing, implementing, and deploying Elementary. In particular, the authors first describe the conceptual framework and architecture of Elementary to integrate different data resources and KBC techniques in a principled manner. They then discuss how they address scalability challenges to enable Web-scale deployment. The authors empirically show that this decomposition-based inference approach achieves higher performance than prior inference approaches. To validate the effectiveness of Elementary\u2019s approach to KBC, they experimentally show that its ability to incorporate diverse signals has positive impacts on KBC quality."
            },
            "slug": "Elementary-Niu-Zhang",
            "title": {
                "fragments": [],
                "text": "Elementary"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The authors present Elementary, a prototype KBC system that is able to combine diverse resources and different KBC techniques via machine learning and statistical inference to construct knowledge bases and empirically show that this decomposition-based inference approach achieves higher performance than prior inference approaches."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Semantic Web and Information Systems"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016781"
                        ],
                        "name": "Heng Ji",
                        "slug": "Heng-Ji",
                        "structuredName": {
                            "firstName": "Heng",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heng Ji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739186"
                        ],
                        "name": "Taylor Cassidy",
                        "slug": "Taylor-Cassidy",
                        "structuredName": {
                            "firstName": "Taylor",
                            "lastName": "Cassidy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taylor Cassidy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118912383"
                        ],
                        "name": "Qi Li",
                        "slug": "Qi-Li",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2364709"
                        ],
                        "name": "S. Tamang",
                        "slug": "S.-Tamang",
                        "structuredName": {
                            "firstName": "Suzanne",
                            "lastName": "Tamang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tamang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[21])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6232256,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "002a5847391a1259bea939b60ffb4e858521a622",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 100,
            "paperAbstract": {
                "fragments": [],
                "text": "Temporal Information Extraction (TIE) plays an important role in many natural language processing and database applications. Temporal slot filling (TSF) is a new and ambitious TIE task prepared for the knowledge base population (KBP2011) track of NIST Text Analysis Conference. TSF requires systems to discover temporally bound facts about entities and their attributes in order to populate a structured knowledge base. In this paper, we will provide an overview of the unique challenges of this new task and our novel approaches to address these challenges. We present challenges from three perspectives: (1) Temporal information representation: We will review the relevant linguistic semantic theories of temporal information and their limitations, motivating the need to develop a new (4-tuple) representation framework for the task. (2) Annotation acquisition: The lack of substantial labeled training data for supervised learning is a limiting factor in the design of TSF systems. Our work examines the use of multi-class logistic regression methods to improve the labeling quality of training data obtained by distant supervision. (3) Temporal information classification: Another key challenge lies in capturing relations between salient text elements separated by a long context. We develop two approaches for temporal classification and combine them through cross-document aggregation: a flat approach that uses lexical context and shallow dependency features and a structured approach that captures long syntactic contexts by using a dependency path kernel tailored for this task. Experimental results demonstrated that our annotation enhancement approach dramatically increased the speed of the training procedure (by almost 100 times), and that the flat and structured classification approaches were complementary, together yielding a state-of-the-art TSF system."
            },
            "slug": "Tackling-representation,-annotation-and-challenges-Ji-Cassidy",
            "title": {
                "fragments": [],
                "text": "Tackling representation, annotation and classification challenges for temporal knowledge base population"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results demonstrated that the annotation enhancement approach dramatically increased the speed of the training procedure, and that the flat and structured classification approaches were complementary, together yielding a state-of-the-art TSF system."
            },
            "venue": {
                "fragments": [],
                "text": "Knowledge and Information Systems"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1863425"
                        ],
                        "name": "Alan Ritter",
                        "slug": "Alan-Ritter",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Ritter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan Ritter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2674444"
                        ],
                        "name": "Mausam",
                        "slug": "Mausam",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Mausam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mausam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "There are more sophisticated methods for training models that don\u2019t make this assumption (such as [28, 36]), but we leave the integration of such methods into KV to future work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9725510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e50fa3360990aad1fc65a89231d16f8d3373836",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Distant supervision algorithms learn information extraction models given only large readily available databases and text collections. Most previous work has used heuristics for generating labeled data, for example assuming that facts not contained in the database are not mentioned in the text, and facts in the database must be mentioned at least once. In this paper, we propose a new latent-variable approach that models missing data. This provides a natural way to incorporate side information, for instance modeling the intuition that text will often mention rare entities which are likely to be missing in the database. Despite the added complexity introduced by reasoning about missing data, we demonstrate that a carefully designed local search approach to inference is very accurate and scales to large datasets. Experiments demonstrate improved performance for binary and unary relation extraction when compared to learning with heuristic labels, including on average a 27% increase in area under the precision recall curve in the binary case."
            },
            "slug": "Modeling-Missing-Data-in-Distant-Supervision-for-Ritter-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "Modeling Missing Data in Distant Supervision for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new latent-variable approach that models missing data provides a natural way to incorporate side information, for instance modeling the intuition that text will often mention rare entities which are likely to be missing in the database."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016781"
                        ],
                        "name": "Heng Ji",
                        "slug": "Heng-Ji",
                        "structuredName": {
                            "firstName": "Heng",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heng Ji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Entity types and predicates come from a fixed ontology, which is similar to that used in other systems, such as YAGO [39], NELL [8], DeepDive [32], and various systems participating in the TAC-KBP slot-filling competition [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7693051,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77d2698e8efadda698b0edb457cd8de75224bfa0",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we give an overview of the Knowledge Base Population (KBP) track at the 2010 Text Analysis Conference. The main goal of KBP is to promote research in discovering facts about entities and augmenting a knowledge base (KB) with these facts. This is done through two tasks, Entity Linking -- linking names in context to entities in the KB -- and Slot Filling -- adding information about an entity to the KB. A large source collection of newswire and web documents is provided from which systems are to discover information. Attributes (\"slots\") derived from Wikipedia infoboxes are used to create the reference KB. In this paper we provide an overview of the techniques which can serve as a basis for a good KBP system, lay out the remaining challenges by comparison with traditional Information Extraction (IE) and Question Answering (QA) tasks, and provide some suggestions to address these challenges."
            },
            "slug": "Knowledge-Base-Population:-Successful-Approaches-Ji-Grishman",
            "title": {
                "fragments": [],
                "text": "Knowledge Base Population: Successful Approaches and Challenges"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The techniques which can serve as a basis for a good KBP system are provided, the remaining challenges by comparison with traditional Information Extraction (IE) and Question Answering (QA) tasks are laid out, and some suggestions to address these challenges are provided."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5072734"
                        ],
                        "name": "Wentao Wu",
                        "slug": "Wentao-Wu",
                        "structuredName": {
                            "firstName": "Wentao",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wentao Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108509772"
                        ],
                        "name": "Hongsong Li",
                        "slug": "Hongsong-Li",
                        "structuredName": {
                            "firstName": "Hongsong",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongsong Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109590665"
                        ],
                        "name": "Haixun Wang",
                        "slug": "Haixun-Wang",
                        "structuredName": {
                            "firstName": "Haixun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haixun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796651"
                        ],
                        "name": "Kenny Q. Zhu",
                        "slug": "Kenny-Q.-Zhu",
                        "structuredName": {
                            "firstName": "Kenny",
                            "lastName": "Zhu",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenny Q. Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14775471,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "760103b363b1557372e048c4c31b5f01162bfcfa",
            "isKey": false,
            "numCitedBy": 703,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Knowledge is indispensable to understanding. The ongoing information explosion highlights the need to enable machines to better understand electronic text in human language. Much work has been devoted to creating universal ontologies or taxonomies for this purpose. However, none of the existing ontologies has the needed depth and breadth for universal understanding. In this paper, we present a universal, probabilistic taxonomy that is more comprehensive than any existing ones. It contains 2.7 million concepts harnessed automatically from a corpus of 1.68 billion web pages. Unlike traditional taxonomies that treat knowledge as black and white, it uses probabilities to model inconsistent, ambiguous and uncertain information it contains. We present details of how the taxonomy is constructed, its probabilistic modeling, and its potential applications in text understanding."
            },
            "slug": "Probase:-a-probabilistic-taxonomy-for-text-Wu-Li",
            "title": {
                "fragments": [],
                "text": "Probase: a probabilistic taxonomy for text understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper presents a universal, probabilistic taxonomy that is more comprehensive than any existing ones, and contains 2.7 million concepts harnessed automatically from a corpus of 1.68 billion web pages."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD Conference"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679784"
                        ],
                        "name": "Fabian M. Suchanek",
                        "slug": "Fabian-M.-Suchanek",
                        "structuredName": {
                            "firstName": "Fabian",
                            "lastName": "Suchanek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabian M. Suchanek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686448"
                        ],
                        "name": "Gjergji Kasneci",
                        "slug": "Gjergji-Kasneci",
                        "structuredName": {
                            "firstName": "Gjergji",
                            "lastName": "Kasneci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gjergji Kasneci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751591"
                        ],
                        "name": "G. Weikum",
                        "slug": "G.-Weikum",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Weikum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Weikum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207163173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00a3f6924f90fcd77e6e7e6534b957a75d0ced07",
            "isKey": false,
            "numCitedBy": 3480,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We present YAGO, a light-weight and extensible ontology with high coverage and quality. YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts. This includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE). The facts have been automatically extracted from Wikipedia and unified with WordNet, using a carefully designed combination of rule-based and heuristic methods described in this paper. The resulting knowledge base is a major step beyond WordNet: in quality by adding knowledge about individuals like persons, organizations, products, etc. with their semantic relationships - and in quantity by increasing the number of facts by more than an order of magnitude. Our empirical evaluation of fact correctness shows an accuracy of about 95%. YAGO is based on a logically clean model, which is decidable, extensible, and compatible with RDFS. Finally, we show how YAGO can be further extended by state-of-the-art information extraction techniques."
            },
            "slug": "Yago:-a-core-of-semantic-knowledge-Suchanek-Kasneci",
            "title": {
                "fragments": [],
                "text": "Yago: a core of semantic knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts, which includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE)."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36181176"
                        ],
                        "name": "Mike D. Mintz",
                        "slug": "Mike-D.-Mintz",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Mintz",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike D. Mintz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87299088"
                        ],
                        "name": "Steven Bills",
                        "slug": "Steven-Bills",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Bills",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Bills"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144621026"
                        ],
                        "name": "R. Snow",
                        "slug": "R.-Snow",
                        "structuredName": {
                            "firstName": "Rion",
                            "lastName": "Snow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Snow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Next, we train relation extractors using distant supervision [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The features that we use are similar to those described in [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10910955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d84b57362e2010f6f65357267df7e0157af30684",
            "isKey": false,
            "numCitedBy": 2479,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Modern models of relation extraction for tasks like ACE are based on supervised learning of relations from small hand-labeled corpora. We investigate an alternative paradigm that does not require labeled corpora, avoiding the domain dependence of ACE-style algorithms, and allowing the use of corpora of any size. Our experiments use Freebase, a large semantic database of several thousand relations, to provide distant supervision. For each pair of entities that appears in some Freebase relation, we find all sentences containing those entities in a large unlabeled corpus and extract textual features to train a relation classifier. Our algorithm combines the advantages of supervised IE (combining 400,000 noisy pattern features in a probabilistic classifier) and unsupervised IE (extracting large numbers of relations from large corpora of any domain). Our model is able to extract 10,000 instances of 102 relations at a precision of 67.6%. We also analyze feature performance, showing that syntactic parse features are particularly helpful for relations that are ambiguous or lexically distant in their expression."
            },
            "slug": "Distant-supervision-for-relation-extraction-without-Mintz-Bills",
            "title": {
                "fragments": [],
                "text": "Distant supervision for relation extraction without labeled data"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work investigates an alternative paradigm that does not require labeled corpora, avoiding the domain dependence of ACE-style algorithms, and allowing the use of corpora of any size."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145420468"
                        ],
                        "name": "Omkar Deshpande",
                        "slug": "Omkar-Deshpande",
                        "structuredName": {
                            "firstName": "Omkar",
                            "lastName": "Deshpande",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omkar Deshpande"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40033871"
                        ],
                        "name": "Digvijay S. Lamba",
                        "slug": "Digvijay-S.-Lamba",
                        "structuredName": {
                            "firstName": "Digvijay",
                            "lastName": "Lamba",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Digvijay S. Lamba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094409224"
                        ],
                        "name": "Michel Tourn",
                        "slug": "Michel-Tourn",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Tourn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michel Tourn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116117928"
                        ],
                        "name": "Sanjib Das",
                        "slug": "Sanjib-Das",
                        "structuredName": {
                            "firstName": "Sanjib",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjib Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50323977"
                        ],
                        "name": "S. Subramaniam",
                        "slug": "S.-Subramaniam",
                        "structuredName": {
                            "firstName": "Sri",
                            "lastName": "Subramaniam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Subramaniam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69484854"
                        ],
                        "name": "A. Rajaraman",
                        "slug": "A.-Rajaraman",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Rajaraman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rajaraman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2866972"
                        ],
                        "name": "Venky Harinarayan",
                        "slug": "Venky-Harinarayan",
                        "structuredName": {
                            "firstName": "Venky",
                            "lastName": "Harinarayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Venky Harinarayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3030274"
                        ],
                        "name": "A. Doan",
                        "slug": "A.-Doan",
                        "structuredName": {
                            "firstName": "AnHai",
                            "lastName": "Doan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "In recent years, several large-scale knowledge bases (KBs) have been constructed, including academic projects such as YAGO [37], NELL [8], DBpedia [3], and Elementary/ DeepDive [30], as well as commercial projects, such as those by Microsoft1, Google2, Facebook3, Walmart [?]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2955648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "745e1710805f1ea18d3a9cb59b378bec93503136",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A knowledge base (KB) contains a set of concepts, instances, and relationships. Over the past decade, numerous KBs have been built, and used to power a growing array of applications. Despite this flurry of activities, however, surprisingly little has been published about the end-to-end process of building, maintaining, and using such KBs in industry. In this paper we describe such a process. In particular, we describe how we build, update, and curate a large KB at Kosmix, a Bay Area startup, and later at WalmartLabs, a development and research lab of Walmart. We discuss how we use this KB to power a range of applications, including query understanding, Deep Web search, in-context advertising, event monitoring in social media, product search, social gifting, and social mining. Finally, we discuss how the KB team is organized, and the lessons learned. Our goal with this paper is to provide a real-world case study, and to contribute to the emerging direction of building, maintaining, and using knowledge bases for data management applications."
            },
            "slug": "Building,-maintaining,-and-using-knowledge-bases:-a-Deshpande-Lamba",
            "title": {
                "fragments": [],
                "text": "Building, maintaining, and using knowledge bases: a report from the trenches"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper describes how to build, update, and curate a large KB at Kosmix, a Bay Area startup, and later at WalmartLabs, a development and research lab of Walmart."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '13"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1875233"
                        ],
                        "name": "Bonan Min",
                        "slug": "Bonan-Min",
                        "structuredName": {
                            "firstName": "Bonan",
                            "lastName": "Min",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bonan Min"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053672176"
                        ],
                        "name": "Li Wan",
                        "slug": "Li-Wan",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Wan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Wan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146410292"
                        ],
                        "name": "Chang Wang",
                        "slug": "Chang-Wang",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2771137"
                        ],
                        "name": "David Gondek",
                        "slug": "David-Gondek",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Gondek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Gondek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[28]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "There are more sophisticated methods for training models that don\u2019t make this assumption (such as [28, 36]), but we leave the integration of such methods into KV to future work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6018348,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5bf4826f769cfdd835a509d23c69ecf60023108",
            "isKey": false,
            "numCitedBy": 232,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Distant supervision, heuristically labeling a corpus using a knowledge base, has emerged as a popular choice for training relation extractors. In this paper, we show that a significant number of \u201cnegative\u201c examples generated by the labeling process are false negatives because the knowledge base is incomplete. Therefore the heuristic for generating negative examples has a seriousflaw. Building on a state-of-the-art distantly-supervised extraction algorithm, we proposed an algorithm that learns from only positive and unlabeled labels at the pair-of-entity level. Experimental results demonstrate its advantage over existing algorithms."
            },
            "slug": "Distant-Supervision-for-Relation-Extraction-with-an-Min-Grishman",
            "title": {
                "fragments": [],
                "text": "Distant Supervision for Relation Extraction with an Incomplete Knowledge Base"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a significant number of \u201cnegative\u201c examples generated by the labeling process are false negatives because the knowledge base is incomplete, therefore the heuristic for generating negative examples has a seriousflaw."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50536468"
                        ],
                        "name": "Danqi Chen",
                        "slug": "Danqi-Chen",
                        "structuredName": {
                            "firstName": "Danqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "The numbers in the legend are the AUC scores.\nthe two prior methods helps performance, since they have complementary strengths and weaknesses (different inductive biases): the AUC of the fused system is 0.911."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8429835,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50d53cc562225549457cbc782546bfbe1ac6f0cf",
            "isKey": true,
            "numCitedBy": 1557,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Knowledge bases are an important resource for question answering and other tasks but often suffer from incompleteness and lack of ability to reason over their discrete entities and relationships. In this paper we introduce an expressive neural tensor network suitable for reasoning over relationships between two entities. Previous work represented entities as either discrete atomic units or with a single entity vector representation. We show that performance can be improved when entities are represented as an average of their constituting word vectors. This allows sharing of statistical strength between, for instance, facts involving the \"Sumatran tiger\" and \"Bengal tiger.\" Lastly, we demonstrate that all models improve when these word vectors are initialized with vectors learned from unsupervised large corpora. We assess the model by considering the problem of predicting additional true relations between entities given a subset of the knowledge base. Our model outperforms previous models and can classify unseen relationships in WordNet and FreeBase with an accuracy of 86.2% and 90.0%, respectively."
            },
            "slug": "Reasoning-With-Neural-Tensor-Networks-for-Knowledge-Socher-Chen",
            "title": {
                "fragments": [],
                "text": "Reasoning With Neural Tensor Networks for Knowledge Base Completion"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An expressive neural tensor network suitable for reasoning over relationships between two entities given a subset of the knowledge base is introduced and performance can be improved when entities are represented as an average of their constituting word vectors."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729762"
                        ],
                        "name": "Maximilian Nickel",
                        "slug": "Maximilian-Nickel",
                        "structuredName": {
                            "firstName": "Maximilian",
                            "lastName": "Nickel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maximilian Nickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700754"
                        ],
                        "name": "Volker Tresp",
                        "slug": "Volker-Tresp",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Tresp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volker Tresp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688561"
                        ],
                        "name": "H. Kriegel",
                        "slug": "H.-Kriegel",
                        "structuredName": {
                            "firstName": "Hans-Peter",
                            "lastName": "Kriegel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kriegel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6348464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "498ca0a1f8c980586408addf7ab2919ecdb7dd3d",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Vast amounts of structured information have been published in the Semantic Web's Linked Open Data (LOD) cloud and their size is still growing rapidly. Yet, access to this information via reasoning and querying is sometimes difficult, due to LOD's size, partial data inconsistencies and inherent noisiness. Machine Learning offers an alternative approach to exploiting LOD's data with the advantages that Machine Learning algorithms are typically robust to both noise and data inconsistencies and are able to efficiently utilize non-deterministic dependencies in the data. From a Machine Learning point of view, LOD is challenging due to its relational nature and its scale. Here, we present an efficient approach to relational learning on LOD data, based on the factorization of a sparse tensor that scales to data consisting of millions of entities, hundreds of relations and billions of known facts. Furthermore, we show how ontological knowledge can be incorporated in the factorization to improve learning results and how computation can be distributed across multiple nodes. We demonstrate that our approach is able to factorize the YAGO~2 core ontology and globally predict statements for this large knowledge base using a single dual-core desktop computer. Furthermore, we show experimentally that our approach achieves good results in several relational learning tasks that are relevant to Linked Data. Once a factorization has been computed, our model is able to predict efficiently, and without any additional training, the likelihood of any of the 4.3 \u22c5 1014 possible triples in the YAGO~2 core ontology."
            },
            "slug": "Factorizing-YAGO:-scalable-machine-learning-for-Nickel-Tresp",
            "title": {
                "fragments": [],
                "text": "Factorizing YAGO: scalable machine learning for linked data"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents an efficient approach to relational learning on LOD data, based on the factorization of a sparse tensor that scales to data consisting of millions of entities, hundreds of relations and billions of known facts, and shows how ontological knowledge can be incorporated in the factorizations to improve learning results and how computation can be distributed across multiple nodes."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144438930"
                        ],
                        "name": "Xiang Li",
                        "slug": "Xiang-Li",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiang Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [45, 25])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11868924,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66b33c252aca322d12526c14c56d49af494be455",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction systems automatically extract structured information from machine-readable documents, such as newswire, web, and multimedia. Despite significant improvement, the performance is far from perfect. Hence, it is useful to accurately estimate confidence in the correctness of the extracted information. Using the Knowledge Base Population Slot Filling task as a case study, we propose a confidence estimation model based on the Maximum Entropy framework, obtaining an average precision of83.5%, Pearson coefficient of54.2%, and2.3%absolute improvement in F-measure score through a weighted voting strategy."
            },
            "slug": "Confidence-Estimation-for-Knowledge-Base-Population-Li-Grishman",
            "title": {
                "fragments": [],
                "text": "Confidence Estimation for Knowledge Base Population"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A confidence estimation model based on the Maximum Entropy framework is proposed, obtaining an average precision of 83.5%, Pearson coefficient of 54.2%, and 2.3%absolute improvement in F-measure score through a weighted voting strategy."
            },
            "venue": {
                "fragments": [],
                "text": "RANLP"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2753838"
                        ],
                        "name": "Ben Hachey",
                        "slug": "Ben-Hachey",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Hachey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ben Hachey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145122113"
                        ],
                        "name": "Will Radford",
                        "slug": "Will-Radford",
                        "structuredName": {
                            "firstName": "Will",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Will Radford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3083916"
                        ],
                        "name": "J. Nothman",
                        "slug": "J.-Nothman",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Nothman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nothman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3182726"
                        ],
                        "name": "Matthew Honnibal",
                        "slug": "Matthew-Honnibal",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Honnibal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Honnibal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733593"
                        ],
                        "name": "J. Curran",
                        "slug": "J.-Curran",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Curran",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Curran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "The in-house named entity linkage system we use is similar to the methods described in [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12263057,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b8bc4268a2084436f1f1e18bee0b97183ccc3a4",
            "isKey": false,
            "numCitedBy": 265,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Evaluating-Entity-Linking-with-Wikipedia-Hachey-Radford",
            "title": {
                "fragments": [],
                "text": "Evaluating Entity Linking with Wikipedia"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987641"
                        ],
                        "name": "Michael L. Wick",
                        "slug": "Michael-L.-Wick",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wick",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael L. Wick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34650964"
                        ],
                        "name": "Sameer Singh",
                        "slug": "Sameer-Singh",
                        "structuredName": {
                            "firstName": "Sameer",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sameer Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2441120"
                        ],
                        "name": "Ari Kobren",
                        "slug": "Ari-Kobren",
                        "structuredName": {
                            "firstName": "Ari",
                            "lastName": "Kobren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ari Kobren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [45, 25])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14165862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "448fb28797e73dd69a205e80c470cc33bb212065",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The purpose of this paper is to begin a conversation about the importance and role of confidence estimation in knowledge bases (KBs). KBs are never perfectly accurate, yet without confidence reporting their users are likely to treat them as if they were, possibly with serious real-world consequences. We define a notion of confidence based on the probability of a KB fact being true. For automatically constructed KBs we propose several algorithms for estimating this confidence from pre-existing probabilistic models of data integration and KB construction. In particular, this paper focuses on confidence estimation in entity resolution. A goal of our exposition here is to encourage creators and curators of KBs to include confidence estimates for entities and relations in their KBs."
            },
            "slug": "Assessing-confidence-of-knowledge-base-content-with-Wick-Singh",
            "title": {
                "fragments": [],
                "text": "Assessing confidence of knowledge base content with an experimental study in entity resolution"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper defines a notion of confidence based on the probability of a KB fact being true and proposes several algorithms for estimating this confidence from pre-existing probabilistic models of data integration and KB construction."
            },
            "venue": {
                "fragments": [],
                "text": "AKBC '13"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1873744"
                        ],
                        "name": "Luis Gal\u00e1rraga",
                        "slug": "Luis-Gal\u00e1rraga",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Gal\u00e1rraga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luis Gal\u00e1rraga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2485235"
                        ],
                        "name": "Christina Teflioudi",
                        "slug": "Christina-Teflioudi",
                        "structuredName": {
                            "firstName": "Christina",
                            "lastName": "Teflioudi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christina Teflioudi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682407"
                        ],
                        "name": "K. Hose",
                        "slug": "K.-Hose",
                        "structuredName": {
                            "firstName": "Katja",
                            "lastName": "Hose",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hose"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679784"
                        ],
                        "name": "Fabian M. Suchanek",
                        "slug": "Fabian-M.-Suchanek",
                        "structuredName": {
                            "firstName": "Fabian",
                            "lastName": "Suchanek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabian M. Suchanek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [15])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This heuristic is also used in previous works such as [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4090850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87245d2460b3545a161db78bf0a450422b66f90f",
            "isKey": false,
            "numCitedBy": 425,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in information extraction have led to huge knowledge bases (KBs), which capture knowledge in a machine-readable format. Inductive Logic Programming (ILP) can be used to mine logical rules from the KB. These rules can help deduce and add missing knowledge to the KB. While ILP is a mature field, mining logical rules from KBs is different in two aspects: First, current rule mining systems are easily overwhelmed by the amount of data (state-of-the art systems cannot even run on today's KBs). Second, ILP usually requires counterexamples. KBs, however, implement the open world assumption (OWA), meaning that absent data cannot be used as counterexamples. In this paper, we develop a rule mining model that is explicitly tailored to support the OWA scenario. It is inspired by association rule mining and introduces a novel measure for confidence. Our extensive experiments show that our approach outperforms state-of-the-art approaches in terms of precision and coverage. Furthermore, our system, AMIE, mines rules orders of magnitude faster than state-of-the-art approaches."
            },
            "slug": "AMIE:-association-rule-mining-under-incomplete-in-Gal\u00e1rraga-Teflioudi",
            "title": {
                "fragments": [],
                "text": "AMIE: association rule mining under incomplete evidence in ontological knowledge bases"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper develops a rule mining model that is explicitly tailored to support the open world assumption (OWA), and is inspired by association rule mining and introduces a novel measure for confidence."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71353149"
                        ],
                        "name": "Thomas Franz",
                        "slug": "Thomas-Franz",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Franz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Franz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46312930"
                        ],
                        "name": "A. Schultz",
                        "slug": "A.-Schultz",
                        "structuredName": {
                            "firstName": "Antje",
                            "lastName": "Schultz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schultz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144589889"
                        ],
                        "name": "Sergej Sizov",
                        "slug": "Sergej-Sizov",
                        "structuredName": {
                            "firstName": "Sergej",
                            "lastName": "Sizov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergej Sizov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752093"
                        ],
                        "name": "Steffen Staab",
                        "slug": "Steffen-Staab",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Staab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Staab"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "If we ignore the sigmoid transform (needed to produce binary responses), this is equivalent to the PARAFAC method of tensor decomposition [14, 5, 11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10499585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16840a46b3980eb39382814adfe2270bd5bbdbc7",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "The Semantic Web fosters novel applications targeting a more efficient and satisfying exploitation of the data available on the web, e.g. faceted browsing of linked open data. Large amounts and high diversity of knowledge in the Semantic Web pose the challenging question of appropriate relevance ranking for producing fine-grained and rich descriptions of the available data, e.g. to guide the user along most promising knowledge aspects. Existing methods for graph-based authority ranking lack support for fine-grained latent coherence between resources and predicates (i.e. support for link semantics in the linked data model). In this paper, we present TripleRank, a novel approach for faceted authority ranking in the context of RDF knowledge bases. TripleRank captures the additional latent semantics of Semantic Web data by means of statistical methods in order to produce richer descriptions of the available data. We model the Semantic Web by a 3-dimensional tensor that enables the seamless representation of arbitrary semantic links. For the analysis of that model, we apply the PARAFAC decomposition, which can be seen as a multi-modal counterpart to Web authority ranking with HITS. The result are groupings of resources and predicates that characterize their authority and navigational (hub) properties with respect to identified topics. We have applied TripleRank to multiple data sets from the linked open data community and gathered encouraging feedback in a user evaluation where TripleRank results have been exploited in a faceted browsing scenario."
            },
            "slug": "TripleRank:-Ranking-Semantic-Web-Data-by-Tensor-Franz-Schultz",
            "title": {
                "fragments": [],
                "text": "TripleRank: Ranking Semantic Web Data by Tensor Decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents TripleRank, a novel approach for faceted authority ranking in the context of RDF knowledge bases that captures the additional latent semantics of Semantic Web data by means of statistical methods in order to produce richer descriptions of the available data."
            },
            "venue": {
                "fragments": [],
                "text": "SEMWEB"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3119801"
                        ],
                        "name": "Xavier Glorot",
                        "slug": "Xavier-Glorot",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Glorot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xavier Glorot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "If we ignore the sigmoid transform (needed to produce binary responses), this is equivalent to the PARAFAC method of tensor decomposition [14, 5, 11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5555779,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2f72cfb48d15d4d2bd1e91a92e7f3ac8635d433",
            "isKey": false,
            "numCitedBy": 328,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Open-text semantic parsers are designed to interpret any statement in natural language by inferring a corresponding meaning representation (MR \u2013 a formal representation of its sense). Unfortunately, large scale systems cannot be easily machine-learned due to a lack of directly supervised data. We propose a method that learns to assign MRs to a wide range of text (using a dictionary of more than 70,000 words mapped to more than 40,000 entities) thanks to a training scheme that combines learning from knowledge bases (e.g. WordNet) with learning from raw text. The model jointly learns representations of words, entities and MRs via a multi-task training process operating on these diverse sources of data. Hence, the system ends up providing methods for knowledge acquisition and wordsense disambiguation within the context of semantic parsing in a single elegant framework. Experiments on these various tasks indicate the promise of the approach."
            },
            "slug": "Joint-Learning-of-Words-and-Meaning-Representations-Bordes-Glorot",
            "title": {
                "fragments": [],
                "text": "Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a method that learns to assign MRs to a wide range of text thanks to a training scheme that combines learning from knowledge bases with learning from raw text."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987641"
                        ],
                        "name": "Michael L. Wick",
                        "slug": "Michael-L.-Wick",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wick",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael L. Wick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34650964"
                        ],
                        "name": "Sameer Singh",
                        "slug": "Sameer-Singh",
                        "structuredName": {
                            "firstName": "Sameer",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sameer Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143946714"
                        ],
                        "name": "Harshal Pandya",
                        "slug": "Harshal-Pandya",
                        "structuredName": {
                            "firstName": "Harshal",
                            "lastName": "Pandya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harshal Pandya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7198388,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "332b88bbf73a32bc238e09ee3d33b8c331317278",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Entity resolution, the task of automatically determining which mentions refer to the same real-world entity, is a crucial aspect of knowledge base construction and management. However, performing entity resolution at large scales is challenging because (1) the inference algorithms must cope with unavoidable system scalability issues and (2) the search space grows exponentially in the number of mentions. Current conventional wisdom has been that performing coreference at these scales requires decomposing the problem by first solving the simpler task of entity-linking (matching a set of mentions to a known set of KB entities), and then performing entity discovery as a post-processing step (to identify new entities not present in the KB). However, we argue that this traditional approach is harmful to both entity-linking and overall coreference accuracy. Therefore, we embrace the challenge of jointly modeling entity-linking and entity-discovery as a single entity resolution problem. In order to make progress towards scalability we (1) present a model that reasons over compact hierarchical entity representations, and (2) propose a novel distributed inference architecture that does not suffer from the synchronicity bottleneck which is inherent in map-reduce architectures. We demonstrate that more test-time data actually improves the accuracy of coreference, and show that joint coreference is substantially more accurate than traditional entity-linking, reducing error by 75%."
            },
            "slug": "A-joint-model-for-discovering-and-linking-entities-Wick-Singh",
            "title": {
                "fragments": [],
                "text": "A joint model for discovering and linking entities"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work embraces the challenge of jointly modeling entity-linking and entity-discovery as a single entity resolution problem and presents a model that reasons over compact hierarchical entity representations, and proposes a novel distributed inference architecture that does not suffer from the synchronicity bottleneck which is inherent in map-reduce architectures."
            },
            "venue": {
                "fragments": [],
                "text": "AKBC '13"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111220343"
                        ],
                        "name": "D. Wang",
                        "slug": "D.-Wang",
                        "structuredName": {
                            "firstName": "Daisy",
                            "lastName": "Wang",
                            "middleNames": [
                                "Zhe"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48144872"
                        ],
                        "name": "Eugene Wu",
                        "slug": "Eugene-Wu",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145955157"
                        ],
                        "name": "Yang Zhang",
                        "slug": "Yang-Zhang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "The confidence scores from each extractor (and/or the fused system) are not necessarily on the same scale, and cannot necessarily be interpreted as probabilities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15642206,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b5077161a6f55a0d18cdfa3abbb612663d08d69",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The World-Wide Web consists of a huge number of unstructured documents, but it also contains structured data in the form of HTML tables. We extracted 14.1 billion HTML tables from Google's general-purpose web crawl, and used statistical classification techniques to find the estimated 154M that contain high-quality relational data. Because each relational table has its own \"schema\" of labeled and typed columns, each such table can be considered a small structured database. The resulting corpus of databases is larger than any other corpus we are aware of, by at least five orders of magnitude. \n \nWe describe the WEBTABLES system to explore two fundamental questions about this collection of databases. First, what are effective techniques for searching for structured data at search-engine scales? Second, what additional power can be derived by analyzing such a huge corpus? \n \nFirst, we develop new techniques for keyword search over a corpus of tables, and show that they can achieve substantially higher relevance than solutions based on a traditional search engine. Second, we introduce a new object derived from the database corpus: the attribute correlation statistics database (AcsDB) that records corpus-wide statistics on co-occurrences of schema elements. In addition to improving search relevance, the AcsDB makes possible several novel applications: schema auto-complete, which helps a database designer to choose schema elements; attribute synonym finding, which automatically computes attribute synonym pairs for schema matching; and join-graph traversal, which allows a user to navigate between extracted schemas using automatically-generated join links."
            },
            "slug": "WebTables:-exploring-the-power-of-tables-on-the-web-Cafarella-Halevy",
            "title": {
                "fragments": [],
                "text": "WebTables: exploring the power of tables on the web"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The WEBTABLES system develops new techniques for keyword search over a corpus of tables, and shows that they can achieve substantially higher relevance than solutions based on a traditional search engine."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2674444"
                        ],
                        "name": "Mausam",
                        "slug": "Mausam",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Mausam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mausam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144874222"
                        ],
                        "name": "Michael Schmitz",
                        "slug": "Michael-Schmitz",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Schmitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Schmitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093554992"
                        ],
                        "name": "Robert Bart",
                        "slug": "Robert-Bart",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Bart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 240
                            }
                        ],
                        "text": "This literature can be clustered into 4 main groups: (1) approaches such as YAGO [37], YAGO2 [18], DBpedia [3], and Freebase [4], which are built on Wikipedia infoboxes and other structured data sources; (2) approaches such as Reverb [11], OLLIE [24], and PRISMATIC [12], which use open information (schema-less) extraction techniques applied to the entire web; (3) approaches such as NELL/ ReadTheWeb [8], PROSPERA [28], and DeepDive/ Elementary [30], which extract information from the entire web, but use a fixed ontology/ schema; and (4) approaches such as Probase [44], which construct taxonomies (is-a hierarchies), as opposed to general KBs with multiple types of predicates."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 246
                            }
                        ],
                        "text": "This literature can be clustered into 4 main groups: (1) approaches such as YAGO [39], YAGO2 [19], DBpedia [3], and Freebase [4], which are built on Wikipedia infoboxes and other structured data sources; (2) approaches such as Reverb [12], OLLIE [26], and PRISMATIC [13], which use open information (schema-less) extraction techniques applied to the entire web; (3) approaches such as NELL/ ReadTheWeb [8], PROSPERA [30], and DeepDive/ Elementary [32], which extract information from the entire web, but use a fixed ontology/ schema; and (4) approaches such as Probase [47], which construct taxonomies (is-a hierarchies), as opposed to general KBs with multiple types of predicates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 74065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ad0e78a9619c50bcb3cae4a589ec9a5d38c437c",
            "isKey": false,
            "numCitedBy": 722,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Open Information Extraction (IE) systems extract relational tuples from text, without requiring a pre-specified vocabulary, by identifying relation phrases and associated arguments in arbitrary sentences. However, state-of-the-art Open IE systems such as ReVerb and woe share two important weaknesses -- (1) they extract only relations that are mediated by verbs, and (2) they ignore context, thus extracting tuples that are not asserted as factual. This paper presents ollie, a substantially improved Open IE system that addresses both these limitations. First, ollie achieves high yield by extracting relations mediated by nouns, adjectives, and more. Second, a context-analysis step increases precision by including contextual information from the sentence in the extractions. ollie obtains 2.7 times the area under precision-yield curve (AUC) compared to ReVerb and 1.9 times the AUC of woeparse."
            },
            "slug": "Open-Language-Learning-for-Information-Extraction-Mausam-Schmitz",
            "title": {
                "fragments": [],
                "text": "Open Language Learning for Information Extraction"
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2282727"
                        ],
                        "name": "Lucas Drumond",
                        "slug": "Lucas-Drumond",
                        "structuredName": {
                            "firstName": "Lucas",
                            "lastName": "Drumond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucas Drumond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388781075"
                        ],
                        "name": "L. Schmidt-Thieme",
                        "slug": "L.-Schmidt-Thieme",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Schmidt-Thieme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Schmidt-Thieme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 2
                            }
                        ],
                        "text": ", [29, 10, 19, 35]); and (3) methods that approximate the correlation using algorithmic approaches, such as random walks [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 138
                            }
                        ],
                        "text": "If we ignore the sigmoid transform (needed to produce binary responses), this is equivalent to the PARAFAC method of tensor decomposition [13, 5, 10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11884399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46219ce9ec4ef309fd384ce235d97cdee4926ad3",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "On RDF datasets, the truth values of triples are known when they are either explicitly stated or can be inferred using logical entailment. Due to the open world semantics of RDF, nothing can be said about the truth values of triples that are neither in the dataset nor can be logically inferred. By estimating the truth values of such triples, one could discover new information from the database thus enabling to broaden the scope of queries to an RDF base that can be answered, support knowledge engineers in maintaining such knowledge bases or recommend users resources worth looking into for instance. In this paper, we present a new approach to predict the truth values of any RDF triple. Our approach uses a 3-dimensional tensor representation of the RDF knowledge base and applies tensor factorization techniques that take open world semantics into account to predict new true triples given already observed ones. We report results of experiments on real world datasets comparing different tensor factorization models. Our empirical results indicate that our approach is highly successful in estimating triple truth values on incomplete RDF datasets."
            },
            "slug": "Predicting-RDF-triples-in-incomplete-knowledge-with-Drumond-Rendle",
            "title": {
                "fragments": [],
                "text": "Predicting RDF triples in incomplete knowledge bases with tensor factorization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper presents a new approach to predict the truth values of any RDF triple that uses a 3-dimensional tensor representation of the RDF knowledge base and applies tensor factorization techniques that take open world semantics into account to predict new true triples given already observed ones."
            },
            "venue": {
                "fragments": [],
                "text": "SAC '12"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110342266"
                        ],
                        "name": "Rahul Gupta",
                        "slug": "Rahul-Gupta",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rahul Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1524732527"
                        ],
                        "name": "Xuezhi Wang",
                        "slug": "Xuezhi-Wang",
                        "structuredName": {
                            "firstName": "Xuezhi",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuezhi Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3288247"
                        ],
                        "name": "S. E. Whang",
                        "slug": "S.-E.-Whang",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Whang",
                            "middleNames": [
                                "Euijong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. E. Whang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110923100"
                        ],
                        "name": "Fei Wu",
                        "slug": "Fei-Wu",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6007468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b16ff58cdb496c41c76b33ea8666be050598afe8",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Search engines make significant efforts to recognize queries that can be answered by structured data and invest heavily in creating and maintaining high-precision databases. While these databases have a relatively wide coverage of entities, the number of attributes they model (e.g., GDP, CAPITAL, ANTHEM) is relatively small. Extending the number of attributes known to the search engine can enable it to more precisely answer queries from the long and heavy tail, extract a broader range of facts from the Web, and recover the semantics of tables on the Web. \n \nWe describe Biperpedia, an ontology with 1.6M (class, attribute) pairs and 67K distinct attribute names. Biperpedia extracts attributes from the query stream, and then uses the best extractions to seed attribute extraction from text. For every attribute Biperpedia saves a set of synonyms and text patterns in which it appears, thereby enabling it to recognize the attribute in more contexts. In addition to a detailed analysis of the quality of Biperpedia, we show that it can increase the number of Web tables whose semantics we can recover by more than a factor of 4 compared with Freebase."
            },
            "slug": "Biperpedia:-An-Ontology-for-Search-Applications-Gupta-Halevy",
            "title": {
                "fragments": [],
                "text": "Biperpedia: An Ontology for Search Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Bperpedia, an ontology with 1.6M (class, attribute) pairs and 67K distinct attribute names, can increase the number of Web tables whose semantics the authors can recover by more than a factor of 4 compared with Freebase."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734332"
                        ],
                        "name": "Petros Venetis",
                        "slug": "Petros-Venetis",
                        "structuredName": {
                            "firstName": "Petros",
                            "lastName": "Venetis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petros Venetis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2224716"
                        ],
                        "name": "J. Madhavan",
                        "slug": "J.-Madhavan",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Madhavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724629"
                        ],
                        "name": "Marius Pasca",
                        "slug": "Marius-Pasca",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Pasca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marius Pasca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34414997"
                        ],
                        "name": "Warren Shen",
                        "slug": "Warren-Shen",
                        "structuredName": {
                            "firstName": "Warren",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Warren Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110923100"
                        ],
                        "name": "Fei Wu",
                        "slug": "Fei-Wu",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39379522"
                        ],
                        "name": "Gengxin Miao",
                        "slug": "Gengxin-Miao",
                        "structuredName": {
                            "firstName": "Gengxin",
                            "lastName": "Miao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gengxin Miao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118841585"
                        ],
                        "name": "Chung Wu",
                        "slug": "Chung-Wu",
                        "structuredName": {
                            "firstName": "Chung",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 263
                            }
                        ],
                        "text": "Then we attempt to identify the relation that is expressed in each column of the table by looking at the entities in each column, and reasoning about which predicate each column could correspond to, by matching to Freebase, as in standard schema matching methods [39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11359711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c44cef69334cb62e6f6c7d0d245e1934f599815f",
            "isKey": false,
            "numCitedBy": 338,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The Web offers a corpus of over 100 million tables [6], but the meaning of each table is rarely explicit from the table itself. Header rows exist in few cases and even when they do, the attribute names are typically useless. We describe a system that attempts to recover the semantics of tables by enriching the table with additional annotations. Our annotations facilitate operations such as searching for tables and finding related tables. \n \nTo recover semantics of tables, we leverage a database of class labels and relationships automatically extracted from the Web. The database of classes and relationships has very wide coverage, but is also noisy. We attach a class label to a column if a sufficient number of the values in the column are identified with that label in the database of class labels, and analogously for binary relationships. We describe a formal model for reasoning about when we have seen sufficient evidence for a label, and show that it performs substantially better than a simple majority scheme. We describe a set of experiments that illustrate the utility of the recovered semantics for table search and show that it performs substantially better than previous approaches. In addition, we characterize what fraction of tables on the Web can be annotated using our approach."
            },
            "slug": "Recovering-Semantics-of-Tables-on-the-Web-Venetis-Halevy",
            "title": {
                "fragments": [],
                "text": "Recovering Semantics of Tables on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A system that attempts to recover the semantics of tables by enriching the table with additional annotations, which leverages a database of class labels and relationships automatically extracted from the Web."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727527"
                        ],
                        "name": "Johannes Hoffart",
                        "slug": "Johannes-Hoffart",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "Hoffart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johannes Hoffart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679784"
                        ],
                        "name": "Fabian M. Suchanek",
                        "slug": "Fabian-M.-Suchanek",
                        "structuredName": {
                            "firstName": "Fabian",
                            "lastName": "Suchanek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabian M. Suchanek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806397"
                        ],
                        "name": "K. Berberich",
                        "slug": "K.-Berberich",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Berberich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Berberich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751591"
                        ],
                        "name": "G. Weikum",
                        "slug": "G.-Weikum",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Weikum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Weikum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "This literature can be clustered into 4 main groups: (1) approaches such as YAGO [37], YAGO2 [18], DBpedia [3], and Freebase [4], which are built on Wikipedia infoboxes and other structured data sources; (2) approaches such as Reverb [11], OLLIE [24], and PRISMATIC [12], which use open information (schema-less) extraction techniques applied to the entire web; (3) approaches such as NELL/ ReadTheWeb [8], PROSPERA [28], and DeepDive/ Elementary [30], which extract information from the entire web, but use a fixed ontology/ schema; and (4) approaches such as Probase [44], which construct taxonomies (is-a hierarchies), as opposed to general KBs with multiple types of predicates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "(An alternative approach is to reify the pairwise relations, and add extra assertions to them, as in the YAGO2 system [18]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "YAGO2: A Spatially and Temporally Enhanced Knowledge Base from Wikipedia."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 105
                            }
                        ],
                        "text": "(An alternative approach is to reify the pairwise relations, and add extra assertions to them, as in the YAGO2 system [18].)"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6118799,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4dfe43ddfcfbe00dd663a4d70b0df9dcc8c92184",
            "isKey": true,
            "numCitedBy": 1138,
            "numCiting": 156,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "YAGO2:-A-Spatially-and-Temporally-Enhanced-Base-Hoffart-Suchanek",
            "title": {
                "fragments": [],
                "text": "YAGO2: A Spatially and Temporally Enhanced Knowledge Base from Wikipedia: Extended Abstract"
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48203512"
                        ],
                        "name": "James Fan",
                        "slug": "James-Fan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295799"
                        ],
                        "name": "D. Ferrucci",
                        "slug": "D.-Ferrucci",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ferrucci",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ferrucci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2771137"
                        ],
                        "name": "David Gondek",
                        "slug": "David-Gondek",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Gondek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Gondek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1973186"
                        ],
                        "name": "Aditya Kalyanpur",
                        "slug": "Aditya-Kalyanpur",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Kalyanpur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aditya Kalyanpur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 256
                            }
                        ],
                        "text": "This literature can be clustered into 4 main groups: (1) approaches such as YAGO [37], YAGO2 [18], DBpedia [3], and Freebase [4], which are built on Wikipedia infoboxes and other structured data sources; (2) approaches such as Reverb [11], OLLIE [24], and PRISMATIC [12], which use open information (schema-less) extraction techniques applied to the entire web; (3) approaches such as NELL/ ReadTheWeb [8], PROSPERA [28], and DeepDive/ Elementary [30], which extract information from the entire web, but use a fixed ontology/ schema; and (4) approaches such as Probase [44], which construct taxonomies (is-a hierarchies), as opposed to general KBs with multiple types of predicates."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 266
                            }
                        ],
                        "text": "This literature can be clustered into 4 main groups: (1) approaches such as YAGO [39], YAGO2 [19], DBpedia [3], and Freebase [4], which are built on Wikipedia infoboxes and other structured data sources; (2) approaches such as Reverb [12], OLLIE [26], and PRISMATIC [13], which use open information (schema-less) extraction techniques applied to the entire web; (3) approaches such as NELL/ ReadTheWeb [8], PROSPERA [30], and DeepDive/ Elementary [32], which extract information from the entire web, but use a fixed ontology/ schema; and (4) approaches such as Probase [47], which construct taxonomies (is-a hierarchies), as opposed to general KBs with multiple types of predicates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16372879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b0e2254fb6cf7f82c97d9c1f9aabb973bf77751",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the main bottlenecks in natural language processing is the lack of a comprehensive lexicalized relation resource that contains fine grained knowledge on predicates. In this paper, we present PRISMATIC, a large scale lexicalized relation resource that is automatically created over 30 gb of text. Specifically, we describe what kind of information is collected in PRISMATIC and how it compares with existing lexical resources. Our main focus has been on building the infrastructure and gathering the data. Although we are still in the early stages of applying PRISMATIC to a wide variety of applications, we believe the resource will be of tremendous value for AI researchers, and we discuss some of potential applications in this paper."
            },
            "slug": "PRISMATIC:-Inducing-Knowledge-from-a-Large-Scale-Fan-Ferrucci",
            "title": {
                "fragments": [],
                "text": "PRISMATIC: Inducing Knowledge from a Large Scale Lexicalized Relation Resource"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Although the resource is still in the early stages of applying PRISMATIC to a wide variety of applications, it is believed the resource will be of tremendous value for AI researchers, and some of potential applications are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "HLT-NAACL 2010"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111220343"
                        ],
                        "name": "D. Wang",
                        "slug": "D.-Wang",
                        "structuredName": {
                            "firstName": "Daisy",
                            "lastName": "Wang",
                            "middleNames": [
                                "Zhe"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31650939"
                        ],
                        "name": "E. Michelakis",
                        "slug": "E.-Michelakis",
                        "structuredName": {
                            "firstName": "Eirinaios",
                            "lastName": "Michelakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Michelakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738210"
                        ],
                        "name": "M. Garofalakis",
                        "slug": "M.-Garofalakis",
                        "structuredName": {
                            "firstName": "Minos",
                            "lastName": "Garofalakis",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garofalakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695576"
                        ],
                        "name": "J. Hellerstein",
                        "slug": "J.-Hellerstein",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Hellerstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hellerstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5471497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d3d96e7fd9e50d815f34241a36cc43c1ed67006",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Several real-world applications need to effectively manage and reason about large amounts of data that are inherently uncertain. For instance, pervasive computing applications must constantly reason about volumes of noisy sensory readings for a variety of reasons, including motion prediction and human behavior modeling. Such probabilistic data analyses require sophisticated machine-learning tools that can effectively model the complex spatio/temporal correlation patterns present in uncertain sensory data. Unfortunately, to date, most existing approaches to probabilistic database systems have relied on somewhat simplistic models of uncertainty that can be easily mapped onto existing relational architectures: Probabilistic information is typically associated with individual data tuples, with only limited or no support for effectively capturing and reasoning about complex data correlations. In this paper, we introduce BayesStore, a novel probabilistic data management architecture built on the principle of handling statistical models and probabilistic inference tools as first-class citizens of the database system. Adopting a machine-learning view, BAYESSTORE employs concise statistical relational models to effectively encode the correlation patterns between uncertain data, and promotes probabilistic inference and statistical model manipulation as part of the standard DBMS operator repertoire to support efficient and sound query processing. We present BAYESSTORE's uncertainty model based on a novel, first-order statistical model, and we redefine traditional query processing operators, to manipulate the data and the probabilistic models of the database in an efficient manner. Finally, we validate our approach, by demonstrating the value of exploiting data correlations during query processing, and by evaluating a number of optimizations which significantly accelerate query processing."
            },
            "slug": "BayesStore:-managing-large,-uncertain-data-with-Wang-Michelakis",
            "title": {
                "fragments": [],
                "text": "BayesStore: managing large, uncertain data repositories with probabilistic graphical models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper introduces BayesStore, a novel probabilistic data management architecture built on the principle of handling statistical models and probabilistically inference tools as first-class citizens of the database system, and presents BAYESSTORE's uncertainty model based on a novel, first-order statistical model, and redefine traditional query processing operators, to manipulate the data and the probabilism models of thedatabase in an efficient manner."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32301760"
                        ],
                        "name": "Gabor Angeli",
                        "slug": "Gabor-Angeli",
                        "structuredName": {
                            "firstName": "Gabor",
                            "lastName": "Angeli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabor Angeli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[2])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8172187,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a9d6ac353c189f9659ca48743d1d5ecaf9c8d69",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Large databases of facts are prevalent in many applications. Such databases are accurate, but as they broaden their scope they become increasingly incomplete. In contrast to extending such a database, we present a system to query whether it contains an arbitrary fact. This work can be thought of as re-casting open domain information extraction: rather than growing a database of known facts, we smooth this data into a database in which any possible fact has membership with some confidence. We evaluate our system predicting held out facts, achieving 74.2% accuracy and outperforming multiple baselines. We also evaluate the system as a commonsense filter for the ReVerb Open IE system, and as a method for answer validation in a Question Answering task."
            },
            "slug": "Philosophers-are-Mortal:-Inferring-the-Truth-of-Angeli-Manning",
            "title": {
                "fragments": [],
                "text": "Philosophers are Mortal: Inferring the Truth of Unseen Facts"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work smooths a database of known facts into a database in which any possible fact has membership with some confidence, and evaluates the system predicting held out facts, achieving 74.2% accuracy and outperforming multiple baselines."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38087946"
                        ],
                        "name": "Anthony Fader",
                        "slug": "Anthony-Fader",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Fader",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Fader"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Knowledge bases that use a fixed ontology should be contrasted with open information extraction (Open IE) approaches, such as Reverb [12], which work at the lexical level."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10318045,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4b651d6a904f69f8fa1dcad4ebe972296af3a9a",
            "isKey": false,
            "numCitedBy": 1249,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Open Information Extraction (IE) is the task of extracting assertions from massive corpora without requiring a pre-specified vocabulary. This paper shows that the output of state-of-the-art Open IE systems is rife with uninformative and incoherent extractions. To overcome these problems, we introduce two simple syntactic and lexical constraints on binary relations expressed by verbs. We implemented the constraints in the ReVerb Open IE system, which more than doubles the area under the precision-recall curve relative to previous extractors such as TextRunner and woepos. More than 30% of ReVerb's extractions are at precision 0.8 or higher---compared to virtually none for earlier systems. The paper concludes with a detailed analysis of ReVerb's errors, suggesting directions for future work."
            },
            "slug": "Identifying-Relations-for-Open-Information-Fader-Soderland",
            "title": {
                "fragments": [],
                "text": "Identifying Relations for Open Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Two simple syntactic and lexical constraints on binary relations expressed by verbs are introduced in the ReVerb Open IE system, which more than doubles the area under the precision-recall curve relative to previous extractors such as TextRunner and woepos."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143818235"
                        ],
                        "name": "Andrew Carlson",
                        "slug": "Andrew-Carlson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Carlson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Carlson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31779043"
                        ],
                        "name": "J. Betteridge",
                        "slug": "J.-Betteridge",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Betteridge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Betteridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16411658"
                        ],
                        "name": "B. Kisiel",
                        "slug": "B.-Kisiel",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Kisiel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kisiel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717452"
                        ],
                        "name": "Burr Settles",
                        "slug": "Burr-Settles",
                        "structuredName": {
                            "firstName": "Burr",
                            "lastName": "Settles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Burr Settles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1842532"
                        ],
                        "name": "Estevam Hruschka",
                        "slug": "Estevam-Hruschka",
                        "structuredName": {
                            "firstName": "Estevam",
                            "lastName": "Hruschka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Estevam Hruschka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In recent years, several large-scale knowledge bases (KBs) have been constructed, including academic projects such as YAGO [39], NELL [8], DBpedia [3], and Elementary/ DeepDive [32], as well as commercial projects, such as those by Microsoft, Google, Facebook, Walmart [9], and others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Entity types and predicates come from a fixed ontology, which is similar to that used in other systems, such as YAGO [39], NELL [8], DeepDive [32], and various systems participating in the TAC-KBP slot-filling competition [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "NELL [8] 271 5."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8423494,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7312b8568d63bbbb239583ed282f46cdc40978d",
            "isKey": false,
            "numCitedBy": 1739,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider here the problem of building a never-ending language learner; that is, an intelligent computer agent that runs forever and that each day must (1) extract, or read, information from the web to populate a growing structured knowledge base, and (2) learn to perform this task better than on the previous day. In particular, we propose an approach and a set of design principles for such an agent, describe a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs with an estimated precision of 74% after running for 67 days, and discuss lessons learned from this preliminary attempt to build a never-ending learning agent."
            },
            "slug": "Toward-an-Architecture-for-Never-Ending-Language-Carlson-Betteridge",
            "title": {
                "fragments": [],
                "text": "Toward an Architecture for Never-Ending Language Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This work proposes an approach and a set of design principles for an intelligent computer agent that runs forever and describes a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2224716"
                        ],
                        "name": "J. Madhavan",
                        "slug": "J.-Madhavan",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Madhavan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 226
                            }
                        ],
                        "text": "These can either come from text pages, or from \u201cdeep web\u201d sources, where data are stored in underlying databases and queried by filling HTML forms; these sources together generate more than 1B pages of data in DOM tree format [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7406627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85fb4f38e74717c409316b5ff2936be0c126a1b7",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Though search on the World-Wide Web has focused mostly on unstructured text, there is an increasing amount of structured data on the Web and growing interest in harnessing such data. Moreover, structured data is starting to play a greater role in many of the social movements enabled by the Web, such as citizen participation in government. I will describe several current projects at Google whose overall goal is enable people to create and share structured data on the Web and to leverage structured data in Web search.I will describe our system for crawling millions of \u201ddeep-web\u201d sites, that offer access to high-quality data through HTML forms and the WebTables and Octopus Systems that leverage structured data in HTML tables and lists on the surface web and enable users to piece together multiple datasets. Finally, I\u2019ll describe Fusion Tables, a recently launched data-management service that lets users create and visualize structured and easily and emphasizes the ability to collaborate with other data owners."
            },
            "slug": "Structured-Data-on-the-Web-Cafarella-Halevy",
            "title": {
                "fragments": [],
                "text": "Structured Data on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Fusion Tables is described, a recently launched data-management service that lets users create and visualize structured and easily and emphasizes the ability to collaborate with other data owners."
            },
            "venue": {
                "fragments": [],
                "text": "2010 12th International Asia-Pacific Web Conference"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742448"
                        ],
                        "name": "K. Bollacker",
                        "slug": "K.-Bollacker",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Bollacker",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bollacker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065123479"
                        ],
                        "name": "Colin Evans",
                        "slug": "Colin-Evans",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Evans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Colin Evans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2990264"
                        ],
                        "name": "Praveen K. Paritosh",
                        "slug": "Praveen-K.-Paritosh",
                        "structuredName": {
                            "firstName": "Praveen",
                            "lastName": "Paritosh",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Praveen K. Paritosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399112633"
                        ],
                        "name": "Tim Sturge",
                        "slug": "Tim-Sturge",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Sturge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Sturge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110748390"
                        ],
                        "name": "Jamie Taylor",
                        "slug": "Jamie-Taylor",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jamie Taylor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 207167677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1976c9eeccc7115d18a04f1e7fb5145db6b96002",
            "isKey": false,
            "numCitedBy": 3825,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications."
            },
            "slug": "Freebase:-a-collaboratively-created-graph-database-Bollacker-Evans",
            "title": {
                "fragments": [],
                "text": "Freebase: a collaboratively created graph database for structuring human knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD Conference"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068720"
                        ],
                        "name": "Rodolphe Jenatton",
                        "slug": "Rodolphe-Jenatton",
                        "structuredName": {
                            "firstName": "Rodolphe",
                            "lastName": "Jenatton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rodolphe Jenatton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7245737"
                        ],
                        "name": "Nicolas Le Roux",
                        "slug": "Nicolas-Le-Roux",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Le Roux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Le Roux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2533906"
                        ],
                        "name": "G. Obozinski",
                        "slug": "G.-Obozinski",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Obozinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Obozinski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [31, 11, 20, 37]); and (3) methods that approximate the correlation using algorithmic approaches, such as random walks [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10854724,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "473b3f2cc2c942c0116d980fe5b36a338f6017de",
            "isKey": false,
            "numCitedBy": 357,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Many data such as social networks, movie preferences or knowledge bases are multi-relational, in that they describe multiple relations between entities. While there is a large body of work focused on modeling these data, modeling these multiple types of relations jointly remains challenging. Further, existing approaches tend to breakdown when the number of these types grows. In this paper, we propose a method for modeling large multi-relational datasets, with possibly thousands of relations. Our model is based on a bilinear structure, which captures various orders of interaction of the data, and also shares sparse latent factors across different relations. We illustrate the performance of our approach on standard tensor-factorization datasets where we attain, or outperform, state-of-the-art results. Finally, a NLP application demonstrates our scalability and the ability of our model to learn efficient and semantically meaningful verb representations."
            },
            "slug": "A-latent-factor-model-for-highly-multi-relational-Jenatton-Roux",
            "title": {
                "fragments": [],
                "text": "A latent factor model for highly multi-relational data"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper proposes a method for modeling large multi-relational datasets, with possibly thousands of relations, based on a bilinear structure, which captures various orders of interaction of the data and also shares sparse latent factors across different relations."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145044578"
                        ],
                        "name": "S. Auer",
                        "slug": "S.-Auer",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Auer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729154"
                        ],
                        "name": "C. Bizer",
                        "slug": "C.-Bizer",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bizer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bizer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2051816"
                        ],
                        "name": "Georgi Kobilarov",
                        "slug": "Georgi-Kobilarov",
                        "structuredName": {
                            "firstName": "Georgi",
                            "lastName": "Kobilarov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georgi Kobilarov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144568027"
                        ],
                        "name": "Jens Lehmann",
                        "slug": "Jens-Lehmann",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Lehmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jens Lehmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702661"
                        ],
                        "name": "Richard Cyganiak",
                        "slug": "Richard-Cyganiak",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Cyganiak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Cyganiak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804315"
                        ],
                        "name": "Z. Ives",
                        "slug": "Z.-Ives",
                        "structuredName": {
                            "firstName": "Zachary",
                            "lastName": "Ives",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Ives"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7278297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b2c30dfd3968c5d9418bb2c14b2382d3ccc64b2",
            "isKey": false,
            "numCitedBy": 4419,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "DBpedia is a community effort to extract structured information from Wikipedia and to make this information available on the Web. DBpedia allows you to ask sophisticated queries against datasets derived from Wikipedia and to link other datasets on the Web to Wikipedia data. We describe the extraction of the DBpedia datasets, and how the resulting information is published on the Web for human-andmachine-consumption. We describe some emerging applications from the DBpedia community and show how website authors can facilitate DBpedia content within their sites. Finally, we present the current status of interlinking DBpedia with other open datasets on the Web and outline how DBpedia could serve as a nucleus for an emerging Web of open data."
            },
            "slug": "DBpedia:-A-Nucleus-for-a-Web-of-Open-Data-Auer-Bizer",
            "title": {
                "fragments": [],
                "text": "DBpedia: A Nucleus for a Web of Open Data"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The extraction of the DBpedia datasets is described, and how the resulting information is published on the Web for human-andmachine-consumption and how DBpedia could serve as a nucleus for an emerging Web of open data."
            },
            "venue": {
                "fragments": [],
                "text": "ISWC/ASWC"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160047"
                        ],
                        "name": "Zhao Xu",
                        "slug": "Zhao-Xu",
                        "structuredName": {
                            "firstName": "Zhao",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhao Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700754"
                        ],
                        "name": "Volker Tresp",
                        "slug": "Volker-Tresp",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Tresp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volker Tresp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114075909"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688561"
                        ],
                        "name": "H. Kriegel",
                        "slug": "H.-Kriegel",
                        "structuredName": {
                            "firstName": "Hans-Peter",
                            "lastName": "Kriegel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kriegel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [48]) or continuous factors (e."
                    },
                    "intents": []
                }
            ],
            "corpusId": 891216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8967a8d3d132673d2e3ff5c785b83b5402bf440",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In many cases it makes sense to model a relationship symmetrically, not implying any particular directionality. Consider the classical example of a recommendation system where the rating of an item by a user should symmetrically be dependent on the attributes of both the user and the item. The attributes of the (known) relationships are also relevant for predicting attributes of entities and for predicting attributes of new relations. In recommendation systems, the exploitation of relational attributes is often referred to as collaborative filtering. Again, in many applications one might prefer to model the collaborative effect in a symmetrical way. In this paper we present a relational model, which is completely symmetrical. The key innovation is that we introduce for each entity (or object) an infinite-dimensional latent variable as part of a Dirichlet process (DP) model. We discuss inference in the model, which is based on a DP Gibbs sampler, i.e., the Chinese restaurant process. We extend the Chinese restaurant process to be applicable to relational modeling. Our approach is evaluated in three applications. One is a recommendation system based on the MovieLens data set. The second application concerns the prediction of the function of yeast genes/proteins on the data set of KDD Cup 2001 using a multi-relational model. The third application involves a relational medical domain. The experimental results show that our model gives significantly improved estimates of attributes describing relationships or entities in complex relational models."
            },
            "slug": "Infinite-Hidden-Relational-Models-Xu-Tresp",
            "title": {
                "fragments": [],
                "text": "Infinite Hidden Relational Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents a relational model, which is completely symmetrical, that introduces for each entity (or object) an infinite-dimensional latent variable as part of a Dirichlet process (DP) model, based on a DP Gibbs sampler."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145696762"
                        ],
                        "name": "R. Speer",
                        "slug": "R.-Speer",
                        "structuredName": {
                            "firstName": "Robyn",
                            "lastName": "Speer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Speer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2232845"
                        ],
                        "name": "Catherine Havasi",
                        "slug": "Catherine-Havasi",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Havasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catherine Havasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [38])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2924682,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b97b4623cf2f183340e548e0aa53abf0f2963d8",
            "isKey": false,
            "numCitedBy": 454,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "ConceptNet is a knowledge representation project, providing a large semantic graph that describes general human knowledge and how it is expressed in natural language. This paper presents the latest iteration, ConceptNet 5, including its fundamental design decisions, ways to use it, and evaluations of its coverage and accuracy."
            },
            "slug": "Representing-General-Relational-Knowledge-in-5-Speer-Havasi",
            "title": {
                "fragments": [],
                "text": "Representing General Relational Knowledge in ConceptNet 5"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The latest iteration of ConceptNet 5 is presented, including its fundamental design decisions, ways to use it, and evaluations of its coverage and accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [27]) that related entities cluster together in the space, so here we focus on predicates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5959482,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "330da625c15427c6e42ccfa3b747fb29e5835bf0",
            "isKey": false,
            "numCitedBy": 21886,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose two novel model architectures for computing continuous vector\nrepresentations of words from very large data sets. The quality of these\nrepresentations is measured in a word similarity task, and the results are\ncompared to the previously best performing techniques based on different types\nof neural networks. We observe large improvements in accuracy at much lower\ncomputational cost, i.e. it takes less than a day to learn high quality word\nvectors from a 1.6 billion words data set. Furthermore, we show that these\nvectors provide state-of-the-art performance on our test set for measuring\nsyntactic and semantic word similarities."
            },
            "slug": "Efficient-Estimation-of-Word-Representations-in-Mikolov-Chen",
            "title": {
                "fragments": [],
                "text": "Efficient Estimation of Word Representations in Vector Space"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Two novel model architectures for computing continuous vector representations of words from very large data sets are proposed and it is shown that these vectors provide state-of-the-art performance on the authors' test set for measuring syntactic and semantic word similarities."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145867172"
                        ],
                        "name": "Xin Dong",
                        "slug": "Xin-Dong",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403176402"
                        ],
                        "name": "Laure Berti-\u00c9quille",
                        "slug": "Laure-Berti-\u00c9quille",
                        "structuredName": {
                            "firstName": "Laure",
                            "lastName": "Berti-\u00c9quille",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laure Berti-\u00c9quille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145860176"
                        ],
                        "name": "D. Srivastava",
                        "slug": "D.-Srivastava",
                        "structuredName": {
                            "firstName": "Divesh",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Srivastava"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9664056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70fd8392d104ef35d85b07fbfab1990f3e4145a2",
            "isKey": false,
            "numCitedBy": 419,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Many data management applications, such as setting up Web portals, managing enterprise data, managing community data, and sharing scientific data, require integrating data from multiple sources. Each of these sources provides a set of values and different sources can often provide conflicting values. To present quality data to users, it is critical that data integration systems can resolve conflicts and discover true values. Typically, we expect a true value to be provided by more sources than any particular false one, so we can take the value provided by the majority of the sources as the truth. Unfortunately, a false value can be spread through copying and that makes truth discovery extremely tricky. In this paper, we consider how to find true values from conflicting information when there are a large number of sources, among which some may copy from others. \n \nWe present a novel approach that considers dependence between data sources in truth discovery. Intuitively, if two data sources provide a large number of common values and many of these values are rarely provided by other sources (e.g., particular false values), it is very likely that one copies from the other. We apply Bayesian analysis to decide dependence between sources and design an algorithm that iteratively detects dependence and discovers truth from conflicting information. We also extend our model by considering accuracy of data sources and similarity between values. Our experiments on synthetic data as well as real-world data show that our algorithm can significantly improve accuracy of truth discovery and is scalable when there are a large number of data sources."
            },
            "slug": "Integrating-Conflicting-Data:-The-Role-of-Source-Dong-Berti-\u00c9quille",
            "title": {
                "fragments": [],
                "text": "Integrating Conflicting Data: The Role of Source Dependence"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper applies Bayesian analysis to decide dependence between sources and design an algorithm that iteratively detects dependence and discovers truth from conflicting information and extends the model by considering accuracy of data sources and similarity between values."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798267"
                        ],
                        "name": "L. Reyzin",
                        "slug": "L.-Reyzin",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Reyzin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Reyzin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "However, we observed considerably better performance by using boosted decision stumps [33]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2483269,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ffa695aeb4f8f59b2a2008c87c687ab34680ca4",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Boosting methods are known not to usually overfit training data even as the size of the generated classifiers becomes large. Schapire et al. attempted to explain this phenomenon in terms of the margins the classifier achieves on training examples. Later, however, Breiman cast serious doubt on this explanation by introducing a boosting algorithm, arc-gv, that can generate a higher margins distribution than AdaBoost and yet performs worse. In this paper, we take a close look at Breiman's compelling but puzzling results. Although we can reproduce his main finding, we find that the poorer performance of arc-gv can be explained by the increased complexity of the base classifiers it uses, an explanation supported by our experiments and entirely consistent with the margins theory. Thus, we find maximizing the margins is desirable, but not necessarily at the expense of other factors, especially base-classifier complexity."
            },
            "slug": "How-boosting-the-margin-can-also-boost-classifier-Reyzin-Schapire",
            "title": {
                "fragments": [],
                "text": "How boosting the margin can also boost classifier complexity"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A close look at Breiman's compelling but puzzling results finds that the poorer performance of arc-gv can be explained by the increased complexity of the base classifiers it uses, an explanation supported by experiments and entirely consistent with the margins theory."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3994427"
                        ],
                        "name": "B. Suh",
                        "slug": "B.-Suh",
                        "structuredName": {
                            "firstName": "Bongwon",
                            "lastName": "Suh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Suh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2495482"
                        ],
                        "name": "G. Convertino",
                        "slug": "G.-Convertino",
                        "structuredName": {
                            "firstName": "Gregorio",
                            "lastName": "Convertino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Convertino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2226805"
                        ],
                        "name": "Ed H. Chi",
                        "slug": "Ed-H.-Chi",
                        "structuredName": {
                            "firstName": "Ed",
                            "lastName": "Chi",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ed H. Chi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144980333"
                        ],
                        "name": "P. Pirolli",
                        "slug": "P.-Pirolli",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Pirolli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pirolli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2721262,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "db36f16943116fba9a3664e659ef515b4e63a9f6",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Prior research on Wikipedia has characterized the growth in content and editors as being fundamentally exponential in nature, extrapolating current trends into the future. We show that recent editing activity suggests that Wikipedia growth has slowed, and perhaps plateaued, indicating that it may have come against its limits to growth. We measure growth, population shifts, and patterns of editor and administrator activities, contrasting these against past results where possible. Both the rate of page growth and editor growth has declined. As growth has declined, there are indicators of increased coordination and overhead costs, exclusion of newcomers, and resistance to new edits. We discuss some possible explanations for these new developments in Wikipedia including decreased opportunities for sharing existing knowledge and increased bureaucratic stress on the socio-technical system itself."
            },
            "slug": "The-singularity-is-not-near:-slowing-growth-of-Suh-Convertino",
            "title": {
                "fragments": [],
                "text": "The singularity is not near: slowing growth of Wikipedia"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that recent editing activity suggests that Wikipedia growth has slowed, and perhaps plateaued, indicating that it may have come against its limits to growth."
            },
            "venue": {
                "fragments": [],
                "text": "Int. Sym. Wikis"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714772"
                        ],
                        "name": "Dale Schuurmans",
                        "slug": "Dale-Schuurmans",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Schuurmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Schuurmans"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "To alleviate this problem, we adopt the standard technique known as Platt Scaling (named after [33]), which consists of fitting a logistic regression model to the scores, using a separate validation set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 64295966,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "b7caf811d6980627caad1a8b3053f40348693508",
            "isKey": false,
            "numCitedBy": 436,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Introduction, Fitting a Sigmoid After the SVM, Empirical Tests, Conclusions, Appendix: Pseudo-code for the Sigmoid Training"
            },
            "slug": "Probabilities-for-SV-Machines-Smola-Bartlett",
            "title": {
                "fragments": [],
                "text": "Probabilities for SV Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter contains sections titled: Introduction, Fitting a Sigmoid After the SVM, Empirical Tests, Conclusions, Appendix: Pseudo-code for the Sigmoids Training."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "We use relatively standard methods for relation extraction from text (see [16] for a recent overview), but we do so at a much larger scale than previous systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 236152584,
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Extraction: Capabilities and Challenges"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "In this paper, we exploit existing triples in Freebase to fit prior models, which can assign a probability to any possible triple, even if there is no corresponding evidence for this fact on the Web (cf. [2])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilities for SV machines Advances in Large Margin Classifiers"
            },
            "venue": {
                "fragments": [],
                "text": "Probabilities for SV machines Advances in Large Margin Classifiers"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Ontology for Search Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Knowledge Extraction Workshop at NAACL-HLT"
            },
            "venue": {
                "fragments": [],
                "text": "The Knowledge Extraction Workshop at NAACL-HLT"
            },
            "year": 2012
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 21
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 49,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Knowledge-vault:-a-web-scale-approach-to-knowledge-Dong-Gabrilovich/cf5ea582bccc7cb21a2ebeb7a0987f79652bde8d?sort=total-citations"
}