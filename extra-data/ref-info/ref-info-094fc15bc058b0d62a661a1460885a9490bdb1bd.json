{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16644750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07f0f4553cfb42c0ed2bd6b07c9b22777b313d8",
            "isKey": false,
            "numCitedBy": 693,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic phrase indexing and term clustering have been widely explored as text representation techniques for text retrieval. In this paper we study the properties of phrasal and clustered indexing languages on a text categorization task, enabling us to study their properties in isolation from query interpretation issues. We show that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing. We also present results suggesting that traditional term clustering method are unlikely to provide significantly improved text representations. An improved probabilistic text categorization method is also presented."
            },
            "slug": "An-evaluation-of-phrasal-and-clustered-on-a-text-Lewis",
            "title": {
                "fragments": [],
                "text": "An evaluation of phrasal and clustered representations on a text categorization task"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, their work analyzes only parts of the TFIDF algorithm and is based on information retrieval instead of on text categorization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The TFIDF classi er provides the basis for the analysis in section 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60458454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69859be3ea6cb8eb38434c80fef5d4997eaec2dc",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation introduces a new theoretical model for text classification systems, including systems for document retrieval, automated indexing, electronic mail filtering, and similar tasks. The Concept Learning model emphasizes the role of manual and automated feature selection and classifier formation in text classification. It enables drawing on results from statistics and machine learning in explaining the effectiveness of alternate representations of text, and specifies desirable characteristics of text representations. \nThe use of syntactic parsing to produce indexing phrases has been widely investigated as a possible route to better text representations. Experiments with syntactic phrase indexing, however, have never yielded significant improvements in text retrieval performance. The Concept Learning model suggests that the poor statistical characteristics of a syntactic indexing phrase representation negate its desirable semantic characteristics. The application of term clustering to this representation to improve its statistical properties while retaining its desirable meaning properties is proposed. \nStandard term clustering strategies from information retrieval (IR), based on cooccurrence of indexing terms in documents or groups of documents, were tested on a syntactic indexing phrase representation. In experiments using a standard text retrieval test collection, small effectiveness improvements were obtained. \nAs a means of evaluating representation quality, a text retrieval test collection introduces a number of confounding factors. In contrast, the text categorization task allows much cleaner determination of text representation properties. In preparation for the use of text categorization to study text representation, a more effective and theoretically well-founded probabilistic text categorization algorithm was developed, building on work by Maron, Fuhr, and others. \nText categorization experiments supported a number of predictions of the Concept Learning model about properties of phrasal representations, including dimensionality properties not previously measured for text representations. However, in carefully controlled experiments using syntactic phrases produced by Church's stochastic bracketer, in conjunction with reciprocal nearest neighbor clustering, term clustering was found to produce essentially no improvement in the properties of the phrasal representation. New cluster analysis approaches are proposed to remedy the problems found in traditional term clustering methods."
            },
            "slug": "Representation-and-Learning-in-Information-Lewis",
            "title": {
                "fragments": [],
                "text": "Representation and Learning in Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A new theoretical model for text classification systems, including systems for document retrieval, automated indexing, electronic mail filtering, and similar tasks, is introduced, suggesting that the poor statistical characteristics of a syntactic indexing phrase representation negate its desirable semantic characteristics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145272844"
                        ],
                        "name": "C. Apt\u00e9",
                        "slug": "C.-Apt\u00e9",
                        "structuredName": {
                            "firstName": "Chidanand",
                            "lastName": "Apt\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Apt\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "68982679"
                        ],
                        "name": "Fred J. Damerau",
                        "slug": "Fred-J.-Damerau",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Damerau",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fred J. Damerau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700185"
                        ],
                        "name": "S. Weiss",
                        "slug": "S.-Weiss",
                        "structuredName": {
                            "firstName": "Sholom",
                            "lastName": "Weiss",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10826654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9257779eed46107bcdce9f4dc86298572ff466ce",
            "isKey": false,
            "numCitedBy": 945,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the results of extensive experiments using optimized rule-based induction methods on large document collections. The goal of these methods is to discover automatically classification patterns that can be used for general document categorization or personalized filtering of free text. Previous reports indicate that human-engineered rule-based systems, requiring many man-years of developmental efforts, have been successfully built to \u201cread\u201d documents and assign topics to them. We show that machine-generated decision rules appear comparable to human performance, while using the identical rule-based representation. In comparison with other machine-learning techniques, results on a key benchmark from the Reuters collection show a large gain in performance, from a previously reported 67% recall/precision breakeven point to 80.5%. In the context of a very high-dimensional feature space, several methodological alternatives are examined, including universal versus local dictionaries, and binary versus frequency-related features."
            },
            "slug": "Automated-learning-of-decision-rules-for-text-Apt\u00e9-Damerau",
            "title": {
                "fragments": [],
                "text": "Automated learning of decision rules for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that machine-generated decision rules appear comparable to human performance, while using the identical rule-based representation, and compared with other machine-learning techniques."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428001"
                        ],
                        "name": "P. Hayes",
                        "slug": "P.-Hayes",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Hayes",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hayes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33308771"
                        ],
                        "name": "Laura E. Knecht",
                        "slug": "Laura-E.-Knecht",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Knecht",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laura E. Knecht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3171559"
                        ],
                        "name": "Monica J. Cellio",
                        "slug": "Monica-J.-Cellio",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Cellio",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Monica J. Cellio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 36
                            }
                        ],
                        "text": "They are used to index news stories [Hayes et al., 1988] or guide a user's search on the World Wide Web [Joachims et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "They are used to index news stories [Hayes et al., 1988] or guide a user's search on the World Wide Web [Joachims et al., 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14018427,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11c07e12a9c69d967a89bc47c0826ec4edffc6bb",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a pilot version of a commercial application of natural language processing techniques to the problem of categorizing news stories into broad topic categories. The system does not perform a complete semantic or syntactic analyses of the input stories. Its categorizations are dependent on fragmentary recognition using pattern-matching techniques. The fragments it looks for are determined by a set of knowledge-based rules. The accuracy of the system is only slightly lower than that of human categorizers."
            },
            "slug": "A-News-Story-Categorization-System-Hayes-Knecht",
            "title": {
                "fragments": [],
                "text": "A News Story Categorization System"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A pilot version of a commercial application of natural language processing techniques to the problem of categorizing news stories into broad topic categories based on fragmentary recognition using pattern-matching techniques is described."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 43
                            }
                        ],
                        "text": "An overview of some heuristics is given in [Salton, Buckley, 1988]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 95
                            }
                        ],
                        "text": "In the following the most popular combination will be used (known as \\tfc\"): \\tf\" word weights [Salton, Buckley, 1988], document length normalization using Euclidian vector length and cosine similarity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 114
                            }
                        ],
                        "text": "The major heuristic component of the Rocchio algorithm is the TFIDF (term frequency / inverse document frequency) [Salton, Buckley, 1988] word weighting scheme."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7725217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e50a316f97c9a405aa000d883a633bd5707f1a34",
            "isKey": false,
            "numCitedBy": 9462,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Term-Weighting-Approaches-in-Automatic-Text-Salton-Buckley",
            "title": {
                "fragments": [],
                "text": "Term-Weighting Approaches in Automatic Text Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 151
                            }
                        ],
                        "text": "The PrTFIDF Algorithm uses a di erent way approximating Pr(Cjjd\n0) inspired by the \\retrieval with probabilistic indexing\" (RPI) approach proposed in [Fuhr, 1989]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 149
                            }
                        ],
                        "text": "The PrTFIDF Algorithm uses a di erent way approximating Pr(Cjjd ) inspired by the \\retrieval with probabilistic indexing\" (RPI) approach proposed in [Fuhr, 1989]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15424327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61af1deb7a3016cd0760aca0f0a38a4fecda3d61",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Models-for-retrieval-with-probabilistic-indexing-Fuhr",
            "title": {
                "fragments": [],
                "text": "Models for retrieval with probabilistic indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2126632"
                        ],
                        "name": "W. S. Cooper",
                        "slug": "W.-S.-Cooper",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cooper",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. S. Cooper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 69
                            }
                        ],
                        "text": "(1)The weaker assumption of \\linked-dependence\" is actually su cient [Cooper, 1991], but not considered here for simplicity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 68
                            }
                        ],
                        "text": "1The weaker assumption of \\linked-dependence\" is actually su cient [Cooper, 1991], but not considered here for simplicity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16376601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5857780939512bf49b5f56fdb2355d1840e382f5",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The probabilistic theory of information retrieval involves the construction of mathematical models based on statistical assumptions of various sorts. One of the hazards inherent in this kind of theory construction is that the assumptions laid down may be inconsistent with the data to which they are applied. Another hazard is that the stated assumptions may not be the real assumptions on which the derived modelling equations or resulting experiments are actually based. Both kinds of error have been made repeatedly in research on probabilistic information retrieval. One consequence of these lapses is that the statistical character of certain probabilistic IR models, including the so-called \u2018binary independence\u2019 model, has been seriously misapprehended."
            },
            "slug": "Some-inconsistencies-and-misnomers-in-probabilistic-Cooper",
            "title": {
                "fragments": [],
                "text": "Some inconsistencies and misnomers in probabilistic information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The statistical character of certain probabilistic IR models, including the so-called \u2018binary independence\u2019 model, has been seriously misapprehended."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35211746"
                        ],
                        "name": "David A. Hull",
                        "slug": "David-A.-Hull",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hull",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Hull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9131020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92062ccb796efbf56fe1ae2dcc8b3a943a2c989b",
            "isKey": false,
            "numCitedBy": 566,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we compare learning techniques based on statistical classification to traditional methods of relevance feedback for the document routing problem. We consider three classification techniques which have decision rules that are derived via explicit error minimization: linear discriminant analysis, logistic regression, and neural networks. We demonstrate that the classifiers perform 1015% better than relevance feedback via Rocchio expansion for the TREC-2 and TREC-3 routing tasks. Error minimization is difficult in high-dimensional feature spaces because the convergence process is slow and the models are prone to overfitting. We use two different strategies, latent semantic indexing and optimal term selection, to reduce the number of features. Our results indicate that features based on latent semantic indexing are more effective for techniques such as linear discriminant analysis and logistic regression, which have no way to protect against overfitting. Neural networks perform equally well with either set of features and can take advantage of the additional information available when both feature sets are used as input."
            },
            "slug": "A-comparison-of-classifiers-and-document-for-the-Sch\u00fctze-Hull",
            "title": {
                "fragments": [],
                "text": "A comparison of classifiers and document representations for the routing problem"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper compares learning techniques based on statistical classification to traditional methods of relevance feedback for the document routing problem and indicates that features based on latent semantic indexing are more effective for techniques such as linear discriminant analysis and logistic regression, which have no way to protect against overfitting."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107261059"
                        ],
                        "name": "S. K. Wong",
                        "slug": "S.-K.-Wong",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Wong",
                            "middleNames": [
                                "K.",
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698696"
                        ],
                        "name": "Yiyu Yao",
                        "slug": "Yiyu-Yao",
                        "structuredName": {
                            "firstName": "Yiyu",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiyu Yao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 44
                            }
                        ],
                        "text": ", 1992] and the TFIDF word weighting scheme [Wong, Yao, 1989] [Wu, Salton, 1981]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118049810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c69cafc3ce157468a873a609636c389aa71f589c",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Based on the Shannon information theory, a measure for term value is introduced. This study is an attempt to provide a theoretical justification for the inverse document frequency (IDF) weighting scheme. The argument presented in this paper is somewhat different from those suggested earlier. It is shown that IDF weights can be derived from the proposed approach by assuming that each index term has an even distribution within a subset of documents. A critical comment on the signal-noise ratio (S/N) weighting method is also included."
            },
            "slug": "A-Note-on-Inverse-Document-Frequency-Weighting-Wong-Yao",
            "title": {
                "fragments": [],
                "text": "A Note on Inverse Document Frequency Weighting Scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that IDF weights can be derived from the proposed approach by assuming that each index term has an even distribution within a subset of documents."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46442363"
                        ],
                        "name": "K. Lang",
                        "slug": "K.-Lang",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Lang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 147
                            }
                        ],
                        "text": "Text categorization techniques are used, for example, to build personalized netnews lter which learn about the news-reading preferences of a user [Lang, 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1921714,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38b3a4447a47a6a6ed1869f3da03352c487f8fe3",
            "isKey": false,
            "numCitedBy": 2117,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "NewsWeeder:-Learning-to-Filter-Netnews-Lang",
            "title": {
                "fragments": [],
                "text": "NewsWeeder: Learning to Filter Netnews"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114590864"
                        ],
                        "name": "Marko Balabanovi",
                        "slug": "Marko-Balabanovi",
                        "structuredName": {
                            "firstName": "Marko",
                            "lastName": "Balabanovi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marko Balabanovi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701353"
                        ],
                        "name": "Y. Shoham",
                        "slug": "Y.-Shoham",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Shoham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shoham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12500166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d4066ce3ffcea187a75f0a07f4f695d1b73da6e",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The current exponential growth of the Internet precipitates a need for new tools to help people cope with the volume of information. To complement recent work on creating searchable indexes of the World-Wide Web and systems for filtering incoming e-mail and Usenet news articles, we describe a system which helps users keep abreast of new and interesting information. Every day it presents a selection of interesting web pages. The user evaluates each page, and given this feedback the system adapts and attempts to produce better pages the following day. We present some early results from an AI programming class to whom this was set as a project, and then describe our current implementation. Over the course of 24 days the output of our system was compared to both randomly-selected and human-selected pages. It consistently performed better than the random pages, and was better than the human-selected pages half of the time."
            },
            "slug": "Learning-Information-Retrieval-Agents:-Experiments-Balabanovi-Shoham",
            "title": {
                "fragments": [],
                "text": "Learning Information Retrieval Agents: Experiments with Automated Web Browsing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A system which helps users keep abreast of new and interesting information Every day it presents a selection of interesting web pages, and the user evaluates each page, and given feedback the system adapts and attempts to produce better pages the following day."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112226698"
                        ],
                        "name": "Harry Wu",
                        "slug": "Harry-Wu",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harry Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 62
                            }
                        ],
                        "text": ", 1992] and the TFIDF word weighting scheme [Wong, Yao, 1989] [Wu, Salton, 1981]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14119842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7cd9f886a79cf85c1f6012b1416219131a850a71",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The term relevance weighting method has been shown to produce optimal information retrieval queries under well-defined conditions. The parameters needed to generate the term relevance factors cannot unfortunately be estimated accurately in practice; futhermore, in realistic test situations, it appears difficult to obtain improved retrieval results using the term relevance weights over much simpler term weighting systems such as, for example, the inverse document frequency weights.It is shown in this study that the inverse document frequency weights and the term relevance weights are closely related over a wide range of the frequency spectrum. Methods are introduced for estimating the term relevance weights, and experimental results are given comparing the inverse document frequency with the estimated term relevance weights."
            },
            "slug": "A-comparison-of-search-term-weighting:-term-vs.-Wu-Salton",
            "title": {
                "fragments": [],
                "text": "A comparison of search term weighting: term relevance vs. inverse document frequency"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown in this study that the inverse document frequency weights and the term relevance weights are closely related over a wide range of the frequency spectrum."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '81"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 94
                            }
                        ],
                        "text": "d(i) for a document d is calculated as a combination of the statistics TF (wi; d) and DF (wi) [Salton, 1991]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 144
                            }
                        ],
                        "text": "Each element d(i) represents a distinct word wi. d(i) for a document d is calculated as a combination of the statistics TF (wi; d) and DF (wi) [Salton, 1991]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 153
                            }
                        ],
                        "text": "This type of classi er is based on the relevance feedback algorithm originally proposed by Rocchio [Rocchio, 1971] for the vector space retrieval model [Salton, 1991]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 44521016,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "36b3711f06725def5884d9d9a48ad689d8187149",
            "isKey": false,
            "numCitedBy": 712,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments in the storage, retrieval, and manipulation of large text files are described. The text analysis problem is examined, and modern approaches leading to the identification and retrieval of selected text items in response to search requests are discussed."
            },
            "slug": "Developments-in-Automatic-Text-Retrieval-Salton",
            "title": {
                "fragments": [],
                "text": "Developments in Automatic Text Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The text analysis problem is examined, and modern approaches leading to the identification and retrieval of selected text items in response to search requests are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144890574"
                        ],
                        "name": "James Allan",
                        "slug": "James-Allan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Allan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 19
                            }
                        ],
                        "text": "As recommended in [Buckley et al., 1994] = 16 and = 4 will be used in the following."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17522959,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "c972982771aeaaafdbdfbbcc7fe205bdecb3cf24",
            "isKey": false,
            "numCitedBy": 372,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The effects of adding information from relevant documents are examined in the TREC routing environment. A modified Rocchio relevance feedback approach is used, with a varying number of relevant documents retrieved by an initial SMART search, and a varying number of terms from those relevant documents used to expand the initial query. Recall-precision evaluation reveals that as the amount of expansion of the query due to adding terms from relevant documents increases, so does the effectiveness. There appears to be a linear relationship between the log of the number of terms added and the recall-precision effectiveness. There also appears to be a linear relationship between the log of the number of known relevant documents and the recall-precision effectiveness."
            },
            "slug": "The-effect-of-adding-relevance-information-in-a-Buckley-Salton",
            "title": {
                "fragments": [],
                "text": "The effect of adding relevance information in a relevance feedback environment"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Recall-precision evaluation reveals that as the amount of expansion of the query due to adding terms from relevant documents increases, so does the effectiveness, and there appears to be a linear relationship between the log of the number of terms added and the recall- Precision effectiveness."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054786149"
                        ],
                        "name": "Robert Armstrong",
                        "slug": "Robert-Armstrong",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Armstrong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Armstrong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2045384,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b157903470e9478413df865b56b155ec670351a",
            "isKey": false,
            "numCitedBy": 665,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an information seeking assistant for the world wide web. This agent, called WebWatcher, interactively helps users locate desired information by employing learned knowledge about which hyperlinks are likely to lead to the target information. Our primary focus to date has been on two issues: (1) organizing WebWatcher to provide interactive advice to Mosaic users while logging their successful and unsuccessful searches as training data, and (2) incorporating machine learning methods to automatically acquire knowledge for selecting an appropriate hyperlink given the current web page viewed by the user and the user\u2019s information goal. We describe the initial design of WebWatcher, and the results of our preliminary learning experiments."
            },
            "slug": "WebWatcher-:-A-Learning-Apprentice-for-the-World-Armstrong-Freitag",
            "title": {
                "fragments": [],
                "text": "WebWatcher : A Learning Apprentice for the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An information seeking assistant for the world wide web, called WebWatcher, interactively helps users locate desired information by employing learned knowledge about which hyperlinks are likely to lead to the target information."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108288395"
                        ],
                        "name": "Zhiwei Wang",
                        "slug": "Zhiwei-Wang",
                        "structuredName": {
                            "firstName": "Zhiwei",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiwei Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107261059"
                        ],
                        "name": "S. K. Wong",
                        "slug": "S.-K.-Wong",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Wong",
                            "middleNames": [
                                "K.",
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698696"
                        ],
                        "name": "Yiyu Yao",
                        "slug": "Yiyu-Yao",
                        "structuredName": {
                            "firstName": "Yiyu",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiyu Yao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 122
                            }
                        ],
                        "text": "Other researchers have already proposed theoretical interpretations of the vector space retrieval model [Bookstein, 1982][Wang et al., 1992] and the TFIDF word weighting scheme [Wong, Yao, 1989] [Wu, Salton, 1981]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16558313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29d307d17d1f1b2a926e68c54f0d00f8819f3c19",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper analyzes the properties, structures and limitations of vector-based models for information retrieval from the computational geometry point of view. It is shown that both the pseudo-cosine and the standard vector space models can be viewed as special cases of a generalized linear model. More importantly, both the necessary and sufficient conditions have been identified, under which ranking functions such as the inner-product, cosine, pseudo-cosine, Dice, covariance and product-moment correlation measures can be used to rank the documents. The structure of the solution region for acceptable ranking is analyzed and an algorithm for finding all the solution vectors is suggested."
            },
            "slug": "An-analysis-of-vector-space-models-based-on-Wang-Wong",
            "title": {
                "fragments": [],
                "text": "An analysis of vector space models based on computational geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Both the pseudo-cosine and the standard vector space models can be viewed as special cases of a generalized linear model and both the necessary and sufficient conditions have been identified under which ranking functions such as the inner-product, cosine, pseudo-Cosine, Dice, covariance and product-moment correlation measures can be used to rank the documents."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 55
                            }
                        ],
                        "text": ", 1988] or guide a user's search on the World Wide Web [Joachims et al., 1997]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 105
                            }
                        ],
                        "text": "They are used to index news stories [Hayes et al., 1988] or guide a user's search on the World Wide Web [Joachims et al., 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7662922,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3022cfe4decc9ea7dd95af935764204924c2f9a1",
            "isKey": false,
            "numCitedBy": 596,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "1 We explore the notion of a tour guide software agent for assisting users browsing the World Wide Web. A Web tour guide agent provides assistance similar to that provided by a human tour guide in a museum { it guides the user along an appropriate path through the collection, based on its knowledge of the user's interests, of the location and relevance of various items in the collection, and of the way in which others have interacted with the collection in the past. This paper describes a simple but operational tour guide, called WebWatcher, which has given over 5000 tours to people browsing CMU's School of Computer Science Web pages. WebWatcher accompanies users from page to page, suggests appropriate hyperlinks, and learns from experience to improve its advice-giving skills. We describe the learning algorithms used by WebWatcher, experimental results showing their e ectiveness, and lessons learned from this case study in Web tour guide agents."
            },
            "slug": "WebWatcher-:-A-Tour-Guide-for-the-World-Wide-Web-Joachims",
            "title": {
                "fragments": [],
                "text": "WebWatcher : A Tour Guide for the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The learning algorithms used by WebWatcher, experimental results showing their e ectiveness, and lessons learned from this case study in Web tour guide agents are described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "134211067"
                        ],
                        "name": "J. Rocchio",
                        "slug": "J.-Rocchio",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Rocchio",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rocchio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 117
                            }
                        ],
                        "text": "One of the most widely applied learning algorithms for text categorization is the Rocchio relevance feedback method [Rocchio, 1971] developed in information retrieval."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 37
                            }
                        ],
                        "text": "The major heuristic component of the Rocchio algorithm is the TFIDF (term frequency / inverse document frequency) [Salton, Buckley, 1988] word weighting scheme."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 125
                            }
                        ],
                        "text": "Cj is the set of training documents assigned to class j and jj~djj denotes the Euclidian length of a vector ~d. Additionally Rocchio requires that negative elements of the vector cj are set to 0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 162
                            }
                        ],
                        "text": "Although\nthe algorithm is intuitive, it has a number of problems which - as I will show - lead to comparably low classi cation accuracy: (1) The objective of the Rocchio algorithm is to maximize a particular functional (introduced in section 3.2.1)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 82
                            }
                        ],
                        "text": "The variant presented here seems to be the most straightforward adaptation of the Rocchio algorithm to text categorization and domains with more than two categories."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "Nevertheless Rocchio does not show why maximizing this functional should lead to a high classi cation accuracy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 51
                            }
                        ],
                        "text": "Using the cosine as a similarity metric and = = 1, Rocchio shows that each prototype vector maximizes the mean similarity of the positive training examples with the prototype vector cj minus the mean similarity of the negative training examples with the prototype vector cj.\n1\njCjj X ~d2Cj cos(~cj ; ~d) 1 jD Cj j X ~d2D Cj cos(~cj; ~d) (4)\nNevertheless it is unclear if or how maximizing this functional connects to the accuracy of the resulting classi er."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 100
                            }
                        ],
                        "text": "This type of classi er is based on the relevance feedback algorithm originally proposed by Rocchio [Rocchio, 1971] for the vector space retrieval model [Salton, 1991]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61859400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4083ad1066cfa2ff0d65866ef4b011399d6873d1",
            "isKey": true,
            "numCitedBy": 3242,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Relevance-feedback-in-information-retrieval-Rocchio",
            "title": {
                "fragments": [],
                "text": "Relevance feedback in information retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61113802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "939d409a615d4b88c0a84e1f9b99ed67a9053208",
            "isKey": false,
            "numCitedBy": 3147,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-SMART-Retrieval-System\u2014Experiments-in-Automatic-Salton",
            "title": {
                "fragments": [],
                "text": "The SMART Retrieval System\u2014Experiments in Automatic Document Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 78
                            }
                        ],
                        "text": "This estimator, which is often called the Laplace estimator, is suggested in [Vapnik, 1982] (pages 54-55)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59746611,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "78ecaabe915ba7df950671d36f92678192802df4",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Estimation-of-Dependences-Based-on-Empirical-Data:-Vapnik",
            "title": {
                "fragments": [],
                "text": "Estimation of Dependences Based on Empirical Data: Springer Series in Statistics (Springer Series in Statistics)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131200"
                        ],
                        "name": "A. Bookstein",
                        "slug": "A.-Bookstein",
                        "structuredName": {
                            "firstName": "Abraham",
                            "lastName": "Bookstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bookstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 105
                            }
                        ],
                        "text": "Other researchers have already proposed theoretical interpretations of the vector space retrieval model [Bookstein, 1982][Wang et al., 1992] and the TFIDF word weighting scheme [Wong, Yao, 1989] [Wu, Salton, 1981]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 104
                            }
                        ],
                        "text": "Other researchers have already proposed theoretical interpretations of the vector space retrieval model [Bookstein, 1982][Wang et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42589599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d99c8f9f4d64bec7d6f698030457d1075119c3eb",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Explanation-and-Generalization-of-Vector-Models-in-Bookstein",
            "title": {
                "fragments": [],
                "text": "Explanation and Generalization of Vector Models in Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cellio, \\A news story categorization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 147
                            }
                        ],
                        "text": "Text categorization techniques are used, for example, to build personalized netnews lter which learn about the news-reading preferences of a user [Lang, 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lang, \\NewsWeeder: Learning to Filter Netnews"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Machine Learning"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "James, \\Classiication Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "James, \\Classiication Algorithms"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Freitag, \\Greedy Attribute Selection"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Machine Learning"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The EEect of Adding Relevance Information in a Relevance F eedback Environment"
            },
            "venue": {
                "fragments": [],
                "text": "I n ternational ACM SIGIR Conference"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 78
                            }
                        ],
                        "text": "This estimator, which is often called the Laplace estimator, is suggested in [Vapnik, 1982] (pages 54-55)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vapnik, \\Estimation of Dependencies Based on Empirical Data"
            },
            "venue": {
                "fragments": [],
                "text": "Vapnik, \\Estimation of Dependencies Based on Empirical Data"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cellio, \\A  news story categorization"
            },
            "venue": {
                "fragments": [],
                "text": "[Hayes et al.,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 144
                            }
                        ],
                        "text": "Each element d(i) represents a distinct word wi. d(i) for a document d is calculated as a combination of the statistics TF (wi; d) and DF (wi) [Salton, 1991]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 153
                            }
                        ],
                        "text": "This type of classi er is based on the relevance feedback algorithm originally proposed by Rocchio [Rocchio, 1971] for the vector space retrieval model [Salton, 1991]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Salton, \\Developments in Automatic Text Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Larson, \\Introduction to Probability Theory and Statistical Inference"
            },
            "venue": {
                "fragments": [],
                "text": "Larson, \\Introduction to Probability Theory and Statistical Inference"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 54
                            }
                        ],
                        "text": "HBAY ES(d0) = argmax C2C Pr(Cjd0) (10) Bayes' theorem [James, 1985] can be used to split the estimation of Pr(Cjd0) into two parts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 12
                            }
                        ],
                        "text": "Bayes' rule [James, 1985] says that to achieve the highest classi cation accuracy, d0 should be assigned to the class for which Pr(Cjd0) is highest."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classi cation Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Wiley"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The TFIDF classi er provides the basis for the analysis in section 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 219
                            }
                        ],
                        "text": "The following describes one approach to estimating Pr(Cjjd\n0), the probability that a document d0 is in class Cj. Bayes' rule says that to achieve the highest classi cation accuracy, d0 should be assigned to the class for which Pr(Cjjd 0) is highest."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "5: Programs for Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": "5: Programs for Machine Learning"
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 32,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Probabilistic-Analysis-of-the-Rocchio-Algorithm-Joachims/094fc15bc058b0d62a661a1460885a9490bdb1bd?sort=total-citations"
}