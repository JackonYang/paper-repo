{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3093886"
                        ],
                        "name": "Max Jaderberg",
                        "slug": "Max-Jaderberg",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Jaderberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Max Jaderberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 141
                            }
                        ],
                        "text": "The problem of detecting and recognizing text in scenes has received increasing attention from the computer vision community in recent years [1, 6, 14, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6] use Convolutional Neural Networks (CNN) for both text region detection and character classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207252329,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5ae7436b5946bd37d17fc1ed26374389a86deff",
            "isKey": false,
            "numCitedBy": 886,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we present an end-to-end system for text spotting\u2014localising and recognising text in natural scene images\u2014and text based image retrieval. This system is based on a region proposal mechanism for detection and deep convolutional neural networks for recognition. Our pipeline uses a novel combination of complementary proposal generation techniques to ensure high recall, and a fast subsequent filtering stage for improving precision. For the recognition and ranking of proposals, we train very large convolutional neural networks to perform word recognition on the whole proposal region at the same time, departing from the character classifier based systems of the past. These networks are trained solely on data produced by a synthetic text generation engine, requiring no human labelled data. Analysing the stages of our pipeline, we show state-of-the-art performance throughout. We perform rigorous experiments across a number of standard end-to-end text spotting benchmarks and text-based image retrieval datasets, showing a large improvement over all previous methods. Finally, we demonstrate a real-world application of our text spotting system to allow thousands of hours of news footage to be instantly searchable via a text query."
            },
            "slug": "Reading-Text-in-the-Wild-with-Convolutional-Neural-Jaderberg-Simonyan",
            "title": {
                "fragments": [],
                "text": "Reading Text in the Wild with Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An end-to-end system for text spotting\u2014localising and recognising text in natural scene images\u2014and text based image retrieval and a real-world application to allow thousands of hours of news footage to be instantly searchable via a text query is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39719398"
                        ],
                        "name": "Anand Mishra",
                        "slug": "Anand-Mishra",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Mishra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Mishra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72492981"
                        ],
                        "name": "Alahari Karteek",
                        "slug": "Alahari-Karteek",
                        "structuredName": {
                            "firstName": "Alahari",
                            "lastName": "Karteek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alahari Karteek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "Other scene text datasets include IIIT 5k-word [13] which contains 3000 cropped word images of scene text downloaded from Google image search as well as Synth90k [5], a dataset of 9 million cropped word images that have been synthetically generated to train systems for character recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9695967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb5b2df137a4d54c3a9145fa363e66531b491580",
            "isKey": false,
            "numCitedBy": 549,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of recognizing text in images taken in the wild has gained significant attention from the computer vision community in recent years. Contrary to recognition of printed documents, recognizing scene text is a challenging problem. We focus on the problem of recognizing text extracted from natural scene images and the web. Significant attempts have been made to address this problem in the recent past. However, many of these works benefit from the availability of strong context, which naturally limits their applicability. In this work we present a framework that uses a higher order prior computed from an English dictionary to recognize a word, which may or may not be a part of the dictionary. We show experimental results on publicly available datasets. Furthermore, we introduce a large challenging word dataset with five thousand words to evaluate various steps of our method exhaustively. The main contributions of this work are: (1) We present a framework, which incorporates higher order statistical language models to recognize words in an unconstrained manner (i.e. we overcome the need for restricted word lists, and instead use an English dictionary to compute the priors). (2) We achieve significant improvement (more than 20%) in word recognition accuracies without using a restricted word list. (3) We introduce a large word recognition dataset (atleast 5 times larger than other public datasets) with character level annotation and benchmark it."
            },
            "slug": "Scene-Text-Recognition-using-Higher-Order-Language-Mishra-Karteek",
            "title": {
                "fragments": [],
                "text": "Scene Text Recognition using Higher Order Language Priors"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A framework is presented that uses a higher order prior computed from an English dictionary to recognize a word, which may or may not be a part of the dictionary, and achieves significant improvement in word recognition accuracies without using a restricted word list."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3093886"
                        ],
                        "name": "Max Jaderberg",
                        "slug": "Max-Jaderberg",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Jaderberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Max Jaderberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 400,
                                "start": 392
                            }
                        ],
                        "text": "Fur-\n1available at http://vision.cornell.edu/se3/coco-text\nma chin\ne p rint\ned\nhan d w\nritte n\noth er\ncategories\n100\n101\n102\n103\n104\n105\nco un ts\nlegible\nma chin\ne p rint\ned\nhan d w\nritte n\noth er\ncategories\nillegible (a) Instances per category in COCO-Text\n1 2 3 4 number of text attributes\n102\n103\n104\n105\n106\n107\nte xt in st an ce s\nStreet View Text\nIIIT 5k-word ICDAR 03\nICDAR 15\nCOCO-Text\nSynth90k\n(b) Number of text attributes vs. number of instances\n0 1 2 3 4 5 6 7 number of instances\n0.0\n0.1\n0.2\n0.3\n0.4 0.5 P er ce nt ag e of im ag es\nICDAR 03 ICDAR 15 COCO-Text including 0 COCO-Text excluding 0\n(c) Instances per image\n0.0025 0.005 0.01 0.02 0.05 0.1 0.25 0.5 Percent of image size\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nP er ce nt ag e of in st an ce s ICDAR 03 ICDAR 15 COCO-Text\n(d) Instance size\n0 0.42 0.54 0.73 1 Variation of spacial text occurance probability as \u03c3/ \u00b5\n(e) Text location ICDAR 15 ICDAR 03COCO-Text\nText uniformly distr ibuted\nText highly clustered\nFigure 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 162
                            }
                        ],
                        "text": "Other scene text datasets include IIIT 5k-word [13] which contains 3000 cropped word images of scene text downloaded from Google image search as well as Synth90k [5], a dataset of 9 million cropped word images that have been synthetically generated to train systems for character recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11072772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0b8aad30d8dfd08535f361864f064b2fbbc9a75",
            "isKey": true,
            "numCitedBy": 684,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we present a framework for the recognition of natural scene text. Our framework does not require any human-labelled data, and performs word recognition on the whole image holistically, departing from the character based recognition systems of the past. The deep neural network models at the centre of this framework are trained solely on data produced by a synthetic text generation engine -- synthetic data that is highly realistic and sufficient to replace real data, giving us infinite amounts of training data. This excess of data exposes new possibilities for word recognition models, and here we consider three models, each one \"reading\" words in a different way: via 90k-way dictionary encoding, character sequence encoding, and bag-of-N-grams encoding. In the scenarios of language based and completely unconstrained text recognition we greatly improve upon state-of-the-art performance on standard datasets, using our fast, simple machinery and requiring zero data-acquisition costs."
            },
            "slug": "Synthetic-Data-and-Artificial-Neural-Networks-for-Jaderberg-Simonyan",
            "title": {
                "fragments": [],
                "text": "Synthetic Data and Artificial Neural Networks for Natural Scene Text Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work presents a framework for the recognition of natural scene text that does not require any human-labelled data, and performs word recognition on the whole image holistically, departing from the character based recognition systems of the past."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148896777"
                        ],
                        "name": "Kai Wang",
                        "slug": "Kai-Wang",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490700"
                        ],
                        "name": "Boris Babenko",
                        "slug": "Boris-Babenko",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Babenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris Babenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 141
                            }
                        ],
                        "text": "The problem of detecting and recognizing text in scenes has received increasing attention from the computer vision community in recent years [1, 6, 14, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "For end-to-end results we only consider a detection a correct match if the words match [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14136313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32b8f58a038df83138435b12a499c8bf0de13811",
            "isKey": false,
            "numCitedBy": 909,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper focuses on the problem of word detection and recognition in natural images. The problem is significantly more challenging than reading text in scanned documents, and has only recently gained attention from the computer vision community. Sub-components of the problem, such as text detection and cropped image word recognition, have been studied in isolation [7, 4, 20]. However, what is unclear is how these recent approaches contribute to solving the end-to-end problem of word recognition. We fill this gap by constructing and evaluating two systems. The first, representing the de facto state-of-the-art, is a two stage pipeline consisting of text detection followed by a leading OCR engine. The second is a system rooted in generic object recognition, an extension of our previous work in [20]. We show that the latter approach achieves superior performance. While scene text recognition has generally been treated with highly domain-specific methods, our results demonstrate the suitability of applying generic computer vision methods. Adopting this approach opens the door for real world scene text recognition to benefit from the rapid advances that have been taking place in object recognition."
            },
            "slug": "End-to-end-scene-text-recognition-Wang-Babenko",
            "title": {
                "fragments": [],
                "text": "End-to-end scene text recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "While scene text recognition has generally been treated with highly domain-specific methods, the results demonstrate the suitability of applying generic computer vision methods."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726358"
                        ],
                        "name": "A. Bissacco",
                        "slug": "A.-Bissacco",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bissacco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bissacco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152710625"
                        ],
                        "name": "M. Cummins",
                        "slug": "M.-Cummins",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Cummins",
                            "middleNames": [
                                "Joseph"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cummins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34180232"
                        ],
                        "name": "Yuval Netzer",
                        "slug": "Yuval-Netzer",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Netzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuval Netzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2665814"
                        ],
                        "name": "H. Neven",
                        "slug": "H.-Neven",
                        "structuredName": {
                            "firstName": "Hartmut",
                            "lastName": "Neven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Neven"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1], where first three different detectors are combined to identify text regions and subsequently characters are classified with a fully connected neural network with HOG features as input supported by a language model based on ngrams."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 141
                            }
                        ],
                        "text": "The problem of detecting and recognizing text in scenes has received increasing attention from the computer vision community in recent years [1, 6, 14, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3149088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31a8803d7e2618bfa44c472d003055bb5961b9de",
            "isKey": false,
            "numCitedBy": 402,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe Photo OCR, a system for text extraction from images. Our particular focus is reliable text extraction from smartphone imagery, with the goal of text recognition as a user input modality similar to speech recognition. Commercially available OCR performs poorly on this task. Recent progress in machine learning has substantially improved isolated character classification, we build on this progress by demonstrating a complete OCR system using these techniques. We also incorporate modern data center-scale distributed language modelling. Our approach is capable of recognizing text in a variety of challenging imaging conditions where traditional OCR systems fail, notably in the presence of substantial blur, low resolution, low contrast, high image noise and other distortions. It also operates with low latency, mean processing time is 600 ms per image. We evaluate our system on public benchmark datasets for text extraction and outperform all previously reported results, more than halving the error rate on multiple benchmarks. The system is currently in use in many applications at Google, and is available as a user input modality in Google Translate for Android."
            },
            "slug": "PhotoOCR:-Reading-Text-in-Uncontrolled-Conditions-Bissacco-Cummins",
            "title": {
                "fragments": [],
                "text": "PhotoOCR: Reading Text in Uncontrolled Conditions"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This work describes Photo OCR, a system for text extraction from images that is capable of recognizing text in a variety of challenging imaging conditions where traditional OCR systems fail, notably in the presence of substantial blur, low resolution, low contrast, high image noise and other distortions."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Computer Vision"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1968574"
                        ],
                        "name": "Sezer Karaoglu",
                        "slug": "Sezer-Karaoglu",
                        "structuredName": {
                            "firstName": "Sezer",
                            "lastName": "Karaoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sezer Karaoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738975"
                        ],
                        "name": "J. V. Gemert",
                        "slug": "J.-V.-Gemert",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Gemert",
                            "middleNames": [
                                "C.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Gemert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "As a consequence, and shown in Figure 2 (e), the spatial text occurrence probability, as in [8], is wider distributed in COCO-Text than in related datasets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6606231,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d2343e94412c10718e9912e47ca98d05985e354",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose to use text recognition to aid in visual object class recognition. To this end we first propose a new algorithm for text detection in natural images. The proposed text detection is based on saliency cues and a context fusion step. The algorithm does not need any parameter tuning and can deal with varying imaging conditions. We evaluate three different tasks: 1. Scene text recognition, where we increase the state-of-the-art by 0.17 on the ICDAR 2003 dataset. 2. Saliency based object recognition, where we outperform other state-of-the-art saliency methods for object recognition on the PASCAL VOC 2011 dataset. 3. Object recognition with the aid of recognized text, where we are the first to report multi-modal results on the IMET set. Results show that text helps for object class recognition if the text is not uniquely coupled to individual object instances."
            },
            "slug": "Object-Reading:-Text-Recognition-for-Object-Karaoglu-Gemert",
            "title": {
                "fragments": [],
                "text": "Object Reading: Text Recognition for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Results show that text helps for object class recognition if the text is not uniquely coupled to individual object instances."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV Workshops"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145532509"
                        ],
                        "name": "Luk\u00e1s Neumann",
                        "slug": "Luk\u00e1s-Neumann",
                        "structuredName": {
                            "firstName": "Luk\u00e1s",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luk\u00e1s Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 141
                            }
                        ],
                        "text": "The problem of detecting and recognizing text in scenes has received increasing attention from the computer vision community in recent years [1, 6, 14, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "Further, Neumann and Matas [14] first identify Extremal Regions, groups them into words and then selects most probable character segmentation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206591895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8b595c9e969e5605f62da51b6c16dad8aad3e0e",
            "isKey": false,
            "numCitedBy": 790,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "An end-to-end real-time scene text localization and recognition method is presented. The real-time performance is achieved by posing the character detection problem as an efficient sequential selection from the set of Extremal Regions (ERs). The ER detector is robust to blur, illumination, color and texture variation and handles low-contrast text. In the first classification stage, the probability of each ER being a character is estimated using novel features calculated with O(1) complexity per region tested. Only ERs with locally maximal probability are selected for the second stage, where the classification is improved using more computationally expensive features. A highly efficient exhaustive search with feedback loops is then applied to group ERs into words and to select the most probable character segmentation. Finally, text is recognized in an OCR stage trained using synthetic fonts. The method was evaluated on two public datasets. On the ICDAR 2011 dataset, the method achieves state-of-the-art text localization results amongst published methods and it is the first one to report results for end-to-end text recognition. On the more challenging Street View Text dataset, the method achieves state-of-the-art recall. The robustness of the proposed method against noise and low contrast of characters is demonstrated by \u201cfalse positives\u201d caused by detected watermark text in the dataset."
            },
            "slug": "Real-time-scene-text-localization-and-recognition-Neumann-Matas",
            "title": {
                "fragments": [],
                "text": "Real-time scene text localization and recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "The proposed end-to-end real-time scene text localization and recognition method achieves state-of-the-art text localization results amongst published methods and it is the first one to report results for end- to-end text recognition."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1968574"
                        ],
                        "name": "Sezer Karaoglu",
                        "slug": "Sezer-Karaoglu",
                        "structuredName": {
                            "firstName": "Sezer",
                            "lastName": "Karaoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sezer Karaoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738975"
                        ],
                        "name": "J. V. Gemert",
                        "slug": "J.-V.-Gemert",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Gemert",
                            "middleNames": [
                                "C.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Gemert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7] use detected scene text for fine-grained building classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8430994,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc36ab26877604d782c3983a438079aef7686ebf",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper focuses on fine-grained classification by detecting photographed text in images. We introduce a text detection method that does not try to detect all possible foreground text regions but instead aims to reconstruct the scene background to eliminate non-text regions. Object cues such as color, contrast, and objectiveness are used in corporation with a random forest classifier to detect background pixels in the scene. Results on two publicly available datasets ICDAR03 and a fine-grained Building subcategories of ImageNet shows the effectiveness of the proposed method."
            },
            "slug": "Con-text:-text-detection-using-background-for-Karaoglu-Gemert",
            "title": {
                "fragments": [],
                "text": "Con-text: text detection using background connectivity for fine-grained object classification"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A text detection method that does not try to detect all possible foreground text regions but instead aims to reconstruct the scene background to eliminate non-text regions and results on two publicly available datasets shows the effectiveness of the proposed method."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148896777"
                        ],
                        "name": "Kai Wang",
                        "slug": "Kai-Wang",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14911813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d307221fa52e3939d46180cb5921ebbd92c8adb",
            "isKey": false,
            "numCitedBy": 425,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for spotting words in the wild, i.e., in real images taken in unconstrained environments. Text found in the wild has a surprising range of difficulty. At one end of the spectrum, Optical Character Recognition (OCR) applied to scanned pages of well formatted printed text is one of the most successful applications of computer vision to date. At the other extreme lie visual CAPTCHAs - text that is constructed explicitly to fool computer vision algorithms. Both tasks involve recognizing text, yet one is nearly solved while the other remains extremely challenging. In this work, we argue that the appearance of words in the wild spans this range of difficulties and propose a new word recognition approach based on state-of-the-art methods from generic object recognition, in which we consider object categories to be the words themselves. We compare performance of leading OCR engines - one open source and one proprietary - with our new approach on the ICDAR Robust Reading data set and a new word spotting data set we introduce in this paper: the Street View Text data set. We show improvements of up to 16% on the data sets, demonstrating the feasibility of a new approach to a seemingly old problem."
            },
            "slug": "Word-Spotting-in-the-Wild-Wang-Belongie",
            "title": {
                "fragments": [],
                "text": "Word Spotting in the Wild"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is argued that the appearance of words in the wild spans this range of difficulties and a new word recognition approach based on state-of-the-art methods from generic object recognition is proposed, in which object categories are considered to be the words themselves."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87531536"
                        ],
                        "name": "A. Panaretos",
                        "slug": "A.-Panaretos",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Panaretos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Panaretos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073684197"
                        ],
                        "name": "Luis Sosa",
                        "slug": "Luis-Sosa",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Sosa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luis Sosa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052189571"
                        ],
                        "name": "Anthony Tang",
                        "slug": "Anthony-Tang",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108862960"
                        ],
                        "name": "Shirley Wong",
                        "slug": "Shirley-Wong",
                        "structuredName": {
                            "firstName": "Shirley",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shirley Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114080648"
                        ],
                        "name": "Robert Young",
                        "slug": "Robert-Young",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Young"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "We analyze COCO-Text and compare it to other popular scene text datasets, in particular, with ICDAR 03 [11] and ICDAR 15 [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "The ICDAR Robust Reading challenge [11], referred to from now on as ICDAR 03, was the first public dataset for detecting and recognizing scene text."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6379469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce39eb5cc1049a1060a499d6b6e94c8b2ec11da1",
            "isKey": false,
            "numCitedBy": 591,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the robust reading competitions forICDAR 2003. With the rapid growth in research over thelast few years on recognizing text in natural scenes, thereis an urgent need to establish some common benchmarkdatasets, and gain a clear understanding of the current stateof the art. We use the term robust reading to refer to text imagesthat are beyond the capabilities of current commercialOCR packages. We chose to break down the robust readingproblem into three sub-problems, and run competitionsfor each stage, and also a competition for the best overallsystem. The sub-problems we chose were text locating,character recognition and word recognition.By breaking down the problem in this way, we hope togain a better understanding of the state of the art in eachof the sub-problems. Furthermore, our methodology involvesstoring detailed results of applying each algorithm toeach image in the data sets, allowing researchers to study indepth the strengths and weaknesses of each algorithm. Thetext locating contest was the only one to have any entries.We report the results of this contest, and show cases wherethe leading algorithms succeed and fail."
            },
            "slug": "ICDAR-2003-robust-reading-competitions-Lucas-Panaretos",
            "title": {
                "fragments": [],
                "text": "ICDAR 2003 robust reading competitions"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The robust reading problem was broken down into three sub-problems, and competitions for each stage, and also a competition for the best overall system, which was the only one to have any entries."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33493200"
                        ],
                        "name": "Tsung-Yi Lin",
                        "slug": "Tsung-Yi-Lin",
                        "structuredName": {
                            "firstName": "Tsung-Yi",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsung-Yi Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48966748"
                        ],
                        "name": "James Hays",
                        "slug": "James-Hays",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hays",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Hays"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699161"
                        ],
                        "name": "C. L. Zitnick",
                        "slug": "C.-L.-Zitnick",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Zitnick",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Zitnick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "In recent years large-scale datasets like SUN [22], Imagenet [3] and MS COCO [10] drove the advancement of several fields in computer vision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "The dataset is based on the Microsoft COCO dataset [10] that annotates common objects in their natural contexts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14113767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71b7178df5d2b112d07e45038cb5637208659ff7",
            "isKey": false,
            "numCitedBy": 19759,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model."
            },
            "slug": "Microsoft-COCO:-Common-Objects-in-Context-Lin-Maire",
            "title": {
                "fragments": [],
                "text": "Microsoft COCO: Common Objects in Context"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding by gathering images of complex everyday scenes containing common objects in their natural context."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730090"
                        ],
                        "name": "L. G. I. Bigorda",
                        "slug": "L.-G.-I.-Bigorda",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Bigorda",
                            "middleNames": [
                                "G\u00f3mez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. G. I. Bigorda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2098117"
                        ],
                        "name": "Anguelos Nicolaou",
                        "slug": "Anguelos-Nicolaou",
                        "structuredName": {
                            "firstName": "Anguelos",
                            "lastName": "Nicolaou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anguelos Nicolaou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39937691"
                        ],
                        "name": "Suman K. Ghosh",
                        "slug": "Suman-K.-Ghosh",
                        "structuredName": {
                            "firstName": "Suman",
                            "lastName": "Ghosh",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suman K. Ghosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749498"
                        ],
                        "name": "Andrew D. Bagdanov",
                        "slug": "Andrew-D.-Bagdanov",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Bagdanov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew D. Bagdanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35613969"
                        ],
                        "name": "M. Iwamura",
                        "slug": "M.-Iwamura",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Iwamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145532509"
                        ],
                        "name": "Luk\u00e1s Neumann",
                        "slug": "Luk\u00e1s-Neumann",
                        "structuredName": {
                            "firstName": "Luk\u00e1s",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luk\u00e1s Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802086"
                        ],
                        "name": "V. Chandrasekhar",
                        "slug": "V.-Chandrasekhar",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Chandrasekhar",
                            "middleNames": [
                                "Ramaseshan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Chandrasekhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771189"
                        ],
                        "name": "Shijian Lu",
                        "slug": "Shijian-Lu",
                        "structuredName": {
                            "firstName": "Shijian",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shijian Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809705"
                        ],
                        "name": "S. Uchida",
                        "slug": "S.-Uchida",
                        "structuredName": {
                            "firstName": "Seiichi",
                            "lastName": "Uchida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Uchida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864362"
                        ],
                        "name": "Ernest Valveny",
                        "slug": "Ernest-Valveny",
                        "structuredName": {
                            "firstName": "Ernest",
                            "lastName": "Valveny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ernest Valveny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "We analyze COCO-Text and compare it to other popular scene text datasets, in particular, with ICDAR 03 [11] and ICDAR 15 [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 184
                            }
                        ],
                        "text": "Evaluation procedure We follow the text detection and recognition evaluation scheme as used in the ICDAR robust reading competition for end-to-end recognition of incidental scene text [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "The newest iteration of this challenge [9] introduced a competition on incidental scene text, referred to as ICDAR 15, which contains about 1500 images acquired with wearable devices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13322740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b02f729e6d442f6872078f599fc9da5c3605cee",
            "isKey": false,
            "numCitedBy": 786,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Results of the ICDAR 2015 Robust Reading Competition are presented. A new Challenge 4 on Incidental Scene Text has been added to the Challenges on Born-Digital Images, Focused Scene Images and Video Text. Challenge 4 is run on a newly acquired dataset of 1,670 images evaluating Text Localisation, Word Recognition and End-to-End pipelines. In addition, the dataset for Challenge 3 on Video Text has been substantially updated with more video sequences and more accurate ground truth data. Finally, tasks assessing End-to-End system performance have been introduced to all Challenges. The competition took place in the first quarter of 2015, and received a total of 44 submissions. Only the tasks newly introduced in 2015 are reported on. The datasets, the ground truth specification and the evaluation protocols are presented together with the results and a brief summary of the participating methods."
            },
            "slug": "ICDAR-2015-competition-on-Robust-Reading-Karatzas-Bigorda",
            "title": {
                "fragments": [],
                "text": "ICDAR 2015 competition on Robust Reading"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A new Challenge 4 on Incidental Scene Text has been added to the Challenges on Born-Digital Images, Focused Scene Images and Video Text and tasks assessing End-to-End system performance have been introduced to all Challenges."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143823474"
                        ],
                        "name": "Mar\u00e7al Rusi\u00f1ol",
                        "slug": "Mar\u00e7al-Rusi\u00f1ol",
                        "structuredName": {
                            "firstName": "Mar\u00e7al",
                            "lastName": "Rusi\u00f1ol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mar\u00e7al Rusi\u00f1ol"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688695"
                        ],
                        "name": "Volkmar Frinken",
                        "slug": "Volkmar-Frinken",
                        "structuredName": {
                            "firstName": "Volkmar",
                            "lastName": "Frinken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volkmar Frinken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749498"
                        ],
                        "name": "Andrew D. Bagdanov",
                        "slug": "Andrew-D.-Bagdanov",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Bagdanov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew D. Bagdanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826881"
                        ],
                        "name": "J. Llad\u00f3s",
                        "slug": "J.-Llad\u00f3s",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Llad\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Llad\u00f3s"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[16] merge visual and textual descriptions to classify administrative document images and Karaoglu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 288739,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bfa6cb9b9eeb5d5a37273b47d6090f617ad0f0d7",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a page classification application in a banking workflow. The proposed architecture represents administrative document images by merging visual and textual descriptions. The visual description is based on a hierarchical representation of the pixel intensity distribution. The textual description uses latent semantic analysis to represent document content as a mixture of topics. Several off-the-shelf classifiers and different strategies for combining visual and textual cues have been evaluated. A final step uses an $$n$$n-gram model of the page stream allowing a finer-grained classification of pages. The proposed method has been tested in a real large-scale environment and we report results on a dataset of 70,000 pages."
            },
            "slug": "Multimodal-page-classification-in-administrative-Rusi\u00f1ol-Frinken",
            "title": {
                "fragments": [],
                "text": "Multimodal page classification in administrative document image streams"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper presents a page classification application in a banking workflow that represents administrative document images by merging visual and textual descriptions and uses an $$n$$n-gram model of the page stream allowing a finer-grained classification of pages."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition (IJDAR)"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847596"
                        ],
                        "name": "Wei Dong",
                        "slug": "Wei-Dong",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94451829"
                        ],
                        "name": "K. Li",
                        "slug": "K.-Li",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "In recent years large-scale datasets like SUN [22], Imagenet [3] and MS COCO [10] drove the advancement of several fields in computer vision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57246310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b47265245e8db53a553049dcb27ed3e495fd625",
            "isKey": false,
            "numCitedBy": 27361,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond."
            },
            "slug": "ImageNet:-A-large-scale-hierarchical-image-database-Deng-Dong",
            "title": {
                "fragments": [],
                "text": "ImageNet: A large-scale hierarchical image database"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new database called \u201cImageNet\u201d is introduced, a large-scale ontology of images built upon the backbone of the WordNet structure, much larger in scale and diversity and much more accurate than the current image datasets."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40599257"
                        ],
                        "name": "Jianxiong Xiao",
                        "slug": "Jianxiong-Xiao",
                        "structuredName": {
                            "firstName": "Jianxiong",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianxiong Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48966748"
                        ],
                        "name": "James Hays",
                        "slug": "James-Hays",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hays",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Hays"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1865091"
                        ],
                        "name": "Krista A. Ehinger",
                        "slug": "Krista-A.-Ehinger",
                        "structuredName": {
                            "firstName": "Krista",
                            "lastName": "Ehinger",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Krista A. Ehinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "In recent years large-scale datasets like SUN [22], Imagenet [3] and MS COCO [10] drove the advancement of several fields in computer vision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1309931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "908091b4a8757c3b2f7d9cfa2c4f616ee12c5157",
            "isKey": false,
            "numCitedBy": 2352,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene categorization is a fundamental problem in computer vision. However, scene understanding research has been constrained by the limited scope of currently-used databases which do not capture the full variety of scene categories. Whereas standard databases for object categorization contain hundreds of different classes of objects, the largest available dataset of scene categories contains only 15 classes. In this paper we propose the extensive Scene UNderstanding (SUN) database that contains 899 categories and 130,519 images. We use 397 well-sampled categories to evaluate numerous state-of-the-art algorithms for scene recognition and establish new bounds of performance. We measure human scene classification performance on the SUN database and compare this with computational methods. Additionally, we study a finer-grained scene representation to detect scenes embedded inside of larger scenes."
            },
            "slug": "SUN-database:-Large-scale-scene-recognition-from-to-Xiao-Hays",
            "title": {
                "fragments": [],
                "text": "SUN database: Large-scale scene recognition from abbey to zoo"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes the extensive Scene UNderstanding (SUN) database that contains 899 categories and 130,519 images and uses 397 well-sampled categories to evaluate numerous state-of-the-art algorithms for scene recognition and establish new bounds of performance."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143648071"
                        ],
                        "name": "S. Eslami",
                        "slug": "S.-Eslami",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Eslami",
                            "middleNames": [
                                "M.",
                                "Ali"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Eslami"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 149
                            }
                        ],
                        "text": "The evaluations for scene text detection uses a single Intersection-over-Union (IoU) criterion, with a threshold of 50%, similar to object detection [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207252270,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "616b246e332573af1f4859aa91440280774c183a",
            "isKey": false,
            "numCitedBy": 3766,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "The Pascal Visual Object Classes (VOC) challenge consists of two components: (i)\u00a0a publicly available dataset of images together with ground truth annotation and standardised evaluation software; and (ii)\u00a0an annual competition and workshop. There are five challenges: classification, detection, segmentation, action classification, and person layout. In this paper we provide a review of the challenge from 2008\u20132012. The paper is intended for two audiences: algorithm designers, researchers who want to see what the state of the art is, as measured by performance on the VOC datasets, along with the limitations and weak points of the current generation of algorithms; and, challenge designers, who want to see what we as organisers have learnt from the process and our recommendations for the organisation of future challenges. To analyse the performance of submitted algorithms on the VOC datasets we introduce a number of novel evaluation methods: a bootstrapping method for determining whether differences in the performance of two algorithms are significant or not; a normalised average precision so that performance can be compared across classes with different proportions of positive instances; a clustering method for visualising the performance across multiple algorithms so that the hard and easy images can be identified; and the use of a joint classifier over the submitted algorithms in order to measure their complementarity and combined performance. We also analyse the community\u2019s progress through time using the methods of Hoiem et al. (Proceedings of European Conference on Computer Vision, 2012) to identify the types of occurring errors. We conclude the paper with an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges."
            },
            "slug": "The-Pascal-Visual-Object-Classes-Challenge:-A-Everingham-Eslami",
            "title": {
                "fragments": [],
                "text": "The Pascal Visual Object Classes Challenge: A Retrospective"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A review of the Pascal Visual Object Classes challenge from 2008-2012 and an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2192178"
                        ],
                        "name": "Olga Russakovsky",
                        "slug": "Olga-Russakovsky",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Russakovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olga Russakovsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[17] propose a framework that combines object detectors with human annotators to annotate a dataset."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6557946,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bbc31c14529b64cd7ad833b8a270b3b3e515c75",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "The long-standing goal of localizing every object in an image remains elusive. Manually annotating objects is quite expensive despite crowd engineering innovations. Current state-of-the-art automatic object detectors can accurately detect at most a few objects per image. This paper brings together the latest advancements in object detection and in crowd engineering into a principled framework for accurately and efficiently localizing objects in images. The input to the system is an image to annotate and a set of annotation constraints: desired precision, utility and/or human cost of the labeling. The output is a set of object annotations, informed by human feedback and computer vision. Our model seamlessly integrates multiple computer vision models with multiple sources of human input in a Markov Decision Process. We empirically validate the effectiveness of our human-in-the-loop labeling approach on the ILSVRC2014 object detection dataset."
            },
            "slug": "Best-of-both-worlds:-Human-machine-collaboration-Russakovsky-Li",
            "title": {
                "fragments": [],
                "text": "Best of both worlds: Human-machine collaboration for object annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper empirically validate the effectiveness of the human-in-the-loop labeling approach on the ILSVRC2014 object detection dataset and seamlessly integrates multiple computer vision models with multiple sources of human input in a Markov Decision Process."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39717886"
                        ],
                        "name": "Xinlei Chen",
                        "slug": "Xinlei-Chen",
                        "structuredName": {
                            "firstName": "Xinlei",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinlei Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113484216"
                        ],
                        "name": "Hao Fang",
                        "slug": "Hao-Fang",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33493200"
                        ],
                        "name": "Tsung-Yi Lin",
                        "slug": "Tsung-Yi-Lin",
                        "structuredName": {
                            "firstName": "Tsung-Yi",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsung-Yi Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8137017"
                        ],
                        "name": "Ramakrishna Vedantam",
                        "slug": "Ramakrishna-Vedantam",
                        "structuredName": {
                            "firstName": "Ramakrishna",
                            "lastName": "Vedantam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ramakrishna Vedantam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144157872"
                        ],
                        "name": "Saurabh Gupta",
                        "slug": "Saurabh-Gupta",
                        "structuredName": {
                            "firstName": "Saurabh",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saurabh Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699161"
                        ],
                        "name": "C. L. Zitnick",
                        "slug": "C.-L.-Zitnick",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Zitnick",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Zitnick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "The presented dataset is based upon MS COCO and its image captions extension [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2210455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "696ca58d93f6404fea0fc75c62d1d7b378f47628",
            "isKey": false,
            "numCitedBy": 1178,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe the Microsoft COCO Caption dataset and evaluation server. When completed, the dataset will contain over one and a half million captions describing over 330,000 images. For the training and validation images, five independent human generated captions will be provided. To ensure consistency in evaluation of automatic caption generation algorithms, an evaluation server is used. The evaluation server receives candidate captions and scores them using several popular metrics, including BLEU, METEOR, ROUGE and CIDEr. Instructions for using the evaluation server are provided."
            },
            "slug": "Microsoft-COCO-Captions:-Data-Collection-and-Server-Chen-Fang",
            "title": {
                "fragments": [],
                "text": "Microsoft COCO Captions: Data Collection and Evaluation Server"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The Microsoft COCO Caption dataset and evaluation server are described and several popular metrics, including BLEU, METEOR, ROUGE and CIDEr are used to score candidate captions."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3035230"
                        ],
                        "name": "Michael J. Wilber",
                        "slug": "Michael-J.-Wilber",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wilber",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Wilber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097992"
                        ],
                        "name": "Iljung S. Kwak",
                        "slug": "Iljung-S.-Kwak",
                        "structuredName": {
                            "firstName": "Iljung",
                            "lastName": "Kwak",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iljung S. Kwak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[21] investigate the use of grid questions, where workers select answers from a grid of images to take advantage of the parallelism of human perception."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7482099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53d1583d6a0691b3f8f890a56cf41e33ac417d31",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Similarity comparisons of the form \"Is object a more similar to b than to c?\" are useful for computer vision and machine learning applications. Unfortunately, an embedding of $n$ points is specified by $n^3$ triplets, making collecting every triplet an expensive task. In noticing this difficulty, other researchers have investigated more intelligent triplet sampling techniques, but they do not study their effectiveness or their potential drawbacks. Although it is important to reduce the number of collected triplets, it is also important to understand how best to display a triplet collection task to a user. In this work we explore an alternative display for collecting triplets and analyze the monetary cost and speed of the display. We propose best practices for creating cost effective human intelligence tasks for collecting triplets. We show that rather than changing the sampling algorithm, simple changes to the crowdsourcing UI can lead to much higher quality embeddings. We also provide a dataset as well as the labels collected from crowd workers."
            },
            "slug": "Cost-Effective-HITs-for-Relative-Similarity-Wilber-Kwak",
            "title": {
                "fragments": [],
                "text": "Cost-Effective HITs for Relative Similarity Comparisons"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that rather than changing the sampling algorithm, simple changes to the crowdsourcing UI can lead to much higher quality embeddings, and this work proposes best practices for creating cost effective human intelligence tasks for collecting triplets."
            },
            "venue": {
                "fragments": [],
                "text": "HCOMP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799898"
                        ],
                        "name": "Andreas Veit",
                        "slug": "Andreas-Veit",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Veit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Veit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3035230"
                        ],
                        "name": "Michael J. Wilber",
                        "slug": "Michael-J.-Wilber",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wilber",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Wilber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1927646"
                        ],
                        "name": "Rajan Vaish",
                        "slug": "Rajan-Vaish",
                        "structuredName": {
                            "firstName": "Rajan",
                            "lastName": "Vaish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajan Vaish"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111092372"
                        ],
                        "name": "James Davis",
                        "slug": "James-Davis",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144578530"
                        ],
                        "name": "Vishal Anand",
                        "slug": "Vishal-Anand",
                        "structuredName": {
                            "firstName": "Vishal",
                            "lastName": "Anand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vishal Anand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144844721"
                        ],
                        "name": "Anshu Aviral",
                        "slug": "Anshu-Aviral",
                        "structuredName": {
                            "firstName": "Anshu",
                            "lastName": "Aviral",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anshu Aviral"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40211576"
                        ],
                        "name": "Prithvijit Chakrabarty",
                        "slug": "Prithvijit-Chakrabarty",
                        "structuredName": {
                            "firstName": "Prithvijit",
                            "lastName": "Chakrabarty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prithvijit Chakrabarty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2232505"
                        ],
                        "name": "Yash Chandak",
                        "slug": "Yash-Chandak",
                        "structuredName": {
                            "firstName": "Yash",
                            "lastName": "Chandak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yash Chandak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057381665"
                        ],
                        "name": "Sidharth Chaturvedi",
                        "slug": "Sidharth-Chaturvedi",
                        "structuredName": {
                            "firstName": "Sidharth",
                            "lastName": "Chaturvedi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sidharth Chaturvedi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39685196"
                        ],
                        "name": "Chinmaya Devaraj",
                        "slug": "Chinmaya-Devaraj",
                        "structuredName": {
                            "firstName": "Chinmaya",
                            "lastName": "Devaraj",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chinmaya Devaraj"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2010095"
                        ],
                        "name": "Ankit Dhall",
                        "slug": "Ankit-Dhall",
                        "structuredName": {
                            "firstName": "Ankit",
                            "lastName": "Dhall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ankit Dhall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2361577"
                        ],
                        "name": "Utkarsh Dwivedi",
                        "slug": "Utkarsh-Dwivedi",
                        "structuredName": {
                            "firstName": "Utkarsh",
                            "lastName": "Dwivedi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Utkarsh Dwivedi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24627399"
                        ],
                        "name": "S. Gupte",
                        "slug": "S.-Gupte",
                        "structuredName": {
                            "firstName": "Sanket",
                            "lastName": "Gupte",
                            "middleNames": [
                                "Rajan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gupte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057436877"
                        ],
                        "name": "S. N. Sridhar",
                        "slug": "S.-N.-Sridhar",
                        "structuredName": {
                            "firstName": "Sharath",
                            "lastName": "Sridhar",
                            "middleNames": [
                                "Nittur"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. N. Sridhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2726622"
                        ],
                        "name": "Karthik Paga",
                        "slug": "Karthik-Paga",
                        "structuredName": {
                            "firstName": "Karthik",
                            "lastName": "Paga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karthik Paga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3210710"
                        ],
                        "name": "Anuj Pahuja",
                        "slug": "Anuj-Pahuja",
                        "structuredName": {
                            "firstName": "Anuj",
                            "lastName": "Pahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anuj Pahuja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3209503"
                        ],
                        "name": "Aditya Raisinghani",
                        "slug": "Aditya-Raisinghani",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Raisinghani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aditya Raisinghani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109364406"
                        ],
                        "name": "Ayush Sharma",
                        "slug": "Ayush-Sharma",
                        "structuredName": {
                            "firstName": "Ayush",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ayush Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109849245"
                        ],
                        "name": "Shweta Sharma",
                        "slug": "Shweta-Sharma",
                        "structuredName": {
                            "firstName": "Shweta",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shweta Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3008246"
                        ],
                        "name": "Darpana Sinha",
                        "slug": "Darpana-Sinha",
                        "structuredName": {
                            "firstName": "Darpana",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Darpana Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47098197"
                        ],
                        "name": "Nisarg Thakkar",
                        "slug": "Nisarg-Thakkar",
                        "structuredName": {
                            "firstName": "Nisarg",
                            "lastName": "Thakkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nisarg Thakkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2132361302"
                        ],
                        "name": "K. Vignesh",
                        "slug": "K.-Vignesh",
                        "structuredName": {
                            "firstName": "Kothapalli",
                            "lastName": "Vignesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Vignesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33479962"
                        ],
                        "name": "Utkarsh Verma",
                        "slug": "Utkarsh-Verma",
                        "structuredName": {
                            "firstName": "Utkarsh",
                            "lastName": "Verma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Utkarsh Verma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065021927"
                        ],
                        "name": "Kanniganti Abhishek",
                        "slug": "Kanniganti-Abhishek",
                        "structuredName": {
                            "firstName": "Kanniganti",
                            "lastName": "Abhishek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kanniganti Abhishek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075308407"
                        ],
                        "name": "A. Agrawal",
                        "slug": "A.-Agrawal",
                        "structuredName": {
                            "firstName": "Amod",
                            "lastName": "Agrawal",
                            "middleNames": [
                                "Kant"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agrawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137611607"
                        ],
                        "name": "A. Aishwarya",
                        "slug": "A.-Aishwarya",
                        "structuredName": {
                            "firstName": "Arya",
                            "lastName": "Aishwarya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aishwarya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32629368"
                        ],
                        "name": "Aurgho Bhattacharjee",
                        "slug": "Aurgho-Bhattacharjee",
                        "structuredName": {
                            "firstName": "Aurgho",
                            "lastName": "Bhattacharjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aurgho Bhattacharjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2098254905"
                        ],
                        "name": "S. Dhanasekar",
                        "slug": "S.-Dhanasekar",
                        "structuredName": {
                            "firstName": "Sarveshwaran",
                            "lastName": "Dhanasekar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dhanasekar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12029791"
                        ],
                        "name": "V. Gullapalli",
                        "slug": "V.-Gullapalli",
                        "structuredName": {
                            "firstName": "Venkata",
                            "lastName": "Gullapalli",
                            "middleNames": [
                                "Karthik"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Gullapalli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000852900"
                        ],
                        "name": "Shuchita Gupta",
                        "slug": "Shuchita-Gupta",
                        "structuredName": {
                            "firstName": "Shuchita",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuchita Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144917431"
                        ],
                        "name": "G. Chandana",
                        "slug": "G.-Chandana",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "Chandana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Chandana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055619433"
                        ],
                        "name": "Kinjal Jain",
                        "slug": "Kinjal-Jain",
                        "structuredName": {
                            "firstName": "Kinjal",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kinjal Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32886212"
                        ],
                        "name": "Simran Kapur",
                        "slug": "Simran-Kapur",
                        "structuredName": {
                            "firstName": "Simran",
                            "lastName": "Kapur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simran Kapur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3024189"
                        ],
                        "name": "Meghana Kasula",
                        "slug": "Meghana-Kasula",
                        "structuredName": {
                            "firstName": "Meghana",
                            "lastName": "Kasula",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meghana Kasula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109682655"
                        ],
                        "name": "Shashi Kumar",
                        "slug": "Shashi-Kumar",
                        "structuredName": {
                            "firstName": "Shashi",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shashi Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3225172"
                        ],
                        "name": "Parth Kundaliya",
                        "slug": "Parth-Kundaliya",
                        "structuredName": {
                            "firstName": "Parth",
                            "lastName": "Kundaliya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Parth Kundaliya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3272917"
                        ],
                        "name": "U. Mathur",
                        "slug": "U.-Mathur",
                        "structuredName": {
                            "firstName": "Utkarsh",
                            "lastName": "Mathur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Mathur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31623053"
                        ],
                        "name": "Alankrit Mishra",
                        "slug": "Alankrit-Mishra",
                        "structuredName": {
                            "firstName": "Alankrit",
                            "lastName": "Mishra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alankrit Mishra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40190563"
                        ],
                        "name": "Aayush Mudgal",
                        "slug": "Aayush-Mudgal",
                        "structuredName": {
                            "firstName": "Aayush",
                            "lastName": "Mudgal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aayush Mudgal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2332945"
                        ],
                        "name": "Aditya Nadimpalli",
                        "slug": "Aditya-Nadimpalli",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Nadimpalli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aditya Nadimpalli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1623023245"
                        ],
                        "name": "M. Nihit",
                        "slug": "M.-Nihit",
                        "structuredName": {
                            "firstName": "Munakala",
                            "lastName": "Nihit",
                            "middleNames": [
                                "Sree"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nihit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2891385"
                        ],
                        "name": "Akanksha Periwal",
                        "slug": "Akanksha-Periwal",
                        "structuredName": {
                            "firstName": "Akanksha",
                            "lastName": "Periwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akanksha Periwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27088780"
                        ],
                        "name": "Ayush Sagar",
                        "slug": "Ayush-Sagar",
                        "structuredName": {
                            "firstName": "Ayush",
                            "lastName": "Sagar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ayush Sagar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36373875"
                        ],
                        "name": "A. Shah",
                        "slug": "A.-Shah",
                        "structuredName": {
                            "firstName": "Ayush",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112607591"
                        ],
                        "name": "V. Sharma",
                        "slug": "V.-Sharma",
                        "structuredName": {
                            "firstName": "Vikash",
                            "lastName": "Sharma",
                            "middleNames": [
                                "Chandra"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28796092"
                        ],
                        "name": "Yashovardhan Sharma",
                        "slug": "Yashovardhan-Sharma",
                        "structuredName": {
                            "firstName": "Yashovardhan",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yashovardhan Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40231253"
                        ],
                        "name": "F. Siddiqui",
                        "slug": "F.-Siddiqui",
                        "structuredName": {
                            "firstName": "Faiza",
                            "lastName": "Siddiqui",
                            "middleNames": [
                                "Banu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Siddiqui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152902942"
                        ],
                        "name": "Virender Singh",
                        "slug": "Virender-Singh",
                        "structuredName": {
                            "firstName": "Virender",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Virender Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114600802"
                        ],
                        "name": "S. Abhinav",
                        "slug": "S.-Abhinav",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Abhinav",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Abhinav"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2018910"
                        ],
                        "name": "Pradyumna Tambwekar",
                        "slug": "Pradyumna-Tambwekar",
                        "structuredName": {
                            "firstName": "Pradyumna",
                            "lastName": "Tambwekar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pradyumna Tambwekar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13823409"
                        ],
                        "name": "R. Taskin",
                        "slug": "R.-Taskin",
                        "structuredName": {
                            "firstName": "Rashida",
                            "lastName": "Taskin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Taskin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064395584"
                        ],
                        "name": "Ankit Tripathi",
                        "slug": "Ankit-Tripathi",
                        "structuredName": {
                            "firstName": "Ankit",
                            "lastName": "Tripathi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ankit Tripathi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47511928"
                        ],
                        "name": "Anurag D. Yadav",
                        "slug": "Anurag-D.-Yadav",
                        "structuredName": {
                            "firstName": "Anurag",
                            "lastName": "Yadav",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anurag D. Yadav"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[18] that proposes strategies to optimize the task allocation to human workers with constrained budgets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2206614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08db1a0846c2a6a7d54338f02286b8d2d9fe9863",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "When crowdsourcing systems are used in combination with machine inference systems in the real world, they benefit the most when the machine system is deeply integrated with the crowd workers. However, if researchers wish to integrate the crowd with \"off-the-shelf\" machine classifiers, this deep integration is not always possible. This work explores two strategies to increase accuracy and decrease cost under this setting. First, we show that reordering tasks presented to the human can create a significant accuracy improvement. Further, we show that greedily choosing parameters to maximize machine accuracy is sub-optimal, and joint optimization of the combined system improves performance."
            },
            "slug": "On-Optimizing-Human-Machine-Task-Assignments-Veit-Wilber",
            "title": {
                "fragments": [],
                "text": "On Optimizing Human-Machine Task Assignments"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that reordering tasks presented to the human can create a significant accuracy improvement, and greedily choosing parameters to maximize machine accuracy is sub-optimal, and joint optimization of the combined system improves performance."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144367090"
                        ],
                        "name": "A. Romney",
                        "slug": "A.-Romney",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Romney",
                            "middleNames": [
                                "Kimball"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Romney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40509723"
                        ],
                        "name": "S. Weller",
                        "slug": "S.-Weller",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Weller",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1962505"
                        ],
                        "name": "W. Batchelder",
                        "slug": "W.-Batchelder",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Batchelder",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Batchelder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15] looked into improving label quality by taking worker accuracy into account."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26465931,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "dd0d45ede8a0b63f85fe4a897081d95c90a2477c",
            "isKey": false,
            "numCitedBy": 1562,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents and tests a formal mathematical model for the analysis of informant responses to systematic interview questions. We assume a situation in which the ethnographer does not know how much each informant knows about the cultural domain under consideration nor the answers to the questions. The model simultaneously provides an estimate of the cultural competence or knowledge of each informant and an estimate of the correct answer to each question asked of the informant. The model currently handles true-false, multiple-choice, andfill-in-the-blank type question formats. In familiar cultural domains the model produces good results from as few as four informants. The paper includes a table showing the number of informants needed to provide stated levels of confidence given the mean level of knowledge among the informants. Implications are discussed."
            },
            "slug": "Culture-as-Consensus:-A-Theory-of-Culture-and-Romney-Weller",
            "title": {
                "fragments": [],
                "text": "Culture as Consensus: A Theory of Culture and Informant Accuracy"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "To reduce bias towards specific approaches, we only use OCR input, where at least one human annotator agrees with the OCR input."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Icdar 2003 robust reading competitions. In IC- DAR '03"
            },
            "venue": {
                "fragments": [],
                "text": "Icdar 2003 robust reading competitions. In IC- DAR '03"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reading text in uncontrolled conditions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A user friendly crowdsourcing task manager"
            },
            "venue": {
                "fragments": [],
                "text": "Workshop on Computer Vision and Human Computation (CVPR),"
            },
            "year": 2014
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 15,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 24,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/COCO-Text:-Dataset-and-Benchmark-for-Text-Detection-Veit-Matera/b7325b788320f96f7b152768226f16e390ab6475?sort=total-citations"
}