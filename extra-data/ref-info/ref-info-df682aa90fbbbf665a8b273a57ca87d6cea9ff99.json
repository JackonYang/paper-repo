{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34830449"
                        ],
                        "name": "M. Sondhi",
                        "slug": "M.-Sondhi",
                        "structuredName": {
                            "firstName": "Man",
                            "lastName": "Sondhi",
                            "middleNames": [
                                "Mohan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sondhi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 286963,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d69572c59afb5e08c81903fa3e50c63bc7eb8fef",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we extend previous work on isolated word recognition based on hidden Markov models by replacing the discrete symbol representation of the speech signal by a continuous Gaussian mixture density. In this manner the inherent quantization error introduced by the discrete representation is essentially eliminated. The resulting recognizer was tested on a vocabulary of the 10 digits across a wide range of talkers and test conditions, and shown to have an error rate at least comparable to that of the best template recognizers and significantly lower than that of the discrete symbol hidden Markov model system. Several issues involved in the training of the continuous density models and in the implementation of the recognizer are discussed."
            },
            "slug": "Recent-developments-in-the-application-of-hidden-to-Juang-Rabiner",
            "title": {
                "fragments": [],
                "text": "Recent developments in the application of hidden Markov models to speaker-independent isolated word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Previous work on isolated word recognition based on hidden Markov models is extended by replacing the discrete symbol representation of the speech signal by a continuous Gaussian mixture density, so that the inherent quantization error introduced by the discrete representation is essentially eliminated."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '85. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102981024"
                        ],
                        "name": "A. Poritz",
                        "slug": "A.-Poritz",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Poritz",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Poritz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73321613"
                        ],
                        "name": "A. Richter",
                        "slug": "A.-Richter",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Richter",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Richter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 253
                            }
                        ],
                        "text": "\u2026of (21) can be modified to accommodate several other types of distributions, giving rise to the so-called vector quantizer HMM (Rabiner et al. 1983), semicontinuous HMM (Huang and Jack 1989), or continuous HMM (Bahl, Brown, de Souza, and Mercer 1988b; Poritz and Richter 1986; Rabiner et al. 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61065603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "489983d52c982aa8c00fae6b9dc8d16afbc8c7f0",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov modeling has become an increasingly popular technique in automatic speech recognition. Recently, attention has been focused on the application of these models to talker-independent, isolated-word recognition. Initial results using models with discrete output densities for isolated-digit recognition were later improved using models based on continuous output densities. In a series of experiments on isolated-word recognition, we applied hidden Markov models with multivariate Gaussian output densities to the problem. Speech data was represented by feature vectors consisting of eight log area ratios and the log LPC error. A weak measure of vocal-tract dynamics was included in the observations by appending to the feature vector observed at time t, the vector observed at time t-\u03b4, for some fixed offset \u03b4. The best models were obtained with offsets of 75 or 90 msecs. When a comparison is made on a common data base, the resulting error rate of 0.2% for isolated-digit recognition improves on previous algorithms."
            },
            "slug": "On-hidden-Markov-models-in-isolated-word-Poritz-Richter",
            "title": {
                "fragments": [],
                "text": "On hidden Markov models in isolated word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "In a series of experiments on isolated-word recognition, hidden Markov models with multivariate Gaussian output densities with best models obtained with offsets of 75 or 90 msecs improved on previous algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '86. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34830449"
                        ],
                        "name": "M. Sondhi",
                        "slug": "M.-Sondhi",
                        "structuredName": {
                            "firstName": "Man",
                            "lastName": "Sondhi",
                            "middleNames": [
                                "Mohan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sondhi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 42
                            }
                        ],
                        "text": "The scaling algorithm, well documented by Levinson et al. (1983) and Juang and Rabiner (1985), alleviates the dynamic-range problem by normalizing the par- B. H. JUANG AND L. R. RABINER tial probabilities, such as the forward variable defined in Section 2.1, at each time instance before they cause\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46254718,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "090f3ea5bc188bbb03aec02aba9ed9c7b38ff870",
            "isKey": false,
            "numCitedBy": 1082,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present several of the salient theoretical and practical issues associated with modeling a speech signal as a probabilistic function of a (hidden) Markov chain. First we give a concise review of the literature with emphasis on the Baum-Welch algorithm. This is followed by a detailed discussion of three issues not treated in the literature: alternatives to the Baum-Welch algorithm; critical facets of the implementation of the algorithms, with emphasis on their numerical properties; and behavior of Markov models on certain artificial but realistic problems. Special attention is given to a particular class of Markov models, which we call \u201cleft-to-right\u201d models. This class of models is especially appropriate for isolated word recognition. The results of the application of these methods to an isolated word, speaker-independent speech recognition experiment are given in a companion paper."
            },
            "slug": "An-introduction-to-the-application-of-the-theory-of-Levinson-Rabiner",
            "title": {
                "fragments": [],
                "text": "An introduction to the application of the theory of probabilistic functions of a Markov process to automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper presents several of the salient theoretical and practical issues associated with modeling a speech signal as a probabilistic function of a (hidden) Markov chain, and focuses on a particular class of Markov models, which are especially appropriate for isolated word recognition."
            },
            "venue": {
                "fragments": [],
                "text": "The Bell System Technical Journal"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60753901,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c41868f69d265783b7540094946ee902571c5cd",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The acoustic-modelling problem in automatic speech recognition is examined from an information theoretic point of view. This problem is to design a speech-recognition system which can extract from the speech waveform as much information as possible about the corresponding word sequence. The information extraction process is factored into two steps: a signal-processing step which converts a speech waveform into a sequence of informative acoustic feature vectors, and a step which models such a sequence. The authors are primarily concerned with the use of hidden Markov models to model sequences of feature vectors which lie in a continuous space. They explore the trade-off between packing information into such sequences and being able to model them accurately. The difficulty of developing accurate models of continuous-parameter sequences is addressed by investigating a method of parameter estimation which is designed to cope with inaccurate modeling assumptions.<<ETX>>"
            },
            "slug": "Speech-recognition-with-continuous-parameter-hidden-Bahl-Brown",
            "title": {
                "fragments": [],
                "text": "Speech recognition with continuous-parameter hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The authors explore the trade-off between packing information into sequences of feature vectors and being able to model them accurately and investigate a method of parameter estimation which is designed to cope with inaccurate modeling assumptions."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145778742"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Juang",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 82
                            }
                        ],
                        "text": "The reason is that the incomplete data problem formulation (Dempster et al. 1977; Rabiner and Juang 1986) , based on which the fundamental HMM probability measure of (8) is defined, is particularly appropriate when explicit knowledge of the exact position (labeling) of the particular sound in the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The reason is that the incomplete data problem formulation (Dempster et al. 1977;  Rabiner and Juang 1986 ), based on which the fundamental HMM probability measure of (8) is defined, is particularly appropriate when explicit knowledge of the exact position (labeling) of the particular sound in the middle of an utterance is lacking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11358505,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9d076613d7c36dbda4a6ff42fbdd076604b96630",
            "isKey": false,
            "numCitedBy": 2944,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The basic theory of Markov chains has been known to mathematicians and engineers for close to 80 years, but it is only in the past decade that it has been applied explicitly to problems in speech processing. One of the major reasons why speech models, based on Markov chains, have not been developed until recently was the lack of a method for optimizing the parameters of the Markov model to match observed signal patterns. Such a method was proposed in the late 1960's and was immediately applied to speech processing in several research institutions. Continued refinements in the theory and implementation of Markov modelling techniques have greatly enhanced the method, leading to a wide range of applications of these models. It is the purpose of this tutorial paper to give an introduction to the theory of Markov models, and to illustrate how they have been applied to problems in speech recognition."
            },
            "slug": "An-introduction-to-hidden-Markov-models-Rabiner-Juang",
            "title": {
                "fragments": [],
                "text": "An introduction to hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The purpose of this tutorial paper is to give an introduction to the theory of Markov models, and to illustrate how they have been applied to problems in speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE ASSP Magazine"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121831295,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7c3f98c68b6609599771b1161c0d94200eae03dc",
            "isKey": false,
            "numCitedBy": 501,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Continuously-variable-duration-hidden-Markov-models-Levinson",
            "title": {
                "fragments": [],
                "text": "Continuously variable duration hidden Markov models for automatic speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115311"
                        ],
                        "name": "R. Pieraccini",
                        "slug": "R.-Pieraccini",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Pieraccini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Pieraccini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154317"
                        ],
                        "name": "J. Wilpon",
                        "slug": "J.-Wilpon",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Wilpon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilpon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62584100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7818446040e36a99fcda685d67265c606c5b85d2",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Acoustic-modeling-for-large-vocabulary-speech-Lee-Rabiner",
            "title": {
                "fragments": [],
                "text": "Acoustic modeling for large vocabulary speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34830449"
                        ],
                        "name": "M. Sondhi",
                        "slug": "M.-Sondhi",
                        "structuredName": {
                            "firstName": "Man",
                            "lastName": "Sondhi",
                            "middleNames": [
                                "Mohan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sondhi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 196
                            }
                        ],
                        "text": "For HMM speech recognition, some trivial measures such as setting a numeric floor to prevent singularity are often found beneficial and are straightforward to implement (Lee, Lin, and Juang 1991; Rabiner et al. 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 63
                            }
                        ],
                        "text": "Although the postprocessor duration model has had some success (Rabiner et al. 1986), the questions of optimality of the estimate, robustness of the solution, and other criteria for successful use of duration information, especially as applied to speech recognition, remain unanswered."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 278
                            }
                        ],
                        "text": "\u2026of (21) can be modified to accommodate several other types of distributions, giving rise to the so-called vector quantizer HMM (Rabiner et al. 1983), semicontinuous HMM (Huang and Jack 1989), or continuous HMM (Bahl, Brown, de Souza, and Mercer 1988b; Poritz and Richter 1986; Rabiner et al. 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 67
                            }
                        ],
                        "text": "1983), semicontinuous HMM (Huang and Jack 1989), or continuous HMM (Bahl, Brown, de Souza, and Mercer 1988b; Poritz and Richter 1986; Rabiner et al. 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 64
                            }
                        ],
                        "text": "Although the postprocessor duration model has had some success (Rabiner et al. 1986) , the questions of optimality of the estimate, robustness of the solution, and other criteria for successful use of duration information, especially as applied to speech recognition, remain unanswered."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 152
                            }
                        ],
                        "text": "Finally, esimates of Pri(di) are obtained based on the optimal state sequence ij by either the ML method or from simple frequency of occurrence counts (Rabiner et al. 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35749818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e90c15e0de8b5452c6291359e98ddc099e3b93f6",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we extend previous work on isolated-word recognition based on hidden Markov models by replacing the discrete symbol representation of the speech signal with a continuous Gaussian mixture density. In this manner the inherent quantization error introduced by the discrete representation is essentially eliminated. The resulting recognizer was tested on a vocabulary of the ten digits across a wide range of talkers and test conditions and shown to have an error rate comparable to that of the best template recognizers and significantly lower than that of the discrete symbol hidden Markov model system. We discuss several issues involved in the training of the continuous density models and in the implementation of the recognizer."
            },
            "slug": "Recognition-of-isolated-digits-using-hidden-Markov-Rabiner-Juang",
            "title": {
                "fragments": [],
                "text": "Recognition of isolated digits using hidden Markov models with continuous mixture densities"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper extends previous work on isolated-word recognition based on hidden Markov models by replacing the discrete symbol representation of the speech signal with a continuous Gaussian mixture density, thereby eliminating the inherent quantization error introduced by the discrete representation."
            },
            "venue": {
                "fragments": [],
                "text": "AT&T Technical Journal"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34830449"
                        ],
                        "name": "M. Sondhi",
                        "slug": "M.-Sondhi",
                        "structuredName": {
                            "firstName": "Man",
                            "lastName": "Sondhi",
                            "middleNames": [
                                "Mohan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sondhi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 150
                            }
                        ],
                        "text": "\u2026mixture distribution of (21) can be modified to accommodate several other types of distributions, giving rise to the so-called vector quantizer HMM (Rabiner et al. 1983), semicontinuous HMM (Huang and Jack 1989), or continuous HMM (Bahl, Brown, de Souza, and Mercer 1988b; Poritz and Richter 1986;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 25
                            }
                        ],
                        "text": "use left-to-right models (Bakis 1976; Rabiner et al. 1983) of the type shown in Figure 7a, since the utterance begins and ends at well-identified time instants (except in the case of very noisy or corrupted speech) and the sequential behavior of the speech is well represented by a sequential HMM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 112
                            }
                        ],
                        "text": "For modeling isolated utterances (i.e., whole words or phrases), we often use left-to-right models (Bakis 1976; Rabiner et al. 1983) of the type shown in Figure 7a, since the utterance begins and ends at well-identified time instants (except in the case of very noisy or corrupted speech) and the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 197
                            }
                        ],
                        "text": "With specific constraints, the basic form of the mixture distribution of (21) can be modified to accommodate several other types of distributions, giving rise to the so-called vector quantizer HMM (Rabiner et al. 1983), semicontinuous HMM (Huang and Jack 1989), or continuous HMM (Bahl, Brown, de Souza, and Mercer 1988b; Poritz and Richter 1986; Rabiner et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 115
                            }
                        ],
                        "text": "Each b,, is obtained via the forward-backward algorithm as the weighted frequency of occurrence of the code index (Rabiner et al. 1983)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 25179305,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8acf7cb1d476ba09b401b0c13abe81d4b96d128e",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present an approach to speaker-independent, isolated word recognition in which the well-known techniques of vector quantization and hidden Markov modeling are combined with a linear predictive coding analysis front end. This is done in the framework of a standard statistical pattern recognition model. Both the vector quantizer and the hidden Markov models need to be trained for the vocabulary being recognized. Such training results in a distinct hidden Markov model for each word of the vocabulary. Classification consists of computing the probability of generating the test word with each word model and choosing the word model that gives the highest probability. There are several factors, in both the vector quantizer and the hidden Markov modeling, that affect the performance of the overall word recognition system, including the size of the vector quantizer, the structure of the hidden Markov model, the ways of handling insufficient training data, etc. The effects, on recognition accuracy, of many of these factors are discussed in this paper. The entire recognizer (training and testing) has been evaluated on a 10-word digits vocabulary. For training, a set of 100 talkers spoke each of the digits one time. For testing, an independent set of 100 tokens of each of the digits was obtained. The overall recognition accuracy was found to be 96.5 percent for the 100-talker test set. These results are comparable to those obtained in earlier work, using a dynamic time-warping recognition algorithm with multiple templates per digit. It is also shown that the computation and storage requirements of the new recognizer were an order of magnitude less than that required for a conventional pattern recognition system using linear prediction with dynamic time warping."
            },
            "slug": "On-the-application-of-vector-quantization-and-to-Rabiner-Levinson",
            "title": {
                "fragments": [],
                "text": "On the application of vector quantization and hidden Markov models to speaker-independent, isolated word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper presents an approach to speaker-independent, isolated word recognition in which the well-known techniques of vector quantization and hidden Markov modeling are combined with a linear predictive coding analysis front end in the framework of a standard statistical pattern recognition model."
            },
            "venue": {
                "fragments": [],
                "text": "The Bell System Technical Journal"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "tistical. performance ( Paul 1985 ). Note that the classical EM"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60933013,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5174286bbbf7e478ace597fd059b833414a729d6",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov models (HMM) are the basis for some of the more successful systems for continuous and discrete utterance speech recognition. One of the reasons for the success of these models is their ability to train automatically from marked speech data. The currently known forward-backward and gradient training methods suffer from the problem that they converge to a local maximum rather than to the global maximum. Simulated annealing is a stochastic optimization procedure which can escape a local optimum in the hope of finding the global optimum when presented with a system which contains many local optima. This paper shows how simulated annealing may be used to train HMM systems. It is experimentally shown to locate what appears to be the global maximum with a higher probability than the forward-backward algorithm."
            },
            "slug": "Training-of-HMM-recognizers-by-simulated-annealing-Paul",
            "title": {
                "fragments": [],
                "text": "Training of HMM recognizers by simulated annealing"
            },
            "tldr": {
                "abstractSimilarityScore": 33,
                "text": "Simulated annealing is experimentally shown to locate what appears to be the global maximum with a higher probability than the forward-backward algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '85. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15553242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "436f38dc28ca25af965b202ebe0e27c747888da6",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a signal modeling technique based upon finite mixture autoregressive probabilistic functions of Markov chains is developed and applied to the problem of speech recognition, particularly speaker-independent recognition of isolated digits. Two types of mixture probability densities are investigated: finite mixtures of Gaussian autoregressive densities (GAM) and nearest-neighbor partitioned finite mixtures of Gaussian autoregressive densities (PGAM). In the former (GAM), the observation density in each Markov state is simply a (stochastically constrained) weighted sum of Gaussian autoregressive densities, while in the latter (PGAM) it involves nearest-neighbor decoding which in effect, defines a set of partitions on the observation space. In this paper we discuss the signal modeling methodology and give experimental results on speaker independent recognition of isolated digits. We also discuss the potential use of the modeling technique for other applications."
            },
            "slug": "Mixture-autoregressive-hidden-Markov-models-for-Juang-Rabiner",
            "title": {
                "fragments": [],
                "text": "Mixture autoregressive hidden Markov models for speech signals"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The signal modeling methodology is discussed and experimental results on speaker independent recognition of isolated digits are given and the potential use of the modeling technique for other applications are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14789841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4775e2f0d27e8be4aae7b5b5c2560b96ce2eb58",
            "isKey": false,
            "numCitedBy": 1403,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech recognition is formulated as a problem of maximum likelihood decoding. This formulation requires statistical models of the speech production process. In this paper, we describe a number of statistical models for use in speech recognition. We give special attention to determining the parameters for such models from sparse data. We also describe two decoding methods, one appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks. To illustrate the usefulness of the methods described, we review a number of decoding results that have been obtained with them."
            },
            "slug": "A-Maximum-Likelihood-Approach-to-Continuous-Speech-Bahl-Jelinek",
            "title": {
                "fragments": [],
                "text": "A Maximum Likelihood Approach to Continuous Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper describes a number of statistical models for use in speech recognition, with special attention to determining the parameters for such models from sparse data, and describes two decoding methods appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153903288"
                        ],
                        "name": "C. Lin",
                        "slug": "C.-Lin",
                        "structuredName": {
                            "firstName": "Chih",
                            "lastName": "Lin",
                            "middleNames": [
                                "Heng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5216458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8334e18eff5e0420982a1f09838e77175d370e1",
            "isKey": false,
            "numCitedBy": 317,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "For a speech-recognition system based on continuous-density hidden Markov models (CDHMM), speaker adaptation of the parameters of CDHMM is formulated as a Bayesian learning procedure. A speaker adaptation procedure which is easily integrated into the segmental k-means training procedure for obtaining adaptive estimates of the CDHMM parameters is presented. Some results for adapting both the mean and the diagonal covariance matrix of the Gaussian state observation densities of a CDHMM are reported. The results from tests on a 39-word English alpha-digit vocabulary in isolated word mode indicate that the speaker adaptation procedure achieves the same level of performance as that of a speaker-independent system, when one training token from each word is used to perform speaker adaptation. It shows that much better performance is achieved when two or more training tokens are used for speaker adaptation. When compared with the speaker-dependent system, it is found that the performance of speaker adaptation is always equal to or better than that of speaker-dependent training using the same amount of training data. >"
            },
            "slug": "A-study-on-speaker-adaptation-of-the-parameters-of-Lee-Lin",
            "title": {
                "fragments": [],
                "text": "A study on speaker adaptation of the parameters of continuous density hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A speaker adaptation procedure which is easily integrated into the segmental k-means training procedure for obtaining adaptive estimates of the CDHMM parameters is presented and shows that much better performance is achieved when two or more training tokens are used for speaker adaptation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759928"
                        ],
                        "name": "A. Ljolje",
                        "slug": "A.-Ljolje",
                        "structuredName": {
                            "firstName": "Andrej",
                            "lastName": "Ljolje",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ljolje"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787242"
                        ],
                        "name": "Y. Ephraim",
                        "slug": "Y.-Ephraim",
                        "structuredName": {
                            "firstName": "Yariv",
                            "lastName": "Ephraim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Ephraim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62187594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ae26228becab97c316fbfc87ad9e9dbc4947223",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach for designing a set of acoustic models for speech recognition applications which results in a minimal empirical error rate for a given decoder and training data is studied. In an evaluation of the system for an isolated word recognition task, hidden Markov models (HMMs) are used to characterize the probability density functions of the acoustic signals from the different words in the vocabulary. Decoding is performed by applying the maximum aposteriori decision rule to the acoustic models. The HMMs are estimated by minimizing a differentiable cost function, which approximates the empirical error rate function, using the steepest descent method. The HMMs designed by the minimum empirical error rate approach were used in multispeaker recognition of the English E-set words and compared to models designed by the standard maximum-likelihood estimation approach. The approach increased recognition accuracy from 68.2% to 76.2% on the training set and from 53.4% to 56.4% on an independent set of test data.<<ETX>>"
            },
            "slug": "Estimation-of-hidden-Markov-model-parameters-by-Ljolje-Ephraim",
            "title": {
                "fragments": [],
                "text": "Estimation of hidden Markov model parameters by minimizing empirical error rate"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An approach for designing a set of acoustic models for speech recognition applications which results in a minimal empirical error rate for a given decoder and training data is studied and hidden Markov models are used to characterize the probability density functions of the acoustic signals from the different words in the vocabulary."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2606242"
                        ],
                        "name": "E. Bocchieri",
                        "slug": "E.-Bocchieri",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Bocchieri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bocchieri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862682"
                        ],
                        "name": "G. Doddington",
                        "slug": "G.-Doddington",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Doddington",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Doddington"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One proposed method of handling this problem is to perform a principal-component analysis on the joint feature set before hidden Markov modeling is performed ( Bocchieri and Doddington 1986 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5352307,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "a149b34bff3820c6110d4bc721c2417f7513b570",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of current speaker independent speech recognition technology is limited by the inadequacy of the measures of the speech data to discriminate between different speech sounds. In particular, two critical assumptions that underlie and limit most current recognition techniques are that: 1) speech data from different frames are statistically independent (e.g., there are no between-frame interactions); and 2) speech data statistics are independent of phonetic events (e.g., distance measures are fixed and independent of input or reference speech). In the context of speaker independent isolated digit recognition, improved recognition performance is demonstrated by: 1) explicitly modeling the correlation between spectral measurements of adjacent frames; and 2) using a distance measure which is a function of the recognition reference frame being used. A statistical model was created from a 2464 token database (2 tokens of each of 11 words \"zero\" through \"nine\" and \"oh\") for 112 speakers. Primary features include energy and filter bank amplitudes. Interspeaker variability was estimated by time aligning all training tokens and creating an ensemble of 224 feature vectors for each reference frame. Normal distributions were then estimated individually for each frame jointly with its neighbors. Testing was performed on a multidialect database of 2486 spoken digit tokens collected from 113 (different) speakers using maximum-likelihood decision methods. The substitution rate dropped from 1.7 to 1.4 percent with incorporation of between-frame statistics, and further to 0.6 percent with incorporation of frame-specific statistics in the likelihood model."
            },
            "slug": "Frame-specific-statistical-features-for-speaker-Bocchieri-Doddington",
            "title": {
                "fragments": [],
                "text": "Frame-specific statistical features for speaker independent speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Improved recognition performance is demonstrated by explicitly modeling the correlation between spectral measurements of adjacent frames; and using a distance measure which is a function of the recognition reference frame being used."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8461145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a529e0a5a796001e466ddf305b7c66abef90ce41",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives a unified theoretical view of the Dynamic Time Warping (DTW) and the Hidden Markov Model (HMM) techniques for speech recognition problems. The application of hidden Markov models in speech recognition is discussed. We show that the conventional dynamic time-warping algorithm with Linear Predictive (LP) signal modeling and distortion measurements can be formulated in a strictly statistical framework. It is further shown that the DTW/LP method is implicitly associated with a specific class of Markov models and is equivalent to the probability maximization procedures for Gaussian autoregressive multivariate probabilistic functions of the underlying Markov model. This unified view offers insights into the effectiveness of the probabilistic models in speech recognition applications."
            },
            "slug": "On-the-hidden-Markov-model-and-dynamic-time-warping-Juang",
            "title": {
                "fragments": [],
                "text": "On the hidden Markov model and dynamic time warping for speech recognition \u2014 A unified view"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A unified theoretical view of the Dynamic Time Warping (DTW) and the Hidden Markov Model (HMM) techniques for speech recognition problems is given and offers insights into the effectiveness of the probabilistic models in speech recognition applications."
            },
            "venue": {
                "fragments": [],
                "text": "AT&T Bell Laboratories Technical Journal"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38697325,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "22b6737a38179c01444d69443e327850c9956c15",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Most current attempts at automatic speech recognition are formulated in an artificial intelligence framework. In this paper we approach the problem from an information-theoretic point of view. We describe the overall structure of a linguistic statistical decoder (LSD) for the recognition of continuous speech. The input to the decoder is a string of phonetic symbols estimated by an acoustic processor (AP). For each phonetic string, the decoder finds the most likely input sentence. The decoder consists of four major subparts: 1) a statistical model of the language being recognized; 2) a phonemic dictionary and statistical phonological rules characterizing the speaker; 3) a phonetic matching algorithm that computes the similarity between phonetic strings, using the performance characteristics of the AP; 4) a word level search control. The details of each of the subparts and their interaction during the decoding process are discussed."
            },
            "slug": "Design-of-a-linguistic-statistical-decoder-for-the-Jelinek-Bahl",
            "title": {
                "fragments": [],
                "text": "Design of a linguistic statistical decoder for the recognition of continuous speech"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper describes the overall structure of a linguistic statistical decoder (LSD) for the recognition of continuous speech and describes a phonetic matching algorithm that computes the similarity between phonetic strings, using the performance characteristics of the AP."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154317"
                        ],
                        "name": "J. Wilpon",
                        "slug": "J.-Wilpon",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Wilpon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilpon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Successful application of the modelclustering algorithms to the speech-recognition problem, using the straightforward ML criterion, has been reported ( Rabiner, Lee, Juang, and Wilpon 1989 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rabiner, Wilpon, and Soong 1989 ), the DARPA Re- Although hidden Markov modeling has sig-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62346091,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "793321bd893efe16c949f5f9544b44b6a4381514",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe an HMM (hidden Markov model) clustering procedure and discuss its application to connected-word systems and to large-vocabulary recognition based on phonelike units. It is shown that the conventional approach of maximizing likelihood is easily implemented but does not work well in practice, as it tends to give improved models of tokens for which the initial model was generally quite good, but does not improve tokens which are poorly represented by the initial model. The authors have developed a splitting procedure which initializes each new cluster (statistical model) by splitting off all tokens in the training set which were poorly represented by the current set of models. This procedure is highly efficient and gives excellent recognition performance in connected-word tasks. In particular, for speaker-independent connected-digit recognition, using two HMM-clustered models, the recognition performance is as good as or better than previous results using 4-6 models/digit obtained from template-based clustering.<<ETX>>"
            },
            "slug": "HMM-clustering-for-connected-word-recognition-Rabiner-Lee",
            "title": {
                "fragments": [],
                "text": "HMM clustering for connected word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The authors have developed a splitting procedure which initializes each new cluster (statistical model) by splitting off all tokens in the training set which were poorly represented by the current set of models, which gives excellent recognition performance in connected-word tasks."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2687013"
                        ],
                        "name": "A. Derouault",
                        "slug": "A.-Derouault",
                        "structuredName": {
                            "firstName": "Anne-Marie",
                            "lastName": "Derouault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Derouault"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60878014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1be23f406a1ee7b6a45b7f98be17e7f562bdd48b",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "One approach to large vocabulary speech recognition, is to build phonetic Markov models, and to concatenate them to obtain word models. In previous work, we already designed a recognizer based on 40 phonetic Markov machines, which accepts a 10,000 words vocabulary ([3]), and recently 200,000 words vocabulary ([5]). Since there is one machine per phoneme, these models obviously do not account for coarticulatory effects, which may lead to recognition errors. In this paper, we improve the phonetic models by using general principles about coarticulation effects on automatic phoneme recognition. We show that both the analysis of the errors made by the recognizer, and linguistic facts about phonetic context influence, suggest a method for choosing context dependent models. This method allows to limit the growing of the number of phonems, and still account for the most important coarticulation effects. We present our experiments with a system applying these principles to a set of models for French. With this new system including context-dependant machines, the phoneme recognition rate goes from 82.2% to 85.3%, and the error rate on words with a 10,000 word dictionary, is decreased from 11.2 to 9.8%."
            },
            "slug": "Context-dependent-phonetic-Markov-models-for-large-Derouault",
            "title": {
                "fragments": [],
                "text": "Context-dependent phonetic Markov models for large vocabulary speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that both the analysis of the errors made by the recognizer, and linguistic facts about phonetic context influence, suggest a method for choosing context dependent models, which allows to limit the growing of the number of phonems, and still account for the most important coarticulation effects."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2727234"
                        ],
                        "name": "Y. Chow",
                        "slug": "Y.-Chow",
                        "structuredName": {
                            "firstName": "Yen-lu",
                            "lastName": "Chow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1941347"
                        ],
                        "name": "M. O. Dunham",
                        "slug": "M.-O.-Dunham",
                        "structuredName": {
                            "firstName": "Mari",
                            "lastName": "Dunham",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. O. Dunham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3353221"
                        ],
                        "name": "O. Kimball",
                        "slug": "O.-Kimball",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Kimball",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kimball"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4953636"
                        ],
                        "name": "M. Krasner",
                        "slug": "M.-Krasner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Krasner",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krasner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084322707"
                        ],
                        "name": "G. Kubala",
                        "slug": "G.-Kubala",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Kubala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kubala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48258694"
                        ],
                        "name": "P. Price",
                        "slug": "P.-Price",
                        "structuredName": {
                            "firstName": "Patti",
                            "lastName": "Price",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Price"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46924970"
                        ],
                        "name": "Salim Roukos",
                        "slug": "Salim-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salim Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152901373"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "Evan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61608679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8fe93d3e5205a450fdd8a9fb94cea0ab73b067f",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe BYBLOS, the BBN continuous speech recognition system. The system, designed for large vocabulary applications, integrates acoustic, phonetic, lexical, and linguistic knowledge sources to achieve high recognition performance. The basic approach, as described in previous papers [1, 2], makes extensive use of robust context-dependent models of phonetic coarticulation using Hidden Markov Models (HMM). We describe the components of the BYBLOS system, including: signal processing frontend, dictionary, phonetic model training system, word model generator, grammar and decoder. In recognition experiments, we demonstrate consistently high word recognition performance on continuous speech across: speakers, task domains, and grammars of varying complexity. In speaker-dependent mode, where 15 minutes of speech is required for training to a speaker, 98.5% word accuracy has been achieved in continuous speech for a 350-word task, using grammars with perplexity ranging from 30 to 60. With only 15 seconds of training speech we demonstrate performance of 97% using a grammar."
            },
            "slug": "BYBLOS:-The-BBN-continuous-speech-recognition-Chow-Dunham",
            "title": {
                "fragments": [],
                "text": "BYBLOS: The BBN continuous speech recognition system"
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154317"
                        ],
                        "name": "J. Wilpon",
                        "slug": "J.-Wilpon",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Wilpon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilpon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705574"
                        ],
                        "name": "F. Soong",
                        "slug": "F.-Soong",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Soong",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Soong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43507125,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "5815d252012f952bd5b654441ee84289ce676bb6",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors use an enhanced analysis feature set consisting of both instantaneous and transitional spectral information and test the hidden-Markov-model (HMM)-based connected-digit recognizer in speaker-trained, multispeaker, and speaker-independent modes. For the evaluation, both a 50-talker connected-digit database recorded over local, dialed-up telephone lines, and the Texas Instruments, 225-adult-talker, connected-digits database are used. Using these databases, the performance achieved was 0.35, 1.65, and 1.75% string error rates for known-length strings, for speaker-trained, multispeaker, and speaker-independent modes, respectively, and 0.78, 2.85, and 2.94% string error rates for unknown-length strings of up to seven digits in length for the three modes. Several experiments were carried out to determine the best set of conditions (e.g., training, recognition, parameters, etc.) for recognition of digits. The results and the interpretation of these experiments are described. >"
            },
            "slug": "High-performance-connected-digit-recognition-using-Rabiner-Wilpon",
            "title": {
                "fragments": [],
                "text": "High performance connected digit recognition using hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "An enhanced analysis feature set consisting of both instantaneous and transitional spectral information is used and the hidden-Markov-model (HMM)-based connected-digit recognizer in speaker-trained, multispeaker, and speaker-independent modes is tested."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154317"
                        ],
                        "name": "J. Wilpon",
                        "slug": "J.-Wilpon",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Wilpon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilpon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1874483,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "8f6ce3c64c24e0f7e3ad8f104e38a7a8190a2e87",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we extend the interpretation of distortion measures, based upon the observation that measurements of speech spectral envelopes (as normally obtained from analysis procedures) are prone to statistical variations due to window position fluctuations, excitation interference, measurement noise, etc. and may possess spurious characteristics because of analysis model constraints. We have found that these undesirable spectral measurement variations can be controlled (i.e. reduced in the level of variation) through proper cepstral processing and that a statistical model can be established to predict the variances of the cepstral coefficient measurements. The findings lead to the use of a bandpass \"liftering\" process aimed at reducing the variability of the statistical components of spectral measurements. We have applied this liftering process to various speech recognition problems; in particular, vowel recognition and isolated word recognition. With the liftering process, we have been able to achieve an average digit error rate of 1%, which is about half of the previously reported best results, with dynamic time warping in a speaker-independent isolated digit test."
            },
            "slug": "On-the-use-of-bandpass-liftering-in-speech-Juang-Rabiner",
            "title": {
                "fragments": [],
                "text": "On the use of bandpass liftering in speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper has found that a bandpass \"liftering\" process reduces the variability of the statistical components of LPC-based spectral measurements and hence it is desirable to use such a liftering process in a speech recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62236094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c5c1621ed69da09ffbd7c42b363486e0c9d2565",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Discusses the problem of estimating the parameter values of hidden Markov word models for speech recognition. The authors argue that maximum-likelihood estimation of the parameters does not lead to values which maximize recognition accuracy and describe an alternative estimation procedure called corrective training which is aimed at minimizing the number of recognition errors. Corrective training is similar to a well-known error-correcting training procedure for linear classifiers and works by iteratively adjusting the parameter values so as to make correct words more probable and incorrect words less probable. There are also strong parallels between corrective training and maximum mutual information estimation. They do not prove that the corrective training algorithm converges, but experimental evidence suggests that it does, and that it leads to significantly fewer recognition errors than maximum likelihood estimation.<<ETX>>"
            },
            "slug": "A-new-algorithm-for-the-estimation-of-hidden-Markov-Bahl-Brown",
            "title": {
                "fragments": [],
                "text": "A new algorithm for the estimation of hidden Markov model parameters"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The authors argue that maximum-likelihood estimation of the parameters does not lead to values which maximize recognition accuracy and describe an alternative estimation procedure called corrective training which is aimed at minimizing the number of recognition errors."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762024"
                        ],
                        "name": "R. Bakis",
                        "slug": "R.-Bakis",
                        "structuredName": {
                            "firstName": "Raimo",
                            "lastName": "Bakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bakis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 100
                            }
                        ],
                        "text": "For modeling isolated utterances (i.e., whole words or phrases), we often use left-to-right models (Bakis 1976; Rabiner et al. 1983) of the type shown in Figure 7a, since the utterance begins and ends at well-identified time instants (except in the case of very noisy or corrupted speech) and the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 119929465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8291be2289154cf1dcd5a4009222c1899533e253",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Continuous speech was treated as if produced by a finite\u2010state machine making a transition every centisecond. The observable output from state transitions was considered to be a power spectrum\u2014a probabilistic function of the target state of each transition. Using this model, observed sequences of power spectra from real speech were decoded as sequences of acoustic states by means of the Viterbi trellis algorithm. The finite\u2010state machine used as a representation of the speech source was composed of machines representing words, combined according to a \u201clanguage model.\u201d When trained to the voice of a particular speaker, the decoder recognized seven\u2010digit telephone numbers correctly 96% of the time, with a better than 99% per\u2010digit accuracy. Results for other tests of the system, including syllable and phoneme recognition, will also be given."
            },
            "slug": "Continuous-speech-recognition-via-centisecond-Bakis",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition via centisecond acoustic states"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "When trained to the voice of a particular speaker, the decoder recognized seven\u2010digit telephone numbers correctly 96% of the time, with a better than 99% per\u2010digit accuracy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705574"
                        ],
                        "name": "F. Soong",
                        "slug": "F.-Soong",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Soong",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Soong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145778742"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Juang",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 64
                            }
                        ],
                        "text": "of many of the subword unit-based speech-recognition algorithms (Lee, Juang, Soong, and Rabiner 1989; Lee et al. 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 130
                            }
                        ],
                        "text": "This principle is the basis of many of the subword unit-based speech-recognition algorithms (Lee, Juang, Soong, and Rabiner 1989; Lee et al. 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60557738,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "a4786a9eaaa563c4b343cb0c9dd554e1d1a52578",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Proposes a global acoustic segment model for characterizing fundamental speech sound units and their interactions based upon a general framework of hidden Markov models (HMM). Each segment model represents a class of acoustically similar sounds. The intra-segment variability of each sound class is modeled by an HMM, and the sound-to-sound transition rules are characterized by a probabilistic intersegment transition matrix. An acoustically-derived lexicon is used to construct word models based upon subword segment models. The proposed segment model was tested on a speaker-trained, isolated word, speech recognition task with a vocabulary of 1109 basic English words. In the current study, only 128 segment models were used, and recognition was performed by optimally aligning the test utterance with all acoustic lexicon entries using a maximum likelihood Viterbi decoding algorithm. Based upon a database of three male speakers, the average word recognition accuracy for the top candidate was 85% and increased to 96% and 98% for the top 3 and top 5 candidates, respectively.<<ETX>>"
            },
            "slug": "A-segment-model-based-approach-to-speech-Lee-Soong",
            "title": {
                "fragments": [],
                "text": "A segment model based approach to speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The proposed segment model was tested on a speaker-trained, isolated word, speech recognition task with a vocabulary of 1109 basic English words and the average word recognition accuracy was 85% and increased to 96% and 98% for the top 3 and top 5 candidates, respectively."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387789571"
                        ],
                        "name": "Vishwa Gupta",
                        "slug": "Vishwa-Gupta",
                        "structuredName": {
                            "firstName": "Vishwa",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vishwa Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2959613"
                        ],
                        "name": "Matthew Lennig",
                        "slug": "Matthew-Lennig",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Lennig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Lennig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143791674"
                        ],
                        "name": "P. Mermelstein",
                        "slug": "P.-Mermelstein",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Mermelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mermelstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60513366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcc924f8e4cbd36ef2b244dce20fdf3893e256a1",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new way of using vector quantization for improving recognition performance for a 60,000 word vocabulary speaker-trained isolated word recognizer using a phonemic Markov model approach to speech recognition. We show that we can effectively increase the codebook size by dividing the feature vector into two vectors of lower dimensionality, and then quantizing and training each vector separately. For a small codebook size, integration of the results of the two parameter vectors provides significant improvement in recognition performance as compared to the quantizing and training of the entire feature set together. Even for a codebook size as small as 64, the results obtained when using the new quantization procedure are quite close to those obtained when using Gaussian distribution of the parameter vectors."
            },
            "slug": "Integration-of-acoustic-information-in-a-large-word-Gupta-Lennig",
            "title": {
                "fragments": [],
                "text": "Integration of acoustic information in a large vocabulary word recognizer"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A new way of using vector quantization for improving recognition performance for a 60,000 word vocabulary speaker-trained isolated word recognizer using a phonemic Markov model approach to speech recognition is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61001580,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "4062986d268d936d714c3c7580d3d6ec19e3c3fc",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an experimental continuous speech recognition system comprising procedures for acoustic/phonetic classification, lexical access and sentence retrieval. Speech is assumed to be composed of a small number of phonetic units which may be identified with the states of a hidden Markov model. The acoustic correlates of the phonetic units are then characterized by the observable Gaussian process associated with the corresponding state of the underlying Markov chain. Once the parameters of such a model are determined, a phonetic transcription of an utterance can be obtained by means of a Viterbi-like algorithm. Given a lexicon in which each entry is orthographically represented in terms of the chosen phonetic units, a word lattice is produced by a lexical access procedure. Lexical items whose orthography matches subsequences of the phonetic transcription are sought by means of a hash coding technique and their likelihoods are computed directly from the corresponding interval of acoustic measurements. The recognition process is completed by recovering from the word lattice, the string of words of maximum likelihood conditioned on the measurements. The desired string is derived by a best-first search algorithm. In an experimental evaluation of the system, the parameters of an acoustic/phonetic model were estimated from fluent utterances of 37 seven-digit numbers. A digit recognition rate of 96% was then observed on an independent test set of 59 utterances of the same form from the same speaker. Half of the observed errors resulted from insertions while deletions and substitutions accounted equally for the other half."
            },
            "slug": "Continuous-speech-recognition-by-means-of-acoustic/-Levinson",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition by means of acoustic/ Phonetic classification obtained from a hidden Markov model"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An experimental continuous speech recognition system comprising procedures for acoustic/phonetic classification, lexical access and sentence retrieval and an experimental evaluation of the system, the parameters of an acoustic/Phonetic model were estimated from fluent utterances of 37 seven-digit numbers."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787242"
                        ],
                        "name": "Y. Ephraim",
                        "slug": "Y.-Ephraim",
                        "structuredName": {
                            "firstName": "Yariv",
                            "lastName": "Ephraim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Ephraim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 128
                            }
                        ],
                        "text": "The MDI modeling criterion carries some information-theoretic justification and can be related to the MMI approach (Ephraim and Rabiner 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60641069,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4b774b3958da214ad79c2402c9f239ba24cdecb",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors examine the relations between maximum likelihood (ML), maximum mutual information (MMI), and minimum discrimination information (MDI) modeling approaches, which have been applied to estimating acoustic word models in speech recognition systems. The show that all three approaches can be uniformly formulated as MDI modeling approaches for estimating the acoustic models for all words simultaneously. The three approaches differ in either the probability distribution (PD) attributed to the source being modeled or in the model effectively being used. None of the approaches, however, assumes model correctness, i.e., that the source has the PD of the model. A new modeling approach is proposed, which, in contrast with the other approaches considered, directly aims at the minimization of the probability of error.<<ETX>>"
            },
            "slug": "On-the-relations-between-modeling-approaches-for-Ephraim-Rabiner",
            "title": {
                "fragments": [],
                "text": "On the relations between modeling approaches for information sources (speech recognition)"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The authors examine the relations between maximum likelihood, maximum mutual information (MMI), and minimum discrimination information (MDI) modeling approaches, which have been applied to estimating acoustic word models in speech recognition systems and show that all three approaches can be uniformly formulated as MDI modeling approaches for estimating the acoustic models for all words simultaneously."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705574"
                        ],
                        "name": "F. Soong",
                        "slug": "F.-Soong",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Soong",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Soong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61168011,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "c1638689890e1107ddf942ffa9f6a25d11e5d16c",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of how to select and construct a set of fundamental unit statistical models suitable for speech recognition is addressed. A unified framework is discussed which can be used to accomplish the goal of creating effective basic models of speech. The performances of three types of fundamental units, namely whole word, phoneme-like, and acoustic segment units, in a 1109-word vocabulary speech recognition task are compared. The authors point out the relative advantages of each type of speech unit based on the results of a series of recognition experiments.<<ETX>>"
            },
            "slug": "Word-recognition-using-whole-word-and-subword-Lee-Juang",
            "title": {
                "fragments": [],
                "text": "Word recognition using whole word and subword models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A unified framework is discussed which can be used to accomplish the goal of creating effective basic models of speech and points out the relative advantages of each type of speech unit based on the results of a series of recognition experiments."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144990248"
                        ],
                        "name": "R. Lippmann",
                        "slug": "R.-Lippmann",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lippmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lippmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145048087"
                        ],
                        "name": "E. A. Martin",
                        "slug": "E.-A.-Martin",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Martin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. A. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61524006,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d0bd9a450359e05bd43234a0c3f3cc08ce183fc2",
            "isKey": false,
            "numCitedBy": 338,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A new training procedure called multi-style training has been developed to improve performance when a recognizer is used under stress or in high noise but cannot be trained in these conditions. Instead of speaking normally during training, talkers use different, easily produced, talking styles. This technique was tested using a speech data base that included stress speech produced during a workload task and when intense noise was presented through earphones. A continuous-distribution talker-dependent Hidden Markov Model (HMM) recognizer was trained both normally (5 normally spoken tokens) and with multi-style training (one token each from normal, fast, clear, loud, and question-pitch talking styles). The average error rate under stress and normal conditions fell by more than a factor of two with multi-style training and the average error rate under conditions sampled during training fell by a factor of four."
            },
            "slug": "Multi-style-training-for-robust-isolated-word-Lippmann-Martin",
            "title": {
                "fragments": [],
                "text": "Multi-style training for robust isolated-word speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A new training procedure called multi-style training has been developed to improve performance when a recognizer is used under stress or in high noise but cannot be trained in these conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150023694"
                        ],
                        "name": "A. N\u00e1das",
                        "slug": "A.-N\u00e1das",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "N\u00e1das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. N\u00e1das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713978"
                        ],
                        "name": "D. Nahamoo",
                        "slug": "D.-Nahamoo",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Nahamoo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nahamoo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774515"
                        ],
                        "name": "M. Picheny",
                        "slug": "M.-Picheny",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Picheny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Picheny"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 82
                            }
                        ],
                        "text": "A detailed account of the issues involved in the complete-label case was given by Nadas, Nahamoo, and Picheny (1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The effect of conditional ML estimation in terms of class prior robustness-that is, uncertain or incorrect Pr,(C,)-can best be illustrated by the following example from  Nadas et al. (1988) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A detailed account of the issues involved in the complete-label case was given by  Nadas, Nahamoo, and Picheny (1988) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Assume that the prior Pr:(C,) = Pr,,(C,) is given or obtained independent of the spoken training set {Ool}, where 0'') are the portion of the training data that are labeled as C,. For this case,  Nadas et al. (1988)  proposed the use of a slightly different training measure-namely, the conditional maximum likelihood estimator,"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 169
                            }
                        ],
                        "text": "The effect of conditional ML estimation in terms of class prior robustness-that is, uncertain or incorrect Pr,(C,)-can best be illustrated by the following example from Nadas et al. (1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 15
                            }
                        ],
                        "text": "For this case, Nadas et al. (1988) proposed the use of a slightly different training measure-namely, the conditional maximum likelihood estimator, TECHNOMETRICS, AUGUST 1991, VOL. 33, NO. 3 (CMLE) obtained by A: , , , = arg max nPr ,(C, / O('j)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33275295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "039900eaeeddd13752aa8d6c61759f0b0e54f0de",
            "isKey": true,
            "numCitedBy": 95,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Training methods for designing better decoders are compared. The training problem is considered as a statistical parameter estimation problem. In particular, the conditional maximum likelihood estimate (CMLE), which estimates the parameter values that maximize the conditional probability of words given acoustics during training, is compared to the maximum-likelihood estimate, which is obtained by maximizing the joint probability of the words and acoustics. For minimizing the decoding error rate of the (optimal) maximum a posteriori probability (MAP) decoder, it is shown that the CMLE (or maximum mutual information estimate, MMIE) may be preferable when the model is incorrect. In this sense, the CMLE/MMIE appears more robust than the MLE. >"
            },
            "slug": "On-a-model-robust-training-method-for-speech-N\u00e1das-Nahamoo",
            "title": {
                "fragments": [],
                "text": "On a model-robust training method for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "For minimizing the decoding error rate of the (optimal) maximum a posteriori probability (MAP) decoder, it is shown that the CMLE (or maximum mutual information estimate, MMIE) may be preferable when the model is incorrect."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6330633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1d1ab917a3566ac8c09482a6c575b2b45809506",
            "isKey": false,
            "numCitedBy": 477,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors discuss and document a parameter estimation algorithm for data sequence modeling involving hidden Markov models. The algorithm, called the segmental K-means method, uses the state-optimized joint likelihood for the observation data and the underlying Markovian state sequence as the objective function for estimation. The authors prove the convergence of the algorithm and compare it with the traditional Baum-Welch reestimation method. They also print out the increased flexibility this algorithm offers in the general speech modeling framework. >"
            },
            "slug": "The-segmental-K-means-algorithm-for-estimating-of-Juang-Rabiner",
            "title": {
                "fragments": [],
                "text": "The segmental K-means algorithm for estimating parameters of hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "The authors discuss and document a parameter estimation algorithm for data sequence modeling involving hidden Markov models that uses the state-optimized joint likelihood for the observation data and the underlying Markovian state sequence as the objective function for estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670760"
                        ],
                        "name": "Jordan Cohen",
                        "slug": "Jordan-Cohen",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jordan Cohen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 161
                            }
                        ],
                        "text": "To emphasize spectral properties that are known to be important to a human listener, auditory models can be incorporated in the overall spectral representation (Cohen 1985; Ghitza 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120526985,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "9ff067d6b56587b32af53acf0e037d2dbbe39f3d",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "One approach to designing signal processors for speech recognition has been to model the mammalian auditory system. Most designs have not attempted to capture the time\u2010varying nature of the system, but have focused on the psychophysical aspects of critical bandwidth and loudness estimation. The IBM 5000\u2010word speech recognition system [Bahl et al., IEEE Trans. Pattern Anal. Machine Intell. PAMI\u20105, 179\u2013190 (1983)] uses an auditory model in which psychophysical critical\u2010band tuning and loudness estimation are combined with a firing\u2010rate model patterned after that of Schroeder and Hall [J. Acoust. Soc. Am. 55, 1055\u20131060 (1974)]. The signal processing system consists of a critical\u2010bandwidth filter bank, loudness estimation (intensity to the 1/3 power), and a reservoir\u2010type firing\u2010rate model with one internal state for each band. This model enhances transient events in the auditory signal, and causes rapid stimulus offsets to be marked by outputs smaller than the resting rate. The use of this auditory model in ..."
            },
            "slug": "Application-of-an-adaptive-auditory-model-to-speech-Cohen",
            "title": {
                "fragments": [],
                "text": "Application of an adaptive auditory model to speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703304"
                        ],
                        "name": "A. Averbuch",
                        "slug": "A.-Averbuch",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Averbuch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Averbuch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762024"
                        ],
                        "name": "R. Bakis",
                        "slug": "R.-Bakis",
                        "structuredName": {
                            "firstName": "Raimo",
                            "lastName": "Bakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1878312"
                        ],
                        "name": "G. Daggett",
                        "slug": "G.-Daggett",
                        "structuredName": {
                            "firstName": "Gregg",
                            "lastName": "Daggett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Daggett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144750187"
                        ],
                        "name": "S. Das",
                        "slug": "S.-Das",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48710731"
                        ],
                        "name": "K. Davies",
                        "slug": "K.-Davies",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Davies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Davies"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054592358"
                        ],
                        "name": "S. V. Gennaro",
                        "slug": "S.-V.-Gennaro",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Gennaro",
                            "middleNames": [
                                "V.",
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. V. Gennaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8138376"
                        ],
                        "name": "E. Epstein",
                        "slug": "E.-Epstein",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Epstein",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Epstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69893463"
                        ],
                        "name": "D. Fraleigh",
                        "slug": "D.-Fraleigh",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Fraleigh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fraleigh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143613831"
                        ],
                        "name": "B. Lewis",
                        "slug": "B.-Lewis",
                        "structuredName": {
                            "firstName": "Burn",
                            "lastName": "Lewis",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143754167"
                        ],
                        "name": "J. Moorhead",
                        "slug": "J.-Moorhead",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Moorhead",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Moorhead"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150023694"
                        ],
                        "name": "A. N\u00e1das",
                        "slug": "A.-N\u00e1das",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "N\u00e1das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. N\u00e1das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713978"
                        ],
                        "name": "D. Nahamoo",
                        "slug": "D.-Nahamoo",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Nahamoo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nahamoo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66648677"
                        ],
                        "name": "M. Picheny",
                        "slug": "M.-Picheny",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Picheny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Picheny"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2801588"
                        ],
                        "name": "G. Shichman",
                        "slug": "G.-Shichman",
                        "structuredName": {
                            "firstName": "Gideon",
                            "lastName": "Shichman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shichman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153068955"
                        ],
                        "name": "P. Spinelli",
                        "slug": "P.-Spinelli",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Spinelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Spinelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722640158"
                        ],
                        "name": "D. V. Compernolle",
                        "slug": "D.-V.-Compernolle",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Compernolle",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. V. Compernolle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36088321"
                        ],
                        "name": "H. Wilkens",
                        "slug": "H.-Wilkens",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Wilkens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wilkens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60970721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ae4756313dc6e8e33ab69593a6f7475025a64fd",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The Speech Recognition Group at IBM Research in Yorktown Heights has developed a real-time, isolated-utterance speech recognizer for natural language based on the IBM Personal Computer AT and IBM Signal Processors. The system has recently been enhanced by expanding the vocabulary from 5,000 words to 20,000 words and by the addition of a speech workstation to support usability studies on document creation by voice. The system supports spelling and interactive personalization to augment the vocabularies. This paper describes the implementation, user interface, and comparative performance of the recognizer."
            },
            "slug": "Experiments-with-the-Tangora-20,000-word-speech-Averbuch-Bahl",
            "title": {
                "fragments": [],
                "text": "Experiments with the Tangora 20,000 word speech recognizer"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The implementation, user interface, and comparative performance of the recognizer is described, which supports spelling and interactive personalization to augment the vocabularies."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734871"
                        ],
                        "name": "N. Merhav",
                        "slug": "N.-Merhav",
                        "structuredName": {
                            "firstName": "Neri",
                            "lastName": "Merhav",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Merhav"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787242"
                        ],
                        "name": "Y. Ephraim",
                        "slug": "Y.-Ephraim",
                        "structuredName": {
                            "firstName": "Yariv",
                            "lastName": "Ephraim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Ephraim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "interested readers should consult  Merhav and Ephraim (in press) .] The segmental k-means algorithm, however, due to the separate optimization of the components of the model parameter set, leads to a more straightforward (simpler with less computation and numerical difficulties) implementation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35864917,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "274a6f9599eaf97b635d6639994f621c287a5155",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Approximate maximum likelihood (ML) hidden Markov modeling using the most likely state sequence (MLSS) is examined and compared with the exact ML approach that considers all possible state sequences. It is shown that for any hidden Markov model (HMM), the difference between the approximate and the exact normalized likelihood functions cannot exceed the logarithm of the number of states divided by the dimension of the output vectors (frame length). Furthermore, for Gaussian HMMs and a given observation sequence, the MLSS is typically the sequence of nearest neighbor states in the Itakura-Saito sense, and the posterior probability of any state sequence which departs from the MLSS in a single time instant, decays exponentially with the frame length. Hence, for a sufficiently large frame length the exact and approximate ML approach provide similar model estimates and likelihood values. >"
            },
            "slug": "Maximum-likelihood-hidden-Markov-modeling-using-a-Merhav-Ephraim",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood hidden Markov modeling using a dominant sequence of states"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that for any hidden Markov model (HMM), the difference between the approximate and the exact normalized likelihood functions cannot exceed the logarithm of the number of states divided by the dimension of the output vectors (frame length)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3084929"
                        ],
                        "name": "B. A. Dautrich",
                        "slug": "B.-A.-Dautrich",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Dautrich",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. A. Dautrich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40569334"
                        ],
                        "name": "T. Martin",
                        "slug": "T.-Martin",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Martin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Martin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14382808,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "fe04c87dbe2c1e74d66c0107a3425cb157a9a31a",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "The vast majority of commercially available isolated word recognizers use a filter bank analysis as the front end processing for recognition. It is not well understood how the parameters of different filter banks (e.g., number of filters, types of filters, filter spacing, etc.) affect recognizer performance. In this paper we present results of performance evaluation of several types of filter bank analyzers in a speaker trained isolated word recognition test using dialed-up telephone line recordings. We have studied both DFT (discrete Fourier transform) and direct form implementations of the filter banks. We have also considered uniform and nonuniform filter spacings. The results indicate that the best performance (highest word accuracy) is obtained by both a 15-channel uniform filter bank and a 13-channel nonuniform filter bank (with channels spacing along a critical band scale). The performance of a 7-channel critical band filter bank is almost as good as that of the two best filter banks. In comparison to a conventional linear predictive coding (LPC) word recognizer, the performance of the best filter bank recognizers was, on average, several percent worse than that of an eighth-order LPC-based recognizer. A discussion as to why some filter banks performed better than others, and why the LPC-based system did the best, is given in this paper."
            },
            "slug": "On-the-effects-of-varying-filter-bank-parameters-on-Dautrich-Rabiner",
            "title": {
                "fragments": [],
                "text": "On the effects of varying filter bank parameters on isolated word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Results of performance evaluation of several types of filter bank analyzers in a speaker trained isolated word recognition test using dialed-up telephone line recordings indicate that the best performance is obtained by both a 15-channel uniform filter bank and a 13-channel nonuniform filter bank."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144531812"
                        ],
                        "name": "Xuedong Huang",
                        "slug": "Xuedong-Huang",
                        "structuredName": {
                            "firstName": "Xuedong",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuedong Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715280"
                        ],
                        "name": "M. Jack",
                        "slug": "M.-Jack",
                        "structuredName": {
                            "firstName": "Mervyn",
                            "lastName": "Jack",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jack"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 171
                            }
                        ],
                        "text": "\u2026of (21) can be modified to accommodate several other types of distributions, giving rise to the so-called vector quantizer HMM (Rabiner et al. 1983), semicontinuous HMM (Huang and Jack 1989), or continuous HMM (Bahl, Brown, de Souza, and Mercer 1988b; Poritz and Richter 1986; Rabiner et al. 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118779259,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee90bfa64cea003aa1b0669e2a960f846f931b86",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A semicontinuous hidden Markov model (HMM), which can be considered as a special form of continuous-mixture HMM with the continuous output probability density functions sharing in a mixture Gaussian density codebook, is proposed. The semicontinuous output probability density function is represented by a combination of the discrete output probabilities of the model and the continuous Gaussian density functions of a mixture Gaussian density codebook. The amount of training data required, as well as the computational complexity of the semicontinuous HMM, can be reduced in comparison to the continuous-mixture HMM. Parameters of the codebook and HMM can be mutually optimized to achieve an optimal model/codebook combination, which leads to a unified modeling approach to vector quantization and hidden Markov modeling of speech signals. Experimental results are included which show that the recognition accuracy of the semicontinuous HMM is measurably higher than those of both the discrete and the continuous HMM.<<ETX>>"
            },
            "slug": "Unified-techniques-for-vector-quantization-and-Huang-Jack",
            "title": {
                "fragments": [],
                "text": "Unified techniques for vector quantization and hidden Markov modeling using semi-continuous models"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A semicontinuous hidden Markov model is proposed, which can be considered as a special form of continuous-mixture HMM with the continuous output probability density functions sharing in a mixture Gaussian density codebook, which leads to a unified modeling approach to vector quantization andhidden Markov modeling of speech signals."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 163
                            }
                        ],
                        "text": "The much increased complication in decoding lattice often renders many search algorithms such as the beam search (Lowerre and Reddy 1980) and the stack algorithm (Jelinek 1969) for handling large problems extremely difficult to implement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31408841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32a175b36ec7f2f08cb3dfac30ce141e144ec9e9",
            "isKey": false,
            "numCitedBy": 991,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical methods useful in automatic recognition of continuous speech are described. They concern modeling of a speaker and of an acoustic processor, extraction of the models' statistical parameters and hypothesis search procedures and likelihood computations of linguistic decoding. Experimental results are presented that indicate the power of the methods."
            },
            "slug": "Continuous-speech-recognition-by-statistical-Jelinek",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition by statistical methods"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Experimental results are presented that indicate the power of the methods and concern modeling of a speaker and of an acoustic processor, extraction of the models' statistical parameters and hypothesis search procedures and likelihood computations of linguistic decoding."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680788"
                        ],
                        "name": "J. Cadzow",
                        "slug": "J.-Cadzow",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cadzow",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cadzow"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 217
                            }
                        ],
                        "text": "\u2026methods as measurement of the discrete (fast) Fourier transform (FFT), all-pole minimum-phase linear prediction (LPC) methods, and autoregressive/moving average models (Allen and Rabiner 1977; Atal and Hanauer 1971; Cadzow 1982; Makhoul 1975; Markel and Gray 1976; Schafer and Rabiner 1971)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 37
                            }
                        ],
                        "text": "autoregressive/moving average models (Allen and Rabiner 1977; Atal and Hanauer 1971; Cadzow 1982; Makhoul 1975; Markel and Gray 1976; Schafer and Rabiner 1971)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17581756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c837a624bcfea70826086e0d85318c7f0d794aa",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for efficiently generating a rational model of a wide-sense stationary time series is presented. In this method the autoregressive parameters associated with an ARMA model consisting of q zeros and p poles are optimally chosen with the selection being based on a finite set of time series observations. This selection is made so that a set of Yule-Walker equation approximations are ``best'' satisfied. The resultant autoregressive parameter estimates have the desired statistical feature of being unbiased and consistent. This estimation method has been found to provide a modeling performance which typically equals or exceeds that of contemporary alternatives. Moreover, this method is amenable to a computationally efficient adaptive solution procedure. The autoregressive parameters characterizing the resultant ARMA model estimate can serve the role of decision variables in pattern classification schemes. For example, these parameters can be utilized in determining whether or not a member(s) of a given signal class is contained within a noise corrupted measurement signal. This approach has been found to be particularly effective in Doppler radar and array processing applications in which one is looking for the presence of spectral lines (i.e., sinusoids) in the measurement signal."
            },
            "slug": "ARMA-Modeling-of-Time-Series-Cadzow",
            "title": {
                "fragments": [],
                "text": "ARMA Modeling of Time Series"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The autoregressive parameters characterizing the resultant ARMA model estimate can serve the role of decision variables in pattern classification schemes and can be utilized in determining whether or not a member(s) of a given signal class is contained within a noise corrupted measurement signal."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 19
                            }
                        ],
                        "text": "Previous attempts (Bahl et al. 1986; Brown 1987) at using the MMI criterion have not produced an estimation procedure that is guaranteed to converge to an optimal solution either."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 56128297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5f09ce0dd760857e0d0e4879f6e2543f04c5d33",
            "isKey": false,
            "numCitedBy": 926,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for estimating the parameters of hidden Markov models of speech is described. Parameter values are chosen to maximize the mutual information between an acoustic observation sequence and the corresponding word sequence. Recognition results are presented comparing this method with maximum likelihood estimation."
            },
            "slug": "Maximum-mutual-information-estimation-of-hidden-for-Bahl-Brown",
            "title": {
                "fragments": [],
                "text": "Maximum mutual information estimation of hidden Markov model parameters for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method for estimating the parameters of hidden Markov models of speech is described and recognition results are presented comparing this method with maximum likelihood estimation."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '86. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154317"
                        ],
                        "name": "J. Wilpon",
                        "slug": "J.-Wilpon",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Wilpon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilpon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71520871"
                        ],
                        "name": "B.-H. Juang",
                        "slug": "B.-H.-Juang",
                        "structuredName": {
                            "firstName": "B.-H.",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B.-H. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 196
                            }
                        ],
                        "text": "For HMM speech recognition, some trivial measures such as setting a numeric floor to prevent singularity are often found beneficial and are straightforward to implement (Lee, Lin, and Juang 1991; Rabiner et al. 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 278
                            }
                        ],
                        "text": "\u2026of (21) can be modified to accommodate several other types of distributions, giving rise to the so-called vector quantizer HMM (Rabiner et al. 1983), semicontinuous HMM (Huang and Jack 1989), or continuous HMM (Bahl, Brown, de Souza, and Mercer 1988b; Poritz and Richter 1986; Rabiner et al. 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 152
                            }
                        ],
                        "text": "Finally, esimates of Pri(di) are obtained based on the optimal state sequence ij by either the ML method or from simple frequency of occurrence counts (Rabiner et al. 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 64
                            }
                        ],
                        "text": "Although the postprocessor duration model has had some success (Rabiner et al. 1986) , the questions of optimality of the estimate, robustness of the solution, and other criteria for successful use of duration information, especially as applied to speech recognition, remain unanswered."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37344085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff07698f776f27878fa904f7f51220e1cdf0b744",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms for recognizing strings of connected words from whole-word patterns have become highly efficient and accurate, although computation rates remain high. Even the most ambitious connected-word recognition task is practical with today's integrated circuit technology, but extracting reliable, robust whole-word reference patterns still is difficult. In the past, connected-word recognizers relied on isolated-word reference patterns or patterns derived from a limited context (e.g., the middle digit from strings of three digits). These whole-word patterns were adequate for slow rates of articulated speech, but not for strings of words spoken at high rates (e.g., about 200 to 300 words per minute). To alleviate this difficulty, a segmental k-means training procedure was used to extract whole-word patterns from naturally spoken word strings. The segmented words are then used to create a set of word reference patterns for recognition. Recognition string accuracies were 98 to 99 percent for digits in variable length strings and 90 to 98 percent for sentences from an airline reservation task. These performance scores represent significant improvements over previous connected-word recognizers."
            },
            "slug": "A-segmental-k-means-training-procedure-for-word-Rabiner-Wilpon",
            "title": {
                "fragments": [],
                "text": "A segmental k-means training procedure for connected word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A segmental k-means training procedure was used to extract whole-word patterns from naturally spoken word strings to create a set of word reference patterns for recognition, and recognition string accuracies were significant improvements over previous connected-word recognizers."
            },
            "venue": {
                "fragments": [],
                "text": "AT&T Technical Journal"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7271498,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "d5485cadbea58548700bbd8033c509b3164e6574",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "It has recently been shown that small but consistent improvements in isolated word recognition accuracy can be obtained by supplementing the Linear Predictive Coding (LPC) features for each frame of a word by a normalized energy value for that frame. The key idea in using energy is to normalize the frame energy by the local energy maximum in time (i.e., relative to the peak energy of the spoken word). If we want to extend the concept of using frame energy as a supplement to the LPC feature set for connected word recognition, we must provide a dynamic method of energy normalization so that the peak energy within strings can closely approximate the energy contours of individual words strung together. In this paper such a dynamic energy normalization is proposed, and it is shown to provide improvements in connected word recognition applications. The normalization consists of determining a continuous peak energy contour for the speech, where the peak energy is determined over periods of time essentially corresponding to a syllable, and then modifying the actual energy contour with the peak energy contour so that absolute energy maxima occur about once per syllable. In this manner, the dynamically normalized, temporal energy contour of the word string effectively provides a set of temporal markers of high-energy events (content words) that aid the recognition of connected word sequences."
            },
            "slug": "On-the-application-of-energy-contours-to-the-of-Rabiner",
            "title": {
                "fragments": [],
                "text": "On the application of energy contours to the recognition of connected word sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The dynamically normalized, temporal energy contour of the word string effectively provides a set of temporal markers of high-energy events (content words) that aid the recognition of connected word sequences."
            },
            "venue": {
                "fragments": [],
                "text": "AT&T Bell Laboratories Technical Journal"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787242"
                        ],
                        "name": "Y. Ephraim",
                        "slug": "Y.-Ephraim",
                        "structuredName": {
                            "firstName": "Yariv",
                            "lastName": "Ephraim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Ephraim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768934"
                        ],
                        "name": "A. Dembo",
                        "slug": "A.-Dembo",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Dembo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dembo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1312345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78e136491e9203b7dd8dfb26256ce2c997ad8e50",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A new iterative approach for hidden Markov modeling of information sources which aims at minimizing the discrimination information (or the cross-entropy) between the source and the model is proposed. This approach does not require the commonly used assumption that the source to be modeled is a hidden Markov process. The algorithm is started from the model estimated by the traditional maximum likelihood (ML) approach and alternatively decreases the discrimination information over all probability distributions of the source which agree with the given measurements and all hidden Markov models. The proposed procedure generalizes the Baum algorithm for ML hidden Markov modeling. The procedure is shown to be a descent algorithm for the discrimination information measure and its local convergence is proved."
            },
            "slug": "A-minimum-discrimination-information-approach-for-Ephraim-Dembo",
            "title": {
                "fragments": [],
                "text": "A minimum discrimination information approach for hidden Markov modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A new iterative approach for hidden Markov modeling of information sources which aims at minimizing the discrimination information (or the cross-entropy) between the source and the model is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 230
                            }
                        ],
                        "text": "\u2026methods as measurement of the discrete (fast) Fourier transform (FFT), all-pole minimum-phase linear prediction (LPC) methods, and autoregressive/moving average models (Allen and Rabiner 1977; Atal and Hanauer 1971; Cadzow 1982; Makhoul 1975; Markel and Gray 1976; Schafer and Rabiner 1971)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 37
                            }
                        ],
                        "text": "autoregressive/moving average models (Allen and Rabiner 1977; Atal and Hanauer 1971; Cadzow 1982; Makhoul 1975; Markel and Gray 1976; Schafer and Rabiner 1971)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36366900,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "17423cc37eee7423423c03624f4a637b191eb998",
            "isKey": false,
            "numCitedBy": 4120,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives an exposition of linear prediction in the analysis of discrete signals. The signal is modeled as a linear combination of its past values and present and past values of a hypothetical input to a system whose output is the given signal. In the frequency domain, this is equivalent to modeling the signal spectrum by a pole-zero spectrum. The major part of the paper is devoted to all-pole models. The model parameters are obtained by a least squares analysis in the time domain. Two methods result, depending on whether the signal is assumed to be stationary or nonstationary. The same results are then derived in the frequency domain. The resulting spectral matching formulation allows for the modeling of selected portions of a spectrum, for arbitrary spectral shaping in the frequency domain, and for the modeling of continuous as well as discrete spectra. This also leads to a discussion of the advantages and disadvantages of the least squares error criterion. A spectral interpretation is given to the normalized minimum prediction error. Applications of the normalized error are given, including the determination of an \"optimal\" number of poles. The use of linear prediction in data compression is reviewed. For purposes of transmission, particular attention is given to the quantization and encoding of the reflection (or partial correlation) coefficients. Finally, a brief introduction to pole-zero modeling is given."
            },
            "slug": "Linear-prediction:-A-tutorial-review-Makhoul",
            "title": {
                "fragments": [],
                "text": "Linear prediction: A tutorial review"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This paper gives an exposition of linear prediction in the analysis of discrete signals as a linear combination of its past values and present and past values of a hypothetical input to a system whose output is the given signal."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2222107"
                        ],
                        "name": "O. Ghitza",
                        "slug": "O.-Ghitza",
                        "structuredName": {
                            "firstName": "Oded",
                            "lastName": "Ghitza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Ghitza"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58264426,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0bb094d7dfb2d04315a65c25372b95be1ac2480f",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Auditory-nerve-representation-as-a-front-end-for-in-Ghitza",
            "title": {
                "fragments": [],
                "text": "Auditory nerve representation as a front-end for speech recognition in a noisy environment"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49626392"
                        ],
                        "name": "W. Lea",
                        "slug": "W.-Lea",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Lea",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2605614"
                        ],
                        "name": "M. Medress",
                        "slug": "M.-Medress",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Medress",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Medress"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144701129"
                        ],
                        "name": "T. Skinner",
                        "slug": "T.-Skinner",
                        "structuredName": {
                            "firstName": "Toby",
                            "lastName": "Skinner",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Skinner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60413458,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "9a3500c77698701301dde8ebc999abd61e08e1e6",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : A strategy is outlined for acoustic aspects of speech recognition, whereby prosodic features are used to detect boundaries between phrases, then stressed syllables are located within each constituent, and a partial distinctive features analysis is done within stressed syllables. Facilities were implemented for linear prediction, formant tracking, and extraction of fundamental frequency and speech energy contours. A program was implemented which detects 90% of all boundaries between major syntactic constituents from fall-rise valleys in fundamental frequency contours."
            },
            "slug": "Prosodic-Aids-to-Speech-Recognition-Lea-Medress",
            "title": {
                "fragments": [],
                "text": "Prosodic Aids to Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A strategy is outlined for acoustic aspects of speech recognition, whereby prosodic features are used to detect boundaries between phrases, then stressed syllables are located within each constituent, and a partial distinctive features analysis is done within stressed syllable."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762024"
                        ],
                        "name": "R. Bakis",
                        "slug": "R.-Bakis",
                        "structuredName": {
                            "firstName": "Raimo",
                            "lastName": "Bakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054136991"
                        ],
                        "name": "P. S. Cohen",
                        "slug": "P.-S.-Cohen",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Cohen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. S. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144309008"
                        ],
                        "name": "A. Cole",
                        "slug": "A.-Cole",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Cole",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143613831"
                        ],
                        "name": "B. Lewis",
                        "slug": "B.-Lewis",
                        "structuredName": {
                            "firstName": "Burn",
                            "lastName": "Lewis",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 769942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f6db1b368ebaeace796f78d1ee02807051487d4",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Further results have been obtained on the recognition of continuously read sentences from a natural language corpus of laser patents. The vocabulary is limited to the 1000 most frequently occurring words in the corpus. Our model of the task language has a perplexity of 24.1 words (corresponding to an entropy of 4.6 bits/word). This paper describes modifications and improvements to the system which have resulted in the lowering of the word error rate from the previously reported 33.1% to 8.9%."
            },
            "slug": "Further-results-on-the-recognition-of-a-read-corpus-Bahl-Bakis",
            "title": {
                "fragments": [],
                "text": "Further results on the recognition of a continuously read natural corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Modifications and improvements to the system which have resulted in the lowering of the word error rate from the previously reported 33.1% to 8.9% are described."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 217
                            }
                        ],
                        "text": "If the state sequence that led to the production of 0 is known, the conditional probability of 0 as defined in (6) involves a product form that implies statistical independence (Sondhi, Levinson, and de la Noue 1988; Wellekens 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120363714,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ff5a3d6464f842c8bcd4f2c60a9796de0aac25b9",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The Hidden Markov models are generalized by defining a new emission probability which takes the correlation between successive feature vectors into account. Estimation formulas for the iterative learning both along Viterbi and Maximum likelihood criteria are presented."
            },
            "slug": "Explicit-time-correlation-in-hidden-Markov-models-Wellekens",
            "title": {
                "fragments": [],
                "text": "Explicit time correlation in hidden Markov models for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The Hidden Markov models are generalized by defining a new emission probability which takes the correlation between successive feature vectors into account andimation formulas for the iterative learning both along Viterbi and Maximum likelihood criteria are presented."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145668559"
                        ],
                        "name": "E. A. Flinn",
                        "slug": "E.-A.-Flinn",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Flinn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. A. Flinn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120831806,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "8361d131583c398d2a708bd7d795c6b33a8ee61e",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "References to publications on linear prediction theory are suggested to complement those given by Atal and Hanauer [J. Acoust. Soc. Amer. 50, 637\u2013655 (1971)]."
            },
            "slug": "Comments-on-\u201cSpeech-Analysis-and-Synthesis-by-of-S.-Flinn",
            "title": {
                "fragments": [],
                "text": "Comments on \u201cSpeech Analysis and Synthesis by Linear Prediction of the Speech Wave\u201d [B. S. Atal and S. L. Hanauer, J. Acoust. Soc. Amer. 50, 637\u2013655 (1971)]"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423281"
                        ],
                        "name": "L. A. Liporace",
                        "slug": "L.-A.-Liporace",
                        "structuredName": {
                            "firstName": "Louis",
                            "lastName": "Liporace",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. A. Liporace"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30026295,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "664eb4fb59f2ce8f2e019a77653f9ed2cc5df591",
            "isKey": false,
            "numCitedBy": 430,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Parameter estimation for multivariate functions of Markov chains, a class of versatile statistical models for vector random processes, is discussed. The model regards an ordered sequence of vectors as noisy multivariate observations of a Markov chain. Mixture distributions are a special case. The foundations of the theory presented here were established by Baum, Petrie, Soules, and Weiss. A powerful representation theorem by Fan is employed to generalize the analysis of Baum, {\\em et al.} to a larger class of distributions."
            },
            "slug": "Maximum-likelihood-estimation-for-multivariate-of-Liporace",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood estimation for multivariate observations of Markov sources"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "Parameter estimation for multivariate functions of Markov chains, a class of versatile statistical models for vector random processes, is discussed, and a powerful representation theorem by Fan is employed to generalize the analysis of Baum, et al. to a larger class of distributions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144665059"
                        ],
                        "name": "Y. Linde",
                        "slug": "Y.-Linde",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Linde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Linde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805395"
                        ],
                        "name": "A. Buzo",
                        "slug": "A.-Buzo",
                        "structuredName": {
                            "firstName": "Andres",
                            "lastName": "Buzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18530691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c46799502bebfe6a9ae0f457b7b8b92248ec260",
            "isKey": false,
            "numCitedBy": 7891,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or on a long training sequence of data. The basic properties of the algorithm are discussed and demonstrated by examples. Quite general distortion measures and long blocklengths are allowed, as exemplified by the design of parameter vector quantizers of ten-dimensional vectors arising in Linear Predictive Coded (LPC) speech compression with a complicated distortion measure arising in LPC analysis that does not depend only on the error vector."
            },
            "slug": "An-Algorithm-for-Vector-Quantizer-Design-Linde-Buzo",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Vector Quantizer Design"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or on a long training sequence of data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693333"
                        ],
                        "name": "R. Schafer",
                        "slug": "R.-Schafer",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Schafer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schafer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 109216980,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "059b8ce08e087610bb1136a33eec717812f58b8b",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A bank of bandpass filters is often used in performing short-time spectrum analysis of speech signals. This paper is concerned with the analysis and design of digital filter banks composed of equally spaced bandpass filters. It is shown that significant improvement in the composite filter bank response can be achieved by proper choice of the relative phases of the bandpass filters. The results are extended to more general filter bank configurations."
            },
            "slug": "Design-of-digital-filter-banks-for-speech-analysis-Schafer-Rabiner",
            "title": {
                "fragments": [],
                "text": "Design of digital filter banks for speech analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153201"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61904772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c180f387357d9302a558bcd643209831744c639b",
            "isKey": false,
            "numCitedBy": 604,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system. DRAGON makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech. The model--that of a probabilistic function of a Markov process--is very flexible and leads to features which allow DRAGON to function despite high error rates from individual knowledge sources. Repeated use of a simple abstract model produces a system which is simple in structure, but powerful in capabilities."
            },
            "slug": "The-DRAGON-system--An-overview-Baker",
            "title": {
                "fragments": [],
                "text": "The DRAGON system--An overview"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system, which makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111257669"
                        ],
                        "name": "Rodney W. Johnson",
                        "slug": "Rodney-W.-Johnson",
                        "structuredName": {
                            "firstName": "Rodney",
                            "lastName": "Johnson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rodney W. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 87
                            }
                        ],
                        "text": "The KullbackLeibler number, cross entropy, I divergence, or discrimination information (Good 1963; Hobson and Cheng 1973; Johnson 1979; Kullback 1958) defined"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 114
                            }
                        ],
                        "text": "The Leibler number, cross entropy, I divergence, or discrimination information (Good 1963; Hobson and Cheng 1973; Johnson 1979; Kullback 1958) defined by is the mean information for discriminating f,against f2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17638390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e61e445ddcf95ef8b751051daa64ed20e1de90ce",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The principle of maximum entropy and a generalization, the principle of minimum cross entropy, are prescriptions for solving problems of the following sort, which are encountered in a remarkable number of different fields. Namely, some system may be in any one of a given set of states; the probabilities of its being in the various states are not specified, but information about the probability distribution is available in the form of expectation values of given functions on the set of states. It is required to assign an optimal, or minimally prejudiced, set of state probabilities consistent with the given information. This paper describes the principles and presents APL functions that use the Newton-Raphson method to compute maximum-entropy and minimum-cross-entropy probability distributions for arbitrary sets of given expectation values. Example calculations are given."
            },
            "slug": "Determining-probability-distributions-by-maximum-Johnson",
            "title": {
                "fragments": [],
                "text": "Determining probability distributions by maximum entropy and minimum cross-entropy"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The principles of maximum entropy and a generalization, the principle of minimum cross entropy, are described and APL functions that use the Newton-Raphson method to compute maximum-entropy and minimum-cross-ent entropy probability distributions for arbitrary sets of given expectation values are presented."
            },
            "venue": {
                "fragments": [],
                "text": "APL '79"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064923128"
                        ],
                        "name": "J. Markel",
                        "slug": "J.-Markel",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Markel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Markel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34886891"
                        ],
                        "name": "A. Gray",
                        "slug": "A.-Gray",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Gray",
                            "middleNames": [
                                "H."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These include such standard methods as measurement of the discrete (fast) Fourier transform (FFT), all-pole minimum-phase linear prediction (LPC) methods, and autoregressive/moving average models (Allen and Rabiner 1977; Atal and Hanauer 1971; Cadzow 1982; Makhoul 1975;  Markel and Gray 1976;  Schafer and Rabiner 1971)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 244
                            }
                        ],
                        "text": "\u2026methods as measurement of the discrete (fast) Fourier transform (FFT), all-pole minimum-phase linear prediction (LPC) methods, and autoregressive/moving average models (Allen and Rabiner 1977; Atal and Hanauer 1971; Cadzow 1982; Makhoul 1975; Markel and Gray 1976; Schafer and Rabiner 1971)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121743269,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f35b697a119f626a5923115cd9bed44f72eab60",
            "isKey": false,
            "numCitedBy": 1456,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction.- 1.1 Basic Physical Principles.- 1.2 Acoustical Waveform Examples.- 1.3 Speech Analysis and Synthesis Models.- 1.4 The Linear Prediction Model.- 1.5 Organization of Book.- 2. Formulations.- 2.1 Historical Perspective.- 2.2 Maximum Likelihood.- 2.3 Minimum Variance.- 2.4 Prony's Method.- 2.5 Correlation Matching.- 2.6 PARCOR (Partial Correlation).- 2.6.1 Inner Products and an Orthogonality Principle.- 2.6.2 The PARCOR Lattice Structure.- 3. Solutions and Properties.- 3.1 Introduction.- 3.2 Vector Spaces and Inner Products.- 3.2.1 Filter or Polynomial Norms.- 3.2.2 Properties of Inner Products.- 3.2.3 Orthogonality Relations.- 3.3 Solution Algorithms.- 3.3.1 Correlation Matrix.- 3.3.2 Initialization.- 3.3.3 Gram-Schmidt Orthogonalization.- 3.3.4 Levinson Recursion.- 3.3.5 Updating Am(z).- 3.3.6 A Test Example.- 3.4 Matrix Forms.- 4. Acoustic Tube Modeling.- 4.1 Introduction.- 4.2 Acoustic Tube Derivation.- 4.2.1 Single Section Derivation.- 4.2.2 Continuity Conditions.- 4.2.3 Boundary Conditions.- 4.3 Relationship between Acoustic Tube and Linear Prediction.- 4.4 An Algorithm, Examples, and Evaluation.- 4.4.1 An Algorithm.- 4.4.2 Examples.- 4.4.3 Evaluation of the Procedure.- 4.5 Estimation of Lip Impedance.- 4.5.1 Lip Impedance Derivation.- 4.6 Further Topics.- 4.6.1 Losses in the Acoustic Tube Model.- 4.6.2 Acoustic Tube Stability.- 5. Speech Synthesis Structures.- 5.1 Introduction.- 5.2 Stability.- 5.2.1 Step-up Procedure.- 5.2.2 Step-down Procedure.- 5.2.3 Polynomial Properties.- 5.2.4 A Bound on |Fm(z)|.- 5.2.5 Necessary and Sufficient Stability Conditions.- 5.2.6 Application of Results.- 5.3 Recursive Parameter Evaluation.- 5.3.1 Inner Product Properties.- 5.3.2 Equation Summary with Program.- 5.4 A General Synthesis Structure.- 5.5 Specific Speech Synthesis Structures.- 5.5.1 The Direct Form.- 5.5.2 Two-Multiplier Lattice Model.- 5.5.3 Kelly-Lochbaum Model.- 5.5.4 One-Multiplier Models.- 5.5.5 Normalized Filter Model.- 5.5.6 A Test Example.- 6. Spectral Analysis.- 6.1 Introduction.- 6.2 Spectral Properties.- 6.2.1 Zero Mean All-Pole Model.- 6.2.2 Gain Factor for Spectral Matching.- 6.2.3 Limiting Spectral Match.- 6.2.4 Non-uniform Spectral Weighting.- 6.2.5 Minimax Spectral Matching.- 6.3 A Spectral Flatness Model.- 6.3.1 A Spectral Flatness Measure.- 6.3.2 Spectral Flatness Transformations.- 6.3.3 Numerical Evaluation.- 6.3.4 Experimental Results.- 6.3.5 Driving Function Models.- 6.4 Selective Linear Prediction.- 6.4.1 Selective Linear Prediction (SLP) Algorithm.- 6.4.2 A Selective Linear Prediction Program.- 6.4.3 Computational Considerations.- 6.5 Considerations in Choice of Analysis Conditions.- 6.5.1 Choice of Method.- 6.5.2 Sampling Rates.- 6.5.3 Order of Filter.- 6.5.4 Choice of Analysis Interval.- 6.5.5 Windowing.- 6.5.6 Pre-emphasis.- 6.6 Spectral Evaluation Techniques.- 6.7 Pole Enhancement.- 7. Automatic Formant Trajectory Estimation.- 7.1 Introduction.- 7.2 Formant Trajectory Estimation Procedure.- 7.2.1 Introduction.- 7.2.2 Raw Data from A(z).- 7.2.3 Examples of Raw Data.- 7.3 Comparison of Raw Data from Linear Prediction and Cepstral Smoothing.- 7.4 Algorithm 1.- 7.5 Algorithm 2.- 7.5.1 Definition of Anchor Points.- 7.5.2 Processing of Each Voiced Segment.- 7.5.3 Final Smoothing.- 7.5.4 Results and Discussion.- 7.6 Formant Estimation Accuracy.- 7.6.1 An Example of Synthetic Speech Analysis.- 7.6.2 An Example of Real Speech Analysis.- 7.6.3 Influence of Voice Periodicity.- 8. Fundamental Frequency Estimation.- 8.1 Introduction.- 8.2 Preprocessing by Spectral Flattening.- 8.2.1 Analysis of Voiced Speech with Spectral Regularity.- 8.2.2 Analysis of Voiced Speech with Spectral Irregularities.- 8.2.3 The STREAK Algorithm.- 8.3 Correlation Techniques.- 8.3.1 Autocorrelation Analysis.- 8.3.2 Modified Autocorrelation Analysis.- 8.3.3 Filtered Error Signal Autocorrelation Analysis.- 8.3.4 Practical Considerations.- 8.3.5 The SIFT Algorithm.- 9. Computational Considerations in Analysis.- 9.1 Introduction.- 9.2 Ill-Conditioning.- 9.2.1 A Measure of Ill-Conditioning.- 9.2.2 Pre-emphasis of Speech Data.- 9.2.3 Prefiltering before Sampling.- 9.3 Implementing Linear Prediction Analysis.- 9.3.1 Autocorrelation Method.- 9.3.2 Covariance Method.- 9.3.3 Computational Comparison.- 9.4 Finite Word Length Considerations.- 9.4.1 Finite Word Length Coefficient Computation.- 9.4.2 Finite Word Length Solution of Equations.- 9.4.3 Overall Finite Word Length Implementation.- 10. Vocoders.- 10.1 Introduction.- 10.2 Techniques.- 10.2.1 Coefficient Transformations.- 10.2.2 Encoding and Decoding.- 10.2.3 Variable Frame Rate Transmission.- 10.2.4 Excitation and Synthesis Gain Matching.- 10.2.5 A Linear Prediction Synthesizer Program.- 10.3 Low Bit Rate Pitch Excited Vocoders.- 10.3.1 Maximum Likelihood and PARCOR Vocoders.- 10.3.2 Autocorrelation Method Vocoders.- 10.3.3 Covariance Method Vocoders.- 10.4 Base-Band Excited Vocoders.- 11. Further Topics.- 11.1 Speaker Identification and Verification.- 11.2 Isolated Word Recognition.- 11.3 Acoustical Detection of Laryngeal Pathology.- 11.4 Pole-Zero Estimation.- 11.5 Summary and Future Directions.- References."
            },
            "slug": "Linear-Prediction-of-Speech-Markel-Gray",
            "title": {
                "fragments": [],
                "text": "Linear Prediction of Speech"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Speech Analysis and Synthesis Models: Basic Physical Principles, Speech Synthesis Structures, and Considerations in Choice of Analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Communication and Cybernetics"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107215080"
                        ],
                        "name": "J. Allen",
                        "slug": "J.-Allen",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Allen",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Allen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 170
                            }
                        ],
                        "text": "\u2026methods as measurement of the discrete (fast) Fourier transform (FFT), all-pole minimum-phase linear prediction (LPC) methods, and autoregressive/moving average models (Allen and Rabiner 1977; Atal and Hanauer 1971; Cadzow 1982; Makhoul 1975; Markel and Gray 1976; Schafer and Rabiner 1971)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15841658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0363fffceb4dc8a9f3e01334d442cf44f4cc436",
            "isKey": false,
            "numCitedBy": 875,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Two distinct methods for synthesizing a signal from its short-time Fourier transform have previously been proposed. We call these methods the filter-bank summation (FBS) method and the overlap add (OLA) method. Each of these synthesis techniques has unique advantages and disadvantages in various applications due to the way in which the signal is reconstructed. In this paper we unify the ideas behind the two synthesis techniques and discuss the similarities and differences between these methods. In particular, we explicitly show the effects of modifications made to the short-time transform (both fixed and time-varying modifications are considered) on the resulting signal and discuss applications where each of the techniques would be most useful The interesting case of nonlinear modifications (possibly signal dependent) to the short-time Fourier transform is also discussed. Finally it is shown that a formal duality exists between the two synthesis methods based on the properties of the window used for obtaining the short-time Fourier transform."
            },
            "slug": "A-unified-approach-to-short-time-Fourier-analysis-Allen-Rabiner",
            "title": {
                "fragments": [],
                "text": "A unified approach to short-time Fourier analysis and synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The effects of modifications made to the short-time transform are explicitly shown on the resulting signal and it is shown that a formal duality exists between the two synthesis methods based on the properties of the window used for obtaining theshort-time Fourier transform."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103072546"
                        ],
                        "name": "J. Eagon",
                        "slug": "J.-Eagon",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Eagon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eagon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14153120,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "69fc8c03d21e22e30d6642824c37158b314f36c3",
            "isKey": false,
            "numCitedBy": 1122,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Summary. The object of this note is to prove the theorem below and sketch two applications, one to statistical estimation for (proba-bilistic) functions of Markov processes [l] and one to Blakley's model for ecology [4]. 2. Result. THEOREM. Let P(x)=P({xij}) be a polynomial with nonnegative coefficients homogeneous of degree d in its variables {##}. Let x= {##} be any point of the domain D: ## \u00a7:(), ]pLi ## = 1, i = l, \u2022 \u2022 \u2022 , p, j=l, \u2022 \u2022 \u2022 , q%. For x= {xij} \u00a3\u00a3> let 3(#) = 3{##} denote the point of D whose i, j coordinate is (dP\\ \\ f \u00ab dP 3(*)<i = (Xij 7\u2014) / 2* *<i \u2014 \\ dXij\\(X)// ,-i dXij (\u00bb> Then P(3(x))>P(x) unless 3(x)=x. Notation, fi will denote a doubly indexed array of nonnegative integers: fx= {M#}> i = l> \u2022 \u2022 \u2022 > <lu i=l, \u2022 \u2022 \u2022 , A #* then denotes Ilf-iH\u00ee-i^* Similarly, c M is an abbreviation for C[ MiJ }. The polynomial P({xij}) is then written P(x) = ]CM V^-In our notation : (1) 3(&)*i = (Z) \u00abWnys*) / JLH CpiiijX\u00bb."
            },
            "slug": "An-inequality-with-applications-to-statistical-for-Baum-Eagon",
            "title": {
                "fragments": [],
                "text": "An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 74
                            }
                        ],
                        "text": "With the understanding of the relationship between the trellis structure (Juang 1984) and the decoding structure of the HMM, as discussed in the evaluation problem, we are able to apply the HMM to many complicated problems without much concern as to computational complexity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 107
                            }
                        ],
                        "text": "Some perspectives as to how these two seemingly different methodologies relate to each other were given by Juang (1984) and Bridle (1984)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10588608,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1c18985b2e70d671f07d784ac9120fdd090569a9",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we discuss parameter estimation by means of the reestimation algorithm for a class of multivariate mixture density functions of Markov chains. The scope of the original reestimation algorithm is expanded and the previous assumptions of log concavity or ellipsoidal symmetry are obviated, thereby enhancing the modeling capability of the technique. Reestimation formulas in terms of the well-known forward-backward inductive procedure are also derived."
            },
            "slug": "Maximum-likelihood-estimation-for-mixture-of-Markov-Juang",
            "title": {
                "fragments": [],
                "text": "Maximum-likelihood estimation for mixture multivariate stochastic observations of Markov chains"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The scope of the original reestimation algorithm is expanded and the previous assumptions of log concavity or ellipsoidal symmetry are obviated, thereby enhancing the modeling capability of the technique."
            },
            "venue": {
                "fragments": [],
                "text": "AT&T Technical Journal"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144051580"
                        ],
                        "name": "A. Hobson",
                        "slug": "A.-Hobson",
                        "structuredName": {
                            "firstName": "Art",
                            "lastName": "Hobson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hobson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144512028"
                        ],
                        "name": "B. Cheng",
                        "slug": "B.-Cheng",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Cheng",
                            "middleNames": [
                                "Kang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Cheng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120073606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5de50fe1cfcc0bf6c4b9b5c5fb6f91752294049",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Two widely used information measures are compared. It is shown that the Kullback measure, unlike the Shannon measure, provides the basis for a consistent theory of information which extends to continuous sample spaces and to nonconstant prior distributions. It is shown that the Kullback measure is a generalization of the Shannon measure, and that the Kullback measure has more reasonable additivity properties than does the Shannon measure. The results lend support to Jaynes's entropy maximization procedure."
            },
            "slug": "A-comparison-of-the-Shannon-and-Kullback-measures-Hobson-Cheng",
            "title": {
                "fragments": [],
                "text": "A comparison of the Shannon and Kullback information measures"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "It is shown that the Kullback measure, unlike the Shannon measure, provides the basis for a consistent theory of information which extends to continuous sample spaces and to nonconstant prior distributions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 163
                            }
                        ],
                        "text": "The much increased complication in decoding lattice often renders many search algorithms such as the beam search (Lowerre and Reddy 1980) and the stack algorithm (Jelinek 1969) for handling large problems extremely difficult to implement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62562997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae9443b39a5abfbf3cc9776173c1ae4f94732408",
            "isKey": false,
            "numCitedBy": 593,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a new sequential decoding algorithm is introduced that uses stack storage at the receiver. It is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp the rate below which the average number of decoding steps is bounded by a constant. Practical problems connected with implementing the stack algorithm are discussed and a scheme is described that facilitates satisfactory performance even with limited stack storage capacity. Preliminary simulation results estimating the decoding effort and the needed stack siazree presented."
            },
            "slug": "Fast-sequential-decoding-algorithm-using-a-stack-Jelinek",
            "title": {
                "fragments": [],
                "text": "Fast sequential decoding algorithm using a stack"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new sequential decoding algorithm is introduced that uses stack storage at the receiver that is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9166720"
                        ],
                        "name": "Chung-ying Cheng",
                        "slug": "Chung-ying-Cheng",
                        "structuredName": {
                            "firstName": "Chung-ying",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung-ying Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73307871"
                        ],
                        "name": "Y. R. Chao",
                        "slug": "Y.-R.-Chao",
                        "structuredName": {
                            "firstName": "Yuen",
                            "lastName": "Chao",
                            "middleNames": [
                                "Ren"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. R. Chao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 44
                            }
                        ],
                        "text": "On the other hand, speech is a linear code (Chao 1968) in the sense that decoded symbols come out one after another and no two symbols can appear at the same time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62487488,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "92a71dddab28f7e8fef4494da30ee319bb230559",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Language and the study of language 2. Phonetics 3. Phonemics 4. Vocabulary and grammar 5. Meaning 6. Change in language 7. Languages of the world 8. Writing 9. Language and life 10. Languages in contact 11. Language technology 12. Symbolic systems Suggested further readings Index."
            },
            "slug": "Language-and-symbolic-systems-Cheng-Chao",
            "title": {
                "fragments": [],
                "text": "Language and symbolic systems"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This book discusses language and the study of language, its applications in the modern world, and its role in the development of language technology."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102259527"
                        ],
                        "name": "B. Lowerre",
                        "slug": "B.-Lowerre",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lowerre",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lowerre"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61406953,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f9fa38c30e6978680304e0f0d1d5330676d8abc9",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Harpy-speech-understanding-system-Lowerre",
            "title": {
                "fragments": [],
                "text": "The Harpy speech understanding system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24804,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16927,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378652"
                        ],
                        "name": "R. Olshen",
                        "slug": "R.-Olshen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Olshen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Olshen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103556459"
                        ],
                        "name": "C. J. Stone",
                        "slug": "C.-J.-Stone",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29458883,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8017699564136f93af21575810d557dba1ee6fc6",
            "isKey": false,
            "numCitedBy": 16307,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Background. Introduction to Tree Classification. Right Sized Trees and Honest Estimates. Splitting Rules. Strengthening and Interpreting. Medical Diagnosis and Prognosis. Mass Spectra Classification. Regression Trees. Bayes Rules and Partitions. Optimal Pruning. Construction of Trees from a Learning Sample. Consistency. Bibliography. Notation Index. Subject Index."
            },
            "slug": "Classification-and-Regression-Trees-Breiman-Friedman",
            "title": {
                "fragments": [],
                "text": "Classification and Regression Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This chapter discusses tree classification in the context of medicine, where right Sized Trees and Honest Estimates are considered and Bayes Rules and Partitions are used as guides to optimal pruning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 63
                            }
                        ],
                        "text": "This simple duration model has been applied with good success (Lowerre and Reddy 1980) for some tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 113
                            }
                        ],
                        "text": "The much increased complication in decoding lattice often renders many search algorithms such as the beam search (Lowerre and Reddy 1980) and the stack algorithm (Jelinek 1969) for handling large"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 105
                            }
                        ],
                        "text": "Such a provision for introducing singularities could have a major impact on the recognition performance (Lowerre and Reddy 1980)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 106
                            }
                        ],
                        "text": "] Such a provision for introducing singularities could have a major impact on the recognition performance (Lowerre and Reddy 1980)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 114
                            }
                        ],
                        "text": "The much increased complication in decoding lattice often renders many search algorithms such as the beam search (Lowerre and Reddy 1980) and the stack algorithm (Jelinek 1969) for handling large problems extremely difficult to implement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The HARPY Speech Understanding System,\" in Trends in Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "ed. W. Lea, Englewood Cliffs, NJ: Prentice-Hall,"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 42
                            }
                        ],
                        "text": "The scaling algorithm, well documented by Levinson et al. (1983) and Juang and Rabiner (1985), alleviates the dynamic-range problem by normalizing the par- B. H. JUANG AND L. R. RABINER tial probabilities, such as the forward variable defined in Section 2.1, at each time instance before they cause\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An TECHNOMETRICS"
            },
            "venue": {
                "fragments": [],
                "text": "An TECHNOMETRICS"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699205"
                        ],
                        "name": "S. Furui",
                        "slug": "S.-Furui",
                        "structuredName": {
                            "firstName": "Sadaoki",
                            "lastName": "Furui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Furui"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 135
                            }
                        ],
                        "text": "The success of spectral parameters for characterizing speech was further augmented by the introduction of the so-called deltacepstrum (Furui 1986), which attempts to model the differential speech spectrum."
                    },
                    "intents": []
                }
            ],
            "corpusId": 124610704,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f2419349de78d4219ebf8308b18d7a7787c33b8b",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speaker-Independent-Isolated-Word-Recognition-Based-Furui",
            "title": {
                "fragments": [],
                "text": "Speaker-Independent Isolated Word Recognition Based on Dynamics-Emphasized Cepstrum"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145179124"
                        ],
                        "name": "I. Good",
                        "slug": "I.-Good",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Good",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Good"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 80
                            }
                        ],
                        "text": "The Leibler number, cross entropy, I divergence, or discrimination information (Good 1963; Hobson and Cheng 1973; Johnson 1979; Kullback 1958) defined by is the mean information for discriminating f,against f2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123298174,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "602084417015618f112c796828786a6af72bf7d9",
            "isKey": false,
            "numCitedBy": 412,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Maximum-Entropy-for-Hypothesis-Formulation,-for-Good",
            "title": {
                "fragments": [],
                "text": "Maximum Entropy for Hypothesis Formulation, Especially for Multidimensional Contingency Tables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102329511"
                        ],
                        "name": "George W. Soules",
                        "slug": "George-W.-Soules",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Soules",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George W. Soules"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063108982"
                        ],
                        "name": "Norman Weiss",
                        "slug": "Norman-Weiss",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norman Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122568650,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3092a4929bdb3d6a8fe53f162586b7431b5ff8a4",
            "isKey": false,
            "numCitedBy": 4551,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Maximization-Technique-Occurring-in-the-Analysis-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The Baum-Welch algorithm (Baum and Egon 1967; Baum and Petrie 1966; Baum, Petrie, Soules, and Weiss 1970; Baum and Sell 1968) (often blended with the forward-backward algorithm because of its interpretation as an extension of the forward induction procedure to the evaluation problem) cleverly accomplishes this maximization objective in a two-step procedure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120208815,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "603bdbb17ba1f909280405a076455ac4f878fbf3",
            "isKey": false,
            "numCitedBy": 2773,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-Inference-for-Probabilistic-Functions-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "Statistical Inference for Probabilistic Functions of Finite State Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145404333"
                        ],
                        "name": "Peter No",
                        "slug": "Peter-No",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "No",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter No"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 110416128,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "535df6b883398c85617da1137718ad4f672aaa2c",
            "isKey": false,
            "numCitedBy": 1531,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Digital-Coding-of-Waveforms-No",
            "title": {
                "fragments": [],
                "text": "Digital Coding of Waveforms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22904118"
                        ],
                        "name": "K. H. Barratt",
                        "slug": "K.-H.-Barratt",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Barratt",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. H. Barratt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 109950677,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "71bc7b7e454337656656b656ce615c9cc17f0e59",
            "isKey": false,
            "numCitedBy": 1167,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Digital-Coding-of-Waveforms-Barratt",
            "title": {
                "fragments": [],
                "text": "Digital Coding of Waveforms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "We can then compute the change in entropy (i.e., loss of information) resulting from the merged models as (Lee 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 64161455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "280db747f41ccf9263459d9c5576838b59ffd1e0",
            "isKey": false,
            "numCitedBy": 382,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-Speech-Recognition-Lee",
            "title": {
                "fragments": [],
                "text": "Automatic Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 281
                            }
                        ],
                        "text": "\u2026utterances are usually not prohibitively long so as to require locally (rather than globally) optimal decoding, and (3) it is possible to formulate the maximization of Pr(q 0 , E. ) in a sequential manner to be solved by dynamic programming methods such as the Viterbi algorithm (Forney 1973)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ") in a sequential manner to be solved by dynamic programming methods such as the Viterbi algorithm (Forney 1973)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62282319,
            "fieldsOfStudy": [],
            "id": "d87a423334afb20747c367b2d907069d7f3b4ed2",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The viterbi algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61012010,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a923c9f89ed53b6e835b3807c0c1bd8d532687b",
            "isKey": false,
            "numCitedBy": 1037,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Interpolated-estimation-of-Markov-source-parameters-Jelinek",
            "title": {
                "fragments": [],
                "text": "Interpolated estimation of Markov source parameters from sparse data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 62
                            }
                        ],
                        "text": "Fortunately. using the well-known forward-backward procedure (Baum 1972), this exorbitant computational requirement of the direct summation can be easily alleviated."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60804212,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "539036ab9e8f038c8a948596e77cc0dfcfa91fb3",
            "isKey": false,
            "numCitedBy": 1785,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-inequality-and-associated-maximization-technique-Baum",
            "title": {
                "fragments": [],
                "text": "An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50818581"
                        ],
                        "name": "G. Sell",
                        "slug": "G.-Sell",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Sell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 24
                            }
                        ],
                        "text": "The Q function of 1970; Baum and Sell 1968) (often blended with the (9) is clearly an expectation operation, so the twoforward-backward algorithm because of its interprestep algorithm is identical to the E(xpectation)tation as an extension of the forward induction pro- M(aximization) algorithm.\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 54933170,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d01ceefe8df12cc5569af0257d38cac989443e6e",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Growth-transformations-for-functions-on-manifolds.-Baum-Sell",
            "title": {
                "fragments": [],
                "text": "Growth transformations for functions on manifolds."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 133
                            }
                        ],
                        "text": "One such category of nonspectral speech features is prosody as it is manifested on both the segmental and the supra-segmental level (Lea 1980)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Prosodic Aids to Speech Recognition.\" in Trends in Speech Recogriilion, ed"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "RABINER Introduction to the Application of the Theory of Probabilistic Functions of a Markov Process to Automatic Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Bell System Technical Journal"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Theory on Adaptive Learning for Pattern Classification.\" unpublished manuscript"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 24
                            }
                        ],
                        "text": "The Q function of 1970; Baum and Sell 1968) (often blended with the (9) is clearly an expectation operation, so the twoforward-backward algorithm because of its interprestep algorithm is identical to the E(xpectation)tation as an extension of the forward induction pro- M(aximization) algorithm.\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Growth Functions for Transformations on Manifolds"
            },
            "venue": {
                "fragments": [],
                "text": "Pacific Journal of Mathematics"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 150
                            }
                        ],
                        "text": "Other attempts to design HMM's for minimum error rate or some form of class separation include the work by Ljolje, Ephraim, and Rabiner (1990) and by Sondhi and Roe (1983)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "unpublished report"
            },
            "venue": {
                "fragments": [],
                "text": "unpublished report"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 37
                            }
                        ],
                        "text": "Previous attempts (Bahl et al. 1986; Brown 1987) at using the MMI criterion have not produced an estimation procedure that is guaranteed to converge to an optimal solution either."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Acoustic-Modelling Problem in Automatic Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "The Acoustic-Modelling Problem in Automatic Speech Recognition"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 18
                            }
                        ],
                        "text": "Previous attempts (Bahl et al. 1986; Brown 1987) at using the MMI criterion have not"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 19
                            }
                        ],
                        "text": "Previous attempts (Bahl et al. 1986; Brown 1987) at using the MMI criterion have not produced an estimation procedure that is guaranteed to converge to an optimal solution either."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum Mutual Information Estimation of Hidden TECHNOMETRICS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 145
                            }
                        ],
                        "text": "\u2026training were also proposed by Katagiri, Lee, and Juang (1990), who combined the adaptive learning concept in learning vector quantizer design (Kohonen 1986) and the corrective training method described previously, leading to a framework for the analysis of related trainingilearning ideas."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Vector Quantization for Pattern Recognition,\" Report TKK-F-A601"
            },
            "venue": {
                "fragments": [],
                "text": "Helsinki University of Technology"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 145
                            }
                        ],
                        "text": "\u2026training were also proposed by Katagiri, Lee, and Juang (1990), who combined the adaptive learning concept in learning vector quantizer design (Kohonen 1986) and the corrective training method described previously, leading to a framework for the analysis of related trainingilearning ideas."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Vector Quantization for Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Learning Vector Quantization for Pattern Recognition"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 18
                            }
                        ],
                        "text": "Previous attempts (Bahl et al. 1986; Brown 1987) at using the MMI criterion have not"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 37
                            }
                        ],
                        "text": "Previous attempts (Bahl et al. 1986; Brown 1987) at using the MMI criterion have not produced an estimation procedure that is guaranteed to converge to an optimal solution either."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Acoustic-Modelling Problem in Automatic Speech Recognition,\" unpublished Ph.D"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 49
                            }
                        ],
                        "text": "It is known (Juang 1985; Juang and Rabiner 1985; Liporace 1982) that these algorithms can accommodate observation densities that are (a) strictly log-concave densities, (b) elliptically symmetric densities, (c) mixtures of distributions of the preceding two categories, and (d) discrete\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\" Maximum Likelihood Estimation for Multivariate Observations of Markov Sources , \" I E E E Trans - aclions on Informalion Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 221
                            }
                        ],
                        "text": "\u2026log energy (and differential log energy) either directly into the feature vector or as an additional feature whose probability (or likelihood) is factored into the likelihood calculation (Bahl et al. 1983; Rabiner 1984; Shikano 1985) with moderate success (i.e., higher recognition performance)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 232
                            }
                        ],
                        "text": "[Of course, we can always oversample the features associated with the prosodic parameters to keep the rate the same as that of the spectral parameters; this in fact is what is currently done in most systems-e.g., Rabiner (1984) and Shikano (1985)]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluation of LPC Spectral Matching Measures for Phonelic Unit Recognition, technical report"
            },
            "venue": {
                "fragments": [],
                "text": "Evaluation of LPC Spectral Matching Measures for Phonelic Unit Recognition, technical report"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Growth Functions for Transformations on Manifolds,\" Pacific"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Mathematics"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On Hidden Markov Models in Isolated Word Recognition,\" in Proceedings of the Interna~ional"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Minimum Discrimination Information Approach for Hidden Markov hlodeling.\" IEEE Transac~ions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Comparison of the Shan"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Unified Techniques"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 187
                            }
                        ],
                        "text": "log energy (and differential log energy) either directly into the feature vector or as an additional feature whose probability (or likelihood) is factored into the likelihood calculation (Bahl et al. 1983; Rabiner 1984; Shikano 1985) with moderate success (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 221
                            }
                        ],
                        "text": "\u2026log energy (and differential log energy) either directly into the feature vector or as an additional feature whose probability (or likelihood) is factored into the likelihood calculation (Bahl et al. 1983; Rabiner 1984; Shikano 1985) with moderate success (i.e., higher recognition performance)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 232
                            }
                        ],
                        "text": "[Of course, we can always oversample the features associated with the prosodic parameters to keep the rate the same as that of the spectral parameters; this in fact is what is currently done in most systems-e.g., Rabiner (1984) and Shikano (1985)]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluation of LPC Spectral Matching Measures for Phonelic"
            },
            "venue": {
                "fragments": [],
                "text": "Unit Recognition,"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Unified Theory of Short-time Spectrum Analysis and Synthesis,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 124
                            }
                        ],
                        "text": "Some perspectives as to how these two seemingly different methodologies relate to each other were given by Juang (1984) and Bridle (1984)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic Models and Template Matching: Some Important Relationships Between Two Apparently Different Techniques for Automatic Speech Recognition,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Institute of Acoustics, Autumn Conference,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic Speech Recognition, the Development of the SPHINX System.\" Boston: Kluwer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Inequality and Associated Maximization Technique in Statistical Estimation for"
            },
            "venue": {
                "fragments": [],
                "text": "Probabilistic Functions of Markov Processes,\" Inequalities,"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\" Maximum Entropy for Hypothesis Formulation"
            },
            "venue": {
                "fragments": [],
                "text": "Especially for Multidimensional Contingency Tables , \" The Annals of ' Malhematical Statistics"
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speaker-Dependent Connected Speech Recognition Via Dynamic Programming and Statistical Methods,"
            },
            "venue": {
                "fragments": [],
                "text": "Speech and Speaker Recognition,"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 135
                            }
                        ],
                        "text": "The success of spectral parameters for characterizing speech was further augmented by the introduction of the so-called deltacepstrum (Furui 1986), which attempts to model the differential speech spectrum."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speaker Independent Isolated Word Recog"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\" A Theory on Adaptive Learning for Pattern Classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Growth Functions for Transformations on Manifolds"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum Entropy for Hypothesis Formu"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recent Developments in the Application of Hidden Markov Models to Speaker-Independent Isolated Word Recognition.\" in Proceedings of the Interna~ional"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\" Hidden Markov Analysis : An Introduction . \" in Hidden Markov Modelsfor Speech"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 100
                            }
                        ],
                        "text": "For modeling isolated utterances (i.e., whole words or phrases), we often use left-to-right models (Bakis 1976; Rabiner et al. 1983) of the type shown in Figure 7a, since the utterance begins and ends at well-identified time instants (except in the case of very noisy or corrupted speech) and the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Continuous Speech Word Recognition Via Centisecond Acoustic States,\" unpublished paper presented at the meeting of the Acoustics Society of America"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Linear Predicrion of Speech"
            },
            "venue": {
                "fragments": [],
                "text": "Linear Predicrion of Speech"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 163
                            }
                        ],
                        "text": "The much increased complication in decoding lattice often renders many search algorithms such as the beam search (Lowerre and Reddy 1980) and the stack algorithm (Jelinek 1969) for handling large problems extremely difficult to implement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Fast Sequential Decoding Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 230
                            }
                        ],
                        "text": "\u2026methods as measurement of the discrete (fast) Fourier transform (FFT), all-pole minimum-phase linear prediction (LPC) methods, and autoregressive/moving average models (Allen and Rabiner 1977; Atal and Hanauer 1971; Cadzow 1982; Makhoul 1975; Markel and Gray 1976; Schafer and Rabiner 1971)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\" Linear Prediction : A Tutorial Review , \" Proceedings of the I E E E"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hidden Markov Analysis: An Introduction"
            },
            "venue": {
                "fragments": [],
                "text": "Princeton. NJ: Institute for Defense Analyses"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Machines, New York: McGrawHill"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 144
                            }
                        ],
                        "text": "\u2026used in vector quantizer designs (Linde, Buzo, and Gray 1980) or the greedy growing algorithm found in set-partition or decision-tree designs (Breiman 1984), all of which are suitable for the purpose of separating inconsistent training data so that each divided subgroup becomes more\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classification and Regression Trees, Monterey, CA: Wadsworth"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Theory on Adaptive Learning for Pattern Classification"
            },
            "venue": {
                "fragments": [],
                "text": "A Theory on Adaptive Learning for Pattern Classification"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Explicit Modeling of State Occupancy in Hidden Markov Models for Automatic Speech Recognition,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Conference on Acoustics, Speech and Signal Processing,"
            },
            "year": 1985
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 30,
            "methodology": 30
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 118,
        "totalPages": 12
    },
    "page_url": "https://www.semanticscholar.org/paper/Hidden-Markov-Models-for-Speech-Recognition-Juang-Rabiner/df682aa90fbbbf665a8b273a57ca87d6cea9ff99?sort=total-citations"
}