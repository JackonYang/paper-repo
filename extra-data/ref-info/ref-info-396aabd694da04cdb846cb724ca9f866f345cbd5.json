{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143767423"
                        ],
                        "name": "Robert C. Moore",
                        "slug": "Robert-C.-Moore",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Moore",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert C. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119117298"
                        ],
                        "name": "W. Lewis",
                        "slug": "W.-Lewis",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 186
                            }
                        ],
                        "text": "We consider three methods for extracting domaintargeted parallel data from a general corpus: sourceside cross-entropy (Cross-Ent), source-side crossentropy difference (Moore-Lewis) from (Moore and Lewis, 2010), and bilingual cross-entropy difference (bML), which is novel."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8170227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0482eeefa01c4cbf585f572c1fd4ed930ee222d2",
            "isKey": false,
            "numCitedBy": 547,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of selecting non-domain-specific language model training data to build auxiliary language models for use in tasks such as machine translation. Our approach is based on comparing the cross-entropy, according to domain-specific and non-domain-specifc language models, for each sentence of the text source used to produce the latter language model. We show that this produces better language models, trained on less data, than both random data selection and two other previously proposed methods."
            },
            "slug": "Intelligent-Selection-of-Language-Model-Training-Moore-Lewis",
            "title": {
                "fragments": [],
                "text": "Intelligent Selection of Language Model Training Data"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work addresses the problem of selecting non-domain-specific language model training data to build auxiliary language models for use in tasks such as machine translation by comparing the cross-entropy, according to domain-specific and non- domain-specifc language models, for each sentence of the text source used to produce the latter language model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683562"
                        ],
                        "name": "Preslav Nakov",
                        "slug": "Preslav-Nakov",
                        "structuredName": {
                            "firstName": "Preslav",
                            "lastName": "Nakov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Preslav Nakov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 8
                            }
                        ],
                        "text": "Unlike (Nakov, 2008), we explicitly did not attempt to resolve any overlap between the phrase tables, as there is no need to do so with the multiple decoding paths."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Nakov (2008) handled identical phrase pairs by prioritizing the source tables, however in our experience identical entries in phrase tables are not very common when comparing across domains."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 574916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b53e2a30f070a3bef3ca17a1872a70acfe478f9",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the experiments of the UC Berkeley team on improving English-Spanish machine translation of news text, as part of the WMT'08 Shared Translation Task. We experiment with domain adaptation, combining a small in-domain news bi-text and a large out-of-domain one from the Europarl corpus, building two separate phrase translation models and two separate language models. We further add a third phrase translation model trained on a version of the news bi-text augmented with monolingual sentence-level syntactic paraphrases on the source-language side, and we combine all models in a log-linear model using minimum error rate training. Finally, we experiment with different tokenization and recasing rules, achieving 35.09% Bleu score on the WMT'07 news test data when translating from English to Spanish, which is a sizable improvement over the highest Bleu score achieved on that dataset at WMT'07: 33.10% (in fact, by our system). On the WMT'08 English to Spanish news translation, we achieve 21.92%, which makes our team the second best on Bleu score."
            },
            "slug": "Improving-English-Spanish-Statistical-Machine-in-Nakov",
            "title": {
                "fragments": [],
                "text": "Improving English-Spanish Statistical Machine Translation: Experiments in Domain Adaptation, Sentence Paraphrasing, Tokenization, and Recasing"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "The experiments of the UC Berkeley team on improving English-Spanish machine translation of news text, as part of the WMT'08 Shared Translation Task, describe the experiments and experiment with domain adaptation, building two separate phrase translation models and two separate language models."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2458308"
                        ],
                        "name": "George F. Foster",
                        "slug": "George-F.-Foster",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Foster",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George F. Foster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2788842"
                        ],
                        "name": "Cyril Goutte",
                        "slug": "Cyril-Goutte",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Goutte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cyril Goutte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143937779"
                        ],
                        "name": "R. Kuhn",
                        "slug": "R.-Kuhn",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Kuhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kuhn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 168
                            }
                        ],
                        "text": "The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Foster et al (2010) do not mention what percentage of the corpus they select for their IR-baseline, but they concatenate the data to their in-domain corpus and report a decrease in performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Foster et al (2010) further perform this on extracted phrase pairs, not just sentences."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6996688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f83f4c72cd43eb99bde196ba33d034380fec3789",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not. This extends previous work on discriminative weighting by using a finer granularity, focusing on the properties of instances rather than corpus components, and using a simpler training procedure. We incorporate instance weighting into a mixture-model framework, and find that it yields consistent improvements over a wide range of baselines."
            },
            "slug": "Discriminative-Instance-Weighting-for-Domain-in-Foster-Goutte",
            "title": {
                "fragments": [],
                "text": "Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not is described."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120618881"
                        ],
                        "name": "S. Matsoukas",
                        "slug": "S.-Matsoukas",
                        "structuredName": {
                            "firstName": "Spyridon",
                            "lastName": "Matsoukas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Matsoukas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39509434"
                        ],
                        "name": "Antti-Veikko I. Rosti",
                        "slug": "Antti-Veikko-I.-Rosti",
                        "structuredName": {
                            "firstName": "Antti-Veikko",
                            "lastName": "Rosti",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antti-Veikko I. Rosti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40379722"
                        ],
                        "name": "Bing Zhang",
                        "slug": "Bing-Zhang",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bing Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 34
                            }
                        ],
                        "text": "A more general method is that of (Matsoukas et al., 2009), who assign a (possibly-zero) weight to each sentence in the large corpus and modify the empirical phrase counts accordingly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 46
                            }
                        ],
                        "text": "Additionally, the most effective features of (Matsoukas et al., 2009) were found to be meta-information about the source documents, which may not be available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7230183,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e923e85b2d491c37bac08258deff0af485ab71b9",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Current statistical machine translation (SMT) systems are trained on sentence-aligned and word-aligned parallel text collected from various sources. Translation model parameters are estimated from the word alignments, and the quality of the translations on a given test set depends on the parameter estimates. There are at least two factors affecting the parameter estimation: domain match and training data quality. This paper describes a novel approach for automatically detecting and down-weighing certain parts of the training corpus by assigning a weight to each sentence in the training bitext so as to optimize a discriminative objective function on a designated tuning set. This way, the proposed method can limit the negative effects of low quality training data, and can adapt the translation model to the domain of interest. It is shown that such discriminative corpus weights can provide significant improvements in Arabic-English translation on various conditions, using a state-of-the-art SMT system."
            },
            "slug": "Discriminative-Corpus-Weight-Estimation-for-Machine-Matsoukas-Rosti",
            "title": {
                "fragments": [],
                "text": "Discriminative Corpus Weight Estimation for Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel approach for automatically detecting and down-weighing certain parts of the training corpus by assigning a weight to each sentence in the training bitext so as to optimize a discriminative objective function on a designated tuning set is described."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14034092"
                        ],
                        "name": "K. Yasuda",
                        "slug": "K.-Yasuda",
                        "structuredName": {
                            "firstName": "Keiji",
                            "lastName": "Yasuda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yasuda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110005363"
                        ],
                        "name": "Ruiqiang Zhang",
                        "slug": "Ruiqiang-Zhang",
                        "structuredName": {
                            "firstName": "Ruiqiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruiqiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49659080"
                        ],
                        "name": "H. Yamamoto",
                        "slug": "H.-Yamamoto",
                        "structuredName": {
                            "firstName": "Hirofumi",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698363"
                        ],
                        "name": "E. Sumita",
                        "slug": "E.-Sumita",
                        "structuredName": {
                            "firstName": "Eiichiro",
                            "lastName": "Sumita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sumita"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 143
                            }
                        ],
                        "text": "The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 83
                            }
                        ],
                        "text": "Additional parallel data can be readily acquired, but at the cost of specificity: either the data is entirely unrelated to the task at hand, or the data is from a broad enough pool of topics and styles, such as the web, that any use this corpus may provide is due to its size, and not its relevance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12973103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7b1e437701b58081102a6799e95791d6405ff53",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Target task matched parallel corpora are required for statistical translation model training. However, training corpora sometimes include both target task matched and unmatched sentences. In such a case, training set selection can reduce the size of the translation model. In this paper, we propose a training set selection method for translation model training using linear translation model interpolation and a language model technique. According to the experimental results, the proposed method reduces the translation model size by 50% and improves BLEU score by 1.76% in comparison with a baseline training corpus usage."
            },
            "slug": "Method-of-Selecting-Training-Data-to-Build-a-and-Yasuda-Zhang",
            "title": {
                "fragments": [],
                "text": "Method of Selecting Training Data to Build a Compact and Efficient Translation Model"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A training set selection method for translation model training using linear translation model interpolation and a language model technique that reduces the translation model size by 50% and improves BLEU score by 1.76% in comparison with a baseline training corpus usage."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1904831"
                        ],
                        "name": "Yajuan L\u00fc",
                        "slug": "Yajuan-L\u00fc",
                        "structuredName": {
                            "firstName": "Yajuan",
                            "lastName": "L\u00fc",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yajuan L\u00fc"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110152686"
                        ],
                        "name": "Jin Huang",
                        "slug": "Jin-Huang",
                        "structuredName": {
                            "firstName": "Jin",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688015"
                        ],
                        "name": "Qun Liu",
                        "slug": "Qun-Liu",
                        "structuredName": {
                            "firstName": "Qun",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qun Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 116
                            }
                        ],
                        "text": "A common approach to managing multiple translation models is to interpolate them, as in (Foster and Kuhn, 2007) and (L\u00fc et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 117
                            }
                        ],
                        "text": "A common approach to managing multiple translation models is to interpolate them, as in (Foster and Kuhn, 2007) and (Lu\u0308 et al., 2007)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16591834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81164d7f2d676b6044888219426cbb248a020930",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Parallel corpus is an indispensable resource for translation model training in statistical machine translation (SMT). Instead of collecting more and more parallel training corpora, this paper aims to improve SMT performance by exploiting full potential of the existing parallel corpora. Two kinds of methods are proposed: offline data optimization and online model optimization. The offline method adapts the training data by redistributing the weight of each training sentence pairs. The online method adapts the translation model by redistributing the weight of each predefined submodels. Information retrieval model is used for the weighting scheme in both methods. Experimental results show that without using any additional resource, both methods can improve SMT performance significantly."
            },
            "slug": "Improving-Statistical-Machine-Translation-by-Data-L\u00fc-Huang",
            "title": {
                "fragments": [],
                "text": "Improving Statistical Machine Translation Performance by Training Data Selection and Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper aims to improve SMT performance by exploiting full potential of the existing parallel corpora by proposing offline data optimization and online model optimization."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152324671"
                        ],
                        "name": "J. Schroeder",
                        "slug": "J.-Schroeder",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "Schroeder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schroeder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 8
                            }
                        ],
                        "text": "Lastly, Koehn and Schroeder (2007) reported improvements from using multiple decoding paths (Birch et al., 2007) to pass both tables to the Moses SMT decoder (Koehn et al., 2003), instead of directly combining the phrase tables to perform domain adaptation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 81
                            }
                        ],
                        "text": "In this work, we directly compare the approaches of (Foster and Kuhn, 2007) and (Koehn and Schroeder, 2007) on the systems generated from the methods mentioned in Section 2.1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 32
                            }
                        ],
                        "text": "We next tested the approach in (Koehn and Schroeder, 2007), passing the two phrase tables directly to the decoder and tuning a system using both\nphrase tables in parallel."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9536363,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "195df0de3c4c181d26391dd73746c7aefe709ab6",
            "isKey": true,
            "numCitedBy": 374,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The special challenge of the WMT 2007 shared task was domain adaptation. We took this opportunity to experiment with various ways of adapting a statistical machine translation systems to a special domain (here: news commentary), when most of the training data is from a different domain (here: European Parliament speeches). This paper also gives a description of the submission of the University of Edinburgh to the shared task."
            },
            "slug": "Experiments-in-Domain-Adaptation-for-Statistical-Koehn-Schroeder",
            "title": {
                "fragments": [],
                "text": "Experiments in Domain Adaptation for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This paper gives a description of the submission of the University of Edinburgh to the WMT 2007 shared task, and experiments with various ways of adapting a statistical machine translation systems to a special domain."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2868598"
                        ],
                        "name": "Amittai Axelrod",
                        "slug": "Amittai-Axelrod",
                        "structuredName": {
                            "firstName": "Amittai",
                            "lastName": "Axelrod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amittai Axelrod"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 138
                            }
                        ],
                        "text": "We apply the method to machine translation, even though perplexity reduction has been shown to not correlate with translation performance (Axelrod, 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62249774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7b2656177ed5a35ee1d1dc7f1fa57da54ed14d6",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine translation systems, as a whole, are currently not able to use the output of linguistic tools, such as part-of-speech taggers, to effectively improve translation performance. However, a new language modeling technique, Factored Language Models can incorporate the additional linguistic information that is produced by these tools. In the field of automatic speech recognition, Factored Language Models smoothed with Generalized Parallel Backoff have been shown to significantly reduce language model perplexity. However, Factored Language Models have previously only been applied to statistical machine translation as part of a second-pass rescoring system. In this thesis, we show that a state-of-the-art phrase-based system using factored language models with generalized parallel backoff can improve performance over an identical system using trigram language models. These improvements can be seen both with the use of additional word features and without. The relative gain from the Factored Language Models increases with smaller training corpora, making this approach especially useful for domains with limited data."
            },
            "slug": "Factored-Language-Models-for-Statistical-Machine-Axelrod",
            "title": {
                "fragments": [],
                "text": "Factored Language Models for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a state-of-the-art phrase-based system using factored language models with generalized parallel backoff can improve performance over an identical system using trigram language models, both with the use of additional word features and without."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2458308"
                        ],
                        "name": "George F. Foster",
                        "slug": "George-F.-Foster",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Foster",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George F. Foster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143937779"
                        ],
                        "name": "R. Kuhn",
                        "slug": "R.-Kuhn",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Kuhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kuhn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 52
                            }
                        ],
                        "text": "In this work, we directly compare the approaches of (Foster and Kuhn, 2007) and (Koehn and Schroeder, 2007) on the systems generated from the methods mentioned in Section 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 88
                            }
                        ],
                        "text": "A common approach to managing multiple translation models is to interpolate them, as in (Foster and Kuhn, 2007) and (L\u00fc et al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1421053,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a0dba86c980d4ba5f881aea0239fa689084e6c5",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a mixture-model approach to adapting a Statistical Machine Translation System for new domains, using weights that depend on text distances to mixture components. We investigate a number of variants on this approach, including cross-domain versus dynamic adaptation; linear versus loglinear mixtures; language and translation model adaptation; different methods of assigning weights; and granularity of the source unit being adapted to. The best methods achieve gains of approximately one BLEU percentage point over a state-of-the art non-adapted baseline system."
            },
            "slug": "Mixture-Model-Adaptation-for-SMT-Foster-Kuhn",
            "title": {
                "fragments": [],
                "text": "Mixture-Model Adaptation for SMT"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A mixture-model approach to adapting a Statistical Machine Translation System for new domains, using weights that depend on text distances to mixture components to achieve gains of approximately one BLEU percentage point over a state-of-the art non-adapted baseline system is described."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 143
                            }
                        ],
                        "text": "The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5474833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f12451245667a85d0ee225a80880fc93c71cc8b",
            "isKey": false,
            "numCitedBy": 3304,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Often, the training procedure for statistical machine translation models is based on maximum likelihood or related criteria. A general problem of this approach is that there is only a loose relation to the final translation quality on unseen text. In this paper, we analyze various training criteria which directly optimize translation quality. These training criteria make use of recently proposed automatic evaluation metrics. We describe a new algorithm for efficient training an unsmoothed error count. We show that significantly better results can often be obtained if the final evaluation criterion is taken directly into account as part of the training procedure."
            },
            "slug": "Minimum-Error-Rate-Training-in-Statistical-Machine-Och",
            "title": {
                "fragments": [],
                "text": "Minimum Error Rate Training in Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that significantly better results can often be obtained if the final evaluation criterion is taken directly into account as part of the training procedure."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47608784"
                        ],
                        "name": "Matthias Eck",
                        "slug": "Matthias-Eck",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Eck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Eck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145247319"
                        ],
                        "name": "S. Vogel",
                        "slug": "S.-Vogel",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 88
                            }
                        ],
                        "text": "In practice, most practical systems also perform target-side language model adaptation (Eck et al., 2004); we eschew this in order to isolate the effects of translation model adaptation alone."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2375338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcf4ced6b5a253c7aec557c95e32d802eac9c414",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Language modeling is an important part for both speech recognition and machine translation systems. Adaptation has been successfully applied to language models for speech recognition. In this paper we present experiments concerning language model adaptation for statistical machine translation. We develop a method to adapt language models using information retrieval methods. The adapted language models drastically reduce perplexity over a general language model and we can show that it is possible to improve the translation quality of a statistical machine translation using those adapted language models instead of a general language model."
            },
            "slug": "Language-Model-Adaptation-for-Statistical-Machine-Eck-Vogel",
            "title": {
                "fragments": [],
                "text": "Language Model Adaptation for Statistical Machine Translation Based on Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A method to adapt language models using information retrieval methods is developed and it is shown that it is possible to improve the translation quality of a statistical machine translation using those adapted language models instead of a general language model."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800422"
                        ],
                        "name": "Jianfeng Gao",
                        "slug": "Jianfeng-Gao",
                        "structuredName": {
                            "firstName": "Jianfeng",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianfeng Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50126864"
                        ],
                        "name": "Joshua Goodman",
                        "slug": "Joshua-Goodman",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Goodman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua Goodman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8392859"
                        ],
                        "name": "Mingjing Li",
                        "slug": "Mingjing-Li",
                        "structuredName": {
                            "firstName": "Mingjing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingjing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 55
                            }
                        ],
                        "text": "This has been done for language modeling, including by Gao et al (2002), and more\nrecently by Moore and Lewis (2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 53
                            }
                        ],
                        "text": "However, parallel in-domain data is usually hard to find1, and so performance is assumed to be limited by the quantity of domain-specific training data used to build the model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a601640a709eb96e65d130ef8aac69e9ea3602d",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a unified approach to Chinese statistical language modeling (SLM). Applying SLM techniques like trigram language models to Chinese is challenging because (1) there is no standard definition of words in Chinese; (2) word boundaries are not marked by spaces; and (3) there is a dearth of training data. Our unified approach automatically and consistently gathers a high-quality training data set from the Web, creates a high-quality lexicon, segments the training data using this lexicon, and compresses the language model, all by using the maximum likelihood principle, which is consistent with trigram model training. We show that each of the methods leads to improvements over standard SLM, and that the combined method yields the best pinyin conversion result reported."
            },
            "slug": "Toward-a-unified-approach-to-statistical-language-Gao-Goodman",
            "title": {
                "fragments": [],
                "text": "Toward a unified approach to statistical language modeling for Chinese"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This article presents a unified approach to Chinese statistical language modeling, which automatically and consistently gathers a high-quality training data set from the Web, creates ahigh-quality lexicon, segments the training data using this Lexicon, and compresses the language model by using the maximum likelihood principle, which is consistent with trigram model training."
            },
            "venue": {
                "fragments": [],
                "text": "TALIP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152378023"
                        ],
                        "name": "Hieu T. Hoang",
                        "slug": "Hieu-T.-Hoang",
                        "structuredName": {
                            "firstName": "Hieu",
                            "lastName": "Hoang",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hieu T. Hoang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2539211"
                        ],
                        "name": "Alexandra Birch",
                        "slug": "Alexandra-Birch",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Birch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandra Birch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102811815"
                        ],
                        "name": "Marcello Federico",
                        "slug": "Marcello-Federico",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Federico",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcello Federico"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895952"
                        ],
                        "name": "N. Bertoldi",
                        "slug": "N.-Bertoldi",
                        "structuredName": {
                            "firstName": "Nicola",
                            "lastName": "Bertoldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Bertoldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46898156"
                        ],
                        "name": "Brooke Cowan",
                        "slug": "Brooke-Cowan",
                        "structuredName": {
                            "firstName": "Brooke",
                            "lastName": "Cowan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brooke Cowan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529583"
                        ],
                        "name": "Wade Shen",
                        "slug": "Wade-Shen",
                        "structuredName": {
                            "firstName": "Wade",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wade Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055137469"
                        ],
                        "name": "C. Moran",
                        "slug": "C.-Moran",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Moran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Moran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983801"
                        ],
                        "name": "R. Zens",
                        "slug": "R.-Zens",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143832874"
                        ],
                        "name": "Ondrej Bojar",
                        "slug": "Ondrej-Bojar",
                        "structuredName": {
                            "firstName": "Ondrej",
                            "lastName": "Bojar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ondrej Bojar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057195055"
                        ],
                        "name": "Alexandra Constantin",
                        "slug": "Alexandra-Constantin",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Constantin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandra Constantin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082901914"
                        ],
                        "name": "Evan Herbst",
                        "slug": "Evan-Herbst",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Herbst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan Herbst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 794019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ee2eab4c298c1824a9fb8799ad8eed21be38d21",
            "isKey": false,
            "numCitedBy": 5929,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an open-source toolkit for statistical machine translation whose novel contributions are (a) support for linguistically motivated factors, (b) confusion network decoding, and (c) efficient data formats for translation models and language models. In addition to the SMT decoder, the toolkit also includes a wide variety of tools for training, tuning and applying the system to many translation tasks."
            },
            "slug": "Moses:-Open-Source-Toolkit-for-Statistical-Machine-Koehn-Hoang",
            "title": {
                "fragments": [],
                "text": "Moses: Open Source Toolkit for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An open-source toolkit for statistical machine translation whose novel contributions are support for linguistically motivated factors, confusion network decoding, and efficient data formats for translation models and language models."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 163
                            }
                        ],
                        "text": "Equally, the general-domain corpus likely includes sentences that are so unlike the domain of the task that using them to train the model is probably more harmful than beneficial."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 180
                            }
                        ],
                        "text": "The only exception was the phrase table for the large out-of-domain system trained on 12m sentence pairs, which we trained on a cluster using a word-dependent HMM-based alignment (He, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5344007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ee147c1fbc4fb0ffab8eef08d90bf12e5a9a306",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a Bayesian Learning based method to train word dependent transition models for HMM based word alignment. We present word alignment results on the Canadian Hansards corpus as compared to the conventional HMM and IBM model 4. We show that this method gives consistent and significant alignment error rate (AER) reduction. We also conducted machine translation (MT) experiments on the Europarl corpus. MT results show that word alignment based on this method can be used in a phrase-based machine translation system to yield up to 1% absolute improvement in BLEU score, compared to a conventional HMM, and 0.8% compared to a IBM model 4 based word alignment."
            },
            "slug": "Using-Word-Dependent-Transition-Models-in-HMM-Based-He",
            "title": {
                "fragments": [],
                "text": "Using Word-Dependent Transition Models in HMM-Based Word Alignment for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A Bayesian Learning based method to train word dependent transition models for HMM based word alignment gives consistent and significant alignment error rate (AER) reduction and machine translation results show that word alignment can be used in a phrase-based machine translation system."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5219389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de2df29b0a0312de7270c3f5a0af6af5645cf91a",
            "isKey": false,
            "numCitedBy": 4471,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We present and compare various methods for computing word alignments using statistical or heuristic models. We consider the five alignment models presented in Brown, Della Pietra, Della Pietra, and Mercer (1993), the hidden Markov alignment model, smoothing techniques, and refinements. These statistical models are compared with two heuristic models based on the Dice coefficient. We present different methods for combining word alignments to perform a symmetrization of directed statistical alignment models. As evaluation criterion, we use the quality of the resulting Viterbi alignment compared to a manually produced reference alignment. We evaluate the models on the German-English Verbmobil task and the French-English Hansards task. We perform a detailed analysis of various design decisions of our statistical alignment system and evaluate these on training corpora of various sizes. An important result is that refined alignment models with a first-order dependence and a fertility model yield significantly better results than simple heuristic models. In the Appendix, we present an efficient training algorithm for the alignment models presented."
            },
            "slug": "A-Systematic-Comparison-of-Various-Statistical-Och-Ney",
            "title": {
                "fragments": [],
                "text": "A Systematic Comparison of Various Statistical Alignment Models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An important result is that refined alignment models with a first-order dependence and a fertility model yield significantly better results than simple heuristic models."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2539211"
                        ],
                        "name": "Alexandra Birch",
                        "slug": "Alexandra-Birch",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Birch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandra Birch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057788"
                        ],
                        "name": "M. Osborne",
                        "slug": "M.-Osborne",
                        "structuredName": {
                            "firstName": "Miles",
                            "lastName": "Osborne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Osborne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 93
                            }
                        ],
                        "text": "Lastly, Koehn and Schroeder (2007) reported improvements from using multiple decoding paths (Birch et al., 2007) to pass both tables to the Moses SMT decoder (Koehn et al., 2003), instead of directly combining the phrase tables to perform domain adaptation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 181
                            }
                        ],
                        "text": "We have also shown in passing that the linear interpolation of translation models may work less well for translation model adaptation than the multiple paths decoding technique of (Birch et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 667949,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e10ac9c2c8e54b8ae8a8b97330986210b654919e",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Combinatorial Categorial Grammar (CCG) supertags present phrase-based machine translation with an opportunity to access rich syntactic information at a word level. The challenge is incorporating this information into the translation process. Factored translation models allow the inclusion of supertags as a factor in the source or target language. We show that this results in an improvement in the quality of translation and that the value of syntactic supertags in flat structured phrase-based models is largely due to better local reorderings."
            },
            "slug": "CCG-Supertags-in-Factored-Statistical-Machine-Birch-Osborne",
            "title": {
                "fragments": [],
                "text": "CCG Supertags in Factored Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that the inclusion of supertags in Factored translation models results in an improvement in the quality of translation and that the value of syntactic super tags in flat structured phrase-based models is largely due to better local reorderings."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 42
                            }
                        ],
                        "text": "We used the SRI Language Modeling Toolkit (Stolcke, 2002) was used for LM training in all cases: corpus selection, MT tuning, and decoding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1988103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "399da68d3b97218b6c80262df7963baa89dcc71b",
            "isKey": false,
            "numCitedBy": 4997,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "SRILM is a collection of C++ libraries, executable programs, and helper scripts designed to allow both production of and experimentation with statistical language models for speech recognition and other applications. SRILM is freely available for noncommercial purposes. The toolkit supports creation and evaluation of a variety of language model types based on N-gram statistics, as well as several related tasks, such as statistical tagging and manipulation of N-best lists and word lattices. This paper summarizes the functionality of the toolkit and discusses its design and implementation, highlighting ease of rapid prototyping, reusability, and combinability of tools."
            },
            "slug": "SRILM-an-extensible-language-modeling-toolkit-Stolcke",
            "title": {
                "fragments": [],
                "text": "SRILM - an extensible language modeling toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The functionality of the SRILM toolkit is summarized and its design and implementation is discussed, highlighting ease of rapid prototyping, reusability, and combinability of tools."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643845523"
                        ],
                        "name": "F. ChenStanley",
                        "slug": "F.-ChenStanley",
                        "structuredName": {
                            "firstName": "F",
                            "lastName": "ChenStanley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. ChenStanley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643789739"
                        ],
                        "name": "GoodmanJoshua",
                        "slug": "GoodmanJoshua",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "GoodmanJoshua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "GoodmanJoshua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 87
                            }
                        ],
                        "text": "We constructed 4gram language models with interpolated modified Kneser-Ney discounting (Chen and Goodman, 1998), and set the GoodTuring threshold to 1 for trigrams."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 215842252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4e8bed3b50a035e1eabad614fe4218a34b3b178",
            "isKey": false,
            "numCitedBy": 2861,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "We survey the most widely-used algorithms for smoothing models for language n -gram modeling. We then present an extensive empirical comparison of several of these smoothing techniques, including t..."
            },
            "slug": "An-empirical-study-of-smoothing-techniques-for-ChenStanley-GoodmanJoshua",
            "title": {
                "fragments": [],
                "text": "An empirical study of smoothing techniques for language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A survey of the most widely-used algorithms for smoothing models for language n -gram modeling and an extensive empirical comparison of several of these smoothing techniques are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 53
                            }
                        ],
                        "text": "In this work, we directly compare the approaches of (Foster and Kuhn, 2007) and (Koehn and Schroeder, 2007) on the systems generated from the methods mentioned in Section 2.1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Foster and Kuhn (2007) interpolated the in- and general-domain phrase tables together, assigning either linear or log-linear weights to the entries in the tables before combining overlapping entries; this is now standard practice."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 89
                            }
                        ],
                        "text": "A common approach to managing multiple translation models is to interpolate them, as in (Foster and Kuhn, 2007) and (Lu\u0308 et al., 2007)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mixture-Model Adaptation for SMT. Workshop on Statistical Machine Translation, Association for Computational Linguis- tics"
            },
            "venue": {
                "fragments": [],
                "text": "Mixture-Model Adaptation for SMT. Workshop on Statistical Machine Translation, Association for Computational Linguis- tics"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 105
                            }
                        ],
                        "text": "The task of domain adaptation is to translate a text in a particular (target) domain for which only a small amount of training data is available, using an MT system trained on a larger set of data that is not restricted to the target domain."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Foster et al (2010) further perform this on extracted phrase pairs, not just sentences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Foster et al (2010) do not mention what percentage of the corpus they select for their IR-baseline, but they concatenate the data to their in-domain corpus and report a decrease in performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 108
                            }
                        ],
                        "text": "Additional parallel data can be readily acquired, but at the cost of specificity: either the data is entirely unrelated to the task at hand, or the data is from a broad enough pool of topics and styles, such as the web, that any use this corpus may provide is due to its size, and not its relevance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 168
                            }
                        ],
                        "text": "The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminative Instatnce Weighting for Domain Adaptation in Statistical Machine Translation"
            },
            "venue": {
                "fragments": [],
                "text": "Empirical Methods in Natural Language Processing."
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 93
                            }
                        ],
                        "text": "Lastly, Koehn and Schroeder (2007) reported improvements from using multiple decoding paths (Birch et al., 2007) to pass both tables to the Moses SMT decoder (Koehn et al., 2003), instead of directly combining the phrase tables to perform domain adaptation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 181
                            }
                        ],
                        "text": "We have also shown in passing that the linear interpolation of translation models may work less well for translation model adaptation than the multiple paths decoding technique of (Birch et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 92
                            }
                        ],
                        "text": "Lastly, Koehn and Schroeder (2007) reported improvements from using multiple decoding paths (Birch et al., 2007) to pass both tables to the Moses SMT decoder (Koehn et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CCG Supertags in Factored Translation Models"
            },
            "venue": {
                "fragments": [],
                "text": "Workshop on Statistical Machine Translation, Association for Computational Linguistics."
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 93
                            }
                        ],
                        "text": "Lastly, Koehn and Schroeder (2007) reported improvements from using multiple decoding paths (Birch et al., 2007) to pass both tables to the Moses SMT decoder (Koehn et al., 2003), instead of directly combining the phrase tables to perform domain adaptation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 181
                            }
                        ],
                        "text": "We have also shown in passing that the linear interpolation of translation models may work less well for translation model adaptation than the multiple paths decoding technique of (Birch et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CCG Supertags in Factored Translation Models. Workshop on Statistical Machine Translation"
            },
            "venue": {
                "fragments": [],
                "text": "CCG Supertags in Factored Translation Models. Workshop on Statistical Machine Translation"
            },
            "year": 2007
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 18
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 22,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Domain-Adaptation-via-Pseudo-In-Domain-Data-Axelrod-He/396aabd694da04cdb846cb724ca9f866f345cbd5?sort=total-citations"
}