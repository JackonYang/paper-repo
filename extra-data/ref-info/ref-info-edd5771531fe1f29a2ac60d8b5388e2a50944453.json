{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2861627"
                        ],
                        "name": "Iddo Drori",
                        "slug": "Iddo-Drori",
                        "structuredName": {
                            "firstName": "Iddo",
                            "lastName": "Drori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iddo Drori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388323541"
                        ],
                        "name": "D. Cohen-Or",
                        "slug": "D.-Cohen-Or",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cohen-Or",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cohen-Or"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47620675"
                        ],
                        "name": "Y. Yeshurun",
                        "slug": "Y.-Yeshurun",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Yeshurun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yeshurun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 72
                            }
                        ],
                        "text": "While previous algorithms [Efros and Leung 1999; Criminisi et al. 2003; Drori et al. 2003; Wilczkowiak et al. 2005] suggest clever ways to reuse visual data within the source image, we demonstrate the benefits of utilizing semantically valid data from a large, unordered collection of unlabelled\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 14
                            }
                        ],
                        "text": "Some methods [Drori et al. 2003; Wilczkowiak et al. 2005] search additional scales and orientations to gain additional source texture samples."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 61
                            }
                        ],
                        "text": "The most successful existing methods [Criminisi et al. 2003; Drori et al. 2003; Wexler et al. 2004; Wilczkowiak et al. 2005; Komodakis 2006] operate by extending adjacent textures and contours into the unknown region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 110
                            }
                        ],
                        "text": "Even in the single image case, some existing methods report running times in the hours [Efros and Leung 1999; Drori et al. 2003] because of the slow texture search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 26
                            }
                        ],
                        "text": "While previous algorithms [Efros and Leung 1999; Criminisi et al. 2003; Drori et al. 2003; Wilczkowiak et al. 2005] suggest clever ways to reuse visual data within the source image, we demonstrate the benefits of utilizing semantically valid data from a large, unordered collection of unlabelled images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6464014,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6eb28cb2368c5196cb6cc5a144cb3e4593c96db5",
            "isKey": true,
            "numCitedBy": 662,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for completing missing parts caused by the removal of foreground or background elements from an image. Our goal is to synthesize a complete, visually plausible and coherent image. The visible parts of the image serve as a training set to infer the unknown parts. Our method iteratively approximates the unknown regions and composites adaptive image fragments into the image. Values of an inverse matte are used to compute a confidence map and a level set that direct an incremental traversal within the unknown area from high to low confidence. In each step, guided by a fast smooth approximation, an image fragment is selected from the most similar and frequent examples. As the selected fragments are composited, their likelihood increases along with the mean confidence of the image, until reaching a complete image. We demonstrate our method by completion of photographs and paintings."
            },
            "slug": "Fragment-based-image-completion-Drori-Cohen-Or",
            "title": {
                "fragments": [],
                "text": "Fragment-based image completion"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new method for completing missing parts caused by the removal of foreground or background elements from an image, iteratively approximating the unknown regions and composites adaptive image fragments into the image to synthesize a complete, visually plausible and coherent image."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9789787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f97938382963c828fe0b3882528d373afa8bfd8",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual system is remarkably tolerant to degradations in image resolution: in a scene recognition task, human performance is similar whether 32 \u00d7 32 color images or multi-mega pixel images are used. With small images, even object recognition and segmentation is performed robustly by the visual system, despite the object being unrecognizable in isolation. Motivated by these observations, we explore the space of 32 \u00d7 32 images using a database of 10 32\u00d7 32 color images gathered from the Internet using image search engines. Each image is loosely labeled with one of the 70, 399 non-abstract nouns in English, as listed in the Wordnet lexical database. Hence the image database represents a dense sampling of all object categories and scenes. With this dataset, we use nearest neighbor methods to perform object recognition across the 10 images."
            },
            "slug": "Tiny-images-Fergus-Freeman",
            "title": {
                "fragments": [],
                "text": "Tiny images"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work explores the space of 32 \u00d7 32 images using a database of 10 32\u00d7 32 color images gathered from the Internet using image search engines and uses nearest neighbor methods to perform object recognition across the 10 images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143945334"
                        ],
                        "name": "Matthew Johnson",
                        "slug": "Matthew-Johnson",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3309893"
                        ],
                        "name": "G. Brostow",
                        "slug": "G.-Brostow",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Brostow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Brostow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143774737"
                        ],
                        "name": "J. Shotton",
                        "slug": "J.-Shotton",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Shotton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shotton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695435"
                        ],
                        "name": "Ognjen Arandjelovic",
                        "slug": "Ognjen-Arandjelovic",
                        "structuredName": {
                            "firstName": "Ognjen",
                            "lastName": "Arandjelovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ognjen Arandjelovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706355"
                        ],
                        "name": "Vivek Kwatra",
                        "slug": "Vivek-Kwatra",
                        "structuredName": {
                            "firstName": "Vivek",
                            "lastName": "Kwatra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vivek Kwatra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 105
                            }
                        ],
                        "text": "However, the database labelling process must be supervised [Diakopoulos et al. 2004] or semi-supervised [Johnson et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 176
                            }
                        ],
                        "text": "Also related are methods which synthesize semantically valid images either from text or image constraints using image databases with labelled regions [Diakopoulos et al. 2004; Johnson et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 206
                            }
                        ],
                        "text": "Our scene matching, in combination with our large database, allows us to do image completion without resorting to explicit semantic constraints as in previous photo synthesis work [Diakopoulos et al. 2004; Johnson et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 249839,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "3556f5d043f1199f95fede9b38ab711e4d7281ae",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Composite images are synthesized from existing photographs by artists who make concept art, e.g., storyboards for movies or architectural planning. Current techniques allow an artist to fabricate such an image by digitally splicing parts of stock photographs. While these images serve mainly to \u201cquickly\u201dconvey how a scene should look, their production is laborious. We propose a technique that allows a person to design a new photograph with substantially less effort. This paper presents a method that generates a composite image when a user types in nouns, such as \u201cboat\u201dand \u201csand.\u201dThe artist can optionally design an intended image by specifying other constraints. Our algorithm formulates the constraints as queries to search an automatically annotated image database. The desired photograph, not a collage, is then synthesized using graph\u2010cut optimization, optionally allowing for further user interaction to edit or choose among alternative generated photos. An implementation of our approach, shown in the associated video, demonstrates our contributions of (1) a method for creating specific images with minimal human effort, and (2) a combined algorithm for automatically building an image library with semantic annotations from any photo collection."
            },
            "slug": "Semantic-Photo-Synthesis-Johnson-Brostow",
            "title": {
                "fragments": [],
                "text": "Semantic Photo Synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A method that generates a composite image when a user types in nouns, such as \u201cboat\u201d and \u201csand\u201d is presented, and a combined algorithm for automatically building an image library with semantic annotations from any photo collection is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Forum"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830653"
                        ],
                        "name": "Noah Snavely",
                        "slug": "Noah-Snavely",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Snavely",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah Snavely"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679223"
                        ],
                        "name": "S. Seitz",
                        "slug": "S.-Seitz",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Seitz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 275
                            }
                        ],
                        "text": "\u2026attempting an accurate reconstruction have to use some other source of data in addition to the input image, such as video (using various background stabilization techniques, e.g. [Irani et al. 1995]) or multiple photographs of the same physical scene [Agarwala et al. 2004; Snavely et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 58
                            }
                        ],
                        "text": "1995]) or multiple photographs of the same physical scene [Agarwala et al. 2004; Snavely et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13385757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5ebf37ce170f13a905f7feba9fb7096b49fb8b3",
            "isKey": false,
            "numCitedBy": 3204,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for interactively browsing and exploring large unstructured collections of photographs of a scene using a novel 3D interface. Our system consists of an image-based modeling front end that automatically computes the viewpoint of each photograph as well as a sparse 3D model of the scene and image to model correspondences. Our photo explorer uses image-based rendering techniques to smoothly transition between photographs, while also enabling full 3D navigation and exploration of the set of images and world geometry, along with auxiliary information such as overhead maps. Our system also makes it easy to construct photo tours of scenic or historic locations, and to annotate image details, which are automatically transferred to other relevant images. We demonstrate our system on several large personal photo collections as well as images gathered from Internet photo sharing sites."
            },
            "slug": "Photo-tourism:-exploring-photo-collections-in-3D-Snavely-Seitz",
            "title": {
                "fragments": [],
                "text": "Photo tourism: exploring photo collections in 3D"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work presents a system for interactively browsing and exploring large unstructured collections of photographs of a scene using a novel 3D interface that consists of an image-based modeling front end that automatically computes the viewpoint of each photograph and a sparse 3D model of the scene and image to model correspondences."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152147500"
                        ],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2130222410"
                        ],
                        "name": "Lu Yuan",
                        "slug": "Lu-Yuan",
                        "structuredName": {
                            "firstName": "Lu",
                            "lastName": "Yuan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lu Yuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729056"
                        ],
                        "name": "Jiaya Jia",
                        "slug": "Jiaya-Jia",
                        "structuredName": {
                            "firstName": "Jiaya",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiaya Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154486"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 283
                            }
                        ],
                        "text": "\u2026texture synthesis [Efros and Leung 1999; Efros and Freeman 2001; Kwatra et al. 2003; Kwatra et al. 2005], sometimes with additional constraints to explicitly preserve Gestalt cues such as good continuation [Wertheimer 1938], either automatically [Criminisi et al. 2003] or by hand [Sun et al. 2005]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 44067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e0c05cf93ac52a0d91a5cf792e8bc6c04ce071e",
            "isKey": false,
            "numCitedBy": 512,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we introduce a novel approach to image completion, which we call structure propagation. In our system, the user manually specifies important missing structure information by extending a few curves or line segments from the known to the unknown regions. Our approach synthesizes image patches along these user-specified curves in the unknown region using patches selected around the curves in the known region. Structure propagation is formulated as a global optimization problem by enforcing structure and consistency constraints. If only a single curve is specified, structure propagation is solved using Dynamic Programming. When multiple intersecting curves are specified, we adopt the Belief Propagation algorithm to find the optimal patches. After completing structure propagation, we fill in the remaining unknown regions using patch-based texture synthesis. We show that our approach works well on a number of examples that are challenging to state-of-the-art techniques."
            },
            "slug": "Image-completion-with-structure-propagation-Sun-Yuan",
            "title": {
                "fragments": [],
                "text": "Image completion with structure propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper introduces a novel approach to image completion in which the user manually specifies important missing structure information by extending a few curves or line segments from the known to the unknown regions by adopting the Belief Propagation algorithm to find the optimal patches."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2943892"
                        ],
                        "name": "N. Diakopoulos",
                        "slug": "N.-Diakopoulos",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Diakopoulos",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Diakopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21472040"
                        ],
                        "name": "Irfan Essa",
                        "slug": "Irfan-Essa",
                        "structuredName": {
                            "firstName": "Irfan",
                            "lastName": "Essa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irfan Essa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 60
                            }
                        ],
                        "text": "However, the database labelling process must be supervised [Diakopoulos et al. 2004] or semi-supervised [Johnson et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 151
                            }
                        ],
                        "text": "Also related are methods which synthesize semantically valid images either from text or image constraints using image databases with labelled regions [Diakopoulos et al. 2004; Johnson et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 181
                            }
                        ],
                        "text": "Our scene matching, in combination with our large database, allows us to do image completion without resorting to explicit semantic constraints as in previous photo synthesis work [Diakopoulos et al. 2004; Johnson et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 59
                            }
                        ],
                        "text": "However, the database labelling process must be supervised [Diakopoulos et al. 2004] or semi-supervised [Johnson et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1439166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b3f290ba65b38e0fc152b1b5ad5e8c4f10eacf6",
            "isKey": true,
            "numCitedBy": 33,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method allowing for semantically guided image editing and synthesis is introduced. The editing process is made considerably easier and more powerful with our content-aware tool. We construct a database of image regions annotated with a carefully chosen vocabulary and utilize recent advances in texture synthesis algorithms to generate new and unique image regions from this database of material. These new regions are then seamlessly composited into a user\u2019s existing photograph. The goal is to empower the end user with the ability to edit existing photographs and synthesize new ones on a high semantic level. Plausible results are generated using a small prototype database and showcase some of the editing possibilities that such a system affords."
            },
            "slug": "Content-Based-Image-Synthesis-Diakopoulos-Essa",
            "title": {
                "fragments": [],
                "text": "Content Based Image Synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A new method allowing for semantically guided image editing and synthesis is introduced and the goal is to empower the end user with the ability to edit existing photographs and synthesize new ones on a high semantic level."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144565371"
                        ],
                        "name": "P. P\u00e9rez",
                        "slug": "P.-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P\u00e9rez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769685"
                        ],
                        "name": "K. Toyama",
                        "slug": "K.-Toyama",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Toyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Toyama"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 49
                            }
                        ],
                        "text": "While previous algorithms [Efros and Leung 1999; Criminisi et al. 2003; Drori et al. 2003; Wilczkowiak et al. 2005] suggest clever ways to reuse visual data within the source image, we demonstrate the benefits of utilizing semantically valid data from a large, unordered collection of unlabelled\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 182
                            }
                        ],
                        "text": "Therefore, to evaluate our method, we performed an IRBapproved perceptual study to see how well naive viewers could distinguish our results, as well as those of a previous approach [Criminisi et al. 2003], from real photographs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 147
                            }
                        ],
                        "text": "2005], sometimes with additional constraints to explicitly preserve Gestalt cues such as good continuation [Wertheimer 1938], either automatically [Criminisi et al. 2003] or by hand [Sun et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 38
                            }
                        ],
                        "text": "The most successful existing methods [Criminisi et al. 2003; Drori et al. 2003; Wexler et al. 2004; Wilczkowiak et al. 2005; Komodakis 2006] operate by extending adjacent textures and contours into the unknown region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 248
                            }
                        ],
                        "text": "\u2026texture synthesis [Efros and Leung 1999; Efros and Freeman 2001; Kwatra et al. 2003; Kwatra et al. 2005], sometimes with additional constraints to explicitly preserve Gestalt cues such as good continuation [Wertheimer 1938], either automatically [Criminisi et al. 2003] or by hand [Sun et al. 2005]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 26
                            }
                        ],
                        "text": "While previous algorithms [Efros and Leung 1999; Criminisi et al. 2003; Drori et al. 2003; Wilczkowiak et al. 2005] suggest clever ways to reuse visual data within the source image, we demonstrate the benefits of utilizing semantically valid data from a large, unordered collection of unlabelled images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 34
                            }
                        ],
                        "text": "Past image completion algorithms [Criminisi et al. 2003] have treated the remaining valid pixels in an image as hard constraints which are not changed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 315138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "077380a6e1bcfcefc3036a208fffaa26713a1f03",
            "isKey": true,
            "numCitedBy": 1007,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "A new algorithm is proposed for removing large objects from digital images. The challenge is to fill in the hole that is left behind in a visually plausible way. In the past, this problem has been addressed by two classes of algorithms: (i) \"texture synthesis\" algorithms for generating large image regions from sample textures, and (ii) \"inpainting\" techniques for filling in small image gaps. The former work well for \"textures\" - repeating two dimensional patterns with some stochasticity; the latter focus on linear \"structures\" which can be thought of as one dimensional patterns, such as lines and object contours. This paper presents a novel and efficient algorithm that combines the advantages of these two approaches. We first note that exemplar-based texture synthesis contains the essential process required to replicate both texture and structure; the success of structure propagation, however, is highly dependent on the order in which the filling proceeds. We propose a best-first algorithm in which the confidence in the synthesized pixel values is propagated in a manner similar to the propagation of information in inpainting. The actual color values are computed using exemplar-based synthesis. Computational efficiency is achieved by a block-based sampling process. A number of examples on real and synthetic images demonstrate the effectiveness of our algorithm in removing large occluding objects as well as thin scratches. Robustness with respect to the shape of the manually selected target region is also demonstrated. Our results compare favorably to those obtained by existing techniques."
            },
            "slug": "Object-removal-by-exemplar-based-inpainting-Criminisi-P\u00e9rez",
            "title": {
                "fragments": [],
                "text": "Object removal by exemplar-based inpainting"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A best-first algorithm in which the confidence in the synthesized pixel values is propagated in a manner similar to the propagation of information in inpainting, which demonstrates the effectiveness of the algorithm in removing large occluding objects as well as thin scratches."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696487"
                        ],
                        "name": "A. Agarwala",
                        "slug": "A.-Agarwala",
                        "structuredName": {
                            "firstName": "Aseem",
                            "lastName": "Agarwala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2875493"
                        ],
                        "name": "Mira Dontcheva",
                        "slug": "Mira-Dontcheva",
                        "structuredName": {
                            "firstName": "Mira",
                            "lastName": "Dontcheva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mira Dontcheva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820412"
                        ],
                        "name": "Maneesh Agrawala",
                        "slug": "Maneesh-Agrawala",
                        "structuredName": {
                            "firstName": "Maneesh",
                            "lastName": "Agrawala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maneesh Agrawala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2311676"
                        ],
                        "name": "S. Drucker",
                        "slug": "S.-Drucker",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Drucker",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Drucker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143792576"
                        ],
                        "name": "Alex Colburn",
                        "slug": "Alex-Colburn",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Colburn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Colburn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800609"
                        ],
                        "name": "B. Curless",
                        "slug": "B.-Curless",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Curless",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Curless"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400248273"
                        ],
                        "name": "Michael F. Cohen",
                        "slug": "Michael-F.-Cohen",
                        "structuredName": {
                            "firstName": "Michael F.",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael F. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 253
                            }
                        ],
                        "text": "\u2026attempting an accurate reconstruction have to use some other source of data in addition to the input image, such as video (using various background stabilization techniques, e.g. [Irani et al. 1995]) or multiple photographs of the same physical scene [Agarwala et al. 2004; Snavely et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 66
                            }
                        ],
                        "text": "A very similar metric was also mentioned but not demonstrated in [Agarwala et al. 2004]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 58
                            }
                        ],
                        "text": "1995]) or multiple photographs of the same physical scene [Agarwala et al. 2004; Snavely et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5699077,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "82b9ec4ab1d3488ed4af81216810ec20a60177b3",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an interactive, computer-assisted framework for combining parts of a set of photographs into a single composite picture, a process we call \"digital photomontage.\" Our framework makes use of two techniques primarily: graph-cut optimization, to choose good seams within the constituent images so that they can be combined as seamlessly as possible; and gradient-domain fusion, a process based on Poisson equations, to further reduce any remaining visible artifacts in the composite. Also central to the framework is a suite of interactive tools that allow the user to specify a variety of high-level image objectives, either globally across the image, or locally through a painting-style interface. Image objectives are applied independently at each pixel location and generally involve a function of the pixel values (such as \"maximum contrast\") drawn from that same location in the set of source images. Typically, a user applies a series of image objectives iteratively in order to create a finished composite. The power of this framework lies in its generality; we show how it can be used for a wide variety of applications, including \"selective composites\" (for instance, group photos in which everyone looks their best), relighting, extended depth of field, panoramic stitching, clean-plate production, stroboscopic visualization of movement, and time-lapse mosaics."
            },
            "slug": "Interactive-digital-photomontage-Agarwala-Dontcheva",
            "title": {
                "fragments": [],
                "text": "Interactive digital photomontage"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The framework makes use of two techniques primarily: graph-cut optimization, to choose good seams within the constituent images so that they can be combined as seamlessly as possible; and gradient-domain fusion, a process based on Poisson equations, to further reduce any remaining visible artifacts in the composite."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2505902"
                        ],
                        "name": "N. Komodakis",
                        "slug": "N.-Komodakis",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Komodakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Komodakis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 125
                            }
                        ],
                        "text": "The most successful existing methods [Criminisi et al. 2003; Drori et al. 2003; Wexler et al. 2004; Wilczkowiak et al. 2005; Komodakis 2006] operate by extending adjacent textures and contours into the unknown region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16805695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dadc3e91d38a691202b39835dfb5108c28f01c35",
            "isKey": false,
            "numCitedBy": 270,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A new exemplar-based framework unifying image completion, texture synthesis and image inpainting is presented in this work. Contrary to existing greedy techniques, these tasks are posed in the form of a discrete global optimization problem with a well defined objective function. For solving this problem a novel optimization scheme, called Priority- BP, is proposed which carries two very important extensions over standard belief propagation (BP): \"prioritybased message scheduling\" and \"dynamic label pruning\". These two extensions work in cooperation to deal with the intolerable computational cost of BP caused by the huge number of existing labels. Moreover, both extensions are generic and can therefore be applied to any MRF energy function as well. The effectiveness of our method is demonstrated on a wide variety of image completion examples."
            },
            "slug": "Image-Completion-Using-Global-Optimization-Komodakis",
            "title": {
                "fragments": [],
                "text": "Image Completion Using Global Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A new exemplar-based framework unifying image completion, texture synthesis and image inpainting is presented, which carries two very important extensions over standard belief propagation (BP): \"prioritybased message scheduling\" and \"dynamic label pruning\"."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706355"
                        ],
                        "name": "Vivek Kwatra",
                        "slug": "Vivek-Kwatra",
                        "structuredName": {
                            "firstName": "Vivek",
                            "lastName": "Kwatra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vivek Kwatra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39685930"
                        ],
                        "name": "A. Sch\u00f6dl",
                        "slug": "A.-Sch\u00f6dl",
                        "structuredName": {
                            "firstName": "Arno",
                            "lastName": "Sch\u00f6dl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sch\u00f6dl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21472040"
                        ],
                        "name": "Irfan Essa",
                        "slug": "Irfan-Essa",
                        "structuredName": {
                            "firstName": "Irfan",
                            "lastName": "Essa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irfan Essa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713189"
                        ],
                        "name": "Greg Turk",
                        "slug": "Greg-Turk",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Turk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 58
                            }
                        ],
                        "text": "This idea is derived from example-based texture synthesis [Efros and Leung 1999; Efros and Freeman 2001; Kwatra et al. 2003; Kwatra et al. 2005], sometimes with additional constraints to explicitly preserve Gestalt cues such as good continuation [Wertheimer 1938], either automatically [Criminisi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 105
                            }
                        ],
                        "text": "This idea is derived from example-based texture synthesis [Efros and Leung 1999; Efros and Freeman 2001; Kwatra et al. 2003; Kwatra et al. 2005], sometimes with additional constraints to explicitly preserve Gestalt cues such as good continuation [Wertheimer 1938], either automatically [Criminisi et\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 121
                            }
                        ],
                        "text": "We composite each matching scene into the incomplete image at its best placement using a form of graph cut seam finding [Kwatra et al. 2003] and standard poisson blending [Perez et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 120
                            }
                        ],
                        "text": "We composite each matching scene into the incomplete image at its best placement using a form of graph cut seam finding [Kwatra et al. 2003] and standard poisson blending [Perez et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6175301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55c3ecb47aebba55a9de761c0e4dc0fd6d8d28b0",
            "isKey": true,
            "numCitedBy": 1556,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we introduce a new algorithm for image and video texture synthesis. In our approach, patch regions from a sample image or video are transformed and copied to the output and then stitched together along optimal seams to generate a new (and typically larger) output. In contrast to other techniques, the size of the patch is not chosen a-priori, but instead a graph cut technique is used to determine the optimal patch region for any given offset between the input and output texture. Unlike dynamic programming, our graph cut technique for seam optimization is applicable in any dimension. We specifically explore it in 2D and 3D to perform video texture synthesis in addition to regular image synthesis. We present approximative offset search techniques that work well in conjunction with the presented patch size optimization. We show results for synthesizing regular, random, and natural images and videos. We also demonstrate how this method can be used to interactively merge different images to generate new scenes."
            },
            "slug": "Graphcut-textures:-image-and-video-synthesis-using-Kwatra-Sch\u00f6dl",
            "title": {
                "fragments": [],
                "text": "Graphcut textures: image and video synthesis using graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A new algorithm for image and video texture synthesis where patch regions from a sample image or video are transformed and copied to the output and then stitched together along optimal seams to generate a new (and typically larger) output."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2003
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 0,
        "totalPages": 0
    },
    "page_url": "https://www.semanticscholar.org/paper/Scene-completion-using-millions-of-photographs-Hays-Efros/edd5771531fe1f29a2ac60d8b5388e2a50944453?sort=total-citations"
}