{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49967661"
                        ],
                        "name": "B. Rost",
                        "slug": "B.-Rost",
                        "structuredName": {
                            "firstName": "Burkhard",
                            "lastName": "Rost",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rost"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882390"
                        ],
                        "name": "C. Sander",
                        "slug": "C.-Sander",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Sander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 9
                            }
                        ],
                        "text": "Rost and Sander 1993b; 1993a started with Qian and\nSejnowski's architecture, but used two methods to ad-dress the over tting problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 148
                            }
                        ],
                        "text": "Althoughtests made on di erent data sets can be hard to compare,the method of Rost and Sander (which resulted in thePHD prediction server (Rost and Sander, 1993b; 1993a;1994)) still reaches the top levels of prediction accuracy(about 72%, measured using 7-fold cross validation)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1530760,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "4a55757c8f347bb232cf95187a48abe38c4fcbb1",
            "isKey": false,
            "numCitedBy": 521,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The explosive accumulation of protein sequences in the wake of large-scale sequencing projects is in stark contrast to the much slower experimental determination of protein structures. Improved methods of structure prediction from the gene sequence alone are therefore needed. Here, we report a substantial increase in both the accuracy and quality of secondary-structure predictions, using a neural-network algorithm. The main improvements come from the use of multiple sequence alignments (better overall accuracy), from \"balanced training\" (better prediction of beta-strands), and from \"structure context training\" (better prediction of helix and strand lengths). This method, cross-validated on seven different test sets purged of sequence similarity to learning sets, achieves a three-state prediction accuracy of 69.7%, significantly better than previous methods. In addition, the predicted structures have a more realistic distribution of helix and strand segments. The predictions may be suitable for use in practice as a first estimate of the structural type of newly sequenced proteins."
            },
            "slug": "Improved-prediction-of-protein-secondary-structure-Rost-Sander",
            "title": {
                "fragments": [],
                "text": "Improved prediction of protein secondary structure by use of sequence profiles and neural networks."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A substantial increase in both the accuracy and quality of secondary-structure predictions, using a neural-network algorithm, and the predicted structures have a more realistic distribution of helix and strand segments."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49967661"
                        ],
                        "name": "B. Rost",
                        "slug": "B.-Rost",
                        "structuredName": {
                            "firstName": "Burkhard",
                            "lastName": "Rost",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rost"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882390"
                        ],
                        "name": "C. Sander",
                        "slug": "C.-Sander",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Sander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 9
                            }
                        ],
                        "text": "Rost and Sander 1993b; 1993a started with Qian and\nSejnowski's architecture, but used two methods to ad-dress the over tting problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 148
                            }
                        ],
                        "text": "Althoughtests made on di erent data sets can be hard to compare,the method of Rost and Sander (which resulted in thePHD prediction server (Rost and Sander, 1993b; 1993a;1994)) still reaches the top levels of prediction accuracy(about 72%, measured using 7-fold cross validation)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15203189,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3247ca84941424412f98e926398dd36472c53b27",
            "isKey": false,
            "numCitedBy": 1466,
            "numCiting": 149,
            "paperAbstract": {
                "fragments": [],
                "text": "Using evolutionary information contained in multiple sequence alignments as input to neural networks, secondary structure can be predicted at significantly increased accuracy. Here, we extend our previous three\u2010level system of neural networks by using additional input information derived from multiple alignments. Using a position\u2010specific conservation weight as part of the input increases performance. Using the number of insertions and deletions reduces the tendency for overprediction and increases overall accuracy. Addition of the global amino acid content yields a further improvement, mainly in predicting structural class. The final network system has a sustained overall accuracy of 71.6% in a multiple cross\u2010validation test on 126 unique protein chains. A test on a new set of 124 recently solved protein structures that have no significant sequence similarity to the learning set confirms the high level of accuracy. The average cross\u2010validated accuracy for all 250 sequence\u2010unique chains is above 72%. Using various data sets, the method is compared to alternative prediction methods, some of which also use multiple alignments: the performance advantage of the network system is at least 6 percentage points in three\u2010state accuracy. In addition, the network estimates secondary structure content from multiple sequence alignments about as well as circular dichroism spectroscopy on a single protein and classifies 75% of the 250 proteins correctly into one of four protein structural classes. Of particular practical importance is the definition of a position\u2010specific reliability index. For 40% of all residues the method has a sustained three\u2010state accuracy of 88%, as high as the overall average for homology modelling. A further strength of the method is greatly increased accuracy in predicting the placement of secondary structure segments. \u00a9 1994 Wiley\u2010Liss, Inc."
            },
            "slug": "Combining-evolutionary-information-and-neural-to-Rost-Sander",
            "title": {
                "fragments": [],
                "text": "Combining evolutionary information and neural networks to predict protein secondary structure"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work extends the previous three\u2010level system of neural networks by using additional input information derived from multiple alignments using a position\u2010specific conservation weight as part of the input to increase performance and greatly increased accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49967661"
                        ],
                        "name": "B. Rost",
                        "slug": "B.-Rost",
                        "structuredName": {
                            "firstName": "Burkhard",
                            "lastName": "Rost",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rost"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882390"
                        ],
                        "name": "C. Sander",
                        "slug": "C.-Sander",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Sander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sander"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Rost and Sander 1993b; 1993a started with Qian and\nSejnowski's architecture, but used two methods to ad-dress the over tting problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 139
                            }
                        ],
                        "text": "Althoughtests made on di erent data sets can be hard to compare,the method of Rost and Sander (which resulted in thePHD prediction server (Rost and Sander, 1993b; 1993a;1994)) still reaches the top levels of prediction accuracy(about 72%, measured using 7-fold cross validation)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35392780,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "6e5950cea430c2e12624083e2c33bd59b2042a3f",
            "isKey": false,
            "numCitedBy": 2961,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We have trained a two-layered feed-forward neural network on a non-redundant data base of 130 protein chains to predict the secondary structure of water-soluble proteins. A new key aspect is the use of evolutionary information in the form of multiple sequence alignments that are used as input in place of single sequences. The inclusion of protein family information in this form increases the prediction accuracy by six to eight percentage points. A combination of three levels of networks results in an overall three-state accuracy of 70.8% for globular proteins (sustained performance). If four membrane protein chains are included in the evaluation, the overall accuracy drops to 70.2%. The prediction is well balanced between alpha-helix, beta-strand and loop: 65% of the observed strand residues are predicted correctly. The accuracy in predicting the content of three secondary structure types is comparable to that of circular dichroism spectroscopy. The performance accuracy is verified by a sevenfold cross-validation test, and an additional test on 26 recently solved proteins. Of particular practical importance is the definition of a position-specific reliability index. For half of the residues predicted with a high level of reliability the overall accuracy increases to better than 82%. A further strength of the method is the more realistic prediction of segment length. The protein family prediction method is available for testing by academic researchers via an electronic mail server."
            },
            "slug": "Prediction-of-protein-secondary-structure-at-better-Rost-Sander",
            "title": {
                "fragments": [],
                "text": "Prediction of protein secondary structure at better than 70% accuracy."
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A two-layered feed-forward neural network is trained on a non-redundant data base to predict the secondary structure of water-soluble proteins with a new key aspect is the use of evolutionary information in the form of multiple sequence alignments that are used as input in place of single sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of molecular biology"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50394648"
                        ],
                        "name": "N. Qian",
                        "slug": "N.-Qian",
                        "structuredName": {
                            "firstName": "Ning",
                            "lastName": "Qian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Qian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15403132,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "c94c156d00e0550a89a4af7bffd1d0c562320c76",
            "isKey": false,
            "numCitedBy": 1260,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Predicting-the-secondary-structure-of-globular-Qian-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Predicting the secondary structure of globular proteins using neural network models."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of molecular biology"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121168328"
                        ],
                        "name": "S. K. Riis",
                        "slug": "S.-K.-Riis",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Riis",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Riis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197258"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13127724,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "96a75947cd7bc189d18157ca17cdfa037a8f5380",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "The prediction of protein secondary structure by use of carefully structured neural networks and multiple sequence alignments has been investigated. Separate networks are used for predicting the three secondary structures alpha-helix, beta-strand, and coil. The networks are designed using a priori knowledge of amino acid properties with respect to the secondary structure and the characteristic periodicity in alpha-helices. Since these single-structure networks all have less than 600 adjustable weights, overfitting is avoided. To obtain a three-state prediction of alpha-helix, beta-strand, or coil, ensembles of single-structure networks are combined with another neural network. This method gives an overall prediction accuracy of 66.3% when using 7-fold cross-validation on a database of 126 nonhomologous globular proteins. Applying the method to multiple sequence alignments of homologous proteins increases the prediction accuracy significantly to 71.3% with corresponding Matthew's correlation coefficients C alpha = 0.59, C beta = 0.52, and Cc = 0.50. More than 72% of the residues in the database are predicted with an accuracy of 80%. It is shown that the network outputs can be interpreted as estimated probabilities of correct prediction, and, therefore, these numbers indicate which residues are predicted with high confidence."
            },
            "slug": "Improving-prediction-of-protein-secondary-structure-Riis-Krogh",
            "title": {
                "fragments": [],
                "text": "Improving prediction of protein secondary structure using structured neural networks and multiple sequence alignments."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the network outputs can be interpreted as estimated probabilities of correct prediction, and, therefore, these numbers indicate which residues are predicted with high confidence."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of computational biology : a journal of computational molecular cell biology"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39581622"
                        ],
                        "name": "James A. Cuff",
                        "slug": "James-A.-Cuff",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cuff",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James A. Cuff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764306"
                        ],
                        "name": "G. Barton",
                        "slug": "G.-Barton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Barton",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Barton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To further compare our system with other predictors, as in ( Cuff & Barton, 1999 ), we also trained an ensemble of BRNNs using the 126 sequences in the Rost and Sander data set.The performance on the 396 test sequences prepared by Cuff Bidirectional Dynamics for Protein Secondary Structure Prediction 99"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "and Barton is Q3 =7 2.0%.This is slightly better than the 71. 9% score for the single best predictor (PHD) amongst (DSC, PHD, NNSSP, and PREDATOR) reported in ( Cuff & Barton, 1999 ).This result is also achieved with the CASP class assignment.Finally, we also trained an ensemble of 6 BRNNs using the set containing 826 sequences with less than 25% identity to the 126 sequences of Rost and Sander.When tested on the 126 sequences, the ..."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6016474,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "a8946a1a1b666edb4fc1b1b4d69a59b2c80015c5",
            "isKey": true,
            "numCitedBy": 657,
            "numCiting": 137,
            "paperAbstract": {
                "fragments": [],
                "text": "A new dataset of 396 protein domains is developed and used to evaluate the performance of the protein secondary structure prediction algorithms DSC, PHD, NNSSP, and PREDATOR. The maximum theoretical Q3 accuracy for combination of these methods is shown to be 78%. A simple consensus prediction on the 396 domains, with automatically generated multiple sequence alignments gives an average Q3 prediction accuracy of 72.9%. This is a 1% improvement over PHD, which was the best single method evaluated. Segment Overlap Accuracy (SOV) is 75.4% for the consensus method on the 396\u2010protein set. The secondary structure definition method DSSP defines 8 states, but these are reduced by most authors to 3 for prediction. Application of the different published 8\u2010 to 3\u2010state reduction methods shows variation of over 3% on apparent prediction accuracy. This suggests that care should be taken to compare methods by the same reduction method. Two new sequence datasets (CB513 and CB251) are derived which are suitable for cross\u2010validation of secondary structure prediction methods without artifacts due to internal homology. A fully automatic World Wide Web service that predicts protein secondary structure by a combination of methods is available via http://barton.ebi.ac.uk/. Proteins 1999;34:508\u2013519. \u00a9 1999 Wiley\u2010Liss, Inc."
            },
            "slug": "Evaluation-and-improvement-of-multiple-sequence-for-Cuff-Barton",
            "title": {
                "fragments": [],
                "text": "Evaluation and improvement of multiple sequence methods for protein secondary structure prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Two new sequence datasets are derived which are suitable for cross\u2010validation of secondary structure prediction methods without artifacts due to internal homology and application of the different published 8\u2010 to 3\u2010state reduction methods shows variation of over 3% on apparent prediction accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107601323"
                        ],
                        "name": "D. T. Jones",
                        "slug": "D.-T.-Jones",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Jones",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. T. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "obtaining a performance of Q3 =7 7.6% per protein, or Q3 =7 5.5% per residue ( Jones, 1999 ).We evaluated that system on the whole set of 35 proteins by"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15506630,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8131893d6b2f1cb8f0c60b559c146d1da05d77d",
            "isKey": true,
            "numCitedBy": 5272,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "A two-stage neural network has been used to predict protein secondary structure based on the position specific scoring matrices generated by PSI-BLAST. Despite the simplicity and convenience of the approach used, the results are found to be superior to those produced by other methods, including the popular PHD method according to our own benchmarking results and the results from the recent Critical Assessment of Techniques for Protein Structure Prediction experiment (CASP3), where the method was evaluated by stringent blind testing. Using a new testing set based on a set of 187 unique folds, and three-way cross-validation based on structural similarity criteria rather than sequence similarity criteria used previously (no similar folds were present in both the testing and training sets) the method presented here (PSIPRED) achieved an average Q3 score of between 76.5% to 78.3% depending on the precise definition of observed secondary structure used, which is the highest published score for any method to date. Given the success of the method in CASP3, it is reasonable to be confident that the evaluation presented here gives a fair indication of the performance of the method in general."
            },
            "slug": "Protein-secondary-structure-prediction-based-on-Jones",
            "title": {
                "fragments": [],
                "text": "Protein secondary structure prediction based on position-specific scoring matrices."
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A two-stage neural network has been used to predict protein secondary structure based on the position specific scoring matrices generated by PSI-BLAST and achieved an average Q3 score of between 76.5% to 78.3% depending on the precise definition of observed secondary structure used, which is the highest published score for any method to date."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of molecular biology"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1899612"
                        ],
                        "name": "F. Richards",
                        "slug": "F.-Richards",
                        "structuredName": {
                            "firstName": "Frederic",
                            "lastName": "Richards",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Richards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5195057"
                        ],
                        "name": "C. Kundrot",
                        "slug": "C.-Kundrot",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Kundrot",
                            "middleNames": [
                                "E"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kundrot"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29126855,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "eed43edd4483b6eaa8fac1454d8cafa22241a744",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A computer program is described that produces a description of the secondary structure and supersecondary structure of a polypeptide chain using the list of alpha carbon coordinates as input. Restricting the term \u201csecondary structure\u201d to the conformation of contiguous segments of the chain, the program determines the initial and final residues in helices, extended strands, sharp turns, and omega loops. This is accomplished through the use of difference distance matrices. The distances in idealized models of the segments are compared with the actual structure, and the differences are evaluated for agreement within preset limits. The program assigns 90\u201395% of the residues in most proteins to at least one type of secondary element"
            },
            "slug": "Identification-of-structural-motifs-from-protein-*-Richards-Kundrot",
            "title": {
                "fragments": [],
                "text": "Identification of structural motifs from protein coordinate data: Secondary structure and first\u2010level supersecondary structure *"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A computer program is described that produces a description of the secondary structure and supersecondary structure of a polypeptide chain using the list of alpha carbon coordinates as input and assigns 90\u201395% of the residues in most proteins to at least one type of secondary element."
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144902513"
                        ],
                        "name": "P. Baldi",
                        "slug": "P.-Baldi",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Baldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2952703"
                        ],
                        "name": "Y. Chauvin",
                        "slug": "Y.-Chauvin",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Chauvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chauvin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2906655"
                        ],
                        "name": "T. Hunkapiller",
                        "slug": "T.-Hunkapiller",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Hunkapiller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hunkapiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35016244"
                        ],
                        "name": "M. A. McClure",
                        "slug": "M.-A.-McClure",
                        "structuredName": {
                            "firstName": "Marcella",
                            "lastName": "McClure",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. McClure"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 44553028,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a68a57a90611629ee21f4cb3b8a2ddadbb6b41b",
            "isKey": false,
            "numCitedBy": 496,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov model (HMM) techniques are used to model families of biological sequences. A smooth and convergent algorithm is introduced to iteratively adapt the transition and emission parameters of the models from the examples in a given family. The HMM approach is applied to three protein families: globins, immunoglobulins, and kinases. In all cases, the models derived capture the important statistical characteristics of the family and can be used for a number of tasks, including multiple alignments, motif detection, and classification. For K sequences of average length N, this approach yields an effective multiple-alignment algorithm which requires O(KN2) operations, linear in the number of sequences."
            },
            "slug": "Hidden-Markov-models-of-biological-primary-sequence-Baldi-Chauvin",
            "title": {
                "fragments": [],
                "text": "Hidden Markov models of biological primary sequence information."
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A smooth and convergent algorithm is introduced to iteratively adapt the transition and emission parameters of the models from the examples in a given family, yielding an effective multiple-alignment algorithm which requires O(KN2) operations, linear in the number of sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755687"
                        ],
                        "name": "A. Bairoch",
                        "slug": "A.-Bairoch",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Bairoch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bairoch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722884"
                        ],
                        "name": "R. Apweiler",
                        "slug": "R.-Apweiler",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Apweiler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Apweiler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 88
                            }
                        ],
                        "text": "More importantly, JONES-2 results have been obtained using pro les from TrEMBL database (Bairoch and Apweiler, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32649061,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "b75c9516971fc73866ab6750215b6b1cf6bf6119",
            "isKey": false,
            "numCitedBy": 1835,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "SWISS-PROT is a curated protein sequence database which strives to provide a high level of annotations (such as the description of the function of a protein, structure of its domains, post-translational modifications, variants, etc.), a minimal level of redundancy and high level of integration with other databases. Recent developments of the database include: an increase in the number and scope of model organisms; cross-references to two additional databases; a variety of new documentation files and the creation of TrEMBL, a computer annotated supplement to SWISS-PROT. This supplement consists of entries in SWISS-PROT-like format derived from the translation of all coding sequences (CDS) in the EMBL nucleotide sequence database, except the CDS already included in SWISS-PROT."
            },
            "slug": "The-SWISS-PROT-protein-sequence-data-bank-and-its-Bairoch-Apweiler",
            "title": {
                "fragments": [],
                "text": "The SWISS-PROT protein sequence data bank and its supplement TrEMBL"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This supplement consists of entries in SWiss-PROT-like format derived from the translation of all coding sequences in the EMBL nucleotide sequence database, except the CDS already included in SWISS- PROT."
            },
            "venue": {
                "fragments": [],
                "text": "Nucleic Acids Res."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144704594"
                        ],
                        "name": "Reinhard Schneider",
                        "slug": "Reinhard-Schneider",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Schneider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Reinhard Schneider"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7147197"
                        ],
                        "name": "A. Daruvar",
                        "slug": "A.-Daruvar",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Daruvar",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Daruvar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882390"
                        ],
                        "name": "C. Sander",
                        "slug": "C.-Sander",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Sander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally we enriched the system using an output filtering network on the top of the ensemble and adding multiple alignment profiles as provided by the HSSP database (Schneider et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In all but one experiment (see below), profiles were obtained from the HSSP database (Schneider et al., 1997) available at http://www."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12823452,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "939645dfc3a08e7e352ddb190aefd9cf8fcdb2b0",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "HSSP is a derived database merging structural three dimensional (3-D) and sequence one dimensional(1-D) information. For each protein of known 3-D structure from the Protein Data Bank (PDB), the database has a multiple sequence alignment of all available homologues and a sequence profile characteristic of the family. The list of homologues is the result of a database search in Swissprot using a position-weighted dynamic programming method for sequence profile alignment (MaxHom). The database is updated frequently. The listed homologues are very likely to have the same 3-D structure as the PDB protein to which they have been aligned. As a result, the database is not only a database of aligned sequence families, but also a database of implied secondary and tertiary structures covering 27% of all Swissprot-stored sequences."
            },
            "slug": "The-HSSP-database-of-protein-structure-sequence-Schneider-Daruvar",
            "title": {
                "fragments": [],
                "text": "The HSSP database of protein structure-sequence alignments"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The HSSP is a derived database merging structural three dimensional (3-D) and sequence one dimensional (1- D) information and a database of implied secondary and tertiary structures covering 27% of all Swissprot-stored sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Nucleic Acids Res."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755687"
                        ],
                        "name": "A. Bairoch",
                        "slug": "A.-Bairoch",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Bairoch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bairoch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722884"
                        ],
                        "name": "R. Apweiler",
                        "slug": "R.-Apweiler",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Apweiler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Apweiler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 87
                            }
                        ],
                        "text": "More importantly, JONES-2results have been obtained using pro les from TrEMBLdatabase (Bairoch and Apweiler, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7217750,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "0c1948a4b33c51309204e3bc1fde9d9de768ade5",
            "isKey": false,
            "numCitedBy": 1138,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "SWISS-PROT is a curated protein sequence database which strives to provide a high level of annotation (such as the description of the function of a protein, its domain structure, post-translational modifications, variants, etc.), a minimal level of redundancy and high level of integration with other databases. Recent developments of the database include: cross-references to additional databases; a variety of new documentation files and improvements to TrEMBL, a computer annotated supplement to SWISS-PROT. TrEMBL consists of entries in SWISS-PROT-like format derived from the translation of all coding sequences (CDS) in the EMBL nucleotide sequence database, except the CDS already included in SWISS-PROT. The URLs for SWISS-PROT on the WWW are: http://www.expasy.ch/sprot and http://www. ebi.ac.uk/sprot"
            },
            "slug": "The-SWISS-PROT-protein-sequence-data-bank-and-its-Bairoch-Apweiler",
            "title": {
                "fragments": [],
                "text": "The SWISS-PROT protein sequence data bank and its supplement TrEMBL in 1999"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Current developments of the database include: cross-references to additional databases; a variety of new documentation files and improvements to TrEMBL, a computer annotated supplement to SWISS-PROT."
            },
            "venue": {
                "fragments": [],
                "text": "Nucleic Acids Res."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697754"
                        ],
                        "name": "D. Frishman",
                        "slug": "D.-Frishman",
                        "structuredName": {
                            "firstName": "Dmitrij",
                            "lastName": "Frishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Frishman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2670711"
                        ],
                        "name": "P. Argos",
                        "slug": "P.-Argos",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Argos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Argos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17487756,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "ae5cb210d73b6aa8dda5fc9efb737ce24ea4f599",
            "isKey": false,
            "numCitedBy": 2186,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed an automatic algorithm STRIDE for protein secondary structure assignment from atomic coordinates based on the combined use of hydrogen bond energy and statistically derived backbone torsional angle information. Parameters of the pattern recognition procedure were optimized using designations provided by the crystallographers as a standard\u2010of\u2010truth. Comparison to the currently most widely used technique DSSP by Kabsch and Sander (Biopolymers 22:2577\u20102637, 1983) shows that STRIDE and DSSP assign secondary structural states in 58 and 31% of 226 protein chains in our data sample, respectively, in greater agreement with the specific residue\u2010by\u2010residue definitions provided by the discoverers of the structures while in 11% of the chains, the assignments are the same. STRIDE delineates every 11th helix and every 32nd strand more in accord with published assignments. \u00a9 1995 Wiley\u2010Liss, Inc."
            },
            "slug": "Knowledge\u2010based-protein-secondary-structure-Frishman-Argos",
            "title": {
                "fragments": [],
                "text": "Knowledge\u2010based protein secondary structure assignment"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "An automatic algorithm STRIDE for protein secondary structure assignment from atomic coordinates based on the combined use of hydrogen bond energy and statistically derived backbone torsional angle information is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144902513"
                        ],
                        "name": "P. Baldi",
                        "slug": "P.-Baldi",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Baldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8169197"
                        ],
                        "name": "S. Brunak",
                        "slug": "S.-Brunak",
                        "structuredName": {
                            "firstName": "S\u00f8ren",
                            "lastName": "Brunak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brunak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2952703"
                        ],
                        "name": "Y. Chauvin",
                        "slug": "Y.-Chauvin",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Chauvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chauvin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3175570"
                        ],
                        "name": "C. A. Andersen",
                        "slug": "C.-A.-Andersen",
                        "structuredName": {
                            "firstName": "Claus",
                            "lastName": "Andersen",
                            "middleNames": [
                                "A.",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. A. Andersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145416108"
                        ],
                        "name": "H. Nielsen",
                        "slug": "H.-Nielsen",
                        "structuredName": {
                            "firstName": "Henrik",
                            "lastName": "Nielsen",
                            "middleNames": [
                                "Bj\u00f8rn"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nielsen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "performance of Q3 =6 4.3%, with the correlations C\u03b1 =0 .41, C\u03b2 =0 .31, and C\u03b3 =0 .41 \u2014 see ( Baldi et al., 1999 ) for a review of the standard performance"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6923178,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78200101cb94b926b376f38571bffcaf0f9cc50e",
            "isKey": false,
            "numCitedBy": 1862,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We provide a unified overview of methods that currently are widely used to assess the accuracy of prediction algorithms, from raw percentages, quadratic error measures and other distances, and correlation coefficients, and to information theoretic measures such as relative entropy and mutual information. We briefly discuss the advantages and disadvantages of each approach. For classification tasks, we derive new learning algorithms for the design of prediction systems by directly optimising the correlation coefficient. We observe and prove several results relating sensitivity and specificity of optimal systems. While the principles are general, we illustrate the applicability on specific problems such as protein secondary structure and signal peptide prediction."
            },
            "slug": "Assessing-the-accuracy-of-prediction-algorithms-for-Baldi-Brunak",
            "title": {
                "fragments": [],
                "text": "Assessing the accuracy of prediction algorithms for classification: an overview"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A unified overview of methods that currently are widely used to assess the accuracy of prediction algorithms, from raw percentages, quadratic error measures and other distances, and correlation coefficients, and to information theoretic measures such as relative entropy and mutual information are provided."
            },
            "venue": {
                "fragments": [],
                "text": "Bioinform."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197258"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153856933"
                        ],
                        "name": "M. Brown",
                        "slug": "M.-Brown",
                        "structuredName": {
                            "firstName": "M",
                            "lastName": "Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1863326"
                        ],
                        "name": "I. Mian",
                        "slug": "I.-Mian",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Mian",
                            "middleNames": [
                                "Saira"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Mian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5233893"
                        ],
                        "name": "K. Sj\u00f6lander",
                        "slug": "K.-Sj\u00f6lander",
                        "structuredName": {
                            "firstName": "Kimmen",
                            "lastName": "Sj\u00f6lander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sj\u00f6lander"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(Jelinek, 1997) for more recent advances), important application of HMMs include sequence analysis in molecular biology (Baldi et al., 1994; Krogh et al., 1994; Baldi & Chauvin, 1996; Baldi & Brunak, 1998), time series prediction (Andrew & Dimitriadis, 1994), numerous pattern recognition problems such as handwriting recognition (Bengio et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2160404,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "5d28fc1a4027d23cc9e4ad8555361d48940e9be8",
            "isKey": false,
            "numCitedBy": 2003,
            "numCiting": 105,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov Models (HMMs) are applied to the problems of statistical modeling, database searching and multiple sequence alignment of protein families and protein domains. These methods are demonstrated on the globin family, the protein kinase catalytic domain, and the EF-hand calcium binding motif. In each case the parameters of an HMM are estimated from a training set of unaligned sequences. After the HMM is built, it is used to obtain a multiple alignment of all the training sequences. It is also used to search the SWISS-PROT 22 database for other sequences that are members of the given protein family, or contain the given domain. The HMM produces multiple alignments of good quality that agree closely with the alignments produced by programs that incorporate three-dimensional structural information. When employed in discrimination tests (by examining how closely the sequences in a database fit the globin, kinase and EF-hand HMMs), the HMM is able to distinguish members of these families from non-members with a high degree of accuracy. Both the HMM and PROFILESEARCH (a technique used to search for relationships between a protein sequence and multiply aligned sequences) perform better in these tests than PROSITE (a dictionary of sites and patterns in proteins). The HMM appears to have a slight advantage over PROFILESEARCH in terms of lower rates of false negatives and false positives, even though the HMM is trained using only unaligned sequences, whereas PROFILESEARCH requires aligned training sequences. Our results suggest the presence of an EF-hand calcium binding motif in a highly conserved and evolutionary preserved putative intracellular region of 155 residues in the alpha-1 subunit of L-type calcium channels which play an important role in excitation-contraction coupling. This region has been suggested to contain the functional domains that are typical or essential for all L-type calcium channels regardless of whether they couple to ryanodine receptors, conduct ions or both."
            },
            "slug": "Hidden-Markov-models-in-computational-biology.-to-Krogh-Brown",
            "title": {
                "fragments": [],
                "text": "Hidden Markov models in computational biology. Applications to protein modeling."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The results suggest the presence of an EF-hand calcium binding motif in a highly conserved and evolutionary preserved putative intracellular region of 155 residues in the alpha-1 subunit of L-type calcium channels which play an important role in excitation-contraction coupling."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of molecular biology"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 104
                            }
                        ],
                        "text": "Alternatively, a modular approach using a di erentMLP for each state can be pursued (Baldi et al., 1994;Bengio and Frasconi, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14298205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25bdc473f8377c1200adbd691fbb3cc77fa7bf70",
            "isKey": false,
            "numCitedBy": 338,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider problems of sequence processing and propose a solution based on a discrete-state model in order to represent past context. We introduce a recurrent connectionist architecture having a modular structure that associates a subnetwork to each state. The model has a statistical interpretation we call input-output hidden Markov model (IOHMM). It can be trained by the estimation-maximization (EM) or generalized EM (GEM) algorithms, considering state trajectories as missing data, which decouples temporal credit assignment and actual parameter estimation. The model presents similarities to hidden Markov models (HMMs), but allows us to map input sequences to output sequences, using the same processing style as recurrent neural networks. IOHMMs are trained using a more discriminant learning paradigm than HMMs, while potentially taking advantage of the EM algorithm. We demonstrate that IOHMMs are well suited for solving grammatical inference problems on a benchmark problem. Experimental results are presented for the seven Tomita grammars, showing that these adaptive models can attain excellent generalization."
            },
            "slug": "Input-output-HMMs-for-sequence-processing-Bengio-Frasconi",
            "title": {
                "fragments": [],
                "text": "Input-output HMMs for sequence processing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is demonstrated that IOHMMs are well suited for solving grammatical inference problems on a benchmark problem and able to map input sequences to output sequences, using the same processing style as recurrent neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2598638"
                        ],
                        "name": "U. Hobohm",
                        "slug": "U.-Hobohm",
                        "structuredName": {
                            "firstName": "Uwe",
                            "lastName": "Hobohm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Hobohm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059653099"
                        ],
                        "name": "M. Scharf",
                        "slug": "M.-Scharf",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Scharf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Scharf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069507994"
                        ],
                        "name": "R. Schneider",
                        "slug": "R.-Schneider",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Schneider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schneider"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882390"
                        ],
                        "name": "C. Sander",
                        "slug": "C.-Sander",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Sander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 138
                            }
                        ],
                        "text": "\u2026the remaining set of chains a representative sub-set with low pairwise sequence similarities were selectedby running the algorithm #1 of Hobohm et al. (1992),using the local alignment procedure search (rigorousSmith-Waterman algorithm) (Myers and Miller, 1988;Pearson, 1990) using the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2558294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b67b4991dffe2b367cd9ce5087e11fd5ee43abc5",
            "isKey": false,
            "numCitedBy": 778,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The Protein Data Bank currently contains about 600 data sets of three\u2010dimensional protein coordinates determined by X\u2010ray crystallography or NMR. There is considerable redundancy in the data base, as many protein pairs are identical or very similar in sequence. However, statistical analyses of protein sequence\u2010structure relations require nonredundant data. We have developed two algorithms to extract from the data base representative sets of protein chains with maximum coverage and minimum redundancy. The first algorithm focuses on optimizing a particular property of the selected proteins and works by successive selection of proteins from an ordered list and exclusion of all neighbors of each selected protein. The other algorithm aims at maximizing the size of the selected set and works by successive thinning out of clusters of similar proteins. Both algorithms are generally applicable to other data bases in which criteria of similarity can be defined and relate to problems in graph theory. The largest nonredundant set extracted from the current release of the Protein Data Bank has 155 protein chains. In this set, no two proteins have sequence similarity higher than a certain cutoff (30% identical residues for aligned subsequences longer than 80 residues), yet all structurally unique protein families are represented. Periodically updated lists of representative data sets are available by electronic mail from the file server \u201cnetserv@embl\u2010heidelberg.de.\u201d The selection may be useful in statistical approaches to protein folding as well as in the analysis and documentation of the known spectrum of three\u2010dimensional protein structures."
            },
            "slug": "Selection-of-representative-protein-data-sets-Hobohm-Scharf",
            "title": {
                "fragments": [],
                "text": "Selection of representative protein data sets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two algorithms are developed to extract from the data base representative sets of protein chains with maximum coverage and minimum redundancy and are generally applicable to other data bases in which criteria of similarity can be defined and relate to problems in graph theory."
            },
            "venue": {
                "fragments": [],
                "text": "Protein science : a publication of the Protein Society"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115356552"
                        ],
                        "name": "Tsungnan Lin",
                        "slug": "Tsungnan-Lin",
                        "structuredName": {
                            "firstName": "Tsungnan",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsungnan Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35216199"
                        ],
                        "name": "B. Horne",
                        "slug": "B.-Horne",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Horne",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4023505"
                        ],
                        "name": "P. Ti\u0148o",
                        "slug": "P.-Ti\u0148o",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Ti\u0148o",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ti\u0148o"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To limit this problem, we propose a remedy motivated by recent studies of NARX networks (Lin et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6638216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6e91c9e7e8f8a577a98ecfcfa998212a683195a",
            "isKey": false,
            "numCitedBy": 630,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "It has previously been shown that gradient-descent learning algorithms for recurrent neural networks can perform poorly on tasks that involve long-term dependencies, i.e. those problems for which the desired output depends on inputs presented at times far in the past. We show that the long-term dependencies problem is lessened for a class of architectures called nonlinear autoregressive models with exogenous (NARX) recurrent neural networks, which have powerful representational capabilities. We have previously reported that gradient descent learning can be more effective in NARX networks than in recurrent neural network architectures that have \"hidden states\" on problems including grammatical inference and nonlinear system identification. Typically, the network converges much faster and generalizes better than other networks. The results in this paper are consistent with this phenomenon. We present some experimental results which show that NARX networks can often retain information for two to three times as long as conventional recurrent neural networks. We show that although NARX networks do not circumvent the problem of long-term dependencies, they can greatly improve performance on long-term dependency problems. We also describe in detail some of the assumptions regarding what it means to latch information robustly and suggest possible ways to loosen these assumptions."
            },
            "slug": "Learning-long-term-dependencies-in-NARX-recurrent-Lin-Horne",
            "title": {
                "fragments": [],
                "text": "Learning long-term dependencies in NARX recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that the long-term dependencies problem is lessened for a class of architectures called nonlinear autoregressive models with exogenous (NARX) recurrent neural networks, which have powerful representational capabilities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 209
                            }
                        ],
                        "text": "Unfortunately there are theoretical reasons suggesting that, despite an adequate representational power, RNNs cannot possibly learn to capture long-ranged information because of the vanishing gradient problem (Bengio et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 210
                            }
                        ],
                        "text": "Unfortunately there are theoreticalreasons suggesting that, despite an adequate represen-tational power, RNNs cannot possibly learn to capturelong-ranged information because of the vanishing gradi-ent problem (Bengio et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206457500,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0be39ee052d246ae99c082a565aba25b811be2d",
            "isKey": false,
            "numCitedBy": 6144,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered."
            },
            "slug": "Learning-long-term-dependencies-with-gradient-is-Bengio-Simard",
            "title": {
                "fragments": [],
                "text": "Learning long-term dependencies with gradient descent is difficult"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases, and exposes a trade-off between efficient learning by gradient descent and latching on information for long periods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "given the input sequence, thus effectively introducing supervision in the learning process, as noted by Bridle (1989) and  Bengio & Frasconi (1994) .However, the"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15753355,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13369d124474b5f8dcbc70d12296a185832192b2",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to recognize or predict sequences using long-term context has many applications. However, practical and theoretical problems are found in training recurrent neural networks to perform tasks in which input/output dependencies span long intervals. Starting from a mathematical analysis of the problem, we consider and compare alternative algorithms and architectures on tasks for which the span of the input/output dependencies can be controlled. Results on the new algorithms show performance qualitatively superior to that obtained with backpropagation."
            },
            "slug": "Credit-Assignment-through-Time:-Alternatives-to-Bengio-Frasconi",
            "title": {
                "fragments": [],
                "text": "Credit Assignment through Time: Alternatives to Backpropagation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work considers and compares alternative algorithms and architectures on tasks for which the span of the input/output dependencies can be controlled and shows performance qualitatively superior to that obtained with backpropagation."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759124"
                        ],
                        "name": "C. Goller",
                        "slug": "C.-Goller",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Goller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Goller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34940447"
                        ],
                        "name": "A. K\u00fcchler",
                        "slug": "A.-K\u00fcchler",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "K\u00fcchler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. K\u00fcchler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6536466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c58dd287a476b4722c5b6b1316629e2874682219",
            "isKey": false,
            "numCitedBy": 578,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "While neural networks are very successfully applied to the processing of fixed-length vectors and variable-length sequences, the current state of the art does not allow the efficient processing of structured objects of arbitrary shape (like logical terms, trees or graphs). We present a connectionist architecture together with a novel supervised learning scheme which is capable of solving inductive inference tasks on complex symbolic structures of arbitrary size. The most general structures that can be handled are labeled directed acyclic graphs. The major difference of our approach compared to others is that the structure-representations are exclusively tuned for the intended inference task. Our method is applied to tasks consisting in the classification of logical terms. These range from the detection of a certain subterm to the satisfaction of a specific unification pattern. Compared to previously known approaches we obtained superior results in that domain."
            },
            "slug": "Learning-task-dependent-distributed-representations-Goller-K\u00fcchler",
            "title": {
                "fragments": [],
                "text": "Learning task-dependent distributed representations by backpropagation through structure"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A connectionist architecture together with a novel supervised learning scheme which is capable of solving inductive inference tasks on complex symbolic structures of arbitrary size is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Neural Networks (ICNN'96)"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50486107"
                        ],
                        "name": "W. Pearson",
                        "slug": "W.-Pearson",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pearson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pearson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 24505202,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "f36e1b178f4503b4339944d41729e072bdc79460",
            "isKey": false,
            "numCitedBy": 2025,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Rapid-and-sensitive-sequence-comparison-with-FASTP-Pearson",
            "title": {
                "fragments": [],
                "text": "Rapid and sensitive sequence comparison with FASTP and FASTA."
            },
            "venue": {
                "fragments": [],
                "text": "Methods in enzymology"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144902513"
                        ],
                        "name": "P. Baldi",
                        "slug": "P.-Baldi",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Baldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2952703"
                        ],
                        "name": "Y. Chauvin",
                        "slug": "Y.-Chauvin",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Chauvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chauvin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17404701,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bdedf988d9a1de26d949daee0c0ed768510e3b7",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a hybrid modeling approach where the parameters of a model are calculated and modulated by another model, typically a neural network (NN), to avoid both overfitting and underfitting. We develop the approach for the case of Hidden Markov Models (HMMs), by deriving a class of hybrid HMM/NN architectures. These architectures can be trained with unified algorithms that blend HMM dynamic programming with NN backpropagation. In the case of complex data, mixtures of HMMs or modulated HMMs must be used. NNs can then be applied both to the parameters of each single HMM, and to the switching or modulation of the models, as a function of input or context. Hybrid HMM/NN architectures provide a flexible NN parameterization for the control of model structure and complexity. At the same time, they can capture distributions that, in practice, are inaccessible to single HMMs. The HMM/NN hybrid approach is tested, in its simplest form, by constructing a model of the immunoglobulin protein family. A hybrid model is trained, and a multiple alignment derived, with less than a fourth of the number of parameters used with previous single HMMs."
            },
            "slug": "Hybrid-Modeling,-HMM/NN-Architectures,-and-Protein-Baldi-Chauvin",
            "title": {
                "fragments": [],
                "text": "Hybrid Modeling, HMM/NN Architectures, and Protein Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The HMM/NN hybrid approach is tested, in its simplest form, by constructing a model of the immunoglobulin protein family, with less than a fourth of the number of parameters used with previous single HMMs."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "tion problems such as handwriting recognition (Bengio et al., 1995; Bunke et al., 1995), and, more recently, information extraction ( Freitag & McCallum, 2000 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15413758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02c8a0bc8bab9920e6615cfacf1df2ab3f2b1f68",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent research has demonstrated the strong performance of hidden Markov models applied to information extraction\u2014the task of populating database slots with corresponding phrases from text documents. A remaining problem, however, is the selection of state-transition structure for the model. This paper demonstrates that extraction accuracy strongly depends on the selection of structure, and presents an algorithm for automatically finding good structures by stochastic optimization. Our algorithm begins with a simple model and then performs hill-climbing in the space of possible structures by splitting states and gauging performance on a validation set. Experimental results show that this technique finds HMM models that almost always out-perform a fixed model, and have superior average performance across tasks."
            },
            "slug": "Information-Extraction-with-HMM-Structures-Learned-Freitag-McCallum",
            "title": {
                "fragments": [],
                "text": "Information Extraction with HMM Structures Learned by Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper demonstrates that extraction accuracy strongly depends on the selection of structure, and presents an algorithm for automatically finding good structures by stochastic optimization, which finds HMM models that almost always out-perform a fixed model, and have superior average performance across tasks."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "of replicating the transition network for each time step, so that a feedforward network with shared weights is obtained.The same unrolling procedure can be applied in more general cases than just sequences.For example it can be applied to trees and graphs, provided that the resulting unrolled network is acyclic (Goller & Kuechler, 1996;  Frasconi et al., 1998 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6197973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5eb96540ef53b49eac2246d6b13635fe6e54451",
            "isKey": false,
            "numCitedBy": 467,
            "numCiting": 100,
            "paperAbstract": {
                "fragments": [],
                "text": "A structured organization of information is typically required by symbolic processing. On the other hand, most connectionist models assume that data are organized according to relatively poor structures, like arrays or sequences. The framework described in this paper is an attempt to unify adaptive models like artificial neural nets and belief nets for the problem of processing structured information. In particular, relations between data variables are expressed by directed acyclic graphs, where both numerical and categorical values coexist. The general framework proposed in this paper can be regarded as an extension of both recurrent neural networks and hidden Markov models to the case of acyclic graphs. In particular we study the supervised learning problem as the problem of learning transductions from an input structured space to an output structured space, where transductions are assumed to admit a recursive hidden statespace representation. We introduce a graphical formalism for representing this class of adaptive transductions by means of recursive networks, i.e., cyclic graphs where nodes are labeled by variables and edges are labeled by generalized delay elements. This representation makes it possible to incorporate the symbolic and subsymbolic nature of data. Structures are processed by unfolding the recursive network into an acyclic graph called encoding network. In so doing, inference and learning algorithms can be easily inherited from the corresponding algorithms for artificial neural networks or probabilistic graphical model."
            },
            "slug": "A-general-framework-for-adaptive-processing-of-data-Frasconi-Gori",
            "title": {
                "fragments": [],
                "text": "A general framework for adaptive processing of data structures"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The framework described in this paper is an attempt to unify adaptive models like artificial neural nets and belief nets for the problem of processing structured information, where relations between data variables are expressed by directed acyclic graphs, where both numerical and categorical values coexist."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115356552"
                        ],
                        "name": "Tsungnan Lin",
                        "slug": "Tsungnan-Lin",
                        "structuredName": {
                            "firstName": "Tsungnan",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsungnan Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35216199"
                        ],
                        "name": "B. Horne",
                        "slug": "B.-Horne",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Horne",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In these networks, the vanishing gradients problem is mitigated by the use of an explicit delay line applied to the output, which provides shorter paths for the effective propagation of error signals.The very same idea cannot be applied directly to BRNNs since output feedback, combined with bidirectional propagation, would generate cycles in the unrolled network.However, as suggested in ( Lin et al., 1998 ), a similar mechanism can be ..."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14241577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e2b855834df1f800414aa4950a22deae63577d6",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "How-embedded-memory-in-recurrent-neural-network-Lin-Horne",
            "title": {
                "fragments": [],
                "text": "How embedded memory in recurrent neural network architectures helps learning long-term temporal dependencies"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6252802"
                        ],
                        "name": "W. Kabsch",
                        "slug": "W.-Kabsch",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Kabsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kabsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144766425"
                        ],
                        "name": "C. Sander",
                        "slug": "C.-Sander",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Sander",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 120
                            }
                        ],
                        "text": "The program DSSP could not produce an output, since we wanted to use the DSSP assignment of protein secondary structure (Kabsch and Sander, 1983)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 119
                            }
                        ],
                        "text": "The program DSSP could not produce an output,since we wanted to use the DSSP assignment ofprotein secondary structure (Kabsch and Sander,1983)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29185760,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "225ba9111ed4b4e0f5bbe12c69e7235e353ff3ff",
            "isKey": false,
            "numCitedBy": 13105,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "For a successful analysis of the relation between amino acid sequence and protein structure, an unambiguous and physically meaningful definition of secondary structure is essential. We have developed a set of simple and physically motivated criteria for secondary structure, programmed as a pattern\u2010recognition process of hydrogen\u2010bonded and geometrical features extracted from x\u2010ray coordinates. Cooperative secondary structure is recognized as repeats of the elementary hydrogen\u2010bonding patterns \u201cturn\u201d and \u201cbridge.\u201d Repeating turns are \u201chelices,\u201d repeating bridges are \u201cladders,\u201d connected ladders are \u201csheets.\u201d Geometric structure is defined in terms of the concepts torsion and curvature of differential geometry. Local chain \u201cchirality\u201d is the torsional handedness of four consecutive C\u03b1 positions and is positive for right\u2010handed helices and negative for ideal twisted \u03b2\u2010sheets. Curved pieces are defined as \u201cbends.\u201d Solvent \u201cexposure\u201d is given as the number of water molecules in possible contact with a residue. The end result is a compilation of the primary structure, including SS bonds, secondary structure, and solvent exposure of 62 different globular proteins. The presentation is in linear form: strip graphs for an overall view and strip tables for the details of each of 10.925 residues. The dictionary is also available in computer\u2010readable form for protein structure prediction work."
            },
            "slug": "Dictionary-of-protein-secondary-structure:-Pattern-Kabsch-Sander",
            "title": {
                "fragments": [],
                "text": "Dictionary of protein secondary structure: Pattern recognition of hydrogen\u2010bonded and geometrical features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A set of simple and physically motivated criteria for secondary structure, programmed as a pattern\u2010recognition process of hydrogen\u2010bonded and geometrical features extracted from x\u2010ray coordinates is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Biopolymers"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145910"
                        ],
                        "name": "E. Myers",
                        "slug": "E.-Myers",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Myers",
                            "middleNames": [
                                "Wimberly"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Myers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119333843"
                        ],
                        "name": "W. Miller",
                        "slug": "W.-Miller",
                        "structuredName": {
                            "firstName": "Webb",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 208
                            }
                        ],
                        "text": "\u2026representative sub-set with low pairwise sequence similarities were selectedby running the algorithm #1 of Hobohm et al. (1992),using the local alignment procedure search (rigorousSmith-Waterman algorithm) (Myers and Miller, 1988;Pearson, 1990) using the pam120 matrix, with gap penal-ties -12, -4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 26
                            }
                        ],
                        "text": "Smith-Waterman algorithm) (Myers and Miller, 1988; Pearson, 1990) using the pam120 matrix, with gap penalties -12, -4."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8140207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21fc6d49ae1a6ac1601ab6be95c7132a5667bd74",
            "isKey": false,
            "numCitedBy": 1230,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Space, not time, is often the limiting factor when computing optimal sequence alignments, and a number of recent papers in the biology literature have proposed space-saving strategies. However, a 1975 computer science paper by Hirschberg presented a method that is superior to the new proposals, both in theory and in practice. The goal of this paper is to give Hirschberg's idea the visibility it deserves by developing a linear-space version of Gotoh's algorithm, which accommodates affine gap penalties. A portable C-software package implementing this algorithm is available on the BIONET free of charge."
            },
            "slug": "Optimal-alignments-in-linear-space-Myers-Miller",
            "title": {
                "fragments": [],
                "text": "Optimal alignments in linear space"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The goal of this paper is to give Hirschberg's idea the visibility it deserves by developing a linear-space version of Gotoh's algorithm, which accommodates affine gap penalties."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Appl. Biosci."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39877031"
                        ],
                        "name": "F. C. Bernstein",
                        "slug": "F.-C.-Bernstein",
                        "structuredName": {
                            "firstName": "Frances",
                            "lastName": "Bernstein",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. C. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4868668"
                        ],
                        "name": "T. Koetzle",
                        "slug": "T.-Koetzle",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Koetzle",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Koetzle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107433006"
                        ],
                        "name": "G. J. Williams",
                        "slug": "G.-J.-Williams",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. J. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46675042"
                        ],
                        "name": "E. Meyer",
                        "slug": "E.-Meyer",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Meyer",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Meyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153584520"
                        ],
                        "name": "M. Brice",
                        "slug": "M.-Brice",
                        "structuredName": {
                            "firstName": "Michael.",
                            "lastName": "Brice",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2537391"
                        ],
                        "name": "J. Rodgers",
                        "slug": "J.-Rodgers",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Rodgers",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rodgers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3328446"
                        ],
                        "name": "O. Kennard",
                        "slug": "O.-Kennard",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Kennard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kennard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46857546"
                        ],
                        "name": "T. Shimanouchi",
                        "slug": "T.-Shimanouchi",
                        "structuredName": {
                            "firstName": "Takehiko",
                            "lastName": "Shimanouchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Shimanouchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3195387"
                        ],
                        "name": "M. Tasumi",
                        "slug": "M.-Tasumi",
                        "structuredName": {
                            "firstName": "Mitsuo",
                            "lastName": "Tasumi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tasumi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22555334,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "5385e8477f93935dcaa5487979fa625e56b506f7",
            "isKey": false,
            "numCitedBy": 5778,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Protein-Data-Bank.-A-computer-based-archival-Bernstein-Koetzle",
            "title": {
                "fragments": [],
                "text": "The Protein Data Bank. A computer-based archival file for macromolecular structures."
            },
            "venue": {
                "fragments": [],
                "text": "European journal of biochemistry"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153170210"
                        ],
                        "name": "Clifford B. Miller",
                        "slug": "Clifford-B.-Miller",
                        "structuredName": {
                            "firstName": "Clifford",
                            "lastName": "Miller",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clifford B. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158193072"
                        ],
                        "name": "Dong Chen",
                        "slug": "Dong-Chen",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115401300"
                        ],
                        "name": "Hsing-Hen Chen",
                        "slug": "Hsing-Hen-Chen",
                        "structuredName": {
                            "firstName": "Hsing-Hen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsing-Hen Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34922532"
                        ],
                        "name": "Guo-Zheng Sun",
                        "slug": "Guo-Zheng-Sun",
                        "structuredName": {
                            "firstName": "Guo-Zheng",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guo-Zheng Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2552960"
                        ],
                        "name": "Yee-Chun Lee",
                        "slug": "Yee-Chun-Lee",
                        "structuredName": {
                            "firstName": "Yee-Chun",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Chun Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19666035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "872cdc269f3cb59f8a227818f35041415091545f",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that a recurrent, second-order neural network using a real-time, forward training algorithm readily learns to infer small regular grammars from positive and negative string training samples. We present simulations that show the effect of initial conditions, training set size and order, and neural network architecture. All simulations were performed with random initial weight strengths and usually converge after approximately a hundred epochs of training. We discuss a quantization algorithm for dynamically extracting finite state automata during and after training. For a well-trained neural net, the extracted automata constitute an equivalence class of state machines that are reducible to the minimal machine of the inferred grammar. We then show through simulations that many of the neural net state machines are dynamically stable, that is, they correctly classify many long unseen strings. In addition, some of these extracted automata actually outperform the trained neural network for classification of unseen strings."
            },
            "slug": "Learning-and-Extracting-Finite-State-Automata-with-Giles-Miller",
            "title": {
                "fragments": [],
                "text": "Learning and Extracting Finite State Automata with Second-Order Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "It is shown that a recurrent, second-order neural network using a real-time, forward training algorithm readily learns to infer small regular grammars from positive and negative string training samples, and many of the neural net state machines are dynamically stable, that is, they correctly classify many long unseen strings."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5371566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b84276fe751ca4f1389549281383b151a746107b",
            "isKey": false,
            "numCitedBy": 1140,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nEugene Charniak breaks new ground in artificial intelligence research by presenting statistical language processing from an artificial intelligence point of view in a text for researchers and scientists with a traditional computer science background. \nNew, exacting empirical methods are needed to break the deadlock in such areas of artificial intelligence as robotics, knowledge representation, machine learning, machine translation, and natural language processing (NLP). It is time, Charniak observes, to switch paradigms. This text introduces statistical language processing techniques -- word tagging, parsing with probabilistic context free grammars, grammar induction, syntactic disambiguation, semantic word classes, word-sense disambiguation -- along with the underlying mathematics and chapter exercises. \nCharniak points out that as a method of attacking NLP problems, the statistical approach has several advantages. It is grounded in real text and therefore promises to produce usable results, and it offers an obvious way to approach learning: \"one simply gathers statistics.\" \nLanguage, Speech, and Communication"
            },
            "slug": "Statistical-language-learning-Charniak",
            "title": {
                "fragments": [],
                "text": "Statistical language learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Eugene Charniak points out that as a method of attacking NLP problems, the statistical approach has several advantages and is grounded in real text and therefore promises to produce usable results, and it offers an obvious way to approach learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29085cdffb3277c1c8fd10ac09e0d89452c8db83",
            "isKey": false,
            "numCitedBy": 357,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a recurrent architecture having a modular structure and we formulate a training procedure based on the EM algorithm. The resulting model has similarities to hidden Markov models, but supports recurrent networks processing style and allows to exploit the supervised learning paradigm while using maximum likelihood estimation."
            },
            "slug": "An-Input-Output-HMM-Architecture-Bengio-Frasconi",
            "title": {
                "fragments": [],
                "text": "An Input Output HMM Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A recurrent architecture having a modular structure that has similarities to hidden Markov models, but supports recurrent networks processing style and allows to exploit the supervised learning paradigm while using maximum likelihood estimation is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680622"
                        ],
                        "name": "H. Lucke",
                        "slug": "H.-Lucke",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Lucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Lucke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The recent view of the HMM as a particular case of Bayesian networks (Bengio & Frasconi, 1995; Lucke, 1995; Smyth et al., 1997) has helped the theoretical understanding and the ability to conceive extensions to the standard model in a sound and formally elegant framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32689660,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c6bfc13e26795ee594218a1382196e3e44519d6",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bayesian-Belief-Networks-as-a-tool-for-stochastic-Lucke",
            "title": {
                "fragments": [],
                "text": "Bayesian Belief Networks as a tool for stochastic parsing"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50860274"
                        ],
                        "name": "Padhraic Smyth",
                        "slug": "Padhraic-Smyth",
                        "structuredName": {
                            "firstName": "Padhraic",
                            "lastName": "Smyth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Padhraic Smyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The recent view of the HMM as a particular case of Bayesian networks (Bengio & Frasconi, 1995; Lucke, 1995; Smyth et al., 1997) has helped the theoretical understanding and the ability to conceive extensions to the standard model in a sound and formally elegant framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10043879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0999dc17b35c0d893974f03d98293f71f27698b",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical techniques for modeling the dependencies of random variables have been explored in a variety of different areas, including statistics, statistical physics, artificial intelligence, speech recognition, image processing, and genetics. Formalisms for manipulating these models have been developed relatively independently in these research communities. In this paper we explore hidden Markov models (HMMs) and related structures within the general framework of probabilistic independence networks (PINs). The paper presents a self-contained review of the basic principles of PINs. It is shown that the well-known forward-backward (F-B) and Viterbi algorithms for HMMs are special cases of more general inference algorithms for arbitrary PINs. Furthermore, the existence of inference and estimation algorithms for more general graphical models provides a set of analysis tools for HMM practitioners who wish to explore a richer class of HMM structures. Examples of relatively complex models to handle sensor fusion and coarticulation in speech recognition are introduced and treated within the graphical model framework to illustrate the advantages of the general approach."
            },
            "slug": "Probabilistic-Independence-Networks-for-Hidden-Smyth-Heckerman",
            "title": {
                "fragments": [],
                "text": "Probabilistic Independence Networks for Hidden Markov Probability Models"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that the well-known forward-backward and Viterbi algorithms for HMMs are special cases of more general inference algorithms for arbitrary PINs and the existence of inference and estimation algorithms for more general graphical models provides a set of analysis tools for HMM practitioners who wish to explore a richer class of HMM structures."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094"
                        ],
                        "name": "J. Bridle",
                        "slug": "J.-Bridle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bridle",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bridle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "given the input sequence, thus effectively introducing supervision in the learning process, as noted by  Bridle (1989)  and Bengio & Frasconi (1994).However, the"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18865663,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "830ccb44084d9d6cdcb70d623df5012ae4835142",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the attractions of neural network approaches to pattern recognition is the use of a discrimination-based training method. We show that once we have modified the output layer of a multilayer perceptron to provide mathematically correct probability distributions, and replaced the usual squared error criterion with a probability-based score, the result is equivalent to Maximum Mutual Information training, which has been used successfully to improve the performance of hidden Markov models for speech recognition. If the network is specially constructed to perform the recognition computations of a given kind of stochastic model based classifier then we obtain a method for discrimination-based training of the parameters of the models. Examples include an HMM-based word discriminator, which we call an 'Alphanet'."
            },
            "slug": "Training-Stochastic-Model-Recognition-Algorithms-as-Bridle",
            "title": {
                "fragments": [],
                "text": "Training Stochastic Model Recognition Algorithms as Networks can Lead to Maximum Mutual Information Estimation of Parameters"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "It is shown that once the output layer of a multilayer perceptron is modified to provide mathematically correct probability distributions, and the usual squared error criterion is replaced with a probability-based score, the result is equivalent to Maximum Mutual Information training."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60769407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1aa31d5deb45f477a6de45b3b75b62c7f4a213e7",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This thesis examines the acoustic-modeling problem in automatic speech recognition from an information-theoretic point of view. This problem is to design a speech-recognition system which can extract from the speech waveform as much information as possible about the corresponding word sequence. The information extraction process is broken down into two steps: a signal processing step which converts a speech waveform into a sequence of information bearing acoustic feature vectors, and a step which models such a sequence. This thesis is primarily concerned with the use of hidden Markov models to model sequences of feature vectors which lie in a continuous space such as R sub N. It explores the trade-off between packing a lot of information into such sequences and being able to model them accurately. The difficulty of developing accurate models of continuous parameter sequences is addressed by investigating a method of parameter estimation which is specifically designed to cope with inaccurate modeling assumptions."
            },
            "slug": "The-acoustic-modeling-problem-in-automatic-speech-Brown",
            "title": {
                "fragments": [],
                "text": "The acoustic-modeling problem in automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This thesis is primarily concerned with the use of hidden Markov models to model sequences of feature vectors which lie in a continuous space such as R sub N and explores the trade-off between packing a lot of information into such sequences and being able to model them accurately."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2975061"
                        ],
                        "name": "C. Nohl",
                        "slug": "C.-Nohl",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Nohl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nohl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 1994; Baldi & Chauvin, 1996; Baldi & Brunak, 1998), time series prediction (Andrew & Dimitriadis, 1994), numerous pattern recognition problems such as handwriting recognition (Bengio et al., 1995; Bunke et al., 1995), and, more recently, information extraction (Freitag & McCallum, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3179635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a4192fd6efb5661eca197cce24289776a4fbcc2",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new approach for on-line recognition of handwritten words written in unconstrained mixed style. The preprocessor performs a word-level normalization by fitting a model of the word structure using the EM algorithm. Words are then coded into low resolution \"annotated images\" where each pixel contains information about trajectory direction and curvature. The recognizer is a convolution network that can be spatially replicated. From the network output, a hidden Markov model produces word scores. The entire system is globally trained to minimize word-level errors."
            },
            "slug": "LeRec:-A-NN/HMM-Hybrid-for-On-Line-Handwriting-Bengio-LeCun",
            "title": {
                "fragments": [],
                "text": "LeRec: A NN/HMM Hybrid for On-Line Handwriting Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A new approach for on-line recognition of handwritten words written in unconstrained mixed style by fitting a model of the word structure using the EM algorithm to minimize word-level errors."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46486898"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2882099"
                        ],
                        "name": "Jesper Vedelsby",
                        "slug": "Jesper-Vedelsby",
                        "structuredName": {
                            "firstName": "Jesper",
                            "lastName": "Vedelsby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jesper Vedelsby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5846986,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "910688d01c01856dd20715907af44157de8d3d1d",
            "isKey": false,
            "numCitedBy": 1971,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning of continuous valued functions using neural network ensembles (committees) can give improved accuracy, reliable estimation of the generalization error, and active learning. The ambiguity is defined as the variation of the output of ensemble members averaged over unlabeled data, so it quantifies the disagreement among the networks. It is discussed how to use the ambiguity in combination with cross-validation to give a reliable estimate of the ensemble generalization error, and how this type of ensemble cross-validation can sometimes improve performance. It is shown how to estimate the optimal weights of the ensemble members using unlabeled data. By a generalization of query by committee, it is finally shown how the ambiguity can be used to select new training data to be labeled in an active learning scheme."
            },
            "slug": "Neural-Network-Ensembles,-Cross-Validation,-and-Krogh-Vedelsby",
            "title": {
                "fragments": [],
                "text": "Neural Network Ensembles, Cross Validation, and Active Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown how to estimate the optimal weights of the ensemble members using unlabeled data and how the ambiguity can be used to select new training data to be labeled in an active learning scheme."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 32583695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93",
            "isKey": false,
            "numCitedBy": 18218,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nProbabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. \nProbabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability."
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems - networks of plausible inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic."
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann series in representation and reasoning"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152471016"
                        ],
                        "name": "Carl H. Smith",
                        "slug": "Carl-H.-Smith",
                        "structuredName": {
                            "firstName": "Carl H.",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carl H. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3209224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6524a6b8e6091c0a11d665180a5ad94bbf1d3b4",
            "isKey": false,
            "numCitedBy": 900,
            "numCiting": 190,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been a great deal of theoretical and experimental work in computer science on inductive inference systems, that is, systems that try to infer general rules from examples. However, a complete and applicable theory of such systems is still a distant goal. This survey highlights and explains the main ideas that have been developed in the study of inductive inference, with special emphasis on the relations between the general theory and the specific algorithms and implementations. 154 references."
            },
            "slug": "Inductive-Inference:-Theory-and-Methods-Angluin-Smith",
            "title": {
                "fragments": [],
                "text": "Inductive Inference: Theory and Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This survey highlights and explains the main ideas that have been developed in the study of inductive inference, with special emphasis on the relations between the general theory and the specific algorithms and implementations."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(Jelinek, 1997) for more recent advances), important application of HMMs include sequence analysis in molecular biology (Baldi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12495425,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "231f6de83cfa4d641da1681e97a11b689a48e3aa",
            "isKey": false,
            "numCitedBy": 2251,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The speech recognition problem hidden Markov models the acoustic model basic language modelling the Viterbi search hypothesis search on a tree and the fast match elements of information theory the complexity of tasks - the quality of language models the expectation - maximization algorithm and its consequences decision trees and tree language models phonetics from orthography - spelling-to-base from mappings triphones and allophones maximum entropy probability estimation and language models three applications of maximum entropy estimation to language modelling estimation of probabilities from counts and the Back-Off method."
            },
            "slug": "Statistical-methods-for-speech-recognition-Jelinek",
            "title": {
                "fragments": [],
                "text": "Statistical methods for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The speech recognition problem hidden Markov models the acoustic model basic language modelling the Viterbi search hypothesis search on a tree and the fast match elements of information theory."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120567545"
                        ],
                        "name": "M. Roth",
                        "slug": "M.-Roth",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403379723"
                        ],
                        "name": "E. G. Schukat-Talamazzini",
                        "slug": "E.-G.-Schukat-Talamazzini",
                        "structuredName": {
                            "firstName": "Ernst",
                            "lastName": "Schukat-Talamazzini",
                            "middleNames": [
                                "G\u00fcnter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. G. Schukat-Talamazzini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(Jelinek, 1997) for more recent advances), important application of HMMs include sequence analysis in molecular biology (Baldi et al., 1994; Krogh et al., 1994; Baldi & Chauvin, 1996; Baldi & Brunak, 1998), time series prediction (Andrew & Dimitriadis, 1994), numerous pattern recognition problems such as handwriting recognition (Bengio et al., 1995;  Bunke et al., 1995 ), and, more recently, information extraction (Freitag & ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18871413,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbb152d521161fba45b4f306188adfefa8c69977",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Off-line-cursive-handwriting-recognition-using-Bunke-Roth",
            "title": {
                "fragments": [],
                "text": "Off-line cursive handwriting recognition using hidden markov models"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2024710"
                        ],
                        "name": "A. Weigend",
                        "slug": "A.-Weigend",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Weigend",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Weigend"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688083"
                        ],
                        "name": "N. Gershenfeld",
                        "slug": "N.-Gershenfeld",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Gershenfeld",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gershenfeld"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26996169,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "85f5b8e3e0b2fb868528349e5032b0c2d20c7a34",
            "isKey": false,
            "numCitedBy": 1882,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Make more knowledge even in less time every day. You may not always spend your time and money to go abroad and get the experience and knowledge by yourself. Reading is a good alternative to do in getting this desirable knowledge and experience. You may gain many things from experiencing directly, but of course it will spend much money. So here, by reading time series prediction forecasting the future and understanding the past, you can take more advantages with limited budget."
            },
            "slug": "Time-Series-Prediction:-Forecasting-the-Future-and-Weigend-Gershenfeld",
            "title": {
                "fragments": [],
                "text": "Time Series Prediction: Forecasting the Future and Understanding the Past"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "By reading time series prediction forecasting the future and understanding the past, you can take more advantages with limited budget."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "the Bayesian network of Figure 1.More details about the basic model can be found in ( Rabiner, 1989 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24804,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A well known result is that the above procedure will converge to a local maximum of the likelihood function (Dempster et al., 1977)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 102
                            }
                        ],
                        "text": "Similar gen-eralizations of second-order RNN (Giles et al., 1992) orrecurrent radial basis functions (Frasconi et al., 1996) areeasily conceivable following the approach here described.4.2 Inference and learningAs for standard RNNs, it is convenient to describe in-ference and learning in BRNNs by\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 44
                            }
                        ],
                        "text": ", 1992) or recurrent radial basis functions (Frasconi et al., 1996) are easily conceivable following the approach here described."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Representation of nite state automata in recurrent radial basis function networks"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071978015"
                        ],
                        "name": "\u5927\u897f \u4ec1",
                        "slug": "\u5927\u897f-\u4ec1",
                        "structuredName": {
                            "firstName": "\u5927\u897f",
                            "lastName": "\u4ec1",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u5927\u897f \u4ec1"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 204167032,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c36143936e3048818d881d9c5ebcae68e88ad70",
            "isKey": false,
            "numCitedBy": 582,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pearl,-J.-(1988,-second-printing-1991).-Reasoning-\u5927\u897f",
            "title": {
                "fragments": [],
                "text": "Pearl, J. (1988, second printing 1991). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan-Kaufmann."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2195511"
                        ],
                        "name": "J. Moult",
                        "slug": "J.-Moult",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Moult",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Moult"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8126949"
                        ],
                        "name": "T. Hubbard",
                        "slug": "T.-Hubbard",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "J.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807652"
                        ],
                        "name": "S. Bryant",
                        "slug": "S.-Bryant",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Bryant",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bryant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1842582"
                        ],
                        "name": "K. Fidelis",
                        "slug": "K.-Fidelis",
                        "structuredName": {
                            "firstName": "Krzysztof",
                            "lastName": "Fidelis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fidelis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48309062"
                        ],
                        "name": "J. Pedersen",
                        "slug": "J.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pedersen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26823924,
            "fieldsOfStudy": [
                "Chemistry",
                "Medicine"
            ],
            "id": "87914ee5258b5ed88d066210e2cc7e2bda4e35c7",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Critical-assessment-of-methods-of-protein-structure-Moult-Hubbard",
            "title": {
                "fragments": [],
                "text": "Critical assessment of methods of protein structure prediction (CASP): Round II"
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16491491"
                        ],
                        "name": "G. Grant",
                        "slug": "G.-Grant",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grant",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grant"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22799724,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "cf171d57f8232ba90a0696f8cb46144b39380d0b",
            "isKey": false,
            "numCitedBy": 514,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bioinformatics-The-Machine-Learning-Approach-Grant",
            "title": {
                "fragments": [],
                "text": "Bioinformatics - The Machine Learning Approach"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Chem."
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 236467223,
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IEEE TRANS. ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 Face Photo-Sketch Synthesis and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 161
                            }
                        ],
                        "text": "Finally we enriched the system using an output ltering network on the top of the ensemble and adding multiple alignment pro les as provided by the HSSP database (Sander and Schneider, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "HSSP: Homology derived secondary structure of proteins"
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A survey of inductive inference: Theory and methods"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Comput. Surv"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Representation of nite state automata in recurrentradial basis function networks"
            },
            "venue": {
                "fragments": [],
                "text": "J . Mol . Biol ."
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Third community wide experiment on the critical assessment of techniques for protein structure prediction"
            },
            "venue": {
                "fragments": [],
                "text": "CASP3"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Jordan . Factorial hiddenMarkov models"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "John Moult et al . Critical assessment of methods of proteinstructure prediction ( CASP ) : Round II"
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Knowledge-based secondary structure"
            },
            "venue": {
                "fragments": [],
                "text": "assignment. Proteins,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 177
                            }
                        ],
                        "text": ", 1994; Baldi & Chauvin, 1996; Baldi & Brunak, 1998), time series prediction (Andrew & Dimitriadis, 1994), numerous pattern recognition problems such as handwriting recognition (Bengio et al., 1995; Bunke et al., 1995), and, more recently, information extraction (Freitag & McCallum, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Off-line Cursive Handwriting Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Using Hidden Markov Models. Pattern Recognition,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluation and improvement of multiple sequence methods for protein secondary structure"
            },
            "venue": {
                "fragments": [],
                "text": "prediction. Proteins,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Selec - tion of representative data sets"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans . on Pattern Analysis and Machine Intelligence"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IEEE Trans. on Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian updating in recursive graphical models by local computations"
            },
            "venue": {
                "fragments": [],
                "text": "Prot . Sci ."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning task-dependent distributed structure-representations by backpropagation through structure"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Knowledge-based secondary structure assignment"
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learn - ing long - term dependencies with gradient descent is di \u000e cult"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans . on Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian updating in recursive graphical models by local computations"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Stat. Quarterly"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combining evolutionary informationand neural networks to predict protein secondary structure"
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Protein secondary structure prediction based on positionspecific scoring matrices"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Molecular Biology"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 138
                            }
                        ],
                        "text": "\u2026the remaining set of chains a representative sub-set with low pairwise sequence similarities were selectedby running the algorithm #1 of Hobohm et al. (1992),using the local alignment procedure search (rigorousSmith-Waterman algorithm) (Myers and Miller, 1988;Pearson, 1990) using the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Selection of representative data"
            },
            "venue": {
                "fragments": [],
                "text": "sets. Prot. Sci.,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Factorial hidden Markov m o d e l s"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 24
                            }
                        ],
                        "text": "Clearly, in these cases theresponse at time t cannot depend on stimulae that thesystem has not yet received as input."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 104
                            }
                        ],
                        "text": "Alternatively, a modular approach using a di erentMLP for each state can be pursued (Baldi et al., 1994;Bengio and Frasconi, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Input-output HMM's for sequence processing"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 138
                            }
                        ],
                        "text": "\u2026the remaining set of chains a representative sub-set with low pairwise sequence similarities were selectedby running the algorithm #1 of Hobohm et al. (1992),using the local alignment procedure search (rigorousSmith-Waterman algorithm) (Myers and Miller, 1988;Pearson, 1990) using the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Selection of representative data sets"
            },
            "venue": {
                "fragments": [],
                "text": "Prot. Sci"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Third community wide experiment on the critical assessment of techniques for protein structure prediction. Unpublished results available in http://predictioncenter.llnl.gov/casp3"
            },
            "venue": {
                "fragments": [],
                "text": "Third community wide experiment on the critical assessment of techniques for protein structure prediction. Unpublished results available in http://predictioncenter.llnl.gov/casp3"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 15,
            "methodology": 19
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 73,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Bidirectional-Dynamics-for-Protein-Secondary-Baldi-Brunak/5a0bc896955dbe1fd2db321a754b2895d47355fc?sort=total-citations"
}