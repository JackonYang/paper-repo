{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2494216"
                        ],
                        "name": "P. Pyreddy",
                        "slug": "P.-Pyreddy",
                        "structuredName": {
                            "firstName": "Pallavi",
                            "lastName": "Pyreddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pyreddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 98
                            }
                        ],
                        "text": "\u2022 In table location, they have been taken at different levels of the table\u2019s physical model: line [18,19]; cell [23,25]; full table [5]; column and row [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13991200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d674f1289f336d88c4ab93e7204a345a302ed2eb",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables form an important kind of data element in text retrieval. Often, the gist of an entire news article or other exposition can be concisely captured in tabular form. In this paper, we examine the utility of exploiting information other than the key words in a digital document to provide the users with more flexible and powerful query capabilities. More specifically, we exploit the structural information in a document to identify tables and their component fields and let the users query based on these fields. Our empirical results have demonstrated that heuristic method based table extraction and component tagging can be performed effectively and efficiently. Moreover, our experiments in retrieval using the TINTIN system have strongly indicated that such structural decomposition can facilitate better representation of user\u2019s information needs and hence more effective retrieval of tables."
            },
            "slug": "TINTIN:-a-system-for-retrieval-in-text-tables-Pyreddy-Croft",
            "title": {
                "fragments": [],
                "text": "TINTIN: a system for retrieval in text tables"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper examines the utility of exploiting information other than the key words in a digital document to provide the users with more flexible and powerful query capabilities and demonstrates that heuristic method based table extraction and component tagging can be performed effectively and efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "DL '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "These however consist of non-marked up HTML tables detected by Wang and Hu [26] algorithm, which is naturally subject to errors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2061833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d89945f77470b6a1dabd1f224f10b7d096fd9435",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a commonly used presentation scheme, especially for describing relational information. However, table understanding remains an open problem. In this paper, we consider the problem of table detection in web documents. Its potential applications include web mining, knowledge management, and web content summarization and delivery to narrow-bandwidth devices. We describe a machine learning based approach to classify each given table entity as either genuine or non-genuine. Various features reflecting the layout as well as content characteristics of tables are studied.In order to facilitate the training and evaluation of our table classifier, we designed a novel web document table ground truthing protocol and used it to build a large table ground truth database. The database consists of 1,393 HTML files collected from hundreds of different web sites and contains 11,477 leaf TABLE elements, out of which 1,740 are genuine tables. Experiments were conducted using the cross validation method and an F-measure of 95.89% was achieved."
            },
            "slug": "A-machine-learning-based-approach-for-table-on-the-Wang-Hu",
            "title": {
                "fragments": [],
                "text": "A machine learning based approach for table detection on the web"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A machine learning based approach to classify each given table entity as either genuine or non-genuine, and designed a novel web document table ground truthing protocol and used it to build a large table ground truth database."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145658132"
                        ],
                        "name": "David Pinto",
                        "slug": "David-Pinto",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876441"
                        ],
                        "name": "Xing Wei",
                        "slug": "Xing-Wei",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "# Table lines 17,619 2,478 15,998 15,287 [16] # Table cells 61,286 7,128 56,065a a Estimate, since precise segmentation ground-truth was not produced for this dataset"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "# Lines 86,627 9,537 86,208 79,966 [16]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[16] found that Conditional Random Fields (CRF) and other algorithms that take explicitly into account line interdependence perform well."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1092004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6991606a1a9d5c285af385ee9159fd46cc14048e",
            "isKey": true,
            "numCitedBy": 440,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to find tables and extract information from them is a necessary component of data mining, question answering, and other information retrieval tasks. Documents often contain tables in order to communicate densely packed, multi-dimensional information. Tables do this by employing layout patterns to efficiently indicate fields and records in two-dimensional form.Their rich combination of formatting and content present difficulties for traditional language modeling techniques, however. This paper presents the use of conditional random fields (CRFs) for table extraction, and compares them with hidden Markov models (HMMs). Unlike HMMs, CRFs support the use of many rich and overlapping layout and language features, and as a result, they perform significantly better. We show experimental results on plain-text government statistical reports in which tables are located with 92% F1, and their constituent lines are classified into 12 table-related categories with 94% accuracy. We also discuss future work on undirected graphical models for segmenting columns, finding cells, and classifying them as data cells or label cells."
            },
            "slug": "Table-extraction-using-conditional-random-fields-Pinto-McCallum",
            "title": {
                "fragments": [],
                "text": "Table extraction using conditional random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Unlike HMMs, CRFs support the use of many rich and overlapping layout and language features, and as a result, they perform significantly better, and are compared with hidden Markov models (HMMs)."
            },
            "venue": {
                "fragments": [],
                "text": "DG.O"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9] propose an evaluation model that is resistant to this difficulty."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "\u2019s [9] by weighing them by the costs of the errors made in each class of questions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7630958,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af42cc46f93bc9cf413770af4f7243f54a31336e",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. While techniques for evaluating the performance of lower-level document analysis tasks such as optical character recognition have gained acceptance in the literature, attempts to formalize the problem for higher-level algorithms, while receiving a fair amount of attention in terms of theory, have generally been less successful in practice, perhaps owing to their complexity. In this paper, we introduce intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition. We also present the results of several small experiments, demonstrating how well the methodologies work and the useful sorts of feedback they provide. We first consider the table detection problem. Here algorithms can yield various classes of errors, including non-table regions improperly labeled as tables (insertion errors), tables missed completely (deletion errors), larger tables broken into a number of smaller ones (splitting errors), and groups of smaller tables combined to form larger ones (merging errors). This leads naturally to the use of an edit distance approach for assessing the results of table detection. Next we address the problem of evaluating table structure recognition. Our model is based on a directed acyclic attribute graph, or table DAG. We describe a new paradigm, \u201cgraph probing,\u201d for comparing the results returned by the recognition system and the representation created during ground-truthing. Probing is in fact a general concept that could be applied to other document recognition tasks as well."
            },
            "slug": "Evaluating-the-performance-of-table-processing-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Evaluating the performance of table processing algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition are introduced and a new paradigm, \u201cgraph probing,\u201d is described for comparing the results returned by the recognition system and the representation created during ground-truthing."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[8] have had ground-truth generated by all four authors: \u201cA line was classified as table or non-table (with) three or four votes\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37293831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "edbd577d793a083de4f337acac992ec7837609e0",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An important step towards the goal of table understanding is a method for reliable table detection. This paper describes a general solution for detecting tables based on computing an optimal partitioning of a document into some number of tables. A dynamic programming algorithm is given to solve the resulting optimization problem. This high-level framework is independent of any particular table quality measure and independent of the document medium. Moreover, it does not rely on the presence of ruling lines or other table delimiters. We also present table quality measures based on white space correlation and vertical connected component analysis. These measures can be applied equally well to ASCII text and scanned images. We report on some preliminary experiments using this method to detect tables in both ASCII text and scanned images, yielding promising results. We present detailed evaluation of these results using three different criteria which by themselves pose interesting research questions."
            },
            "slug": "Medium-independent-table-detection-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Medium-independent table detection"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A general solution for detecting tables based on computing an optimal partitioning of a document into some number of tables is described and a dynamic programming algorithm is given to solve the resulting optimization problem."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49915337"
                        ],
                        "name": "A. C. E. Silva",
                        "slug": "A.-C.-E.-Silva",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Silva",
                            "middleNames": [
                                "Costa",
                                "e"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. C. E. Silva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7260147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "166e2f3ff52620ffc975acca6281915995498605",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov Models (HMM) are probabilistic graphical models for interdependent classification. In this paper we experiment with different ways of combining the components of an HMM for document analysis applications, in particular for finding tables in text. We show: a) how to integrate different document structure finders into the HMM; b) that transition probabilities should vary along the chain to embed general knowledge axioms of our field, c) some emission energies can be selectively ignored, and d) emission and transition probabilities can be weighed differently. We conclude these changes increase the expressiveness and usability of HMMs in our field."
            },
            "slug": "Learning-Rich-Hidden-Markov-Models-in-Document-Silva",
            "title": {
                "fragments": [],
                "text": "Learning Rich Hidden Markov Models in Document Analysis: Table Location"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper experiments with different ways of combining the components of an HMM for document analysis applications, in particular for finding tables in text, and shows how to integrate different document structure finders into the HMM."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153924342"
                        ],
                        "name": "Hsin-Hsi Chen",
                        "slug": "Hsin-Hsi-Chen",
                        "structuredName": {
                            "firstName": "Hsin-Hsi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsin-Hsi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072526610"
                        ],
                        "name": "Shih-Chung Tsai",
                        "slug": "Shih-Chung-Tsai",
                        "structuredName": {
                            "firstName": "Shih-Chung",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Chung Tsai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2949513"
                        ],
                        "name": "Jin-He Tsai",
                        "slug": "Jin-He-Tsai",
                        "structuredName": {
                            "firstName": "Jin-He",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin-He Tsai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": "\u2022 In table location, they have been taken at different levels of the table\u2019s physical model: line [18,19]; cell [23,25]; full table [5]; column and row [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6844025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "578c63514136ac5b9af0144bcfe06efcfdd3099c",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a very common presentation scheme, but few papers touch on table extraction in text data mining. This paper focuses on mining tables from large-scale HTML texts. Table filtering, recognition, interpretation, and presentation are discussed. Heuristic rules and cell similarities are employed to identify tables. The F-measure of table recognition is 86.50%. We also propose an algorithm to capture attribute-value relationships among table cells. Finally, more structured data is extracted and presented."
            },
            "slug": "Mining-Tables-from-Large-Scale-HTML-Texts-Chen-Tsai",
            "title": {
                "fragments": [],
                "text": "Mining Tables from Large Scale HTML Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper focuses on mining tables from large-scale HTML texts by using heuristic rules and cell similarities to identify tables and proposes an algorithm to capture attribute-value relationships among table cells."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5481713,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ba28bb5c79f9115b3f3b62593feedf1d73b3027",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis looks at the issues relating to the development of technology capable of processing tables as they appear in textual documents so that their contents may be accessed and further interpreted by standard information extraction and natural language processing systems. The thesis offers a formal description of the table and the description and evaluation of a system which provides instances of that model for table examples. There are three parts to the thesis. The first looks at tables in general terms, suggests where their complexities are to be found, and reviews the literature dealing with research into tables in other fields. The second part introduces a layered model of the table and provides some notational equipment for encoding tables in these component layers. The final part discusses the design, implementation and evaluation of a system which produces an instance of the model for the tables found in a document. It also discusses the design and collection of a corpus of tables used for the training and evaluation of the system. The thesis catalogues a laxge number of phenomena discovered in the corpus collected during the research and provides appropriate terminology."
            },
            "slug": "The-interpretation-of-tables-in-texts-Hurst",
            "title": {
                "fragments": [],
                "text": "The interpretation of tables in texts"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This thesis looks at the issues relating to the development of technology capable of processing tables as they appear in textual documents so that their contents may be accessed and further interpreted by standard information extraction and natural language processing systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49915337"
                        ],
                        "name": "A. C. E. Silva",
                        "slug": "A.-C.-E.-Silva",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Silva",
                            "middleNames": [
                                "Costa",
                                "e"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. C. E. Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772839"
                        ],
                        "name": "A. Jorge",
                        "slug": "A.-Jorge",
                        "structuredName": {
                            "firstName": "Al\u00edpio",
                            "lastName": "Jorge",
                            "middleNames": [
                                "M\u00e1rio"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jorge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66444903"
                        ],
                        "name": "L. Torgo",
                        "slug": "L.-Torgo",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Torgo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Torgo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "\u2019s [19] algorithm, which uses a two-step approach for locating tables, common in other interdependent classification problems [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 98
                            }
                        ],
                        "text": "\u2022 In table location, they have been taken at different levels of the table\u2019s physical model: line [18,19]; cell [23,25]; full table [5]; column and row [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17729940,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c379a594600b94bf02d2df81450f00b582c210a",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Information contained in companies\u2019 financial statements is valuable to support a variety of decisions. In such documents, much of the relevant information is contained in tables and is extracted mainly by hand. We propose a method that accomplishes a preliminary step of the task of automatically extracting information from tables in documents: selecting the lines which are likely to belong to the tables containing the information to be extracted. Our method has been developed by empirically analysing a set of Portuguese companies\u2019 financial statements, using statistical and data mining techniques. Empirical evaluation indicates that more than 99% of the table lines are selected after discarding at least 50% of them. The method can cope with the complexity of styles used in assembling information on paper and adapt its performance accordingly, thus maximizing its results."
            },
            "slug": "Selection-of-Table-Areas-for-Information-Extraction-Silva-Jorge",
            "title": {
                "fragments": [],
                "text": "Selection of Table Areas for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method that accomplishes a preliminary step of the task of automatically extracting information from tables in documents: selecting the lines which are likely to belong to the tables containing the information to be extracted."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3216372"
                        ],
                        "name": "Chung Yong Lim",
                        "slug": "Chung-Yong-Lim",
                        "structuredName": {
                            "firstName": "Chung",
                            "lastName": "Lim",
                            "middleNames": [
                                "Yong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung Yong Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054350109"
                        ],
                        "name": "Jessica Li Teng Koo",
                        "slug": "Jessica-Li-Teng-Koo",
                        "structuredName": {
                            "firstName": "Jessica",
                            "lastName": "Koo",
                            "middleNames": [
                                "Li",
                                "Teng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jessica Li Teng Koo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15] in table location and Hurst [10] in functional analysis) is not the best strategy for this problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "\u2022 In table location, they have been taken at different levels of the table\u2019s physical model: line [18,19]; cell [23,25]; full table [5]; column and row [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16206198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d937270157cabb23288ce6a948275f4aeeaa827",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Many real-world texts contain tables. In order to process these texts correctly and extract the information contained within the tables, it is important to identify the presence and structure of tables. In this paper, we present a new approach that learns to recognize tables in free text, including the boundary, rows and columns of tables. When tested on Wall Street Journal news documents, our learning approach outperforms a deterministic table recognition algorithm that identifies table recognition algorithm that identifies tables based on a fixed set of conditions. Our learning approach is also more flexible and easily adaptable to texts in different domains with different table characteristics."
            },
            "slug": "Learning-to-Recognize-Tables-in-Free-Text-Ng-Lim",
            "title": {
                "fragments": [],
                "text": "Learning to Recognize Tables in Free Text"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new approach that learns to recognize tables in free text, including the boundary, rows and columns of tables, outperforms a deterministic table recognition algorithm that identifies tables based on a fixed set of conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49915337"
                        ],
                        "name": "A. C. E. Silva",
                        "slug": "A.-C.-E.-Silva",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Silva",
                            "middleNames": [
                                "Costa",
                                "e"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. C. E. Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772839"
                        ],
                        "name": "A. Jorge",
                        "slug": "A.-Jorge",
                        "structuredName": {
                            "firstName": "Al\u00edpio",
                            "lastName": "Jorge",
                            "middleNames": [
                                "M\u00e1rio"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jorge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66444903"
                        ],
                        "name": "L. Torgo",
                        "slug": "L.-Torgo",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Torgo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Torgo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "Based on these concepts, we propose the following absolute metrics [20]:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15425019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7f1c7ab6bb331944c0667b3ab75cba46021db1a",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper plans an end-to-end method for extracting information from tables embedded in documents; input format is ASCII, to which any richer format can be converted, preserving all textual and much of the layout information. We start by defining table. Then we describe the steps involved in extracting information from tables and analyse table-related research to place the contribution of different authors, find the paths research is following, and identify issues that are still unsolved. We then analyse current approaches to evaluating table processing algorithms and propose two new metrics for the task of segmenting cells/columns/rows. We proceed to design our own end-to-end method, where there is a higher interaction between different steps; we indicate how back loops in the usual order of the steps can reduce the possibility of errors and contribute to solving previously unsolved problems. Finally, we explore how the actual interpretation of the table not only allows inferring the accuracy of the overall extraction process but also contributes to actually improving its quality. In order to do so, we believe interpretation has to consider context-specific knowledge; we explore how the addition of this knowledge can be made in a plug-in/out manner, such that the overall method will maintain its operability in different contexts."
            },
            "slug": "Design-of-an-end-to-end-method-to-extract-from-Silva-Jorge",
            "title": {
                "fragments": [],
                "text": "Design of an end-to-end method to extract information from tables"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper plans an end-to-end method for extracting information from tables embedded in documents; input format is ASCII, to which any richer format can be converted, preserving all textual and much of the layout information."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145955157"
                        ],
                        "name": "Yang Zhang",
                        "slug": "Yang-Zhang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111220343"
                        ],
                        "name": "D. Wang",
                        "slug": "D.-Wang",
                        "structuredName": {
                            "firstName": "Daisy",
                            "lastName": "Wang",
                            "middleNames": [
                                "Zhe"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48144872"
                        ],
                        "name": "Eugene Wu",
                        "slug": "Eugene-Wu",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "\u2019s [2], who created the first large repository of HTML tables, with 154 million tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15553291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b75428bc47306492df2eeb61bb72a43d736d7e0e",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "World-Wide Web consists of a huge number of unstruc- tured hypertext documents, but it also contains structured data in the form of HTML tables. Many of these tables contain both relational-style data and a small \"schema\" of labeled and typed columns, making each such table a small structured database. The WebTables project is an effort to extract and make use of the huge number of these structured tables on the Web. A clean collection of relational-style ta- bles could be useful for improving web search, schema de- sign, and many other applications. This paper describes the first stage of the WebTables project. First, we give an in-depth study of the Web's HTML table corpus. For example, we extracted 14.1 billion HTML ta- bles from a several-billion-page portion of Google's general- purpose web crawl, and estimate that 154 million of these tables contain high-quality relational-style data. We also de- scribe the crawl's distribution of table sizes and data types. Second, we describe a system for performing relation recov- ery. The Web mixes relational and non-relational tables indiscriminately (often on the same page), so there is no simple way to distinguish the 1.1% of good relations from the remainder, nor to recover column label and type infor- mation. Our mix of hand-written detectors and statistical classifiers takes a raw Web crawl as input, and generates a collection of databases that is five orders of magnitude larger than any other collection we are aware of. Relation recovery achieves precision and recall that are comparable to other domain-independent information extraction systems."
            },
            "slug": "Uncovering-the-Relational-Web-Cafarella-Halevy",
            "title": {
                "fragments": [],
                "text": "Uncovering the Relational Web"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper gives an in-depth study of the Web's HTML table corpus, and describes a system for performing relation recovery that achieves precision and recall that are comparable to other domain-independent information extraction systems."
            },
            "venue": {
                "fragments": [],
                "text": "WebDB"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2180183"
                        ],
                        "name": "Ferihane Kboubi",
                        "slug": "Ferihane-Kboubi",
                        "structuredName": {
                            "firstName": "Ferihane",
                            "lastName": "Kboubi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ferihane Kboubi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30417928"
                        ],
                        "name": "Anja Habacha Cha\u00efbi",
                        "slug": "Anja-Habacha-Cha\u00efbi",
                        "structuredName": {
                            "firstName": "Anja",
                            "lastName": "Cha\u00efbi",
                            "middleNames": [
                                "Habacha"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anja Habacha Cha\u00efbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143678432"
                        ],
                        "name": "M. Ahmed",
                        "slug": "M.-Ahmed",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Ahmed",
                            "middleNames": [
                                "Ben"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ahmed"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7117117,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c98fe1b90985f41fb160e3fb91c2b3aafba790c",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a new approach of document analysis and recognition (DAR) based on the combination of OCR systems. The proposed approach aims to improve the document recognition by combining the result of several OCR systems according to their performances. We focus our attention, in this paper, on the table combination. We start by presenting the results of the evaluation of OCR system in the table block recognition. Then, we present our table combination method. We are interested in both table structure and table content."
            },
            "slug": "Table-recognition-evaluation-and-combination-Kboubi-Cha\u00efbi",
            "title": {
                "fragments": [],
                "text": "Table recognition evaluation and combination methods"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A new approach of document analysis and recognition (DAR) based on the combination of OCR systems, which aims to improve the document recognition by combining the result of several O CR systems according to their performances."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37301838"
                        ],
                        "name": "Vanessa Long",
                        "slug": "Vanessa-Long",
                        "structuredName": {
                            "firstName": "Vanessa",
                            "lastName": "Long",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vanessa Long"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "In segmentation, Long [14] also has very verbose metrics, defining seven error types at six different levels of granularity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18758093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4881bb9429e06d2ea28404952ad19a3a09ee512",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Table analysis is a complex problem, involving searching solutions from a large search space. Studies show that finding the most credible answers to complex problems often require combining multiple kinds of knowledge. Although the literature shows that both layout and language information have been used in table extraction systems, the amount of information each system uses is limited, and up till now, there is not an easy, systematic way to incorporate new information in these systems. This paper describesa framework for combining multiple solutions (including partial solutions) to solve a general table recognition problem."
            },
            "slug": "An-RDF-Based-Blackboard-Architecture-for-Improving-Long",
            "title": {
                "fragments": [],
                "text": "An RDF-Based Blackboard Architecture for Improving Table Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A framework for combining multiple solutions (including partial solutions) to solve a general table recognition problem is described."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105434437"
                        ],
                        "name": "Scott Tupaj",
                        "slug": "Scott-Tupaj",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Tupaj",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Tupaj"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110396962"
                        ],
                        "name": "Zhong Shi",
                        "slug": "Zhong-Shi",
                        "structuredName": {
                            "firstName": "Zhong",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhong Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145923790"
                        ],
                        "name": "D. H. Chang",
                        "slug": "D.-H.-Chang",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Chang",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Chang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[23] agree: financial tables tend to be very varied, having unequally filled-in columns or rows and complicated multiline headers, an algorithm doing well in this context is likely to do better in more \u201cwell behaved\u201d tables, e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "This would be the case with scientific journals, newspaper databases or law books, which contents tend to be easier for table recognition than that of financial tables [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 112
                            }
                        ],
                        "text": "\u2022 In table location, they have been taken at different levels of the table\u2019s physical model: line [18,19]; cell [23,25]; full table [5]; column and row [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18379904,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebeade30e54c102bf7d806739ea0f963ba07a20e",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents work done in locating and extracting tables and their contents from document images. While most research in the area of table analysis and recognition has focused on analyzing the raster image, our approach builds upon the advances in optical character recognition (OCR) software to preserve the layout of tabular data by means of white space. By using methods to analyze the geometry, syntax, and the semantics of the character data, as well as utilizing some well-known image processing techniques, we are able to 1) isolate embedded tables from documents, and 2) identify table components uch as title blocks, table entries, and footer blocks. Furthermore, the table analysis techniques presented in this paper can also be applied when analyzing blocks of text isolated by traditional methods such as connected component analysis[1] or bounding box [2]."
            },
            "slug": "Extracting-Tabular-Information-From-Text-Files-Tupaj-Shi",
            "title": {
                "fragments": [],
                "text": "Extracting Tabular Information From Text Files"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The approach builds upon the advances in optical character recognition software to preserve the layout of tabular data by means of white space to isolate embedded tables from documents and identify table components uch as title blocks, table entries, and footer blocks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772839"
                        ],
                        "name": "A. Jorge",
                        "slug": "A.-Jorge",
                        "structuredName": {
                            "firstName": "Al\u00edpio",
                            "lastName": "Jorge",
                            "middleNames": [
                                "M\u00e1rio"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jorge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009953"
                        ],
                        "name": "A. Lopes",
                        "slug": "A.-Lopes",
                        "structuredName": {
                            "firstName": "Alneu",
                            "lastName": "Lopes",
                            "middleNames": [
                                "de",
                                "Andrade"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lopes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "\u2019s [19] algorithm, which uses a two-step approach for locating tables, common in other interdependent classification problems [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14936507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cedc97179c0630f6878d8c724fd2d7fa17a09a8c",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Assigning a category to a given word (tagging) depends on the particular word and on the categories (tags) of neighboring words. A theory that is able to assign tags to a given text can naturally be viewed as a recursive logic program. This article describes how iterative induction, a technique that has been proven powerful in the synthesis of recursive logic programs, has been applied to the task of part-of-speech tagging. The main strategy consists of inducing a succession T1, T2,..., Tn of theories, using in the induction of theory Ti all the previously induced theories. Each theory in the sequence may have lexical rules, context rules and hybrid ones. This iterative strategy is, to a large extent, independent of the inductive algorithm underneath. Here we consider one particular relational learning algorithm, CSC(RC), and we induce first order theories from positive examples and background knowledge that are able to successfully tag a relatively large corpus in Portuguese."
            },
            "slug": "Iterative-Part-of-Speech-Tagging-Jorge-Lopes",
            "title": {
                "fragments": [],
                "text": "Iterative Part-of-Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This article describes how iterative induction, a technique that has been proven powerful in the synthesis of recursive logic programs, has been applied to the task of part-of-speech tagging by inducing first order theories from positive examples and background knowledge that are able to successfully tag a relatively large corpus in Portuguese."
            },
            "venue": {
                "fragments": [],
                "text": "Learning Language in Logic"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34817063"
                        ],
                        "name": "A. Chhabra",
                        "slug": "A.-Chhabra",
                        "structuredName": {
                            "firstName": "Atul",
                            "lastName": "Chhabra",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chhabra"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "We note that our metrics are correlated with [17] six metrics, which were created having in mind the aggregation of pixels into different document structures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 31517603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34a78626bf0277710cb9ab192ec0c094d2bfb784",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a methodology for evaluating graphics recognition systems operating on images that contain straight lines, circles, circular arcs, and text blocks. It enables an empirical comparison of vectorization software packages and uses practical performance evaluation methods that can be applied to complete vectorization systems. The methodology includes a set of matching criteria for pairs of graphical entities, a set of performance evaluation metrics, and a benchmark for the evaluation of graphics recognition systems. The benchmark was tested on three systems. The results are reported and analyzed in the paper."
            },
            "slug": "Empirical-Performance-Evaluation-of-Graphics-Phillips-Chhabra",
            "title": {
                "fragments": [],
                "text": "Empirical Performance Evaluation of Graphics Recognition Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Presents a methodology for evaluating graphics recognition systems operating on images that contain straight lines, circles, circular arcs, and text blocks that enables an empirical comparison of vectorization software packages and uses practical performance evaluation methods that can be applied to complete vectorization systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2701105"
                        ],
                        "name": "J. Dem\u0161ar",
                        "slug": "J.-Dem\u0161ar",
                        "structuredName": {
                            "firstName": "Janez",
                            "lastName": "Dem\u0161ar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dem\u0161ar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Dem\u0161ar [6] justifies why commonly used statistical tests are inappropriate for result comparison."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Dem\u0161ar [6] explains these tests in detail."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7553535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f1408d33858a78f90f9000a34856664fc639ae4",
            "isKey": false,
            "numCitedBy": 9185,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams."
            },
            "slug": "Statistical-Comparisons-of-Classifiers-over-Data-Dem\u0161ar",
            "title": {
                "fragments": [],
                "text": "Statistical Comparisons of Classifiers over Multiple Data Sets"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers is recommended: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparisons of more classifiers over multiple data sets."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70192607"
                        ],
                        "name": "Abdullah M. Al Ghoson",
                        "slug": "Abdullah-M.-Al-Ghoson",
                        "structuredName": {
                            "firstName": "Abdullah",
                            "lastName": "Ghoson",
                            "middleNames": [
                                "M.",
                                "Al"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdullah M. Al Ghoson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "We constructed a decision tree using SAS Enterprise Miner, which aims at minimising entropy and holds three pruning parameters [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61854058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e0a940ace79e17749c8638207eddcd7b1bef8b7",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Decision tree induction and Clustering are two of the most prevalent data mining techniques used separately or together in many business applications. Most commercial data mining software tools provide these two techniques but few of them satisfy business needs.\u00a0\u00a0There are many criteria and factors to choose the most appropriate software for a particular organization. This paper aims to provide a comparative analysis for three popular data mining software tools, which are SAS\u00ae Enterprise Miner, SPSS Clementine, and IBM DB2\u00ae Intelligent Miner based on four main criteria, which are performance, functionality, usability, and auxiliary Task Support."
            },
            "slug": "Decision-Tree-Induction-&-Clustering-Techniques-In-Ghoson",
            "title": {
                "fragments": [],
                "text": "Decision Tree Induction & Clustering Techniques In SAS Enterprise Miner, SPSS Clementine, And IBM Intelligent Miner A Comparative Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper aims to provide a comparative analysis for three popular data mining software tools, which are SAS\u00ae Enterprise Miner, SPSS Clementine, and IBM DB2\u00ae Intelligent Miner based on four main criteria, which is performance, functionality, usability, and auxiliary Task Support."
            },
            "venue": {
                "fragments": [],
                "text": "BIOINFORMATICS 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744430"
                        ],
                        "name": "J. Cussens",
                        "slug": "J.-Cussens",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cussens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cussens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693549"
                        ],
                        "name": "S. D\u017eeroski",
                        "slug": "S.-D\u017eeroski",
                        "structuredName": {
                            "firstName": "Sa\u0161o",
                            "lastName": "D\u017eeroski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D\u017eeroski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6334401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fc98d7974c4c993d1ddcd7f4f3651605d65d1ab",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introductions & Overviews.- An Introduction to Inductive Logic Programming and Learning Language in Logic.- A Brief Introduction to Natural Language Processing for Non-linguists.- A Closer Look at the Automatic Induction of Linguistic Knowledge.- Learning for Semantic Interpretation: Scaling Up without Dumbing Down.- Morphology & Phonology.- Learning to Lemmatise Slovene Words.- Achievements and Prospects of Learning Word Morphology with Inductive Logic Programming.- Learning the Logic of Simple Phonotactics.- Syntax.- Grammar Induction as Substructural Inductive Logic Programming.- Experiments in Inductive Chart Parsing.- ILP in Part-of-Speech Tagging - An Overview.- Iterative Part-of-Speech Tagging.- DCG Induction Using MDL and Parsed Corpora.- Learning Log-Linear Models on Constraint-Based Grammars for Disambiguation.- Unsupervised Lexical Learning with Categorial Grammars Using the LLL Corpus.- Induction of Recursive Transfer Rules.- Learning for Text Categorization and Information Extraction with ILP.- Corpus-Based Learning of Semantic Relations by the ILP System, Asium.- Improving Learning by Choosing Examples Intelligently in Two Natural Language Tasks."
            },
            "slug": "Learning-Language-in-Logic-Cussens-D\u017eeroski",
            "title": {
                "fragments": [],
                "text": "Learning Language in Logic"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This book discusses Corpus-Based Learning of Semantic Relations by the ILP System, Asium, and Improving Learning by Choosing Examples Intelligently in Two Natural Language Tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792884"
                        ],
                        "name": "Charles M. Bishop",
                        "slug": "Charles-M.-Bishop",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles M. Bishop"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2662552"
                        ],
                        "name": "M. Svens\u00e9n",
                        "slug": "M.-Svens\u00e9n",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Svens\u00e9n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Svens\u00e9n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065164439"
                        ],
                        "name": "Goeffrey E. Hinton",
                        "slug": "Goeffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Goeffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Goeffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "Model D0 is a simple HMM. HMMs typically use P(Xi |Zi ) in their formulation; however, by noting that P(Xi |Zi ) is proportional to P(Zi |Xi )/P(Zi ) when P(Xi ) is observed, we simply used the probabilities of the decision tree in Table 4 straight into the HMM [1]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "In D, we use a Hidden Markov Model (HMM) to group of table candidates into tables; we investigate into how HMMs can best be built in document analysis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 236
                            }
                        ],
                        "text": "HMMs typically use P(Xi |Zi ) in their formulation; however, by noting that P(Xi |Zi ) is proportional to P(Zi |Xi )/P(Zi ) when P(Xi ) is observed, we simply used the probabilities of the decision tree in Table 4 straight into the HMM [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "To compensate for some discrepancies between HMMs and table-specific needs, some heuristics had to be applied."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "The results of each model show how using HMMs, incorporating in it information from different document structure recognisers, and using adaptable transition tables are good strategies when creating a table finder: in fact, both C&P simultaneously improve from model to model."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9866297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e16a64bbef0b45b38f688414872f6ef328dfb9b6",
            "isKey": true,
            "numCitedBy": 73,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system that separates text from graphics strokes in handwritten digital ink. It utilizes not just the characteristics of the strokes, but also the information provided by the gaps between the strokes, as well as the temporal characteristics of the stroke sequence. It is built using machine learning techniques that infer the internal parameters of the system from real digital ink, collected using a tablet PC."
            },
            "slug": "Distinguishing-text-from-graphics-in-on-line-ink-Bishop-Svens\u00e9n",
            "title": {
                "fragments": [],
                "text": "Distinguishing text from graphics in on-line handwritten ink"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A system that separates text from graphics strokes in handwritten digital ink is presented, built using machine learning techniques that infer the internal parameters of the system from real digital ink, collected using a tablet PC."
            },
            "venue": {
                "fragments": [],
                "text": "Ninth International Workshop on Frontiers in Handwriting Recognition"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To illustrate our metrics, we will use the example in Fig. 1, first presented in [ 11 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Hurst [ 11 ] calls this sort of approach functional, in contrast to the more common absolute approaches."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 In table segmentation, Hurst [ 11 ] proposes two metrics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Fig. 1 Image shown in [ 11 ] used here for illustration purposes"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1649340,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a7be096a4ed48b143691bdd2deeae585afebc4d6",
            "isKey": true,
            "numCitedBy": 25,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an approach to deriving an abstractgeometric model of a table from a physical representation.The technique developed uses a graph of constraints betweencells which must be satisfied in order to determinetheir relative horizontal and vertical position. The methodis evaluated with a test set of tables drawn from US Securitiesand Exchange Commission (SEC) filings."
            },
            "slug": "A-constraint-based-approach-to-table-structure-Hurst",
            "title": {
                "fragments": [],
                "text": "A constraint-based approach to table structure derivation"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An approach to deriving an abstractgeometric model of a table from a physical representation using a graph of constraints which must be satisfied in order to determinate the relative horizontal and vertical position."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46383755"
                        ],
                        "name": "D. B. Powell",
                        "slug": "D.-B.-Powell",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Powell",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. B. Powell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690704"
                        ],
                        "name": "Edward A. Lee",
                        "slug": "Edward-A.-Lee",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Lee",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward A. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144688191"
                        ],
                        "name": "W. C. Newman",
                        "slug": "W.-C.-Newman",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Newman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. C. Newman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144629409"
                        ],
                        "name": "S. Bhattacharyya",
                        "slug": "S.-Bhattacharyya",
                        "structuredName": {
                            "firstName": "Shuvra",
                            "lastName": "Bhattacharyya",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bhattacharyya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39969030"
                        ],
                        "name": "S. Ha",
                        "slug": "S.-Ha",
                        "structuredName": {
                            "firstName": "Soonhoi",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815712"
                        ],
                        "name": "D. Messerschmitt",
                        "slug": "D.-Messerschmitt",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Messerschmitt",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Messerschmitt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66891077"
                        ],
                        "name": "D. Genin",
                        "slug": "D.-Genin",
                        "structuredName": {
                            "firstName": "Dominique",
                            "lastName": "Genin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Genin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2865600"
                        ],
                        "name": "J. D. Moortel",
                        "slug": "J.-D.-Moortel",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Moortel",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. D. Moortel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1897422"
                        ],
                        "name": "D. Desmet",
                        "slug": "D.-Desmet",
                        "structuredName": {
                            "firstName": "Dirk",
                            "lastName": "Desmet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Desmet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2298414"
                        ],
                        "name": "E. V. D. Velde",
                        "slug": "E.-V.-D.-Velde",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Velde",
                            "middleNames": [
                                "F.",
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. V. D. Velde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699786"
                        ],
                        "name": "L. Hendren",
                        "slug": "L.-Hendren",
                        "structuredName": {
                            "firstName": "Laurie",
                            "lastName": "Hendren",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hendren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50318619"
                        ],
                        "name": "G. Gao",
                        "slug": "G.-Gao",
                        "structuredName": {
                            "firstName": "Guang",
                            "lastName": "Gao",
                            "middleNames": [
                                "Rong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682451"
                        ],
                        "name": "E. Altman",
                        "slug": "E.-Altman",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Altman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Altman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40590306"
                        ],
                        "name": "C. Mukherjee",
                        "slug": "C.-Mukherjee",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Mukherjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mukherjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082414"
                        ],
                        "name": "W. Ho",
                        "slug": "W.-Ho",
                        "structuredName": {
                            "firstName": "W.-H.",
                            "lastName": "Ho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Ho"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 174
                            }
                        ],
                        "text": "the results of these, we applied a technique we term flagging, which consists of creating a classifier to distinguish the cases where an algorithm is likely to make mistakes [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16892037,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47a9844bd5316af3fbd87bafceccedc8053b4066",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Managing the buffering of data along arcs is a critical part of compiling a synchronous dataflow (SDF) program. This paper shows how dataflow properties can be analyzed at compile-time to make buffering more efficient. Since the target code corresponding to each node of an SDF graph is normally obtained from a hand-optimized library of predefined blocks, the efficiency of data transfer between blocks is often the limiting factor in how closely an SDF compiler can approximate meticulous manual coding. Furthermore, in the presence of large sample-rate changes, straightforward buffering techniques can quickly exhaust limited on-chip data memory, necessitating the use of slower external memory. The techniques presented in this paper address both of these problems in a unified manner."
            },
            "slug": "Parts-that-add-up-to-a-whole-:-a-framework-for-the-Powell-Lee",
            "title": {
                "fragments": [],
                "text": "Parts that add up to a whole : a framework for the analysis of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper shows how dataflow properties can be analyzed at compile-time to make buffering more efficient in a synchronous dataflow (SDF) program."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070970"
                        ],
                        "name": "H. Varian",
                        "slug": "H.-Varian",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Varian",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Varian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "The degree by which one user prefers completeness to purity can be represented in the same chart using Utility Curves (UCs) [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 154543156,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "cfb2e9e2841c3c19b3938f4a69b75fa1edd4fb5d",
            "isKey": false,
            "numCitedBy": 2033,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The worldwide best-selling intermediate microeconomics textbook is distinguished by its remarkably up-to-date and rigorous yet accessible analytical approach. The seventh edition has been carefully updated and revised, adding a wealth of new applications and examples that analyse the important lessons offered by eBay, drug companies, the Yellow Pages and even Maine Lobstermen."
            },
            "slug": "Intermediate-Microeconomics:-A-Modern-Approach-Varian",
            "title": {
                "fragments": [],
                "text": "Intermediate Microeconomics: A Modern Approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 24
                            }
                        ],
                        "text": "\u2022 In table segmentation, Hurst [11] proposes two metrics."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "\u2022 In table functional analysis, Hurst [10] measures precision and recall separately at the attribute and data cell level; because attribute cells tend to be less frequent but mistakes more serious, the author normalises results by their relative weight in the test set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "Hurst [11] calls this sort of approach functional, in contrast to the more common absolute approaches."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 97
                            }
                        ],
                        "text": "This suggests that a uniformly sized neighbourhood (used by Ng et al. [15] in table location and Hurst [10] in functional analysis) is not the best strategy for this problem."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 48
                            }
                        ],
                        "text": "Of the 16 rows and 6 columns of the real table, Hurst\u2019s algorithm identified all rows but 9 columns."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "[15] in table location and Hurst [10] in functional analysis) is not the best strategy for this problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The interpretation of tables in text"
            },
            "venue": {
                "fragments": [],
                "text": "PhD, Edinburgh University, UK"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "\u2022 In table segmentation, Hurst [11] proposes two metrics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 31
                            }
                        ],
                        "text": "\u2022 In table functional analysis, Hurst [10] measures precision and recall separately at the attribute and data cell level; because attribute cells tend to be less frequent but mistakes more serious, the author normalises results by their relative weight in the test set."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Hurst [11] calls this sort of approach functional, in contrast to the more common absolute approaches."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "1 Image shown in [11] used here for illustration purposes"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 97
                            }
                        ],
                        "text": "This suggests that a uniformly sized neighbourhood (used by Ng et al. [15] in table location and Hurst [10] in functional analysis) is not the best strategy for this problem."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 48
                            }
                        ],
                        "text": "Of the 16 rows and 6 columns of the real table, Hurst\u2019s algorithm identified all rows but 9 columns."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Constraint-Based Approach to able Structure Derivation"
            },
            "venue": {
                "fragments": [],
                "text": "pp. 911\u2013915. ICDAR, UK"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49132848"
                        ],
                        "name": "Wang Ya-lin",
                        "slug": "Wang-Ya-lin",
                        "structuredName": {
                            "firstName": "Wang",
                            "lastName": "Ya-lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wang Ya-lin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 170
                            }
                        ],
                        "text": "In fact, several document analysis methods take as input a given document and subdivide it into its constituent parts, which are then tagged in a computer searchable way [3,25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Wang [25] combines three measures similar to Hu et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 112
                            }
                        ],
                        "text": "\u2022 In table location, they have been taken at different levels of the table\u2019s physical model: line [18,19]; cell [23,25]; full table [5]; column and row [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59721094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "096b3dad175d17788e8935027c5df24cb3e9e621",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Document-ANalysis:-Table-Structure-Understanding-Ya-lin",
            "title": {
                "fragments": [],
                "text": "Document ANalysis: Table Structure Understanding and Zone Content Classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Background pattern recognition in multi-page PDF documents"
            },
            "venue": {
                "fragments": [],
                "text": "DLIA Workshop, UK, pp. 41\u201346"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "( 2000 ) , Chapter 11 : \u201c Iterative part - of - speech tagging \u201d , Learning Language in Logic"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Iterative part-of-speech tagging \" , Learning Language in Logic"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[12] take the proportion of cases where eleven error types occurred, these error types referring to splitting or fusion of cells, lines, columns, tables and table nondetection."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Table Recognition and Combination Methods"
            },
            "venue": {
                "fragments": [],
                "text": "pp. 1237\u20131241. ICDAR, Korea"
            },
            "year": 2005
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 10,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Metrics-for-evaluating-performance-in-document-to-Silva/256074b71accf193ea742736bba0d498fdfa30c2?sort=total-citations"
}