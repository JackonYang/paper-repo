{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862313"
                        ],
                        "name": "J. Weinman",
                        "slug": "J.-Weinman",
                        "structuredName": {
                            "firstName": "Jerod",
                            "lastName": "Weinman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weinman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389846455"
                        ],
                        "name": "E. Learned-Miller",
                        "slug": "E.-Learned-Miller",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Learned-Miller",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Learned-Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1548186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fcf1755bc1fdc82e2469690d2ba7260812ab568",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Many sources of information relevant to computer vision and machine learning tasks are often underused. One example is the similarity between the elements from a novel source, such as a speaker, writer, or printed font. By comparing instances emitted by a source, we help ensure that similar instances are given the same label. Previous approaches have clustered instances prior to recognition. We propose a probabilistic framework that unifies similarity with prior identity and contextual information. By fusing information sources in a single model, we eliminate unrecoverable errors that result from processing the information in separate stages and improve overall accuracy. The framework also naturally integrates dissimilarity information, which has previously been ignored. We demonstrate with an application in printed character recognition from images of signs in natural scenes."
            },
            "slug": "Improving-Recognition-of-Novel-Input-with-Weinman-Learned-Miller",
            "title": {
                "fragments": [],
                "text": "Improving Recognition of Novel Input with Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A probabilistic framework that unifies similarity with prior identity and contextual information is proposed that fusing information sources in a single model to eliminate unrecoverable errors that result from processing the information in separate stages and improve overall accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069641275"
                        ],
                        "name": "Paul Clark",
                        "slug": "Paul-Clark",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728108"
                        ],
                        "name": "M. Mirmehdi",
                        "slug": "M.-Mirmehdi",
                        "structuredName": {
                            "firstName": "Majid",
                            "lastName": "Mirmehdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mirmehdi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 134
                            }
                        ],
                        "text": "Most of the work in this field is based on locating and rectifying the text areas (e.g. (Kumar et al., 2007), (Krempp et al., 2002), (Clark and Mirmehdi, 2002) and (Brown et al., 2007)), followed by the application of OCR techniques (Kise and Doermann, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 21029507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed92505aa6d7fb60c0ef764e60e0ee043e28eb7a",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. We present two different approaches to the location and recovery of text in images of real scenes. The techniques we describe are invariant to the scale and 3D orientation of the text, and allow recovery of text in cluttered scenes. The first approach uses page edges and other rectangular boundaries around text to locate a surface containing text, and to recover a fronto-parallel view. This is performed using line detection, perceptual grouping, and comparison of potential text regions using a confidence measure. The second approach uses low-level texture measures with a neural network classifier to locate regions of text in an image. Then we recover a fronto-parallel view of each located paragraph of text by separating the individual lines of text and determining the vanishing points of the text plane. We illustrate our results using a number of images."
            },
            "slug": "Recognising-text-in-real-scenes-Clark-Mirmehdi",
            "title": {
                "fragments": [],
                "text": "Recognising text in real scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Two different approaches to the location and recovery of text in images of real scenes are presented, one using page edges and other rectangular boundaries around text, and the other using low-level texture measures with a neural network classifier."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 24
                            }
                        ],
                        "text": "Patch descriptor (PCH) (Varma and Zisserman, 2003) is the simplest dense feature extraction method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 456211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70284b4fe852f472d4576c30f97a6fddbfef2aee",
            "isKey": false,
            "numCitedBy": 532,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We question the role that large scale filter banks have traditionally played in texture classification. It is demonstrated that textures can be classified using the joint distribution of intensity values over extremely compact neighborhoods (starting from as small as 3 /spl times/ 3 pixels square), and that this outperforms classification using filter banks with large support. We develop a novel texton based representation, which is suited to modeling this joint neighborhood distribution for MRFs. The representation is learnt from training images, and then used to classify novel images (with unknown viewpoint and lighting) into texture classes. The power of the method is demonstrated by classifying over 2800 images of all 61 textures present in the Columbia-Utrecht database. The classification performance surpasses that of recent state-of-the-art filter bank based classifiers such as Leung & Malik, Cula & Dana, and Varma & Zisserman."
            },
            "slug": "Texture-classification:-are-filter-banks-necessary-Varma-Zisserman",
            "title": {
                "fragments": [],
                "text": "Texture classification: are filter banks necessary?"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel texton based representation is developed, which is suited to modeling this joint neighborhood distribution for MRFs, and it is demonstrated that textures can be classified using the joint distribution of intensity values over extremely compact neighborhoods."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145140331"
                        ],
                        "name": "Hao Zhang",
                        "slug": "Hao-Zhang",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 9
                            }
                        ],
                        "text": ", 1998), (Zhang et al., 2006) and other works on the MNIST"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 140
                            }
                        ],
                        "text": "Simpler recognition pipelines based on classifying raw images have been widely explored for digits recognition (see (le Cun et al., 1998), (Zhang et al., 2006) and other works on the MNIST\nand USPS datasets)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 274094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ceb0e1a86dc35e21ce5f0524c8476f15e1b08988",
            "isKey": false,
            "numCitedBy": 1278,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider visual category recognition in the framework of measuring similarities, or equivalently perceptual distances, to prototype examples of categories. This approach is quite flexible, and permits recognition based on color, texture, and particularly shape, in a homogeneous framework. While nearest neighbor classifiers are natural in this setting, they suffer from the problem of high variance (in bias-variance decomposition) in the case of limited sampling. Alternatively, one could use support vector machines but they involve time-consuming optimization and computation of pairwise distances. We propose a hybrid of these two methods which deals naturally with the multiclass setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice. The basic idea is to find close neighbors to a query sample and train a local support vector machine that preserves the distance function on the collection of neighbors. Our method can be applied to large, multiclass data sets for which it outperforms nearest neighbor and support vector machines, and remains efficient when the problem becomes intractable for support vector machines. A wide variety of distance functions can be used and our experiments show state-of-the-art performance on a number of benchmark data sets for shape and texture classification (MNIST, USPS, CUReT) and object recognition (Caltech- 101). On Caltech-101 we achieved a correct classification rate of 59.05%(\u00b10.56%) at 15 training images per class, and 66.23%(\u00b10.48%) at 30 training images."
            },
            "slug": "SVM-KNN:-Discriminative-Nearest-Neighbor-for-Visual-Zhang-Berg",
            "title": {
                "fragments": [],
                "text": "SVM-KNN: Discriminative Nearest Neighbor Classification for Visual Category Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This work considers visual category recognition in the framework of measuring similarities, or equivalently perceptual distances, to prototype examples of categories and proposes a hybrid of these two methods which deals naturally with the multiclass setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3214795,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7417d7dcf6152736612e3f04ccc72731dc8d9505",
            "isKey": false,
            "numCitedBy": 418,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new approach to material classification under unknown viewpoint and illumination. Our texture model is based on the statistical distribution of clustered filter responses. However, unlike previous 3D texton representations, we use rotationally invariant filters and cluster in an extremely low dimensional space. Having built a texton dictionary, we present a novel method of classifying a single image without requiring any a priori knowledge about the viewing or illumination conditions under which it was photographed. We argue that using rotationally invariant filters while clustering in such a low dimensional space improves classification performance and demonstrate this claim with results on all 61 textures in the Columbia-Utrecht database. We then proceed to show how texture models can be further extended by compensating for viewpoint changes using weak isotropy.The new clustering and classification methods are compared to those of Leung and Malik (ICCV 1999), Schmid (CVPR 2001) and Cula and Dana (CVPR 2001), which are the current state-of-the-art approaches."
            },
            "slug": "Classifying-Images-of-Materials:-Achieving-and-Varma-Zisserman",
            "title": {
                "fragments": [],
                "text": "Classifying Images of Materials: Achieving Viewpoint and Illumination Independence"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper presents a novel method of classifying a single image without requiring any a priori knowledge about the viewing or illumination conditions under which it was photographed, and argues that using rotationally invariant filters while clustering in such a low dimensional space improves classification performance."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 12
                            }
                        ],
                        "text": "Spin image (Lazebnik et al., 2005), (Johnson and Herbert, 1999) is a two-dimensional histogram encoding the distribution of image brightness values in the neighborhood of a particular reference point."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206763997,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "72bf4b2ce534b95bc24118491dbc4f8d550734a2",
            "isKey": false,
            "numCitedBy": 1158,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a texture representation suitable for recognizing images of textured surfaces under a wide range of transformations, including viewpoint changes and nonrigid deformations. At the feature extraction stage, a sparse set of affine Harris and Laplacian regions is found in the image. Each of these regions can be thought of as a texture element having a characteristic elliptic shape and a distinctive appearance pattern. This pattern is captured in an affine-invariant fashion via a process of shape normalization followed by the computation of two novel descriptors, the spin image and the RIFT descriptor. When affine invariance is not required, the original elliptical shape serves as an additional discriminative feature for texture recognition. The proposed approach is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints."
            },
            "slug": "A-sparse-texture-representation-using-local-affine-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "A sparse texture representation using local affine regions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The proposed texture representation is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109862994"
                        ],
                        "name": "Sunil Kumar",
                        "slug": "Sunil-Kumar",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sunil Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110344379"
                        ],
                        "name": "Rajat Gupta",
                        "slug": "Rajat-Gupta",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajat Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48676526"
                        ],
                        "name": "N. Khanna",
                        "slug": "N.-Khanna",
                        "structuredName": {
                            "firstName": "Nitin",
                            "lastName": "Khanna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Khanna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144725842"
                        ],
                        "name": "S. Chaudhury",
                        "slug": "S.-Chaudhury",
                        "structuredName": {
                            "firstName": "Santanu",
                            "lastName": "Chaudhury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chaudhury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705669"
                        ],
                        "name": "S. Joshi",
                        "slug": "S.-Joshi",
                        "structuredName": {
                            "firstName": "Shiv",
                            "lastName": "Joshi",
                            "middleNames": [
                                "Dutt"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Joshi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 89
                            }
                        ],
                        "text": "Most of the work in this field is based on locating and rectifying the text areas (e.g. (Kumar et al., 2007), (Krempp et al., 2002), (Clark and Mirmehdi, 2002) and (Brown et al., 2007)), followed by the application of OCR techniques (Kise and Doermann, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1223283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "909f2c6dec43e702d425b6e5166043d878e42996",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we have proposed a novel scheme for the extraction of textual areas of an image using globally matched wavelet filters. A clustering-based technique has been devised for estimating globally matched wavelet filters using a collection of groundtruth images. We have extended our text extraction scheme for the segmentation of document images into text, background, and picture components (which include graphics and continuous tone images). Multiple, two-class Fisher classifiers have been used for this purpose. We also exploit contextual information by using a Markov random field formulation-based pixel labeling scheme for refinement of the segmentation results. Experimental results have established effectiveness of our approach."
            },
            "slug": "Text-Extraction-and-Document-Image-Segmentation-and-Kumar-Gupta",
            "title": {
                "fragments": [],
                "text": "Text Extraction and Document Image Segmentation Using Matched Wavelets and MRF Model"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A clustering-based technique has been devised for estimating globally matched wavelet filters using a collection of groundtruth images and a text extraction scheme for the segmentation of document images into text, background, and picture components is extended."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82117876"
                        ],
                        "name": "F. Jurie",
                        "slug": "F.-Jurie",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Jurie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jurie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 233
                            }
                        ],
                        "text": "This is achieved, for instance, by grouping the low-level features collected from an image corpus into a specified number of clusters using an unsupervised algorithm such asK-Means(for other methods of generating the vocabulary see (Jurie and Triggs, 2005))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11117513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d32093cd04d6beffb6d757f58b5ac950543ff7d",
            "isKey": false,
            "numCitedBy": 896,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual codebook based quantization of robust appearance descriptors extracted from local image patches is an effective means of capturing image statistics for texture analysis and scene classification. Codebooks are usually constructed by using a method such as k-means to cluster the descriptor vectors of patches sampled either densely ('textons') or sparsely ('bags of features' based on key-points or salience measures) from a set of training images. This works well for texture analysis in homogeneous images, but the images that arise in natural object recognition tasks have far less uniform statistics. We show that for dense sampling, k-means over-adapts to this, clustering centres almost exclusively around the densest few regions in descriptor space and thus failing to code other informative regions. This gives suboptimal codes that are no better than using randomly selected centres. We describe a scalable acceptance-radius based clusterer that generates better codebooks and study its performance on several image classification tasks. We also show that dense representations outperform equivalent keypoint based ones on these tasks and that SVM or mutual information based feature selection starting from a dense codebook further improves the performance."
            },
            "slug": "Creating-efficient-codebooks-for-visual-recognition-Jurie-Triggs",
            "title": {
                "fragments": [],
                "text": "Creating efficient codebooks for visual recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that dense representations outperform equivalent keypoint based ones on these tasks and that SVM or mutual information based feature selection starting from a dense codebook further improves the performance."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 120
                            }
                        ],
                        "text": "Simpler recognition pipelines based on classifying raw images have been widely explored for digits recognition (see (le Cun et al., 1998), (Zhang et al., 2006) and other works on the MNIST\nand USPS datasets)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35236,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Not only did we try out shape and edge based features, such as Shape Context, Geometric Blur and SIFT, but also features used for representing texture, such as filter responses, patches and Spin Images, since these were found to work well in (Weinman and Learned Miller, 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "As regards features, the shape based features, Geometric Blur and Shape Context, consistently outperformed SIFT as well as the appearance based features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 238
                            }
                        ],
                        "text": "The features were also evaluated using SVMs with RBF kernels for theImg dataset, leading to the re-\n2http://www.abbyy.com 3http://algoval.essex.ac.uk/icdar\nFeature Fonts Hand Images\nGB 69.71\u00b10.64 65.40\u00b10.58 47.09 SC 64.83\u00b10.60 67.57\u00b11.40 34.41 SIFT 46.94\u00b10.71 44.16\u00b10.79 20.75 Patches 44.93\u00b10.65 69.41\u00b10.72 21.40 SPIN 28.75\u00b10.76 26.32\u00b10.42 11.83 MR8 30.71\u00b10.67 25.33\u00b10.63 10.43 ABBYY 66.05\u00b10.00 \u2013 30.77 # train splits 10 5 1\nTable 2: Classification results ("
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 42
                            }
                        ],
                        "text": "Scale Invariant Feature Transform (SIFT) (Lowe, 1999) are extracted on points located by the Harris Hessian-Laplace detector, which gives affine transform parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "The same interest point locations used for SIFT were used for spin images."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 21
                            }
                        ],
                        "text": "Geometric Blur (GB) (Berg et al., 2005) is a feature extractor with a sampling method similar to that of SC, but instead of histogramming points, the region around an interest point is blurred according to the distance from this point."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6055435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12c7fc38debaf3589e712973642246bd54fe63b3",
            "isKey": false,
            "numCitedBy": 956,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We approach recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points. This algorithm sets up correspondence as an integer quadratic programming problem, where the cost function has terms based on similarity of corresponding geometric blur point descriptors as well as the geometric distortion between pairs of corresponding feature points. The algorithm handles outliers, and thus enables matching of exemplars to query images in the presence of occlusion and clutter. Given the correspondences, we estimate an aligning transform, typically a regularized thin plate spline, resulting in a dense correspondence between the two shapes. Object recognition is then handled in a nearest neighbor framework where the distance between exemplar and query is the matching cost between corresponding points. We show results on two datasets. One is the Caltech 101 dataset (Fei-Fei, Fergus and Perona), an extremely challenging dataset with large intraclass variation. Our approach yields a 48% correct classification rate, compared to Fei-Fei et al 's 16%. We also show results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "slug": "Shape-matching-and-object-recognition-using-low-Berg-Berg",
            "title": {
                "fragments": [],
                "text": "Shape matching and object recognition using low distortion correspondences"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work approaches recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points, and shows results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144586498"
                        ],
                        "name": "R. Plamondon",
                        "slug": "R.-Plamondon",
                        "structuredName": {
                            "firstName": "R\u00e9jean",
                            "lastName": "Plamondon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Plamondon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 60
                            }
                        ],
                        "text": "Methods for off-line recognition of handprinted characters (Plamondon and Srihari, 2000), (Pal et al., 2007) have successfully tackled the problem of intra-class variation due to differing writing styles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15782139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d12864a8acbab1830be755bfb9cb177e31ca5e20",
            "isKey": false,
            "numCitedBy": 2742,
            "numCiting": 719,
            "paperAbstract": {
                "fragments": [],
                "text": "Handwriting has continued to persist as a means of communication and recording information in day-to-day life even with the introduction of new technologies. Given its ubiquity in human transactions, machine recognition of handwriting has practical significance, as in reading handwritten notes in a PDA, in postal addresses on envelopes, in amounts in bank checks, in handwritten fields in forms, etc. This overview describes the nature of handwritten language, how it is transduced into electronic data, and the basic concepts behind written language recognition algorithms. Both the online case (which pertains to the availability of trajectory data during writing) and the off-line case (which pertains to scanned images) are considered. Algorithms for preprocessing, character and word recognition, and performance with practical systems are indicated. Other fields of application, like signature verification, writer authentification, handwriting learning tools are also considered."
            },
            "slug": "On-Line-and-Off-Line-Handwriting-Recognition:-A-Plamondon-Srihari",
            "title": {
                "fragments": [],
                "text": "On-Line and Off-Line Handwriting Recognition: A Comprehensive Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The nature of handwritten language, how it is transduced into electronic data, and the basic concepts behind written language recognition algorithms are described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 78
                            }
                        ],
                        "text": "Another approach is based on modeling this as a shape matching problem (e.g. (Belongie et al., 2002)): several shape descriptors are detected and extracted and point-by-point matching is computed between pairs of images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 20
                            }
                        ],
                        "text": "Shape Contexts(SC) (Belongie et al., 2002) is a descriptor for point sets and binary images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "(Belongie et al., 2002)): several shape descriptors are detected and extracted and point-by-point matching is computed between pairs of images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 129468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "faf8444bad76e8aa727c8b2df42fefe7b8242957",
            "isKey": true,
            "numCitedBy": 5812,
            "numCiting": 94,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents my work on computing shape models that are computationally fast and invariant basic transformations like translation, scaling and rotation. In this paper, I propose shape detection using a feature called shape context. Shape context describes all boundary points of a shape with respect to any single boundary point. Thus it is descriptive of the shape of the object. Object recognition can be achieved by matching this feature with a priori knowledge of the shape context of the boundary points of the object. Experimental results are promising on handwritten digits, trademark images."
            },
            "slug": "Shape-matching-and-object-recognition-using-shape-Belongie-Malik",
            "title": {
                "fragments": [],
                "text": "Shape matching and object recognition using shape contexts"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This paper presents work on computing shape models that are computationally fast and invariant basic transformations like translation, scaling and rotation, and proposes shape detection using a feature called shape context, which is descriptive of the shape of the object."
            },
            "venue": {
                "fragments": [],
                "text": "2010 3rd International Conference on Computer Science and Information Technology"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52118596"
                        ],
                        "name": "S. Krempp",
                        "slug": "S.-Krempp",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Krempp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Krempp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4801654"
                        ],
                        "name": "Y. Amit",
                        "slug": "Y.-Amit",
                        "structuredName": {
                            "firstName": "Yali",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Amit"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 9
                            }
                        ],
                        "text": ", 2007), (Krempp et al., 2002), (Clark and Mirmehdi, 2002) and (Brown et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 111
                            }
                        ],
                        "text": "Most of the work in this field is based on locating and rectifying the text areas (e.g. (Kumar et al., 2007), (Krempp et al., 2002), (Clark and Mirmehdi, 2002) and (Brown et al., 2007)), followed by the application of OCR techniques (Kise and Doermann, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6386555,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61b933b8ef5b10ae4f6491a89f89972322534cf0",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Our long-range goal is detecting instances from a large number of object classes in a computationally efficient manner. Detectors involving a hierarchy of tests based on edges have been used elsewhere and shown to be quite fast online. However, significant further gains in efficiency in representation, error rates and computation can be realized if the family of detectors is constructed from common parts. Our parts are flexible, extended edge configurations; they are learned, not pre-designed. In training, object classes are presented sequentially; the objective is then to accommodate new classes by maximally reusing parts. Ideally, the number of distinct parts in the system would grow much more slowly than linearly with the number of classes. Initial experiments on learning to detect several hundred LTEXsymbols are encouraging."
            },
            "slug": "Sequential-Learning-of-Reusable-Parts-for-Object-Krempp-Geman",
            "title": {
                "fragments": [],
                "text": "Sequential Learning of Reusable Parts for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Initial experiments on learning to detect several hundred LTEXsymbols are encouraging, and significant further gains in efficiency in representation, error rates and computation can be realized if the family of detectors is constructed from common parts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3037691"
                        ],
                        "name": "A. Johnson",
                        "slug": "A.-Johnson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Johnson",
                            "middleNames": [
                                "Edie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 37
                            }
                        ],
                        "text": "Spin image (Lazebnik et al., 2005), (Johnson and Herbert, 1999) is a two-dimensional histogram encoding the distribution of image brightness values in the neighborhood of a particular reference point."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 9
                            }
                        ],
                        "text": ", 2005), (Johnson and Herbert, 1999) is a two-dimensional histogram encoding the distribution of image brightness values in the neighborhood of a particular reference point."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1377132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df6c0c55864252090b4099237aa821a6c75b52c2",
            "isKey": false,
            "numCitedBy": 2634,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a 3D shape-based object recognition system for simultaneous recognition of multiple objects in scenes containing clutter and occlusion. Recognition is based on matching surfaces by matching points using the spin image representation. The spin image is a data level shape descriptor that is used to match surfaces represented as surface meshes. We present a compression scheme for spin images that results in efficient multiple object recognition which we verify with results showing the simultaneous recognition of multiple objects from a library of 20 models. Furthermore, we demonstrate the robust performance of recognition in the presence of clutter and occlusion through analysis of recognition trials on 100 scenes."
            },
            "slug": "Using-Spin-Images-for-Efficient-Object-Recognition-Johnson-Hebert",
            "title": {
                "fragments": [],
                "text": "Using Spin Images for Efficient Object Recognition in Cluttered 3D Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A compression scheme for spin images that results in efficient multiple object recognition which is verified with results showing the simultaneous recognition of multiple objects from a library of 20 models."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144411536"
                        ],
                        "name": "Y. Jin",
                        "slug": "Y.-Jin",
                        "structuredName": {
                            "firstName": "Ya",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 1
                            }
                        ],
                        "text": "(Jin and Geman, 2006) introduced composition machines for constructing probabilistic hierarchical image models which accommodate contextual relationships."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10695459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15d48f8e1739ab85bb409b5a8813787534cabafc",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "It is widely conjectured that the excellent ROC performance of biological vision systems is due in large part to the exploitation of context at each of many levels in a part/whole hierarchy. We propose a mathematical framework (a \"composition machine\") for constructing probabilistic hierarchical image models, designed to accommodate arbitrary contextual relationships, and we build a demonstration system for reading Massachusetts license plates in an image set collected at Logan Airport. The demonstration system detects and correctly reads more than 98% of the plates, with a negligible rate of false detection. Unlike a formal grammar, the architecture of a composition machine does not exclude the sharing of sub-parts among multiple entities, and does not limit interpretations to single trees (e.g. a scene can have multiple license plates, or no plates at all). In this sense, the architecture is more like a general Bayesian network than a formal grammar. On the other hand, unlike a Bayesian network, the distribution is non-Markovian, and therefore more like a probabilistic context-sensitive grammar. The conceptualization and construction of a composition machine is facilitated by its formulation as the result of a series of non-Markovian perturbations of a \"Markov backbone.\""
            },
            "slug": "Context-and-Hierarchy-in-a-Probabilistic-Image-Jin-Geman",
            "title": {
                "fragments": [],
                "text": "Context and Hierarchy in a Probabilistic Image Model"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A mathematical framework for constructing probabilistic hierarchical image models, designed to accommodate arbitrary contextual relationships, is proposed, and a demonstration system for reading Massachusetts license plates in an image set collected at Logan Airport is built."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789036"
                        ],
                        "name": "Debajyoti Ray",
                        "slug": "Debajyoti-Ray",
                        "structuredName": {
                            "firstName": "Debajyoti",
                            "lastName": "Ray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Debajyoti Ray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 90
                            }
                        ],
                        "text": "An additional experiment was performed with the multiple kernel learning (MKL) method of (Varma and Ray, 2007), which gave stateof-the-art results in the Caltech256 challenge."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 119
                            }
                        ],
                        "text": "The best result on theEnglish Imgdatabase was 55.26% and was obtained by the multiple kernel learning (MKL) method of (Varma and Ray, 2007) when trained using 15Img samples per class."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 69
                            }
                        ],
                        "text": "26% and was obtained by the multiple kernel learning (MKL) method of (Varma and Ray, 2007) when trained using 15Img samples per class."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13942014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3edd9e15976ca3aa2d627d41384e1f0908a91632",
            "isKey": false,
            "numCitedBy": 582,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the problem of learning optimal descriptors for a given classification task. Many hand-crafted descriptors have been proposed in the literature for measuring visual similarity. Looking past initial differences, what really distinguishes one descriptor from another is the tradeoff that it achieves between discriminative power and invariance. Since this trade-off must vary from task to task, no single descriptor can be optimal in all situations. Our focus, in this paper, is on learning the optimal tradeoff for classification given a particular training set and prior constraints. The problem is posed in the kernel learning framework. We learn the optimal, domain-specific kernel as a combination of base kernels corresponding to base features which achieve different levels of trade-off (such as no invariance, rotation invariance, scale invariance, affine invariance, etc.) This leads to a convex optimisation problem with a unique global optimum which can be solved for efficiently. The method is shown to achieve state-of-the-art performance on the UIUC textures, Oxford flowers and Cal- tech 101 datasets."
            },
            "slug": "Learning-The-Discriminative-Power-Invariance-Varma-Ray",
            "title": {
                "fragments": [],
                "text": "Learning The Discriminative Power-Invariance Trade-Off"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This paper investigates the problem of learning optimal descriptors for a given classification task using the kernel learning framework and learns the optimal, domain-specific kernel as a combination of base kernels corresponding to base features which achieve different levels of trade-off."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143955418"
                        ],
                        "name": "M. S. Brown",
                        "slug": "M.-S.-Brown",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Brown",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. S. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118253366"
                        ],
                        "name": "Mingxuan Sun",
                        "slug": "Mingxuan-Sun",
                        "structuredName": {
                            "firstName": "Mingxuan",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingxuan Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38958903"
                        ],
                        "name": "Ruigang Yang",
                        "slug": "Ruigang-Yang",
                        "structuredName": {
                            "firstName": "Ruigang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruigang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058466711"
                        ],
                        "name": "Lin Yun",
                        "slug": "Lin-Yun",
                        "structuredName": {
                            "firstName": "Lin",
                            "lastName": "Yun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lin Yun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9324035"
                        ],
                        "name": "W. B. Seales",
                        "slug": "W.-B.-Seales",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Seales",
                            "middleNames": [
                                "Brent"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. B. Seales"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 40
                            }
                        ],
                        "text": ", 2002), (Clark and Mirmehdi, 2002) and (Brown et al., 2007)), followed by the application of OCR techniques (Kise and Doermann, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 165
                            }
                        ],
                        "text": "Most of the work in this field is based on locating and rectifying the text areas (e.g. (Kumar et al., 2007), (Krempp et al., 2002), (Clark and Mirmehdi, 2002) and (Brown et al., 2007)), followed by the application of OCR techniques (Kise and Doermann, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2124025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be093b79947b64a8de922f7350a946915d42ea3d",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a framework to restore the 2D content printed on documents in the presence of geometric distortion and nonuniform illumination. Compared with text-based document imaging approaches that correct distortion to a level necessary to obtain sufficiently readable text or to facilitate optical character recognition (OCR), our work targets nontextual documents where the original printed content is desired. To achieve this goal, our framework acquires a 3D scan of the document's surface together with a high-resolution image. Conformal mapping is used to rectify geometric distortion by mapping the 3D surface back to a plane while minimizing angular distortion. This conformal \"deskewing\" assumes no parametric model of the document's surface and is suitable for arbitrary distortions. Illumination correction is performed by using the 3D shape to distinguish content gradient edges from illumination gradient edges in the high-resolution image. Integration is performed using only the content edges to obtain a reflectance image with significantly less illumination artifacts. This approach makes no assumptions about light sources and their positions. The results from the geometric and photometric correction are combined to produce the final output."
            },
            "slug": "Restoring-2D-Content-from-Distorted-Documents-Brown-Sun",
            "title": {
                "fragments": [],
                "text": "Restoring 2D Content from Distorted Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This paper presents a framework to restore the 2D content printed on documents in the presence of geometric distortion and nonuniform illumination, and assumes no parametric model of the document's surface and is suitable for arbitrary distortions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Not only did we try out shape and edge based features, such as Shape Context, Geometric Blur and SIFT, but also features used for representing texture, such as filter responses, patches and Spin Images, since these were found to work well in (Weinman and Learned Miller, 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "As regards features, the shape based features, Geometric Blur and Shape Context, consistently outperformed SIFT as well as the appearance based features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 238
                            }
                        ],
                        "text": "The features were also evaluated using SVMs with RBF kernels for theImg dataset, leading to the re-\n2http://www.abbyy.com 3http://algoval.essex.ac.uk/icdar\nFeature Fonts Hand Images\nGB 69.71\u00b10.64 65.40\u00b10.58 47.09 SC 64.83\u00b10.60 67.57\u00b11.40 34.41 SIFT 46.94\u00b10.71 44.16\u00b10.79 20.75 Patches 44.93\u00b10.65 69.41\u00b10.72 21.40 SPIN 28.75\u00b10.76 26.32\u00b10.42 11.83 MR8 30.71\u00b10.67 25.33\u00b10.63 10.43 ABBYY 66.05\u00b10.00 \u2013 30.77 # train splits 10 5 1\nTable 2: Classification results ("
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 42
                            }
                        ],
                        "text": "Scale Invariant Feature Transform (SIFT) (Lowe, 1999) are extracted on points located by the Harris Hessian-Laplace detector, which gives affine transform parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "The same interest point locations used for SIFT were used for spin images."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 234
                            }
                        ],
                        "text": "Most of the work in this field is based on locating and rectifying the text areas (e.g. (Kumar et al., 2007), (Krempp et al., 2002), (Clark and Mirmehdi, 2002) and (Brown et al., 2007)), followed by the application of OCR techniques (Kise and Doermann, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the Second International Workshop on Camerabased Document Analysis and Recognition CBDAR"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Workshop on Camerabased Document Analysis and Recognition CBDAR"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 15
                            }
                        ],
                        "text": "For instance, (Tu et al., 2005) used insights from natural language processing and present a Markov chain framework for parsing images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "age parsing : Unifying segmentation , detection , and recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 233
                            }
                        ],
                        "text": "This is achieved, for instance, by grouping the low-level features collected from an image corpus into a specified number of clusters using an unsupervised algorithm such asK-Means(for other methods of generating the vocabulary see (Jurie and Triggs, 2005))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Creating efficient codebook"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 134
                            }
                        ],
                        "text": "Most of the work in this field is based on locating and rectifying the text areas (e.g. (Kumar et al., 2007), (Krempp et al., 2002), (Clark and Mirmehdi, 2002) and (Brown et al., 2007)), followed by the application of OCR techniques (Kise and Doermann, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognising text in real scenes.International"
            },
            "venue": {
                "fragments": [],
                "text": "Journal on Document Analysis and Recognition"
            },
            "year": 2002
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 23,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Character-Recognition-in-Natural-Images-Campos-Babu/dbbd5fdc09349bbfdee7aa7365a9d37716852b32?sort=total-citations"
}