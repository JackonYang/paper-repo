{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8909922"
                        ],
                        "name": "N. Intrator",
                        "slug": "N.-Intrator",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Intrator",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Intrator"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 0
                            }
                        ],
                        "text": "Intrator, 1990). The back-propagation experiments Hinton, G. E. and S. J. Nowlan (1990) A'eural Cornwere done by Charles M."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 34
                            }
                        ],
                        "text": "Mathematical details are given in Intrator (1990)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 36
                            }
                        ],
                        "text": "The full derivation can be found in Intrator (1990a). The lateral inhibition network performs a direct search of k-dimensional projections together, which may finJ a richer structure that a stepwise approach may miss, e.g. see example 14.1 Huber (1985)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 200
                            }
                        ],
                        "text": "Mean field theory for a network based on these neurons is presented in (Scofield and Unsupervised Fcaturc Extracting Nctwork Cooper, 1985; Cooper and Scofield, 1988), statistical analysis is given in Intrator (1990c) computer simulations and biological relevance are discussed in (Soul et )p."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 36
                            }
                        ],
                        "text": "The full derivation can be found in Intrator (1990a). The lateral inhibition network performs a direct search of k-dimensional projections together, which may finJ a richer structure that a stepwise approach may miss, e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29674074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f56fcd47ecfda8433b573ba473498d630482c60",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper suggests a statistical framework for the parameter estimation problem associated with unsupervised learning in a neural network, leading to an exploratory projection pursuit network that performs feature extraction, or dimensionality reduction."
            },
            "slug": "A-Neural-Network-for-Feature-Extraction-Intrator",
            "title": {
                "fragments": [],
                "text": "A Neural Network for Feature Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The paper suggests a statistical framework for the parameter estimation problem associated with unsupervised learning in a neural network, leading to an exploratory projection pursuit network that performs feature extraction, or dimensionality reduction."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8909922"
                        ],
                        "name": "N. Intrator",
                        "slug": "N.-Intrator",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Intrator",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Intrator"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30194578"
                        ],
                        "name": "J. Gold",
                        "slug": "J.-Gold",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Gold",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8654445,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0f0e831679484543e1e81ea618a2ce36f46243d",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an object recognition scheme based on a method for feature extraction from gray level images that corresponds to recent statistical theory, called projection pursuit, and is derived from a biologically motivated feature extracting neuron. To evaluate the performance of this method we use a set of very detailed psychophysical three-dimensional object recognition experiments (Blthoff and Edelman 1992)."
            },
            "slug": "Three-Dimensional-Object-Recognition-Using-an-BCM-Intrator-Gold",
            "title": {
                "fragments": [],
                "text": "Three-Dimensional Object Recognition Using an Unsupervised BCM Network: The Usefulness of Distinguishing Features"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "An object recognition scheme based on a method for feature extraction from gray level images that corresponds to recent statistical theory, called projection pursuit, and is derived from a biologically motivated feature extracting neuron is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8909922"
                        ],
                        "name": "N. Intrator",
                        "slug": "N.-Intrator",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Intrator",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Intrator"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8926225,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1046704930644e99b1305228c71216dfcbead6c",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 104,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel classification and regression method that combines exploratory projection pursuit (unsupervised training) with projection pursuit regression (supervised training), to yield a new family of cost/complexity penalty terms. Some improved generalization properties are demonstrated on real-world problems."
            },
            "slug": "Combining-Exploratory-Projection-Pursuit-and-with-Intrator",
            "title": {
                "fragments": [],
                "text": "Combining Exploratory Projection Pursuit and Projection Pursuit Regression with Application to Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A novel classification and regression method that combines exploratory projection pursuit (unsupervised training) with projection pursuit regression ( supervised training), to yield a new family of cost/complexity penalty terms."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8909922"
                        ],
                        "name": "N. Intrator",
                        "slug": "N.-Intrator",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Intrator",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Intrator"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1918411"
                        ],
                        "name": "G. Tajchman",
                        "slug": "G.-Tajchman",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Tajchman",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tajchman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56717147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4585922e664653bf71160248547059778843af62",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors explore the application of a novel classification method that combines supervised and unsupervised training, and compare its performance to various more classical methods. The authors first construct a detailed high dimensional representation of the speech signal using Lyon's cochlear model and then optimally reduce its dimensionality. The resulting low dimensional projection retains the information needed for robust speech recognition.<<ETX>>"
            },
            "slug": "Supervised-and-unsupervised-feature-extraction-from-Intrator-Tajchman",
            "title": {
                "fragments": [],
                "text": "Supervised and unsupervised feature extraction from a cochlear model for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The authors first construct a detailed high dimensional representation of the speech signal using Lyon's cochlear model and then optimally reduce its dimensionality, so that the resulting low dimensional projection retains the information needed for robust speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing Proceedings of the 1991 IEEE Workshop"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726997"
                        ],
                        "name": "E. Oja",
                        "slug": "E.-Oja",
                        "structuredName": {
                            "firstName": "Erkki",
                            "lastName": "Oja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Oja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16577977,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3e00dd12caea7c4dab1633a35d1da3cb2e76b420",
            "isKey": false,
            "numCitedBy": 2357,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A simple linear neuron model with constrained Hebbian-type synaptic modification is analyzed and a new class of unconstrained learning rules is derived. It is shown that the model neuron tends to extract the principal component from a stationary input vector sequence."
            },
            "slug": "Simplified-neuron-model-as-a-principal-component-Oja",
            "title": {
                "fragments": [],
                "text": "Simplified neuron model as a principal component analyzer"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A simple linear neuron model with constrained Hebbian-type synaptic modification is analyzed and a new class of unconstrained learning rules is derived."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of mathematical biology"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 249
                            }
                        ],
                        "text": "\u2026dimensionality reduction methods, called exploratory projection pursuit, is based on seeking interesting projections of high-dimensional data points (Kruskal 1972; Friedman and Feature Extraction Using an Unsupervised Neural Network 99 Tukey 1974; Friedman 1987; Huber 1985, for review)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Friedman (1987) argues that the most computationally efficient measures are based on polynomial moments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 71
                            }
                        ],
                        "text": "In those cases it is possible to make such transformations beforehand (Friedman 1987), and then assume that the data possess these invariant properties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Friedman (1987)  argues that the most computationally efficient measures are based on polynomial moments.,In those cases it is possible to make such transformations beforehand ( Friedman 1987 ), and then assume that the data possess these invariant properties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120727315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cce218b91cf634413ef9a71f702bd37b1a9ad2a6",
            "isKey": true,
            "numCitedBy": 590,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A new projection pursuit algorithm for exploring multivariate data is presented that has both statistical and computational advantages over previous methods. A number of practical issues concerning its application are addressed. A connection to multivariate density estimation is established, and its properties are investigated through simulation studies and application to real data. The goal of exploratory projection pursuit is to use the data to find low- (one-, two-, or three-) dimensional projections that provide the most revealing views of the full-dimensional data. With these views the human gift for pattern recognition can be applied to help discover effects that may not have been anticipated in advance. Since linear effects are directly captured by the covariance structure of the variable pairs (which are straightforward to estimate) the emphasis here is on the discovery of nonlinear effects such as clustering or other general nonlinear associations among the variables. Although arbitrary ..."
            },
            "slug": "Exploratory-Projection-Pursuit-Friedman",
            "title": {
                "fragments": [],
                "text": "Exploratory Projection Pursuit"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A new projection pursuit algorithm for exploring multivariate data is presented that has both statistical and computational advantages over previous methods and the emphasis here is on the discovery of nonlinear effects such as clustering or other general nonlinear associations among the variables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577641"
                        ],
                        "name": "R. Linsker",
                        "slug": "R.-Linsker",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Linsker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Linsker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 228
                            }
                        ],
                        "text": "Comparison with Other Feature Extraction Methods The above feature extraction method has been applied so far to various high-dimensional classification problems: extracting rotation invariant features from 3D wire-like objects (Intrator and Gold 1991) based on a set of sophisticated psychophysical experiments (Edelman and Bulthoff 1991); feature extraction from the TIMIT speech data base using Lyon's Cochlea model (Intrator and Tajchman 1991)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "The application of BCM to speech is discussed in more detail in Seebach (1991) and in a forthcoming article (Seebach and Intrator, in press)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "both in Nathan Intrator"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Nathan Intrator Figure 3: An average of the six stop consonants followed by the vowel [a] ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 6
                            }
                        ],
                        "text": "%e Intrator (1990) for comparison with principal components feature extraction and with k-NN as a classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "Mathematical details are given in Intrator (1990)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 120
                            }
                        ],
                        "text": "These assumptions are needed for the approximation of the resulting deterministic gradient descent by a stochastic one (Intrator and Cooper 1991)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "The relation between this network and the network studied by Cooper and Scofield (1988) is discussed in Intrator and Cooper (1991)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "These energy levels %e Intrator ("
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "For the nonlinear neuron, 0, is defined Nathan Intrator to be 0, = E[a*(x. m)] ."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1527671,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16d70e8af45ca0ae2c1bb73f3be6628518d40b8f",
            "isKey": true,
            "numCitedBy": 1417,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The emergence of a feature-analyzing function from the development rules of simple, multilayered networks is explored. It is shown that even a single developing cell of a layered network exhibits a remarkable set of optimization properties that are closely related to issues in statistics, theoretical physics, adaptive signal processing, the formation of knowledge representation in artificial intelligence, and information theory. The network studied is based on the visual system. These results are used to infer an information-theoretic principle that can be applied to the network as a whole, rather than a single cell. The organizing principle proposed is that the network connections develop in such a way as to maximize the amount of information that is preserved when signals are transformed at each processing stage, subject to certain constraints. The operation of this principle is illustrated for some simple cases.<<ETX>>"
            },
            "slug": "Self-organization-in-a-perceptual-network-Linsker",
            "title": {
                "fragments": [],
                "text": "Self-organization in a perceptual network"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "It is shown that even a single developing cell of a layered network exhibits a remarkable set of optimization properties that are closely related to issues in statistics, theoretical physics, adaptive signal processing, the formation of knowledge representation in artificial intelligence, and information theory."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8909922"
                        ],
                        "name": "N. Intrator",
                        "slug": "N.-Intrator",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Intrator",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Intrator"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8884630"
                        ],
                        "name": "L. Cooper",
                        "slug": "L.-Cooper",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Cooper",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cooper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 104
                            }
                        ],
                        "text": "The relation between this network and the network studied by Cooper and Scofield (1988) is discussed in Intrator and Cooper (1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 120
                            }
                        ],
                        "text": "These assumptions are needed for the approximation of the resulting deterministic gradient descent by a stochastic one (Intrator and Cooper 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2376905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b62d1925b9909ab7da5132ee162960ef160c48de",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Objective-function-formulation-of-the-BCM-theory-of-Intrator-Cooper",
            "title": {
                "fragments": [],
                "text": "Objective function formulation of the BCM theory of visual cortical plasticity: Statistical connections, stability conditions"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15727980,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "de13c62828f41c863cffb7444daaa37d928272d2",
            "isKey": false,
            "numCitedBy": 508,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryA time-dependent, nonlinear model of neuronal interaction which was probabilistically analyzed in a previous article is shown here to be a natural generalization of the Hartline-Ratliff model of the Limulus retina. Although the primary physical variables in the model are the membrane potentials of neurons, the equations which govern the means and covariances of the membrane potentials are coupled through the average firing rates; as a consequence, the average firing rates control the selective storage and retrieval of covariance information. Motor learning in the cerebellar cortex is treated as a problem of covariance storage, and a prediction is made for the underlying synaptic plasticity: the change in synaptic strength between a parallel fiber and a Purkinje cell should be proportional to the covariance between discharges in the parallel fiber and the climbing fiber. Unlike previous proposals for synaptic plasticity, this prediction requires both facilitation and depression to occur (under different conditions) at the same synapse."
            },
            "slug": "Storing-covariance-with-nonlinearly-interacting-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Storing covariance with nonlinearly interacting neurons"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A time-dependent, nonlinear model of neuronal interaction which was probabilistically analyzed in a previous article is shown here to be a natural generalization of the Hartline-Ratliff model of the Limulus retina."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of mathematical biology"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2957320"
                        ],
                        "name": "C. Scofield",
                        "slug": "C.-Scofield",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Scofield",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Scofield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8884630"
                        ],
                        "name": "L. Cooper",
                        "slug": "L.-Cooper",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Cooper",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cooper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121425053,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "38aba5b35cb0d5266d0a11df8f4508add5a08744",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Recent progress in a theory of the development of neural networks and their application to visual cortex is discussed. We find, that under proper assumptions, distributed memories display some of the features of animal memory. We discuss a mechanism, consistent with known neurophysiology, by which these memories develop and modify with experience. This mechanism is applied to the problem of the development of orientation selectivity and ocular dominance in visual cortex. The proposed mechanism of synaptic evolution is based upon the competition of incoming patterns rather than converging afferents. It is found that neurons develop maximal selectivity with respect to their signal environment, and under a variety of rearing conditions develop orientation tuning curves and ocular dominance comparable to that found in experiment. Finally, we describe a model first-order anatomy of visual cortex in which we implement this form of synaptic modification."
            },
            "slug": "Development-and-properties-of-neural-networks-Scofield-Cooper",
            "title": {
                "fragments": [],
                "text": "Development and properties of neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is found that neurons develop maximal selectivity with respect to their signal environment, and under a variety of rearing conditions develop orientation tuning curves and ocular dominance comparable to that found in experiment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8909922"
                        ],
                        "name": "N. Intrator",
                        "slug": "N.-Intrator",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Intrator",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Intrator"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16533383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a23675052ea71447037baf1716444dbe689ce728",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-combination-of-supervised-and-unsupervised-Intrator",
            "title": {
                "fragments": [],
                "text": "On the combination of supervised and unsupervised learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16928,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684300"
                        ],
                        "name": "W. Stuetzle",
                        "slug": "W.-Stuetzle",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Stuetzle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Stuetzle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14183758,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "589b8659007e1124f765a5d1bd940b2bf4d79054",
            "isKey": false,
            "numCitedBy": 2178,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A new method for nonparametric multiple regression is presented. The procedure models the regression surface as a sum of general smooth functions of linear combinations of the predictor variables in an iterative manner. It is more general than standard stepwise and stagewise regression procedures, does not require the definition of a metric in the predictor space, and lends itself to graphical interpretation."
            },
            "slug": "Projection-Pursuit-Regression-Friedman-Stuetzle",
            "title": {
                "fragments": [],
                "text": "Projection Pursuit Regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8884630"
                        ],
                        "name": "L. Cooper",
                        "slug": "L.-Cooper",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Cooper",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2957320"
                        ],
                        "name": "C. Scofield",
                        "slug": "C.-Scofield",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Scofield",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Scofield"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The relation between this network and the network studied by  Cooper and Scofield (1988)  is discussed in Intrator and Cooper (1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 61
                            }
                        ],
                        "text": "The relation between this network and the network studied by Cooper and Scofield (1988) is discussed in Intrator and Cooper (1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 24322552,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "00493ee4876a02717bf761db9a913a8a654ae161",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A single-cell theory for the development of selectivity and ocular dominance in visual cortex has been generalized to incorporate more realistic neural networks that approximate the actual anatomy of small regions of cortex. In particular, we have analyzed a network consisting of excitatory and inhibitory cells, both of which may receive information from the lateral geniculate nucleus (LGN) and then interact through cortico-cortical synapses in a mean-field approximation. Our investigation of the evolution of a cell in this mean-field network indicates that many of the results on existence and stability of fixed points that have been obtained previously in the single-cell theory can be successfully generalized here. We can, in addition, make explicit further statements concerning the independent effects of excitatory and inhibitory neurons on selectivity and ocular dominance. For example, shutting off inhibitory cells lessens selectivity and alters ocular dominance (masked synapses). These inhibitory cells may be selective, but there is no theoretical necessity that they be so. Further, the intercortical inhibitory synapses do not have to be very responsive to visual experience. Most of the learning process can occur among the excitatory LGN-cortical synapses."
            },
            "slug": "Mean-field-theory-of-a-neural-network.-Cooper-Scofield",
            "title": {
                "fragments": [],
                "text": "Mean-field theory of a neural network."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Investigation of the evolution of a cell in this mean-field network indicates that many of the results on existence and stability of fixed points that have been obtained previously in the single-cell theory can be successfully generalized here."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145044772"
                        ],
                        "name": "D. Morgan",
                        "slug": "D.-Morgan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Morgan",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2957320"
                        ],
                        "name": "C. Scofield",
                        "slug": "C.-Scofield",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Scofield",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Scofield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059787600"
                        ],
                        "name": "T. M. Lorenzo",
                        "slug": "T.-M.-Lorenzo",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Lorenzo",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. M. Lorenzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2891612"
                        ],
                        "name": "E. C. Real",
                        "slug": "E.-C.-Real",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Real",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. C. Real"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66878729"
                        ],
                        "name": "D. P. Loconto",
                        "slug": "D.-P.-Loconto",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Loconto",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. P. Loconto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57333874,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4341897b2cae0fa41b09c08f5e94f5726434e40a",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Experiments using restricted Coulomb energy (RCE) and backward error propagation trained artificial neural networks (ANNs) for secondary processing in a keyword spotting application are described. Several types and configurations of neural networks are explored, including single, multiple, and hybrid networks. Several feature space transformations are used to permit the ANNs to examine the potential word in several time-invariant formats. The best performance is obtained using a multiple RCE network structure, which improves performance an average of 5% over a range of false alarm rates. The effectiveness of several ANNs as feature extraction mechanisms and as pattern classifiers is discussed relative to the keyword spotting problem. Issues pertaining to the complexity and required training time of the ANN structures are discussed.<<ETX>>"
            },
            "slug": "A-keyword-spotter-which-incorporates-neural-for-Morgan-Scofield",
            "title": {
                "fragments": [],
                "text": "A keyword spotter which incorporates neural networks for secondary processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The effectiveness of several ANNs as feature extraction mechanisms and as pattern classifiers is discussed relative to the keyword spotting problem and issues pertaining to the complexity and required training time of the ANN structures are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403569"
                        ],
                        "name": "R. Rimey",
                        "slug": "R.-Rimey",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Rimey",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rimey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "65878371"
                        ],
                        "name": "P. Gouin",
                        "slug": "P.-Gouin",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Gouin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gouin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2957320"
                        ],
                        "name": "C. Scofield",
                        "slug": "C.-Scofield",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Scofield",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Scofield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40615609"
                        ],
                        "name": "D. Reilly",
                        "slug": "D.-Reilly",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Reilly",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Reilly"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57746476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36657b506960190bb4b61197d75cb20dff33f94e",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe some experiments in real-time 3-D object classification using a learning system derived from a general neural model for supervised learning. The primary advantages of the learning system are its ability to learn from experience to recognize patterns and its inherent massive parallelism. Our motivation is to examine the feasibility and merits of the learning system in a simple machine vision problem."
            },
            "slug": "Real-Time-3-D-Object-Classification-Using-a-System-Rimey-Gouin",
            "title": {
                "fragments": [],
                "text": "Real-Time 3-D Object Classification Using a Learning System"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This work describes some experiments in real-time 3-D object classification using a learning system derived from a general neural model for supervised learning and examines the feasibility and merits of the learning system in a simple machine vision problem."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2356410"
                        ],
                        "name": "M. Bear",
                        "slug": "M.-Bear",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Bear",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bear"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8884630"
                        ],
                        "name": "L. Cooper",
                        "slug": "L.-Cooper",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Cooper",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cooper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 140937046,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "184dcb02b7f9510c031460606cce37926b6abad8",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Concurrent with the recent developments in neural network theories of learning and memory has been the experimental demonstration of experience- dependent synaptic plasticity at the highest level of the mammalian nervous system, the cerebral cortex. A neurobiological problem of extraordinary interest is to identify the molecular mechanisms which underlie this process of cortical modification. For the complex forms of plasticity evoked in neocortex by changes in the sensory environment, an essential first step in sorting out the various possibilities is to derive a set of rules that can adequately account for the observed modifications. These rules serve as a guide towards identifying candidate mechanisms that can then be tested experimentally. Hence, it can be seen that two lines of inquiry on concerning neural network theory, the other concerning molecular mechanisms of synapse modification-- converge at the level of the modification rule. We have proposed such a modification rule to explain the rich body of experimental evidence available on the experience-dependent plasticity of the feline visual cortex during early postnatal development. This theoretical form of modification is able to account for the results of a wide variety of deprivation experiments, and has led to a number of predictions that appear to have been confirmed by more recent experiments. In this chapter we shall illustrate how this theory has interacted with experiment to suggest a possible molecular basis for synapse modification in the visual cortex."
            },
            "slug": "Molecular-Mechanisms-for-Synaptic-Modification-in-Bear-Cooper",
            "title": {
                "fragments": [],
                "text": "Molecular Mechanisms for Synaptic Modification in the Visual Cortex: Interaction between Theory and Experiment"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This chapter illustrates how this theory has interacted with experiment to suggest a possible molecular basis for synapse modification in the visual cortex, and proposes a modification rule to explain the rich body of experimental evidence available on the experience-dependent plasticity of the feline visual cortex during early postnatal development."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2246319"
                        ],
                        "name": "E. Bienenstock",
                        "slug": "E.-Bienenstock",
                        "structuredName": {
                            "firstName": "Elie",
                            "lastName": "Bienenstock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bienenstock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8884630"
                        ],
                        "name": "L. Cooper",
                        "slug": "L.-Cooper",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Cooper",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094648"
                        ],
                        "name": "P. Munro",
                        "slug": "P.-Munro",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Munro",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Munro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 132
                            }
                        ],
                        "text": "The 4 function has been suggested as a biologically plausible synaptic modification function to explain visual cortical plasticity (Bienenstock et al. 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 273
                            }
                        ],
                        "text": "\u2026continuously differentiable, its minimization can be achieved via a gradient descent method with respect to m, namely The resulting differential equations give a modified version of the law governing synaptic weight modification in the BCM theory for learning and memory (Bienenstock et al. 1982)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1607496,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9f22cf81654dd50b95e65b86b1125cfe6803a67b",
            "isKey": false,
            "numCitedBy": 2695,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "The development of stimulus selectivity in the primary sensory cortex of higher vertebrates is considered in a general mathematical framework. A synaptic evolution scheme of a new kind is proposed in which incoming patterns rather than converging afferents compete. The change in the efficacy of a given synapse depends not only on instantaneous pre- and postsynaptic activities but also on a slowly varying time-averaged value of the postsynaptic activity. Assuming an appropriate nonlinear form for this dependence, development of selectivity is obtained under quite general conditions on the sensory environment. One does not require nonlinearity of the neuron's integrative power nor does one need to assume any particular form for intracortical circuitry. This is first illustrated in simple cases, e.g., when the environment consists of only two different stimuli presented alternately in a random manner. The following formal statement then holds: the state of the system converges with probability 1 to points of maximum selectivity in the state space. We next consider the problem of early development of orientation selectivity and binocular interaction in primary visual cortex. Giving the environment an appropriate form, we obtain orientation tuning curves and ocular dominance comparable to what is observed in normally reared adult cats or monkeys. Simulations with binocular input and various types of normal or altered environments show good agreement with the relevant experimental data. Experiments are suggested that could test our theory further."
            },
            "slug": "Theory-for-the-development-of-neuron-selectivity:-Bienenstock-Cooper",
            "title": {
                "fragments": [],
                "text": "Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The development of stimulus selectivity in the primary sensory cortex of higher vertebrates is considered in a general mathematical framework and a synaptic evolution scheme of a new kind is proposed in which incoming patterns rather than converging afferents compete."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of neuroscience : the official journal of the Society for Neuroscience"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2356410"
                        ],
                        "name": "M. Bear",
                        "slug": "M.-Bear",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Bear",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bear"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8884630"
                        ],
                        "name": "L. Cooper",
                        "slug": "L.-Cooper",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Cooper",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16865285"
                        ],
                        "name": "F. Ebner",
                        "slug": "F.-Ebner",
                        "structuredName": {
                            "firstName": "Ford",
                            "lastName": "Ebner",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ebner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43508483,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "c5639c7fb1cdf3988efff559953b7def6444b5fe",
            "isKey": false,
            "numCitedBy": 541,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "The functional organization of the cerebral cortex is modified dramatically by sensory experience during early postnatal life. The basis for these modifications is a type of synaptic plasticity that may also contribute to some forms of adult learning. The question of how synapses modify according to experience has been approached by determining theoretically what is required of a modification mechanism to account for the available experimental data in the developing visual cortex. The resulting theory states precisely how certain variables might influence synaptic modifications. This insight has led to the development of a biologically plausible molecular model for synapse modification in the cerebral cortex."
            },
            "slug": "A-physiological-basis-for-a-theory-of-synapse-Bear-Cooper",
            "title": {
                "fragments": [],
                "text": "A physiological basis for a theory of synapse modification."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The question of how synapses modify according to experience has been approached by determining theoretically what is required of a modification mechanism to account for the available experimental data in the developing visual cortex, and the resulting theory states precisely how certain variables might influence synaptic modifications."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8386096"
                        ],
                        "name": "A. Saul",
                        "slug": "A.-Saul",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Saul",
                            "middleNames": [
                                "B"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Saul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3284007"
                        ],
                        "name": "E. Clothiaux",
                        "slug": "E.-Clothiaux",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Clothiaux",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Clothiaux"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 142079854,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "0bbaaa9751317429b11d6c187e32281eef5d0627",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This document presents a tutorial describing aspects of the coding of computerized simulations of models of visual cortical development. The model considered has an anatomy of an excitatory projection from thalamus to cortex combined with intracortical inhibition. Cortical cells develop specificity to stimulus patterns in this model only when appropriate experience enables synaptic modification to organize the network. The simulation consists of a time loop. For each iteration of this loop, a stimulus is generated, the cortical response to this stimulus is computed, and synaptic weights are modified. The developing network is tested intermittently and the behavior of the system analyzed. Some of the details of the coding given include a method of describing rearing conditions, a convenient abstract form for the input stimuli, an iterative calculation of the intracortical feedback, a simple way to store synaptic strengths, and routines for performing the analysis. Keywords: numerical methods and procedures; plasticity."
            },
            "slug": "Modeling-and-simulation-III:-Simulation-of-a-model-Saul-Clothiaux",
            "title": {
                "fragments": [],
                "text": "Modeling and simulation III: Simulation of a model for development of visual cortical specificity"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A tutorial describing aspects of the coding of computerized simulations of models of visual cortical development of an anatomy of an excitatory projection from thalamus to cortex combined with intracortical inhibition is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2016914"
                        ],
                        "name": "J. Tukey",
                        "slug": "J.-Tukey",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tukey",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tukey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7997450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e12d7b5498d251692d87abc3ee983c078fee7f5f",
            "isKey": false,
            "numCitedBy": 1652,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for the analysis of multivariate data is presented and is discussed in terms of specific examples. The algorithm seeks to find one-and two-dimensional linear projections of multivariate data that are relatively highly revealing."
            },
            "slug": "A-Projection-Pursuit-Algorithm-for-Exploratory-Data-Friedman-Tukey",
            "title": {
                "fragments": [],
                "text": "A Projection Pursuit Algorithm for Exploratory Data Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An algorithm for the analysis of multivariate data is presented and is discussed in terms of specific examples to find one-and two-dimensional linear projections of multivariable data that are relatively highly revealing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3284007"
                        ],
                        "name": "E. Clothiaux",
                        "slug": "E.-Clothiaux",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Clothiaux",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Clothiaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2356410"
                        ],
                        "name": "M. Bear",
                        "slug": "M.-Bear",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Bear",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bear"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8884630"
                        ],
                        "name": "L. Cooper",
                        "slug": "L.-Cooper",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Cooper",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cooper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 202
                            }
                        ],
                        "text": "The biological relevance of the theory has been extensively studied (Bear et al. 1987; Bear and Cooper 1988) and it was shown that the theory is in agreement with the classical deprivation experiments (Clothiaux et al. 1991)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 9438779,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "8b7d5e3ee048c97ebe87b60c6e1244c68ad98719",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "1. The aim of this work was to assess whether a form of synaptic modification based on the theory of Bienenstock, Cooper, and Munro (BCM) can, with a fixed set of parameters, reproduce both the kinetics and equilibrium states of experience-dependent modifications cortex. 2. According to the BCM theory, the connection strength of excitatory geniculocortical synapses varies as the product of a measure of input activity (d) and a function (phi) of the summed postsynaptic response. For all postsynaptic responses greater than spontaneous but less than a critical value called the \"modification threshold\" (theta), phi has a negative value. For all postsynaptic responses greater than theta, phi has a positive value. A novel feature of the BCM theory is that the value of theta is not fixed, but rather \"slides\" as a nonlinear function of the average postsynaptic response. 3. This theory permits precise specification of theoretical equivalents of experimental situations, allowing detailed, quantitative comparisons of theory with experiment. Such comparisons were carried out here in a series of computer simulations. 4. Simulations are performed by presenting input to a model cortical neuron, calculating the summed postsynaptic response, and then changing the synaptic weights according to the BCM theory. This process is repeated until the synaptic weights reach an equilibrium state. 5. Two types of geniculocortical input are simulated: \"pattern\" and \"noise.\" Pattern input is assumed to correspond to the type of input that arises when a visual contour of a particular orientation is presented to the retina. This type of input is said to be \"correlated\" when the two sets of geniculocortical fibers relaying information from the two eyes convey the same patterns at the same time. Noise input is assumed to correspond to the type of input that arises in the absence of visual contours and, by definition, is uncorrelated. 6. By varying the types of input available to the two sets of geniculocortical synapses, we simulate the following types of visual experience: 1) normal binocular contour vision, 2) monocular deprivation, 3) reverse suture, 4) strabismus, 5) binocular deprivation, and 6) normal contour vision after a period of monocular deprivation. 7. The constraints placed on the set of parameters by each type of simulated visual environment, and the effects that such constraints have on the evolution of the synaptic weights, are investigated in detail.(ABSTRACT TRUNCATED AT 400 WORDS)"
            },
            "slug": "Synaptic-plasticity-in-visual-cortex:-comparison-of-Clothiaux-Bear",
            "title": {
                "fragments": [],
                "text": "Synaptic plasticity in visual cortex: comparison of theory with experiment."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The aim of this work was to assess whether a form of synaptic modification based on the theory of Bienenstock, Cooper, and Munro (BCM) can, with a fixed set of parameters, reproduce both the kinetics and equilibrium states of experience-dependent modifications cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of neurophysiology"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684300"
                        ],
                        "name": "W. Stuetzle",
                        "slug": "W.-Stuetzle",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Stuetzle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Stuetzle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052409300"
                        ],
                        "name": "A. Schroeder",
                        "slug": "A.-Schroeder",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Schroeder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schroeder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9170233,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0b7db4faa23eb52920d420bd20a91393c50fa0e2",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The projection pursuit methodology is applied to the multivariate density estimation problem. The resulting nonparametric procedure is often less biased than the kernel and near-neighbor methods. In addition, graphical information is produced that can be used to help gain geometric insight into the multivariate data distribution."
            },
            "slug": "PROJECTION-PURSUIT-DENSITY-ESTIMATION-Friedman-Stuetzle",
            "title": {
                "fragments": [],
                "text": "PROJECTION PURSUIT DENSITY ESTIMATION"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143971171"
                        ],
                        "name": "P. Hall",
                        "slug": "P.-Hall",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hall"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121148010,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ecc800dbab31bcee35124099ca9f6ea6f9ea7212",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryEstimation of orientation is a key operation at each step in projection pursuit. Since projection pursuit is a nonparametric algorithm, and since even low-dimensional approximations to the target function must converge to their limits at rates considerably slower than n-12(where n is sample size), then it might be thought that the same is true of orientation estimates. It is shown in the present paper that this is not the case, and that estimation of orientation is a parametric operation, in the sense that, under mild nonparametric assumptions, correctly-chosen kernel-type orientation estimates converge to their limits at rate n-12. This property is not enjoyed by standard projection pursuit orientation estimates, which converge at a slower rate than n-12. Most attention in the present paper is focussed on the case of projection pursuit density approximation, but it is pointed out that our arguments hold generally. An important practical conclusion is that data should be smoothed less when estimating orientation than when constructing the final projection pursuit approximation."
            },
            "slug": "Estimating-the-direction-in-which-a-data-set-is-Hall",
            "title": {
                "fragments": [],
                "text": "Estimating the direction in which a data set is most interesting"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802785"
                        ],
                        "name": "S. Nowlan",
                        "slug": "S.-Nowlan",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Nowlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowlan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 142
                            }
                        ],
                        "text": "In some special cases, where the data are known in advance to be bimodal, it is relatively straightforward to define a good projection index (Hinton and Nowlan 1990), however, when the structure is not known in advance , defining a general multimodal measure of the projected data is not\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42681933,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af6759ecd0f6c8ba1eb7030894eff4c91a55778d",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm that is widely used for adaptive equalization in current modems is the bootstrap or decision-directed version of the Widrow-Hoff rule. We show that this algorithm can be viewed as an unsupervised clustering algorithm in which the data points are transformed so that they form two clusters that are as tight as possible. The standard algorithm performs gradient ascent in a crude model of the log likelihood of generating the transformed data points from two gaussian distributions with fixed centers. Better convergence is achieved by using the exact gradient of the log likelihood."
            },
            "slug": "The-Bootstrap-Widrow-Hoff-Rule-as-a-Algorithm-Hinton-Nowlan",
            "title": {
                "fragments": [],
                "text": "The Bootstrap Widrow-Hoff Rule as a Cluster-Formation Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work shows that the bootstrap or decision-directed version of the Widrow-Hoff rule can be viewed as an unsupervised clustering algorithm in which the data points are transformed so that they form two clusters that are as tight as possible."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10398168"
                        ],
                        "name": "J. Kruskal",
                        "slug": "J.-Kruskal",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Kruskal",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kruskal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117280376,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa339092fd5e22a86137bce164cdd05e46fbaa05",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "TOWARD-A-PRACTICAL-METHOD-WHICH-HELPS-UNCOVER-THE-A-Kruskal",
            "title": {
                "fragments": [],
                "text": "TOWARD A PRACTICAL METHOD WHICH HELPS UNCOVER THE STRUCTURE OF A SET OF MULTIVARIATE OBSERVATIONS BY FINDING THE LINEAR TRANSFORMATION WHICH OPTIMIZES A NEW \u201cINDEX OF CONDENSATION\u201d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145025204"
                        ],
                        "name": "P. Lieberman",
                        "slug": "P.-Lieberman",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Lieberman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lieberman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2249526"
                        ],
                        "name": "S. Blumstein",
                        "slug": "S.-Blumstein",
                        "structuredName": {
                            "firstName": "Sheila",
                            "lastName": "Blumstein",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Blumstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 51
                            }
                        ],
                        "text": "The application of BCM to speech is discussed in more detail in Seebach (1991) and in a forthcoming article (Seebach and Intrator, in press)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 3
                            }
                        ],
                        "text": "Neural Computation 4, 98-107 (1992) @ 1992 Massachusetts Institute of Technology"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60590725,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "22307f267611f90cdb11555a0eec82088436a654",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "List of Figures Preface Acknowledgements 1. Introduction 2. A qualitative introduction to the physiology of speech 3. Basic acoustics 4. Source-filter theory of speech production 5. Speech analysis 6. Anatomy and physiology of speech production 7. Speech perception 8. Phonetic theories 9. Some current topics in speech research 10. Acoustic correlates of speech sounds Bibliography Index."
            },
            "slug": "Speech-Physiology,-Speech-Perception,-and-Acoustic-Lieberman-Blumstein",
            "title": {
                "fragments": [],
                "text": "Speech Physiology, Speech Perception, and Acoustic Phonetics"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A qualitative introduction to the physiology of speech and the source-filter theory of speech production and some current topics in speech research are mentioned."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2099819725"
                        ],
                        "name": "Raymond M. Wright",
                        "slug": "Raymond-M.-Wright",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Wright",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond M. Wright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144355808"
                        ],
                        "name": "P. Switzer",
                        "slug": "P.-Switzer",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Switzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Switzer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119921451,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "97c95749e923fce522beb50c7abe6e2215716a08",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Eighty-eight specimens of Eocene nummulitids from the Yellow Limestone Formation of northwestern Jamaica are classified according to quantitative measurements of morphologic parameters that are generally considered to be taxonomically useful. The specimens are grouped into homogeneous classes by the computer screening of differently oriented data projections. By this method, the use of similarity coefficients and the question of a priori weighting of characters, for which numerical taxonomy has been heavily criticized, are both avoided. The stability of the classes thus obtained is validated by discriminant analysis. These techniques provide an objective view of phenetic differences among specimens and show how the measured characters produce those differences. Tightness of coiling and total number of whorls, prove to be the most useful features in discriminating between groups but seem to have taxonomic value only at the specific and not at the generic level. This suggests that the generaOperculinoides andNummulites are synonymous."
            },
            "slug": "Numerical-classification-applied-to-certain-eocene-Wright-Switzer",
            "title": {
                "fragments": [],
                "text": "Numerical classification applied to certain Jamaican eocene nummulitids"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 264
                            }
                        ],
                        "text": "\u2026dimensionality reduction methods, called exploratory projection pursuit, is based on seeking interesting projections of high-dimensional data points (Kruskal 1972; Friedman and Feature Extraction Using an Unsupervised Neural Network 99 Tukey 1974; Friedman 1987; Huber 1985, for review)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 161
                            }
                        ],
                        "text": "There are cases in which it is desirable to make the projection index invariant under certain transformations, and maybe even remove second-order structure (see Huber 1985 for desirable invariant properties of projection indices)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 105
                            }
                        ],
                        "text": "However, polynomial moments heavily emphasize departure from normality in the tails of the distribution (Huber 1985)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 196
                            }
                        ],
                        "text": "The lateral inhibition network performs a direct search of Q-dimensional projections in parallel, and therefore may find a richer structure that a step wise approach may miss (see example 14.1 in Huber 1985)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Projection pursuit (with discussion)"
            },
            "venue": {
                "fragments": [],
                "text": "Ann. Statist"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1398,
                                "start": 12
                            }
                        ],
                        "text": "Kittler (1982) Pattern Rec. gnition between the directions (features) extracted by the tion: A Statistiklj Approach. Prentice Hall London network can be regulated via the global inhibition, allowing some tuning of the network to different types of Diaconis, P, and D. Freedman (1984) Asymptotics of data for optimal results; iii) the pursuit is done on all Graphica Projection Pursuit. The Annals of Statisthe directions at once thus leading to the capability of tics, 12 793-815. finding more interesting structures than methods that Friedman, J. H. and J. W. Tukey (1974) A projection find only one projection direction at a time. pursuit algorithm for exploratory data analysis. IEEE Regarding the speech experiment, the network and Trans. Coid. C-23:881-889 its training paradigm present a different approach to Friedman, J. H. and W. Stuetzle (1981) Projection speaker independent speech recognition. In this ap- pursuit regression. J. Amer. Statzst. Assoc. 76:817proach the speaker variability problem is addressed by 823 training a network that concentrates mainly on the distinguishing features, on a single speaker, as opposed Friedman, J. H., W. Stuetzle and A. Schroeder (1984) to training a network that concentrates on both the Projection pursuit density estimation. J. Amer. distinguishing and common features, on multi-speaker Statist. Assoc. 79:599-608 data. Friedman, J. H. (1987) Exploratory Projection Pur-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1189,
                                "start": 12
                            }
                        ],
                        "text": "Kittler (1982) Pattern Rec. gnition between the directions (features) extracted by the tion: A Statistiklj Approach. Prentice Hall London network can be regulated via the global inhibition, allowing some tuning of the network to different types of Diaconis, P, and D. Freedman (1984) Asymptotics of data for optimal results; iii) the pursuit is done on all Graphica Projection Pursuit. The Annals of Statisthe directions at once thus leading to the capability of tics, 12 793-815. finding more interesting structures than methods that Friedman, J. H. and J. W. Tukey (1974) A projection find only one projection direction at a time. pursuit algorithm for exploratory data analysis. IEEE Regarding the speech experiment, the network and Trans. Coid. C-23:881-889 its training paradigm present a different approach to Friedman, J. H. and W. Stuetzle (1981) Projection speaker independent speech recognition. In this ap- pursuit regression. J. Amer. Statzst. Assoc. 76:817proach the speaker variability problem is addressed by 823 training a network that concentrates mainly on the distinguishing features, on a single speaker, as opposed Friedman, J. H., W. Stuetzle and A. Schroeder (1984) to training a network that concentrates on both the Projection pursuit density estimation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 855,
                                "start": 12
                            }
                        ],
                        "text": "Kittler (1982) Pattern Rec. gnition between the directions (features) extracted by the tion: A Statistiklj Approach. Prentice Hall London network can be regulated via the global inhibition, allowing some tuning of the network to different types of Diaconis, P, and D. Freedman (1984) Asymptotics of data for optimal results; iii) the pursuit is done on all Graphica Projection Pursuit. The Annals of Statisthe directions at once thus leading to the capability of tics, 12 793-815. finding more interesting structures than methods that Friedman, J. H. and J. W. Tukey (1974) A projection find only one projection direction at a time. pursuit algorithm for exploratory data analysis. IEEE Regarding the speech experiment, the network and Trans. Coid. C-23:881-889 its training paradigm present a different approach to Friedman, J. H. and W. Stuetzle (1981) Projection speaker independent speech recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 12
                            }
                        ],
                        "text": "Kittler (1982) Pattern Rec. gnition between the directions (features) extracted by the tion: A Statistiklj Approach. Prentice Hall London network can be regulated via the global inhibition, allowing some tuning of the network to different types of Diaconis, P, and D. Freedman (1984) Asymptotics of data for optimal results; iii) the pursuit is done on all Graphica Projection Pursuit."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 3
                            }
                        ],
                        "text": "m)(2)j, and the functions applicable, since they very heavily emphasize depar- 4(c,O,,) = c-(2) _ 2cE, 4(c,0,) = - c4 ,. The ture from normality in the tails of the distribution (Hu- 4 function have been suggested as a biologically plauber, 1985). Friedman (1987) addresses this issue by sible synaptic modification function to explain visual introducing a nonlinear transformation that squashes cortical plasticity (Bienenstock, Cooper and Munro."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 657,
                                "start": 51
                            }
                        ],
                        "text": "The unsupervised feature extraction/classification 2. Several observations can be made from the results; method is presented in Figure 6. Similar approach us- First, the principal components dimensionality reducing the RCE and back-propagation network have been tion is clearly not sufficient in discovering structure carried out by several researchers (Rimey et al., 1986; for this kind of data, suggesting that the structure is Reilly ct al., 1987, 1988; Zemani et al., 1989), and highly non linear. Second, the back-propagation netusing the unsupervised charge clustering network by work is doing well in finding structure useful for clasScofield (1988) sification of the trained data, but this structure does not concentrates on distinctive features solely, it also Five features/directions were extracted from the 440 contains speaker dependent and voicing dependent feadimensional preprocessed speech vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 574,
                                "start": 12
                            }
                        ],
                        "text": "Kittler (1982) Pattern Rec. gnition between the directions (features) extracted by the tion: A Statistiklj Approach. Prentice Hall London network can be regulated via the global inhibition, allowing some tuning of the network to different types of Diaconis, P, and D. Freedman (1984) Asymptotics of data for optimal results; iii) the pursuit is done on all Graphica Projection Pursuit. The Annals of Statisthe directions at once thus leading to the capability of tics, 12 793-815. finding more interesting structures than methods that Friedman, J. H. and J. W. Tukey (1974) A projection find only one projection direction at a time."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A theory of the development Morgan Kaufinann. of neuronal selectivity"
            },
            "venue": {
                "fragments": [],
                "text": "Doctoral dissertation, Brown IntrTa - N"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 282
                            }
                        ],
                        "text": "This unsupervised feature extraction class is used in projection pursuit methods (PP) originally introduced by Kruskal (1969, 1972), Switzer When a classification of high dimensional vectors is (1970, 1971), and later implemented by Friedman and sought, the curse of dimensionality (Bellman, 1961) Tukey (1974)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 763,
                                "start": 184
                            }
                        ],
                        "text": "Note that the multiplication by a' reducetion in the BCM theory for learning and memory (Bi- sensitivity to outliers of the differential equation since enenstock, Cooper and Munro, 1982). This theory was for outliers a' is close to zero. presented to account for various experimental results Based on this formulation, a network of Q identical in visual cortical plasticity. According to this theory, I the synaptic efficacy of active inputs increases whenand inhibit each t ptsynaptic tfficarge cti onunty dcelared b other, may be constructed in order to extract several the postsynaptic target is concurrently depolarized befeatures at once. A similar network has been studied yond a modification threshold, 19,. However, when the by Scofield and Cooper (1985). The activity of neuron level of postsynaptic activity falls below E, then the k in the network is defined as ck = X -M, where nik is strength of active synapses decreases."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 408,
                                "start": 283
                            }
                        ],
                        "text": "This unsupervised feature extraction class is used in projection pursuit methods (PP) originally introduced by Kruskal (1969, 1972), Switzer When a classification of high dimensional vectors is (1970, 1971), and later implemented by Friedman and sought, the curse of dimensionality (Bellman, 1961) Tukey (1974). These methods are reviewed in Huber becomes the main factor affecting the classification (1985). performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 90
                            }
                        ],
                        "text": "When a classification of high-dimensional vectors is sought, the curse of dimensionality (Bellman 1961) becomes the main factor affecting the classification performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 311,
                                "start": 283
                            }
                        ],
                        "text": "This unsupervised feature extraction class is used in projection pursuit methods (PP) originally introduced by Kruskal (1969, 1972), Switzer When a classification of high dimensional vectors is (1970, 1971), and later implemented by Friedman and sought, the curse of dimensionality (Bellman, 1961) Tukey (1974). These methods are reviewed in Huber becomes the main factor affecting the classification (1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptive Control Processes, traction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 412,
                                "start": 4
                            }
                        ],
                        "text": "The gradient descent is valid, provided that the risk is bounded from below. Based on this formulation, a network of Q identical nodes may be constructed. All the neurons in this network receive the same input and inhibit each other, so as to extract several features in parallel. The relation between this network and the network studied by Cooper and Scofield (1988) is discussed in Intrator and Cooper (1991). The activity of neuron k in the network is defined as ck = u ( x ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 567,
                                "start": 79
                            }
                        ],
                        "text": "dimensionality reduction based on minimization of misclassification error (using backpropagation with MSE criterion). In the latter we regard the hidden unit representation as a new reduced feature representation of the input space. Classification on the new feature space was done using backpropagation.2 The unsupervised feature extraction/classification method is presented in Figure 2. The pixel images corresponding to speech data, are shown in Figure 3. Similar approaches using the RCE and backpropagation network have been carried out by Reilly et al. (1988). The following describes the linguistic motivation of the experiment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 369,
                                "start": 4
                            }
                        ],
                        "text": "The gradient descent is valid, provided that the risk is bounded from below. Based on this formulation, a network of Q identical nodes may be constructed. All the neurons in this network receive the same input and inhibit each other, so as to extract several features in parallel. The relation between this network and the network studied by Cooper and Scofield (1988) is discussed in Intrator and Cooper (1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Three-dimensional object recognition of gray level images: The usefulness of distinguishing features"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143971178"
                        ],
                        "name": "P. Hall",
                        "slug": "P.-Hall",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120672575,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4575a28fbd135dea99dfc7bb362a3ac7dbeac560",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-Polynomial-Based-Projection-Indices-for-Pursuit-Hall",
            "title": {
                "fragments": [],
                "text": "On Polynomial-Based Projection Indices for Exploratory Projection Pursuit"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3819348"
                        ],
                        "name": "B. Seebach",
                        "slug": "B.-Seebach",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Seebach",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Seebach"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 147
                            }
                        ],
                        "text": "Additional details on biological motivation for the preprocessing, and linguistic motivation related to child language acquisition can be found in Seebach (1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118224973,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "5838a95f33cfd141d034426873a4c10231254a82",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Evidence-for-the-development-of-phonetic-property-a-Seebach",
            "title": {
                "fragments": [],
                "text": "Evidence for the development of phonetic property detectors in a neural net without innate knowledge of linguistic structure"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2796350"
                        ],
                        "name": "P. Diaconis",
                        "slug": "P.-Diaconis",
                        "structuredName": {
                            "firstName": "Persi",
                            "lastName": "Diaconis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Diaconis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32854168"
                        ],
                        "name": "D. Freedman",
                        "slug": "D.-Freedman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Freedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Freedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 85511682,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "76b0a46ee00bc34fcc8ebd4b22e1fe672cdd652c",
            "isKey": false,
            "numCitedBy": 577,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Asymptotics-of-Graphical-Projection-Pursuit-Diaconis-Freedman",
            "title": {
                "fragments": [],
                "text": "Asymptotics of Graphical Projection Pursuit"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144873562"
                        ],
                        "name": "R. Bellman",
                        "slug": "R.-Bellman",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Bellman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bellman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62668616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a0cd8a28b7668fcd38b98b8e1598c33e1852077",
            "isKey": false,
            "numCitedBy": 846,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "V.-Adaptive-Control-Processes-Bellman",
            "title": {
                "fragments": [],
                "text": "V. Adaptive Control Processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144504703"
                        ],
                        "name": "E. Zwicker",
                        "slug": "E.-Zwicker",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Zwicker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Zwicker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 41
                            }
                        ],
                        "text": "respond to Zwicker critical band filters (Zwicker 1961)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 88
                            }
                        ],
                        "text": "Brighter areas correspond to stronger energy. respond to Zwicker critical band filters (Zwicker 1961)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60975741,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "5c323a2a4d12c0fef4fe3705edd4300da02e9aeb",
            "isKey": false,
            "numCitedBy": 832,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Subdivision-of-the-audible-frequency-range-into-Zwicker",
            "title": {
                "fragments": [],
                "text": "Subdivision of the audible frequency range into critical bands"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 162
                            }
                        ],
                        "text": "Consider the six stop consonants [p,k,t,b,g,dl, which have been a subject of recent research in evaluating neural networks for phoneme recognition (see review in Lippmann 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58451198,
            "fieldsOfStudy": [],
            "id": "e3386ef9540273ab35bf85e454cd126dde76a650",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Review of neural networks for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47804608"
                        ],
                        "name": "R. Bek",
                        "slug": "R.-Bek",
                        "structuredName": {
                            "firstName": "Roman",
                            "lastName": "Bek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20520403,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "a09d930fea5161406f735acf02e703e7824811dc",
            "isKey": false,
            "numCitedBy": 721,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Discourse-on-one-way-in-which-a-quantum-mechanics-Bek",
            "title": {
                "fragments": [],
                "text": "Discourse on one way in which a quantum-mechanics language on the classical logical base can be built up"
            },
            "venue": {
                "fragments": [],
                "text": "Kybernetika"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 220119561,
            "fieldsOfStudy": [],
            "id": "0a55b22bc98bc997bc31af0244038643e2bae74a",
            "isKey": false,
            "numCitedBy": 6373,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Received",
            "title": {
                "fragments": [],
                "text": "Received"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 144
                            }
                        ],
                        "text": "\u2026has been applied so far to various high-dimensional classification problems: extracting rotation invariant features from 3D wire-like objects (Intrator and Gold 1991) based on a set of sophisticated psychophysical experiments (Edelman and Bulthoff 1991); feature extraction from the TIMIT\u2026"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Three-dimensional object recognition of gray level images: The usefulness of distinguishing features"
            },
            "venue": {
                "fragments": [],
                "text": "Three-dimensional object recognition of gray level images: The usefulness of distinguishing features"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A neural net model of perinatal inductive acquisition of phonetic features"
            },
            "venue": {
                "fragments": [],
                "text": "A neural net model of perinatal inductive acquisition of phonetic features"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 132
                            }
                        ],
                        "text": "The 4 function has been suggested as a biologically plausible synaptic modification function to explain visual cortical plasticity (Bienenstock et al. 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 273
                            }
                        ],
                        "text": "\u2026continuously differentiable, its minimization can be achieved via a gradient descent method with respect to m, namely The resulting differential equations give a modified version of the law governing synaptic weight modification in the BCM theory for learning and memory (Bienenstock et al. 1982)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "dona Differential Equations"
            },
            "venue": {
                "fragments": [],
                "text": "Munro Brown University"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A physiological basis for a"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Synaptic plasticity in visual"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Self-organization of orientation sensitivity cells in the striate cortex. hybernelik Mathematical Appendix"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Synaptic Modification Model of Learning and Memory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 142
                            }
                        ],
                        "text": "In some special cases, where the data are known in advance to be bimodal, it is relatively straightforward to define a good projection index (Hinton and Nowlan 1990), however, when the structure is not known in advance , defining a general multimodal measure of the projected data is not\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The bootstrap Widrow-Hoff rule as a 249-266. exploratory data analysis 881-889. bias-variance dilemma. To appear. cluster-formation algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Comp"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 109
                            }
                        ],
                        "text": "This has led many researchers in recent years to construct methods that specifically avoid this problem (see Geman et al. 1991 for review in the context of neural networks)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural networks and the"
            },
            "venue": {
                "fragments": [],
                "text": "Neural networks and the"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 146
                            }
                        ],
                        "text": "\u2026models are based on second-order statistics and lead to extraction of the principal components (Sejnowski 1977; von der Malsburg 1973; q a 1982; Miller 1988; Linsker 1988), second-order polynomials are not sufficient to characterize the important features of a distribution (see examples in\u2026"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Correlation-based models of neural development"
            },
            "venue": {
                "fragments": [],
                "text": "Correlation-based models of neural development"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exploratory projection pursuit A projection pursuit algorithm for"
            },
            "venue": {
                "fragments": [],
                "text": "J. Arner. Statist. Assoc"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 146
                            }
                        ],
                        "text": "\u2026many synaptic plasticity models are based on second-order statistics and lead to extraction of the principal components (Sejnowski 1977; von der Malsburg 1973; q a 1982; Miller 1988; Linsker 1988), second-order polynomials are not sufficient to characterize the important features of a\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Self-organization of orientation sensitivity cells"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Projection Pursuit Algorithm Physiological Basis for a Theory of Synapse Modifica- for Exploratory Data Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Unpublished Ph.D. tion"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 86
                            }
                        ],
                        "text": "Similar approaches using the RCE and backpropagation network have been carried out by Reilly et al. (1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gensep: A multiple neural network with modifiable network topology. INNS Conf. Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Gensep: A multiple neural network with modifiable network topology. INNS Conf. Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "a decision space, in the case of a single neuron a zero baum (1988) GENSEP: a multiple neural network with decision means that the neuron does not fire"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Canonical views and the representation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modeling and Simulation II: Simulation of a Model for Development"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 86
                            }
                        ],
                        "text": "Similar approaches using the RCE and backpropagation network have been carried out by Reilly et al. (1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gensep: A multiple neural network with modifiable network topology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Canonical views and the representation of novel three-dimensional objects"
            },
            "venue": {
                "fragments": [],
                "text": "Canonical views and the representation of novel three-dimensional objects"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 300,
                                "start": 276
                            }
                        ],
                        "text": "Performing supervised feature extraction using the class labels is sensitive to the dimensionality in a similar manner to a high-dimensional classifier, and may result in a strong bias to the training data leading to poor generalization properties of the resulting classifier (Barron and Barron 1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 267
                            }
                        ],
                        "text": "\u2026supervised feature extraction using the class labels is sensitive to the dimensionality in a similar manner to a high-dimensional classifier, and may result in a strong bias to the training data leading to poor generalization properties of the resulting classifier (Barron and Barron 1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical learning networks: A unifying view"
            },
            "venue": {
                "fragments": [],
                "text": "In"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experiments in discrete utterance rcg"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 151
                            }
                        ],
                        "text": "\u2026dimensionality reduction methods, called exploratory projection pursuit, is based on seeking interesting projections of high-dimensional data points (Kruskal 1972; Friedman and Feature Extraction Using an Unsupervised Neural Network 99 Tukey 1974; Friedman 1987; Huber 1985, for review)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Linear transformation of multivariate data to reveal clustering In Multidimensional Scaling: The0 ry and Application in the Behavioral Sciences"
            },
            "venue": {
                "fragments": [],
                "text": "Linear transformation of multivariate data to reveal clustering In Multidimensional Scaling: The0 ry and Application in the Behavioral Sciences"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Linear Transformation of multification applied to certain Jamaican encene nuniniulivariate data to reveal clustering"
            },
            "venue": {
                "fragments": [],
                "text": "Multidimenszonal tids . Math . cal ."
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 72
                            }
                        ],
                        "text": "The relation between this network and the network studied by Cooper and Scofield (1988) is discussed in Intrator and Cooper (1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Unsupervised learning in the N the minimizer exists. In particular, for a given x' the dimensional Coulomb net. Abstracts in thefirst annual decision b,,(x"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature Extraction using an Exity : orientation specificity and binocular interaction in ploratory Projection Pursuit Neural Network . Ph . D . visual cortex"
            },
            "venue": {
                "fragments": [],
                "text": "J . Neurosci ."
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mean-field the- ate observations by finding the linear transformation ory of a neural network"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Natl. Acad. Sci. USA which optimizes a new 'index of condensation'"
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 16,
            "methodology": 17,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 66,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Feature-Extraction-Using-an-Unsupervised-Neural-Intrator/136fc611e49e5f3676265a288b78e473a752783b?sort=total-citations"
}