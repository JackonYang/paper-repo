{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39263338"
                        ],
                        "name": "Longxin Lin",
                        "slug": "Longxin-Lin",
                        "structuredName": {
                            "firstName": "Longxin",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Longxin Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60875658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54c4cf3a8168c1b70f91cf78a3dc98b671935492",
            "isKey": false,
            "numCitedBy": 907,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "Reinforcement learning agents are adaptive, reactive, and self-supervised. The aim of this dissertation is to extend the state of the art of reinforcement learning and enable its applications to complex robot-learning problems. In particular, it focuses on two issues. First, learning from sparse and delayed reinforcement signals is hard and in general a slow process. Techniques for reducing learning time must be devised. Second, most existing reinforcement learning methods assume that the world is a Markov decision process. This assumption is too strong for many robot tasks of interest. \nThis dissertation demonstrates how we can possibly overcome the slow learning problem and tackle non-Markovian environments, making reinforcement learning more practical for realistic robot tasks: (1) Reinforcement learning can be naturally integrated with artificial neural networks to obtain high-quality generalization, resulting in a significant learning speedup. Neural networks are used in this dissertation, and they generalize effectively even in the presence of noise and a large of binary and real-valued inputs. (2) Reinforcement learning agents can save many learning trials by using an action model, which can be learned on-line. With a model, an agent can mentally experience the effects of its actions without actually executing them. Experience replay is a simple technique that implements this idea, and is shown to be effective in reducing the number of action executions required. (3) Reinforcement learning agents can take advantage of instructive training instances provided by human teachers, resulting in a significant learning speedup. Teaching can also help learning agents avoid local optima during the search for optimal control. Simulation experiments indicate that even a small amount of teaching can save agents many learning trials. (4) Reinforcement learning agents can significantly reduce learning time by hierarchical learning--they first solve elementary learning problems and then combine solutions to the elementary problems to solve a complex problem. Simulation experiments indicate that a robot with hierarchical learning can solve a complex problem, which otherwise is hardly solvable within a reasonable time. (5) Reinforcement learning agents can deal with a wide range of non-Markovian environments by having a memory of their past. Three memory architectures are discussed. They work reasonably well for a variety of simple problems. One of them is also successfully applied to a nontrivial non-Markovian robot task. \nThe results of this dissertation rely on computer simulation, including (1) an agent operating in a dynamic and hostile environment and (2) a mobile robot operating in a noisy and non-Markovian environment. The robot simulator is physically realistic. This dissertation concludes that it is possible to build artificial agents than can acquire complex control policies effectively by reinforcement learning."
            },
            "slug": "Reinforcement-learning-for-robots-using-neural-Lin",
            "title": {
                "fragments": [],
                "text": "Reinforcement learning for robots using neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This dissertation concludes that it is possible to build artificial agents than can acquire complex control policies effectively by reinforcement learning and enable its applications to complex robot-learning problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730590"
                        ],
                        "name": "A. Barto",
                        "slug": "A.-Barto",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barto",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9166388,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97efafdb4a3942ab3efba53ded7413199f79c054",
            "isKey": false,
            "numCitedBy": 32837,
            "numCiting": 636,
            "paperAbstract": {
                "fragments": [],
                "text": "Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning."
            },
            "slug": "Reinforcement-Learning:-An-Introduction-Sutton-Barto",
            "title": {
                "fragments": [],
                "text": "Reinforcement Learning: An Introduction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book provides a clear and simple account of the key ideas and algorithms of reinforcement learning, which ranges from the history of the field's intellectual foundations to the most recent developments and applications."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144202584"
                        ],
                        "name": "S. Lange",
                        "slug": "S.-Lange",
                        "structuredName": {
                            "firstName": "Sascha",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1240464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36086ff255207cc1adb818c4d0cd62287d437d38",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses the effectiveness of deep auto-encoder neural networks in visual reinforcement learning (RL) tasks. We propose a framework for combining the training of deep auto-encoders (for learning compact feature spaces) with recently-proposed batch-mode RL algorithms (for learning policies). An emphasis is put on the data-efficiency of this combination and on studying the properties of the feature spaces automatically constructed by the deep auto-encoders. These feature spaces are empirically shown to adequately resemble existing similarities and spatial relations between observations and allow to learn useful policies. We propose several methods for improving the topology of the feature spaces making use of task-dependent information. Finally, we present first results on successfully learning good control policies directly on synthesized and real images."
            },
            "slug": "Deep-auto-encoder-neural-networks-in-reinforcement-Lange-Riedmiller",
            "title": {
                "fragments": [],
                "text": "Deep auto-encoder neural networks in reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A framework for combining the training of deep auto-encoders (for learning compact feature spaces) with recently-proposed batch-mode RL algorithms ( for learning policies) is proposed and an emphasis is put on the data-efficiency and on studying the properties of the feature spaces automatically constructed by the deep Auto-encoder neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "The 2010 International Joint Conference on Neural Networks (IJCNN)"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35044670"
                        ],
                        "name": "C. Law",
                        "slug": "C.-Law",
                        "structuredName": {
                            "firstName": "Chi-Tat",
                            "lastName": "Law",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Law"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30194578"
                        ],
                        "name": "J. Gold",
                        "slug": "J.-Gold",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Gold",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5320751,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "d6a74ea198b8a00692d6b5aeee1a83da0c7ec6df",
            "isKey": false,
            "numCitedBy": 260,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We recently showed that improved perceptual performance on a visual motion direction\u2013discrimination task corresponds to changes in how an unmodified sensory representation in the brain is interpreted to form a decision that guides behavior. Here we found that these changes can be accounted for using a reinforcement-learning rule to shape functional connectivity between the sensory and decision neurons. We modeled performance on the basis of the readout of simulated responses of direction-selective sensory neurons in the middle temporal area (MT) of monkey cortex. A reward prediction error guided changes in connections between these sensory neurons and the decision process, first establishing the association between motion direction and response direction, and then gradually improving perceptual sensitivity by selectively strengthening the connections from the most sensitive neurons in the sensory population. The results suggest a common, feedback-driven mechanism for some forms of associative and perceptual learning."
            },
            "slug": "Reinforcement-learning-can-account-for-associative-Law-Gold",
            "title": {
                "fragments": [],
                "text": "Reinforcement learning can account for associative and perceptual learning on a visual decision task"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work modeled performance on the basis of the readout of simulated responses of direction-selective sensory neurons in the middle temporal area of monkey cortex and found that changes can be accounted for using a reinforcement-learning rule to shape functional connectivity between the sensory and decision neurons."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792298"
                        ],
                        "name": "Marc G. Bellemare",
                        "slug": "Marc-G.-Bellemare",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Bellemare",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc G. Bellemare"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2294249"
                        ],
                        "name": "Yavar Naddaf",
                        "slug": "Yavar-Naddaf",
                        "structuredName": {
                            "firstName": "Yavar",
                            "lastName": "Naddaf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yavar Naddaf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144056327"
                        ],
                        "name": "J. Veness",
                        "slug": "J.-Veness",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Veness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Veness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687780"
                        ],
                        "name": "Michael Bowling",
                        "slug": "Michael-Bowling",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bowling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Bowling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1552061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f82e4ff4f003581330338aaae71f60316e58dd26",
            "isKey": false,
            "numCitedBy": 2062,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. All of the software, including the benchmark agents, is publicly available."
            },
            "slug": "The-Arcade-Learning-Environment:-An-Evaluation-for-Bellemare-Naddaf",
            "title": {
                "fragments": [],
                "text": "The Arcade Learning Environment: An Evaluation Platform for General Agents (Extended Abstract)"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The promise of ALE is illustrated by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning, and an evaluation methodology made possible by ALE is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207178999,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e60ff004dde5c13ec53087872cfcdd12e85beb57",
            "isKey": false,
            "numCitedBy": 7558,
            "numCiting": 345,
            "paperAbstract": {
                "fragments": [],
                "text": "Theoretical results strongly suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one needs deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult optimization task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This paper discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks."
            },
            "slug": "Learning-Deep-Architectures-for-AI-Bengio",
            "title": {
                "fragments": [],
                "text": "Learning Deep Architectures for AI"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer modelssuch as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Mach. Learn."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2777657"
                        ],
                        "name": "T. Gabel",
                        "slug": "T.-Gabel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Gabel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gabel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49512734"
                        ],
                        "name": "Roland Hafner",
                        "slug": "Roland-Hafner",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Hafner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roland Hafner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144202584"
                        ],
                        "name": "S. Lange",
                        "slug": "S.-Lange",
                        "structuredName": {
                            "firstName": "Sascha",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lange"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17961083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e227e9f7a0ffc41bee929d2ee07a76f3b445bdb1",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Batch reinforcement learning methods provide a powerful framework for learning efficiently and effectively in autonomous robots. The paper reviews some recent work of the authors aiming at the successful application of reinforcement learning in a challenging and complex domain. It discusses several variants of the general batch learning framework, particularly tailored to the use of multilayer perceptrons to approximate value functions over continuous state spaces. The batch learning framework is successfully used to learn crucial skills in our soccer-playing robots participating in the RoboCup competitions. This is demonstrated on three different case studies."
            },
            "slug": "Reinforcement-learning-for-robot-soccer-Riedmiller-Gabel",
            "title": {
                "fragments": [],
                "text": "Reinforcement learning for robot soccer"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Several variants of the general batch learning framework are discussed, particularly tailored to the use of multilayer perceptrons to approximate value functions over continuous state spaces, which are successfully used to learn crucial skills in soccer-playing robots participating in the RoboCup competitions."
            },
            "venue": {
                "fragments": [],
                "text": "Auton. Robots"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681946"
                        ],
                        "name": "Carlos Diuk",
                        "slug": "Carlos-Diuk",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Diuk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlos Diuk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3023158"
                        ],
                        "name": "A. Cohen",
                        "slug": "A.-Cohen",
                        "structuredName": {
                            "firstName": "Andre",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144885169"
                        ],
                        "name": "M. Littman",
                        "slug": "M.-Littman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Littman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Littman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207168200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25fd7e9ed8d1a669c7a8d28a8b620479899e6b53",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 116,
            "paperAbstract": {
                "fragments": [],
                "text": "Rich representations in reinforcement learning have been studied for the purpose of enabling generalization and making learning feasible in large state spaces. We introduce Object-Oriented MDPs (OO-MDPs), a representation based on objects and their interactions, which is a natural way of modeling environments and offers important generalization opportunities. We introduce a learning algorithm for deterministic OO-MDPs and prove a polynomial bound on its sample complexity. We illustrate the performance gains of our representation and algorithm in the well-known Taxi domain, plus a real-life videogame."
            },
            "slug": "An-object-oriented-representation-for-efficient-Diuk-Cohen",
            "title": {
                "fragments": [],
                "text": "An object-oriented representation for efficient reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Object-Oriented MDPs (OO-MDPs) are introduced, a representation based on objects and their interactions, which is a natural way of modeling environments and offers important generalization opportunities and a polynomial bound on its sample complexity is proved."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145401965"
                        ],
                        "name": "W. Schultz",
                        "slug": "W.-Schultz",
                        "structuredName": {
                            "firstName": "Wolfram",
                            "lastName": "Schultz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Schultz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144895942"
                        ],
                        "name": "P. Montague",
                        "slug": "P.-Montague",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Montague",
                            "middleNames": [
                                "Read"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Montague"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 220093382,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "12b9019f99a315a137400389ee7c6faa4cceef35",
            "isKey": false,
            "numCitedBy": 7610,
            "numCiting": 114,
            "paperAbstract": {
                "fragments": [],
                "text": "The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control."
            },
            "slug": "A-Neural-Substrate-of-Prediction-and-Reward-Schultz-Dayan",
            "title": {
                "fragments": [],
                "text": "A Neural Substrate of Prediction and Reward"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Findings in this work indicate that dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events can be understood through quantitative theories of adaptive optimizing control."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6921329,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "282001869bd502c7917db8b32b75593addfbbc68",
            "isKey": false,
            "numCitedBy": 894,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces NFQ, an algorithm for efficient and effective training of a Q-value function represented by a multi-layer perceptron. Based on the principle of storing and reusing transition experiences, a model-free, neural network based Reinforcement Learning algorithm is proposed. The method is evaluated on three benchmark problems. It is shown empirically, that reasonably few interactions with the plant are needed to generate control policies of high quality."
            },
            "slug": "Neural-Fitted-Q-Iteration-First-Experiences-with-a-Riedmiller",
            "title": {
                "fragments": [],
                "text": "Neural Fitted Q Iteration - First Experiences with a Data Efficient Neural Reinforcement Learning Method"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "NFQ, an algorithm for efficient and effective training of a Q-value function represented by a multi-layer perceptron, is introduced and it is shown empirically, that reasonably few interactions with the plant are needed to generate control policies of high quality."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5883542"
                        ],
                        "name": "E. Thorndike",
                        "slug": "E.-Thorndike",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Thorndike",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Thorndike"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 143789988,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c5810a36025d2e8a023347275a8cd7194b177461",
            "isKey": false,
            "numCitedBy": 504,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Animal Intelligence is a consolidated record of Edward L. Thorndike's theoretical and empirical contributions to the comparative psychology of learning. Thorndike's approach is systematic and comprehensive experimentation using a variety of animals and tasks, all within a laboratory setting. When this book first appeared, it set a compelling example, and helped make the study of animal behavior very much an experimental laboratory science. This landmark study in the investigation of animal intelligence illustrates Thorndike's thinking on the evolution of the mind. It includes his formal statement of the influential law of effect, which had a significant impact on other behaviorists. Hull's law of primary reinforcement was closely related to the law of effect and Skinner acknowledged that the process of operant conditioning was probably that described in the law of effect. The new introduction by Darryl Bruce is an in-depth study of Thorndike's legacy to comparative psychology as well as a thorough retrospective review of Animal Intelligence. He includes a biographical introduction of the behaviorist and then delves into his theories and work. Among the topics Bruce covers with respect to Thorndike's studies are the nature of animal intelligence, the laws of learning and connectionism, implications for comparative psychology, and relation to theories of other behaviorists. Animal Intelligence is an intriguing analysis that will be of importance to psychologists and animal behaviorists."
            },
            "slug": "Animal-Intelligence;-Experimental-Studies-Thorndike",
            "title": {
                "fragments": [],
                "text": "Animal Intelligence; Experimental Studies"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701656"
                        ],
                        "name": "James L. McClelland",
                        "slug": "James-L.-McClelland",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McClelland",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. McClelland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33259752"
                        ],
                        "name": "B. McNaughton",
                        "slug": "B.-McNaughton",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "McNaughton",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. McNaughton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390067049"
                        ],
                        "name": "R. O\u2019Reilly",
                        "slug": "R.-O\u2019Reilly",
                        "structuredName": {
                            "firstName": "Randall",
                            "lastName": "O\u2019Reilly",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. O\u2019Reilly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2832081,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "2ebf18e7892e660a833152ddc6cf8f1d21a7b881",
            "isKey": false,
            "numCitedBy": 4390,
            "numCiting": 309,
            "paperAbstract": {
                "fragments": [],
                "text": "Damage to the hippocampal system disrupts recent memory but leaves remote memory intact. The account presented here suggests that memories are first stored via synaptic changes in the hippocampal system, that these changes support reinstatement of recent memories in the neocortex, that neocortical synapses change a little on each reinstatement, and that remote memory is based on accumulated neocortical changes. Models that learn via changes to connections help explain this organization. These models discover the structure in ensembles of items if learning of each item is gradual and interleaved with learning about other items. This suggests that the neocortex learns slowly to discover the structure in ensembles of experiences. The hippocampal system permits rapid learning of new items without disrupting this structure, and reinstatement of new memories interleaves them with others to integrate them into structured neocortical memory systems."
            },
            "slug": "Why-there-are-complementary-learning-systems-in-the-McClelland-McNaughton",
            "title": {
                "fragments": [],
                "text": "Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory."
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The account presented here suggests that memories are first stored via synaptic changes in the hippocampal system, that these changes support reinstatement of recent memories in the neocortex, that neocortical synapses change a little on each reinstatement, and that remote memory is based on accumulated neocorticals changes."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145290695"
                        ],
                        "name": "C. Watkins",
                        "slug": "C.-Watkins",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Watkins",
                            "middleNames": [
                                "J.",
                                "C.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Watkins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8223593,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7708178d34d069b58a88ea4eb13aa1f57d87bedb",
            "isKey": false,
            "numCitedBy": 2931,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\n$$\\mathcal{Q}$$\n-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.This paper presents and proves in detail a convergence theorem for \n$$\\mathcal{Q}$$\n-learning based on that outlined in Watkins (1989). We show that \n$$\\mathcal{Q}$$\n-learning converges to the optimum action-values with probability 1 so long as all actions are repeatedly sampled in all states and the action-values are represented discretely. We also sketch extensions to the cases of non-discounted, but absorbing, Markov environments, and where many \n$$\\mathcal{Q}$$\n values can be changed each iteration, rather than just one."
            },
            "slug": "Technical-Note:-Q-Learning-Watkins-Dayan",
            "title": {
                "fragments": [],
                "text": "Technical Note: Q-Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A convergence theorem is presented and proves that Q -learning converges to the optimum action-values with probability 1 so long as all actions are repeatedly sampled in all states and the action- values are represented discretely."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3098331"
                        ],
                        "name": "N. Sigala",
                        "slug": "N.-Sigala",
                        "structuredName": {
                            "firstName": "Natasha",
                            "lastName": "Sigala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sigala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31772450"
                        ],
                        "name": "N. Logothetis",
                        "slug": "N.-Logothetis",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Logothetis",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Logothetis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4300291,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "0bbd52aaddd00bc863c93d7b106db658c5c29402",
            "isKey": false,
            "numCitedBy": 562,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "The way that we perceive and interact with objects depends on our previous experience with them. For example, a bird expert is more likely to recognize a bird as a sparrow, a sandpiper or a cockatiel than a non-expert. Neurons in the inferior temporal cortex have been shown to be important in the representation of visual objects; however, it is unknown which object features are represented and how these representations are affected by categorization training. Here we show that feature selectivity in the macaque inferior temporal cortex is shaped by categorization of objects on the basis of their visual features. Specifically, we recorded from single neurons while monkeys performed a categorization task with two sets of parametric stimuli. Each stimulus set consisted of four varying features, but only two of the four were important for the categorization task (diagnostic features). We found enhanced neuronal representation of the diagnostic features relative to the non-diagnostic ones. These findings demonstrate that stimulus features important for categorization are instantiated in the activity of single units (neurons) in the primate inferior temporal cortex."
            },
            "slug": "Visual-categorization-shapes-feature-selectivity-in-Sigala-Logothetis",
            "title": {
                "fragments": [],
                "text": "Visual categorization shapes feature selectivity in the primate temporal cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work shows that feature selectivity in the macaque inferior temporal cortex is shaped by categorization of objects on the basis of their visual features, and finds enhanced neuronal representation of the diagnostic features relative to the non-diagnostic ones."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206775608,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "69e68bfaadf2dccff800158749f5a50fe82d173b",
            "isKey": false,
            "numCitedBy": 3717,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by \u201clearning without a teacher\u201d, and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname \u201cneocognitron\u201d. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of \u201cS-cells\u201d, which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of \u201cC-cells\u201d similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any \u201cteacher\u201d during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern."
            },
            "slug": "Neocognitron:-A-self-organizing-neural-network-for-Fukushima",
            "title": {
                "fragments": [],
                "text": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A neural network model for a mechanism of visual pattern recognition that is self-organized by \u201clearning without a teacher\u201d, and acquires an ability to recognize stimulus patterns based on the geometrical similarity of their shapes without affected by their positions."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": false,
            "numCitedBy": 80947,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792298"
                        ],
                        "name": "Marc G. Bellemare",
                        "slug": "Marc-G.-Bellemare",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Bellemare",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc G. Bellemare"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144056327"
                        ],
                        "name": "J. Veness",
                        "slug": "J.-Veness",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Veness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Veness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687780"
                        ],
                        "name": "Michael Bowling",
                        "slug": "Michael-Bowling",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bowling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Bowling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2554656,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3689115fa21e16d50030aaec01822af996f3e4e7",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n Contingency awareness is the recognition that some aspects of a future observation are under an agent's control while others are solely determined by the environment. This paper explores the idea of contingency awareness in reinforcement learning using the platform of Atari 2600 games. We introduce a technique for accurately identifying contingent regions and describe how to exploit this knowledge to generate improved features for value function approximation. We evaluate the performance of our techniques empirically, using 46 unseen, diverse, and challenging games for the Atari 2600 console. Our results suggest that contingency awareness is a generally useful concept for model-free reinforcement learning agents.\n \n"
            },
            "slug": "Investigating-Contingency-Awareness-Using-Atari-Bellemare-Veness",
            "title": {
                "fragments": [],
                "text": "Investigating Contingency Awareness Using Atari 2600 Games"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper introduces a technique for accurately identifying contingent regions and describes how to exploit this knowledge to generate improved features for value function approximation, and evaluates the performance of the techniques empirically."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760402"
                        ],
                        "name": "A. Moore",
                        "slug": "A.-Moore",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Moore",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8483722"
                        ],
                        "name": "C. Atkeson",
                        "slug": "C.-Atkeson",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Atkeson",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Atkeson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 38901226,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e21956fdbc06204db7984aacea09db7eda6355ad",
            "isKey": false,
            "numCitedBy": 463,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new algorithm, prioritized sweeping, for efficient prediction and control of stochastic Markov systems. Incremental learning methods such as temporal differencing and Q-learning have real-time performance. Classical methods are slower, but more accurate, because they make full use of the observations. Prioritized sweeping aims for the best of both worlds. It uses all previous experiences both to prioritize important dynamic programming sweeps and to guide the exploration of state-space. We compare prioritized sweeping with other reinforcement learning schemes for a number of different stochastic optimal control problems. It successfully solves large state-space real-time problems with which other methods have difficulty."
            },
            "slug": "Prioritized-Sweeping:-Reinforcement-Learning-with-Moore-Atkeson",
            "title": {
                "fragments": [],
                "text": "Prioritized Sweeping: Reinforcement Learning with Less Data and Less Time"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work presents a new algorithm, prioritized sweeping, for efficient prediction and control of stochastic Markov systems, which successfully solves large state-space real-time problems with which other methods have difficulty."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045071"
                        ],
                        "name": "D. Bendor",
                        "slug": "D.-Bendor",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bendor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bendor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28367208"
                        ],
                        "name": "M. Wilson",
                        "slug": "M.-Wilson",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Wilson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wilson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7709293,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "fd923b9aae5b69a345a324581bd56ad5ffe3247e",
            "isKey": false,
            "numCitedBy": 268,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "The hippocampus is essential for encoding self-experienced events into memory. During sleep, neural activity in the hippocampus related to a recent experience has been observed to spontaneously reoccur, and this 'replay' has been postulated to be important for memory consolidation. Task-related cues can enhance memory consolidation when presented during a post-training sleep session, and, if memories are consolidated by hippocampal replay, a specific enhancement for this replay should be observed. To test this, we trained rats on an auditory-spatial association task while recording from neuronal ensembles in the hippocampus. We found that, during sleep, a task-related auditory cue biased reactivation events toward replaying the spatial memory associated with that cue. These results indicate that sleep replay can be manipulated by external stimulation and provide further evidence for the role of hippocampal replay in memory consolidation."
            },
            "slug": "Biasing-the-content-of-hippocampal-replay-during-Bendor-Wilson",
            "title": {
                "fragments": [],
                "text": "Biasing the content of hippocampal replay during sleep"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Rats were trained on an auditory-spatial association task while recording from neuronal ensembles in the hippocampus and it was found that, during sleep, a task-related auditory cue biased reactivation events toward replaying the spatial memory associated with that cue."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709512"
                        ],
                        "name": "L. Kaelbling",
                        "slug": "L.-Kaelbling",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Kaelbling",
                            "middleNames": [
                                "Pack"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kaelbling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144885169"
                        ],
                        "name": "M. Littman",
                        "slug": "M.-Littman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Littman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Littman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2453007"
                        ],
                        "name": "A. Cassandra",
                        "slug": "A.-Cassandra",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Cassandra",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cassandra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5613003,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "116d7798c1123cf7fad4176e98f58fd49de4f8f1",
            "isKey": false,
            "numCitedBy": 3955,
            "numCiting": 137,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Planning-and-Acting-in-Partially-Observable-Domains-Kaelbling-Littman",
            "title": {
                "fragments": [],
                "text": "Planning and Acting in Partially Observable Stochastic Domains"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1658773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e",
            "isKey": false,
            "numCitedBy": 14642,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such \u201cautoencoder\u201d networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "slug": "Reducing-the-Dimensionality-of-Data-with-Neural-Hinton-Salakhutdinov",
            "title": {
                "fragments": [],
                "text": "Reducing the Dimensionality of Data with Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work describes an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701656"
                        ],
                        "name": "James L. McClelland",
                        "slug": "James-L.-McClelland",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McClelland",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. McClelland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15291527,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff2c2e3e83d1e8828695484728393c76ee07a101",
            "isKey": false,
            "numCitedBy": 15710,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The fundamental principles, basic mechanisms, and formal analyses involved in the development of parallel distributed processing (PDP) systems are presented in individual chapters contributed by leading experts. Topics examined include distributed representations, PDP models and general issues in cognitive science, feature discovery by competitive learning, the foundations of harmony theory, learning and relearning in Boltzmann machines, and learning internal representations by error propagation. Consideration is given to linear algebra in PDP, the logic of additive functions, resource requirements of standard and programmable nets, and the P3 parallel-network simulating system."
            },
            "slug": "Parallel-distributed-processing:-explorations-in-of-Rumelhart-McClelland",
            "title": {
                "fragments": [],
                "text": "Parallel distributed processing: explorations in the microstructure of cognition, vol. 1: foundations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1422230128"
                        ],
                        "name": "J. O\u2019Neill",
                        "slug": "J.-O\u2019Neill",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "O\u2019Neill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O\u2019Neill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404670785"
                        ],
                        "name": "Barty Pleydell-Bouverie",
                        "slug": "Barty-Pleydell-Bouverie",
                        "structuredName": {
                            "firstName": "Barty",
                            "lastName": "Pleydell-Bouverie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barty Pleydell-Bouverie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3409334"
                        ],
                        "name": "D. Dupret",
                        "slug": "D.-Dupret",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Dupret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dupret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5799995"
                        ],
                        "name": "J. Csicsvari",
                        "slug": "J.-Csicsvari",
                        "structuredName": {
                            "firstName": "Jozsef",
                            "lastName": "Csicsvari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Csicsvari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9000835,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "40d650666e1bba23602297d2e6290795a9bb2048",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Play-it-again:-reactivation-of-waking-experience-O\u2019Neill-Pleydell-Bouverie",
            "title": {
                "fragments": [],
                "text": "Play it again: reactivation of waking experience and memory"
            },
            "venue": {
                "fragments": [],
                "text": "Trends in Neurosciences"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981539"
                        ],
                        "name": "Thomas Serre",
                        "slug": "Thomas-Serre",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Serre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Serre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145128145"
                        ],
                        "name": "Lior Wolf",
                        "slug": "Lior-Wolf",
                        "structuredName": {
                            "firstName": "Lior",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lior Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 260426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "040c23e5a409fbdedd5032263dfcb1a4d7dfd200",
            "isKey": false,
            "numCitedBy": 969,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel set of features for robust object recognition. Each element of this set is a complex feature obtained by combining position- and scale-tolerant edge-detectors over neighboring positions and multiple orientations. Our system's architecture is motivated by a quantitative model of visual cortex. We show that our approach exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories. We also demonstrate that our system is able to learn from very few examples. The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex."
            },
            "slug": "Object-recognition-with-features-inspired-by-visual-Serre-Wolf",
            "title": {
                "fragments": [],
                "text": "Object recognition with features inspired by visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex and exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699108"
                        ],
                        "name": "G. Tesauro",
                        "slug": "G.-Tesauro",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Tesauro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tesauro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6023746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ed59f49c1bb7de06cfa2a9467d5efb535103277",
            "isKey": false,
            "numCitedBy": 845,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Ever since the days of Shannon's proposal for a chess-playing algorithm [12] and Samuel's checkers-learning program [10] the domain of complex board games such as Go, chess, checkers, Othello, and backgammon has been widely regarded as an ideal testing ground for exploring a variety of concepts and approaches in artificial intelligence and machine learning. Such board games offer the challenge of tremendous complexity and sophistication required to play at expert level. At the same time, the problem inputs and performance measures are clear-cut and well defined, and the game environment is readily automated in that it is easy to simulate the board, the rules of legal play, and the rules regarding when the game is over and determining the outcome."
            },
            "slug": "Temporal-difference-learning-and-TD-Gammon-Tesauro",
            "title": {
                "fragments": [],
                "text": "Temporal difference learning and TD-Gammon"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The domain of complex board games such as Go, chess, checkers, Othello, and backgammon has been widely regarded as an ideal testing ground for exploring a variety of concepts and approaches in artificial intelligence and machine learning."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144224173"
                        ],
                        "name": "J. Tsitsiklis",
                        "slug": "J.-Tsitsiklis",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tsitsiklis",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tsitsiklis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731282"
                        ],
                        "name": "Benjamin Van Roy",
                        "slug": "Benjamin-Van-Roy",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Van Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7353554,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "ceee9569717991607b399d9a6890f1dcb9541ac0",
            "isKey": false,
            "numCitedBy": 1441,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "We present new results about the temporal-difference learning algorithm, as applied to approximating the cost-to-go function of a Markov chain using linear function approximators. The algorithm we analyze performs on-line updating of a parameter vector during a single endless trajectory of an aperiodic irreducible finite state Markov chain. Results include convergence (with probability 1), a characterization of the limit of convergence, and a bound on the resulting approximation error. In addition to establishing new and stronger results than those previously available, our analysis is based on a new line of reasoning that provides new intuition about the dynamics of temporal-difference learning. Furthermore, we discuss the implications of two counter-examples with regards to the Significance of on-line updating and linearly parameterized function approximators."
            },
            "slug": "Analysis-of-Temporal-Diffference-Learning-with-Tsitsiklis-Roy",
            "title": {
                "fragments": [],
                "text": "Analysis of Temporal-Diffference Learning with Function Approximation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "New results about the temporal-difference learning algorithm, as applied to approximating the cost-to-go function of a Markov chain using linear function approximators are presented."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334226"
                        ],
                        "name": "D. Hubel",
                        "slug": "D.-Hubel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hubel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hubel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2629471"
                        ],
                        "name": "T. Wiesel",
                        "slug": "T.-Wiesel",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Wiesel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wiesel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6171259,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d7fb932bca642615fcbcf3f5d26b2c26666603d3",
            "isKey": false,
            "numCitedBy": 805,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Cells in the cat's striate cortex show marked specificity in their responses to restricted retinal stimulation (Hubel & Wiesel, 1959, 1962). The most effective stimulus shapes are long narrow rectangles of light ('slits'), dark bars against a light background ('dark bars'), and straight-line borders separating areas of different brightness ('edges'). A given cell responds vigorously when an appropriate stimulus is shone on the receptive field or moved across it, provided the stimulus is presented in a specific orientation. This orientation is termed the 'receptive-field axis orientation'. It is critical, and constant for any particular cell, but may differ for different cells. The visual cortex is subdivided into discrete regions or columns extending from surface to white matter, in which all cells have the same receptivefield axis orientation (Hubel & Wiesel, 1962). The present experiments were undertaken with the object of learning more about the anatomical configuration of the columns. We wished to have a clearer idea of their shape, especially if the walls of a column were, as previous work suggested, parallel to the radial fibre bundles of the cortex and perpendicular to the cortical layers, and whether the columns were uniform or irregular in their cross-sectional shape and size. Furthermore, we were curious to know if there was any relationship between the receptive-field axis orientations of neighbouring columns, or whether, on the contrary, the different columns were intermixed in a random way throughout the cortex. These questions were approached: (1) by making several deep, closely spaced, parallel micro-electrode penetrations, placing electrolytic lesions at every shift in receptive-field orientation, and(2) by making many short penetrations in a small cortical area, noting the axis orientation of cells lying in the upper one or two layers of cortex."
            },
            "slug": "Shape-and-arrangement-of-columns-in-cat's-striate-Hubel-Wiesel",
            "title": {
                "fragments": [],
                "text": "Shape and arrangement of columns in cat's striate cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Questions were approached by making several deep, closely spaced, parallel micro-electrode penetrations, placing electrolytic lesions at every shift in receptive-field orientation, and by making many short penetrations in a small cortical area, noting the axis orientation of cells lying in the upper one or two layers of cortex."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of physiology"
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34313265"
                        ],
                        "name": "S. Legg",
                        "slug": "S.-Legg",
                        "structuredName": {
                            "firstName": "Shane",
                            "lastName": "Legg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Legg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154444"
                        ],
                        "name": "Marcus Hutter",
                        "slug": "Marcus-Hutter",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcus Hutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 847021,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e8ec502208f29ee9f78ded19226578e027ecd16",
            "isKey": false,
            "numCitedBy": 484,
            "numCiting": 164,
            "paperAbstract": {
                "fragments": [],
                "text": "A fundamental problem in artificial intelligence is that nobody really knows what intelligence is. The problem is especially acute when we need to consider artificial systems which are significantly different to humans. In this paper we approach this problem in the following way: we take a number of well known informal definitions of human intelligence that have been given by experts, and extract their essential features. These are then mathematically formalised to produce a general measure of intelligence for arbitrary machines. We believe that this equation formally captures the concept of machine intelligence in the broadest reasonable sense. We then show how this formal definition is related to the theory of universal optimal learning agents. Finally, we survey the many other tests and definitions of intelligence that have been proposed for machines."
            },
            "slug": "Universal-Intelligence:-A-Definition-of-Machine-Legg-Hutter",
            "title": {
                "fragments": [],
                "text": "Universal Intelligence: A Definition of Machine Intelligence"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A number of well known informal definitions of human intelligence are taken, and mathematically formalised to produce a general measure of intelligence for arbitrary machines that formally captures the concept of machine intelligence in the broadest reasonable sense."
            },
            "venue": {
                "fragments": [],
                "text": "Minds and Machines"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35262,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073603971"
                        ],
                        "name": "Vinod Nair",
                        "slug": "Vinod-Nair",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Nair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinod Nair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15539264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a538b05ebb01a40323997629e171c91aa28b8e2f",
            "isKey": false,
            "numCitedBy": 12808,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these \"Stepped Sigmoid Units\" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors."
            },
            "slug": "Rectified-Linear-Units-Improve-Restricted-Boltzmann-Nair-Hinton",
            "title": {
                "fragments": [],
                "text": "Rectified Linear Units Improve Restricted Boltzmann Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units that learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077257730"
                        ],
                        "name": "Kevin Jarrett",
                        "slug": "Kevin-Jarrett",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Jarrett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Jarrett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206769720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f88427d7aa8225e47f946ac41a0667d7b69ac52",
            "isKey": false,
            "numCitedBy": 2085,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (\u226b 65%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53%)."
            },
            "slug": "What-is-the-best-multi-stage-architecture-for-Jarrett-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "What is the best multi-stage architecture for object recognition?"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks and that two stages of feature extraction yield better accuracy than one."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803520"
                        ],
                        "name": "L. V. D. Maaten",
                        "slug": "L.-V.-D.-Maaten",
                        "structuredName": {
                            "firstName": "Laurens",
                            "lastName": "Maaten",
                            "middleNames": [
                                "van",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. V. D. Maaten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5855042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c46943103bd7b7a2c7be86859995a4144d1938b",
            "isKey": false,
            "numCitedBy": 22354,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new technique called \u201ct-SNE\u201d that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large datasets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of datasets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the datasets."
            },
            "slug": "Visualizing-Data-using-t-SNE-Maaten-Hinton",
            "title": {
                "fragments": [],
                "text": "Visualizing Data using t-SNE"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A new technique called t-SNE that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map, a variation of Stochastic Neighbor Embedding that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4940444"
                        ],
                        "name": "M. Genesereth",
                        "slug": "M.-Genesereth",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Genesereth",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Genesereth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38372561"
                        ],
                        "name": "Nathaniel Love",
                        "slug": "Nathaniel-Love",
                        "structuredName": {
                            "firstName": "Nathaniel",
                            "lastName": "Love",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathaniel Love"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145044563"
                        ],
                        "name": "B. Pell",
                        "slug": "B.-Pell",
                        "structuredName": {
                            "firstName": "Barney",
                            "lastName": "Pell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Pell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13216868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c89c71dbe5617bea44383585b58cd0cbc37bf79a",
            "isKey": false,
            "numCitedBy": 536,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A general game playing system is one that can accept a formal description of a game and play the game effectively without human intervention. Unlike specialized game players, such as Deep Blue, general game players do not rely on algorithms designed in advance for specific games; and, unlike Deep Blue, they are able to play different kinds of games. In order to promote work in this area, the AAAI is sponsoring an open competition at this summer's Twentieth National Conference on Artificial Intelligence. This article is an overview of the technical issues and logistics associated with this summer's competition, as well as the relevance of general game playing to the long range-goals of artificial intelligence."
            },
            "slug": "General-Game-Playing:-Overview-of-the-AAAI-Genesereth-Love",
            "title": {
                "fragments": [],
                "text": "General Game Playing: Overview of the AAAI Competition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An overview of the technical issues and logistics associated with this summer's competition, as well as the relevance of general game playing to the long range-goals of artificial intelligence, are overviewed."
            },
            "venue": {
                "fragments": [],
                "text": "AI Mag."
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Human-level control through deep reinforcement learning"
            },
            "venue": {
                "fragments": [],
                "text": "Nature 518,"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rescale to 84 \u00d7 84 and convert to grayscale"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pinball Boxing Breakout Star Gunner Montezuma's Private Eye Gravitar Ms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 36,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d?sort=total-citations"
}