{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759801"
                        ],
                        "name": "Ermelinda Oro",
                        "slug": "Ermelinda-Oro",
                        "structuredName": {
                            "firstName": "Ermelinda",
                            "lastName": "Oro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ermelinda Oro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794345"
                        ],
                        "name": "M. Ruffolo",
                        "slug": "M.-Ruffolo",
                        "structuredName": {
                            "firstName": "Massimo",
                            "lastName": "Ruffolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ruffolo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5900801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99ecff93087b010e466d47aca2eedece88929aab",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents PDF-TREX, an heuristic approach for table recognition and extraction from PDF documents.The heuristics starts from an initial set of basic content elements and aligns and groups them, in bottom-up way by considering only their spatial features, in order to identify tabular arrangements of information. The scope of the approach is to recognize tables contained in PDF documents as a 2-dimensional grid on a Cartesian plane and extract them as a set of cells equipped by 2-dimensional coordinates. Experiments, carried out on a dataset composed of tables contained in documents coming from different domains, shows that the approach is well performing in recognizing table cells.The approach aims at improving PDF document annotation and information extraction by providing an output that can be further processed for understanding table and document contents."
            },
            "slug": "PDF-TREX:-An-Approach-for-Recognizing-and-Tables-Oro-Ruffolo",
            "title": {
                "fragments": [],
                "text": "PDF-TREX: An Approach for Recognizing and Extracting Tables from PDF Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The approach aims at improving PDF document annotation and information extraction by providing an output that can be further processed for understanding table and document contents."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777642"
                        ],
                        "name": "Liangcai Gao",
                        "slug": "Liangcai-Gao",
                        "structuredName": {
                            "firstName": "Liangcai",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liangcai Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143830636"
                        ],
                        "name": "Zhi Tang",
                        "slug": "Zhi-Tang",
                        "structuredName": {
                            "firstName": "Zhi",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46520089"
                        ],
                        "name": "Xiaofan Lin",
                        "slug": "Xiaofan-Lin",
                        "structuredName": {
                            "firstName": "Xiaofan",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofan Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49420283"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29035564"
                        ],
                        "name": "Ruiheng Qiu",
                        "slug": "Ruiheng-Qiu",
                        "structuredName": {
                            "firstName": "Ruiheng",
                            "lastName": "Qiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruiheng Qiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47904794"
                        ],
                        "name": "Yongtao Wang",
                        "slug": "Yongtao-Wang",
                        "structuredName": {
                            "firstName": "Yongtao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongtao Wang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Wrapper-based table detection is a subgraph of the document with some constraints using data instances for extracting related data [92]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11984172,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f9aba7af8ff6b69e03dd82342f98e8ef28c62c4",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Nowadays PDF documents have become a dominating knowledge repository for both the academia and industry largely because they are very convenient to print and exchange. However, the methods of automated structure information extraction are yet to be fully explored and the lack of effective methods hinders the information reuse of the PDF documents. To enhance the usability for PDF-formatted electronic books, we propose a novel computational framework to analyze the underlying physical structure and logical structure. The analysis is conducted at both page level and document level, including global typographies, reading order, logical elements, chapter/section hierarchy and metadata. Moreover, two characteristics of PDF-based books, i.e., style consistency in the whole book document and natural rendering order of PDF files, are fully exploited in this paper to improve the conventional image-based structure extraction methods. This paper employs the bipartite graph as a common structure for modeling various tasks, including reading order recovery, figure and caption association, and metadata extraction. Based on the graph representation, the optimal matching (OM) method is utilized to find the global optima in those tasks. Extensive benchmarking using real-world data validates the high efficiency and discrimination ability of the proposed method."
            },
            "slug": "Structure-extraction-from-PDF-based-book-documents-Gao-Tang",
            "title": {
                "fragments": [],
                "text": "Structure extraction from PDF-based book documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel computational framework to analyze the underlying physical structure and logical structure of PDF-formatted electronic books and employs the bipartite graph as a common structure for modeling various tasks, including reading order recovery, figure and caption association, and metadata extraction."
            },
            "venue": {
                "fragments": [],
                "text": "JCDL '11"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398476"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930195"
                        ],
                        "name": "P. Mitra",
                        "slug": "P.-Mitra",
                        "structuredName": {
                            "firstName": "Prasenjit",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Few research works pay attention to the use of statistical approaches for table detection, including probabilistic modelling [40], the Naive Bayes classifier [44, 52, 57, 61, 66], the Maximum Entropy Classifier [34, 44], decision trees [40, 44, 45, 68], Support Vector Machine [45, 51, 59, 65], the Winnow classifier [44], Conditional Random Fields [33, 34, 51, 59, 67] and an HMM of the traditional sort [70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Some research works used heuristics-based techniques for table detection [23, 27, 29, 31, 33, 36, 38, 41, 42, 48, 52\u201361]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1957282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b05417cde0ae70e1c74a364a89e2661db5f1231",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Most prior work on information extraction has focused on extracting information from text in digital documents. However, often, the most important information being reported in an article is presented in tabular form in a digital document. If the data reported in tables can be extracted and stored in a database, the data can be queried and joined with other data using database management systems. In order to prepare the data source for table search, accurately detecting the table boundary plays a crucial role for the later table structure decomposition. Table boundary detection and content extraction is a challenging problem because tabular formats are not standardized across all documents. In this paper, we propose a simple but effective preprocessing method to improve the table boundary detection performance by considering the sparse-line property of table rows. Our method easily simplifies the table boundary detection problem into the sparse line analysis problem with much less noise. We design eight line label types and apply two machine learning techniques, Conditional Random Field (CRF) and Support Vector Machines (SVM), on the table boundary detection field. The experimental results not only compare the performances between the machine learning methods and the heuristics-based method, but also demonstrate the effectiveness of the sparse line analysis in the table boundary detection."
            },
            "slug": "Identifying-table-boundaries-in-digital-documents-Liu-Mitra",
            "title": {
                "fragments": [],
                "text": "Identifying table boundaries in digital documents via sparse line detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a simple but effective preprocessing method to improve the table boundary detection performance by considering the sparse-line property of table rows, and designs eight line label types and applies two machine learning techniques, Conditional Random Field and Support Vector Machines, on the table Boundary detection field."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398476"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930195"
                        ],
                        "name": "P. Mitra",
                        "slug": "P.-Mitra",
                        "structuredName": {
                            "firstName": "Prasenjit",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144654778"
                        ],
                        "name": "Kun Bai",
                        "slug": "Kun-Bai",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Bai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some research works used heuristics-based techniques for table detection [23, 27, 29, 31, 33, 36, 38, 41, 42, 48, 52\u201361]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6795495,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ba3e110dfb9a5d70da1c257f3868f5d4842f341",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are used to present, list, summarize, and structure important data in documents. In scholarly articles, they are often used to present the relationships among data and highlight a collection of results obtained from experiments and scientific analysis. In digital libraries, extracting this data automatically and understanding the structure and content of tables are very important to many applications. Automatic identification extraction, and search for the contents of tables can be made more precise with the help of metadata. In this paper, we propose a set of medium-independent table metadata to facilitate the table indexing, searching, and exchanging. To extract the contents of tables and their metadata, an automatic table metadata extraction algorithm is designed and tested on PDF documents"
            },
            "slug": "Automatic-extraction-of-table-metadata-from-digital-Liu-Mitra",
            "title": {
                "fragments": [],
                "text": "Automatic extraction of table metadata from digital documents"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A set of medium-independent table metadata is proposed to facilitate the table indexing, searching, and exchanging and an automatic table metadata extraction algorithm is designed and tested on PDF documents."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 6th ACM/IEEE-CS Joint Conference on Digital Libraries (JCDL '06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876441"
                        ],
                        "name": "Xing Wei",
                        "slug": "Xing-Wei",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Few research works pay attention to the use of statistical approaches for table detection, including probabilistic modelling [40], the Naive Bayes classifier [44, 52, 57, 61, 66], the Maximum Entropy Classifier [34, 44], decision trees [40, 44, 45, 68], Support Vector Machine [45, 51, 59, 65], the Winnow classifier [44], Conditional Random Fields [33, 34, 51, 59, 67] and an HMM of the traditional sort [70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1457849,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cad9dee27047bb051a63b2484550ec9a989ac848",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to find tables and extract information from them is a necessary component of many information retrieval tasks. Documents often contain tables in order to communicate densely packed, multi-dimensional information. Tables do this by employing layout patterns to efficiently indicate fields and records in two-dimensional form. Their rich combination of formatting and content presents difficulties for traditional retrieval techniques. This paper describes techniques for extracting tables from text and retrieving answers from the extracted information. We compare machine learning (especially, Conditional Random Fields) and heuristic methods for table extraction. To retrieve answers, our approach creates a cell document, which contains the cell and its metadata (headers, titles) for each table cell, and the retrieval model ranks the cells of the extracted tables using a language-modeling approach. Performance is tested using government statistical Web sites and news articles, and errors are analyzed in order to improve the system."
            },
            "slug": "Table-extraction-for-answer-retrieval-Wei-Croft",
            "title": {
                "fragments": [],
                "text": "Table extraction for answer retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "To retrieve answers, the approach creates a cell document, which contains the cell and its metadata (headers, titles) for each table cell, and the retrieval model ranks the cells of the extracted tables using a language-modeling approach."
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8549842"
                        ],
                        "name": "Juan-Zi Li",
                        "slug": "Juan-Zi-Li",
                        "structuredName": {
                            "firstName": "Juan-Zi",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juan-Zi Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46199760"
                        ],
                        "name": "Jie Tang",
                        "slug": "Jie-Tang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112702645"
                        ],
                        "name": "Qiang Song",
                        "slug": "Qiang-Song",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092025759"
                        ],
                        "name": "Peng Xu",
                        "slug": "Peng-Xu",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Xu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4364549,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc780eb8822a575c12564b60c0cc76e0fb62ea4e",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Addressed in this paper is the issue of table extraction from plain text. Table is one of the commonest modes for presenting information. Table extraction has applications in information retrieval, knowledge acquisition, and text mining. Automatic information extraction from table is a challenge. Existing methods was mainly focusing on table extraction from web pages (formatted table extraction). So far the problem of table extraction on plain text, to the best of our knowledge, has not received sufficient attention. In this paper, unformatted table extraction is formalized as unformatted table block detection and unformatted table row identification. We concentrate particularly on the table extraction from Chinese documents. We propose to conduct the task of table extraction by combining machine learning methods and document structure. We first view the task as classification and propose a statistical approach to deal with it based on Naive Bayes. We define features in the classification model. Next, we use document structure to improve the detection performance. Experimental results indicate that the proposed methods can significantly outperform the baseline methods for unformatted table extraction."
            },
            "slug": "Table-Detection-from-Plain-Text-Using-Machine-and-Li-Tang",
            "title": {
                "fragments": [],
                "text": "Table Detection from Plain Text Using Machine Learning and Document Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Experimental results indicate that the proposed methods can significantly outperform the baseline methods for unformatted table extraction and use document structure to improve the detection performance."
            },
            "venue": {
                "fragments": [],
                "text": "APWeb"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Few research works pay attention to the use of statistical approaches for table detection, including probabilistic modelling [40], the Naive Bayes classifier [44, 52, 57, 61, 66], the Maximum Entropy Classifier [34, 44], decision trees [40, 44, 45, 68], Support Vector Machine [45, 51, 59, 65], the Winnow classifier [44], Conditional Random Fields [33, 34, 51, 59, 67] and an HMM of the traditional sort [70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Table analysis after table extraction has been considered by some researchers [40, 43, 97\u201399]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9393238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7673ba3e72a07d4bbfb6b03d806fc3d8f0283105",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a commonly used presentation scheme for describing relational information. Table understanding on the web has many potential applications including web mining, knowledge management, and web content summarization and delivery to narrow-bandwidth devices. Although in HTML documents tables are generally marked as ?table? elements, a ?table? element does not necessarily indicate the presence of a genuine relational table. Thus the important first step in table understanding in the web domain is the detection of the genuine tables. In our earlier work we designed a basic rule-based algorithm to detect genuine tables in major news and corporate home pages as part of a web content filtering system. In this paper we investigate a machine learning based approach that is trainable and thus can be automatically generalized to including any domain. Various features reflecting the layout as well as content characteristics of tables are explored. The system is tested on a large database which consists of 1, 393 HTML files collected from hundreds of different web sites from various domains and contains over 10,000 leaf ?table? elements. Experiments were conducted using the cross validation method. The machine learning based approach outperformed the rule-based system and achieved an F-measure of 95.88%."
            },
            "slug": "Detecting-Tables-in-HTML-Documents-Wang-Hu",
            "title": {
                "fragments": [],
                "text": "Detecting Tables in HTML Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper investigates a machine learning based approach that is trainable and thus can be automatically generalized to including any domain and outperformed the rule-based system and achieved an F-measure of 95.88%."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115379063"
                        ],
                        "name": "Jing Fang",
                        "slug": "Jing-Fang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070898875"
                        ],
                        "name": "Xin Tao",
                        "slug": "Xin-Tao",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087321561"
                        ],
                        "name": "Zhi Tang",
                        "slug": "Zhi-Tang",
                        "structuredName": {
                            "firstName": "Zhi",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29035564"
                        ],
                        "name": "Ruiheng Qiu",
                        "slug": "Ruiheng-Qiu",
                        "structuredName": {
                            "firstName": "Ruiheng",
                            "lastName": "Qiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruiheng Qiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49420283"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "There is no benchmark/ground truth to evaluate experimental results; therefore no performance metrics could be achieved [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[12] provide a ground-truth general dataset, and propose evaluation metrics with publicly available source code for table detection algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "All evaluation methods discussed above can evaluate algorithms as a whole and cannot highlight detailed error descriptions with no improvement hints [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Each algorithm has limitations, and no single algorithm can provide ideal performance considering all evaluation metrics [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 23786594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f7a62139dfd09bfad667691332bd55e31736887",
            "isKey": true,
            "numCitedBy": 41,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Table detection is an important task in the field of document analysis. It has been extensively studied since a couple of decades. Various kinds of document mediums are involved, from scanned images to web pages, from plain texts to PDF files. Numerous algorithms published bring up a challenging issue: how to evaluate algorithms in different context. Currently, most work on table detection conducts experiments on their in-house dataset. Even the few sources of online datasets are targeted at image documents only. Moreover, Precision and recall measurement are usual practice in order to account performance based on human evaluation. In this paper, we provide a dataset that is representative, large and most importantly, publicly available. The compatible format of the ground truth makes evaluation independent of document medium. We also propose a set of new measures, implement them, and open the source code. Finally, three existing table detection algorithms are evaluated to demonstrate the reliability of the dataset and metrics."
            },
            "slug": "Dataset,-Ground-Truth-and-Performance-Metrics-for-Fang-Tao",
            "title": {
                "fragments": [],
                "text": "Dataset, Ground-Truth and Performance Metrics for Table Detection Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A dataset that is representative, large and most importantly, publicly available, and the compatible format of the ground truth makes evaluation independent of document medium is provided."
            },
            "venue": {
                "fragments": [],
                "text": "2012 10th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Genuine tables have relationships among cells in a two-dimensional grid and non-genuine tables are just clusters for viewing purposes only [45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Few research works pay attention to the use of statistical approaches for table detection, including probabilistic modelling [40], the Naive Bayes classifier [44, 52, 57, 61, 66], the Maximum Entropy Classifier [34, 44], decision trees [40, 44, 45, 68], Support Vector Machine [45, 51, 59, 65], the Winnow classifier [44], Conditional Random Fields [33, 34, 51, 59, 67] and an HMM of the traditional sort [70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Wang and Hu [45] use both Decision Tree Classifier and SVM for finding fake and genuine entities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Wang and Hu propose a system for storing extracted table data in databases for retrieving information through spoken language interface [45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2061833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d89945f77470b6a1dabd1f224f10b7d096fd9435",
            "isKey": true,
            "numCitedBy": 227,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a commonly used presentation scheme, especially for describing relational information. However, table understanding remains an open problem. In this paper, we consider the problem of table detection in web documents. Its potential applications include web mining, knowledge management, and web content summarization and delivery to narrow-bandwidth devices. We describe a machine learning based approach to classify each given table entity as either genuine or non-genuine. Various features reflecting the layout as well as content characteristics of tables are studied.In order to facilitate the training and evaluation of our table classifier, we designed a novel web document table ground truthing protocol and used it to build a large table ground truth database. The database consists of 1,393 HTML files collected from hundreds of different web sites and contains 11,477 leaf TABLE elements, out of which 1,740 are genuine tables. Experiments were conducted using the cross validation method and an F-measure of 95.89% was achieved."
            },
            "slug": "A-machine-learning-based-approach-for-table-on-the-Wang-Hu",
            "title": {
                "fragments": [],
                "text": "A machine learning based approach for table detection on the web"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A machine learning based approach to classify each given table entity as either genuine or non-genuine, and designed a novel web document table ground truthing protocol and used it to build a large table ground truth database."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37293831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "edbd577d793a083de4f337acac992ec7837609e0",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An important step towards the goal of table understanding is a method for reliable table detection. This paper describes a general solution for detecting tables based on computing an optimal partitioning of a document into some number of tables. A dynamic programming algorithm is given to solve the resulting optimization problem. This high-level framework is independent of any particular table quality measure and independent of the document medium. Moreover, it does not rely on the presence of ruling lines or other table delimiters. We also present table quality measures based on white space correlation and vertical connected component analysis. These measures can be applied equally well to ASCII text and scanned images. We report on some preliminary experiments using this method to detect tables in both ASCII text and scanned images, yielding promising results. We present detailed evaluation of these results using three different criteria which by themselves pose interesting research questions."
            },
            "slug": "Medium-independent-table-detection-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Medium-independent table detection"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A general solution for detecting tables based on computing an optimal partitioning of a document into some number of tables is described and a dynamic programming algorithm is given to solve the resulting optimization problem."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398476"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144654778"
                        ],
                        "name": "Kun Bai",
                        "slug": "Kun-Bai",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930195"
                        ],
                        "name": "P. Mitra",
                        "slug": "P.-Mitra",
                        "structuredName": {
                            "firstName": "Prasenjit",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "All these models cannot cover table-related information as well as document background information [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, very little work has been carried out on such formats [21, 48, 58, 60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2940120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "627ae41c9e345f002a766cdb777fdac91d5f5427",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are ubiquitous in digital libraries. In scientific documents, tables are widely used to present experimental results or statistical data in a condensed fashion. However, current search engines do not support table search. The difficulty of automatic extracting tables from un-tagged documents, the lack of a universal table metadata specification, and the limitation of the existing ranking schemes make table search problem challenging. In this paper, we describe TableSeer, a search engine for tables. TableSeer crawls digital libraries, detects tables from documents, extracts tables metadata, indexes and ranks tables, and provides a user-friendly search interface. We propose an extensive set of medium-independent metadata for tables that scientists and other users can adopt for representing table information. In addition, we devise a novel page box-cutting method to improve the performance of the table detection. Given a query, TableSeer ranks the matched tables using an innovative ranking algorithm - TableRank. TableRank rates each \u20edquery, table\u2102 pair with a tailored vector space model and a specific term weighting scheme. Overall, TableSeer eliminates the burden of manually extract table data from digital libraries and enables users to automatically examine tables. We demonstrate the value of TableSeer with empirical studies on scientific documents."
            },
            "slug": "TableSeer:-automatic-table-metadata-extraction-and-Liu-Bai",
            "title": {
                "fragments": [],
                "text": "TableSeer: automatic table metadata extraction and searching in digital libraries"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Overall, TableSeer eliminates the burden of manually extract table data from digital libraries and enables users to automatically examine tables, and proposes an extensive set of medium-independent metadata for tables that scientists and other users can adopt for representing table information."
            },
            "venue": {
                "fragments": [],
                "text": "JCDL '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Few research works pay attention to the use of statistical approaches for table detection, including probabilistic modelling [40], the Naive Bayes classifier [44, 52, 57, 61, 66], the Maximum Entropy Classifier [34, 44], decision trees [40, 44, 45, 68], Support Vector Machine [45, 51, 59, 65], the Winnow classifier [44], Conditional Random Fields [33, 34, 51, 59, 67] and an HMM of the traditional sort [70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7205594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f52409df167cfe6bafdebac63dfcf8710a56c92",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we consider the table understanding task and present a catalogue of particular issues that arise when the tables are those found on the web. In addition, we consider what happens when processes commonly associated with web pages are applied to those bearing tables. 1 Table Understanding and the Web The ubiquity of tables, and their ability to describe relational information in a compact and immediate manner make them attractive targets for automated understanding. Recent research into the automatic location, recognition and understanding of tables has demonstrated the viability of integrating automated table processing systems into larger knowledge management applications ([8]). However, table understanding is still a relatively novel research area, one whose definition and terminology are still not fixed. It is useful to break the task down into some subtasks, and to consider them in turn with respect to the understanding of tables delivered on the web. Generally, table processing can be conceptualized as consisting of table location; table recognition; functional and structural analysis; and finally interpretation the extraction of meaningful and unambiguously structured information ([4]). We concentrate on the first two tasks in the following. location table location is the processes of spotting tables in documents. Traditionally, this task comes in two basic forms document image sourced tables ([7], [3]) and electronic text sourced tables including HTML ([1]). The problem is extended to include the spotting of tables in other document encodings such as postscript, pdf, rtf, word, etc. In general, when considering tables on the web, the appropriate HTML tags are exploited (TABLE, TH, TD, etc.). However, this is where we come to the first two distinguishing points. the presence of the TABLE tag in an HTML document does not necessarily indicate the presence of a table ([1] suggest less than 30 % of HTML TABLEs are real tables in one particular domain). there are many other ways in which tables may be presented in web delivered documents plain text (PRE), images, mixtures of table specific tags (TABLE, etc.) and tags used within the table for their functionality in terms of placing text spatially (PRE, LI, etc.) see Figure 1 for an example of such complexities. The first point requires the creation of accurate classification technology. Given any TABLE node in the HTML, the classifier must accept or reject it. Such a classifier may be built either via hand crafted rules ([1]) or using a machine learning approach. Experiments suggest that a machine learning approach using a naive bayse classifier ([9]) based on a feature set describing the set of tags below the potential TABLE node in the document tree produces adequate results. Locating tables encoded in other formats requires technology from other areas. For example, images of tables may be processed by techniques from the document image field ([2]), pre-formatted tables (using the PRE) tag may be processed using plain text table methods ([5]). However, the classification problem extends to these cases and individual classifiers must be constructed to make decisions about document elements of each type. The remaining outstanding issues relate to the mixture of encoding types (e.g. tables built out of TABLE nodes and pre-formatted elements), as well as the mixture of encoding purposes (e.g. the use of the HTML TABLE to encode surrounding text as well as an embedded table). Figure 1. A web page using a mixture of HTML tables (on the left) and images of tables (on the right). recognition table recognition is the task of segmenting the original description of the table into a relative spatial description. In general this task is required when the input is low-level, such as a document image or an electronic text. Clearly, if such tables are found on a web page, the same process is required. Again, given certain assumptions, we can take the marked up tables in a web page to be the logical spatial table. However, there are certain issues that need to be understood in order to account for certain variations: internal cell structure though tags like TH and TD may be assumed to delimit a single cell in the table, there are cases where other non-table tags are used to provide internal structure in such a way as to associate the cell\u2019s contents with those of other cells. A solution would be required to apply a certain amount of recursive processing working into the structure and building a unified abstract table. split cells in order to gain more control over the distribution of the text in a cell, authors occasionally split the text and place it in two or more adjacent cells. This problem may be accommodated by exploiting linguistic process as described in [6] where the content of the cell can be used to indicate continuity, if any, to other cells. errors spanning errors occur when the COLSPAN or ROWSPAN values are not correctly calculated. There are two cases. In the first the cell spans beyond the border of the intended table giving the cell incorrect coordinates. In the second, the span of the cell does not communicate the correct meaning of the cell. For example, a cell that is intended to span three cells below it spans only one leading to ambiguity. The first type of problem may be repaired by some form of normalization, whereas the second requires intelligent processing in order to distinguish the following two cases:"
            },
            "slug": "Layout-and-Language:-Challenges-for-Table-on-the-Hurst",
            "title": {
                "fragments": [],
                "text": "Layout and Language: Challenges for Table Understanding on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The table understanding task is considered and a catalogue of particular issues that arise when the tables are those found on the web are presented and what happens when processes commonly associated with web pages are applied to those bearing tables is considered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145658132"
                        ],
                        "name": "David Pinto",
                        "slug": "David-Pinto",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876441"
                        ],
                        "name": "Xing Wei",
                        "slug": "Xing-Wei",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1092004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6991606a1a9d5c285af385ee9159fd46cc14048e",
            "isKey": false,
            "numCitedBy": 440,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to find tables and extract information from them is a necessary component of data mining, question answering, and other information retrieval tasks. Documents often contain tables in order to communicate densely packed, multi-dimensional information. Tables do this by employing layout patterns to efficiently indicate fields and records in two-dimensional form.Their rich combination of formatting and content present difficulties for traditional language modeling techniques, however. This paper presents the use of conditional random fields (CRFs) for table extraction, and compares them with hidden Markov models (HMMs). Unlike HMMs, CRFs support the use of many rich and overlapping layout and language features, and as a result, they perform significantly better. We show experimental results on plain-text government statistical reports in which tables are located with 92% F1, and their constituent lines are classified into 12 table-related categories with 94% accuracy. We also discuss future work on undirected graphical models for segmenting columns, finding cells, and classifying them as data cells or label cells."
            },
            "slug": "Table-extraction-using-conditional-random-fields-Pinto-McCallum",
            "title": {
                "fragments": [],
                "text": "Table extraction using conditional random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Unlike HMMs, CRFs support the use of many rich and overlapping layout and language features, and as a result, they perform significantly better, and are compared with hidden Markov models (HMMs)."
            },
            "venue": {
                "fragments": [],
                "text": "DG.O"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2857970"
                        ],
                        "name": "Gianluca Quercini",
                        "slug": "Gianluca-Quercini",
                        "structuredName": {
                            "firstName": "Gianluca",
                            "lastName": "Quercini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gianluca Quercini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762236"
                        ],
                        "name": "C. Reynaud",
                        "slug": "C.-Reynaud",
                        "structuredName": {
                            "firstName": "Chantal",
                            "lastName": "Reynaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Reynaud"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the literature, tables are annotated by precompiled catalogue of entities, types of relationships [18, 81, 85], LOD datasets [79] or ontologies [61]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In these approaches, missing entities annotation is done using text classifiers over snippets returned by search engines [18], using ITEM tool for extracting tables whose structure resembles the RDF knowledge base where new tuples are identified and stored in knowledge base [83] or using ITEM but not using the RDF knowledge base for detecting new entities in tables, Google Fusion Tables (GFT) [73]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The above-mentioned approaches present annotated tables using existing knowledge bases [80, 81], ontologies [61, 79] or information that is automatically extracted from web pages [85] and therefore annotate only those entities that are known, whereas annotating missing entities remains untouched Annotating messing entities that do not exist in reference catalogue is addressed by some researchers [18, 73, 83]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "GFT is a popular web application provided by Google that allows people, including those with no database expertise, to manage their data [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Tables present valuable information in a summarized and illustrated manner surrounded by words, symbols and other informative material inside text and thus need to be automatically detected for their searching and retrieval [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8252126,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0142141e5098532b3f3e380a3c36217b9797b87b",
            "isKey": true,
            "numCitedBy": 44,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The Web is rich of tables (e.g., HTML tables, spreadsheets, Google Fusion Tables) that host a considerable wealth of high-quality relational data. Unlike unstructured texts, tables usually favour the automatic extraction of data because of their regular structure and properties. The data extraction is usually complemented by the annotation of the table, which determines its semantics by identifying a type for each column, the relations between columns, if any, and the entities that occur in each cell.\n In this paper, we focus on the problem of discovering and annotating entities in tables. More specifically, we describe an algorithm that identifies the rows of a table that contain information on entities of specific types (e.g., restaurant, museum, theatre) derived from an ontology and determines the cells in which the names of those entities occur. We implemented this algorithm while developing a faceted browser over a repository of RDF data on points of interest of cities that we extracted from Google Fusion Tables.\n We claim that our algorithm complements the existing approaches, which annotate entities in a table based on a pre-compiled reference catalogue that lists the types of a finite set of entities; as a result, they are unable to discover and annotate entities that do not belong to the reference catalogue. Instead, we train our algorithm to look for information on previously unseen entities on the Web so as to annotate them with the correct type."
            },
            "slug": "Entity-discovery-and-annotation-in-tables-Quercini-Reynaud",
            "title": {
                "fragments": [],
                "text": "Entity discovery and annotation in tables"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm is described that identifies the rows of a table that contain information on entities of specific types derived from an ontology and determines the cells in which the names of those entities occur and is trained to look for information on previously unseen entities on the Web so as to annotate them with the correct type."
            },
            "venue": {
                "fragments": [],
                "text": "EDBT '13"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689847"
                        ],
                        "name": "Jean-Yves Ramel",
                        "slug": "Jean-Yves-Ramel",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Ramel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Ramel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719698"
                        ],
                        "name": "M. Crucianu",
                        "slug": "M.-Crucianu",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Crucianu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Crucianu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145645182"
                        ],
                        "name": "N. Vincent",
                        "slug": "N.-Vincent",
                        "structuredName": {
                            "firstName": "Nicole",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38138508"
                        ],
                        "name": "C. Faure",
                        "slug": "C.-Faure",
                        "structuredName": {
                            "firstName": "Claudie",
                            "lastName": "Faure",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faure"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18293386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "275d79256336a53141e6602d5fdf736139e90b8f",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We are concerned with the extraction of tables from exchange format representations of very diverse composite documents. We put forward a flexible representation scheme for complex tables, based on a clear distinction between the physical layout of a table and its logical structure. Relying on this scheme, we develop a new method for the detection and the extraction of tables by an analysis of the graphic lines. To deal with tables that lack all or most of the graphic marks, one must focus on the regularities of the text elements alone. We propose such a method, based on a multi-level analysis of the layout of text components on a page. A general graph representation of the relative positions of blocks of text is exploited."
            },
            "slug": "Detection,-extraction-and-representation-of-tables-Ramel-Crucianu",
            "title": {
                "fragments": [],
                "text": "Detection, extraction and representation of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A flexible representation scheme for complex tables is put forward, based on a clear distinction between the physical layout of a table and its logical structure, and a new method for the detection and the extraction of tables by an analysis of the graphic lines is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2632608"
                        ],
                        "name": "B. Yildiz",
                        "slug": "B.-Yildiz",
                        "structuredName": {
                            "firstName": "Burcu",
                            "lastName": "Yildiz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yildiz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804028"
                        ],
                        "name": "K. Kaiser",
                        "slug": "K.-Kaiser",
                        "structuredName": {
                            "firstName": "Katharina",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692521"
                        ],
                        "name": "S. Miksch",
                        "slug": "S.-Miksch",
                        "structuredName": {
                            "firstName": "Silvia",
                            "lastName": "Miksch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Miksch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "carried out the first relative research on PDF for tables [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, very little work has been carried out on such formats [21, 48, 58, 60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Some research works used heuristics-based techniques for table detection [23, 27, 29, 31, 33, 36, 38, 41, 42, 48, 52\u201361]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, detected multiline blocks that may belong to the same table are merged [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17242556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5dc08add84ef4070b00c2b43dac037bcfd6df460",
            "isKey": true,
            "numCitedBy": 100,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are a common structuring element in many documents, such as PDF files. To reuse such tables, appropriate methods need to be develop, which capture the structure and the content information. We have developed several heuristics which together recognize and decompose tables in PDF files and store the extracted data in a structured data format (XML) for easier reuse. Additionally, we implemented a prototype, which gives the user the ability of making adjustments on the extracted data. Our work shows that purely heuristic-based approaches can achieve good results, especially for lucid tables."
            },
            "slug": "pdf2table:-A-Method-to-Extract-Table-Information-Yildiz-Kaiser",
            "title": {
                "fragments": [],
                "text": "pdf2table: A Method to Extract Table Information from PDF Files"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work developed several heuristics which together recognize and decompose tables in PDF files and store the extracted data in a structured data format (XML) for easier reuse and shows that purely heuristic-based approaches can achieve good results, especially for lucid tables."
            },
            "venue": {
                "fragments": [],
                "text": "IICAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5481713,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ba28bb5c79f9115b3f3b62593feedf1d73b3027",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis looks at the issues relating to the development of technology capable of processing tables as they appear in textual documents so that their contents may be accessed and further interpreted by standard information extraction and natural language processing systems. The thesis offers a formal description of the table and the description and evaluation of a system which provides instances of that model for table examples. There are three parts to the thesis. The first looks at tables in general terms, suggests where their complexities are to be found, and reviews the literature dealing with research into tables in other fields. The second part introduces a layered model of the table and provides some notational equipment for encoding tables in these component layers. The final part discusses the design, implementation and evaluation of a system which produces an instance of the model for the tables found in a document. It also discusses the design and collection of a corpus of tables used for the training and evaluation of the system. The thesis catalogues a laxge number of phenomena discovered in the corpus collected during the research and provides appropriate terminology."
            },
            "slug": "The-interpretation-of-tables-in-texts-Hurst",
            "title": {
                "fragments": [],
                "text": "The interpretation of tables in texts"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This thesis looks at the issues relating to the development of technology capable of processing tables as they appear in textual documents so that their contents may be accessed and further interpreted by standard information extraction and natural language processing systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49915337"
                        ],
                        "name": "A. C. E. Silva",
                        "slug": "A.-C.-E.-Silva",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Silva",
                            "middleNames": [
                                "Costa",
                                "e"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. C. E. Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772839"
                        ],
                        "name": "A. Jorge",
                        "slug": "A.-Jorge",
                        "structuredName": {
                            "firstName": "Al\u00edpio",
                            "lastName": "Jorge",
                            "middleNames": [
                                "M\u00e1rio"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jorge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66444903"
                        ],
                        "name": "L. Torgo",
                        "slug": "L.-Torgo",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Torgo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Torgo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15425019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7f1c7ab6bb331944c0667b3ab75cba46021db1a",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper plans an end-to-end method for extracting information from tables embedded in documents; input format is ASCII, to which any richer format can be converted, preserving all textual and much of the layout information. We start by defining table. Then we describe the steps involved in extracting information from tables and analyse table-related research to place the contribution of different authors, find the paths research is following, and identify issues that are still unsolved. We then analyse current approaches to evaluating table processing algorithms and propose two new metrics for the task of segmenting cells/columns/rows. We proceed to design our own end-to-end method, where there is a higher interaction between different steps; we indicate how back loops in the usual order of the steps can reduce the possibility of errors and contribute to solving previously unsolved problems. Finally, we explore how the actual interpretation of the table not only allows inferring the accuracy of the overall extraction process but also contributes to actually improving its quality. In order to do so, we believe interpretation has to consider context-specific knowledge; we explore how the addition of this knowledge can be made in a plug-in/out manner, such that the overall method will maintain its operability in different contexts."
            },
            "slug": "Design-of-an-end-to-end-method-to-extract-from-Silva-Jorge",
            "title": {
                "fragments": [],
                "text": "Design of an end-to-end method to extract information from tables"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper plans an end-to-end method for extracting information from tables embedded in documents; input format is ASCII, to which any richer format can be converted, preserving all textual and much of the layout information."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144531841"
                        ],
                        "name": "Saleh A. Alrashed",
                        "slug": "Saleh-A.-Alrashed",
                        "structuredName": {
                            "firstName": "Saleh",
                            "lastName": "Alrashed",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saleh A. Alrashed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Sometimes entities are context-dependent and can be annotated with surrounding text using domain ontology [119]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13391709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fddf90d5e553e5882ed4fba6231668e6c5d12c87",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Combining data from different sources for further automatic processing is often hindered by differences in the underlying semantics and representation. Therefore when linking information presented in documents in tabular form with data held in databases, it is important to determine as much information about the table and its content. Important information about the table data is often given in the text surrounding the table in that document. The table's creators cannot clarify all the semantics in the table itself therefore they use the table context or the text around it to give further information. These semantics are very useful when integrating and using this data, but are often difficult to detect automatically. We propose a solution to part of this problem based on a domain ontology. The input to our system is a document that contains tabular data and the system aims to find semantics in the document that are related to the tabular data. The output of our system is a set of detected semantics linked to the corresponding table. The system uses elements of semantic detection, semantic representation, and data integration. In this paper, we discuss the experiment used to evaluate the prototype system. We also discuss the different types of test, the experiment will perform. After using the system with the test data and gathering the results of these tests, we show the significant results in our experiment."
            },
            "slug": "Finding-hidden-semantics-of-text-tables-Alrashed",
            "title": {
                "fragments": [],
                "text": "Finding hidden semantics of text tables"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper discusses the experiment used to evaluate the prototype system, and uses the system with the test data and gathering the results of these tests, to show the significant results in the experiment."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30699745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5cd207fa19e51db1d6eadb0e5e70f1c5b8d1ecd0",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are the only acceptable means of communicating certain types of structured data. A precise definition of \"tabularity\" remains elusive because some bureaucratic forms, multicolumn text layouts, and schematic drawings share many characteristics of tables. There are significant differences between typeset tables, electronic files designed for display of tables, and tables in symbolic form intended for information retrieval. Although most research to date has addressed the extraction of low-level geometric information from scanned raster images of paper tables, the recent trend toward the analysis of tables in electronic form may pave the way to a higherl evel of table understanding. \n \nRecent research on table composition and table analysis has improved ourunde rstanding of the distinction between the logical and physical structures of tables, and has led to improved formalisms for modeling tables. The present study indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display. \n \nAlthough tables are not a conventional format for conveying the primary content of technical papers, here we attempt to subdue our natural garrulity by adopting this genre to communicate what we have to say about tables entirely in tabular form."
            },
            "slug": "A-Tabular-Survey-of-Automated-Table-Processing-Lopresti-Nagy",
            "title": {
                "fragments": [],
                "text": "A Tabular Survey of Automated Table Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The present study indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2494216"
                        ],
                        "name": "P. Pyreddy",
                        "slug": "P.-Pyreddy",
                        "structuredName": {
                            "firstName": "Pallavi",
                            "lastName": "Pyreddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pyreddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This system indexes and searches tables [27]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Some research works used heuristics-based techniques for table detection [23, 27, 29, 31, 33, 36, 38, 41, 42, 48, 52\u201361]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13991200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d674f1289f336d88c4ab93e7204a345a302ed2eb",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables form an important kind of data element in text retrieval. Often, the gist of an entire news article or other exposition can be concisely captured in tabular form. In this paper, we examine the utility of exploiting information other than the key words in a digital document to provide the users with more flexible and powerful query capabilities. More specifically, we exploit the structural information in a document to identify tables and their component fields and let the users query based on these fields. Our empirical results have demonstrated that heuristic method based table extraction and component tagging can be performed effectively and efficiently. Moreover, our experiments in retrieval using the TINTIN system have strongly indicated that such structural decomposition can facilitate better representation of user\u2019s information needs and hence more effective retrieval of tables."
            },
            "slug": "TINTIN:-a-system-for-retrieval-in-text-tables-Pyreddy-Croft",
            "title": {
                "fragments": [],
                "text": "TINTIN: a system for retrieval in text tables"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper examines the utility of exploiting information other than the key words in a digital document to provide the users with more flexible and powerful query capabilities and demonstrates that heuristic method based table extraction and component tagging can be performed effectively and efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "DL '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115379063"
                        ],
                        "name": "Jing Fang",
                        "slug": "Jing-Fang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777642"
                        ],
                        "name": "Liangcai Gao",
                        "slug": "Liangcai-Gao",
                        "structuredName": {
                            "firstName": "Liangcai",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liangcai Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064776984"
                        ],
                        "name": "Kun Bai",
                        "slug": "Kun-Bai",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29035564"
                        ],
                        "name": "Ruiheng Qiu",
                        "slug": "Ruiheng-Qiu",
                        "structuredName": {
                            "firstName": "Ruiheng",
                            "lastName": "Qiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruiheng Qiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070898875"
                        ],
                        "name": "Xin Tao",
                        "slug": "Xin-Tao",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087321561"
                        ],
                        "name": "Zhi Tang",
                        "slug": "Zhi-Tang",
                        "structuredName": {
                            "firstName": "Zhi",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi Tang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10738490,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1839a3dc008765457f434ad6920fb28bbe669a92",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Table detection is always an important task of document analysis and recognition. In this paper, we propose a novel and effective table detection method via visual separators and geometric content layout information, targeting at PDF documents. The visual separators refer to not only the graphic ruling lines but also the white spaces to handle tables with or without ruling lines. Furthermore, we detect page columns in order to assist table region delimitation in complex layout pages. Evaluations of our algorithm on an e-Book dataset and a scientific document dataset show competitive performance. It is noteworthy that the proposed method has been successfully incorporated into a commercial software package for large-scale Chinese e-Book production."
            },
            "slug": "A-Table-Detection-Method-for-Multipage-PDF-via-and-Fang-Gao",
            "title": {
                "fragments": [],
                "text": "A Table Detection Method for Multipage PDF Documents via Visual Seperators and Tabular Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A novel and effective table detection method via visual separators and geometric content layout information, targeting at PDF documents is proposed, successfully incorporated into a commercial software package for large-scale Chinese e-Book production."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3200914"
                        ],
                        "name": "Asif Shahab",
                        "slug": "Asif-Shahab",
                        "structuredName": {
                            "firstName": "Asif",
                            "lastName": "Shahab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Asif Shahab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "propose a colour-encoding-based evaluation method [73]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The Silva dataset is composed of 22 PDF financial statements [73]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In these approaches, missing entities annotation is done using text classifiers over snippets returned by search engines [18], using ITEM tool for extracting tables whose structure resembles the RDF knowledge base where new tuples are identified and stored in knowledge base [83] or using ITEM but not using the RDF knowledge base for detecting new entities in tables, Google Fusion Tables (GFT) [73]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The above-mentioned approaches present annotated tables using existing knowledge bases [80, 81], ontologies [61, 79] or information that is automatically extracted from web pages [85] and therefore annotate only those entities that are known, whereas annotating missing entities remains untouched Annotating messing entities that do not exist in reference catalogue is addressed by some researchers [18, 73, 83]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In this regard, one approach can be the use of a catalogue, but entities not present in the catalogue cannot be identified [73]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16140787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bff7592f28354b3be632f4bf678b622f765a2b8d",
            "isKey": true,
            "numCitedBy": 63,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Table spotting and structural analysis are just a small fraction of tasks relevant when speaking of table analysis. Today, quite a large number of different approaches facing these tasks have been described in literature or are available as part of commercial OCR systems that claim to deal with tables on the scanned documents and to treat them accordingly.\n However, the problem of detecting tables is not yet solved at all. Different approaches have different strengths and weak points. Some fail in certain situations or layouts where others perform better. How shall one know, which approach or system is the best for his specific job? The answer to this question raises the demand for an objective comparison of different approaches which address the same task of spotting tables and recognizing their structure.\n This paper describes our approach towards establishing a complete and publicly available, hence open environment for the benchmarking of table spotting and structural analysis. We provide free access to the ground truthing tool and evaluation mechanism described in this paper, describe the ideas behind and we also provide ground truth for the 547 documents of the UNLV and UW-3 datasets that contain tables.\n In addition, we applied the quality measures to the results that were generated by the T-Recs system which we developed some years ago and which we started to further advance since a few months."
            },
            "slug": "An-open-approach-towards-the-benchmarking-of-table-Shahab-Shafait",
            "title": {
                "fragments": [],
                "text": "An open approach towards the benchmarking of table structure recognition systems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The approach towards establishing a complete and publicly available, hence open environment for the benchmarking of table spotting and structural analysis is described and free access to the ground truthing tool and evaluation mechanism described is provided."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047516905"
                        ],
                        "name": "Max C. G\u00f6bel",
                        "slug": "Max-C.-G\u00f6bel",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "G\u00f6bel",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Max C. G\u00f6bel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "18592170"
                        ],
                        "name": "Tamir Hassan",
                        "slug": "Tamir-Hassan",
                        "structuredName": {
                            "firstName": "Tamir",
                            "lastName": "Hassan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamir Hassan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759801"
                        ],
                        "name": "Ermelinda Oro",
                        "slug": "Ermelinda-Oro",
                        "structuredName": {
                            "firstName": "Ermelinda",
                            "lastName": "Oro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ermelinda Oro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35203250"
                        ],
                        "name": "G. Orsi",
                        "slug": "G.-Orsi",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Orsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orsi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3223096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f79cfbecadb5c7cce7618ea4cff65f5e941f8951",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a methodology for the evaluation of table understanding algorithms for PDF documents. The evaluation takes into account three major tasks: table detection, table structure recognition and functional analysis. We provide a general and flexible output model for each task along with corresponding evaluation metrics and methods. We also present a methodology for collecting and ground-truthing PDF documents based on consensus-reaching principles and provide a publicly available ground-truthed dataset."
            },
            "slug": "A-methodology-for-evaluating-algorithms-for-table-G\u00f6bel-Hassan",
            "title": {
                "fragments": [],
                "text": "A methodology for evaluating algorithms for table understanding in PDF documents"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The evaluation takes into account three major tasks: table detection, table structure recognition and functional analysis and provides a general and flexible output model for each task along with corresponding evaluation metrics and methods."
            },
            "venue": {
                "fragments": [],
                "text": "DocEng '12"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153821949"
                        ],
                        "name": "Girija Limaye",
                        "slug": "Girija-Limaye",
                        "structuredName": {
                            "firstName": "Girija",
                            "lastName": "Limaye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Girija Limaye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770124"
                        ],
                        "name": "Sunita Sarawagi",
                        "slug": "Sunita-Sarawagi",
                        "structuredName": {
                            "firstName": "Sunita",
                            "lastName": "Sarawagi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sunita Sarawagi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40941894"
                        ],
                        "name": "Soumen Chakrabarti",
                        "slug": "Soumen-Chakrabarti",
                        "structuredName": {
                            "firstName": "Soumen",
                            "lastName": "Chakrabarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumen Chakrabarti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The dataset used in this approach is the Wiki manual, which is publicly available [79]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[79], that is, the best class label (or relation) is one that maximizes the probability of values given by class label (or relation) for the column."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In the literature, tables are annotated by precompiled catalogue of entities, types of relationships [18, 81, 85], LOD datasets [79] or ontologies [61]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The above-mentioned approaches present annotated tables using existing knowledge bases [80, 81], ontologies [61, 79] or information that is automatically extracted from web pages [85] and therefore annotate only those entities that are known, whereas annotating missing entities remains untouched Annotating messing entities that do not exist in reference catalogue is addressed by some researchers [18, 73, 83]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9262964,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53f5249ff2dc66a7a8a3ccabca24911e932a98b4",
            "isKey": true,
            "numCitedBy": 388,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are a universal idiom to present relational data. Billions of tables on Web pages express entity references, attributes and relationships. This representation of relational world knowledge is usually considerably better than completely unstructured, free-format text. At the same time, unlike manually-created knowledge bases, relational information mined from \"organic\" Web tables need not be constrained by availability of precious editorial time. Unfortunately, in the absence of any formal, uniform schema imposed on Web tables, Web search cannot take advantage of these high-quality sources of relational information. In this paper we propose new machine learning techniques to annotate table cells with entities that they likely mention, table columns with types from which entities are drawn for cells in the column, and relations that pairs of table columns seek to express. We propose a new graphical model for making all these labeling decisions for each table simultaneously, rather than make separate local decisions for entities, types and relations. Experiments using the YAGO catalog, DB-Pedia, tables from Wikipedia, and over 25 million HTML tables from a 500 million page Web crawl uniformly show the superiority of our approach. We also evaluate the impact of better annotations on a prototype relational Web search tool. We demonstrate clear benefits of our annotations beyond indexing tables in a purely textual manner."
            },
            "slug": "Annotating-and-searching-web-tables-using-entities,-Limaye-Sarawagi",
            "title": {
                "fragments": [],
                "text": "Annotating and searching web tables using entities, types and relationships"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes new machine learning techniques to annotate table cells with entities that they likely mention, table columns with types from which entities are drawn for cells in the column, and relations that pairs of table columns seek to express, and a new graphical model for making all these labeling decisions for each table simultaneously."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540194"
                        ],
                        "name": "R. Mohemad",
                        "slug": "R.-Mohemad",
                        "structuredName": {
                            "firstName": "Rosmayati",
                            "lastName": "Mohemad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohemad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114936300"
                        ],
                        "name": "Zulaiha Ali Othman Noor MaizuraMohamad Noor Abdul Razak Hamdan",
                        "slug": "Zulaiha-Ali-Othman-Noor-MaizuraMohamad-Noor-Abdul",
                        "structuredName": {
                            "firstName": "Zulaiha",
                            "lastName": "Abdul Razak Hamdan",
                            "middleNames": [
                                "Ali",
                                "Othman",
                                "Noor",
                                "MaizuraMohamad",
                                "Noor"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zulaiha Ali Othman Noor MaizuraMohamad Noor Abdul Razak Hamdan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[50], which presents a typical work based on a predefined table layout structure for text, then associates text using a combination of heuristics-based, rule-based and predefined layout approaches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Limitations of this technique include the use of a predefined threshold for calculating distance between text elements as this can produce wrong results because of wrong clusters owing to the combination of dissimilar text parts [50]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13242204,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "473941e27a6c70c2db43f08a714a1f36ee7ff78e",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Nowadays, government agencies, business corporate companies and personal individual disseminate their electronic documents in Portable Document Format (PDF) as the quickest and convenient way to publish information including text, tables and graphical images. In the survey conducted by Association of Information and Image Management (AIIM) in 2008, 90% of 200 member organizations stored information in PDF either by scanning the documents or converting from Microsoft Office files to PDFbased format and it is predicted the use of PDF fluctuates to 93% for the next five years [1]. Various types of digital documents either newspapers, catalogues, reports, magazines, articles and even forms are available in PDF since the technology is good at offering open standard feature in which it is platform independent for sharing, archiving, retrieving and printing electronic document. Despite of it benefits, PDF has drawback in terms of content and structure analysis. As the result, information represented in PDF format is inconvenient for people to retrieve and reuse in other applications automatically, for example decisionmaking applications and office automation systems, which requires International Journal on New Computer Architectures and Their Applications (IJNCAA) 1(2): 404-411 The Society of Digital Information and Wireless Communications, 2011 (ISSN: 2220-9085)"
            },
            "slug": "AUTOMATIC-DOCUMENT-STRUCTURE-ANALYSIS-OF-STRUCTURED-Mohemad-Hamdan",
            "title": {
                "fragments": [],
                "text": "AUTOMATIC DOCUMENT STRUCTURE ANALYSIS OF STRUCTURED PDF FILES"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145723023"
                        ],
                        "name": "C. Tao",
                        "slug": "C.-Tao",
                        "structuredName": {
                            "firstName": "Cui",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742211"
                        ],
                        "name": "Stephen W. Liddle",
                        "slug": "Stephen-W.-Liddle",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Liddle",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen W. Liddle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "They claim that by changing the context ontology they can adapt to any context [62]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5406402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b777c808a71ed4bd8c9da4f1a2475110b15d23f7",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automating-the-extraction-of-data-from-HTML-tables-Embley-Tao",
            "title": {
                "fragments": [],
                "text": "Automating the extraction of data from HTML tables with unknown structure"
            },
            "venue": {
                "fragments": [],
                "text": "Data Knowl. Eng."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805399"
                        ],
                        "name": "Varish Mulwad",
                        "slug": "Varish-Mulwad",
                        "structuredName": {
                            "firstName": "Varish",
                            "lastName": "Mulwad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Varish Mulwad"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61786096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "527d0ebe7c65f03249ca3ce5a996bbd36b2a3760",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an automatic framework for extracting, interpreting and generating linked data from tables. In the process of representing tables as linked data, we assign every column header a class label from an appropriate ontology, link table cells (if appropriate) to an entity from the Linked Open Data cloud and identify relations between various columns in the table, which helps us to build an overall interpretation of the table. Using the limited evidence provided by a table in the form of table headers and table data in rows and columns, we adopt a novel approach of querying existing knowledge bases such as Wikitology, DBpedia etc. to figure the class labels for table headers. In the process of entity linking, besides querying knowledgebases, we use machine learning algorithms like support vector machine and algorithms which can learn to rank entities within a given set to link a table cell to entity. We further use the class labels, linked entities and information from the knowledge bases to identify relations between columns. We prototyped a system to evaluate our approach against tables obtained from Google Squared, Wikipedia and set of tables obtained from a dataset which Google shared with us."
            },
            "slug": "T2LD-An-automatic-framework-for-extracting,-and-as-Mulwad",
            "title": {
                "fragments": [],
                "text": "T2LD - An automatic framework for extracting, interpreting and representing tables as Linked Data"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "An automatic framework for extracting, interpreting and generating linked data from tables, which uses machine learning algorithms like support vector machine and algorithms which can learn to rank entities within a given set to link a table cell to entity."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000882"
                        ],
                        "name": "Wolfgang Gatterbauer",
                        "slug": "Wolfgang-Gatterbauer",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Gatterbauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Gatterbauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308385"
                        ],
                        "name": "Paul Bohunsky",
                        "slug": "Paul-Bohunsky",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Bohunsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Bohunsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153481005"
                        ],
                        "name": "M. Herzog",
                        "slug": "M.-Herzog",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Herzog",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Herzog"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738409"
                        ],
                        "name": "Bernhard Kr\u00fcpl",
                        "slug": "Bernhard-Kr\u00fcpl",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Kr\u00fcpl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernhard Kr\u00fcpl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36806626"
                        ],
                        "name": "B. Pollak",
                        "slug": "B.-Pollak",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Pollak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Pollak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17356112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95c9961c73db64837fd6b8dbda2f0b246fed6812",
            "isKey": false,
            "numCitedBy": 245,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditionally, information extraction from web tables has focused on small, more or less homogeneous corpora, often based on assumptions about the use of <table> tags. A multitude of different HTML implementations of web tables make these approaches difficult to scale. In this paper, we approach the problem of domain-independent information extraction from web tables by shifting our attention from the tree-based representation of webpages to a variation of the two-dimensional visual box model used by web browsers to display the information on the screen. The there by obtained topological and style information allows us to fill the gap created by missing domain-specific knowledge about content and table templates. We believe that, in a future step, this approach can become the basis for a new way of large-scale knowledge acquisition from the current \"Visual Web."
            },
            "slug": "Towards-domain-independent-information-extraction-Gatterbauer-Bohunsky",
            "title": {
                "fragments": [],
                "text": "Towards domain-independent information extraction from web tables"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper shifts attention from the tree-based representation of webpages to a variation of the two-dimensional visual box model used by web browsers to display the information on the screen and believes that this approach can become the basis for a new way of large-scale knowledge acquisition from the current \"Visual Web\"."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3155627"
                        ],
                        "name": "Deliang Jiang",
                        "slug": "Deliang-Jiang",
                        "structuredName": {
                            "firstName": "Deliang",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deliang Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809356"
                        ],
                        "name": "Xiaohu Yang",
                        "slug": "Xiaohu-Yang",
                        "structuredName": {
                            "firstName": "Xiaohu",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaohu Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1756387,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2d4ce856b8e5d5ae017fd1c3e9ac078d0f41dc6",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Converting PDF document to HTML document with the same layout format is a very important and interesting research problem. After the conversion, it is easy for PDF document to be browsed online and information extracted. Based on the extraction result of the PDF document of the open source tool PDFBox, the paper described a method that can detect the layout information of the PDF document and convert the PDF document to HTML page effectively."
            },
            "slug": "Converting-PDF-to-HTML-approach-based-on-text-Jiang-Yang",
            "title": {
                "fragments": [],
                "text": "Converting PDF to HTML approach based on text detection"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Based on the extraction result of the PDF document of the open source tool PDFBox, the paper described a method that can detect the layout information of thepdf document and convert thePDF document to HTML page effectively."
            },
            "venue": {
                "fragments": [],
                "text": "ICIS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688230"
                        ],
                        "name": "Venkatesh Ganti",
                        "slug": "Venkatesh-Ganti",
                        "structuredName": {
                            "firstName": "Venkatesh",
                            "lastName": "Ganti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Venkatesh Ganti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31602559"
                        ],
                        "name": "A. K\u00f6nig",
                        "slug": "A.-K\u00f6nig",
                        "structuredName": {
                            "firstName": "Arnd",
                            "lastName": "K\u00f6nig",
                            "middleNames": [
                                "Christian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. K\u00f6nig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804102"
                        ],
                        "name": "R. Vernica",
                        "slug": "R.-Vernica",
                        "structuredName": {
                            "firstName": "Rares",
                            "lastName": "Vernica",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vernica"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Sometimes entity annotation needs semantic enrichment from external knowledge resources [69, 70]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Few research works pay attention to the use of statistical approaches for table detection, including probabilistic modelling [40], the Naive Bayes classifier [44, 52, 57, 61, 66], the Maximum Entropy Classifier [34, 44], decision trees [40, 44, 45, 68], Support Vector Machine [45, 51, 59, 65], the Winnow classifier [44], Conditional Random Fields [33, 34, 51, 59, 67] and an HMM of the traditional sort [70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 834396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82368f102ce6f389a45566961d756c70097642a3",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Extracting entities (such as people, movies) from documents and identifying the categories (such as painter, writer) they belong to enable structured querying and data analysis over unstructured document collections. In this paper, we focus on the problem of categorizing extracted entities. Most prior approaches developed for this task only analyzed the local document context within which entities occur. In this paper, we significantly improve the accuracy of entity categorization by (i) considering an entity's context across multiple documents containing it, and (ii) exploiting existing large lists of related entities (e.g., lists of actors, directors, books). These approaches introduce computational challenges because (a) the context of entities has to be aggregated across several documents and (b) the lists of related entities may be very large. We develop techniques to address these challenges. We present a thorough experimental study on real data sets that demonstrates the increase in accuracy and the scalability of our approaches."
            },
            "slug": "Entity-categorization-over-large-document-Ganti-K\u00f6nig",
            "title": {
                "fragments": [],
                "text": "Entity categorization over large document collections"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work significantly improves the accuracy of entity categorization by considering an entity's context across multiple documents containing it, and exploiting existing large lists of related entities (e.g., lists of actors, directors, books)."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35155791"
                        ],
                        "name": "William A. Kornfeld",
                        "slug": "William-A.-Kornfeld",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Kornfeld",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William A. Kornfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152697317"
                        ],
                        "name": "J. Wattecamps",
                        "slug": "J.-Wattecamps",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wattecamps",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wattecamps"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This tree is then compared word by word with a manually built collection of all possible alternatives to name the concepts they wish to extract [23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Some commonly used words in table processing are detection, extraction [9, 23], interpretation [9] and understanding [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Some research works used heuristics-based techniques for table detection [23, 27, 29, 31, 33, 36, 38, 41, 42, 48, 52\u201361]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10974046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "675519b637ca69534a7ffd8829f05ce774885e26",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Information retrieval of ASCLI documents generally refers to retrieval based on linear patterns found in the source documents. We have developed a method for recognizing and extracting tabular data, inthis case financial tables. Tables are extracted using a version of the LR(k) parsing algorithm adapted for this purpose. Because of sloppiness in the construction of tables, somewhat less than 100% of the tables can be retrieved automatically; a method has been found to integrate the parsing algorithm into amodule analogous to a programming language debugger that allows operators to quickly correct defects in the source document. This paper describes an application in commercial use."
            },
            "slug": "Automatically-locating,-extracting-and-analyzing-Kornfeld-Wattecamps",
            "title": {
                "fragments": [],
                "text": "Automatically locating, extracting and analyzing tabular data"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A method has been found to integrate the parsing algorithm into amodule analogous to a programming language debugger that allows operators to quickly correct defects in the source document."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2454221,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1d9629cd4fdfba3211f1ebdf8582c60ddf23584",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The shift of interest to web tables in HTML and PDF files, coupled with the incorporation of table analysis and conversion routines in commercial desktop document processing software, are likely to turn table recognition into more of a systems than an algorithmic issue. We illustrate the transition by some actual examples of web table conversion. We then suggest that the appropriate target format for table analysis, whether performed by conventional customized programs or by off-the-shelf software, is a representation based on the abstract table introduced by X. Wang in 1996. We show that the Wang model is adequate for some useful tasks that prove elusive for less explicit representations, and outline our plans to develop a semi-automated table processing system to demonstrate this approach. Screen-snaphots of a prototype tool to allow table mark-up in the style of Wang are also presented."
            },
            "slug": "Notes-on-Contemporary-Table-Recognition-Embley-Lopresti",
            "title": {
                "fragments": [],
                "text": "Notes on Contemporary Table Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is suggested that the appropriate target format for table analysis, whether performed by conventional customized programs or by off-the-shelf software, is a representation based on the abstract table introduced by X. Wang in 1996."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34996245"
                        ],
                        "name": "B. Klein",
                        "slug": "B.-Klein",
                        "structuredName": {
                            "firstName": "Bertin",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2602600"
                        ],
                        "name": "Serdar G\u00f6kkus",
                        "slug": "Serdar-G\u00f6kkus",
                        "structuredName": {
                            "firstName": "Serdar",
                            "lastName": "G\u00f6kkus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serdar G\u00f6kkus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some research works used heuristics-based techniques for table detection [23, 27, 29, 31, 33, 36, 38, 41, 42, 48, 52\u201361]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42252433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea049d0fc3995977b52c10be08fc288789b86ac1",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces three approaches for an industrial, comprehensive document analysis system to enable it to spot tables in documents. Searching for a set of known table headers (approach 1) works rather well in a significant number of documents. But this approach (though it is implemented tolerant to OCR errors) is not tolerant enough towards some kinds of even minor aberrations. This not only decreases the recognition results, but also, even worse, makes users feel uncomfortable. Pragmatically trying to mimic for what the human eyes might key, leads to our two further, complementary approaches: searching for layout structures which resemble parts of columns (approach 2), and searching for groupings of similar lines (approach 3). The suitability of the approaches for our system requires them to be very simple to implement and simple to explain to users, computationally cheap, and combinable. In the domain of health insurances who receive huge amounts of so called medical liquidations on a daily basis we obtain very good results. On document samples representative for the every day practice of five customers-health insurance companies-tables were spotted as good and as fast as the customers expected the system to be. We thus consider our current approaches as a step towards cognitive adequacy."
            },
            "slug": "Three-approaches-to-\"industrial\"-table-spotting-Klein-G\u00f6kkus",
            "title": {
                "fragments": [],
                "text": "Three approaches to \"industrial\" table spotting"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This paper introduces three approaches for an industrial, comprehensive document analysis system to enable it to spot tables in documents, and considers the current approaches as a step towards cognitive adequacy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Wang uses table ground truth and develops a tool for generating table element-containing documents [95]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 628973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd7e243fb7041c582a479116a11126904f2be010",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We first describe an automatic table ground truth generation system which can efficiently generate a large amount of accurate table ground truth suitable for the development of table detection algorithms. Then a novel background analysis-based, coarse-to-fine table identification algorithm and an X-Y cut table decomposition algorithm are described. We discuss an experimental protocol to evaluate the table detection algorithms. For a total of 1,125 document pages having 518 table entities and a total of 10,941 cell entities, our table detection algorithm takes line, word segmentation results as input and obtains around 90% cell correct detection rates."
            },
            "slug": "Automatic-table-ground-truth-generation-and-a-table-Wang-Haralick",
            "title": {
                "fragments": [],
                "text": "Automatic table ground truth generation and a background-analysis-based table structure extraction method"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "An automatic table groundtruth generation system which can efficiently generate a large amount of accurate table ground truth suitable for the development of table detection algorithms and an X-Y cut table decomposition algorithm are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "collected 26 Wall Street Journal articles and email messages as a dataset [110]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "address an edit-distance-based measurement [110]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7630958,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af42cc46f93bc9cf413770af4f7243f54a31336e",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. While techniques for evaluating the performance of lower-level document analysis tasks such as optical character recognition have gained acceptance in the literature, attempts to formalize the problem for higher-level algorithms, while receiving a fair amount of attention in terms of theory, have generally been less successful in practice, perhaps owing to their complexity. In this paper, we introduce intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition. We also present the results of several small experiments, demonstrating how well the methodologies work and the useful sorts of feedback they provide. We first consider the table detection problem. Here algorithms can yield various classes of errors, including non-table regions improperly labeled as tables (insertion errors), tables missed completely (deletion errors), larger tables broken into a number of smaller ones (splitting errors), and groups of smaller tables combined to form larger ones (merging errors). This leads naturally to the use of an edit distance approach for assessing the results of table detection. Next we address the problem of evaluating table structure recognition. Our model is based on a directed acyclic attribute graph, or table DAG. We describe a new paradigm, \u201cgraph probing,\u201d for comparing the results returned by the recognition system and the representation created during ground-truthing. Probing is in fact a general concept that could be applied to other document recognition tasks as well."
            },
            "slug": "Evaluating-the-performance-of-table-processing-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Evaluating the performance of table processing algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition are introduced and a new paradigm, \u201cgraph probing,\u201d is described for comparing the results returned by the recognition system and the representation created during ground-truthing."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595112"
                        ],
                        "name": "Sekhar Mandal",
                        "slug": "Sekhar-Mandal",
                        "structuredName": {
                            "firstName": "Sekhar",
                            "lastName": "Mandal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sekhar Mandal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105636642"
                        ],
                        "name": "S. Chowdhury",
                        "slug": "S.-Chowdhury",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Chowdhury",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chowdhury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152167018"
                        ],
                        "name": "Amit Kumar Das",
                        "slug": "Amit-Kumar-Das",
                        "structuredName": {
                            "firstName": "Amit Kumar",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amit Kumar Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784810"
                        ],
                        "name": "B. Chanda",
                        "slug": "B.-Chanda",
                        "structuredName": {
                            "firstName": "Bhabatosh",
                            "lastName": "Chanda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Chanda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27098537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86a11c997be11cc9ea43ae018d7970c9257be1eb",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The requirement of detection and identification of tables from document images is crucial to any document image analysis and digital library system. In this paper we report a very simple but extremely powerful approach to detect tables present in document pages. The algorithm relies on the observation that the tables have distinct columns which implies that gaps between the fields are substantially larger than the gaps between the words in text lines. This deceptively simple observation has led to the design of a simple but powerful table detection system with low computation cost. Moreover, mathematical foundation of the approach is also established including formation of a regular expression for ease of implementation."
            },
            "slug": "A-simple-and-effective-table-detection-system-from-Mandal-Chowdhury",
            "title": {
                "fragments": [],
                "text": "A simple and effective table detection system from document images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A very simple but extremely powerful approach to detect tables present in document pages based on the observation that the tables have distinct columns which implies that gaps between the fields are substantially larger than the gap between the words in text lines."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some commonly used words in table processing are detection, extraction [9, 23], interpretation [9] and understanding [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10215983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8eb9090db385fd6fa77f02736f48d7c98a8d6a5",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 110,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are a ubiquitous form of communication. While everyone seems to know what a table is, a precise, analytical definition of \u201ctabularity\u201d remains elusive because some bureaucratic forms, multicolumn text layouts, and schematic drawings share many characteristics of tables. There are significant differences between typeset tables, electronic files designed for display of tables, and tables in symbolic form intended for information retrieval. Most past research has addressed the extraction of low-level geometric information from raster images of tables scanned from printed documents, although there is growing interest in the processing of tables in electronic form as well. Recent research on table composition and table analysis has improved our understanding of the distinction between the logical and physical structures of tables, and has led to improved formalisms for modeling tables. This review, which is structured in terms of generalized paradigms for table processing, indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "slug": "Table-processing-paradigms:-a-research-survey-Embley-Hurst",
            "title": {
                "fragments": [],
                "text": "Table-processing paradigms: a research survey"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This review, which is structured in terms of generalized paradigms for table processing, indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734332"
                        ],
                        "name": "Petros Venetis",
                        "slug": "Petros-Venetis",
                        "structuredName": {
                            "firstName": "Petros",
                            "lastName": "Venetis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petros Venetis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2224716"
                        ],
                        "name": "J. Madhavan",
                        "slug": "J.-Madhavan",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Madhavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724629"
                        ],
                        "name": "Marius Pasca",
                        "slug": "Marius-Pasca",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Pasca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marius Pasca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34414997"
                        ],
                        "name": "Warren Shen",
                        "slug": "Warren-Shen",
                        "structuredName": {
                            "firstName": "Warren",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Warren Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110923100"
                        ],
                        "name": "Fei Wu",
                        "slug": "Fei-Wu",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39379522"
                        ],
                        "name": "Gengxin Miao",
                        "slug": "Gengxin-Miao",
                        "structuredName": {
                            "firstName": "Gengxin",
                            "lastName": "Miao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gengxin Miao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118841585"
                        ],
                        "name": "Chung Wu",
                        "slug": "Chung-Wu",
                        "structuredName": {
                            "firstName": "Chung",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For table annotation Venetis crawls web pages using regular expressions to obtain class information [85]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "YAGO [114] can be used for extracting multiple labels for each column in a table and discovering relations between columns [85]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In the literature, tables are annotated by precompiled catalogue of entities, types of relationships [18, 81, 85], LOD datasets [79] or ontologies [61]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The above-mentioned approaches present annotated tables using existing knowledge bases [80, 81], ontologies [61, 79] or information that is automatically extracted from web pages [85] and therefore annotate only those entities that are known, whereas annotating missing entities remains untouched Annotating messing entities that do not exist in reference catalogue is addressed by some researchers [18, 73, 83]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11359711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c44cef69334cb62e6f6c7d0d245e1934f599815f",
            "isKey": true,
            "numCitedBy": 338,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The Web offers a corpus of over 100 million tables [6], but the meaning of each table is rarely explicit from the table itself. Header rows exist in few cases and even when they do, the attribute names are typically useless. We describe a system that attempts to recover the semantics of tables by enriching the table with additional annotations. Our annotations facilitate operations such as searching for tables and finding related tables. \n \nTo recover semantics of tables, we leverage a database of class labels and relationships automatically extracted from the Web. The database of classes and relationships has very wide coverage, but is also noisy. We attach a class label to a column if a sufficient number of the values in the column are identified with that label in the database of class labels, and analogously for binary relationships. We describe a formal model for reasoning about when we have seen sufficient evidence for a label, and show that it performs substantially better than a simple majority scheme. We describe a set of experiments that illustrate the utility of the recovered semantics for table search and show that it performs substantially better than previous approaches. In addition, we characterize what fraction of tables on the Web can be annotated using our approach."
            },
            "slug": "Recovering-Semantics-of-Tables-on-the-Web-Venetis-Halevy",
            "title": {
                "fragments": [],
                "text": "Recovering Semantics of Tables on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A system that attempts to recover the semantics of tables by enriching the table with additional annotations, which leverages a database of class labels and relationships automatically extracted from the Web."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759801"
                        ],
                        "name": "Ermelinda Oro",
                        "slug": "Ermelinda-Oro",
                        "structuredName": {
                            "firstName": "Ermelinda",
                            "lastName": "Oro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ermelinda Oro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794345"
                        ],
                        "name": "M. Ruffolo",
                        "slug": "M.-Ruffolo",
                        "structuredName": {
                            "firstName": "Massimo",
                            "lastName": "Ruffolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ruffolo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15060839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fd01ab3f5c39511f4a9311b3b7abb06a13d2be6",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction is of paramount importance in several real world applications in the areas of business intelligence, competitive and military intelligence. Although several sophisticated and indeed complex approaches were proposed, they are still limited in many aspects. In this paper the novel ontology-based system named XONTO, that allows the semantic extraction of information from PDF unstructured documents, is presented. The XONTO system is founded on the idea of self-describing ontologies in which objects and classes can be equipped by a set of rules named descriptors. These rules represent patterns that allow to automatically recognize and extract ontology objects contained in PDF documents also when information is arranged in tabular form. This way a self-describing ontology expresses the semantic of the information to extract and the rules that, in turn, populate itself. In the paper XONTO system behaviors and structure are sketched by means of a running example."
            },
            "slug": "XONTO:-An-Ontology-Based-System-for-Semantic-from-Oro-Ruffolo",
            "title": {
                "fragments": [],
                "text": "XONTO: An Ontology-Based System for Semantic Information Extraction from PDF Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The novel ontology-based system named XONTO, that allows the semantic extraction of information from PDF unstructured documents, is presented, founded on the idea of self-describing ontologies in which objects and classes can be equipped by a set of rules named descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "2008 20th IEEE International Conference on Tools with Artificial Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061023482"
                        ],
                        "name": "M. Shaker",
                        "slug": "M.-Shaker",
                        "structuredName": {
                            "firstName": "Mahmoud",
                            "lastName": "Shaker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shaker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87656074"
                        ],
                        "name": "H. Ibrahim",
                        "slug": "H.-Ibrahim",
                        "structuredName": {
                            "firstName": "Hamidah",
                            "lastName": "Ibrahim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ibrahim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144475512"
                        ],
                        "name": "A. Mustapha",
                        "slug": "A.-Mustapha",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Mustapha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mustapha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34865917"
                        ],
                        "name": "L. N. Abdullah",
                        "slug": "L.-N.-Abdullah",
                        "structuredName": {
                            "firstName": "Lili",
                            "lastName": "Abdullah",
                            "middleNames": [
                                "Nurliyana"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. N. Abdullah"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Another approach processes web pages for normalizing and interpreting tables for determining attribute\u2013value pair formation [117]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 21098293,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee1a7f9d75539d3f4ebf3596a504953c3bfd82a4",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Nowadays, many users use web search engines to find and gather information. User faces an increasing amount of various web pages information sources. The issue of correlating, integrating and presenting related information to users becomes important. When a user uses a search engine such as Yahoo and Google to seek a specific information, the results are not only information about the availability of the desired information, but also information about other pages on which the desired information is mentioned. Extracting information from the web pages also becomes very important because the massive and increasing amount of diverse web pages information sources in the Internet that are available to users, and the variety of web pages making the process of information extraction from web a challenging problem. This paper proposes an approach for extracting information from web tables based on standard classifications. The proposed approach consists of four main phases, namely: (i) pre-processing, (ii) extraction, (iii) classification, and (iv) simplification. The proposed approach is evaluated by conducting experiments on a number of web pages from the Nokia products domain, as to the best of our knowledge this is the only product that has complete and complex standard classifiers."
            },
            "slug": "Information-extraction-from-web-tables-Shaker-Ibrahim",
            "title": {
                "fragments": [],
                "text": "Information extraction from web tables"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An approach for extracting information from web tables based on standard classifiers is proposed, which consists of four main phases, namely: (i) pre-processing, (ii) extraction, (iii) classification, and (iv) simplification."
            },
            "venue": {
                "fragments": [],
                "text": "iiWAS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781377"
                        ],
                        "name": "J. Beel",
                        "slug": "J.-Beel",
                        "structuredName": {
                            "firstName": "Joeran",
                            "lastName": "Beel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145151838"
                        ],
                        "name": "Bela Gipp",
                        "slug": "Bela-Gipp",
                        "structuredName": {
                            "firstName": "Bela",
                            "lastName": "Gipp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bela Gipp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40515722"
                        ],
                        "name": "Ammar Shaker",
                        "slug": "Ammar-Shaker",
                        "structuredName": {
                            "firstName": "Ammar",
                            "lastName": "Shaker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ammar Shaker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39949007"
                        ],
                        "name": "Nick Friedrich",
                        "slug": "Nick-Friedrich",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Friedrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nick Friedrich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16627758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79cea2d377b1641f74ede340cc5846fe45539d82",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Extracting titles from a PDF's full text is an important task in information retrieval to identify PDFs. Existing approaches apply complicated and expensive (in terms of calculating power) machine learning algorithms such as Support Vector Machines and Conditional Random Fields. In this paper we present a simple rule based heuristic, which considers style information (font size) to identify a PDF's title. In a first experiment we show that this heuristic delivers better results (77.9% accuracy) than a support vector machine by CiteSeer (69.4% accuracy) in an 'academic search engine' scenario and better run times (8:19 minutes vs. 57:26 minutes)."
            },
            "slug": "SciPlore-Xtract:-Extracting-Titles-from-Scientific-Beel-Gipp",
            "title": {
                "fragments": [],
                "text": "SciPlore Xtract: Extracting Titles from Scientific PDF Documents by Analyzing Style Information (Font Size)"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper presents a simple rule based heuristic, which considers style information (font size) to identify a PDF's title and shows that this heuristic delivers better results than a support vector machine by CiteSeer."
            },
            "venue": {
                "fragments": [],
                "text": "ECDL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37301838"
                        ],
                        "name": "Vanessa Long",
                        "slug": "Vanessa-Long",
                        "structuredName": {
                            "firstName": "Vanessa",
                            "lastName": "Long",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vanessa Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144301565"
                        ],
                        "name": "R. Dale",
                        "slug": "R.-Dale",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Dale",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891272"
                        ],
                        "name": "S. Cassidy",
                        "slug": "S.-Cassidy",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Cassidy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Cassidy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "fie ld [3 3 , 3 4 , 6 7 ] \u2014 [5 1 ,5 9 ] [3 3 ] \u2014 \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "D ec is io n tr ee s [4 5 ] [4 0 , 4 4 ] [4 5 , 6 8 ] \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "SV M [6 5 ] \u2014 [5 1 ,5 9 ] [4 5 ] \u2014 \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Se m an ti c ex tr ac ti o n [2 3 , 5 2 , 6 9 ,7 0 ] [1 8 , 2 3 ,7 1 \u2013 7 3 ] [4 1 ,7 4 ] [4 0 , 6 2 , 7 5 \u2013 8 6 ] [1 8 , 6 4 ] [8 7 ,8 8 ] Khusro et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "St at is ti ca l St at is ti ca l [2 7 , 3 4 , 5 2 ,6 5 \u2013 6 7 ] [4 0 ] [9 , 4 8 , 5 0 ,5 1 , 5 7 , 5 9 \u2013 6 1 ] [1 4 , 4 0 , 4 4 ,4 5 ] [4 0 , 6 4 ,6 8 ] \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Lo ca ti o n [2 3 , 2 7 \u2013 3 4 ] [3 2 , 3 5 \u2013 4 0 ] [4 1 ,4 2 ] [1 4 , 3 3 , 4 3 \u2013 4 5 ] [4 0 ] [4 6 ,4 7 ]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "N ai ve B ay es C la ss ifi er [4 5 , 6 8 ] \u2014 [5 7 ,6 1 ] [4 4 ] \u2014 \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "It is a superstructure in plain text that is imposed on a character-level grid [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "H eu ri st ic b as ed [2 3 , 2 7 , 2 9 ,3 1 , 3 3 , 5 2 , 5 3 ] [3 6 , 3 8 ,5 4 , 5 5 ] [4 1 ,4 2 , 4 8 , 5 6 \u2013 6 1 ] [3 3 , 4 3 , 6 2 ,6 3 ] [6 4 ] \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Se gm en ta ti o n Se gm en ta ti o n \u2014 [3 2 , 3 3 ] [3 2 , 3 6 ,4 0 ] [2 0 ,4 2 , 4 8 \u2013 5 0 ] [1 4 ] \u2014 [4 6 ]"
                    },
                    "intents": []
                }
            ],
            "corpusId": 5877694,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee91bc5683f9047a66543348ad2a7a5865232552",
            "isKey": true,
            "numCitedBy": 8,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A spanned cell in a table is a single, complete unit that physically occupies multiple columns and/or multiple rows. Spanned cells are common in tables, and they are a significant cause of error in the extraction of tables from free text documents. In this paper, we present a model for the detection and merging of vertically spanned cells for tables presented in plain text documents. Our model and algorithm are based purely on the layout features of the tables, and they require no semantic understanding of the documents. When tested on the 98 tables appearing in 40 randomly selected documents from a corpus of company announcements from the Australian Stock Exchange (ASX), our algorithm achieves an accuracy of 86.79% in detecting and merging vertically spanned cells."
            },
            "slug": "A-model-for-detecting-and-merging-vertically-table-Long-Dale",
            "title": {
                "fragments": [],
                "text": "A model for detecting and merging vertically spanned table cells in plain text documents"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper presents a model and algorithm for the detection and merging of vertically spanned cells for tables presented in plain text documents based purely on the layout features of the tables, and they require no semantic understanding of the documents."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944286"
                        ],
                        "name": "D. Rus",
                        "slug": "D.-Rus",
                        "structuredName": {
                            "firstName": "Daniela",
                            "lastName": "Rus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34736316"
                        ],
                        "name": "K. Summers",
                        "slug": "K.-Summers",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Summers",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Summers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60453794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "283fbac96fc1f7460a5f8105c6afae6835807883",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We present and analyze efficient algorithms for the automated recognition and interpretation of layout structures in electronic documents. The key idea is to use the patterns in the distribution of white space in a document to recognize and interpret its components. The recognition algorithm divides the document into a hierarchy of logical elements; the interpretation algorithms classify these divisions as base-text, tables, indented lists, polygonal drawings, and graphs. We present experimental data and discuss an information access application. Our methodology allows the automatic markup of documents\\footnote{For instance in the SGML format} and the creation of multi-level indices and browsing tools for electronic libraries."
            },
            "slug": "Using-White-Space-for-Automated-Document-Rus-Summers",
            "title": {
                "fragments": [],
                "text": "Using White Space for Automated Document Structuring"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The key idea is to use the patterns in the distribution of white space in a document to recognize and interpret its components to allow the automatic markup of documents and the creation of multi-level indices and browsing tools for electronic libraries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3345638"
                        ],
                        "name": "Mark van Assem",
                        "slug": "Mark-van-Assem",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Assem",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark van Assem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806139"
                        ],
                        "name": "H. Rijgersberg",
                        "slug": "H.-Rijgersberg",
                        "structuredName": {
                            "firstName": "Hajo",
                            "lastName": "Rijgersberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rijgersberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802335"
                        ],
                        "name": "Mari Wigham",
                        "slug": "Mari-Wigham",
                        "structuredName": {
                            "firstName": "Mari",
                            "lastName": "Wigham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mari Wigham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38763817"
                        ],
                        "name": "J. Top",
                        "slug": "J.-Top",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Top",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Top"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6174076,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e580d68ef317bcc27f6fae9f4f54b1bc3396fb2a",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Companies, governmental agencies and scientists produce a large amount of quantitative (research) data, consisting of measurements ranging from e.g. the surface temperatures of an ocean to the viscosity of a sample of mayonnaise. Such measurements are stored in tables in e.g. spreadsheet files and research reports. To integrate and reuse such data, it is necessary to have a semantic description of the data. However, the notation used is often ambiguous, making automatic interpretation and conversion to RDF or other suitable format difficult. For example, the table header cell \"f (Hz)\" refers to frequency measured in Hertz, but the symbol \"f\" can also refer to the unit farad or the quantities force or luminous flux. Current annotation tools for this task either work on less ambiguous data or perform a more limited task. We introduce new disambiguation strategies based on an ontology, which allows to improve performance on \"sloppy\" datasets not yet targeted by existing systems."
            },
            "slug": "Converting-and-Annotating-Quantitative-Data-Tables-Assem-Rijgersberg",
            "title": {
                "fragments": [],
                "text": "Converting and Annotating Quantitative Data Tables"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "New disambiguation strategies based on an ontology are introduced, which allows to improve performance on \"sloppy\" datasets not yet targeted by existing systems."
            },
            "venue": {
                "fragments": [],
                "text": "SEMWEB"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9731552"
                        ],
                        "name": "M. Amin",
                        "slug": "M.-Amin",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Amin",
                            "middleNames": [
                                "Shafkat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Amin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736083"
                        ],
                        "name": "Anupam Bhattacharjee",
                        "slug": "Anupam-Bhattacharjee",
                        "structuredName": {
                            "firstName": "Anupam",
                            "lastName": "Bhattacharjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anupam Bhattacharjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698677"
                        ],
                        "name": "H. Jamil",
                        "slug": "H.-Jamil",
                        "structuredName": {
                            "firstName": "Hasan",
                            "lastName": "Jamil",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Jamil"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[80] proposed an algorithm that labels each column of a table using a Wikipedia best describing category based on column content."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The above-mentioned approaches present annotated tables using existing knowledge bases [80, 81], ontologies [61, 79] or information that is automatically extracted from web pages [85] and therefore annotate only those entities that are known, whereas annotating missing entities remains untouched Annotating messing entities that do not exist in reference catalogue is addressed by some researchers [18, 73, 83]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 585287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b92d138ab043a80ce396e689de8a07818b6fd9b",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "As the volume of information available on the internet is growing exponentially, it is clear that most of this information will have to be processed and digested by computers to produce useful information for human consumption. Unfortunately, most web contents are currently designed for direct human consumption in which it is assumed that a human will decipher the information presented to him in some context and will be able to connect the missing dots, if any. In particular, information presented in some tabular form often does not accompany descriptive titles or column names similar to attribute names in tables. While such omissions are not really an issue for humans, it is truly hard to extract information in autonomous systems in which a machine is expected to understand the meaning of the table presented and extract the right information in the context of the query. It is even more difficult when the information needed is distributed across the globe and involve semantic heterogeneity. In this paper, our goal is to address the issue of how to interpret tables with missing column names by developing a method for the assignment of attributes names in an arbitrary table extracted from the web in a fully autonomous manner. We propose a novel approach by leveraging Wikipedia for the first time for column name discovery for the purpose of table annotation. We show that this leads to an improved likelihood of capturing the context and interpretation of the table accurately and producing a semantically meaningful query response."
            },
            "slug": "Wikipedia-driven-autonomous-label-assignment-in-Amin-Bhattacharjee",
            "title": {
                "fragments": [],
                "text": "Wikipedia driven autonomous label assignment in wrapper induced tables with missing column names"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a novel approach by leveraging Wikipedia for the first time for column name discovery for the purpose of table annotation and shows that this leads to an improved likelihood of capturing the context and interpretation of the table accurately and producing a semantically meaningful query response."
            },
            "venue": {
                "fragments": [],
                "text": "SAC '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "There are three major categories of table detection methodologies: predefined layout approaches [37], heuristics-based approaches [31, 32, 54, 89] and statistical approaches, as well as a mixture of both heuristic and statistical approaches [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206776168,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d25a61cc0cd816eba75864912fe2f6f44be3cecf",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables. T-Recs works on the output of commercial OCR systems that provide the word bounding box geometry together with the text itself (e.g. Xerox ScanWorX). While T-Recs performs well on a number of document categories, business letters still remained a challenging domain because the T-Recs location heuristics are mislead by their header or footer resulting in a low recognition precision. Business letters such as invoices are a very interesting domain for industrial applications due to the large amount of documents to be analyzed and the importance of the data carried within their tables. Hence, we developed a more restrictive approach which is implemented in the T-Recs++ prototype. This paper describes the ideas of the T-Recs++ location and also proposes a quality evaluation measure that reflects the bottom-up strategy of either T-Recs or T-Recs++. Finally, some results comparing both systems on a collection of business letters are given."
            },
            "slug": "Applying-the-T-Recs-table-recognition-system-to-the-Kieninger-Dengel",
            "title": {
                "fragments": [],
                "text": "Applying the T-Recs table recognition system to the business letter domain"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables, and proposes a quality evaluation measure that reflects the bottom-up strategy of either T-recs or T- Recs++."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1987357"
                        ],
                        "name": "Stefan Zwicklbauer",
                        "slug": "Stefan-Zwicklbauer",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Zwicklbauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Zwicklbauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2215836"
                        ],
                        "name": "Christoph Einsiedler",
                        "slug": "Christoph-Einsiedler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Einsiedler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoph Einsiedler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2389675"
                        ],
                        "name": "M. Granitzer",
                        "slug": "M.-Granitzer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Granitzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Granitzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145566115"
                        ],
                        "name": "C. Seifert",
                        "slug": "C.-Seifert",
                        "structuredName": {
                            "firstName": "Christin",
                            "lastName": "Seifert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Seifert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8099087,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e131545692f6317e3a33e8828e951bf529576f5a",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Web tables comprise a rich source of factual information. However, without semantic annotation of the tables' content the information is not usable for automatic integration and search. We propose a methodology to annotate table headers with semantic type information based on the content of column's cells. In our experiments on 50 tables we achieved an F1 value of 0.55, where the accuracy greatly varies depending on the used ontology. Moreover, we found that for 94% of maximal F1 score only 20 cells (37%) need to be considered on average. Results suggest that for table disambiguation the choice of the ontology needs to be considered and the data input size can be reduced."
            },
            "slug": "Towards-Disambiguating-Web-Tables-Zwicklbauer-Einsiedler",
            "title": {
                "fragments": [],
                "text": "Towards Disambiguating Web Tables"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A methodology to annotate table headers with semantic type information based on the content of column's cells to suggest that for table disambiguation the choice of the ontology needs to be considered and the data input size can be reduced."
            },
            "venue": {
                "fragments": [],
                "text": "SEMWEB"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11241450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "214a525dbaeb9692c5681cfa06311caba39721ac",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables appearing in natural language documents provide a compact method for presenting relational information in an immediate and intuitive manner, while simultaneously organizing and indexing that information. Despite their ubiquity and obvious utility, tables have not received the same level of formal characterization enjoyed by sentential text. Rather, they are modeled in terms of geometry, simple hierarchies of strings and database-like relational structures. Tables have been the focus of a large volume of research in the document image analysis field and lately, have received particular attention from researchers interested in extracting information from non-trivial elements of web pages. This paper provides a framework for representing tables at both the semantic and structural levels. It presents a representation of the indexing structures present in tables and the relationship between these structures and the underlying categories."
            },
            "slug": "Towards-a-theory-of-tables-Hurst",
            "title": {
                "fragments": [],
                "text": "Towards a theory of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a representation of the indexing structures present in tables and the relationship between these structures and the underlying categories, and presents a framework for representing tables at both the semantic and structural levels."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2456613"
                        ],
                        "name": "J. H. Shamilian",
                        "slug": "J.-H.-Shamilian",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shamilian",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Shamilian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1394247998"
                        ],
                        "name": "T. Wood",
                        "slug": "T.-Wood",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Wood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wood"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "There are three major categories of table detection methodologies: predefined layout approaches [37], heuristics-based approaches [31, 32, 54, 89] and statistical approaches, as well as a mixture of both heuristic and statistical approaches [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Shamilian presents a predefine layout based table identification and segmentation algorithm [37]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206775234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ad7b7fe1c5e346b1cb9034af4fa18b5afe4d45e",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the architecture of a system for reading machine-printed documents in known predefined tabular-data layout styles. In these tables, textual data are presented in record lines made up of fixed-width fields. Tables often do not rely on line-art (ruled lines) to delimit fields, and in this way differ crucially from fixed forms. Our system performs these steps: copes with multiple tables per page; identifies records within tables; segments records into fields; and recognizes characters within fields, constrained by field-specific contextual knowledge. Obstacles to good performance on tables include small print, tight line-spacing, poor-quality text (such as photocopies), and line-art or background patterns that touch the text. Precise skew-correction and pitch-estimation, and high-performance OCR using neural nets proved crucial in overcoming these obstacles. The most significant technical advances in this work appear to be algorithms for identifying and segmenting records with known layout, and integration of these algorithms with a graphical user interface (GUI) for defining new layouts. This GUI has been ergonomically designed to make efficient and intuitive use of exemplary images, so that the skill and manual effort required to retarget the system to new table layouts are held to a minimum. The system has been applied in this way to more than 400 distinct tabular layouts. During the last three years the system has read over fifty million records with high accuracy."
            },
            "slug": "A-retargetable-table-reader-Shamilian-Baird",
            "title": {
                "fragments": [],
                "text": "A retargetable table reader"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The architecture of a system for reading machine-printed documents in known predefined tabular-data layout styles, and algorithms for identifying and segmenting records with known layout, and integration of these algorithms with a graphical user interface (GUI) for defining new layouts are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108023096"
                        ],
                        "name": "Xinxin Wang",
                        "slug": "Xinxin-Wang",
                        "structuredName": {
                            "firstName": "Xinxin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinxin Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The model assumes that stub-heads are empty, and headers are only positioned inside the box-head and stub of the table [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16895319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb8327c5b091ea26e42ed924e25a02c564998f19",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation investigates the composition of high-quality tables with the use of electronic tools. A generic model is designed to support the different stages of tabular composition, including the editing of logical structure, the specification of layout structure, and the formatting of concrete tables. The model separates table's logical structure from its layout structure, which consists of tabular topology and typographic style. The notion of an abstract table, which describes the logical relationships among tabular items, is formally defined and a set of logical operations is proposed to manipulate tables based on these logical relationships. An abstract table can be visualized through a layout structure specified by a set of topological rules, which determine the relative placement of tabular items in two dimensions, and a set of style rules, which determine the final appearance of different items. The absolute placement of a concrete table can be automatically generated by applying a layout specification to an abstract line. An NP-complete problem arises in the formatting process that uses automatic line breaking and determines the physical dimension of a table to satisfy user-specified size constraints. An algorithm has been designed to solve the formatting problem in polynomial time for typical tables. Based on the tabular model, a prototype tabular composition system has been implemented in a UNIX, X Windows environment. This prototype provides an interactive interface to edit the logical structure, the topology and the styles of tables. It allows us to manipulate tables based on the logical relationships tabular items, regardless of where the items are placed in the layout structure, and capable of presenting a table in different topologies and styles so that we can select a high-quality layout structure."
            },
            "slug": "Tabular-Abstraction,-Editing,-and-Formatting-Wang",
            "title": {
                "fragments": [],
                "text": "Tabular Abstraction, Editing, and Formatting"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This dissertation investigates the composition of high-quality tables with the use of electronic tools using a generic model designed to support the different stages of tabular composition, including the editing of logical structure, the specification of layout structure, and the formatting of concrete tables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153924342"
                        ],
                        "name": "Hsin-Hsi Chen",
                        "slug": "Hsin-Hsi-Chen",
                        "structuredName": {
                            "firstName": "Hsin-Hsi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsin-Hsi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072526610"
                        ],
                        "name": "Shih-Chung Tsai",
                        "slug": "Shih-Chung-Tsai",
                        "structuredName": {
                            "firstName": "Shih-Chung",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Chung Tsai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2949513"
                        ],
                        "name": "Jin-He Tsai",
                        "slug": "Jin-He-Tsai",
                        "structuredName": {
                            "firstName": "Jin-He",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin-He Tsai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Table analysis after table extraction has been considered by some researchers [40, 43, 97\u201399]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6844025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "578c63514136ac5b9af0144bcfe06efcfdd3099c",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a very common presentation scheme, but few papers touch on table extraction in text data mining. This paper focuses on mining tables from large-scale HTML texts. Table filtering, recognition, interpretation, and presentation are discussed. Heuristic rules and cell similarities are employed to identify tables. The F-measure of table recognition is 86.50%. We also propose an algorithm to capture attribute-value relationships among table cells. Finally, more structured data is extracted and presented."
            },
            "slug": "Mining-Tables-from-Large-Scale-HTML-Texts-Chen-Tsai",
            "title": {
                "fragments": [],
                "text": "Mining Tables from Large Scale HTML Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper focuses on mining tables from large-scale HTML texts by using heuristic rules and cell similarities to identify tables and proposes an algorithm to capture attribute-value relationships among table cells."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39955233"
                        ],
                        "name": "Zareen Syed",
                        "slug": "Zareen-Syed",
                        "structuredName": {
                            "firstName": "Zareen",
                            "lastName": "Syed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zareen Syed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144121212"
                        ],
                        "name": "Timothy W. Finin",
                        "slug": "Timothy-W.-Finin",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Finin",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy W. Finin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805399"
                        ],
                        "name": "Varish Mulwad",
                        "slug": "Varish-Mulwad",
                        "structuredName": {
                            "firstName": "Varish",
                            "lastName": "Mulwad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Varish Mulwad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145029954"
                        ],
                        "name": "A. Joshi",
                        "slug": "A.-Joshi",
                        "structuredName": {
                            "firstName": "Anupam",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Joshi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14658159,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ca3599de8f6deffd331368d38ff87a9d206f634",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Much of the world\u2019s knowledge is contained in structured documents like spreadsheets, database relations and tables in documents found on the Web and in print. The information in these tables might be much more valuable if it could be appropriately exported or encoded in RDF, making it easier to share, understand and integrate with other information. This is especially true if it could be linked into the growing linked data cloud. We describe techniques to automatically infer a (partial) semantic model for information in tables using both table headings, if available, and the values stored in table cells and to export the data the table represents as linked data. The techniques have been prototyped for a subset of linked data that covers the core of Wikipedia."
            },
            "slug": "Exploiting-a-Web-of-Semantic-Data-for-Interpreting-Syed-Finin",
            "title": {
                "fragments": [],
                "text": "Exploiting a Web of Semantic Data for Interpreting Tables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40395378"
                        ],
                        "name": "J. Ponte",
                        "slug": "J.-Ponte",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Ponte",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2759772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33151c9905102c47d431f59fc9a5a7667960507a",
            "isKey": false,
            "numCitedBy": 635,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In today's world, there is no shortage of information. However, for a specific information need, only a small subset of all of the available information will be useful. The field of information retrieval (IR) is the study of methods to provide users with that small subset of information relevant to their needs and to do so in a timely fashion. Information sources can take many forms, but this thesis will focus on text based information systems and investigate problems germane to the retrieval of written natural language documents. \n \nCentral to these problems is the notion of \"topic.\" In other words, what are documents about? However, topics depend on the semantics of documents and retrieval systems are not endowed with knowledge of the semantics of natural language. The approach taken in this thesis will be to make use of probabilistic language models to investigate text based information retrieval and related problems. \n \nOne such problem is the prediction of topic shifts in text, the topic segmentation problem. It will be shown that probabilistic methods can be used to predict topic changes in the context of the task of new event detection. Two complementary sets of features are studied individually and then combined into a single language model. The language modeling approach allows this problem to be approached in a principled way without complex semantic modeling. \n \nNext, the problem of document retrieval in response to a user query will be investigated. Models of document indexing and document retrieval have been extensively studied over the past three decades. The integration of these two classes of models has been the goal of several researchers but it is a very difficult problem. Much of the reason for this is that the indexing component requires inferences as to the semantics of documents. Instead, an approach to retrieval based on probabilistic language modeling will be presented. Models are estimated for each document individually. The approach to modeling is non-parametric and integrates the entire retrieval process into a single model. One advantage of this approach is that collection statistics, which are used heuristically for the assignment of concept probabilities in other probabilistic models, are used directly in the estimation of language model probabilities in this approach. The language modeling approach has been implemented and tested empirically and performs very well on standard test collections and query sets. \n \nIn order to improve retrieval effectiveness, IR systems use additional techniques such as relevance feedback, unsupervised query expansion and structured queries. These and other techniques are discussed in terms of the language modeling approach and empirical results are given for several of the techniques developed. These results provide further proof of concept for the use of language models for retrieval tasks."
            },
            "slug": "A-Language-Modeling-Approach-to-Information-Ponte-Croft",
            "title": {
                "fragments": [],
                "text": "A Language Modeling Approach to Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It will be shown that probabilistic methods can be used to predict topic changes in the context of the task of new event detection and provide further proof of concept for the use of language models for retrieval tasks."
            },
            "venue": {
                "fragments": [],
                "text": "SIGF"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2655674"
                        ],
                        "name": "G. Hignette",
                        "slug": "G.-Hignette",
                        "structuredName": {
                            "firstName": "Ga\u00eblle",
                            "lastName": "Hignette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hignette"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1954709"
                        ],
                        "name": "P. Buche",
                        "slug": "P.-Buche",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Buche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Buche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403715086"
                        ],
                        "name": "Juliette Dibie-Barth\u00e9lemy",
                        "slug": "Juliette-Dibie-Barth\u00e9lemy",
                        "structuredName": {
                            "firstName": "Juliette",
                            "lastName": "Dibie-Barth\u00e9lemy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juliette Dibie-Barth\u00e9lemy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958656"
                        ],
                        "name": "Ollivier Haemmerl\u00e9",
                        "slug": "Ollivier-Haemmerl\u00e9",
                        "structuredName": {
                            "firstName": "Ollivier",
                            "lastName": "Haemmerl\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ollivier Haemmerl\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6314202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ea3248d5281bf2db900e80bab75c4e4fbb83946",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an automatic system for annotating accurately data tables extracted from the web. This system is designed to provide additional data to an existing querying system called MIEL, which relies on a common vocabulary used to query local relational databases. We will use the same vocabulary, translated into an OWL ontology, to annotate the tables. Our annotation system is unsupervised. It uses only the knowledge defined in the ontology to automatically annotate the entire content of tables, using an aggregation approach: first annotate cells, then columns, then relations between those columns. The annotations are fuzzy: instead of linking an element of the table with a precise concept of the ontology, the elements of the table are annotated with several concepts, associated with their relevance degree. Our annotation process has been validated experimentally on scientific domains (microbial risk in food, chemical risk in food) and a technical domain (aeronautics)."
            },
            "slug": "Fuzzy-Annotation-of-Web-Data-Tables-Driven-by-a-Hignette-Buche",
            "title": {
                "fragments": [],
                "text": "Fuzzy Annotation of Web Data Tables Driven by a Domain Ontology"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An automatic system for annotating accurately data tables extracted from the web, designed to provide additional data to an existing querying system called MIEL, which relies on a common vocabulary used to query local relational databases."
            },
            "venue": {
                "fragments": [],
                "text": "ESWC"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145470231"
                        ],
                        "name": "Kwan Y. Wong",
                        "slug": "Kwan-Y.-Wong",
                        "structuredName": {
                            "firstName": "Kwan",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwan Y. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1880661"
                        ],
                        "name": "F. Wahl",
                        "slug": "F.-Wahl",
                        "structuredName": {
                            "firstName": "Friedrich",
                            "lastName": "Wahl",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wahl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15921038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7abca302c74d2f5adfd323a28e26d40b019df2b5",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included."
            },
            "slug": "Document-Analysis-System-Wong-Casey",
            "title": {
                "fragments": [],
                "text": "Document Analysis System"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing, are outlined and several critical functions have been investigated and the technical approaches are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901883"
                        ],
                        "name": "Shona Douglas",
                        "slug": "Shona-Douglas",
                        "structuredName": {
                            "firstName": "Shona",
                            "lastName": "Douglas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shona Douglas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054489514"
                        ],
                        "name": "David Quinn",
                        "slug": "David-Quinn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Quinn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Quinn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some research works used heuristics-based techniques for table detection [23, 27, 29, 31, 33, 36, 38, 41, 42, 48, 52\u201361]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18944899,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "211d7cdfbff8f379ad4885e96f4b68d0d9bc9b9e",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Figure 2:A generic table with terminology (`*' representsoptionality)3.2VariationsonTableLayoutDi erent layout arrangements can b e thought of as expressing functional asp ects of the relation, usingsomesimple heuristicsab outthewaygroupingandorderingmay b eexpressedintodimensions.Because we conventionally read tables from the left and from the top, we distinguish theleft marginandtopmarginoftablesasareasthetableinwhichhigh-precedencedomains areplaced(seeFigure 2).A given layout supp orts a certainreading order.This reading order reectsthe way inwhich domains are organised and sp eci cally thegroupsandordersin which domains can b e easilyusedaskeysin cho osing and reading/constructing a tuple from the table; the reading order is thusthe emb o diment of the decision structure we identi ed as the functional part of the table.Thus,while a single canonical form may have many layouts, a given canonical form plus functionalinformation will have a much reducedrange of felicitous layouts.These typical constraints on laoutwillb eusedlaterinourpro cessingheuristics.First,wepresentarep ertoireoftransformations ofsimple tables in terms of which we can analyse the variations in layout that o ccur.RotationThis transformation is b est describ ed by example:StandardslumpValue75mmv1ST1125mmv275mmv3ST2125mmv4!Standard75mm125mmValueST1v1v2v34"
            },
            "slug": "Using-Natural-Language-Processing-for-Identifying-Douglas-Hurst",
            "title": {
                "fragments": [],
                "text": "Using Natural Language Processing for Identifying and Interpreting Tables in Plain Text"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "While a single canonical form may have many layouts, a given canonical form plus functional information will have a much reducedrange of felicitous layouts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143250326"
                        ],
                        "name": "Xi-Wen Zhang",
                        "slug": "Xi-Wen-Zhang",
                        "structuredName": {
                            "firstName": "Xi-Wen",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xi-Wen Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785083"
                        ],
                        "name": "Michael R. Lyu",
                        "slug": "Michael-R.-Lyu",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lyu",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael R. Lyu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135951"
                        ],
                        "name": "G. Dai",
                        "slug": "G.-Dai",
                        "structuredName": {
                            "firstName": "Guozhong",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Dai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18115347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6ba541857b0e4551837c1fd8d3345a8c1f8f031",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Extraction-and-segmentation-of-tables-from-Chinese-Zhang-Lyu",
            "title": {
                "fragments": [],
                "text": "Extraction and segmentation of tables from Chinese ink documents based on a matrix model"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144507822"
                        ],
                        "name": "Jingjing Wang",
                        "slug": "Jingjing-Wang",
                        "structuredName": {
                            "firstName": "Jingjing",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingjing Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109590665"
                        ],
                        "name": "Haixun Wang",
                        "slug": "Haixun-Wang",
                        "structuredName": {
                            "firstName": "Haixun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haixun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135394423"
                        ],
                        "name": "Zhongyuan Wang",
                        "slug": "Zhongyuan-Wang",
                        "structuredName": {
                            "firstName": "Zhongyuan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhongyuan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796651"
                        ],
                        "name": "Kenny Q. Zhu",
                        "slug": "Kenny-Q.-Zhu",
                        "structuredName": {
                            "firstName": "Kenny",
                            "lastName": "Zhu",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenny Q. Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Determining the main concepts associated with tables can be done using single-entity column values and remaining column headers [84] where concept extraction is done using the Probase knowledge base [113]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5905962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26a373beb4c7d50143bb0f262eeef0b1432c7659",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The Web contains a wealth of information, and a key challenge is to make this information machine processable. In this paper, we study how to \"understand\" HTML tables on the Web, which is one step further from finding the schemas of tables. From 0.3 billion Web documents, we obtain 1.95 billion tables, and 0.5-1% of these contain information of various entities and their properties. We argue that in order for computers to understand these tables, computers must first have a brain --- a general purpose knowledge taxonomy that is comprehensive enough to cover the concepts (of worldly facts) in a human mind. Second, we argue that the process of understanding a table is the process of finding the right position for the table in the knowledge taxonomy. Once a table is associated with a concept in the knowledge taxonomy, it will be automatically linked to all other tables that are associated with the same concept, as well as tables associated with concepts related to this concept. In other words, understanding occurs when computers will understand the semantics of the tables through the interconnections of concepts in the knowledge base. In this paper, we illustrate a two phase process. Our experimental results show that the approach is feasible and it may benefit many useful applications such as web search."
            },
            "slug": "Understanding-Tables-on-the-Web-Wang-Wang",
            "title": {
                "fragments": [],
                "text": "Understanding Tables on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper argues that in order for computers to understand HTML tables, computers must first have a brain --- a general purpose knowledge taxonomy that is comprehensive enough to cover the concepts of worldly facts in a human mind, and illustrates a two phase process."
            },
            "venue": {
                "fragments": [],
                "text": "ER"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144145189"
                        ],
                        "name": "Stephen Lynn",
                        "slug": "Stephen-Lynn",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Lynn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Lynn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A lexicon and a domain concept-rich library of regular expressions is used for mappings, relationships and constraints discovery [77]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1837090,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cf47d7ef015e58632bf682fdd5229aff835970f",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Enabling a system to automatically conceptualize and annotate a human-readable table is one way to create interesting semantic-web content. But exactly \"how?\" is not clear. With conceptualization and annotation in mind, we investigate a semantic-enrichment procedure as a way to turn syntactically observed table layout into semantically coherent ontological concepts, relationships, and constraints. Our semantic-enrichment procedure shows how to make use of auxiliary world knowledge to construct rich ontological structures and to populate these ontological structures with instance data. The system uses auxiliary knowledge (1) to recognize concepts and which data values belong to which concepts, (2) to discover relationships among concepts and which data-value combinations represent relationship instances, and (3) to discover constraints over the concepts and relationships that the data values and data-value combinations should satisfy. Experimental evaluations indicate that the automatic conceptualization and annotation processes perform well, yielding F-measures of 90% for concept recognition, 77% for relationship discovery, and 90% for constraint discovery in web tables selected from the geopolitical domain."
            },
            "slug": "Semantically-Conceptualizing-and-Annotating-Tables-Lynn-Embley",
            "title": {
                "fragments": [],
                "text": "Semantically Conceptualizing and Annotating Tables"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work investigates a semantic-enrichment procedure as a way to turn syntactically observed table layout into semantically coherent ontological concepts, relationships, and constraints and shows how to make use of auxiliary world knowledge to construct rich ontological structures and to populate these ontological structure with instance data."
            },
            "venue": {
                "fragments": [],
                "text": "ASWC"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3216372"
                        ],
                        "name": "Chung Yong Lim",
                        "slug": "Chung-Yong-Lim",
                        "structuredName": {
                            "firstName": "Chung",
                            "lastName": "Lim",
                            "middleNames": [
                                "Yong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung Yong Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054350109"
                        ],
                        "name": "Jessica Li Teng Koo",
                        "slug": "Jessica-Li-Teng-Koo",
                        "structuredName": {
                            "firstName": "Jessica",
                            "lastName": "Koo",
                            "middleNames": [
                                "Li",
                                "Teng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jessica Li Teng Koo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some research works used heuristics-based techniques for table detection [23, 27, 29, 31, 33, 36, 38, 41, 42, 48, 52\u201361]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "There are three major categories of table detection methodologies: predefined layout approaches [37], heuristics-based approaches [31, 32, 54, 89] and statistical approaches, as well as a mixture of both heuristic and statistical approaches [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16206198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d937270157cabb23288ce6a948275f4aeeaa827",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Many real-world texts contain tables. In order to process these texts correctly and extract the information contained within the tables, it is important to identify the presence and structure of tables. In this paper, we present a new approach that learns to recognize tables in free text, including the boundary, rows and columns of tables. When tested on Wall Street Journal news documents, our learning approach outperforms a deterministic table recognition algorithm that identifies table recognition algorithm that identifies tables based on a fixed set of conditions. Our learning approach is also more flexible and easily adaptable to texts in different domains with different table characteristics."
            },
            "slug": "Learning-to-Recognize-Tables-in-Free-Text-Ng-Lim",
            "title": {
                "fragments": [],
                "text": "Learning to Recognize Tables in Free Text"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new approach that learns to recognize tables in free text, including the boundary, rows and columns of tables, outperforms a deterministic table recognition algorithm that identifies tables based on a fixed set of conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805399"
                        ],
                        "name": "Varish Mulwad",
                        "slug": "Varish-Mulwad",
                        "structuredName": {
                            "firstName": "Varish",
                            "lastName": "Mulwad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Varish Mulwad"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6934715,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fab12b1ab482f3733c7665375b6a76eadea47b99",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Vast amounts of information is encoded in tables found in documents, on the Web, and in spreadsheets or databases. Integrating or searching over this information benefits from understanding its intended meaning and making it explicit in a semantic representation language like RDF. Most current approaches to generating Semantic Web representations from tables requires human input to create schemas and often results in graphs that do not follow best practices for linked data. Evidence for a table's meaning can be found in its column headers, cell values, implicit relations between columns, caption and surrounding text but also requires general and domain-specific background knowledge. We describe techniques grounded in graphical models and probabilistic reasoning to infer meaning associated with a table. Using background knowledge from the Linked Open Data cloud, we jointly infer the semantics of column headers, table cell values (e.g., strings and numbers) and relations between columns and represent the inferred meaning as graph of RDF triples. A table's meaning is thus captured by mapping columns to classes in an appropriate ontology, linking cell values to literal constants, implied measurements, or entities in the linked data cloud (existing or new) and discovering or and identifying relations between columns."
            },
            "slug": "DC-Proposal:-Graphical-Models-and-Probabilistic-for-Mulwad",
            "title": {
                "fragments": [],
                "text": "DC Proposal: Graphical Models and Probabilistic Reasoning for Generating Linked Data from Tables"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Using background knowledge from the Linked Open Data cloud, techniques grounded in graphical models and probabilistic reasoning are described to infer meaning associated with a table and represent the inferred meaning as graph of RDF triples."
            },
            "venue": {
                "fragments": [],
                "text": "SEMWEB"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1839745"
                        ],
                        "name": "Y. Tijerino",
                        "slug": "Y.-Tijerino",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Tijerino",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Tijerino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730612"
                        ],
                        "name": "Deryle W. Lonsdale",
                        "slug": "Deryle-W.-Lonsdale",
                        "structuredName": {
                            "firstName": "Deryle",
                            "lastName": "Lonsdale",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deryle W. Lonsdale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645191"
                        ],
                        "name": "Yihong Ding",
                        "slug": "Yihong-Ding",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Ding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Ding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "present a more detailed description (without experimentation) of their vision of how TANGO should work to automatically generate Semantic Web ontologies from either lists or tables [72]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Similarly, TANGO [72], short for Table ANalysis for Generating Ontologies, works mostly within the geopolitical domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11682816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "288673018a6f48a8aa20936833bcd3ef8661508b",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "At the heart of today's information-explosion problems are issues involving semantics, mutual understanding, concept matching, and interoperability. Ontologies and the Semantic Web are offered as a potential solution, but creating ontologies for real-world knowledge is nontrivial. If we could automate the process, we could significantly improve our chances of making the Semantic Web a reality. While understanding natural language is difficult, tables and other structured information make it easier to interpret new items and relations. In this paper we introduce an approach to generating ontologies based on table analysis. We thus call our approach TANGO (Table ANalysis for Generating Ontologies). Based on conceptual modeling extraction techniques, TANGO attempts to (i) understand a table's structure and conceptual content; (ii) discover the constraints that hold between concepts extracted from the table; (iii) match the recognized concepts with ones from a more general specification of related concepts; and (iv) merge the resulting structure with other similar knowledge representations. TANGO is thus a formalized method of processing the format and content of tables that can serve to incrementally build a relevant reusable conceptual ontology."
            },
            "slug": "Towards-Ontology-Generation-from-Tables-Tijerino-Embley",
            "title": {
                "fragments": [],
                "text": "Towards Ontology Generation from Tables"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper introduces an approach to generating ontologies based on table analysis called TANGO (Table ANalysis for Generating Ontologies), a formalized method of processing the format and content of tables that can serve to incrementally build a relevant reusable conceptual ontology."
            },
            "venue": {
                "fragments": [],
                "text": "World Wide Web"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206405589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "108030474840ce5e1086cc8ef598ff3e6c13693c",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an efficient approach to identify tabular structures within either electronic or paper documents. The resulting T-Recs system takes word bounding box information as input, and outputs the corresponding logical text block units. Starting with an arbitrary word as block seed the algorithm recursively expands this block to all words that interleave with their vertical neighbors. Since even smallest gaps of table columns prevent their words from mutual interleaving, this initial segmentation is able to identify and isolate such columns. In order to deal with some inherent segmentation errors caused by isolated lines, overhanging words, or cells spawning more than one column, a series of postprocessing steps is added. These steps benefit form a very simple distinction between type 1 and type 2 blocks: type 1 blocks are those of at most one word per line, all others are of type 2. This distinction allows the selective application of heuristics to each group of blocks. The conjoint decomposition of column blocks into subsets of table cells leads to the final block segmentation of a homogeneous abstraction level. These segments serve the final layout analysis which identifies table environments and cells that are stretching over several rows and/or columns."
            },
            "slug": "Table-structure-recognition-based-on-robust-block-Kieninger",
            "title": {
                "fragments": [],
                "text": "Table structure recognition based on robust block segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An efficient approach to identify tabular structures within either electronic or paper documents by taking word bounding box information as input, and outputs the corresponding logical text block units through the T-Recs system."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398476"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144654778"
                        ],
                        "name": "Kun Bai",
                        "slug": "Kun-Bai",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930195"
                        ],
                        "name": "P. Mitra",
                        "slug": "P.-Mitra",
                        "structuredName": {
                            "firstName": "Prasenjit",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "TableSeer [51] also uses a ranking algorithm that extracts tables from documents using a box-cutting method [17] and applies this ranking algorithm on tables."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Few research works pay attention to the use of statistical approaches for table detection, including probabilistic modelling [40], the Naive Bayes classifier [44, 52, 57, 61, 66], the Maximum Entropy Classifier [34, 44], decision trees [40, 44, 45, 68], Support Vector Machine [45, 51, 59, 65], the Winnow classifier [44], Conditional Random Fields [33, 34, 51, 59, 67] and an HMM of the traditional sort [70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 541098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbaff1dbf5a998643603a1c43ee7ddc7aec53bca",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are ubiquitous in web pages and scientific documents. With the explosive development of the web, tables have become a valuable information repository. Therefore, effectively and efficiently searching tables becomes a challenge. Existing search engines do not provide satisfactory search results largely because the current ranking schemes are inadequate for table search and automatic table understanding and extraction are rather difficult in general. In this work, we design and evaluate a novel table ranking algorithm-TableRank to improve the performance of our table search engine Table-Seer. Given a keyword based table query, TableRank facilities TableSeer to return the most relevant tables by tailoring the classic vector space model. TableRank adopts an innovative term weighting scheme by aggregating multiple weighting factors from three levels: term, table and document. The experimental results show that our table search engine out-performs existing search engines on table search. In addition, incorporating multiple weighting factors can significantly improve the ranking results."
            },
            "slug": "TableRank:-A-Ranking-Algorithm-for-Table-Search-and-Liu-Bai",
            "title": {
                "fragments": [],
                "text": "TableRank: A Ranking Algorithm for Table Search and Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel table ranking algorithm-TableRank is designed and evaluated to improve the performance of the table search engine Table-Seer, which adopts an innovative term weighting scheme by aggregating multiple weighting factors from three levels: term, table and document."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679784"
                        ],
                        "name": "Fabian M. Suchanek",
                        "slug": "Fabian-M.-Suchanek",
                        "structuredName": {
                            "firstName": "Fabian",
                            "lastName": "Suchanek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabian M. Suchanek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686448"
                        ],
                        "name": "Gjergji Kasneci",
                        "slug": "Gjergji-Kasneci",
                        "structuredName": {
                            "firstName": "Gjergji",
                            "lastName": "Kasneci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gjergji Kasneci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751591"
                        ],
                        "name": "G. Weikum",
                        "slug": "G.-Weikum",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Weikum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Weikum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The latest and richest open knowledge bases are YAGO [114], DBpedia [115] and Freebase."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "YAGO [114] can be used for extracting multiple labels for each column in a table and discovering relations between columns [85]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207163173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00a3f6924f90fcd77e6e7e6534b957a75d0ced07",
            "isKey": false,
            "numCitedBy": 3480,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We present YAGO, a light-weight and extensible ontology with high coverage and quality. YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts. This includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE). The facts have been automatically extracted from Wikipedia and unified with WordNet, using a carefully designed combination of rule-based and heuristic methods described in this paper. The resulting knowledge base is a major step beyond WordNet: in quality by adding knowledge about individuals like persons, organizations, products, etc. with their semantic relationships - and in quantity by increasing the number of facts by more than an order of magnitude. Our empirical evaluation of fact correctness shows an accuracy of about 95%. YAGO is based on a logically clean model, which is decidable, extensible, and compatible with RDFS. Finally, we show how YAGO can be further extended by state-of-the-art information extraction techniques."
            },
            "slug": "Yago:-a-core-of-semantic-knowledge-Suchanek-Kasneci",
            "title": {
                "fragments": [],
                "text": "Yago: a core of semantic knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts, which includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE)."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122689890"
                        ],
                        "name": "Lee S. Jensen",
                        "slug": "Lee-S.-Jensen",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Jensen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lee S. Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Few research works pay attention to the use of statistical approaches for table detection, including probabilistic modelling [40], the Naive Bayes classifier [44, 52, 57, 61, 66], the Maximum Entropy Classifier [34, 44], decision trees [40, 44, 45, 68], Support Vector Machine [45, 51, 59, 65], the Winnow classifier [44], Conditional Random Fields [33, 34, 51, 59, 67] and an HMM of the traditional sort [70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2313483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0909fee90833e20913adb553bf6667c9a3b854b0",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "A program that makes an existing website look like a database is called a wrapper. Wrapper learning is the problem of learning website wrappers from examples. We present a wrapper-learning system called WL2 that can exploit several different representations of a document. Examples of such different representations include DOM-level and token-level representations, as well as two-dimensional geometric views of the rendered page (for tabular data) and representations of the visual appearance of text asm it will be rendered. Additionally, the learning system is modular, and can be easily adapted to new domains and tasks. The learning system described is part of an \"industrial-strength\" wrapper management system that is in active use at WhizBang Labs. Controlled experiments show that the learner has broader coverage and a faster learning rate than earlier wrapper-learning systems."
            },
            "slug": "A-flexible-learning-system-for-wrapping-tables-and-Cohen-Hurst",
            "title": {
                "fragments": [],
                "text": "A flexible learning system for wrapping tables and lists in HTML documents"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A wrapper-learning system called WL2 that can exploit several different representations of a document, including DOM-level and token-level representations, as well as two-dimensional geometric views of the rendered page and representations of the visual appearance of text asm it will be rendered."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805399"
                        ],
                        "name": "Varish Mulwad",
                        "slug": "Varish-Mulwad",
                        "structuredName": {
                            "firstName": "Varish",
                            "lastName": "Mulwad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Varish Mulwad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144121212"
                        ],
                        "name": "Timothy W. Finin",
                        "slug": "Timothy-W.-Finin",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Finin",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy W. Finin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145029954"
                        ],
                        "name": "A. Joshi",
                        "slug": "A.-Joshi",
                        "structuredName": {
                            "firstName": "Anupam",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Joshi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These also focus on literals and work across multiple domain-web tables, and medical and open government data [81]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In the literature, tables are annotated by precompiled catalogue of entities, types of relationships [18, 81, 85], LOD datasets [79] or ontologies [61]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The above-mentioned approaches present annotated tables using existing knowledge bases [80, 81], ontologies [61, 79] or information that is automatically extracted from web pages [85] and therefore annotate only those entities that are known, whereas annotating missing entities remains untouched Annotating messing entities that do not exist in reference catalogue is addressed by some researchers [18, 73, 83]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5324786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbe9f26a44b20bc27d08fe8343bb74c72e04a85e",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Vast amounts of information is encoded in structured tables found in documents, on the Web, and in spreadsheets or databases. Integrating or searching over this information benets from understanding its intended meaning. Evidence for a table\u2019s meaning can be found in its column headers, cell values, implicit relations between columns, caption and surrounding text but also requires general and domain-specic background knowledge. We represent a table\u2019s meaning by mapping columns to classes in an appropriate ontology, linking cell values to literal constants, implied measurements, or entities in the linked data cloud (existing or new) and discovering or and identifying relations between columns. We describe techniques grounded in graphical models and probabilistic reasoning to infer meaning (semantics) associated with a table. Using background knowledge from the Linked Open Data cloud, we jointly infer the semantics of column headers, table cell values (e.g.,strings and numbers) and relations between columns and represent the inferred meaning as graph of RDF triples. We motivate the value of this approach using tables from the medical domain, discussing some of the challenges presented by these tables and describing techniques to tackle them."
            },
            "slug": "Generating-Linked-Data-by-Inferring-the-Semantics-Mulwad-Finin",
            "title": {
                "fragments": [],
                "text": "Generating Linked Data by Inferring the Semantics of Tables"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Using background knowledge from the Linked Open Data cloud, techniques grounded in graphical models and probabilistic reasoning to infer meaning (semantics) associated with a table are described and the inferred meaning is represented as graph of RDF triples."
            },
            "venue": {
                "fragments": [],
                "text": "VLDS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49932604"
                        ],
                        "name": "X. Guo",
                        "slug": "X.-Guo",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743832"
                        ],
                        "name": "Yueguo Chen",
                        "slug": "Yueguo-Chen",
                        "structuredName": {
                            "firstName": "Yueguo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yueguo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108304551"
                        ],
                        "name": "Jinchuan Chen",
                        "slug": "Jinchuan-Chen",
                        "structuredName": {
                            "firstName": "Jinchuan",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinchuan Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144589756"
                        ],
                        "name": "Xiaoyong Du",
                        "slug": "Xiaoyong-Du",
                        "structuredName": {
                            "firstName": "Xiaoyong",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoyong Du"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In these approaches, missing entities annotation is done using text classifiers over snippets returned by search engines [18], using ITEM tool for extracting tables whose structure resembles the RDF knowledge base where new tuples are identified and stored in knowledge base [83] or using ITEM but not using the RDF knowledge base for detecting new entities in tables, Google Fusion Tables (GFT) [73]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The above-mentioned approaches present annotated tables using existing knowledge bases [80, 81], ontologies [61, 79] or information that is automatically extracted from web pages [85] and therefore annotate only those entities that are known, whereas annotating missing entities remains untouched Annotating messing entities that do not exist in reference catalogue is addressed by some researchers [18, 73, 83]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33668760,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c19aee0bbef1dde43dc2a10cbdb4471e7200b83b",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Many RDF Knowledge Bases are created and enlarged by mining and extracting web data. Hence their data sources are limited to social tagging networks, such as Wikipedia, WordNet, IMDB, etc., and their precision is not guaranteed. In this paper, we propose a new system, ITEM, for extracting and integrating entities from tabular data to RDF knowledge base. ITEM can efficiently compute the schema mapping between a table and a KB, and inject novel entities into the KB. Therefore, ITEM can enlarge and improve RDF KB by employing tabular data, which is assumed of high quality. ITEM detects the schema mapping between table and RDF KB only by tuples, rather than the table's schema information. Experimental results show that our system has high precision and good performance."
            },
            "slug": "ITEM:-Extract-and-Integrate-Entities-from-Tabular-Guo-Chen",
            "title": {
                "fragments": [],
                "text": "ITEM: Extract and Integrate Entities from Tabular Data to RDF Knowledge Base"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a new system, ITEM, for extracting and integrating entities from tabular data to RDF knowledge base, and shows that this system has high precision and good performance."
            },
            "venue": {
                "fragments": [],
                "text": "APWeb"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2583649"
                        ],
                        "name": "Robert J. Sandusky",
                        "slug": "Robert-J.-Sandusky",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Sandusky",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert J. Sandusky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145102313"
                        ],
                        "name": "C. Tenopir",
                        "slug": "C.-Tenopir",
                        "structuredName": {
                            "firstName": "Carol",
                            "lastName": "Tenopir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tenopir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144235147"
                        ],
                        "name": "Margaret M. Casado",
                        "slug": "Margaret-M.-Casado",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Casado",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Margaret M. Casado"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 52082481,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "967342a1f26b4d30866092cc685e7ec9714cab70",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes how scientists utilize specific journal article components, the tables, figures, maps, photographs, and graphs contained in journal articles, to support both their teaching and research. These findings are taken from a comprehensive investigation into scientists' satisfaction with and use of a prototype retrieval system that indexes tables and figures culled from scientific journal articles. Rather than focusing on seeking and searching, this paper summarizes four ways in which scientists utilize the information they find in tables and figures obtained from journal articles. While the first type of use described here, creating new fixed documents, confirms the findings of previous research, the other three types of use reveal emerging practices with journal article components: creating documents to support performative activities; making comparisons between a scientist's own work and the work of other researchers; and creating other information forms and objects."
            },
            "slug": "Uses-of-figures-and-tables-from-scholarly-journal-Sandusky-Tenopir",
            "title": {
                "fragments": [],
                "text": "Uses of figures and tables from scholarly journal articles in teaching and research"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Four ways in which scientists utilize the information they find in tables and figures obtained from journal articles are summarized, confirming the findings of previous research and revealing emerging practices with journal article components."
            },
            "venue": {
                "fragments": [],
                "text": "ASIST"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32686247"
                        ],
                        "name": "R. Jandhyala",
                        "slug": "R.-Jandhyala",
                        "structuredName": {
                            "firstName": "Ramana",
                            "lastName": "Jandhyala",
                            "middleNames": [
                                "Chakradhar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jandhyala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751773"
                        ],
                        "name": "M. Krishnamoorthy",
                        "slug": "M.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Mukkai",
                            "lastName": "Krishnamoorthy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krishnamoorthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070513249"
                        ],
                        "name": "R. Padmanabhan",
                        "slug": "R.-Padmanabhan",
                        "structuredName": {
                            "firstName": "Raghav",
                            "lastName": "Padmanabhan",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Padmanabhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108734"
                        ],
                        "name": "W. Silversmith",
                        "slug": "W.-Silversmith",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Silversmith",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Silversmith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10244615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "467e44dcd3c6f787a24cce9f2667af2fc2f1d2b5",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The extraction of the relations of nested table headers to content cells is automated with a view to constructing narrow domain ontologies of semi-structured web data. A taxonomy of tessellations for displaying tabular data is developed. X-Y tessellations that can be obtained by a divide-and-conquer method are asymptotically only an infinitesimal fraction of all partitions of a rectangle into rectangles. Admissible tessellations are the even smaller subset of all partitions that correspond to the structures of published tables and that contain only rectangles produced by successive guillotine cuts. Many of these can be processed automatically. Their structures can be conveniently represented by X-Y trees, which facilitate relating hierarchical row and column headings to content cells. A formal grammar is proposed for characterizing the X-Y trees of layout-equivalent admissible tessellations. Algorithms are presented for transforming a tessellation into an X-Y tree and hence into multidimensional, layout- independent Category Trees (Wang abstract data types)."
            },
            "slug": "From-Tessellations-to-Table-Interpretation-Jandhyala-Krishnamoorthy",
            "title": {
                "fragments": [],
                "text": "From Tessellations to Table Interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The extraction of the relations of nested table headers to content cells is automated with a view to constructing narrow domain ontologies of semi-structured web data."
            },
            "venue": {
                "fragments": [],
                "text": "Calculemus/MKM"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729154"
                        ],
                        "name": "C. Bizer",
                        "slug": "C.-Bizer",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bizer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bizer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144568027"
                        ],
                        "name": "Jens Lehmann",
                        "slug": "Jens-Lehmann",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Lehmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jens Lehmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2051816"
                        ],
                        "name": "Georgi Kobilarov",
                        "slug": "Georgi-Kobilarov",
                        "structuredName": {
                            "firstName": "Georgi",
                            "lastName": "Kobilarov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georgi Kobilarov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145044578"
                        ],
                        "name": "S. Auer",
                        "slug": "S.-Auer",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Auer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068696031"
                        ],
                        "name": "Christian Becker",
                        "slug": "Christian-Becker",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Becker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Becker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702661"
                        ],
                        "name": "Richard Cyganiak",
                        "slug": "Richard-Cyganiak",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Cyganiak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Cyganiak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2024066"
                        ],
                        "name": "Sebastian Hellmann",
                        "slug": "Sebastian-Hellmann",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Hellmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Hellmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The latest and richest open knowledge bases are YAGO [114], DBpedia [115] and Freebase."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This approach uses YAGO ontology, which is built on top of Wikipedia [115], to label cells with entity IDs, and to label table columns as well as finding binary relationships between columns using probabilistic graphical model-based framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16081721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58f72b53d576c6e4a42b4d8812e5542ffa2c03cc",
            "isKey": false,
            "numCitedBy": 2246,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "DBpedia-A-crystallization-point-for-the-Web-of-Data-Bizer-Lehmann",
            "title": {
                "fragments": [],
                "text": "DBpedia - A crystallization point for the Web of Data"
            },
            "venue": {
                "fragments": [],
                "text": "J. Web Semant."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3100918"
                        ],
                        "name": "W. Wong",
                        "slug": "W.-Wong",
                        "structuredName": {
                            "firstName": "Wern",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143696281"
                        ],
                        "name": "David Mart\u00ednez",
                        "slug": "David-Mart\u00ednez",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mart\u00ednez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Mart\u00ednez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788025"
                        ],
                        "name": "L. Cavedon",
                        "slug": "L.-Cavedon",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Cavedon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cavedon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6773023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95d19871710a295fdd245ac3bad805f10075fe74",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the challenge of extracting information about genetic mutations from tables, an important source of information in scientific papers. We use various machine learning algorithms and feature sets, and evaluate performance in extracting fields associated with an existing handcreated database of mutations. We then show how classifying tabular information can be leveraged for the task of named entity detection for mutations."
            },
            "slug": "Extraction-of-Named-Entities-from-Tables-in-Gene-Wong-Mart\u00ednez",
            "title": {
                "fragments": [],
                "text": "Extraction of Named Entities from Tables in Gene Mutation Literature"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This work investigates the challenge of extracting information about genetic mutations from tables, and shows how classifying tabular information can be leveraged for the task of named entity detection for mutations."
            },
            "venue": {
                "fragments": [],
                "text": "BioNLP@HLT-NAACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144881104"
                        ],
                        "name": "E. A. Green",
                        "slug": "E.-A.-Green",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Green",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. A. Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751773"
                        ],
                        "name": "M. Krishnamoorthy",
                        "slug": "M.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Mukkai",
                            "lastName": "Krishnamoorthy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krishnamoorthy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 866386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecb5fdcdeff0d56ebf61b151ac8617ae3b30881e",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a strategy for extracting the underlying relational information from the images of printed tables. Visual clues that exist in the image are used for extracting first the physical, and then the logical structure of the table. Since these visual clues generally have a logical meaning, there must be some association made between the graphical attributes extracted and their function of reflecting the logic expressed by the table; this knowledge is coordinated in a model. This approach, therefore, can be adapted to all tables which have graphical attributes discernible to the image analysis being used."
            },
            "slug": "Model-based-analysis-of-printed-tables-Green-Krishnamoorthy",
            "title": {
                "fragments": [],
                "text": "Model-based analysis of printed tables"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This strategy for extracting the underlying relational information from the images of printed tables is developed and can be adapted to all tables which have graphical attributes discernible to the image analysis being used."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "provide a downloadable software tool package, and produced 1125 document image groundtruths, 565 table entities and 10,298 cell entities, but their dataset and ground-truth are not publicly available [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A table is a compact and efficient presentation that is commonly used in various types of documents, especially for describing statistical and relational information [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "There are three major categories of table detection methodologies: predefined layout approaches [37], heuristics-based approaches [31, 32, 54, 89] and statistical approaches, as well as a mixture of both heuristic and statistical approaches [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3351839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a46ba896cdb3386f591db1a2d6172459f1bd2523",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Table-structure-understanding-and-its-performance-Wang-Phillips",
            "title": {
                "fragments": [],
                "text": "Table structure understanding and its performance evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Few research works pay attention to the use of statistical approaches for table detection, including probabilistic modelling [40], the Naive Bayes classifier [44, 52, 57, 61, 66], the Maximum Entropy Classifier [34, 44], decision trees [40, 44, 45, 68], Support Vector Machine [45, 51, 59, 65], the Winnow classifier [44], Conditional Random Fields [33, 34, 51, 59, 67] and an HMM of the traditional sort [70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Some research works used heuristics-based techniques for table detection [23, 27, 29, 31, 33, 36, 38, 41, 42, 48, 52\u201361]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28689838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed11aa01933bb23a019129c44a35bc32b593e6cd",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to accurately detect those areas in plain text documents that consist of contiguous text is an important pre- process to many applications. This paper introduces a novel method that uses both spatial and linguistic knowledge in an accurate manner to provide an initial analysis of the document. This initial analysis may then be extended to provide a complete analysis of the text areas in the document."
            },
            "slug": "Layout-and-language:-an-efficient-algorithm-for-on-Hurst",
            "title": {
                "fragments": [],
                "text": "Layout and language: an efficient algorithm for detecting text blocks based on spatial and linguistic evidence"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper introduces a novel method that uses both spatial and linguistic knowledge in an accurate manner to provide an initial analysis of the document that may then be extended to provide a completeAnalysis of the text areas in the document."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060810463"
                        ],
                        "name": "Akira Amano",
                        "slug": "Akira-Amano",
                        "structuredName": {
                            "firstName": "Akira",
                            "lastName": "Amano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akira Amano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2406896"
                        ],
                        "name": "Naoki Asada",
                        "slug": "Naoki-Asada",
                        "structuredName": {
                            "firstName": "Naoki",
                            "lastName": "Asada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naoki Asada"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The graph is encoded in XML format using context-free grammar for table layouts [94]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7044142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62018285f077a277c77d58c1e5732c71be58a98d",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Structure analysis of table form document is importantbecause printed documents and also electronical documentsonly provide geometrical layout and lexical information explicitly.To handle these documents automatically, logicalstructure information is necessary. In this paper, we firstpropose a general representation of table form documentbased on XML, which contains both structure and layoutinformation. Next, we present structure analysis systembased on graph grammar which represents document structureknowledge. As the relation between adjacent fields intable form documents become two dimensional, two dimensionalnotation is necessary to denote structural knowledge.Therefore, we adopt two dimensional graph grammar to denotethem. By using grammar notation, we can easily modifyand keep consistency of it, as the rules are relatively simple.Another advantage of using grammar notation is that,it can be used for generating documents only from logicalstructure. Experimental results have shown that the systemsuccessfully analyzed several kinds of table forms."
            },
            "slug": "Graph-grammar-based-analysis-system-of-complex-form-Amano-Asada",
            "title": {
                "fragments": [],
                "text": "Graph grammar based analysis system of complex table form document"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A general representation of table form document based on XML, which contains both structure and layout information and a structure analysis system based on graph grammar which represents document structureknowledge is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748977"
                        ],
                        "name": "P. Cimiano",
                        "slug": "P.-Cimiano",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Cimiano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cimiano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726067"
                        ],
                        "name": "J. V\u00f6lker",
                        "slug": "J.-V\u00f6lker",
                        "structuredName": {
                            "firstName": "Johanna",
                            "lastName": "V\u00f6lker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V\u00f6lker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Cimiano and V\u00f6lker [75] use WordNet for annotation purposes and Fleischman and Hovy [69] use a document corpus for entity annotation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1886b2edefc7916d2c5d6da7d6c9d7714566b773",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Named entity recognition and classication research has so far mainly focused on supervised techniques and has typically considered only small sets of classes with regard to which to classify the recognized entities. In this paper we address the classication of named entities with regard to large sets of classes which are specied by a given ontology. Our approach is unsupervised as it relies on no labeled training data and is open-domain as the ontology can simply be exchanged. The approach is based on Harris\u2019 distributional hypothesis and, based on the vector-space model, it assigns a named entity to the contextually most similar concept from the ontology. The main contribution of the paper is a systematic analysis of the impact of varying certain parameters on such a context-based approach exploiting similarities in vector space for the disambiguation of named entities."
            },
            "slug": "Towards-large-scale,-open-domain-and-ontology-based-Cimiano-V\u00f6lker",
            "title": {
                "fragments": [],
                "text": "Towards large-scale, open-domain and ontology-based named entity classification"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The main contribution of the paper is a systematic analysis of the impact of varying certain parameters on such a context-based approach exploiting similarities in vector space for the disambiguation of named entities."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5072734"
                        ],
                        "name": "Wentao Wu",
                        "slug": "Wentao-Wu",
                        "structuredName": {
                            "firstName": "Wentao",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wentao Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108509772"
                        ],
                        "name": "Hongsong Li",
                        "slug": "Hongsong-Li",
                        "structuredName": {
                            "firstName": "Hongsong",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongsong Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109590665"
                        ],
                        "name": "Haixun Wang",
                        "slug": "Haixun-Wang",
                        "structuredName": {
                            "firstName": "Haixun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haixun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796651"
                        ],
                        "name": "Kenny Q. Zhu",
                        "slug": "Kenny-Q.-Zhu",
                        "structuredName": {
                            "firstName": "Kenny",
                            "lastName": "Zhu",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenny Q. Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Determining the main concepts associated with tables can be done using single-entity column values and remaining column headers [84] where concept extraction is done using the Probase knowledge base [113]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17177377,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07554d53dd3b37a5183b2b85e0aaa1a5a2d7e20a",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Knowledge is indispensable to understanding. The ongoing information explosion highlights the need to enable machines to better understand electronic text in natural human language. The challenge lies in how to transfer human knowledge to machines. Much work has been devoted to creating universal ontologies for this purpose. However, none of the existing ontologies has the necessary depth and breadth to offer \u201cuniversal understanding.\u201d In this paper, we present a universal, probabilistic ontology that is more comprehensive than any of the existing ontologies. It contains 2.7 million concepts harnessed automatically from a corpus of 1.68 billion web pages and two years\u2019 worth of search log data. Unlike traditional knowledge bases that treat knowledge as black and white, it enables probabilistic interpretations of the information it contains. The probabilistic nature then enables it to incorporate heterogeneous information in a natural way. We present details of how the core ontology is constructed, and how it models knowledge\u2019s inherent uncertainty, ambiguity, and inconsistency. We also discuss potential applications, e.g., understanding user intent, that can benefit from the taxonomy."
            },
            "slug": "Towards-a-Probabilistic-Taxonomy-of-Many-Concepts-Wu-Li",
            "title": {
                "fragments": [],
                "text": "Towards a Probabilistic Taxonomy of Many Concepts"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents a universal, probabilistic ontology that is more comprehensive than any of the existing ontologies, and enables Probabilistic interpretations of the information it contains to incorporate heterogeneous information in a natural way."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2995684"
                        ],
                        "name": "Jiwon Shin",
                        "slug": "Jiwon-Shin",
                        "structuredName": {
                            "firstName": "Jiwon",
                            "lastName": "Shin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiwon Shin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70322883"
                        ],
                        "name": "Nick Guerette",
                        "slug": "Nick-Guerette",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Guerette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nick Guerette"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some research works used heuristics-based techniques for table detection [23, 27, 29, 31, 33, 36, 38, 41, 42, 48, 52\u201361]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "There are three major categories of table detection methodologies: predefined layout approaches [37], heuristics-based approaches [31, 32, 54, 89] and statistical approaches, as well as a mixture of both heuristic and statistical approaches [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61480199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8daf6741c9ba82452edc04fb6480d8922d86a168",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm that recognizes tables in document images and extracts their structural information. We use region growing to locate bounding boxes around text, and cluster them into columns by examining spatial relationships between bounding boxes and their vertical neighbors. Once initial clustering is complete, a series of post-processing steps are applied to the clusters to find columns that line up horizontally and may form tables."
            },
            "slug": "Table-Recognition-and-Evaluation-Shin-Guerette",
            "title": {
                "fragments": [],
                "text": "Table Recognition and Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An algorithm is presented that recognizes tables in document images and extracts their structural information by using region growing to locate bounding boxes around text, and cluster them into columns by examining spatial relationships between bounding Boxes and their vertical neighbors."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145658132"
                        ],
                        "name": "David Pinto",
                        "slug": "David-Pinto",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778809"
                        ],
                        "name": "Michael Branstein",
                        "slug": "Michael-Branstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Branstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Branstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775617"
                        ],
                        "name": "R. Coleman",
                        "slug": "R.-Coleman",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Coleman",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Coleman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070838843"
                        ],
                        "name": "M. King",
                        "slug": "M.-King",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "King",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. King"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40400230"
                        ],
                        "name": "Wei Li",
                        "slug": "Wei-Li",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876441"
                        ],
                        "name": "Xing Wei",
                        "slug": "Xing-Wei",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Wei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7375302,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abc36842cfb5677382a19a5b34a0f4869b271a55",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a system for question answering using semi-structured metadata, QuASM (pronounced \"chasm\"). Question answering systems aim to improve search performance by providing users with specific answers, rather than having users scan retrieved documents for these answers. Our goal is to answer factual questions by exploiting the structure inherent in documents found on the World Wide Web (WWW). Based on this structure, documents are indexed into smaller units and associated with metadata. Transforming table cells into smaller units associated with metadata is an important part of this task. In addition, we report on work to improve question classification using language models. The domain used to develop this system is documents retrieved from a crawl of www.fedstats.gov."
            },
            "slug": "QuASM:-a-system-for-question-answering-using-data-Pinto-Branstein",
            "title": {
                "fragments": [],
                "text": "QuASM: a system for question answering using semi-structured data"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A system for question answering using semi-structured metadata, QuASM (pronounced \"chasm\"), which aims to answer factual questions by exploiting the structure inherent in documents found on the World Wide Web."
            },
            "venue": {
                "fragments": [],
                "text": "JCDL '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786259"
                        ],
                        "name": "S. Brin",
                        "slug": "S.-Brin",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Brin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48479130"
                        ],
                        "name": "Lawrence Page",
                        "slug": "Lawrence-Page",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Page",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lawrence Page"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Ranking results are normally based on query/page similarities, various retrieval models such as Vector Space Model with pivoted document length normalization [102], language modelling [103], Okapi BM formula [104] and ranking algorithms such as PageRank [105]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7587743,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10d6778bc45aebcd58d336b4062b935861d2fe8a",
            "isKey": false,
            "numCitedBy": 15466,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Anatomy-of-a-Large-Scale-Hypertextual-Web-Brin-Page",
            "title": {
                "fragments": [],
                "text": "The Anatomy of a Large-Scale Hypertextual Web Search Engine"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Networks"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145329865"
                        ],
                        "name": "Minoru Yoshida",
                        "slug": "Minoru-Yoshida",
                        "structuredName": {
                            "firstName": "Minoru",
                            "lastName": "Yoshida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minoru Yoshida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768754"
                        ],
                        "name": "Kentaro Torisawa",
                        "slug": "Kentaro-Torisawa",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Torisawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kentaro Torisawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737901"
                        ],
                        "name": "Junichi Tsujii",
                        "slug": "Junichi-Tsujii",
                        "structuredName": {
                            "firstName": "Junichi",
                            "lastName": "Tsujii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junichi Tsujii"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "categorize tables into nine types according to table structure and their relative locations of attribute strings and value strings [99]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For more details about types the interested user may read [99]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Table analysis after table extraction has been considered by some researchers [40, 43, 97\u201399]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15867784,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2985934cf5161c1fb6cecc8728dbd155cb6d278a",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The World Wide Web (WWW) allows a person to access a great amount of data provided by a wide variety of entities. However, the content varies widely in expression. This makes it difficult to browse many pages effectively, even if the contents of the pages are quite similar. This study is the first step toward the reduction of such variety of WWW contents. The method proposed in this paper enables us to easily obtain information about similar objects scattered over the WWW. We focus on the tables contained in the WWW pages and propose a method to integrate them according to the category of objects presented in each table. The table integrated in a uniform format enables us to easily compare the objects of different locations and styles of expressions."
            },
            "slug": "A-method-to-integrate-tables-of-the-World-Wide-Web-Yoshida-Torisawa",
            "title": {
                "fragments": [],
                "text": "A method to integrate tables of the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This study focuses on the tables contained in the WWW pages and proposes a method to integrate them according to the category of objects presented in each table, which enables us to easily compare the objects of different locations and styles of expressions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430625"
                        ],
                        "name": "S. Robertson",
                        "slug": "S.-Robertson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Robertson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Robertson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48872185"
                        ],
                        "name": "S. Walker",
                        "slug": "S.-Walker",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Walker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398053996"
                        ],
                        "name": "M. Hancock-Beaulieu",
                        "slug": "M.-Hancock-Beaulieu",
                        "structuredName": {
                            "firstName": "Micheline",
                            "lastName": "Hancock-Beaulieu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hancock-Beaulieu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12049607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e948e69da982310a283d04ba185ff2bdcf43a2a",
            "isKey": false,
            "numCitedBy": 446,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Three runs were submitted: medium (title and description), short (title only) and a run which was a combination of a long run (title, description and narrative) with the medium and short runs. The average precision of the last mentioned run was higher by several percent than any other submitted run, but another participant recently noticed an impossibly high score for one topic in the short run. This led to the discovery that due to a mistake in the indexing procedures part of the SUBJECT eld of the LA Times documents had been indexed. Use of this eld was explicitly forbidden in the guidelines [1] for the ad hoc track. The o cial runs were repeated against a corrected index, and the corrected results are reported below, average precisions being reduced by about 2{4%."
            },
            "slug": "Okapi-at-TREC-7:-Automatic-Ad-Hoc,-Filtering,-VLC-Robertson-Walker",
            "title": {
                "fragments": [],
                "text": "Okapi at TREC-7: Automatic Ad Hoc, Filtering, VLC and Interactive"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "Three runs were submitted: medium (title and description), short (title only) and a run which was a combination of a long run (title, description and narrative) with the medium and short runs, which led to the discovery that due to a mistake in the indexing procedures part of the LA Times documents had been indexed."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144102030"
                        ],
                        "name": "M. Fleischman",
                        "slug": "M.-Fleischman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Fleischman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fleischman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Cimiano and V\u00f6lker [75] use WordNet for annotation purposes and Fleischman and Hovy [69] use a document corpus for entity annotation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Sometimes entity annotation needs semantic enrichment from external knowledge resources [69, 70]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5570507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "198b711915429fa55162e749a0b964755b36a62e",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "While Named Entity extraction is useful in many natural language applications, the coarse categories that most NE extractors work with prove insufficient for complex applications such as Question Answering and Ontology generation. We examine one coarse category of named entities, persons, and describe a method for automatically classifying person instances into eight finer-grained subcategories. We present a supervised learning method that considers the local context surrounding the entity as well as more global semantic information derived from topic signatures and WordNet. We reinforce this method with an algorithm that takes advantage of the presence of entities in multiple contexts."
            },
            "slug": "Fine-Grained-Classification-of-Named-Entities-Fleischman-Hovy",
            "title": {
                "fragments": [],
                "text": "Fine Grained Classification of Named Entities"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A supervised learning method is presented that considers the local context surrounding the entity as well as more global semantic information derived from topic signatures and WordNet, and reinforces this method with an algorithm that takes advantage of the presence of entities in multiple contexts."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793699"
                        ],
                        "name": "R. Zanibbi",
                        "slug": "R.-Zanibbi",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zanibbi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zanibbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683822"
                        ],
                        "name": "J. Cordy",
                        "slug": "J.-Cordy",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cordy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cordy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42236309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c92be1e0a4ecb0c0ee28aa7da9ec0a39611e5bc",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 117,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.Table characteristics vary widely. Consequently, a great variety of computational approaches have been applied to table recognition. In this survey, the table recognition literature is presented as an interaction of table models, observations, transformations, and inferences. A table model defines the physical and logical structure of tables; the model is used to detect tables and to analyze and decompose the detected tables. Observations perform feature measurements and data lookup, transformations alter or restructure data, and inferences generate and test hypotheses. This presentation clarifies both the decisions made by a table recognizer and the assumptions and inferencing techniques that underlie these decisions."
            },
            "slug": "A-survey-of-table-recognition-Zanibbi-Blostein",
            "title": {
                "fragments": [],
                "text": "A survey of table recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This presentation clarifies both the decisions made by a table recognizer and the assumptions and inferencing techniques that underlie these decisions."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis and Recognition"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49915337"
                        ],
                        "name": "A. C. E. Silva",
                        "slug": "A.-C.-E.-Silva",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Silva",
                            "middleNames": [
                                "Costa",
                                "e"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. C. E. Silva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7260147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "166e2f3ff52620ffc975acca6281915995498605",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov Models (HMM) are probabilistic graphical models for interdependent classification. In this paper we experiment with different ways of combining the components of an HMM for document analysis applications, in particular for finding tables in text. We show: a) how to integrate different document structure finders into the HMM; b) that transition probabilities should vary along the chain to embed general knowledge axioms of our field, c) some emission energies can be selectively ignored, and d) emission and transition probabilities can be weighed differently. We conclude these changes increase the expressiveness and usability of HMMs in our field."
            },
            "slug": "Learning-Rich-Hidden-Markov-Models-in-Document-Silva",
            "title": {
                "fragments": [],
                "text": "Learning Rich Hidden Markov Models in Document Analysis: Table Location"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper experiments with different ways of combining the components of an HMM for document analysis applications, in particular for finding tables in text, and shows how to integrate different document structure finders into the HMM."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40400230"
                        ],
                        "name": "Wei Li",
                        "slug": "Wei-Li",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conditional Random Fields are used for part-of-speech tagging [65], shallow parsing [90] and named entity recognition [91] as well as for table detection [34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11664683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d65ee7aa0a9dac3957093985e9179e1ccb9bd3b",
            "isKey": false,
            "numCitedBy": 1233,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Models for many natural language tasks benefit from the flexibility to use overlapping, non-independent features. For example, the need for labeled data can be drastically reduced by taking advantage of domain knowledge in the form of word lists, part-of-speech tags, character n-grams, and capitalization patterns. While it is difficult to capture such inter-dependent features with a generative probabilistic model, conditionally-trained models, such as conditional maximum entropy models, handle them well. There has been significant work with such models for greedy sequence modeling in NLP (Ratnaparkhi, 1996; Borthwick et al., 1998)."
            },
            "slug": "Early-results-for-Named-Entity-Recognition-with-and-McCallum-Li",
            "title": {
                "fragments": [],
                "text": "Early results for Named Entity Recognition with Conditional Random Fields, Feature Induction and Web-Enhanced Lexicons"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work has shown that conditionally-trained models, such as conditional maximum entropy models, handle inter-dependent features of greedy sequence modeling in NLP well."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97639849"
                        ],
                        "name": "M. Tamhankar",
                        "slug": "M.-Tamhankar",
                        "structuredName": {
                            "firstName": "Mangesh",
                            "lastName": "Tamhankar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tamhankar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15811182,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "326d9ae1a8f12b0dc7e8adb756c4aceb554c0230",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The essential layout attributes of a visual table can be defined by the location of four critical grid cells. Although these critical cells can often be located by automated analysis, some means of human interaction is necessary for correcting residual errors. VeriClick is a macro-enabled spreadsheet interface that provides ground-truthing, confirmation, correction, and verification functions for CSV tables. All user actions are logged. Experimental results of seven subjects on one hundred tables suggest that VeriClick can provide a ten- to twenty-fold speedup over performing the same functions with standard spreadsheet editing commands."
            },
            "slug": "VeriClick:-an-efficient-tool-for-table-format-Nagy-Tamhankar",
            "title": {
                "fragments": [],
                "text": "VeriClick: an efficient tool for table format verification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "VeriClick is a macro-enabled spreadsheet interface that provides ground-truthing, confirmation, correction, and verification functions for CSV tables that can provide a ten- to twenty-fold speedup over performing the same functions with standard spreadsheet editing commands."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33129088"
                        ],
                        "name": "Piyushee Jha",
                        "slug": "Piyushee-Jha",
                        "structuredName": {
                            "firstName": "Piyushee",
                            "lastName": "Jha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piyushee Jha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14069469,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "b0a1bf4ddfdb88e1763f097f206633008f49d151",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The Wang Notation Tool (WNT) is a semi-automatic, interactive tool that converts tables to Wang notation - a layout independent representation of tables where all relationships between cells are recorded without relying on the physical structure of tables. WNT requires minimal interaction to select categories from which it deduces relationships. However, if WNT is incorrect, user correction is available to generate correct Wang notation."
            },
            "slug": "Wang-Notation-Tool:-Layout-independent-of-tables-Jha-Nagy",
            "title": {
                "fragments": [],
                "text": "Wang Notation Tool: Layout independent representation of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The Wang Notation Tool (WNT) is a semi-automatic, interactive tool that converts tables to Wang notation - a layout independent representation of tables where all relationships between cells are recorded without relying on the physical structure of tables."
            },
            "venue": {
                "fragments": [],
                "text": "2008 19th International Conference on Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13440867,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "f5ecf0fe5a2a06463d2ff560985a623cfeb81d88",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Document images are degraded through bilevel processes such as scanning, printing, and photocopying. The resulting image degradations can be categorized based either on observable degradation features or on degradation model parameters. The degradation features can be related mathematically to model parameters. In this paper we statistically compare pairs of populations of degraded character images created with different model parameters. The changes in the probability that the characters are from different populations when the model parameters vary correlate with the relationship between observable degradation features and the model parameters. The paper also shows which features have the largest impact on the image."
            },
            "slug": "Document-Analysis-Systems-V-Lopresti-Hu",
            "title": {
                "fragments": [],
                "text": "Document Analysis Systems V"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper statistically compares pairs of populations of degraded character images created with different model parameters to show the changes in the probability that the characters are from different populations when the model parameters vary correlate with the relationship between observable degradation features and themodel parameters."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145757665"
                        ],
                        "name": "Fei Sha",
                        "slug": "Fei-Sha",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Sha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Sha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conditional Random Fields are used for part-of-speech tagging [65], shallow parsing [90] and named entity recognition [91] as well as for table detection [34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13936575,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "897249c93f55ef1c0d2aa1e799eb67b414c6d4a6",
            "isKey": false,
            "numCitedBy": 1544,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Conditional random fields for sequence labeling offer advantages over both generative models like HMMs and classifiers applied at each sequence position. Among sequence labeling tasks in language processing, shallow parsing has received much attention, with the development of standard evaluation datasets and extensive comparison among methods. We show here how to train a conditional random field to achieve performance as good as any reported base noun-phrase chunking method on the CoNLL task, and better than any reported single model. Improved training methods based on modern optimization algorithms were critical in achieving these results. We present extensive comparisons between models and training methods that confirm and strengthen previous results on shallow parsing and training methods for maximum-entropy models."
            },
            "slug": "Shallow-Parsing-with-Conditional-Random-Fields-Sha-Pereira",
            "title": {
                "fragments": [],
                "text": "Shallow Parsing with Conditional Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work shows how to train a conditional random field to achieve performance as good as any reported base noun-phrase chunking method on the CoNLL task, and better than any reported single model."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50785579"
                        ],
                        "name": "N. Friedman",
                        "slug": "N.-Friedman",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Friedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Much research and development has been carried out on extracting tables from documents and web pages [5, 22], but owing to diversity in table layouts, no work is perfect in extracting all types of tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14995779,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0a9b181fc252108de45720d4645ac245e1ba463",
            "isKey": false,
            "numCitedBy": 6020,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Most tasks require a person or an automated system to reason -- to reach conclusions based on available information. The framework of probabilistic graphical models, presented in this book, provides a general approach for this task. The approach is model-based, allowing interpretable models to be constructed and then manipulated by reasoning algorithms. These models can also be learned automatically from data, allowing the approach to be used in cases where manually constructing a model is difficult or even impossible. Because uncertainty is an inescapable aspect of most real-world applications, the book focuses on probabilistic models, which make the uncertainty explicit and provide models that are more faithful to reality. Probabilistic Graphical Models discusses a variety of models, spanning Bayesian networks, undirected Markov networks, discrete and continuous models, and extensions to deal with dynamical systems and relational data. For each class of models, the text describes the three fundamental cornerstones: representation, inference, and learning, presenting both basic concepts and advanced techniques. Finally, the book considers the use of the proposed framework for causal reasoning and decision making under uncertainty. The main text in each chapter provides the detailed technical development of the key ideas. Most chapters also include boxes with additional material: skill boxes, which describe techniques; case study boxes, which discuss empirical cases related to the approach described in the text, including applications in computer vision, robotics, natural language understanding, and computational biology; and concept boxes, which present significant concepts drawn from the material in the chapter. Instructors (and readers) can group chapters in various combinations, from core topics to more technically advanced material, to suit their particular needs."
            },
            "slug": "Probabilistic-Graphical-Models-Principles-and-Koller-Friedman",
            "title": {
                "fragments": [],
                "text": "Probabilistic Graphical Models - Principles and Techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The framework of probabilistic graphical models, presented in this book, provides a general approach for causal reasoning and decision making under uncertainty, allowing interpretable models to be constructed and then manipulated by reasoning algorithms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144484815"
                        ],
                        "name": "T. Merz",
                        "slug": "T.-Merz",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Merz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Merz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "fie ld [3 3 , 3 4 , 6 7 ] \u2014 [5 1 ,5 9 ] [3 3 ] \u2014 \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "St at is ti ca l St at is ti ca l [2 7 , 3 4 , 5 2 ,6 5 \u2013 6 7 ] [4 0 ] [9 , 4 8 , 5 0 ,5 1 , 5 7 , 5 9 \u2013 6 1 ] [1 4 , 4 0 , 4 4 ,4 5 ] [4 0 , 6 4 ,6 8 ] \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Lo ca ti o n [2 3 , 2 7 \u2013 3 4 ] [3 2 , 3 5 \u2013 4 0 ] [4 1 ,4 2 ] [1 4 , 3 3 , 4 3 \u2013 4 5 ] [4 0 ] [4 6 ,4 7 ]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "H eu ri st ic b as ed [2 3 , 2 7 , 2 9 ,3 1 , 3 3 , 5 2 , 5 3 ] [3 6 , 3 8 ,5 4 , 5 5 ] [4 1 ,4 2 , 4 8 , 5 6 \u2013 6 1 ] [3 3 , 4 3 , 6 2 ,6 3 ] [6 4 ] \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Merz views it as a file format that saves graphically and typographically complex documents [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Se gm en ta ti o n Se gm en ta ti o n \u2014 [3 2 , 3 3 ] [3 2 , 3 6 ,4 0 ] [2 0 ,4 2 , 4 8 \u2013 5 0 ] [1 4 ] \u2014 [4 6 ]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "H id d en M ar ko v m o d el [3 4 ] \u2014 \u2014 \u2014 \u2014 \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "cl as si fie r [3 4 ] \u2014 \u2014 [4 4 ] \u2014 \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "From a PDF developer\u2019s point of view, the exciting characteristics include random access because of cross-referenced table and incremental updates [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35723318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1b61128c48247d8c0065424f6a7297acd5aee67",
            "isKey": true,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis book explains all that's needed to combine the structural advantages of HTML with the comprehensive layout possibilities of PDF. It presents many of the tricks for the dynamic generation of PDF data, as well as information on integrating Acrobat into CGI, JavaScript, VBScript, and Active Server Pages. The CD includes useful software tools and the Acrobat Reader."
            },
            "slug": "Web-Publishing-with-Acrobat/PDF-Merz",
            "title": {
                "fragments": [],
                "text": "Web Publishing with Acrobat/PDF"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This book presents many of the tricks for the dynamic generation of PDF data, as well as information on integrating Acrobat into CGI, JavaScript, VBScript, and Active Server Pages."
            },
            "venue": {
                "fragments": [],
                "text": "Springer Berlin Heidelberg"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716902"
                        ],
                        "name": "Marti A. Hearst",
                        "slug": "Marti-A.-Hearst",
                        "structuredName": {
                            "firstName": "Marti",
                            "lastName": "Hearst",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marti A. Hearst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2545677"
                        ],
                        "name": "A. Divoli",
                        "slug": "A.-Divoli",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Divoli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Divoli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2990587"
                        ],
                        "name": "H. Guturu",
                        "slug": "H.-Guturu",
                        "structuredName": {
                            "firstName": "Harendra",
                            "lastName": "Guturu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Guturu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2481551"
                        ],
                        "name": "Alex Ksikes",
                        "slug": "Alex-Ksikes",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Ksikes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Ksikes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683562"
                        ],
                        "name": "Preslav Nakov",
                        "slug": "Preslav-Nakov",
                        "structuredName": {
                            "firstName": "Preslav",
                            "lastName": "Nakov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Preslav Nakov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31441413"
                        ],
                        "name": "Michael A. Wooldridge",
                        "slug": "Michael-A.-Wooldridge",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wooldridge",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Wooldridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2024915"
                        ],
                        "name": "J. Ye",
                        "slug": "J.-Ye",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2596623,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26df08b4903e14af32a7b2e2447625456231124b",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "UNLABELLED\nThe BioText Search Engine is a freely available Web-based application that provides biologists with new ways to access the scientific literature. One novel feature is the ability to search and browse article figures and their captions. A grid view juxtaposes many different figures associated with the same keywords, providing new insight into the literature. An abstract/title search and list view shows at a glance many of the figures associated with each article. The interface is carefully designed according to usability principles and techniques. The search engine is a work in progress, and more functionality will be added over time.\n\n\nAVAILABILITY\nhttp://biosearch.berkeley.edu."
            },
            "slug": "BioText-Search-Engine:-beyond-abstract-search-Hearst-Divoli",
            "title": {
                "fragments": [],
                "text": "BioText Search Engine: beyond abstract search"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "The BioText Search Engine is a freely available Web-based application that provides biologists with new ways to access the scientific literature, with the ability to search and browse article figures and their captions."
            },
            "venue": {
                "fragments": [],
                "text": "Bioinform."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113414328"
                        ],
                        "name": "Fernando Pereira",
                        "slug": "Fernando-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 219683473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ba954b0412773d047dc41231c733de0c1f4926",
            "isKey": false,
            "numCitedBy": 13409,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "slug": "Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum",
            "title": {
                "fragments": [],
                "text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents iterative parameter estimation algorithms for conditional random fields and compares the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050089"
                        ],
                        "name": "Lushan Han",
                        "slug": "Lushan-Han",
                        "structuredName": {
                            "firstName": "Lushan",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lushan Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144121212"
                        ],
                        "name": "Timothy W. Finin",
                        "slug": "Timothy-W.-Finin",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Finin",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy W. Finin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8594851"
                        ],
                        "name": "C. Parr",
                        "slug": "C.-Parr",
                        "structuredName": {
                            "firstName": "Cynthia",
                            "lastName": "Parr",
                            "middleNames": [
                                "Sims"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Parr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31899604"
                        ],
                        "name": "J. Sachs",
                        "slug": "J.-Sachs",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Sachs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sachs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145029954"
                        ],
                        "name": "A. Joshi",
                        "slug": "A.-Joshi",
                        "structuredName": {
                            "firstName": "Anupam",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Joshi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9859736,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fca75fb11bc8dcb01e687a0bcb00dc50e81bfac6",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe RDF123, a highly flexible open-source tool for translating spreadsheet data to RDF. Existing spreadsheet-to-rdf tools typically map only to star-shaped RDF graphs, i.e. each spreadsheet row is an instance, with each column representing a property. RDF123, on the other hand, allows users to define mappings to arbitrary graphs, thus allowing much richer spreadsheet semantics to be expressed. Further, each row in the spreadsheet can be mapped with a fairly different RDF scheme. Two interfaces are available. The first is a graphical application that allows users to create their mapping in an intuitive manner. The second is a Web service that takes as input a URL to a Google spreadsheet or CSV file and an RDF123 map, and provides RDF as output."
            },
            "slug": "RDF123:-From-Spreadsheets-to-RDF-Han-Finin",
            "title": {
                "fragments": [],
                "text": "RDF123: From Spreadsheets to RDF"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "RDF123, a highly flexible open-source tool for translating spreadsheet data to RDF, allows users to define mappings to arbitrary graphs, thus allowing much richer spreadsheet semantics to be expressed."
            },
            "venue": {
                "fragments": [],
                "text": "SEMWEB"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2573193"
                        ],
                        "name": "S. Lewandowsky",
                        "slug": "S.-Lewandowsky",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Lewandowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lewandowsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3034755"
                        ],
                        "name": "I. Spence",
                        "slug": "I.-Spence",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Spence",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Spence"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "It enables readers to rapidly search, compare and understand facts and draw conclusions [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62524583,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "5789805c6885deea09ee917214d9273c9d8fb93e",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphs have been an essential tool for the analysis and communication of statistical data for about 200 years. Despite widespread use and their importance in science, business, and many other walks of life, relatively little is known about how people perceive and process statistical graphs. This article reviews several empirical studies designed to explore the suitability of various graphs for a variety of purposes, and discusses the relevant theoretical psychological literature. The role of traditional psychophysics is considered, especially in connection with the long-running dispute concerning the relative merits of pie and bar charts. The review also discusses experiments on the perception of scatterplots and the use of multivariate displays, and points out the need for more empirical work."
            },
            "slug": "The-Perception-of-Statistical-Graphs-Lewandowsky-Spence",
            "title": {
                "fragments": [],
                "text": "The Perception of Statistical Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Several empirical studies designed to explore the suitability of various graphs for a variety of purposes are reviewed, and the relevant theoretical psychological literature is discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114655963"
                        ],
                        "name": "Richard Cohn",
                        "slug": "Richard-Cohn",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Cohn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Cohn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Ta b le Se er [2 1 ] Ja va M u lt i T H T M L O p en Se ar ch /r et ri ev e/"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Sc iP lo re X tr ac t[ 1 2 0 ] Ja va M u lt i T X M L O p en \u2014 St o re al l la yo u t"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Se m an ti c ex tr ac ti o n [2 3 , 5 2 , 6 9 ,7 0 ] [1 8 , 2 3 ,7 1 \u2013 7 3 ] [4 1 ,7 4 ] [4 0 , 6 2 , 7 5 \u2013 8 6 ] [1 8 , 6 4 ] [8 7 ,8 8 ] Khusro et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "St at is ti ca l St at is ti ca l [2 7 , 3 4 , 5 2 ,6 5 \u2013 6 7 ] [4 0 ] [9 , 4 8 , 5 0 ,5 1 , 5 7 , 5 9 \u2013 6 1 ] [1 4 , 4 0 , 4 4 ,4 5 ] [4 0 , 6 4 ,6 8 ] \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A p p ro ac h es P re d ef in ed la yo ut \u2014 \u2014 [5 0 ,5 2 ] \u2014 \u2014 \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Lo ca ti o n [2 3 , 2 7 \u2013 3 4 ] [3 2 , 3 5 \u2013 4 0 ] [4 1 ,4 2 ] [1 4 , 3 3 , 4 3 \u2013 4 5 ] [4 0 ] [4 6 ,4 7 ]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Te ch n o lo gi es [2 0 ] Ja va , ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "H eu ri st ic b as ed [2 3 , 2 7 , 2 9 ,3 1 , 3 3 , 5 2 , 5 3 ] [3 6 , 3 8 ,5 4 , 5 5 ] [4 1 ,4 2 , 4 8 , 5 6 \u2013 6 1 ] [3 3 , 4 3 , 6 2 ,6 3 ] [6 4 ] \u2014"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Se gm en ta ti o n Se gm en ta ti o n \u2014 [3 2 , 3 3 ] [3 2 , 3 6 ,4 0 ] [2 0 ,4 2 , 4 8 \u2013 5 0 ] [1 4 ] \u2014 [4 6 ]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In PDF documents are presented in a way that is independent of the application software or hardware that was originally used for their production [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61564286,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f88f02a2f86b87ca31a54e7c0586c3e9a8d20101",
            "isKey": true,
            "numCitedBy": 78,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Portable-Document-Format-Reference-Manual-Cohn",
            "title": {
                "fragments": [],
                "text": "Portable Document Format Reference Manual"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144713465"
                        ],
                        "name": "Joshua Berney",
                        "slug": "Joshua-Berney",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Berney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua Berney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70322883"
                        ],
                        "name": "Nick Guerette",
                        "slug": "Nick-Guerette",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Guerette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nick Guerette"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2578543"
                        ],
                        "name": "Frederick W. P. Heckel",
                        "slug": "Frederick-W.-P.-Heckel",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Heckel",
                            "middleNames": [
                                "W.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederick W. P. Heckel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "23442305"
                        ],
                        "name": "America Holloway",
                        "slug": "America-Holloway",
                        "structuredName": {
                            "firstName": "America",
                            "lastName": "Holloway",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "America Holloway"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122754651"
                        ],
                        "name": "Andrew Lacey",
                        "slug": "Andrew-Lacey",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lacey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Lacey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054228273"
                        ],
                        "name": "Benjamin Mitchell",
                        "slug": "Benjamin-Mitchell",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Mitchell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49703096"
                        ],
                        "name": "J. Perini",
                        "slug": "J.-Perini",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Perini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Perini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2327074"
                        ],
                        "name": "Zachary A. Pezzementi",
                        "slug": "Zachary-A.-Pezzementi",
                        "structuredName": {
                            "firstName": "Zachary",
                            "lastName": "Pezzementi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zachary A. Pezzementi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122717494"
                        ],
                        "name": "Zackary P. Rider",
                        "slug": "Zackary-P.-Rider",
                        "structuredName": {
                            "firstName": "Zackary",
                            "lastName": "Rider",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zackary P. Rider"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2995684"
                        ],
                        "name": "Jiwon Shin",
                        "slug": "Jiwon-Shin",
                        "structuredName": {
                            "firstName": "Jiwon",
                            "lastName": "Shin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiwon Shin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153254323"
                        ],
                        "name": "N. Ward",
                        "slug": "N.-Ward",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Ward",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ward"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2009300"
                        ],
                        "name": "R. Wicentowski",
                        "slug": "R.-Wicentowski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Wicentowski",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wicentowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 74070068,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "8b949557d0d7e4b879a8f188eefc8ac07ecb2f9c",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "During-the-2004-2005-academic-year,-the-Senior-was-Berney-Guerette",
            "title": {
                "fragments": [],
                "text": "During the 2004-2005 academic year, the Senior Conference was led by Richard Wicentowski in the area of Natural Language Processing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710927"
                        ],
                        "name": "M. Pechoucek",
                        "slug": "M.-Pechoucek",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Pechoucek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pechoucek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20657127"
                        ],
                        "name": "H. Lowe",
                        "slug": "H.-Lowe",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Lowe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145166238"
                        ],
                        "name": "A. Bundy",
                        "slug": "A.-Bundy",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bundy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bundy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 65236258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ff540401a927c3f22d71496d1dc66d7aa07d0e4",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "PAP97:-Proceedings-of-the-Fifth-International-on-of-Pechoucek-Lowe",
            "title": {
                "fragments": [],
                "text": "PAP97: Proceedings of the Fifth International Conference on the Practical Application of PROLOG"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20839449"
                        ],
                        "name": "H. Frei",
                        "slug": "H.-Frei",
                        "structuredName": {
                            "firstName": "Hans-Peter",
                            "lastName": "Frei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Frei"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60269360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bb2635b3e7d2eafab5eb51779fb128c4ec90800",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SIGIR-'96-:-proceedings-of-the-19th-Annual-ACM-on-Frei",
            "title": {
                "fragments": [],
                "text": "SIGIR '96 : proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, August 18-22, 1996, Zurich, Switzerland"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46399320"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60060152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e3393c2f87e348b61141ff273714052db3f24ed",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "TableSeer:-Automatic-Table-Extraction,-Search,-and-Liu",
            "title": {
                "fragments": [],
                "text": "TableSeer: Automatic Table Extraction, Search, and Understanding."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 28,
            "methodology": 43
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 103,
        "totalPages": 11
    },
    "page_url": "https://www.semanticscholar.org/paper/On-methods-and-tools-of-table-detection,-extraction-Khusro-Latif/a8d485f66f43bab50315f0c9a5cd042c8cc5d7ac?sort=total-citations"
}