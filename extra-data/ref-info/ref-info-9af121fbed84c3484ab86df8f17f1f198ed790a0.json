{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680891"
                        ],
                        "name": "S. Qian",
                        "slug": "S.-Qian",
                        "structuredName": {
                            "firstName": "Shie",
                            "lastName": "Qian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Qian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712614"
                        ],
                        "name": "Dapang Chen",
                        "slug": "Dapang-Chen",
                        "structuredName": {
                            "firstName": "Dapang",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dapang Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Similar algorithms were proposed by Qian and Chen for Gabor dictionaries [ 35 ] and by Villemoes for Walsh dictionaries [40]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A similar algorithm was proposed for Gabor dictionaries by Qian and Chen [ 35 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 39772221,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "30e4f00c8d79789d805e277b405df764b988feaa",
            "isKey": false,
            "numCitedBy": 265,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Signal-representation-using-adaptive-normalized-Qian-Chen",
            "title": {
                "fragments": [],
                "text": "Signal representation using adaptive normalized Gaussian functions"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Process."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49810022"
                        ],
                        "name": "G. Davis",
                        "slug": "G.-Davis",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Davis",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746242"
                        ],
                        "name": "S. Mallat",
                        "slug": "S.-Mallat",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Mallat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mallat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109019649"
                        ],
                        "name": "Zhifeng Zhang",
                        "slug": "Zhifeng-Zhang",
                        "structuredName": {
                            "firstName": "Zhifeng",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhifeng Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[11]) involves an extra step of orthogonalization."
                    },
                    "intents": []
                }
            ],
            "corpusId": 120546315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2acd8d8f8d2df5bb3f5350e3b009436544a5f907",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Computing the optimal expansion of a signal in a redundant dictionary of waveforms is an NP-hard problem. We introduce a greedy algorithm, called a matching pursuit, which computes a suboptimal expansion. The dictionary waveforms that best match a signal's structures are chosen iteratively. An orthogonalized version of the matching pursuit is also developed. Matching pursuits are general procedures for computing adaptive signal representations. With a dictionary of Gabor functions, a matching pursuit defines an adaptive time-frequency transform. Matching pursuits are chaotic maps whose attractors define a generic noise with respect to the dictionary. We derive an algorithm that isolates the coherent structures of a signal and describe an application to pattern extraction from noisy signals."
            },
            "slug": "Adaptive-time-frequency-decompositions-Davis-Mallat",
            "title": {
                "fragments": [],
                "text": "Adaptive time-frequency decompositions"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "An algorithm is derived that isolates the coherent structures of a signal and describes an application to pattern extraction from noisy signals, using a greedy algorithm called a matching pursuit, which computes a suboptimal expansion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780112"
                        ],
                        "name": "R. Coifman",
                        "slug": "R.-Coifman",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Coifman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Coifman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709398"
                        ],
                        "name": "M. Wickerhauser",
                        "slug": "M.-Wickerhauser",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Wickerhauser",
                            "middleNames": [
                                "Victor"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wickerhauser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "This diagram, adapted from Coifman and Wickerhauser [7], associates with each cosine packet or wavelet packet a rectangle in the time-frequency phase plane."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 179
                            }
                        ],
                        "text": "To make BP and BOB most comparable, suppose that they are both working with a cosine packet dictionary, and note that the `(1)-norm of coe cients is what Coifman and Wickerhauser [7] call an \\additive measure of information\"."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 206
                            }
                        ],
                        "text": "These range from general approaches, like the Method of Frames [9], and the method of Matching Pursuit [25], to clever schemes derived for specialized dictionaries, like the method of Best Orthogonal Basis [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "Coifman and Wickerhauser [7] have proposed a method of adaptively picking from among these many bases a single orthogonal basis that is the \\best basis\"."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "We implement Coifman and Wickerhauser's BOB algorithm [7], which also has a complexity of order O(n log(n))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 152
                            }
                        ],
                        "text": "To make BP and BOB most comparable, suppose that they are both working with a cosine packet dictionary, and note that the `1-norm of coe cients is what Coifman and Wickerhauser [7] call an \\additive measure of information\"."
                    },
                    "intents": []
                }
            ],
            "corpusId": 546882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5478a91c183c3a460bd4098acb8927bfc671367c",
            "isKey": true,
            "numCitedBy": 3339,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Adapted waveform analysis uses a library of orthonormal bases and an efficiency functional to match a basis to a given signal or family of signals. It permits efficient compression of a variety of signals, such as sound and images. The predefined libraries of modulated waveforms include orthogonal wavelet-packets and localized trigonometric functions, and have reasonably well-controlled time-frequency localization properties. The idea is to build out of the library functions an orthonormal basis relative to which the given signal or collection of signals has the lowest information cost. The method relies heavily on the remarkable orthogonality properties of the new libraries: all expansions in a given library conserve energy and are thus comparable. Several cost functionals are useful; one of the most attractive is Shannon entropy, which has a geometric interpretation in this context. >"
            },
            "slug": "Entropy-based-algorithms-for-best-basis-selection-Coifman-Wickerhauser",
            "title": {
                "fragments": [],
                "text": "Entropy-based algorithms for best basis selection"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "Adapted waveform analysis uses a library of orthonormal bases and an efficiency functional to match a basis to a given signal or family of signals, and relies heavily on the remarkable orthogonality properties of the new libraries."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709392"
                        ],
                        "name": "D. Donoho",
                        "slug": "D.-Donoho",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Donoho",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Donoho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2364792"
                        ],
                        "name": "I. Johnstone",
                        "slug": "I.-Johnstone",
                        "structuredName": {
                            "firstName": "Iain",
                            "lastName": "Johnstone",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Johnstone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818391"
                        ],
                        "name": "G. Kerkyacharian",
                        "slug": "G.-Kerkyacharian",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Kerkyacharian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kerkyacharian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145897897"
                        ],
                        "name": "D. Picard",
                        "slug": "D.-Picard",
                        "structuredName": {
                            "firstName": "Dominique",
                            "lastName": "Picard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Picard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12737710,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b20b4095236f461ab067d0c23bc9653d3d1f9c0",
            "isKey": false,
            "numCitedBy": 1647,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "Much recent effort has sought asymptotically minimax methods for recovering infinite dimensional objects-curves, densities, spectral densities, images-from noisy data. A now rich and complex body of work develops nearly or exactly minimax estimators for an array of interesting problems. Unfortunately, the results have rarely moved into practice, for a variety of reasons-among them being similarity to known methods, computational intractability and lack of spatial adaptivity. We discuss a method for curve estimation based on n noisy data: translate the empirical wavelet coefficients towards the origin by an amount \u221a(2 log n) /\u221an. The proposal differs from those in current use, is computationally practical and is spatially adaptive; it thus avoids several of the previous objections. Further, the method is nearly minimax both for a wide variety of loss functions-pointwise error, global error measured in L p -norms, pointwise and global error in estimation of derivatives-and for a wide range of smoothness classes, including standard Holder and Sobolev classes, and bounded variation. This is a much broader near optimality than anything previously proposed: we draw loose parallels with near optimality in robustness and also with the broad near eigenfunction properties of wavelets themselves. Finally, the theory underlying the method is interesting, as it exploits a correspondence between statistical questions and questions of optimal recovery and information-based complexity"
            },
            "slug": "Wavelet-Shrinkage:-Asymptopia-Donoho-Johnstone",
            "title": {
                "fragments": [],
                "text": "Wavelet Shrinkage: Asymptopia?"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A method for curve estimation based on n noisy data: translate the empirical wavelet coefficients towards the origin by an amount \u221a(2 log n) /\u221an and draw loose parallels with near optimality in robustness and also with the broad near eigenfunction properties of wavelets themselves."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34817070"
                        ],
                        "name": "Y. C. Pati",
                        "slug": "Y.-C.-Pati",
                        "structuredName": {
                            "firstName": "Yagyensh",
                            "lastName": "Pati",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. C. Pati"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368882"
                        ],
                        "name": "R. Rezaiifar",
                        "slug": "R.-Rezaiifar",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Rezaiifar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rezaiifar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426392"
                        ],
                        "name": "P. Krishnaprasad",
                        "slug": "P.-Krishnaprasad",
                        "structuredName": {
                            "firstName": "Perinkulam",
                            "lastName": "Krishnaprasad",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Krishnaprasad"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "A later re nement of the algorithm (see Pati [34] and Davis et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "A later re nement of the algorithm (see Pati [34] and Davis et al. [11]) involves an extra step of orthogonalization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "This method is called Orthogonal Matching Pursuit (OMP) by Pati [34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16513805,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "2071f3ee9ec4d17250b00626d55e47bf75ae2726",
            "isKey": false,
            "numCitedBy": 4152,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a recursive algorithm to compute representations of functions with respect to nonorthogonal and possibly overcomplete dictionaries of elementary building blocks e.g. affine (wavelet) frames. We propose a modification to the matching pursuit algorithm of Mallat and Zhang (1992) that maintains full backward orthogonality of the residual (error) at every step and thereby leads to improved convergence. We refer to this modified algorithm as orthogonal matching pursuit (OMP). It is shown that all additional computation required for the OMP algorithm may be performed recursively.<<ETX>>"
            },
            "slug": "Orthogonal-matching-pursuit:-recursive-function-to-Pati-Rezaiifar",
            "title": {
                "fragments": [],
                "text": "Orthogonal matching pursuit: recursive function approximation with applications to wavelet decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A modification to the matching pursuit algorithm of Mallat and Zhang (1992) that maintains full backward orthogonality of the residual at every step and thereby leads to improved convergence is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 27th Asilomar Conference on Signals, Systems and Computers"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360881"
                        ],
                        "name": "D. Heeger",
                        "slug": "D.-Heeger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heeger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "are all circulant shifts of each other, the shift being n=2j samples. Some authors [ 37 ]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 43701174,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8515604037444b3f079a9d328b0c560f33da0a19",
            "isKey": false,
            "numCitedBy": 1427,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the major drawbacks of orthogonal wavelet transforms is their lack of translation invariance: the content of wavelet subbands is unstable under translations of the input signal. Wavelet transforms are also unstable with respect to dilations of the input signal and, in two dimensions, rotations of the input signal. The authors formalize these problems by defining a type of translation invariance called shiftability. In the spatial domain, shiftability corresponds to a lack of aliasing; thus, the conditions under which the property holds are specified by the sampling theorem. Shiftability may also be applied in the context of other domains, particularly orientation and scale. Jointly shiftable transforms that are simultaneously shiftable in more than one domain are explored. Two examples of jointly shiftable transforms are designed and implemented: a 1-D transform that is jointly shiftable in position and scale, and a 2-D transform that is jointly shiftable in position and orientation. The usefulness of these image representations for scale-space analysis, stereo disparity measurement, and image enhancement is demonstrated. >"
            },
            "slug": "Shiftable-multiscale-transforms-Simoncelli-Freeman",
            "title": {
                "fragments": [],
                "text": "Shiftable multiscale transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Two examples of jointly shiftable transforms that are simultaneously shiftable in more than one domain are explored and the usefulness of these image representations for scale-space analysis, stereo disparity measurement, and image enhancement is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709392"
                        ],
                        "name": "D. Donoho",
                        "slug": "D.-Donoho",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Donoho",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Donoho"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Huo\u2019s thesis [23] considered decompositions in an overcomplete dictionary consisting of wavelets and so-called edgelets [ 14 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15209351,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "bf9c49c3ab09924337cf302494a1299cd7cdc200",
            "isKey": false,
            "numCitedBy": 736,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We study a simple \\Horizon Model\" for the problem of recovering an image from noisy data; in this model the image has an edge with fi-Holder regularity. Adopting the viewpoint of computational harmonic analysis, we develop an overcomplete collection of atoms called wedgelets, dyadically organized indicator functions with a variety of locations, scales, and orientations. The wedgelet representation provides nearly-optimal representations of objects in the Horizon model, as measured by minimax description length. We show how to rapidly compute a wedgelet approximation to noisy data by flnding a special edgelet-decorated recursive partition which minimizes a complexity-penalized sum of squares. This estimate, using su-cient sub-pixel resolution, achieves nearly the minimax mean-squared error in the Horizon Model. In fact, the method is adaptive in the sense that it achieves nearly the minimax risk for any value of the unknown degree of regularity of the Horizon, 1\u2022 fi\u2022 2. Wedgelet analysis and de-noising may be used successfully outside the Horizon model. We study images modelled as indicators of star-shaped sets with smooth bound- aries and show that complexity-penalized wedgelet partitioning achieves nearly the minimax risk in that setting also."
            },
            "slug": "Wedgelets:-nearly-minimax-estimation-of-edges-Donoho",
            "title": {
                "fragments": [],
                "text": "Wedgelets: nearly minimax estimation of edges"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An overcomplete collection of atoms called wedgelets, dyadically organized indicator functions with a variety of locations, scales, and orientations are developed, which provides nearly-optimal representations of objects in the Horizon model, as measured by minimax description length."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2099236"
                        ],
                        "name": "L. Villemoes",
                        "slug": "L.-Villemoes",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Villemoes",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Villemoes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Similar algorithms were proposed by Qian and Chen for Gabor dictionaries [35] and by Villemoes for Walsh dictionaries [ 40 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122108661,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fab3b46ffe3e693a1010f100d205b2917dfbee27",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. We consider the approximation in L2R of a given function using finite linear combinations of Walsh atoms, which are Walsh functions localized to dyadic intervals, also called Haar\u2014Walsh wavelet packets. It is shown that up to a constant factor, a linear combination of K atoms can be represented to relative error \u025b by a linear combination of \n $K^2 \\log(1/\\varepsilon)$ orthogonal atoms. In finite dimension N, best approximation with K orthogonal atoms can be realized with an algorithm of order \n $KN(1+\\log(N/K))$ . A faster algorithm of order \n $N \\log N$ solves the problem with indirect control over K. Therefore the above result connects algorithmic and theoretical best approximation."
            },
            "slug": "Best-Approximation-with-Walsh-Atoms-Villemoes",
            "title": {
                "fragments": [],
                "text": "Best Approximation with Walsh Atoms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that up to a constant factor, a linear combination of K atoms can be represented to relative error by alinear combination of   $K^2 \\log(1/\\varepsilon)$ orthogonal atoms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709392"
                        ],
                        "name": "D. Donoho",
                        "slug": "D.-Donoho",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Donoho",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Donoho"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "In the case of a dictionary that is an orthonormal basis, a number of papers [13, 16] have carefully studied an approach to de-noising by so-called \\soft-thresholding in an orthonormal basis\"."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 149055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2cc257b0c7db92f90c3224c35df7b8e85f57a090",
            "isKey": false,
            "numCitedBy": 8943,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "Donoho and Johnstone (1994) proposed a method for reconstructing an unknown function f on [0,1] from noisy data d/sub i/=f(t/sub i/)+/spl sigma/z/sub i/, i=0, ..., n-1,t/sub i/=i/n, where the z/sub i/ are independent and identically distributed standard Gaussian random variables. The reconstruction f/spl circ/*/sub n/ is defined in the wavelet domain by translating all the empirical wavelet coefficients of d toward 0 by an amount /spl sigma//spl middot//spl radic/(2log (n)/n). The authors prove two results about this type of estimator. [Smooth]: with high probability f/spl circ/*/sub n/ is at least as smooth as f, in any of a wide variety of smoothness measures. [Adapt]: the estimator comes nearly as close in mean square to f as any measurable estimator can come, uniformly over balls in each of two broad scales of smoothness classes. These two properties are unprecedented in several ways. The present proof of these results develops new facts about abstract statistical inference and its connection with an optimal recovery model. >"
            },
            "slug": "De-noising-by-soft-thresholding-Donoho",
            "title": {
                "fragments": [],
                "text": "De-noising by soft-thresholding"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "The authors prove two results about this type of estimator that are unprecedented in several ways: with high probability f/spl circ/*/sub n/ is at least as smooth as f, in any of a wide variety of smoothness measures."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47003307"
                        ],
                        "name": "Yuying Li",
                        "slug": "Yuying-Li",
                        "structuredName": {
                            "firstName": "Yuying",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuying Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737945"
                        ],
                        "name": "F. Santosa",
                        "slug": "F.-Santosa",
                        "structuredName": {
                            "firstName": "Fadil",
                            "lastName": "Santosa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Santosa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Li and Santosa [ 26 ] have developed an alternative algorithmfor this problembased on interior-point m ethods for convex optim ization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "However, the optimization problems we are interested in have a key difference fromthe successful large-scale applications outlined in [ 26 , 1]. The m atrix A we deal with is not at all sparse; it is generally completely dense."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12728705,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "413180a61b950f6e2f85c8166ae5a18bef249df8",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "A reliable and efficient computational algorithm for restoring blurred and noisy images is proposed. The restoration process is based on the minimal total variation principle introduced by Rudin et al. For discrete images, the proposed algorithm minimizes a piecewise linear l (1) function (a measure of total variation) subject to a single 2-norm inequality constraint (a measure of data fit). The algorithm starts by finding a feasible point for the inequality constraint using a (partial) conjugate gradient method. This corresponds to a deblurring process. Noise and other artifacts are removed by a subsequent total variation minimization process. The use of the linear l(1) objective function for the total variation measurement leads to a simpler computational algorithm. Both the steepest descent and an affine scaling Newton method are considered to solve this constrained piecewise linear l(1) minimization problem. The resulting algorithm, when viewed as an image restoration and enhancement process, has the feature that it can be used in an adaptive/interactive manner in situations when knowledge of the noise variance is either unavailable or unreliable. Numerical examples are presented to demonstrate the effectiveness of the proposed iterative image restoration and enhancement process."
            },
            "slug": "A-computational-algorithm-for-minimizing-total-in-Li-Santosa",
            "title": {
                "fragments": [],
                "text": "A computational algorithm for minimizing total variation in image restoration"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A reliable and efficient computational algorithm for restoring blurred and noisy images that can be used in an adaptive/interactive manner in situations when knowledge of the noise variance is either unavailable or unreliable is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746242"
                        ],
                        "name": "S. Mallat",
                        "slug": "S.-Mallat",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Mallat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mallat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144393117"
                        ],
                        "name": "W. Hwang",
                        "slug": "W.-Hwang",
                        "structuredName": {
                            "firstName": "Wen-Liang",
                            "lastName": "Hwang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hwang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 278
                            }
                        ],
                        "text": "Experiments with standard time-frequency dictionaries indicate some of the potential bene ts of BP. Experiments with some nonstandard dictionaries { like the stationary wavelet dictionary and the Heaviside dictionary { indicate important connections between BP and methods like Mallat\nand Zhong's Multi-Scale Edge Representation and Osher, Rudin and Fatemi's Total Variation-based De-Noising methods."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Mallat and Zhong proposed an iterative method that reconstructs an object having the same values of the CWT at \\maxima\"."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 106
                            }
                        ],
                        "text": "An important contrast: Meyer has a counterexample to multi-scale edge approaches, showing that the Mallat-Zhong approach may fail in certain cases [29]; but there can be no such counterexamples to BP.\n4.2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 204
                            }
                        ],
                        "text": "There is a surprisingly close agreement of the BP representation in a stationary wavelet dictionary with ideas about signal representation associated with the \\MultiScale Edges\" ideas of Mallat and Zhong [26, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2661011,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7756c24837b1f9ca3fc5be4ce7b4de0fcf9de8e6",
            "isKey": true,
            "numCitedBy": 4078,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "The mathematical characterization of singularities with Lipschitz exponents is reviewed. Theorems that estimate local Lipschitz exponents of functions from the evolution across scales of their wavelet transform are reviewed. It is then proven that the local maxima of the wavelet transform modulus detect the locations of irregular structures and provide numerical procedures to compute their Lipschitz exponents. The wavelet transform of singularities with fast oscillations has a particular behavior that is studied separately. The local frequency of such oscillations is measured from the wavelet transform modulus maxima. It has been shown numerically that one- and two-dimensional signals can be reconstructed, with a good approximation, from the local maxima of their wavelet transform modulus. As an application, an algorithm is developed that removes white noises from signals by analyzing the evolution of the wavelet transform maxima across scales. In two dimensions, the wavelet transform maxima indicate the location of edges in images. >"
            },
            "slug": "Singularity-detection-and-processing-with-wavelets-Mallat-Hwang",
            "title": {
                "fragments": [],
                "text": "Singularity detection and processing with wavelets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is proven that the local maxima of the wavelet transform modulus detect the locations of irregular structures and provide numerical procedures to compute their Lipschitz exponents."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40246285"
                        ],
                        "name": "L. Rudin",
                        "slug": "L.-Rudin",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Rudin",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rudin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782265"
                        ],
                        "name": "S. Osher",
                        "slug": "S.-Osher",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Osher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Osher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143749693"
                        ],
                        "name": "E. Fatemi",
                        "slug": "E.-Fatemi",
                        "structuredName": {
                            "firstName": "Emad",
                            "lastName": "Fatemi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fatemi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 356,
                                "start": 350
                            }
                        ],
                        "text": "Experiments with standard time-frequency dictionaries indicate some of the potential bene ts of BP. Experiments with some nonstandard dictionaries { like the stationary wavelet dictionary and the Heaviside dictionary { indicate important connections between BP and methods like Mallat\nand Zhong's Multi-Scale Edge Representation and Osher, Rudin and Fatemi's Total Variation-based De-Noising methods."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "Recently, Rudin, Osher and Fatemi [31] have called attention to the possibility of de-noising images using total-variation penalized least-squares."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13133466,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "54205667c1f65a320f667d73c354ed8e86f1b9d9",
            "isKey": false,
            "numCitedBy": 13754,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nonlinear-total-variation-based-noise-removal-Rudin-Osher",
            "title": {
                "fragments": [],
                "text": "Nonlinear total variation based noise removal algorithms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737063"
                        ],
                        "name": "I. Daubechies",
                        "slug": "I.-Daubechies",
                        "structuredName": {
                            "firstName": "Ingrid",
                            "lastName": "Daubechies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Daubechies"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "Method-of-Frames De-Noising (MOFDN) refers to minimizing the squared l2 error plus an l2 penalizing term:\nmin ks k22 + k k22\nwhere is a penalizing parameter; we chose in these examples to be p 2 log(p)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 169
                            }
                        ],
                        "text": "By starting from this decomposition and applying a strategy based on a limited number of iterations of our algorithm, we get what we view as an iterative improvement on MOF."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 125
                            }
                        ],
                        "text": "Formally, one solves the problem\nmink k1 subject to = s:(3.1)\nFrom one point of view, (3.1) is very similar to the Method of Frames (2.3): we are simply replacing the `2 norm in (2.3) with the `1 norm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "We observe that BP\nis typically slower than MOF and BOB."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "Panels c)-f) display de-noising results for MOF, BOB, MP, and BP, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 195
                            }
                        ],
                        "text": "There is a matrix y, the generalized inverse of , that calculates the minimum-length solution to a system of linear equations:\ny = ys = T ( T ) 1s :(2.4)\nFor so-called \\Tight Frame\" dictionaries MOF is available in closed form."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 57
                            }
                        ],
                        "text": "BP-Interior has an interesting relation to the Method of Frames."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "These range from general approaches, like the Method of Frames [9], and the method of Matching Pursuit [25], to clever schemes derived for specialized dictionaries, like the method of Best Orthogonal Basis [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 43
                            }
                        ],
                        "text": "BP-Interior initializes with the Method of Frames solution."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 67
                            }
                        ],
                        "text": "Hence one can say that BP sequentially \\improves\" on the Method of Frames."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "If the underlying object has a very sparse representation in terms of the dictionary, then the coe cients found by MOF are likely to be very much less sparse."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "MOF gives a reconstruction that is inherently resolution-limited and oscillatory."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 10
                            }
                        ],
                        "text": "Method of Frames."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "Second, MOF is intrinsically resolution-limited."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "We employ a conjugate-gradient solver for the generalized inverse in the MOF solution (2.4); the resulting algorithm for MOF has a complexity order O(n log(n))."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 46
                            }
                        ],
                        "text": "There are two key problems with the Method of Frames."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 14
                            }
                        ],
                        "text": "The Method of Frames leads to a quadratic optimization problem with linear equality constraints, and so involves essentially just the solution of a system of linear equations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "The Method of Frames (MOF) [9] picks out, among all solutions\nof (2.2), one whose coe cients have minimum l2 norm:\nmink k2 subject to = s:(2.3) The solution of this problem is unique; label it y. Geometrically, the collection of all solutions to (2.2) is an a ne subspace inRp; MOF selects the element of this subspace closest to the origin."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 158
                            }
                        ],
                        "text": "We do believe that the pursuit process, carried out for whatever length of time we are willing to invest in it, makes a useful improvement over the Method of Frames."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "We compare BPDN with three other de-noising methods adapted from MOF, MP and BOB."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "In this case, reconstruction by MOF, Figure 2.4b, is simply convolution with the Dirichlet kernel."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "We give examples exhibiting several advantages over MOF, MP and BOB, including better sparsity, and super-resolution."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "The Method of Frames (MOF) [9] picks out, among all solutions of (2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 161
                            }
                        ],
                        "text": "Because of the nondi erentiability of the `1 norm, this optimization principle leads to decompositions that can have very di erent properties from the Method of Frames { in particular they can be much sparser."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Using a 4-fold overcomplete discrete cosine dictionary, reconstructions by the MOF, MP, and by BPDN are given."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "First, MOF is not sparsity-preserving."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "As already discussed, MOF and BP di er in the replacement of an l2 objective function by an l1 objective."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "First, note that MOF uses all basis functions that are not orthogonal to the 6 atoms, i.e. all the atoms at times and frequencies that overlap with some atom appearing in the signal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "Figure 3.1 displays the results in phase-plane form; for comparison, we include the phase planes obtained using MOF, MP, and BOB."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "Moreover, we have a natural initial solution { from MOF { that would be viewed by some researchers as already an acceptable method of atomic decomposition."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Frames."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9718015,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "913352b1422fcea77b5b4cfe2300596515f92eec",
            "isKey": true,
            "numCitedBy": 589,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The author defines a set of operators which localize in both time and frequency. These operators are similar to but different from the low-pass time-limiting operator, the singular functions of which are the prolate spheroidal wave functions. The author's construction differs from the usual approach in that she treats the time-frequency plane as one geometric whole (phase space) rather than as two separate spaces. For disk-shaped or ellipse-shaped domains in time-frequency plane, the associated localization operators are remarkably simple. Their eigenfunctions are Hermite functions, and the corresponding eigenvalues are given by simple explicit formulas involving the incomplete gamma functions. >"
            },
            "slug": "Time-frequency-localization-operators:-A-geometric-Daubechies",
            "title": {
                "fragments": [],
                "text": "Time-frequency localization operators: A geometric phase space approach"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The author defines a set of operators which localize in both time and frequency, similar to but different from the low-pass time-limiting operator, the singular functions of which are the prolate spheroidal wave functions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737063"
                        ],
                        "name": "I. Daubechies",
                        "slug": "I.-Daubechies",
                        "structuredName": {
                            "firstName": "Ingrid",
                            "lastName": "Daubechies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Daubechies"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "Although the rules of construction are more complicated (boundary conditions [28], orthogonality versus bi-orthogonality [10], etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": ", Daubechies Nearly Symmetric wavelets with eight vanishing moments; see [10] for examples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "The most important variations are smooth wavelet bases, using splines or using wavelets de ned recursively from twoscale ltering relations [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58524360,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "7e63bf9af3f70abd5771c06d459a0d3fbfbb2909",
            "isKey": false,
            "numCitedBy": 15555,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction Preliminaries and notation The what, why, and how of wavelets The continuous wavelet transform Discrete wavelet transforms: Frames Time-frequency density and orthonormal bases Orthonormal bases of wavelets and multiresolutional analysis Orthonormal bases of compactly supported wavelets More about the regularity of compactly supported wavelets Symmetry for compactly supported wavelet bases Characterization of functional spaces by means of wavelets Generalizations and tricks for orthonormal wavelet bases References Indexes."
            },
            "slug": "Ten-Lectures-on-Wavelets-Daubechies",
            "title": {
                "fragments": [],
                "text": "Ten Lectures on Wavelets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a meta-analyses of the wavelet transforms of Coxeter\u2019s inequality and its applications to multiresolutional analysis and orthonormal bases."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118528593"
                        ],
                        "name": "Sheng Chen",
                        "slug": "Sheng-Chen",
                        "structuredName": {
                            "firstName": "Sheng",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sheng Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719377"
                        ],
                        "name": "S. Billings",
                        "slug": "S.-Billings",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Billings",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Billings"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9192861"
                        ],
                        "name": "W. Luo",
                        "slug": "W.-Luo",
                        "structuredName": {
                            "firstName": "Wan",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Luo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For an earlier instance of a related algorithm, see [ 5 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7567970,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bce84d14172b25f3844efc0b11507cbc93c049d3",
            "isKey": false,
            "numCitedBy": 1532,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Identification algorithms based on the well-known linear least squares methods of gaussian elimination, Cholesky decomposition, classical Gram-Schmidt, modified Gram-Schmidt, Householder transformation, Givens method, and singular value decomposition are reviewed. The classical Gram-Schmidt, modified Gram-Schmidt, and Householder transformation algorithms are then extended to combine structure determination, or which terms to include in the model, and parameter estimation in a very simple and efficient manner for a class of multivariate discrete-time non-linear stochastic systems which are linear in the parameters."
            },
            "slug": "Orthogonal-least-squares-methods-and-their-to-Chen-Billings",
            "title": {
                "fragments": [],
                "text": "Orthogonal least squares methods and their application to non-linear system identification"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "Identification algorithms based on the well-known linear least squares methods of gaussian elimination, Cholesky decomposition, classical Gram-Schmidt, modified Gram- Schmidt, Householder transformation, Givens method, and singular value decomposition are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2226478"
                        ],
                        "name": "I. Lustig",
                        "slug": "I.-Lustig",
                        "structuredName": {
                            "firstName": "Irvin",
                            "lastName": "Lustig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Lustig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472238"
                        ],
                        "name": "R. E. Marsten",
                        "slug": "R.-E.-Marsten",
                        "structuredName": {
                            "firstName": "Roy",
                            "lastName": "Marsten",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. E. Marsten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213123"
                        ],
                        "name": "D. Shanno",
                        "slug": "D.-Shanno",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Shanno",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Shanno"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "A good overview of the recent rapid progress in this eld and the current state of the art is a orded by the article of Lustig, Marsten and Shanno [23] and the accompanying discussions by Bixby [1], Saunders [36], Todd [38], and Vanderbei [39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "We cannot summarize all these ideas here; many of them are mentioned in [23] and others are covered in the references of that article."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "Since then a very wide array of interior-point algorithms have been proposed and considerable practical [23] and theoretical [30] understanding is now available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "However, the optimizationproblems we are interested in have a key di erence from the successful large-scale applications outlined in [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "The primal-dual log barrier algorithm we just described works in a fashion similar to other interior-point methods [23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9562072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30cd8eedb652ed4b22996eeb065d5070582b54ca",
            "isKey": true,
            "numCitedBy": 300,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A survey of the significant developments in the field of interior point methods for linear programming is presented, beginning with Karmarkar's projective algorithm and concentrating on the many variants that can be derived from logarithmic barrier methods. Full implementation details of the primal-dual predictor-corrector code OB1 are given, including preprocessing, matrix orderings, and matrix factorization techniques. A computational comparison of OB1 with a state-of-the-art simplex code using eight large models is given. In addition, computational results are presented where OB1 is used to solve two very large models that have never been solved by any simplex code INFORMS Journal on Computing , ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499."
            },
            "slug": "Feature-Article-Interior-Point-Methods-for-Linear-Lustig-Marsten",
            "title": {
                "fragments": [],
                "text": "Feature Article - Interior Point Methods for Linear Programming: Computational State of the Art"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A survey of the significant developments in the field of interior point methods for linear programming is presented, beginning with Karmarkar's projective algorithm and concentrating on the many variants that can be derived from logarithmic barrier methods."
            },
            "venue": {
                "fragments": [],
                "text": "INFORMS J. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080288"
                        ],
                        "name": "C. Paige",
                        "slug": "C.-Paige",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Paige",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Paige"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145621255"
                        ],
                        "name": "M. Saunders",
                        "slug": "M.-Saunders",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Saunders",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Saunders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "gradient methods such as LSQR [36,  37 ] for solving the least-squares problem (6.5)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45621422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d09b664b36f0f1783811db466c5ea08d95ce996",
            "isKey": false,
            "numCitedBy": 690,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Received 4 June 1980; revised 23 September 1981, accepted 28 February 1982 This work was supported by Natural Sciences and Engineering Research Council of Canada Grant A8652, by the New Zealand Department of Scientific and Industrial Research; and by U S. National Science Foundation Grants MCS-7926009 and ECS-8012974, the Department of Energy under Contract AM03-76SF00326, PA No. DE-AT03-76ER72018, the Office of Naval Research under Contract N00014-75-C-0267, and the Army Research Office under Contract DAA29-79-C-0U0, Authors' addresses: C. C. Paige, School of Computer Science, McGill University, Montreal, Quebec, Canada H3A 2K6; M. A Saundem, Department of Operations Research, Stanford University, Stanford, CA 94305. Permmsion to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notme is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. \u00a9 1982 ACM 0098-3500/82/0600-0[95 $00 75"
            },
            "slug": "Algorithm-583:-LSQR:-Sparse-Linear-Equations-and-Paige-Saunders",
            "title": {
                "fragments": [],
                "text": "Algorithm 583: LSQR: Sparse Linear Equations and Least Squares Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work was supported by Natural Sciences and Engineering Research Council of Canada Grant A8652, by the New Zealand Department of Scientific and Industrial Research, and by the Department of Energy under Contract DE-AT03-76ER72018."
            },
            "venue": {
                "fragments": [],
                "text": "TOMS"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080288"
                        ],
                        "name": "C. Paige",
                        "slug": "C.-Paige",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Paige",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Paige"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145621255"
                        ],
                        "name": "M. Saunders",
                        "slug": "M.-Saunders",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Saunders",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Saunders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "Similarly, the algorithms for Au and ATv can be used directly in conjugate-gradient methods such as LSQR [32, 33] for solving the least-squares problem (6.5)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 104
                            }
                        ],
                        "text": "Similarly, the algorithms for Au and Av can be used directly in conjugate-gradient methods such as LSQR [32, 33] for solving the least-squares problem (6."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 21774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30cadff20998ea7bea6da42fa0eed48334fdde1e",
            "isKey": false,
            "numCitedBy": 3906,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "An iterative method is given for solving Ax ~ffi b and minU Ax b 112, where the matrix A is large and sparse. The method is based on the bidiagonalization procedure of Golub and Kahan. It is analytically equivalent to the standard method of conjugate gradients, but possesses more favorable numerical properties. Reliable stopping criteria are derived, along with estimates of standard errors for x and the condition number of A. These are used in the FORTRAN implementation of the method, subroutine LSQR. Numerical tests are described comparing I~QR with several other conjugate-gradient algorithms, indicating that I~QR is the most reliable algorithm when A is ill-conditioned."
            },
            "slug": "LSQR:-An-Algorithm-for-Sparse-Linear-Equations-and-Paige-Saunders",
            "title": {
                "fragments": [],
                "text": "LSQR: An Algorithm for Sparse Linear Equations and Sparse Least Squares"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Numerical tests are described comparing I~QR with several other conjugate-gradient algorithms, indicating that I ~QR is the most reliable algorithm when A is ill-conditioned."
            },
            "venue": {
                "fragments": [],
                "text": "TOMS"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47003307"
                        ],
                        "name": "Yuying Li",
                        "slug": "Yuying-Li",
                        "structuredName": {
                            "firstName": "Yuying",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuying Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737945"
                        ],
                        "name": "F. Santosa",
                        "slug": "F.-Santosa",
                        "structuredName": {
                            "firstName": "Fadil",
                            "lastName": "Santosa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Santosa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Li and Santosa [22] have developed an alternative algorithm for this problem based on interior-point methods for convex optimization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14212641,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "980475959280d12e9c92b52eea10eea059752f70",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A computational algorithm is proposed for image enhancement based on total variation minimization with constraints. This constrained minimization problem is introduced by Rudin et al \\cite{osher1,osher3,osher2} to enhance blurred and noisy images. Our computational algorithm solves the constrained minimization problem directly by adapting the affine scaling method for the unconstrained $l_1$ problem \\cite{CL89}. The resulting computational scheme, when viewed as an image enhancement process, has the feature that it can be used in an interactive manner in situations where knowledge of the noise level is either unavailable or unreliable. This computational algorithm can be implemented with a conjugate gradient method. It is further demonstrated that the iterative enhancement process is efficient."
            },
            "slug": "An-Affine-Scaling-Algorithm-for-Minimizing-Total-in-Li-Santosa",
            "title": {
                "fragments": [],
                "text": "An Affine Scaling Algorithm for Minimizing Total Variation in Image Enhancement"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The resulting computational scheme, when viewed as an image enhancement process, has the feature that it can be used in an interactive manner in situations where knowledge of the noise level is either unavailable or unreliable."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1932759"
                        ],
                        "name": "M. Todd",
                        "slug": "M.-Todd",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Todd",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Todd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 218
                            }
                        ],
                        "text": "A good overview of the recent rapid progress in this eld and the current state of the art is a orded by the article of Lustig, Marsten and Shanno [23] and the accompanying discussions by Bixby [1], Saunders [36], Todd [38], and Vanderbei [39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207225616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5e39db8acaac0016b1ed59e9900c5c0cea17c91",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The last decade has been a fascinating time for researchers interested in linear programming and its extensions. It opened with Narendra Karmarkar's theoretical paper on the computational complexity of linear programming problems and his claims that his method solved problems 50 times faster than the simplex method. After 10 years of development in both interior-point and simplex methods, we are now at a point at which both approaches can handle problems that seemed intractable before, but where interior-point methods seem to be superior to simplex algorithms for many very large-scale sparse linear programming problems. Lustig, Marsten, and Shanno (LMS) provide an excellent overview of these advances, particularly with respect to their computational significance. Of course, they have been major contributors to the development of interior-point algorithms as well as of sophisticated implementations with their OB1 code. Their experience leads to many interesting insights and also raises some questions: why ..."
            },
            "slug": "Commentary-Theory-and-Practice-for-Interior-Point-Todd",
            "title": {
                "fragments": [],
                "text": "Commentary - Theory and Practice for Interior-Point Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "L Lustig, Marsten, and Shanno (LMS) provide an excellent overview of these advances in interior-point algorithms, particularly with respect to their computational significance."
            },
            "venue": {
                "fragments": [],
                "text": "INFORMS J. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143676697"
                        ],
                        "name": "Y. Nesterov",
                        "slug": "Y.-Nesterov",
                        "structuredName": {
                            "firstName": "Yurii",
                            "lastName": "Nesterov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nesterov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145853268"
                        ],
                        "name": "A. Nemirovski",
                        "slug": "A.-Nemirovski",
                        "structuredName": {
                            "firstName": "Arkadi",
                            "lastName": "Nemirovski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nemirovski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "Since then a very wide array of interior-point algorithms have been proposed and considerable practical [23] and theoretical [30] understanding is now available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117194167,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d479fbf514db0362e90d9d81f246318a6afb8004",
            "isKey": false,
            "numCitedBy": 3492,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Written for specialists working in optimization, mathematical programming, or control theory. The general theory of path-following and potential reduction interior point polynomial time methods, interior point methods, interior point methods for linear and quadratic programming, polynomial time methods for nonlinear convex programming, efficient computation methods for control problems and variational inequalities, and acceleration of path-following methods are covered. In this book, the authors describe the first unified theory of polynomial-time interior-point methods. Their approach provides a simple and elegant framework in which all known polynomial-time interior-point methods can be explained and analyzed; this approach yields polynomial-time interior-point methods for a wide variety of problems beyond the traditional linear and quadratic programs. The book contains new and important results in the general theory of convex programming, e.g., their \"conic\" problem formulation in which duality theory is completely symmetric. For each algorithm described, the authors carefully derive precise bounds on the computational effort required to solve a given family of problems to a given precision. In several cases they obtain better problem complexity estimates than were previously known. Several of the new algorithms described in this book, e.g., the projective method, have been implemented, tested on \"real world\" problems, and found to be extremely efficient in practice. Contents : Chapter 1: Self-Concordant Functions and Newton Method; Chapter 2: Path-Following Interior-Point Methods; Chapter 3: Potential Reduction Interior-Point Methods; Chapter 4: How to Construct Self- Concordant Barriers; Chapter 5: Applications in Convex Optimization; Chapter 6: Variational Inequalities with Monotone Operators; Chapter 7: Acceleration for Linear and Linearly Constrained Quadratic Problems"
            },
            "slug": "Interior-point-polynomial-algorithms-in-convex-Nesterov-Nemirovski",
            "title": {
                "fragments": [],
                "text": "Interior-point polynomial algorithms in convex programming"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This book describes the first unified theory of polynomial-time interior-point methods, and describes several of the new algorithms described, e.g., the projective method, which have been implemented, tested on \"real world\" problems, and found to be extremely efficient in practice."
            },
            "venue": {
                "fragments": [],
                "text": "Siam studies in applied mathematics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378746"
                        ],
                        "name": "N. Karmarkar",
                        "slug": "N.-Karmarkar",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Karmarkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Karmarkar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 222
                            }
                        ],
                        "text": "Much of the rapid expansion in the size of linear programs solved is due to the \\Interior Point revolution\" initiated by Karmarkar's proof that a pseudo-polynomial time algorithm could be based on an interior-point method [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7257867,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "dbf8aa1e547c863f509a5a4c03a39fa9c92c9651",
            "isKey": false,
            "numCitedBy": 4005,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new polynomial-time algorithm for linear programming. In the worst case, the algorithm requiresO(n3.5L) arithmetic operations onO(L) bit numbers, wheren is the number of variables andL is the number of bits in the input. The running-time of this algorithm is better than the ellipsoid algorithm by a factor ofO(n2.5). We prove that given a polytopeP and a strictly interior point a \u03b5P, there is a projective transformation of the space that mapsP, a toP\u2032, a\u2032 having the following property. The ratio of the radius of the smallest sphere with center a\u2032, containingP\u2032 to the radius of the largest sphere with center a\u2032 contained inP\u2032 isO(n). The algorithm consists of repeated application of such projective transformations each followed by optimization over an inscribed sphere to create a sequence of points which converges to the optimal solution in polynomial time."
            },
            "slug": "A-new-polynomial-time-algorithm-for-linear-Karmarkar",
            "title": {
                "fragments": [],
                "text": "A new polynomial-time algorithm for linear programming"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is proved that given a polytopeP and a strictly interior point a \u03b5P, there is a projective transformation of the space that mapsP, a toP\u2032, a\u2032 having the following property: the ratio of the radius of the smallest sphere with center a\u2032, containingP\u2032 to theradius of the largest sphere withCenter a\u2032 contained inP\u2032 isO(n)."
            },
            "venue": {
                "fragments": [],
                "text": "Comb."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685738"
                        ],
                        "name": "M. H. Wright",
                        "slug": "M.-H.-Wright",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Wright",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. H. Wright"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For fuller discussions of this and related algorithms, again see [20,  49 , 27, 50, 40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "practical [25, 27, 32, 50] and theoretical [ 49 , 35, 40] understanding is now available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We cannot summarize all these ideas here; many of them are mentioned in [ 49 , 27, 50, 40], for example."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121970817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f28d164d99e0f1b8ca237fa6e062aad17e96242",
            "isKey": true,
            "numCitedBy": 277,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Interior methods for optimization were widely used in the 1960s, primarily in the form of barrier methods. However, they were not seriously applied to linear programming because of the dominance of the simplex method. Barrier methods fell from favour during the 1970s for a variety of reasons, including their apparent inefficiency compared with the best available alternatives. In 1984, Karmarkar's announcement of a fast polynomial-time interior method for linear programming caused tremendous excitement in the field of optimization. A formal connection can be shown between his method and classical barrier methods, which have consequently undergone a renaissance in interest and popularity. Most papers published since 1984 have concentrated on issues of computational complexity in interior methods for linear programming. During the same period, implementations of interior methods have displayed great efficiency in solving many large linear programs of ever-increasing size. Interior methods have also been applied with notable success to nonlinear and combinatorial problems. This paper presents a self-contained survey of major themes in both classical material and recent developments related to the theory and practice of interior methods."
            },
            "slug": "Interior-methods-for-constrained-optimization-Wright",
            "title": {
                "fragments": [],
                "text": "Interior methods for constrained optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A self-contained survey of major themes in both classical material and recent developments related to the theory and practice of interior methods for linear programming is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Acta Numerica"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1986103"
                        ],
                        "name": "R. Vanderbei",
                        "slug": "R.-Vanderbei",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Vanderbei",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vanderbei"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 238
                            }
                        ],
                        "text": "A good overview of the recent rapid progress in this eld and the current state of the art is a orded by the article of Lustig, Marsten and Shanno [23] and the accompanying discussions by Bixby [1], Saunders [36], Todd [38], and Vanderbei [39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1194844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15746958f80c5a73af923cfbf70c04fb5a3cf75c",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper by Lustig, Marsten, and Shanno (LMS) gives an excellent presentation of the current state of the art for interior-point methods (as represented by their OB1 code) as it compares to the current state of the art for the simplex method (represented by OSL). The paper is well organized and thoughtful. The results of their experiments clearly indicate that for large problems interior-point methods offer a serious alternative to the simplex method. In these comments, we will try to clarify the relation among some of the algorithms discussed in LMS. In addition, we will compare the implementation strategy described in LMS, which is based on solving the so-called normal equations, to an alternative implementation strategy based on solving the so-called reduced Karush-Kuhn-Tucker (KKT) system. We will show that for many problems the two approaches yield virtually identical results but, for certain classes of challenging problems, the reduced KKT approach yields a much more efficient code. Also, we will a..."
            },
            "slug": "Commentary-Interior-Point-Methods:-Algorithms-and-Vanderbei",
            "title": {
                "fragments": [],
                "text": "Commentary - Interior-Point Methods: Algorithms and Formulations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The implementation strategy described in LMS is compared to an alternative implementation strategy based on solving the so-called reduced Karush-Kuhn-Tucker (KKT) system and it is shown that for many problems the two approaches yield virtually identical results but the reduced KKT approach yields a much more efficient code."
            },
            "venue": {
                "fragments": [],
                "text": "INFORMS J. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706816"
                        ],
                        "name": "N. Megiddo",
                        "slug": "N.-Megiddo",
                        "structuredName": {
                            "firstName": "Nimrod",
                            "lastName": "Megiddo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Megiddo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "practical [25, 27,  32 , 50] and theoretical [49, 35, 40] understanding is now available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12960172,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "feef559e5906dcfbf06ed6ec3969d885435b008c",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that if there exists a strongly polynomial time algorithm that finds a basis which is optimal for both the primal and the dual problems, given an optimal solution for one of the problems, then there exists a strongly polynomial algorithm for the general linear programming problem. On the other hand, we give a strongly polynomial time algorithm that finds such a basis, given any pair of optimal solutions (not necessarily basic) for the primal and the dual problems. Such an algorithm is needed when one is using an interior point method and is interested in finding a basis which is both primal- and dual-optimal. INFORMS Journal on Computing, ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499."
            },
            "slug": "On-Finding-Primal-and-Dual-Optimal-Bases-Megiddo",
            "title": {
                "fragments": [],
                "text": "On Finding Primal- and Dual-Optimal Bases"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "It is shown that if there exists a strongly polynomial time algorithm that finds a basis which is optimal for both the primal and the dual problems, given an optimal solution for one of the problems, then there exist a stronglyPolynomial algorithm for the general linear programming problem."
            },
            "venue": {
                "fragments": [],
                "text": "INFORMS J. Comput."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145621255"
                        ],
                        "name": "M. Saunders",
                        "slug": "M.-Saunders",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Saunders",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Saunders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 17
                            }
                        ],
                        "text": "Recently Michael Saunders and Shaobing Chen have shown [4] that (5.1) is equiv-\nalent to the following perturbed linear program:\nmincTx+ 1\n2 kpk2 subject to Ax+ p = b; x 0; = 1\nwhere A = ( ; ); b = y; c = 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "In the current state of the art of linear programming [36], one attempts to do this by exploiting sparsity of the underlying matrix A."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 207
                            }
                        ],
                        "text": "A good overview of the recent rapid progress in this eld and the current state of the art is a orded by the article of Lustig, Marsten and Shanno [23] and the accompanying discussions by Bixby [1], Saunders [36], Todd [38], and Vanderbei [39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40450104,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "323dedcbb8e6679eed514f3607f11e38cf1ebc0e",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Probably more than any other group, authors Lustig, Marsten, and Shanno have led the way in demonstrating the effectiveness of interior methods for solving large, real-world linear programs. For several years they have written at length about things they have actually done. There are no pies in the sky, no secrets. They have explored a multitude of algorithmic ideas and implementation strategies, and they have done more than could be asked to share their experience with the rest of the world. Here, the authors look back on a decade's events that revived barrier methods for constrained optimization and eventually led to their production LP solver OB1. The results reported are indeed impressive. In this commentary, we focus mostly on the \u201cengine\u201d\u2014the Cholesky factorizer\u2014that has made OB1 such a practical success. INFORMS Journal on Computing, ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499."
            },
            "slug": "Commentary-Major-Cholesky-Would-Feel-Proud-Saunders",
            "title": {
                "fragments": [],
                "text": "Commentary - Major Cholesky Would Feel Proud"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Here, the authors look back on a decade's events that revived barrier methods for constrained optimization and eventually led to their production LP solver OB1 and focus mostly on the \u201cengine\u201d\u2014the Cholesky factorizer\u2014that has made OB1 such a practical success."
            },
            "venue": {
                "fragments": [],
                "text": "INFORMS J. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709392"
                        ],
                        "name": "D. Donoho",
                        "slug": "D.-Donoho",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Donoho",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Donoho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2364792"
                        ],
                        "name": "I. Johnstone",
                        "slug": "I.-Johnstone",
                        "structuredName": {
                            "firstName": "Iain",
                            "lastName": "Johnstone",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Johnstone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Best orthogonal basis denoising (BOBDN) is a thresholding scheme in the basis chosen by the BOB algorithm with a special entropy [ 16 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17008380,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a6ff4e21143fbb73192bfb9a474f1f15a2f5016e",
            "isKey": false,
            "numCitedBy": 373,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Nous decrivons une extension de la methode de la \u00abmeilleure base\u00bb qui permet de selectionner, a partir de donnees bruitees, une base orthonormee dans laquelle le debruitage est d'efficacite presque ideale"
            },
            "slug": "Ideal-denoising-in-an-orthonormal-basis-chosen-from-Donoho-Johnstone",
            "title": {
                "fragments": [],
                "text": "Ideal denoising in an orthonormal basis chosen from a library of bases"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47910698"
                        ],
                        "name": "R. Coifman",
                        "slug": "R.-Coifman",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Coifman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Coifman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40154333"
                        ],
                        "name": "Y. Meyer",
                        "slug": "Y.-Meyer",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Meyer",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Meyer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "Recently, Coifman and Meyer [6] developed the wavelet packet and cosine packet dictionaries especially to meet the computational demands of discrete-time signal processing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 23
                            }
                        ],
                        "text": "An important contrast: Meyer has a counterexample to multi-scale edge approaches, showing that the Mallat-Zhong approach may fail in certain cases [29]; but there can be no such counterexamples to BP.\n4.2."
                    },
                    "intents": []
                }
            ],
            "corpusId": 190188704,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "536345bdb6921f7fb61da0fa035d392f14866a38",
            "isKey": true,
            "numCitedBy": 274,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In the context of windowed Fourier analysis, new orthonormal bases are constructed and provide a local Fourier analysis that can be adapted to arbitrary windows Dans le contexte general de l'analyse de Fourier a fenetre, nous construisons de nouvelles bases orthonormees que l'on peut adapter a n'importe quelle segmentation"
            },
            "slug": "Remarques-sur-l'analyse-de-Fourier-\u00e0-fen\u00eatre-Coifman-Meyer",
            "title": {
                "fragments": [],
                "text": "Remarques sur l'analyse de Fourier \u00e0 fen\u00eatre"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145457164"
                        ],
                        "name": "Kees Roos",
                        "slug": "Kees-Roos",
                        "structuredName": {
                            "firstName": "Kees",
                            "lastName": "Roos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kees Roos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722879"
                        ],
                        "name": "T. Terlaky",
                        "slug": "T.-Terlaky",
                        "structuredName": {
                            "firstName": "Tam\u00e1s",
                            "lastName": "Terlaky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Terlaky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145566894"
                        ],
                        "name": "J. Vial",
                        "slug": "J.-Vial",
                        "structuredName": {
                            "firstName": "Jean-Philippe",
                            "lastName": "Vial",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vial"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For fuller discussions of this and related algorithms, again see [20, 49, 27, 50,  40 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We cannot summarize all these ideas here; many of them are mentioned in [49, 27, 50,  40 ], for example."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "practical [25, 27, 32, 50] and theoretical [49, 35,  40 ] understanding is now available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32992663,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3ab2bcb8721b7c295c5c6b8a4deb48951ffb2a26",
            "isKey": true,
            "numCitedBy": 606,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Partial table of contents: INTRODUCTION: THEORY AND COMPLEXITY. Duality Theory for Linear Optimization. A Polynomial Algorithm for the Skew-Symmetric Model. Solving the Canonical Problem. THE LOGARITHMIC BARRIER APPROACH. The Dual Logarithmic Barrier Method. Initialization. THE TARGET-FOLLOWING APPROACH. The Primal-Dual Newton Method. Application to the Method of Centers. MISCELLANEOUS TOPICS. Karmarkar's Projective Method. More Properties of the Central Path. Partial Updating. High-Order Methods. Parametric and Sensitivity Analysis. Implementing Interior Point Methods. Appendices. Bibliography. Indexes."
            },
            "slug": "Theory-and-algorithms-for-linear-optimization-an-Roos-Terlaky",
            "title": {
                "fragments": [],
                "text": "Theory and algorithms for linear optimization - an interior point approach"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This chapter discusses duality Theory for Linear Optimization, a Polynomial Algorithm for the Skew-Symmetric Model, and Parametric and Sensitivity Analysis, as well as implementing Interior Point Methods."
            },
            "venue": {
                "fragments": [],
                "text": "Wiley-Interscience series in discrete mathematics and optimization"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2687592"
                        ],
                        "name": "M. Kojima",
                        "slug": "M.-Kojima",
                        "structuredName": {
                            "firstName": "Masakazu",
                            "lastName": "Kojima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kojima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118530872"
                        ],
                        "name": "S. Mizuno",
                        "slug": "S.-Mizuno",
                        "structuredName": {
                            "firstName": "Shinji",
                            "lastName": "Mizuno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mizuno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783421"
                        ],
                        "name": "Akiko Yoshise",
                        "slug": "Akiko-Yoshise",
                        "structuredName": {
                            "firstName": "Akiko",
                            "lastName": "Yoshise",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akiko Yoshise"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "practical [ 25 , 27, 32, 50] and theoretical [49, 35, 40] understanding is now available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118545545,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5dc5871971caa9ca13f1c0833f81e889248d688c",
            "isKey": false,
            "numCitedBy": 511,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter presents an algorithm that works simultaneously on primal and dual linear programming problems and generates a sequence of pairs of their interior feasible solutions. Along the sequence generated, the duality gap converges to zero at least linearly with a global convergence ratio (1 \u2014 \u03b7/n); each iteration reduces the duality gap by at least \u03b7/n. Here n denotes the size of the problems and \u03b7 a positive number depending on initial interior feasible solutions of the problems. The algorithm is based on an application of the classical logarithmic barrier function method to primal and dual linear programs, which has recently been proposed and studied by Megiddo."
            },
            "slug": "A-primal-dual-interior-point-algorithm-for-linear-Kojima-Mizuno",
            "title": {
                "fragments": [],
                "text": "A primal-dual interior point algorithm for linear programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2895664"
                        ],
                        "name": "J. B. Buckheit",
                        "slug": "J.-B.-Buckheit",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Buckheit",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. B. Buckheit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709392"
                        ],
                        "name": "D. Donoho",
                        "slug": "D.-Donoho",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Donoho",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Donoho"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "This paper has been written following the discipline of Reproducible Research described in [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16424339,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "ca6ac901df1ce9b6a080997e9384cfda50f0265a",
            "isKey": false,
            "numCitedBy": 557,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Wavelab is a library of wavelet-packet analysis, cosine-packet analysis and matching pursuit. The library is available free of charge over the Internet. Versions are provided for Macintosh, UNIX and Windows machines."
            },
            "slug": "WaveLab-and-Reproducible-Research-Buckheit-Donoho",
            "title": {
                "fragments": [],
                "text": "WaveLab and Reproducible Research"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Wavelab is a library of wavelet-packet analysis, cosine- Packet analysis and matching pursuit, available free of charge over the Internet."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780827"
                        ],
                        "name": "R. Bixby",
                        "slug": "R.-Bixby",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bixby",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bixby"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 193
                            }
                        ],
                        "text": "A good overview of the recent rapid progress in this eld and the current state of the art is a orded by the article of Lustig, Marsten and Shanno [23] and the accompanying discussions by Bixby [1], Saunders [36], Todd [38], and Vanderbei [39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20010900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d14a9bc65a7b50aa32794415f9efe6b6ca580026",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "There is little doubt that barrier methods are now indispensable tools in the solution of large-scale linear programming problems. However, it is our opinion that the results of Lustig, Marsten, and Shanno (hereafter LMS) somewhat overstate the performance of these methods relative to the simplex method. We will present a slightly different view of progress in linear programming, one in which barrier methods do not dominate in the solution of large-scale problems. INFORMS Journal on Computing , ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499."
            },
            "slug": "Commentary-Progress-in-Linear-Programming-Bixby",
            "title": {
                "fragments": [],
                "text": "Commentary - Progress in Linear Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is suggested that the results of Lustig, Marsten, and Shanno (hereafter LMS) somewhat overstate the performance of these methods relative to the simplex method."
            },
            "venue": {
                "fragments": [],
                "text": "INFORMS J. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26373808"
                        ],
                        "name": "R. DeVore",
                        "slug": "R.-DeVore",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "DeVore",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. DeVore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755101"
                        ],
                        "name": "V. Temlyakov",
                        "slug": "V.-Temlyakov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Temlyakov",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Temlyakov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "DeVore [12], one constructs a dictionary having n+1 atoms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15510358,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "564bd7d86621ba639e0f94761cf45f1c29e068f1",
            "isKey": false,
            "numCitedBy": 510,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Estimates are given for the rate of approximation of a function by means of greedy algorithms. The estimates apply to approximation from an arbitrary dictionary of functions. Three greedy algorithms are discussed: the Pure Greedy Algorithm, an Orthogonal Greedy Algorithm, and a Relaxed Greedy Algorithm."
            },
            "slug": "Some-remarks-on-greedy-algorithms-DeVore-Temlyakov",
            "title": {
                "fragments": [],
                "text": "Some remarks on greedy algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Three greedy algorithms are discussed: the Pure GreedyAlgorithm, an Orthogonal Greedy Algorithm, and a Relaxed Gre greedy Algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput. Math."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744288"
                        ],
                        "name": "P. Gill",
                        "slug": "P.-Gill",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Gill",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143873253"
                        ],
                        "name": "W. Murray",
                        "slug": "W.-Murray",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Murray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802641"
                        ],
                        "name": "D. Poncele\u00f3n",
                        "slug": "D.-Poncele\u00f3n",
                        "structuredName": {
                            "firstName": "Dulce",
                            "lastName": "Poncele\u00f3n",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Poncele\u00f3n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145621255"
                        ],
                        "name": "M. Saunders",
                        "slug": "M.-Saunders",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Saunders",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Saunders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[17] proposed solving the following perturbed LP:"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "Our strategy for routine signal processing by BP is as follows: We employ the \\primal-dual logarithmic barrier method\" for perturbed LP [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "(c) Duality Gap = z T x 1+kzk2kxk2 < PDGapTol: For fuller discussions of this and related algorithms, again see [17] or references there."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Perturbed linear programming is really quadratic programming, but retains structure similar to linear programming [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 674401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91c4bdee8379dfd253ff4b4db8df5dbe7da8bf3a",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : In barrier methods for constrained optimization, the main work lies in solving large linear systems Kp = r, where K is symmetric and indefinite. We have implemented reduced KKT systems in a primal-dual algorithm for linear programming, based on the sparse indefinite solver MA27 from the Harwell Subroutine Library. Some features of the algorithm are presented, along with results on the netlib LP test set."
            },
            "slug": "Solving-Reduced-KKT-Systems-in-Barrier-Methods-for-Gill-Murray",
            "title": {
                "fragments": [],
                "text": "Solving Reduced KKT Systems in Barrier Methods for Linear and Quadratic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work has implemented reduced KKT systems in a primal-dual algorithm for linear programming, based on the sparse indefinite solver MA27 from the Harwell Subroutine Library."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116307686"
                        ],
                        "name": "Richard J. Coppins",
                        "slug": "Richard-J.-Coppins",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Coppins",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard J. Coppins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69560838"
                        ],
                        "name": "Nesa L'abbe Wu",
                        "slug": "Nesa-L'abbe-Wu",
                        "structuredName": {
                            "firstName": "Nesa",
                            "lastName": "Wu",
                            "middleNames": [
                                "L'abbe"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nesa L'abbe Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 46
                            }
                        ],
                        "text": "The linear program in so-called standard form [8, 18] is a constrained optimization problem de ned in terms of a variable x 2 R by mincx subject to Ax = b; x 0 ; (3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60017879,
            "fieldsOfStudy": [
                "Business",
                "Mathematics",
                "Computer Science"
            ],
            "id": "24a183b16c5c9ee803e8af3daa1ac5164c6e19e3",
            "isKey": false,
            "numCitedBy": 1894,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "\uf0b7 Formulation skills for problems as a deterministic linear mathematical model (linear programming, goal (multi-objective) programming, integer programming, transportation, transshipment) \uf0b7 Travel Sales Person (TSP) problems \uf0b7 Simplex method for solving linear programming (LP) \uf0b7 Dual of an LP and its application \uf0b7 Extensive sensitivity analysis to answer \u201cwhat if\u201d questions (for all models) \uf0b7 Application of software to solve the problems"
            },
            "slug": "Linear-programming-and-extensions-Coppins-Wu",
            "title": {
                "fragments": [],
                "text": "Linear programming and extensions"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Formulation skills for problems as a deterministic linear mathematical model, application of software to solve the problems and extensive sensitivity analysis to answer \u201cwhat if\u201d questions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 82
                            }
                        ],
                        "text": "The DeVore-Temlyakov example applies to the original MP algorithm as announced by Mallat and Zhang in 1992."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Matching Pursuit De-Noising (MPDN) runs Matching Pursuit until the coe cient\nassociated with the selected atom gets below the threshold p 2 log(p)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "These range from general approaches, like the Method of Frames [9], and the method of Matching Pursuit [25], to clever schemes derived for specialized dictionaries, like the method of Best Orthogonal Basis [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 11
                            }
                        ],
                        "text": "Orthogonal Matching Pursuit starts from an \\empty model\" and builds up a signal model an atom at a time, at each step adding to the model only the most important new atom among all those not so far in the model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "We use terminology introduced by Mallat and Zhang [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 85
                            }
                        ],
                        "text": "Because it is based on global optimization, it can stably super-resolve in ways that Matching Pursuit can not."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Mallat and Zhang [25] have discussed a general method for approximate decomposition (1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 115
                            }
                        ],
                        "text": "Overcomplete signal representation, De-Noising, Time-Frequency Analysis, TimeScale Analysis, `1 norm optimization, Matching Pursuit, Wavelets, Wavelet Packets, Cosine Packets, Interior-point methods for linear programming, Total Variation De-Noising, Multi-Scale Edges."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Matching Pursuit."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Mallat and Zhang [25] have discussed a general method for approximate decomposition (1.2) that addresses the sparsity issue directly."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 33
                            }
                        ],
                        "text": "This method is called Orthogonal Matching Pursuit (OMP) by Pati [34]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Matching Pursuit in a time-frequency dictionary"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Signal Processing, 41 "
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 278
                            }
                        ],
                        "text": "Experiments with standard time-frequency dictionaries indicate some of the potential bene ts of BP. Experiments with some nonstandard dictionaries { like the stationary wavelet dictionary and the Heaviside dictionary { indicate important connections between BP and methods like Mallat\nand Zhong's Multi-Scale Edge Representation and Osher, Rudin and Fatemi's Total Variation-based De-Noising methods."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Mallat and Zhong proposed an iterative method that reconstructs an object having the same values of the CWT at \\maxima\"."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 106
                            }
                        ],
                        "text": "An important contrast: Meyer has a counterexample to multi-scale edge approaches, showing that the Mallat-Zhong approach may fail in certain cases [29]; but there can be no such counterexamples to BP.\n4.2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 204
                            }
                        ],
                        "text": "There is a surprisingly close agreement of the BP representation in a stationary wavelet dictionary with ideas about signal representation associated with the \\MultiScale Edges\" ideas of Mallat and Zhong [26, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wavelet Transform Maxima and MultiScale Edges"
            },
            "venue": {
                "fragments": [],
                "text": "Ruskai et al., eds, Wavelet and their applications, Boston: Jones and Bartlett"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40154333"
                        ],
                        "name": "Y. Meyer",
                        "slug": "Y.-Meyer",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Meyer",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Meyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Although the rules of construction are more complicated (boundary conditions [28], orthogonality versus bi-orthogonality [10], etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120589655,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4d33ca7af6cb72d739c3262c144adef5c1838b26",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Ondelettes-sur-l'intervalle.-Meyer",
            "title": {
                "fragments": [],
                "text": "Ondelettes sur l'intervalle."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16298171"
                        ],
                        "name": "D. Gabor",
                        "slug": "D.-Gabor",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Gabor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gabor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61327032,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8ef7e8990527f01847845da9953896f35e489d5",
            "isKey": false,
            "numCitedBy": 4630,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theory-of-communication-Gabor",
            "title": {
                "fragments": [],
                "text": "Theory of communication"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1946
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744288"
                        ],
                        "name": "P. Gill",
                        "slug": "P.-Gill",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Gill",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143873253"
                        ],
                        "name": "W. Murray",
                        "slug": "W.-Murray",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Murray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685738"
                        ],
                        "name": "M. H. Wright",
                        "slug": "M.-H.-Wright",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Wright",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. H. Wright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 46
                            }
                        ],
                        "text": "The linear program in so-called standard form [8, 18] is a constrained optimization problem de ned in terms of a variable x 2 R by mincx subject to Ax = b; x 0 ; (3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "Moreover, LP researchers have shown how one can select terms to swap in such a way as to guarantee convergence to an optimal solution (anti-cycling rules) [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 204
                            }
                        ],
                        "text": "Of course, in general solving systems of equations is not rapid: a general n by n system Bw = h takes order O(n(3)) time to solve by standard elimination methods or by modern stable factorization schemes [19, 18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117910111,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4ed7857396dd00b811a0caea8f7dc61323cf40ea",
            "isKey": false,
            "numCitedBy": 471,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Numerical-Linear-Algebra-and-Optimization-Gill-Murray",
            "title": {
                "fragments": [],
                "text": "Numerical Linear Algebra and Optimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "Formal arguments similar to those in [15] can be used to give a proof that meansquared error properties of the resulting procedure are near-optimal under certain conditions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Empirical atomic decomposition"
            },
            "venue": {
                "fragments": [],
                "text": "Manuscript"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "An important contrast: Meyer has a counterexample to multi-scale edge approaches, showing that the Mallat-Zhong approach may fail in certain cases [29]; but there can be no such counterexamples to BP."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wavelets: Algorithms and Applications"
            },
            "venue": {
                "fragments": [],
                "text": "SIAM, Philadelphia"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "(The equivalence of minimum `(1) optimizations with linear programming has been known since the 1950's; see [2])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Least Absolute Deviations: Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Applications, and Algorithms, Birkhauser, Boston"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "In the case of a dictionary that is an orthonormal basis, a number of papers [13, 16] have carefully studied an approach to de-noising by so-called \\soft-thresholding in an orthonormal basis\"."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wavelet shrinkage: asymptopia? Journal of the Royal Statistical Society"
            },
            "venue": {
                "fragments": [],
                "text": "Series B, 57 "
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 25,
            "methodology": 24
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 44,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Atomic-Decomposition-by-Basis-Pursuit-Chen-Donoho/9af121fbed84c3484ab86df8f17f1f198ed790a0?sort=total-citations"
}