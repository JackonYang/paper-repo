{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277853"
                        ],
                        "name": "A. Vailaya",
                        "slug": "A.-Vailaya",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Vailaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vailaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "[4] A. Vailaya and A. Jain, \u201cDetecting sky and vegetation in outdoor images\u201d, Proc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "More recently, Vailaya and Jain [4] presented an exemplar-based approach that uses a combination of color and texture features to classify sub-blocks (16 \u00d7 16 pixels) in an outdoor scene as sky or vegetation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 42603343,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fed3c3eb2d9a80dba7c3b0794b99c476bed0d411",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Developing semantic indices into large image databases is a challenging and important problem in content-based image retrieval. We address the problem of detecting objects in an image based on color and texture features. Specifically, we consider the following two problems of detecting sky and vegetation in outdoor images. An image is divided into 16 X 16 sub-blocks and color, texture, and position features are extracted form every sub-block. We demonstrate how a small set of codebook vectors, extracted from every sub- block. We demonstrate how a small set of codebook vectors, extracted from a learning vector quantizer, can be used to estimate the class-conditional densities of the low-level observed feature needed for the Bayesian methodology. The sky and vegetation detectors have been trained on over 400 color images from the Corel database. We achieve classification accuracies of over 94 percent for both the classifiers on the training data. We are currently extending our evaluation to a larger database of 1,700 images."
            },
            "slug": "Detecting-sky-and-vegetation-in-outdoor-images-Vailaya-Jain",
            "title": {
                "fragments": [],
                "text": "Detecting sky and vegetation in outdoor images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is demonstrated how a small set of codebook vectors, extracted from a learning vector quantizer, can be used to estimate the class-conditional densities of the low-level observed feature needed for the Bayesian methodology."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2123706"
                        ],
                        "name": "P. Lipson",
                        "slug": "P.-Lipson",
                        "structuredName": {
                            "firstName": "Pamela",
                            "lastName": "Lipson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lipson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9] present a spatial context modeling approach, called configuration-based scene modeling, for content-based indexing and retrieval applications."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206589454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8cf3f0ea76961eca50bf26ab31e677037cab622",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene classification is a major open challenge in machine vision. Most solutions proposed so far such as those based on color histograms and local texture statistics cannot capture a scene's global configuration, which is critical in perceptual judgments of scene similarity. We present a novel approach, \"configural recognition\", for encoding scene class structure. The approach's main feature is its use of qualitative spatial and photometric relationships within and across regions in low resolution images. The emphasis on qualitative measures leads to enhanced generalization abilities and the use of low-resolution images renders the scheme computationally efficient. We present results on a large database of natural scenes. We also describe how qualitative scene concepts may be learned from examples."
            },
            "slug": "Configuration-based-scene-classification-and-image-Lipson-Grimson",
            "title": {
                "fragments": [],
                "text": "Configuration based scene classification and image indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel approach, \"configural recognition\", for encoding scene class structure using qualitative spatial and photometric relationships within and across regions in low resolution images and how qualitative scene concepts may be learned from examples is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144242236"
                        ],
                        "name": "J. Batlle",
                        "slug": "J.-Batlle",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Batlle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Batlle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144921705"
                        ],
                        "name": "A. Casals",
                        "slug": "A.-Casals",
                        "structuredName": {
                            "firstName": "Alicia",
                            "lastName": "Casals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Casals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797590"
                        ],
                        "name": "J. Freixenet",
                        "slug": "J.-Freixenet",
                        "structuredName": {
                            "firstName": "Jordi",
                            "lastName": "Freixenet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Freixenet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153913367"
                        ],
                        "name": "J. Mart\u00ed",
                        "slug": "J.-Mart\u00ed",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Mart\u00ed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mart\u00ed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[8] provide a comprehensive review of most of the work related to building scene models for specific image types."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18313105,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9f8c022044375ba5dea30040822c3cad1b55442",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-review-on-strategies-for-recognizing-natural-in-Batlle-Casals",
            "title": {
                "fragments": [],
                "text": "A review on strategies for recognizing natural objects in colour images of outdoor scenes"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145163573"
                        ],
                        "name": "A. Singhal",
                        "slug": "A.-Singhal",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Singhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singhal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33642939"
                        ],
                        "name": "Jiebo Luo",
                        "slug": "Jiebo-Luo",
                        "structuredName": {
                            "firstName": "Jiebo",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiebo Luo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 171
                            }
                        ],
                        "text": "We have implemented a number of individual material detectors that combine low-level features with some unique region analysis to generate individual material belief maps [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 165
                            }
                        ],
                        "text": "While some of these individual material detectors (such as sky) have very good performance because of material-specific region analysis that removes false positives [5], other material detectors such as open water and snowfields have substantially high false positive detection rates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61118486,
            "fieldsOfStudy": [
                "Physics",
                "Environmental Science"
            ],
            "id": "9051e773e660860ba7dc7b339fef1975149bf808",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Sky is among the semantic object classes frequently seen in photographs and useful for image understanding, processing, and retrieval. We propose a novel hybrid approach to sky detection; based on color and texture classification, region extraction, and physics motivated sky signature validation. Sky can be of many different types; clear blue sky, cloudy/overcast sky, mixed sky, and twilight sky, etc. A single model cannot correctly characterize all the various types of skies due to the large difference in physics and appearance associated with different sky types. We have developed a set of physics-motivated sky models to identify clear blue-sky regions and cloudy/overcast sky regions. An exemplar-based approach is to generate the initial set of candidate sky regions. Another data-derived model is subsequently used to combine the results for different sky types to form a more complete sky map. Extensive testing using more than 3000 (randomly oriented) natural images shows that our comprehensive sky detector is able to accurately recall approximately 96% of all sky regions in the image set, with a precision of about 92%. Assuming correct image orientation, the precision on the same set of images increases to about 96%."
            },
            "slug": "Hybrid-approach-to-classifying-sky-regions-in-Singhal-Luo",
            "title": {
                "fragments": [],
                "text": "Hybrid approach to classifying sky regions in natural images"
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "This work is related to Torralba and Sinha [11] but there are major distinctions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 23
                            }
                        ],
                        "text": "[11]A. Torralba and P. Sinha, \u201cStatistical context priming for object detection,\u201d Proc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 34
                            }
                        ],
                        "text": "[9] P. Lipson, E. Grimson, and P. Sinha, \"Configuration based scene classification and image indexing,\" Proc."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9982531,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6a48c0dbff6e7fa752fdcf8ef34f8cba8202b41",
            "isKey": true,
            "numCitedBy": 202,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "There is general consensus that context can be a rich source of information about an object's identity, location and scale. However the issue of how to formalize centextual influences is still largely open. Here we introduce a simple probabilistic framework for modeling the relationship between context and object properties. We represent global context information in terms of the spatial layout of spectral components. The resulting scheme serves as an effective procedure for context driven focus of attention and scale-selection on real-world scenes. Based on a simple holistic analysis of an image, the scheme is able to accurately predict object locations and sizes."
            },
            "slug": "Statistical-context-priming-for-object-detection-Torralba-Sinha",
            "title": {
                "fragments": [],
                "text": "Statistical Context Priming for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple probabilistic framework for modeling the relationship between context and object properties is introduced, representing global context information in terms of the spatial layout of spectral components and serving as an effective procedure for context driven focus of attention and scale-selection on real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120499"
                        ],
                        "name": "N. Campbell",
                        "slug": "N.-Campbell",
                        "structuredName": {
                            "firstName": "Neill",
                            "lastName": "Campbell",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Campbell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3306363"
                        ],
                        "name": "B. Thomas",
                        "slug": "B.-Thomas",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Thomas",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Thomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4997851"
                        ],
                        "name": "T. Troscianko",
                        "slug": "T.-Troscianko",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Troscianko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Troscianko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7] limited their images to those taken from driving a vehicle around (containing primarily sky, vegetation, road surface, road border, fence/wall, buildings, and cars) for an autonomous navigation application."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42018080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68c7744b39fd3307721211cecad46bc275ac4a7b",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes how neural networks may be used to segment and label objects in images. A self-organising feature map is used for the segmentation phase, and we quantify the quality of the segmentations produced as well as the contribution made by colour and texture features. A multi-layer perception is trained to label the regions produced by the segmentation process. It is shown that 91.1% of the image area is correctly classified into one of eleven categories which include cars, houses, fences, roads, vegetation and sky."
            },
            "slug": "Automatic-Segmentation-and-Classification-of-Images-Campbell-Thomas",
            "title": {
                "fragments": [],
                "text": "Automatic Segmentation and Classification of Outdoor Images Using Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "How neural networks may be used to segment and label objects in images is described, and the quality of the segmentations produced as well as the contribution made by colour and texture features are quantified."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Neural Syst."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507859"
                        ],
                        "name": "S. Berretti",
                        "slug": "S.-Berretti",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Berretti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Berretti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680785"
                        ],
                        "name": "E. Vicario",
                        "slug": "E.-Vicario",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Vicario",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Vicario"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 205
                            }
                        ],
                        "text": "One is via checking the bounding boxes of the regions and the other is via a lookup table of the directional weights of two regions computed via a statistical counting method based on weighted walkthrough [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16486608,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "947ca26109136a218ef79b361e32ab51e90b088a",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Spatial-arrangement-of-color-in-retrieval-by-visual-Berretti-Bimbo",
            "title": {
                "fragments": [],
                "text": "Spatial arrangement of color in retrieval by visual similarity"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733172"
                        ],
                        "name": "E. Saber",
                        "slug": "E.-Saber",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Saber",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Saber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747853"
                        ],
                        "name": "A. Tekalp",
                        "slug": "A.-Tekalp",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Tekalp",
                            "middleNames": [
                                "Murat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tekalp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2033060"
                        ],
                        "name": "R. Eschbach",
                        "slug": "R.-Eschbach",
                        "structuredName": {
                            "firstName": "Reiner",
                            "lastName": "Eschbach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Eschbach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2101856"
                        ],
                        "name": "K. Knox",
                        "slug": "K.-Knox",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Knox",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Knox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[2] used color classification to detect sky by assuming a 2D Gaussian probability density function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 141
                            }
                        ],
                        "text": "Prior work in scene context-aware material detection has operated at an extremely narrow level with specific scene models for specific types [2, 3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16709636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aacea0e8b97cce51f8ce1494dbd6f739dcf7eeb3",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a system which automatically annotates images with a set of prespecified keywords, based on supervised color classification of pixels intoNprespecified classes using simple pixelwise operations. The conditional distribution of the chrominance components of pixels belonging to each class is modeled by a two-dimensional Gaussian function, where the mean vector and the covariance matrix for each class are estimated from appropriate training sets. Then, a succession of binary hypothesis tests with image-adaptive thresholds has been employed to decide whether each pixel in a given image belongs to one of the predetermined classes. To this effect, a universal decision threshold is first selected for each class based on receiver operating characteristics (ROC) curves quantifying the optimum \u201ctrue positive\u201d vs \u201cfalse positive\u201d performance on the training set. Then, a new method is introduced for adapting these thresholds to the characteristics of individual input images based on histogram cluster analysis. If a particular pixel is found to belong to more than one class, a maximuma posterioriprobability (MAP) rule is employed to resolve the ambiguity. The performance improvement obtained by the proposed adaptive hypothesis testing approach over using universal decision thresholds is demonstrated by annotating a database of 31 images."
            },
            "slug": "Automatic-Image-Annotation-Using-Adaptive-Color-Saber-Tekalp",
            "title": {
                "fragments": [],
                "text": "Automatic Image Annotation Using Adaptive Color Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A system which automatically annotates images with a set of prespecified keywords, based on supervised color classification of pixels intoprespecified classes using simple pixelwise operations is described."
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780080"
                        ],
                        "name": "M. Naphade",
                        "slug": "M.-Naphade",
                        "structuredName": {
                            "firstName": "Milind",
                            "lastName": "Naphade",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Naphade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742920"
                        ],
                        "name": "I. Kozintsev",
                        "slug": "I.-Kozintsev",
                        "structuredName": {
                            "firstName": "Igor",
                            "lastName": "Kozintsev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kozintsev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108949759"
                        ],
                        "name": "T. Huang",
                        "slug": "T.-Huang",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Huang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144161012"
                        ],
                        "name": "K. Ramchandran",
                        "slug": "K.-Ramchandran",
                        "structuredName": {
                            "firstName": "Kannan",
                            "lastName": "Ramchandran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ramchandran"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 25
                            }
                        ],
                        "text": "[1] M. Naphade and T. S. Huang, \u201cA factor graph framework for semantic indexing and retrieval in video, \u201d CVPR Workshop on Content-based Image and Video Retrieval, 2000."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "For example, Naphade and Huang [1] use a list of semantic objects, including sky, snow, rock, water, and forest, in a factor graph-based framework for semantic indexing and retrieval of video."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "This step may be unnecessary if one uses a single classifier to detect all the material types [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18164034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eacbf8e5ac31d60138c9e5fa2c14b075ccd01a27",
            "isKey": true,
            "numCitedBy": 53,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a novel framework for semantic indexing and retrieval in digital video. The components of the framework are probabilistic multimedia objects (multijects) and a network of such objects (multinets). The main contribution of this paper is a novel application of a factor graph framework to model the interactions in a network of multijects (multinet) at a semantic level. Factor graphs are statistical graphical models that provide an efficient framework for exact and approximate inference via the sum-product algorithm. Incorporating the statistical interactions between the concepts using factor graphs enhances the detection probability of individual multijects and provides a unified framework for integrating multiple modalities and supports inference of unobservable concepts based on their relation with observable concepts. Our experiments reveal significant performance improvement using the inference on the factor graph models."
            },
            "slug": "A-factor-graph-framework-for-semantic-indexing-and-Naphade-Kozintsev",
            "title": {
                "fragments": [],
                "text": "A factor graph framework for semantic indexing and retrieval in video"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This paper proposes a novel framework for semantic indexing and retrieval in digital video by incorporating the statistical interactions between the concepts using factor graphs to model the interactions in a network of multijects at a semantic level."
            },
            "venue": {
                "fragments": [],
                "text": "2000 Proceedings Workshop on Content-based Access of Image and Video Libraries"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1073705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c99f2391b956dc189855541e49e53c21ae5ec603",
            "isKey": false,
            "numCitedBy": 888,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "There is general consensus that context can be a rich source of information about an object's identity, location and scale. In fact, the structure of many real-world scenes is governed by strong configurational rules akin to those that apply to a single object. Here we introduce a simple framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains. The resulting scheme serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes."
            },
            "slug": "Contextual-Priming-for-Object-Detection-Torralba",
            "title": {
                "fragments": [],
                "text": "Contextual Priming for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144014783"
                        ],
                        "name": "J.R. Smith",
                        "slug": "J.R.-Smith",
                        "structuredName": {
                            "firstName": "J.R.",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J.R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406720703"
                        ],
                        "name": "Chung-Sheng-Li",
                        "slug": "Chung-Sheng-Li",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Chung-Sheng-Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung-Sheng-Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62752862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fb507a8f20b3a2384fb2e9aecf24efc209aac0b",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a method for decoding image semantics using composite region templates (CRTs). The CRTs define prototypal spatial arrangements of regions and features in the images. The system classifies unknown images by matching the strings of regions extracted from the images to the templates in a CRT library. They describe the process for generating the CRTs from photographic images by automatically segmenting the images into color regions. They demonstrate that the system performs well in classifying images from ten semantic classes and in searching for images in a large collection."
            },
            "slug": "Decoding-image-semantics-using-composite-region-Smith-Chung-Sheng-Li",
            "title": {
                "fragments": [],
                "text": "Decoding image semantics using composite region templates"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "The authors present a method for decoding image semantics using composite region templates (CRTs) and demonstrate that the system performs well in classifying images from ten semantic classes and in searching for images in a large collection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. IEEE Workshop on Content-Based Access of Image and Video Libraries (Cat. No.98EX173)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076857013"
                        ],
                        "name": "\u5927\u7530 \u53cb\u4e00",
                        "slug": "\u5927\u7530-\u53cb\u4e00",
                        "structuredName": {
                            "firstName": "\u5927\u7530",
                            "lastName": "\u53cb\u4e00",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u5927\u7530 \u53cb\u4e00"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60808481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be8b7a7d49f1a4eec1f6e48cb3a1543a2bcf9544",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Knowledge-based-interpretation-of-outdoor-natural-\u5927\u7530",
            "title": {
                "fragments": [],
                "text": "Knowledge-based interpretation of outdoor natural color scenes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Configuration basedsceneclassificationandimageindexing"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE International Conference on Computer Vision andPatternRecognition"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statisticalcontextpriming forobjectdetection"
            },
            "venue": {
                "fragments": [],
                "text": "Proc.InternationalConference onComputerVision"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic segmentation and classification of outdoorimagesusingneuralnetworks"
            },
            "venue": {
                "fragments": [],
                "text": "International JournalofNeuralSystems"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A reviewonstrategiesforrecognizingnaturalobjectsin colourimagesofoutdoorscenes"
            },
            "venue": {
                "fragments": [],
                "text": "ImageVisionand Computing"
            },
            "year": 2000
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 16,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Probabilistic-spatial-context-models-for-scene-Singhal-Luo/01c2f706c107c9853a86d1a2d6cd8e6f82b31db1?sort=total-citations"
}