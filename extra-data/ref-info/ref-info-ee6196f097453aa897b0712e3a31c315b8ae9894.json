{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2874808"
                        ],
                        "name": "Tim Furche",
                        "slug": "Tim-Furche",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Furche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Furche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684745"
                        ],
                        "name": "G. Gottlob",
                        "slug": "G.-Gottlob",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Gottlob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gottlob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24604135"
                        ],
                        "name": "G. Grasso",
                        "slug": "G.-Grasso",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Grasso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grasso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3347054"
                        ],
                        "name": "Omer Gunes",
                        "slug": "Omer-Gunes",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Gunes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Gunes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146371097"
                        ],
                        "name": "Xiaonan Guo",
                        "slug": "Xiaonan-Guo",
                        "structuredName": {
                            "firstName": "Xiaonan",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaonan Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48322444"
                        ],
                        "name": "A. Kravchenko",
                        "slug": "A.-Kravchenko",
                        "structuredName": {
                            "firstName": "Andrey",
                            "lastName": "Kravchenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kravchenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35203250"
                        ],
                        "name": "G. Orsi",
                        "slug": "G.-Orsi",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Orsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orsi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766300"
                        ],
                        "name": "C. Schallhart",
                        "slug": "C.-Schallhart",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Schallhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schallhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34565417"
                        ],
                        "name": "A. Sellers",
                        "slug": "A.-Sellers",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Sellers",
                            "middleNames": [
                                "Jon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sellers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119128164"
                        ],
                        "name": "Cheng Wang",
                        "slug": "Cheng-Wang",
                        "structuredName": {
                            "firstName": "Cheng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "The vision and components of DIADEM are outlined briefly in [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10082324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce83f2034c9689254139a2fd8f8c4154c9041e81",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Search engines are the sinews of the web. These sinews have become strained, however: Where the web's function once was a mix of library and yellow pages, it has become the central marketplace for information of almost any kind. We search more and more for objects with specific characteristics, a car with a certain mileage, an affordable apartment close to a good school, or the latest accessory for our phones. Search engines all too often fail to provide reasonable answers, making us sift through dozens of websites with thousands of offers--never to be sure a better offer isn't just around the corner. What search engines are missing is understanding of the objects and their attributes published on websites. Automatically identifying and extracting these objects is akin to alchemy: transforming unstructured web information into highly structured data with near perfect accuracy. With DIADEM we present a formula for this transformation, but at a price: DIADEM identifies and extracts data from a website with high accuracy. The price is that for this task we need to provide DIADEM with extensive knowledge about the ontology and phenomenology of the domain, i.e., about entities (and relations) and about the representation of these entities in the textual, structural, and visual language of a website of this domain. In this demonstration, we demonstrate with a first prototype of DIADEM that, in contrast to alchemists, DIADEM has developed a viable formula."
            },
            "slug": "DIADEM:-domain-centric,-intelligent,-automated-data-Furche-Gottlob",
            "title": {
                "fragments": [],
                "text": "DIADEM: domain-centric, intelligent, automated data extraction methodology"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "In this demonstration, it is demonstrated with a first prototype of DIADEM that, in contrast to alchemists, DIADem has developed a viable formula for transforming unstructured web information into highly structured data with near perfect accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111220343"
                        ],
                        "name": "D. Wang",
                        "slug": "D.-Wang",
                        "structuredName": {
                            "firstName": "Daisy",
                            "lastName": "Wang",
                            "middleNames": [
                                "Zhe"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48144872"
                        ],
                        "name": "Eugene Wu",
                        "slug": "Eugene-Wu",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145955157"
                        ],
                        "name": "Yang Zhang",
                        "slug": "Yang-Zhang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15642206,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b5077161a6f55a0d18cdfa3abbb612663d08d69",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The World-Wide Web consists of a huge number of unstructured documents, but it also contains structured data in the form of HTML tables. We extracted 14.1 billion HTML tables from Google's general-purpose web crawl, and used statistical classification techniques to find the estimated 154M that contain high-quality relational data. Because each relational table has its own \"schema\" of labeled and typed columns, each such table can be considered a small structured database. The resulting corpus of databases is larger than any other corpus we are aware of, by at least five orders of magnitude. \n \nWe describe the WEBTABLES system to explore two fundamental questions about this collection of databases. First, what are effective techniques for searching for structured data at search-engine scales? Second, what additional power can be derived by analyzing such a huge corpus? \n \nFirst, we develop new techniques for keyword search over a corpus of tables, and show that they can achieve substantially higher relevance than solutions based on a traditional search engine. Second, we introduce a new object derived from the database corpus: the attribute correlation statistics database (AcsDB) that records corpus-wide statistics on co-occurrences of schema elements. In addition to improving search relevance, the AcsDB makes possible several novel applications: schema auto-complete, which helps a database designer to choose schema elements; attribute synonym finding, which automatically computes attribute synonym pairs for schema matching; and join-graph traversal, which allows a user to navigate between extracted schemas using automatically-generated join links."
            },
            "slug": "WebTables:-exploring-the-power-of-tables-on-the-web-Cafarella-Halevy",
            "title": {
                "fragments": [],
                "text": "WebTables: exploring the power of tables on the web"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The WEBTABLES system develops new techniques for keyword search over a corpus of tables, and shows that they can achieve substantially higher relevance than solutions based on a traditional search engine."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2224716"
                        ],
                        "name": "J. Madhavan",
                        "slug": "J.-Madhavan",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Madhavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32403215"
                        ],
                        "name": "D. Ko",
                        "slug": "D.-Ko",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Ko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763174"
                        ],
                        "name": "Lucja Kot",
                        "slug": "Lucja-Kot",
                        "structuredName": {
                            "firstName": "Lucja",
                            "lastName": "Kot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucja Kot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730492"
                        ],
                        "name": "Vignesh Ganapathy",
                        "slug": "Vignesh-Ganapathy",
                        "structuredName": {
                            "firstName": "Vignesh",
                            "lastName": "Ganapathy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vignesh Ganapathy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058347525"
                        ],
                        "name": "Alex Rasmussen",
                        "slug": "Alex-Rasmussen",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Rasmussen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Rasmussen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 78
                            }
                        ],
                        "text": "DIADEM\u2019s exploration combines focused crawling [7] and automatic form filling [29, 31, 38]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 125
                            }
                        ],
                        "text": ", by prioritizing exploration paths that are more likely to surface results, but without relying on content redundancy as in [29, 38]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 195743,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc81e708ebdcf6232daf3a8a92e3321910cd4d56",
            "isKey": false,
            "numCitedBy": 401,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The Deep Web, i.e., content hidden behind HTML forms, has long been acknowledged as a significant gap in search engine coverage. Since it represents a large portion of the structured data on the Web, accessing Deep-Web content has been a long-standing challenge for the database community. This paper describes a system for surfacing Deep-Web content, i.e., pre-computing submissions for each HTML form and adding the resulting HTML pages into a search engine index. The results of our surfacing have been incorporated into the Google search engine and today drive more than a thousand queries per second to Deep-Web content. \n \nSurfacing the Deep Web poses several challenges. First, our goal is to index the content behind many millions of HTML forms that span many languages and hundreds of domains. This necessitates an approach that is completely automatic, highly scalable, and very efficient. Second, a large number of forms have text inputs and require valid inputs values to be submitted. We present an algorithm for selecting input values for text search inputs that accept keywords and an algorithm for identifying inputs which accept only values of a specific type. Third, HTML forms often have more than one input and hence a naive strategy of enumerating the entire Cartesian product of all possible inputs can result in a very large number of URLs being generated. We present an algorithm that efficiently navigates the search space of possible input combinations to identify only those that generate URLs suitable for inclusion into our web search index. We present an extensive experimental evaluation validating the effectiveness of our algorithms."
            },
            "slug": "Google's-Deep-Web-crawl-Madhavan-Ko",
            "title": {
                "fragments": [],
                "text": "Google's Deep Web crawl"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm that efficiently navigates the search space of possible input combinations to identify only those that generate URLs suitable for inclusion into the authors' web search index and an extensive experimental evaluation validating the effectiveness of the algorithms is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2339397"
                        ],
                        "name": "Michele Banko",
                        "slug": "Michele-Banko",
                        "structuredName": {
                            "firstName": "Michele",
                            "lastName": "Banko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michele Banko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50452701"
                        ],
                        "name": "M. Broadhead",
                        "slug": "M.-Broadhead",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Broadhead",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Broadhead"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 44
                            }
                        ],
                        "text": "It differs from open information extraction [16, 37], where the target is unstructured text, and from product extraction [22], targeting unstructured product listings."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207169186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "498bb0efad6ec15dd09d941fb309aa18d6df9f5f",
            "isKey": false,
            "numCitedBy": 2290,
            "numCiting": 148,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditionally, Information Extraction (IE) has focused on satisfying precise, narrow, pre-specified requests from small homogeneous corpora (e.g., extract the location and time of seminars from a set of announcements). Shifting to a new domain requires the user to name the target relations and to manually create new extraction rules or hand-tag new training examples. This manual labor scales linearly with the number of target relations. This paper introduces Open IE (OIE), a new extraction paradigm where the system makes a single data-driven pass over its corpus and extracts a large set of relational tuples without requiring any human input. The paper also introduces TEXTRUNNER, a fully implemented, highly scalable OIE system where the tuples are assigned a probability and indexed to support efficient extraction and exploration via user queries. We report on experiments over a 9,000,000 Web page corpus that compare TEXTRUNNER with KNOWITALL, a state-of-the-art Web IE system. TEXTRUNNER achieves an error reduction of 33% on a comparable set of extractions. Furthermore, in the amount of time it takes KNOWITALL to perform extraction for a handful of pre-specified relations, TEXTRUNNER extracts a far broader set of facts reflecting orders of magnitude more relations, discovered on the fly. We report statistics on TEXTRUNNER\u2019s 11,000,000 highest probability tuples, and show that they contain over 1,000,000 concrete facts and over 6,500,000more abstract assertions."
            },
            "slug": "Open-Information-Extraction-from-the-Web-Banko-Cafarella",
            "title": {
                "fragments": [],
                "text": "Open Information Extraction from the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Open IE (OIE), a new extraction paradigm where the system makes a single data-driven pass over its corpus and extracts a large set of relational tuples without requiring any human input, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791339"
                        ],
                        "name": "Valter Crescenzi",
                        "slug": "Valter-Crescenzi",
                        "structuredName": {
                            "firstName": "Valter",
                            "lastName": "Crescenzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Valter Crescenzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785690"
                        ],
                        "name": "G. Mecca",
                        "slug": "G.-Mecca",
                        "structuredName": {
                            "firstName": "Giansalvatore",
                            "lastName": "Mecca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mecca"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6572841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a47888c0243cac0b173c2748d8ed1b0a2a15fdd8",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction from websites is nowadays a relevant problem, usually performed by software modules called wrappers. A key requirement is that the wrapper generation process should be automated to the largest extent, in order to allow for large-scale extraction tasks even in presence of changes in the underlying sites. So far, however, only semi-automatic proposals have appeared in the literature.We present a novel approach to information extraction from websites, which reconciles recent proposals for supervised wrapper induction with the more traditional field of grammar inference. Grammar inference provides a promising theoretical framework for the study of unsupervised---that is, fully automatic---wrapper generation algorithms. However, due to some unrealistic assumptions on the input, these algorithms are not practically applicable to Web information extraction tasks.The main contributions of the article stand in the definition of a class of regular languages, called the prefix mark-up languages, that abstract the structures usually found in HTML pages, and in the definition of a polynomial-time unsupervised learning algorithm for this class. The article shows that, differently from other known classes, prefix mark-up languages and the associated algorithm can be practically used for information extraction purposes.A system based on the techniques described in the article has been implemented in a working prototype. We present some experimental results on known Websites, and discuss opportunities and limitations of the proposed approach."
            },
            "slug": "Automatic-information-extraction-from-large-Crescenzi-Mecca",
            "title": {
                "fragments": [],
                "text": "Automatic information extraction from large websites"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A novel approach to information extraction from websites is presented, which reconciles recent proposals for supervised wrapper induction with the more traditional field of grammar inference, and shows that, differently from other known classes, prefix mark-up languages and the associated algorithm can be practically used for information extraction purposes."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34929007"
                        ],
                        "name": "Nora Derouiche",
                        "slug": "Nora-Derouiche",
                        "structuredName": {
                            "firstName": "Nora",
                            "lastName": "Derouiche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nora Derouiche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2772242"
                        ],
                        "name": "B. Cautis",
                        "slug": "B.-Cautis",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Cautis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Cautis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831624"
                        ],
                        "name": "T. Abdessalem",
                        "slug": "T.-Abdessalem",
                        "structuredName": {
                            "firstName": "Talel",
                            "lastName": "Abdessalem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Abdessalem"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 65
                            }
                        ],
                        "text": "Domain knowledge has been used in existing extraction approaches [35, 13, 14], however, DIADEM uses knowledge in a unique fashion: Its domain knowledge, the DIADEM ontology, not only includes a schema of the domain and entity recognisers for the schema types, but also classifies and constrains these types with respect to their appearance on web sites."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 239
                            }
                        ],
                        "text": "Domain knowledge has recently been increasingly employed in record identification, mostly for reducing supervision in wrapper induction via automatic annotation of training samples [13, 33] or for schema-based validation of the extraction [14, 35]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17728706,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6cefe99b3d22d58e92546eb58d509512dcf27cef",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present in this paper a novel approach for extracting structured data from the Web, whose goal is to harvest real-world items from template-based HTML pages (the structured Web). It illustrates a two-phase querying of the Web, in which an intentional description of the data that is targeted is first provided, in a flexible and widely applicable manner. The extraction process leverages then both the input description and the source structure. Our approach is domain-independent, in the sense that it applies to any relation, either flat or nested, describing real-world items. Extensive experiments on five different domains and comparison with the main state of the art extraction systems from literature illustrate its flexibility and precision. We advocate via our technique that automatic extraction and integration of complex structured data can be done fast and effectively, when the redundancy of the Web meets knowledge over the to-be-extracted data."
            },
            "slug": "Automatic-Extraction-of-Structured-Web-Data-with-Derouiche-Cautis",
            "title": {
                "fragments": [],
                "text": "Automatic Extraction of Structured Web Data with Domain Knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper illustrates a two-phase querying of the Web, in which an intentional description of the data that is targeted is first provided, in a flexible and widely applicable manner, and advocates via the technique that automatic extraction and integration of complex structured data can be done fast and effectively."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE 28th International Conference on Data Engineering"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2224716"
                        ],
                        "name": "J. Madhavan",
                        "slug": "J.-Madhavan",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Madhavan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 113
                            }
                        ],
                        "text": "The automatic, yet accurate extraction of the structured data underlying such pages is a long standing challenge [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "Web data extraction targets data on the web structured by templates and visual styling [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7406627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85fb4f38e74717c409316b5ff2936be0c126a1b7",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Though search on the World-Wide Web has focused mostly on unstructured text, there is an increasing amount of structured data on the Web and growing interest in harnessing such data. Moreover, structured data is starting to play a greater role in many of the social movements enabled by the Web, such as citizen participation in government. I will describe several current projects at Google whose overall goal is enable people to create and share structured data on the Web and to leverage structured data in Web search.I will describe our system for crawling millions of \u201ddeep-web\u201d sites, that offer access to high-quality data through HTML forms and the WebTables and Octopus Systems that leverage structured data in HTML tables and lists on the surface web and enable users to piece together multiple datasets. Finally, I\u2019ll describe Fusion Tables, a recently launched data-management service that lets users create and visualize structured and easily and emphasizes the ability to collaborate with other data owners."
            },
            "slug": "Structured-Data-on-the-Web-Cafarella-Halevy",
            "title": {
                "fragments": [],
                "text": "Structured Data on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Fusion Tables is described, a recently launched data-management service that lets users create and visualize structured and easily and emphasizes the ability to collaborate with other data owners."
            },
            "venue": {
                "fragments": [],
                "text": "2010 12th International Asia-Pacific Web Conference"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2874808"
                        ],
                        "name": "Tim Furche",
                        "slug": "Tim-Furche",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Furche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Furche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684745"
                        ],
                        "name": "G. Gottlob",
                        "slug": "G.-Gottlob",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Gottlob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gottlob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24604135"
                        ],
                        "name": "G. Grasso",
                        "slug": "G.-Grasso",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Grasso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grasso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146371097"
                        ],
                        "name": "Xiaonan Guo",
                        "slug": "Xiaonan-Guo",
                        "structuredName": {
                            "firstName": "Xiaonan",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaonan Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35203250"
                        ],
                        "name": "G. Orsi",
                        "slug": "G.-Orsi",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Orsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orsi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766300"
                        ],
                        "name": "C. Schallhart",
                        "slug": "C.-Schallhart",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Schallhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schallhart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "DIADEM\u2019s form filling, which builds on DIADEM\u2019s form analysis component OPAL [18], is an example for such transducers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "ICQ dataset HA [15] ExQ [41] StatParser [36] DIADEM [18]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "The form is analysed by a phenomenological transducer based on the OPAL [18] approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "More details on the major components is available in [18] (form understanding), [19] (record and attribute identification), [20] (extraction language OXPATH)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "DIADEM\u2019s form understanding [18], result page analysis [19], and extraction engine [20] have been published previously."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "With domain knowledge, OPAL is able to achieve higher accuracy, see [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "For form understanding (see [24] for a recent survey), DIADEM uses an extended version of OPAL [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2770721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96f9a5fb65d8536d822e7391021662563c8a9573",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Forms are our gates to the Web. They enable us to access the deep content of Web sites. Automatic form understanding provides applications, ranging from crawlers over meta-search engines to service integrators, with a key to this content. Yet, it has received little attention other than as component in specific applications such as crawlers or meta-search engines. No comprehensive approach to form understanding exists, let alone one that produces rich models for semantic services or integration with linked open data. In this paper, we present opal, the first comprehensive approach to form understanding and integration. We identify form labeling and form interpretation as the two main tasks involved in form understanding. On both problems, opal advances the state of the art: For form labeling, it combines features from the text, structure, and visual rendering of a Web page. In extensive experiments on the ICQ and TEL-8 benchmarks and a set of 200 modern Web forms, opal outperforms previous approaches for form labeling by a significant margin. For form interpretation, opal uses a schema (or ontology) of forms in a given domain. Thanks to this domain schema, it is able to produce nearly perfect ($$>$$>97\u00a0% accuracy in the evaluation domains) form interpretations. Yet, the effort to produce a domain schema is very low, as we provide a datalog-based template language that eases the specification of such schemata and a methodology for deriving a domain schema largely automatically from an existing domain ontology. We demonstrate the value of opal\u2019s form interpretations through a light-weight form integration system that successfully translates and distributes master queries to hundreds of forms with no error, yet is implemented with only a handful translation rules."
            },
            "slug": "The-ontological-key:-automatically-understanding-to-Furche-Gottlob",
            "title": {
                "fragments": [],
                "text": "The ontological key: automatically understanding and integrating forms to access the deep Web"
            },
            "venue": {
                "fragments": [],
                "text": "The VLDB Journal"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2874808"
                        ],
                        "name": "Tim Furche",
                        "slug": "Tim-Furche",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Furche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Furche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684745"
                        ],
                        "name": "G. Gottlob",
                        "slug": "G.-Gottlob",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Gottlob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gottlob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24604135"
                        ],
                        "name": "G. Grasso",
                        "slug": "G.-Grasso",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Grasso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grasso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35203250"
                        ],
                        "name": "G. Orsi",
                        "slug": "G.-Orsi",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Orsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orsi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766300"
                        ],
                        "name": "C. Schallhart",
                        "slug": "C.-Schallhart",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Schallhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schallhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119128164"
                        ],
                        "name": "Cheng Wang",
                        "slug": "Cheng-Wang",
                        "structuredName": {
                            "firstName": "Cheng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 91
                            }
                        ],
                        "text": "Example 1: Domain-aware template discovery\nDIADEM\u2019s domain-aware template discovery, called AMBER [19], is realised as a phenomenological transducer that encodes domain-independent rules for detecting patterns on web sites."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 69
                            }
                        ],
                        "text": "In contrast to existing automated approaches for template discovery, AMBER is driven by domain knowledge (as introduced in Section 3): The most important distinction is the concept of pivot attribute."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "AMBER\u2019s transducer is input-driven resumable: It is called once per page in a sequence of result pages (typically connected by pagination links), each time refining the model of the template underlying the result pages."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "More details on the major components is available in [18] (form understanding), [19] (record and attribute identification), [20] (extraction language OXPATH)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "DIADEM\u2019s form understanding [18], result page analysis [19], and extraction engine [20] have been published previously."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "DIADEM\u2019s domain-aware template discovery, called AMBER [19], is realised as a phenomenological transducer that encodes domain-independent rules for detecting patterns on web sites."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 93
                            }
                        ],
                        "text": "Among the other transducers, the wrapper induction takes up to 18%, followed by the crawler, AMBER, DIADEM\u2019s result and attribute identification, and OPAL, the form understanding transducer."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18628942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfb92eb2c06e51642bb2fa931114c547af797f4a",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Web extraction is the task of turning unstructured HTML into structured data. Previous approaches rely exclusively on detecting repeated structures in result pages. These approaches trade intensive user interaction for precision. \n \nIn this paper, we introduce the Amber (\"Adaptable Model-based Extraction of Result Pages\") system that replaces the human interaction with a domain ontology applicable to all sites of a domain. It models domain knowledge about (1) records and attributes of the domain, (2) low-level (textual) representations of these concepts, and (3) constraints linking representations to records and attributes. Parametrized with these constraints, otherwise domain-independent heuristics exploit the repeated structure of result pages to derive attributes and records. Amber is implemented in logical rules to allow an explicit formulation of the heuristics and easy adaptation to different domains. \n \nWe apply Amber to the UK real estate domain where we achieve near perfect accuracy on a representative sample of 50 agency websites."
            },
            "slug": "Little-Knowledge-Rules-the-Web:-Domain-Centric-Page-Furche-Gottlob",
            "title": {
                "fragments": [],
                "text": "Little Knowledge Rules the Web: Domain-Centric Result Page Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A Amber system that replaces the human interaction with a domain ontology applicable to all sites of a domain, and is implemented in logical rules to allow an explicit formulation of the heuristics and easy adaptation to different domains."
            },
            "venue": {
                "fragments": [],
                "text": "RR"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1872872"
                        ],
                        "name": "Thomas Kabisch",
                        "slug": "Thomas-Kabisch",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kabisch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Kabisch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1825318"
                        ],
                        "name": "Eduard Constantin Dragut",
                        "slug": "Eduard-Constantin-Dragut",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Dragut",
                            "middleNames": [
                                "Constantin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eduard Constantin Dragut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642131"
                        ],
                        "name": "Clement T. Yu",
                        "slug": "Clement-T.-Yu",
                        "structuredName": {
                            "firstName": "Clement",
                            "lastName": "Yu",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clement T. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693022"
                        ],
                        "name": "U. Leser",
                        "slug": "U.-Leser",
                        "structuredName": {
                            "firstName": "Ulf",
                            "lastName": "Leser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Leser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "ICQ dataset HA [15] ExQ [41] StatParser [36] DIADEM [18]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "Table 3 summarises the form labeling accuracy (F1-score) of DIADEM and compares it to HA [15], ExQ [41], and StatParser [36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7656137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a01bcdf86be29550a652ae8c23a3886cad31a96",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Much data in the Web is hidden behind Web query interfaces. In most cases the only means to \"surface\" the content of a Web database is by formulating complex queries on such interfaces. Applications such as Deep Web crawling and Web database integration require an automatic usage of these interfaces. Therefore, an important problem to be addressed is the automatic extraction of query interfaces into an appropriate model. We hypothesize the existence of a set of domain-independent \"commonsense design rules\" that guides the creation of Web query interfaces. These rules transform query interfaces into schema trees. In this paper we describe a Web query interface extraction algorithm, which combines HTML tokens and the geometric layout of these tokens within a Web page. Tokens are classified into several classes out of which the most significant ones are text tokens and field tokens. A tree structure is derived for text tokens using their geometric layout. Another tree structure is derived for the field tokens. The hierarchical representation of a query interface is obtained by iteratively merging these two trees. Thus, we convert the extraction problem into an integration problem. Our experiments show the promise of our algorithm: it outperforms the previous approaches on extracting query interfaces on about 6.5% in accuracy as evaluated over three corpora with more than 500 Deep Web interfaces from 15 different domains."
            },
            "slug": "A-Hierarchical-Approach-to-Model-Web-Query-for-Web-Kabisch-Dragut",
            "title": {
                "fragments": [],
                "text": "A Hierarchical Approach to Model Web Query Interfaces for Web Source Integration"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper describes a Web query interface extraction algorithm, which combines HTML tokens and the geometric layout of these tokens within a Web page, and hypothesizes the existence of a set of domain-independent \"commonsense design rules\" that guides the creation of Web query interfaces."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110165806"
                        ],
                        "name": "Jiying Wang",
                        "slug": "Jiying-Wang",
                        "structuredName": {
                            "firstName": "Jiying",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiying Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2182929"
                        ],
                        "name": "F. Lochovsky",
                        "slug": "F.-Lochovsky",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Lochovsky",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lochovsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 182
                            }
                        ],
                        "text": "Attempts to automate the extraction process via unsupervised learning of hidden page templates by discovering structural and visual regularities lead to unsupervised data extraction [9, 23, 27, 28, 34, 43, 44, 35, 40]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1951423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e4ecd6b2429076558b02ddd1b23c6c519eea7c8",
            "isKey": false,
            "numCitedBy": 421,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Many tools have been developed to help users query, extract and integrate data from web pages generated dynamically from databases, i.e., from the Hidden Web. A key prerequisite for such tools is to obtain the schema of the attributes of the retrieved data. In this paper, we describe a system called, DeLa, which reconstructs (part of) a \"hidden\" back-end web database. It does this by sending queries through HTML forms, automatically generating regular expression wrappers to extract data objects from the result pages and restoring the retrieved data into an annotated (labelled) table. The whole process needs no human involvement and proves to be fast (less than one minute for wrapper induction for each site) and accurate (over 90% correctness for data extraction and around 80% correctness for label assignment)."
            },
            "slug": "Data-extraction-and-label-assignment-for-web-Wang-Lochovsky",
            "title": {
                "fragments": [],
                "text": "Data extraction and label assignment for web databases"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A system called, DeLa, which reconstructs (part of) a \"hidden\" back-end web database by sending queries through HTML forms, automatically generating regular expression wrappers to extract data objects from the result pages and restoring the retrieved data into an annotated (labelled) table."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34361707"
                        ],
                        "name": "Kai Simon",
                        "slug": "Kai-Simon",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Simon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Simon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809410"
                        ],
                        "name": "G. Lausen",
                        "slug": "G.-Lausen",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Lausen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lausen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 182
                            }
                        ],
                        "text": "Attempts to automate the extraction process via unsupervised learning of hidden page templates by discovering structural and visual regularities lead to unsupervised data extraction [9, 23, 27, 28, 34, 43, 44, 35, 40]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7329393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eca8d0c78af7917cd774bbe1b56e62d61bd74cc0",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of unsupervised Web data extraction. We show that unsupervised Web data extraction becomes feasible when supposing pages that are made up of repetitive patterns, as it is the case, e.g., for search engine result pages. Hereby the extraction rules are generated automatically without any training or human interaction, by means of operating on the DOM tree respectively the flat tag token sequence of a single page.Our contribution to automatic data extraction through this paper is twofold. First, we identify and rank potential repetitive patterns with respect to the user's visual perception of the Web page, well aware that location and size of matching elements within a Web page constitute important criteria for defining relevance. Second, matching sub-sequences of the pattern with the highest weightiness are aligned with global multiple sequence alignment techniques. Experimental results show that our system is able to achieve high accuracy in distilling and aligning regularly structured objects inside complex Web pages."
            },
            "slug": "ViPER:-augmenting-automatic-information-extraction-Simon-Lausen",
            "title": {
                "fragments": [],
                "text": "ViPER: augmenting automatic information extraction with visual perceptions"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The unsupervised Web data extraction becomes feasible when supposing pages that are made up of repetitive patterns, as it is the case, e.g., for search engine result pages, by means of operating on the DOM tree respectively the flat tag token sequence of a single page."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2874808"
                        ],
                        "name": "Tim Furche",
                        "slug": "Tim-Furche",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Furche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Furche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684745"
                        ],
                        "name": "G. Gottlob",
                        "slug": "G.-Gottlob",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Gottlob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gottlob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24604135"
                        ],
                        "name": "G. Grasso",
                        "slug": "G.-Grasso",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Grasso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grasso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766300"
                        ],
                        "name": "C. Schallhart",
                        "slug": "C.-Schallhart",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Schallhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schallhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34565417"
                        ],
                        "name": "A. Sellers",
                        "slug": "A.-Sellers",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Sellers",
                            "middleNames": [
                                "Jon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sellers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "More details on the major components is available in [18] (form understanding), [19] (record and attribute identification), [20] (extraction language OXPATH)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "DIADEM\u2019s form understanding [18], result page analysis [19], and extraction engine [20] have been published previously."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "We do not evaluate DIADEM\u2019s wrapper execution individually for space reasons, but refer to [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14542107,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f93d6d8bfb9b9fcf8e9cd02357f6183ede716c1",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "The evolution of the web has outpaced itself: A growing wealth of information and increasingly sophisticated interfaces necessitate automated processing, yet existing automation and data extraction technologies have been overwhelmed by this very growth. To address this trend, we identify four key requirements for web data extraction, automation, and (focused) web crawling: (1) interact with sophisticated web application interfaces, (2) precisely capture the relevant data to be extracted, (3) scale with the number of visited pages, and (4) readily embed into existing web technologies. We introduce OXPath as an extension of XPath for interacting with web applications and extracting data thus revealed\u2014matching all the above requirements. OXPath\u2019s page-at-a-time evaluation guarantees memory use independent of the number of visited pages, yet remains polynomial in time. We experimentally validate the theoretical complexity and demonstrate that OXPath\u2019s resource consumption is dominated by page rendering in the underlying browser. With an extensive study of sublanguages and properties of OXPath, we pinpoint the effect of specific features on evaluation performance. Our experiments show that OXPath outperforms existing commercial and academic data extraction tools by a wide margin."
            },
            "slug": "OXPath:-A-language-for-scalable-data-extraction,-on-Furche-Gottlob",
            "title": {
                "fragments": [],
                "text": "OXPath: A language for scalable data extraction, automation, and crawling on the deep web"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work introduces OXPath as an extension of XPath for interacting with web applications and extracting data thus revealed\u2014matching all the above requirements for web data extraction, automation, and (focused) web crawling."
            },
            "venue": {
                "fragments": [],
                "text": "The VLDB Journal"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8551365"
                        ],
                        "name": "N. Kushmerick",
                        "slug": "N.-Kushmerick",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Kushmerick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kushmerick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 58
                            }
                        ],
                        "text": "Given a set of already annotated pages, wrapper induction [2, 12, 21, 25] derives small wrapper programs to extract the corresponding data from other pages relying on the same page template."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11075952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f052f40a3307de1e45e11a3007a7552b36ebfc8",
            "isKey": false,
            "numCitedBy": 641,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Wrapper-induction:-Efficiency-and-expressiveness-Kushmerick",
            "title": {
                "fragments": [],
                "text": "Wrapper induction: Efficiency and expressiveness"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40343421"
                        ],
                        "name": "Yanhong Zhai",
                        "slug": "Yanhong-Zhai",
                        "structuredName": {
                            "firstName": "Yanhong",
                            "lastName": "Zhai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanhong Zhai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145321667"
                        ],
                        "name": "B. Liu",
                        "slug": "B.-Liu",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 182
                            }
                        ],
                        "text": "Attempts to automate the extraction process via unsupervised learning of hidden page templates by discovering structural and visual regularities lead to unsupervised data extraction [9, 23, 27, 28, 34, 43, 44, 35, 40]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 184
                            }
                        ],
                        "text": "For the record and attribute identification accuracy, we compare DIADEM with RoadRunner [9], MDR [27], ViNTs [44] (in supervised mode where we provide a set of result pages) and Depta [43]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 127
                            }
                        ],
                        "text": "significantly increases the accuracy of record and attribute identification compared to existing template discovery approaches [9, 43]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 4
                            }
                        ],
                        "text": "For Depta, we only consider identification accuracy for attributes in records that are perfectly segmented by Depta."
                    },
                    "intents": []
                }
            ],
            "corpusId": 506970,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "468c8699f772ce84dec9c656e71bd52e15c1889a",
            "isKey": true,
            "numCitedBy": 213,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies the problem of structured data extraction from arbitrary Web pages. The objective of the proposed research is to automatically segment data records in a page, extract data items/fields from these records, and store the extracted data in a database. Existing methods addressing the problem can be classified into three categories. Methods in the first category provide some languages to facilitate the construction of data extraction systems. Methods in the second category use machine learning techniques to learn wrappers (which are data extraction programs) from human labeled examples. Manual labeling is time-consuming and is hard to scale to a large number of sites on the Web. Methods in the third category are based on the idea of automatic pattern discovery. However, multiple pages that conform to a common schema are usually needed as the input. In this paper, we propose a novel and effective technique (called DEPTA) to perform the task of Web data extraction automatically. The method consists of two steps: 1) identifying individual records in a page and 2) aligning and extracting data items from the identified records. For step 1, a method based on visual information and tree matching is used to segment data records. For step 2, a novel partial alignment technique is proposed. This method aligns only those data items in a pair of records that can be aligned with certainty, making no commitment on the rest of the items. Experimental results obtained using a large number of Web pages from diverse domains show that the proposed two-step technique is highly effective"
            },
            "slug": "Structured-Data-Extraction-from-the-Web-Based-on-Zhai-Liu",
            "title": {
                "fragments": [],
                "text": "Structured Data Extraction from the Web Based on Partial Tree Alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A novel and effective technique to perform the task of Web data extraction automatically, called DEPTA, which consists of two steps: identifying individual records in a page and aligning and extracting data items from the identified records."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3709168"
                        ],
                        "name": "Ritu Khare",
                        "slug": "Ritu-Khare",
                        "structuredName": {
                            "firstName": "Ritu",
                            "lastName": "Khare",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ritu Khare"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938877"
                        ],
                        "name": "Yuan An",
                        "slug": "Yuan-An",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "An",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan An"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144436171"
                        ],
                        "name": "I. Song",
                        "slug": "I.-Song",
                        "structuredName": {
                            "firstName": "Il-Yeol",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Song"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "For form understanding (see [24] for a recent survey), DIADEM uses an extended version of OPAL [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7483952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6ac45a48e73978292fc701c63da78c784632149",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a survey on the major approaches to search interface understanding. The Deep Web consists of data that exist on the Web but are inaccessible via text search engines. The traditional way to access these data, i.e., by manually filling-up HTML forms on search interfaces, is not scalable given the growing size of Deep Web. Automatic access to these data requires an automatic understanding of search interfaces. While it is easy for a human to perceive an interface, machine processing of an interface is challenging. During the last decade, several works addressed the automatic interface understanding problem while employing a variety of understanding strategies. This paper presents a survey conducted on the key works. This is the first survey in the field of search interface understanding. Through an exhaustive analysis, we organize the works on a 2-D graph based on the underlying database information extracted and based on the technique employed."
            },
            "slug": "Understanding-deep-web-search-interfaces:-a-survey-Khare-An",
            "title": {
                "fragments": [],
                "text": "Understanding deep web search interfaces: a survey"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This paper presents a survey on the major approaches to search interface understanding, and organizes the works on a 2-D graph based on the underlying database information extracted andbased on the technique employed."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46641573"
                        ],
                        "name": "W. Liu",
                        "slug": "W.-Liu",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143976873"
                        ],
                        "name": "Xiaofeng Meng",
                        "slug": "Xiaofeng-Meng",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Meng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Meng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38699354"
                        ],
                        "name": "W. Meng",
                        "slug": "W.-Meng",
                        "structuredName": {
                            "firstName": "Weiyi",
                            "lastName": "Meng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Meng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 182
                            }
                        ],
                        "text": "Attempts to automate the extraction process via unsupervised learning of hidden page templates by discovering structural and visual regularities lead to unsupervised data extraction [9, 23, 27, 28, 34, 43, 44, 35, 40]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6338383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6d47812facda5522d1f16f653bbeac1aa0764bb",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Web contents are accessed by queries submitted to Web databases and the returned data records are enwrapped in dynamically generated Web pages (they will be called deep Web pages in this paper). Extracting structured data from deep Web pages is a challenging problem due to the underlying intricate structures of such pages. Until now, a large number of techniques have been proposed to address this problem, but all of them have inherent limitations because they are Web-page-programming-language-dependent. As the popular two-dimensional media, the contents on Web pages are always displayed regularly for users to browse. This motivates us to seek a different way for deep Web data extraction to overcome the limitations of previous works by utilizing some interesting common visual features on the deep Web pages. In this paper, a novel vision-based approach that is Web-page-programming-language-independent is proposed. This approach primarily utilizes the visual features on the deep Web pages to implement deep Web data extraction, including data record extraction and data item extraction. We also propose a new evaluation measure revision to capture the amount of human effort needed to produce perfect extraction. Our experiments on a large set of Web databases show that the proposed vision-based approach is highly effective for deep Web data extraction."
            },
            "slug": "ViDE:-A-Vision-Based-Approach-for-Deep-Web-Data-Liu-Meng",
            "title": {
                "fragments": [],
                "text": "ViDE: A Vision-Based Approach for Deep Web Data Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel vision-based approach that is Web-page-programming-language-independent is proposed that primarily utilizes the visual features on the deep Web pages to implement deep Web data extraction, including data record extraction and data item extraction."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36367542"
                        ],
                        "name": "Wensheng Wu",
                        "slug": "Wensheng-Wu",
                        "structuredName": {
                            "firstName": "Wensheng",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wensheng Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3030274"
                        ],
                        "name": "A. Doan",
                        "slug": "A.-Doan",
                        "structuredName": {
                            "firstName": "AnHai",
                            "lastName": "Doan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642131"
                        ],
                        "name": "Clement T. Yu",
                        "slug": "Clement-T.-Yu",
                        "structuredName": {
                            "firstName": "Clement",
                            "lastName": "Yu",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clement T. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38699354"
                        ],
                        "name": "W. Meng",
                        "slug": "W.-Meng",
                        "structuredName": {
                            "firstName": "Weiyi",
                            "lastName": "Meng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Meng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "ICQ dataset HA [15] ExQ [41] StatParser [36] DIADEM [18]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "Table 3 summarises the form labeling accuracy (F1-score) of DIADEM and compares it to HA [15], ExQ [41], and StatParser [36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1682760,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e11ad25c31f4fb5b8d88672069f33a89f542e161",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Interface modeling & extraction is a fundamental step in building a uniform query interface to a multitude of databases on the Web. Existing solutions are limited in that they assume interfaces are flat and thus ignore the inherent structure of interfaces, which then seriously hampers the effectiveness of interface integration. To address this limitation, in this chapter, we model an interface with a hierarchical schema (e.g., an ordered-tree of attributes). We describe ExQ, a novel schema extraction system with two distinct features. First, ExQ discovers the structure of an interface based on its visual representation via spatial clustering. Second, ExQ annotates the discovered schema with labels from the interface by imitating the human-annotation process. ExQ has been extensively evaluated with real-world query interfaces in five different domains and the results show that ExQ achieves above 90% accuracy rate in both structure discovery & schema annotation tasks."
            },
            "slug": "Modeling-and-Extracting-Deep-Web-Query-Interfaces-Wu-Doan",
            "title": {
                "fragments": [],
                "text": "Modeling and Extracting Deep-Web Query Interfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This chapter describes ExQ, a novel schema extraction system with two distinct features, ExQ discovers the structure of an interface based on its visual representation via spatial clustering and annotates the discovered schema with labels from the interface by imitating the human-annotation process."
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Information and Intelligent Systems"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791339"
                        ],
                        "name": "Valter Crescenzi",
                        "slug": "Valter-Crescenzi",
                        "structuredName": {
                            "firstName": "Valter",
                            "lastName": "Crescenzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Valter Crescenzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796590"
                        ],
                        "name": "P. Merialdo",
                        "slug": "P.-Merialdo",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Merialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Merialdo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756080"
                        ],
                        "name": "Disheng Qiu",
                        "slug": "Disheng-Qiu",
                        "structuredName": {
                            "firstName": "Disheng",
                            "lastName": "Qiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Disheng Qiu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "Crowdsourcing wrapper validation [10] still requires a large number of workers to obtain accurate wrappers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14723809,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19399dfb4424a429cb53ccfe3bebaadd81de5f0f",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The development of solutions to scale the extraction of data from Web sources is still a challenging issue. High accuracy can be achieved by supervised approaches but the costs of training data, i.e., annotations over a set of sample pages, limit their scalability. Crowd sourcing platforms are making the manual annotation process more affordable. However, the tasks demanded to these platforms should be extremely simple, to be performed by non-expert people, and their number should be minimized, to contain the costs. We introduce a framework to support a supervised wrapper inference system with training data generated by the crowd. Training data are labeled values generated by means of membership queries, the simplest form of queries, posed to the crowd. We show that the costs of producing the training data are strongly affected by the expressiveness of the wrapper formalism and by the choice of the training set. Traditional supervised wrapper inference approaches use a statically defined formalism, assuming it is able to express the wrapper. Conversely, we present an inference algorithm that dynamically chooses the expressiveness of the wrapper formalism and actively selects the training set, while minimizing the number of membership queries to the crowd. We report the results of experiments on real web sources to confirm the effectiveness and the feasibility of the approach."
            },
            "slug": "A-framework-for-learning-web-wrappers-from-the-Crescenzi-Merialdo",
            "title": {
                "fragments": [],
                "text": "A framework for learning web wrappers from the crowd"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces a framework to support a supervised wrapper inference system with training data generated by the crowd, and presents an inference algorithm that dynamically chooses the expressiveness of the wrapper formalism and actively selects the training set, while minimizing the number of membership queries to the crowd."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734682"
                        ],
                        "name": "P. Senellart",
                        "slug": "P.-Senellart",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Senellart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Senellart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3323099"
                        ],
                        "name": "Avin Mittal",
                        "slug": "Avin-Mittal",
                        "structuredName": {
                            "firstName": "Avin",
                            "lastName": "Mittal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Avin Mittal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3116283"
                        ],
                        "name": "D. Muschick",
                        "slug": "D.-Muschick",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Muschick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Muschick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741371"
                        ],
                        "name": "R\u00e9mi Gilleron",
                        "slug": "R\u00e9mi-Gilleron",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Gilleron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9mi Gilleron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144640325"
                        ],
                        "name": "M. Tommasi",
                        "slug": "M.-Tommasi",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Tommasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tommasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7896529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e70cf29922d7f23a3e22b7655d37811464e2f29a",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an original approach to the automatic induction of wrappers for sources of the hidden Web that does not need any human supervision. Our approach only needs domain knowledge expressed as a set of concept names and concept instances. There are two parts in extracting valuable data from hidden-Web sources: understanding the structure of a given HTML form and relating its fields to concepts of the domain, and understanding how resulting records are represented in an HTML result page. For the former problem, we use a combination of heuristics and of probing with domain instances; for the latter, we use a supervised machine learning technique adapted to tree-like information on an automatic, imperfect, and imprecise, annotation using the domain knowledge. We show experiments that demonstrate the validity and potential of the approach."
            },
            "slug": "Automatic-wrapper-induction-from-hidden-web-sources-Senellart-Mittal",
            "title": {
                "fragments": [],
                "text": "Automatic wrapper induction from hidden-web sources with domain knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An original approach to the automatic induction of wrappers for sources of the hidden Web that does not need any human supervision and only needs domain knowledge expressed as a set of concept names and concept instances."
            },
            "venue": {
                "fragments": [],
                "text": "WIDM '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40941894"
                        ],
                        "name": "Soumen Chakrabarti",
                        "slug": "Soumen-Chakrabarti",
                        "structuredName": {
                            "firstName": "Soumen",
                            "lastName": "Chakrabarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumen Chakrabarti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113834241"
                        ],
                        "name": "M. V. D. Berg",
                        "slug": "M.-V.-D.-Berg",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Berg",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. V. D. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786444"
                        ],
                        "name": "B. Dom",
                        "slug": "B.-Dom",
                        "structuredName": {
                            "firstName": "Byron",
                            "lastName": "Dom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dom"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "DIADEM\u2019s exploration combines focused crawling [7] and automatic form filling [29, 31, 38]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206134284,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "daac06a4830488f0d47278e3c0c17394646d8354",
            "isKey": false,
            "numCitedBy": 1777,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Focused-Crawling:-A-New-Approach-to-Topic-Specific-Chakrabarti-Berg",
            "title": {
                "fragments": [],
                "text": "Focused Crawling: A New Approach to Topic-Specific Web Resource Discovery"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760944"
                        ],
                        "name": "Mirko Bronzi",
                        "slug": "Mirko-Bronzi",
                        "structuredName": {
                            "firstName": "Mirko",
                            "lastName": "Bronzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirko Bronzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791339"
                        ],
                        "name": "Valter Crescenzi",
                        "slug": "Valter-Crescenzi",
                        "structuredName": {
                            "firstName": "Valter",
                            "lastName": "Crescenzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Valter Crescenzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796590"
                        ],
                        "name": "P. Merialdo",
                        "slug": "P.-Merialdo",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Merialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Merialdo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802817"
                        ],
                        "name": "Paolo Papotti",
                        "slug": "Paolo-Papotti",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Papotti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paolo Papotti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5774632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "131383aa1f91eb0e9578dcae80f4dfcfb0f11e3e",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised approach for harvesting the data exposed by a set of structured and partially overlapping data-intensive web sources. Our proposal comes within a formal framework tackling two problems: the data extraction problem, to generate extraction rules based on the input websites, and the data integration problem, to integrate the extracted data in a unified schema. We introduce an original algorithm, WEIR, to solve the stated problems and formally prove its correctness. WEIR leverages the overlapping data among sources to make better decisions both in the data extraction (by pruning rules that do not lead to redundant information) and in the data integration (by reflecting local properties of a source over the mediated schema). Along the way, we characterize the amount of redundancy needed by our algorithm to produce a solution, and present experimental results to show the benefits of our approach with respect to existing solutions."
            },
            "slug": "Extraction-and-Integration-of-Partially-Overlapping-Bronzi-Crescenzi",
            "title": {
                "fragments": [],
                "text": "Extraction and Integration of Partially Overlapping Web Sources"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An original algorithm, WEIR, is introduced to solve the stated problems and formally prove its correctness and the amount of redundancy needed by the algorithm to produce a solution is characterized."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2627799"
                        ],
                        "name": "P. Gulhane",
                        "slug": "P.-Gulhane",
                        "structuredName": {
                            "firstName": "Pankaj",
                            "lastName": "Gulhane",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gulhane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696519"
                        ],
                        "name": "R. Rastogi",
                        "slug": "R.-Rastogi",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Rastogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rastogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757518"
                        ],
                        "name": "Srinivasan H. Sengamedu",
                        "slug": "Srinivasan-H.-Sengamedu",
                        "structuredName": {
                            "firstName": "Srinivasan",
                            "lastName": "Sengamedu",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Srinivasan H. Sengamedu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2990683"
                        ],
                        "name": "Ashwin Tengli",
                        "slug": "Ashwin-Tengli",
                        "structuredName": {
                            "firstName": "Ashwin",
                            "lastName": "Tengli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashwin Tengli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "It differs from open information extraction [16, 37], where the target is unstructured text, and from product extraction [22], targeting unstructured product listings."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9237436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bcf4adf0d69e9b9f8606eb42d90ea4558389e71",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel extraction approach that exploits content redundancy on the web to extract structured data from template-based web sites. We start by populating a seed database with records extracted from a few initial sites. We then identify values within the pages of each new site that match attribute values contained in the seed set of records. To match attribute values with diverse representations across sites, we define a new similarity metric that leverages the templatized structure of attribute content. Specifically, our metric discovers the matching pattern between attribute values from two sites, and uses this to ignore extraneous portions of attribute values when computing similarity scores. Further, to filter out noisy attribute value matches, we exploit the fact that attribute values occur at fixed positions within template-based sites. We develop an efficient Apriori-style algorithm to systematically enumerate attribute position configurations with sufficient matching values across pages. Finally, we conduct an extensive experimental study with real-life web data to demonstrate the effectiveness of our extraction approach."
            },
            "slug": "Exploiting-content-redundancy-for-web-information-Gulhane-Rastogi",
            "title": {
                "fragments": [],
                "text": "Exploiting content redundancy for web information extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A novel extraction approach that exploits content redundancy on the web to extract structured data from template-based web sites by developing an efficient Apriori-style algorithm to systematically enumerate attribute position configurations with sufficient matching values across pages."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2662719"
                        ],
                        "name": "Hongkun Zhao",
                        "slug": "Hongkun-Zhao",
                        "structuredName": {
                            "firstName": "Hongkun",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongkun Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38699354"
                        ],
                        "name": "W. Meng",
                        "slug": "W.-Meng",
                        "structuredName": {
                            "firstName": "Weiyi",
                            "lastName": "Meng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Meng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109556899"
                        ],
                        "name": "Zonghuan Wu",
                        "slug": "Zonghuan-Wu",
                        "structuredName": {
                            "firstName": "Zonghuan",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zonghuan Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714283"
                        ],
                        "name": "Vijay V. Raghavan",
                        "slug": "Vijay-V.-Raghavan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Raghavan",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay V. Raghavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642131"
                        ],
                        "name": "Clement T. Yu",
                        "slug": "Clement-T.-Yu",
                        "structuredName": {
                            "firstName": "Clement",
                            "lastName": "Yu",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clement T. Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "For the record and attribute identification accuracy, we compare DIADEM with RoadRunner [9], MDR [27], ViNTs [44] (in supervised mode where we provide a set of result pages) and Depta [43]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 182
                            }
                        ],
                        "text": "Attempts to automate the extraction process via unsupervised learning of hidden page templates by discovering structural and visual regularities lead to unsupervised data extraction [9, 23, 27, 28, 34, 43, 44, 35, 40]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "Successful applications of AFE have been limited to narrow settings with simple structure, such as title and body extraction for news articles [39] or search engine results (ViNTs [44])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "For example, ViNTs [44] full-site extraction identifies records (of title and body only) with only 83%-88% accuracy (Section 5), even when supervised by selecting negative and positive examples of result pages for each site."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "For the latter, we also show the corresponding numbers for ViNTs [44]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": ", search-engine listings (ViNTs [44]), thus trading generality for scalability."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "In contrast to previous AFE systems, such as ViNTs [44], DIADEM extracts, for over 90% of the 10602 evaluated websites, highly structured data with dozens of attributes at 97% accuracy."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 6149544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7eb6b3c556755146897fb06524e66af3da8af572",
            "isKey": true,
            "numCitedBy": 364,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "When a query is submitted to a search engine, the search engine returns a dynamically generated result page containing the result records, each of which usually consists of a link to and/or snippet of a retrieved Web page. In addition, such a result page often also contains information irrelevant to the query, such as information related to the hosting site of the search engine and advertisements. In this paper, we present a technique for automatically producing wrappers that can be used to extract search result records from dynamically generated result pages returned by search engines. Automatic search result record extraction is very important for many applications that need to interact with search engines such as automatic construction and maintenance of metasearch engines and deep Web crawling. The novel aspect of the proposed technique is that it utilizes both the visual content features on the result page as displayed on a browser and the HTML tag structures of the HTML source file of the result page. Experimental results indicate that this technique can achieve very high extraction accuracy."
            },
            "slug": "Fully-automatic-wrapper-generation-for-search-Zhao-Meng",
            "title": {
                "fragments": [],
                "text": "Fully automatic wrapper generation for search engines"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A technique for automatically producing wrappers that can be used to extract search result records from dynamically generated result pages returned by search engines, and experimental results indicate that this technique can achieve very high extraction accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1923209"
                        ],
                        "name": "Nilesh N. Dalvi",
                        "slug": "Nilesh-N.-Dalvi",
                        "structuredName": {
                            "firstName": "Nilesh",
                            "lastName": "Dalvi",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nilesh N. Dalvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683442"
                        ],
                        "name": "Ravi Kumar",
                        "slug": "Ravi-Kumar",
                        "structuredName": {
                            "firstName": "Ravi",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ravi Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144018773"
                        ],
                        "name": "Mohamed A. Soliman",
                        "slug": "Mohamed-A.-Soliman",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Soliman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohamed A. Soliman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Specifically, [13] considers certain subsets of automatically generated, possibly noisy annotations and induces wrappers for each of subsets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 65
                            }
                        ],
                        "text": "Domain knowledge has been used in existing extraction approaches [35, 13, 14], however, DIADEM uses knowledge in a unique fashion: Its domain knowledge, the DIADEM ontology, not only includes a schema of the domain and entity recognisers for the schema types, but also classifies and constrains these types with respect to their appearance on web sites."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 181
                            }
                        ],
                        "text": "Domain knowledge has recently been increasingly employed in record identification, mostly for reducing supervision in wrapper induction via automatic annotation of training samples [13, 33] or for schema-based validation of the extraction [14, 35]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13] replaces human supervision with automatically-generated annotations at the price of limiting the learning of extraction rules to single attributes, and thus requiring a (possibly infeasible) reconciliation phase in the case of multi-attribute extraction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "65ec5824f6a997df0322827285ee691510b4527a",
            "isKey": true,
            "numCitedBy": 139,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a generic framework to make wrapper induction algorithms tolerant to noise in the training data. This enables us to learn wrappers in a completely unsupervised manner from automatically and cheaply obtained noisy training data, e.g., using dictionaries and regular expressions. By removing the site-level supervision that wrapper-based techniques require, we are able to perform information extraction at web-scale, with accuracy unattained with existing unsupervised extraction techniques. Our system is used in production at Yahoo! and powers live applications."
            },
            "slug": "Automatic-Wrappers-for-Large-Scale-Web-Extraction-Dalvi-Kumar",
            "title": {
                "fragments": [],
                "text": "Automatic Wrappers for Large Scale Web Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "By removing the site-level supervision that wrapper-based techniques require, this work is able to perform information extraction at web-scale, with accuracy unattained with existing unsupervised extraction techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2627799"
                        ],
                        "name": "P. Gulhane",
                        "slug": "P.-Gulhane",
                        "structuredName": {
                            "firstName": "Pankaj",
                            "lastName": "Gulhane",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gulhane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136102"
                        ],
                        "name": "Amit Madaan",
                        "slug": "Amit-Madaan",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Madaan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amit Madaan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259494"
                        ],
                        "name": "Rupesh R. Mehta",
                        "slug": "Rupesh-R.-Mehta",
                        "structuredName": {
                            "firstName": "Rupesh",
                            "lastName": "Mehta",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rupesh R. Mehta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2311735"
                        ],
                        "name": "J. Ramamirtham",
                        "slug": "J.-Ramamirtham",
                        "structuredName": {
                            "firstName": "Jeyashankher",
                            "lastName": "Ramamirtham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ramamirtham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696519"
                        ],
                        "name": "R. Rastogi",
                        "slug": "R.-Rastogi",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Rastogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rastogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1837802"
                        ],
                        "name": "Sandeepkumar Satpal",
                        "slug": "Sandeepkumar-Satpal",
                        "structuredName": {
                            "firstName": "Sandeepkumar",
                            "lastName": "Satpal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sandeepkumar Satpal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757518"
                        ],
                        "name": "Srinivasan H. Sengamedu",
                        "slug": "Srinivasan-H.-Sengamedu",
                        "structuredName": {
                            "firstName": "Srinivasan",
                            "lastName": "Sengamedu",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Srinivasan H. Sengamedu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2990683"
                        ],
                        "name": "Ashwin Tengli",
                        "slug": "Ashwin-Tengli",
                        "structuredName": {
                            "firstName": "Ashwin",
                            "lastName": "Tengli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashwin Tengli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081450365"
                        ],
                        "name": "Charu Tiwari",
                        "slug": "Charu-Tiwari",
                        "structuredName": {
                            "firstName": "Charu",
                            "lastName": "Tiwari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charu Tiwari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 58
                            }
                        ],
                        "text": "Given a set of already annotated pages, wrapper induction [2, 12, 21, 25] derives small wrapper programs to extract the corresponding data from other pages relying on the same page template."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13091007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a12502ba5b9686e37b0ec9d86a2dc7f4b7022ac",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Vertex is a Wrapper Induction system developed at Yahoo! for extracting structured records from template-based Web pages. To operate at Web scale, Vertex employs a host of novel algorithms for (1) Grouping similar structured pages in a Web site, (2) Picking the appropriate sample pages for wrapper inference, (3) Learning XPath-based extraction rules that are robust to variations in site structure, (4) Detecting site changes by monitoring sample pages, and (5) Optimizing editorial costs by reusing rules, etc. The system is deployed in production and currently extracts more than 250 million records from more than 200 Web sites. To the best of our knowledge, Vertex is the first system to do high-precision information extraction at Web scale."
            },
            "slug": "Web-scale-information-extraction-with-vertex-Gulhane-Madaan",
            "title": {
                "fragments": [],
                "text": "Web-scale information extraction with vertex"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "Vertex is a Wrapper Induction system developed at Yahoo! for extracting structured records from template-based Web pages that is the first system to do high-precision information extraction at Web scale."
            },
            "venue": {
                "fragments": [],
                "text": "2011 IEEE 27th International Conference on Data Engineering"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1923209"
                        ],
                        "name": "Nilesh N. Dalvi",
                        "slug": "Nilesh-N.-Dalvi",
                        "structuredName": {
                            "firstName": "Nilesh",
                            "lastName": "Dalvi",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nilesh N. Dalvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730124"
                        ],
                        "name": "P. Bohannon",
                        "slug": "P.-Bohannon",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Bohannon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bohannon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145757665"
                        ],
                        "name": "Fei Sha",
                        "slug": "Fei-Sha",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Sha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Sha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 58
                            }
                        ],
                        "text": "Given a set of already annotated pages, wrapper induction [2, 12, 21, 25] derives small wrapper programs to extract the corresponding data from other pages relying on the same page template."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 51
                            }
                        ],
                        "text": "Semisupervised data extraction approaches, such as [2, 12], have been investigated extensively, but require users to supervise the induction by navigating each site and identifying relevant data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10711472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b47e5640376b1a3858e1f8119b8588d1e7517f6c",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "On script-generated web sites, many documents share common HTML tree structure, allowing wrappers to effectively extract information of interest. Of course, the scripts and thus the tree structure evolve over time, causing wrappers to break repeatedly, and resulting in a high cost of maintaining wrappers. In this paper, we explore a novel approach: we use temporal snapshots of web pages to develop a tree-edit model of HTML, and use this model to improve wrapper construction. We view the changes to the tree structure as suppositions of a series of edit operations: deleting nodes, inserting nodes and substituting labels of nodes. The tree structures evolve by choosing these edit operations stochastically. Our model is attractive in that the probability that a source tree has evolved into a target tree can be estimated efficiently--in quadratic time in the size of the trees--making it a potentially useful tool for a variety of tree-evolution problems. We give an algorithm to learn the probabilistic model from training examples consisting of pairs of trees, and apply this algorithm to collections of web-page snapshots to derive HTML-specific tree edit models. Finally, we describe a novel wrapper-construction framework that takes the tree-edit model into account, and compare the quality of resulting wrappers to that of traditional wrappers on synthetic and real HTML document examples."
            },
            "slug": "Robust-web-extraction:-an-approach-based-on-a-model-Dalvi-Bohannon",
            "title": {
                "fragments": [],
                "text": "Robust web extraction: an approach based on a probabilistic tree-edit model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper uses temporal snapshots of web pages to develop a tree-edit model of HTML, and uses this model to improve wrapper construction, and gives an algorithm to learn the probabilistic model from training examples consisting of pairs of trees."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD Conference"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144027083"
                        ],
                        "name": "Hoa Nguyen",
                        "slug": "Hoa-Nguyen",
                        "structuredName": {
                            "firstName": "Hoa",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hoa Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144101748"
                        ],
                        "name": "T. Nguyen",
                        "slug": "T.-Nguyen",
                        "structuredName": {
                            "firstName": "Thanh",
                            "lastName": "Nguyen",
                            "middleNames": [
                                "Hoang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144162611"
                        ],
                        "name": "J. Freire",
                        "slug": "J.-Freire",
                        "structuredName": {
                            "firstName": "Juliana",
                            "lastName": "Freire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Freire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2552049,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b611a3742e8c5373e4c889394884e9fbee61c9e",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new approach to extract element labels from Web form interfaces. Having these labels is a requirement for several techniques that attempt to retrieve and integrate information that is hidden behind form interfaces, such as hidden Web crawlers and metasearchers. However, given the wide variation in form layout, even within a well-defined domain, automatically extracting these labels is a challenging problem. Whereas previous approaches to this problem have relied on heuristics and manually specified extraction rules, our technique makes use of a learning classifier ensemble to identify element-label mappings; and it applies a reconciliation step which leverages the classifier-derived mappings to boost extraction accuracy. We present a detailed experimental evaluation using over three thousand Web forms. Our results show that our approach is effective: it obtains significantly higher accuracy and is more robust to variability in form layout than previous label extraction techniques."
            },
            "slug": "Learning-to-extract-form-labels-Nguyen-Nguyen",
            "title": {
                "fragments": [],
                "text": "Learning to extract form labels"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This technique makes use of a learning classifier ensemble to identify element-label mappings; and it applies a reconciliation step which leverages the classifier-derived mappings to boost extraction accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1923209"
                        ],
                        "name": "Nilesh N. Dalvi",
                        "slug": "Nilesh-N.-Dalvi",
                        "structuredName": {
                            "firstName": "Nilesh",
                            "lastName": "Dalvi",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nilesh N. Dalvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2357165"
                        ],
                        "name": "Ashwin Machanavajjhala",
                        "slug": "Ashwin-Machanavajjhala",
                        "structuredName": {
                            "firstName": "Ashwin",
                            "lastName": "Machanavajjhala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashwin Machanavajjhala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144865353"
                        ],
                        "name": "B. Pang",
                        "slug": "B.-Pang",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Pang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Pang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "A significant portion of data is only available in this long-tail [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6820835,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9bdef4898c3cbdc196a4d076e9bd5df38b97f28d",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we analyze the nature and distribution of structured data on the Web. Web-scale information extraction, or the problem of creating structured tables using extraction from the entire web, is gathering lots of research interest. We perform a study to understand and quantify the value of Web-scale extraction, and how structured information is distributed amongst top aggregator websites and tail sites for various interesting domains. We believe this is the first study of its kind, and gives us new insights for information extraction over the Web."
            },
            "slug": "An-Analysis-of-Structured-Data-on-the-Web-Dalvi-Machanavajjhala",
            "title": {
                "fragments": [],
                "text": "An Analysis of Structured Data on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This is the first study of its kind to understand and quantify the value of Web-scale extraction, and how structured information is distributed amongst top aggregator websites and tail sites for various interesting domains."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996394"
                        ],
                        "name": "Lidong Bing",
                        "slug": "Lidong-Bing",
                        "structuredName": {
                            "firstName": "Lidong",
                            "lastName": "Bing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lidong Bing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144594306"
                        ],
                        "name": "Wai Lam",
                        "slug": "Wai-Lam",
                        "structuredName": {
                            "firstName": "Wai",
                            "lastName": "Lam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wai Lam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39756936"
                        ],
                        "name": "Tak-Lam Wong",
                        "slug": "Tak-Lam-Wong",
                        "structuredName": {
                            "firstName": "Tak-Lam",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tak-Lam Wong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 158
                            }
                        ],
                        "text": "Notice that this problem also affects approaches based on statistical redundancy that accumulate generic knowledge about the structure of the results such as [3, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "/(//div[3]//li[1]/foll-sibl::li[@class=\u2019paging-next\u2019]/a[@class=\u2019pagingbutton\u2019]/{nextclick /})* \u00c3"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6031858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e41e3d45115d45a6553db7dc89d18fcb1f3fa459",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Web data record extraction aims at extracting a set of similar object records from a single webpage. These records have similar attributes or fields and are presented with a regular format in a coherent region of the page. To tackle this problem, most existing works analyze the DOM tree of an input page. One major limitation of these methods is that the lack of a global view in detecting data records from an input page results in a myopic decision. Their brute-force searching manner in detecting various types of records degrades the flexibility and robustness. We propose a Structure-Knowledge-Oriented Global Analysis (Skoga) framework which can perform robust detection of different-kinds of data records and record regions. The major component of the Skoga framework is a DOM structure-knowledge-driven detection model which can conduct a global analysis on the DOM structure to achieve effective detection. The DOM structure knowledge consists of background knowledge as well as statistical knowledge capturing different characteristics of data records and record regions, as exhibited in the DOM structure. The background knowledge encodes the semantics of labels indicating general constituents of data records and regions. The statistical knowledge is represented by some carefully designed features that capture different characteristics of a single node or a node group in the DOM. The feature weights are determined using a development dataset via a parameter estimation algorithm based on a structured output support vector machine. An optimization method based on the divide-and-conquer principle is developed making use of the DOM structure knowledge to quantitatively infer and recognize appropriate records and regions for a page. Extensive experiments have been conducted on four datasets. The experimental results demonstrate that our framework achieves higher accuracy compared with state-of-the-art methods."
            },
            "slug": "Robust-detection-of-semi-structured-web-records-a-Bing-Lam",
            "title": {
                "fragments": [],
                "text": "Robust detection of semi-structured web records using a DOM structure-knowledge-driven model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a Structure-Knowledge-Oriented Global Analysis (Skoga) framework which can perform robust detection of different-kinds of data records and record regions and achieves higher accuracy compared with state-of-the-art methods."
            },
            "venue": {
                "fragments": [],
                "text": "TWEB"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2484984"
                        ],
                        "name": "Mohammed Kayed",
                        "slug": "Mohammed-Kayed",
                        "structuredName": {
                            "firstName": "Mohammed",
                            "lastName": "Kayed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohammed Kayed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720956"
                        ],
                        "name": "Chia-Hui Chang",
                        "slug": "Chia-Hui-Chang",
                        "structuredName": {
                            "firstName": "Chia-Hui",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chia-Hui Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40241708"
                        ],
                        "name": "K. Shaalan",
                        "slug": "K.-Shaalan",
                        "structuredName": {
                            "firstName": "Khaled",
                            "lastName": "Shaalan",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shaalan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570984"
                        ],
                        "name": "M. Girgis",
                        "slug": "M.-Girgis",
                        "structuredName": {
                            "firstName": "Moheb",
                            "lastName": "Girgis",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Girgis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2982778,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39fc8e9f8f423c4a520216fb3e4fbd87e56074fb",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Web data extraction has been an important part for many Web data analysis applications. In this paper, we formulate the data extraction problem as the decoding process of page generation based on structured data and tree templates. We propose an unsupervised, page-level data extraction approach to deduce the schema and templates for each individual deep Website, which contains either singleton or multiple data records in one Webpage. FiVaTech applies tree matching, tree alignment, and mining techniques to achieve the challenging task. In experiments, FiVaTech has much higher precision than EXALG and is comparable with other record-level extraction systems like ViPER and MSE. The experiments show an encouraging result for the test pages used in many state-of-the-art Web data extraction works."
            },
            "slug": "FiVaTech:-Page-Level-Web-Data-Extraction-from-Pages-Kayed-Chang",
            "title": {
                "fragments": [],
                "text": "FiVaTech: Page-Level Web Data Extraction from Template Pages"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "FiVaTech proposes an unsupervised, page-level data extraction approach to deduce the schema and templates for each individual deep Website, which contains either singleton or multiple data records in one Webpage."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679784"
                        ],
                        "name": "Fabian M. Suchanek",
                        "slug": "Fabian-M.-Suchanek",
                        "structuredName": {
                            "firstName": "Fabian",
                            "lastName": "Suchanek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabian M. Suchanek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686448"
                        ],
                        "name": "Gjergji Kasneci",
                        "slug": "Gjergji-Kasneci",
                        "structuredName": {
                            "firstName": "Gjergji",
                            "lastName": "Kasneci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gjergji Kasneci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751591"
                        ],
                        "name": "G. Weikum",
                        "slug": "G.-Weikum",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Weikum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Weikum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 44
                            }
                        ],
                        "text": "It differs from open information extraction [16, 37], where the target is unstructured text, and from product extraction [22], targeting unstructured product listings."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207163173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00a3f6924f90fcd77e6e7e6534b957a75d0ced07",
            "isKey": false,
            "numCitedBy": 3480,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We present YAGO, a light-weight and extensible ontology with high coverage and quality. YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts. This includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE). The facts have been automatically extracted from Wikipedia and unified with WordNet, using a carefully designed combination of rule-based and heuristic methods described in this paper. The resulting knowledge base is a major step beyond WordNet: in quality by adding knowledge about individuals like persons, organizations, products, etc. with their semantic relationships - and in quantity by increasing the number of facts by more than an order of magnitude. Our empirical evaluation of fact correctness shows an accuracy of about 95%. YAGO is based on a logically clean model, which is decidable, extensible, and compatible with RDFS. Finally, we show how YAGO can be further extended by state-of-the-art information extraction techniques."
            },
            "slug": "Yago:-a-core-of-semantic-knowledge-Suchanek-Kasneci",
            "title": {
                "fragments": [],
                "text": "Yago: a core of semantic knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts, which includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE)."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110185029"
                        ],
                        "name": "Junfeng Wang",
                        "slug": "Junfeng-Wang",
                        "structuredName": {
                            "firstName": "Junfeng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junfeng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2588203"
                        ],
                        "name": "Chun Chen",
                        "slug": "Chun-Chen",
                        "structuredName": {
                            "firstName": "Chun",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chun Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47074461"
                        ],
                        "name": "C. Wang",
                        "slug": "C.-Wang",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145525190"
                        ],
                        "name": "J. Pei",
                        "slug": "J.-Pei",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Pei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145383433"
                        ],
                        "name": "Jiajun Bu",
                        "slug": "Jiajun-Bu",
                        "structuredName": {
                            "firstName": "Jiajun",
                            "lastName": "Bu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiajun Bu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749272"
                        ],
                        "name": "Ziyu Guan",
                        "slug": "Ziyu-Guan",
                        "structuredName": {
                            "firstName": "Ziyu",
                            "lastName": "Guan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziyu Guan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155468128"
                        ],
                        "name": "Wei Vivian Zhang",
                        "slug": "Wei-Vivian-Zhang",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Zhang",
                            "middleNames": [
                                "Vivian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Vivian Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 149
                            }
                        ],
                        "text": "\u2026services\nGeneral Terms Languages, Experimentation\nKeywords data extraction, deep web, wrapper induction \u2217The research leading to these results has received funding from the European Research Council under the European Community\u2019s Seventh Framework Programme (FP7/2007\u20132013) / ERC grant agreement\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7232091,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f72218e3d9814a7655c92da60ae70a60ade7cba",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic news extraction from news pages is important in many Web applications such as news aggregation. However, the existing news extraction methods based on template-level wrapper induction have three serious limitations. First, the existing methods cannot correctly extract pages belonging to an unseen template. Second, it is costly to maintain up-to-date wrappers for a large amount of news websites, because any change of a template may invalidate the corresponding wrapper. Last, the existing methods can merely extract unformatted plain texts, and thus are not user friendly. In this paper, we tackle the problem of template-independent Web news extraction in a user-friendly way. We formalize Web news extraction as a machine learning problem and learn a template-independent wrapper using a very small number of labeled news pages from a single site. Novel features dedicated to news titles and bodies are developed. Correlations between news titles and news bodies are exploited. Our template-independent wrapper can extract news pages from different sites regardless of templates. Moreover, our approach can extract not only texts, but also images and animates within the news bodies and the extracted news articles are in the same visual style as in the original pages. In our experiments, a wrapper learned from 40 pages from a single news site achieved an accuracy of 98.1% on 3,973 news pages from 12 news sites."
            },
            "slug": "Can-we-learn-a-template-independent-wrapper-for-a-Wang-Chen",
            "title": {
                "fragments": [],
                "text": "Can we learn a template-independent wrapper for news article extraction from a single training site?"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper formalizes Web news extraction as a machine learning problem and learns a template-independent wrapper using a very small number of labeled news pages from a single site."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758619"
                        ],
                        "name": "Yingju Xia",
                        "slug": "Yingju-Xia",
                        "structuredName": {
                            "firstName": "Yingju",
                            "lastName": "Xia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yingju Xia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144051204"
                        ],
                        "name": "Hao Yu",
                        "slug": "Hao-Yu",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108086890"
                        ],
                        "name": "Shu Zhang",
                        "slug": "Shu-Zhang",
                        "structuredName": {
                            "firstName": "Shu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shu Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 158
                            }
                        ],
                        "text": "Notice that this problem also affects approaches based on statistical redundancy that accumulate generic knowledge about the structure of the results such as [3, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11562299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "676286a67713bbdf6c1ed27932b17cb644725f2a",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the automatic extraction of data from forums, blogs and news web sites. Web pages are increasingly dynamically generated using a common template populated with data from databases. This paper proposes a novel method that uses tree alignment to automatically extract data from these types of web pages. A new tree alignment algorithm is presented for determining the optimal matching structure of the input web pages. Based on the alignment, the trees are merged into one union tree whose nodes record statistical information obtained from multiple web pages. A heuristic method is employed for determining the most probable content block and the alignment algorithm detects repeating patterns on the union tree. A wrapper built on the most probable content block and the repeating patterns extracts data from web pages. Experimental results show that the method achieves high extraction accuracy and has steady performance."
            },
            "slug": "Automatic-web-data-extraction-using-tree-alignment-Xia-Yu",
            "title": {
                "fragments": [],
                "text": "Automatic web data extraction using tree alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A novel method that uses tree alignment to automatically extract data from forums, blogs and news web sites is proposed and Experimental results show that the method achieves high extraction accuracy and has steady performance."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145321667"
                        ],
                        "name": "B. Liu",
                        "slug": "B.-Liu",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743874"
                        ],
                        "name": "R. Grossman",
                        "slug": "R.-Grossman",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Grossman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grossman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40343421"
                        ],
                        "name": "Yanhong Zhai",
                        "slug": "Yanhong-Zhai",
                        "structuredName": {
                            "firstName": "Yanhong",
                            "lastName": "Zhai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanhong Zhai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 182
                            }
                        ],
                        "text": "Attempts to automate the extraction process via unsupervised learning of hidden page templates by discovering structural and visual regularities lead to unsupervised data extraction [9, 23, 27, 28, 34, 43, 44, 35, 40]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "For the record and attribute identification accuracy, we compare DIADEM with RoadRunner [9], MDR [27], ViNTs [44] (in supervised mode where we provide a set of result pages) and Depta [43]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "For ViNTs and MDR, we only report the record case, as they return no or very limited (title and body) attributes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "For MDR, we pre-filter navigation menus, footers, headers, pagination links, and other regular structures which otherwise are returned by MDR as records."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11383614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8cdce10fc4c9505ca22796920d1cd4b0f82dc76",
            "isKey": true,
            "numCitedBy": 556,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "A large amount of information on the Web is contained in regularly structured objects, which we call data records. Such data records are important because they often present the essential information of their host pages, e.g., lists of products or services. It is useful to mine such data records in order to extract information from them to provide value-added services. Existing automatic techniques are not satisfactory because of their poor accuracies. In this paper, we propose a more effective technique to perform the task. The technique is based on two observations about data records on the Web and a string matching algorithm. The proposed technique is able to mine both contiguous and non-contiguous data records. Our experimental results show that the proposed technique outperforms existing techniques substantially."
            },
            "slug": "Mining-data-records-in-Web-pages-Liu-Grossman",
            "title": {
                "fragments": [],
                "text": "Mining data records in Web pages"
            },
            "tldr": {
                "abstractSimilarityScore": 34,
                "text": "The experimental results show that the proposed technique outperforms existing techniques substantially, and is able to mine both contiguous and non-contiguous data records."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144221846"
                        ],
                        "name": "Robert Baumgartner",
                        "slug": "Robert-Baumgartner",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Baumgartner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Baumgartner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730314"
                        ],
                        "name": "S. Flesca",
                        "slug": "S.-Flesca",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Flesca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Flesca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684745"
                        ],
                        "name": "G. Gottlob",
                        "slug": "G.-Gottlob",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Gottlob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gottlob"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 58
                            }
                        ],
                        "text": "Given a set of already annotated pages, wrapper induction [2, 12, 21, 25] derives small wrapper programs to extract the corresponding data from other pages relying on the same page template."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 51
                            }
                        ],
                        "text": "Semisupervised data extraction approaches, such as [2, 12], have been investigated extensively, but require users to supervise the induction by navigating each site and identifying relevant data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 432493,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35a38da0b7079bb61ef29bb27915ada2c4665e0a",
            "isKey": false,
            "numCitedBy": 590,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present new techniques for supervised wrapper generation and automated web information extraction, and a system called Lixto implementing these techniques. Our system can generate wrappers which translate relevant pieces of HTML pages into XML. Lixto, of which a working prototype has been implemented, assists the user to semi-automatically create wrapper programs by providing a fully visual and interactive user interface. In this convenient user-interface very expressive extraction programs can be created. Internally, this functionality is reected by the new logicbased declarative language Elog. Users never have to deal with Elog and even familiarity with HTML is not required. Lixto can be used to create an \\XML-Companion\" for an HTML web page with changing content, containing the continually updated XML translation of the relevant information."
            },
            "slug": "Visual-Web-Information-Extraction-with-Lixto-Baumgartner-Flesca",
            "title": {
                "fragments": [],
                "text": "Visual Web Information Extraction with Lixto"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Lixto, of which a working prototype has been implemented, assists the user to semi-automatically create wrapper programs by providing a fully visual and interactive user interface that helps to create very expressive extraction programs."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33947737"
                        ],
                        "name": "Guilherme A. Toda",
                        "slug": "Guilherme-A.-Toda",
                        "structuredName": {
                            "firstName": "Guilherme",
                            "lastName": "Toda",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guilherme A. Toda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2865037"
                        ],
                        "name": "Eli Cortez C. Vilarinho",
                        "slug": "Eli-Cortez-C.-Vilarinho",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Vilarinho",
                            "middleNames": [
                                "Cortez",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eli Cortez C. Vilarinho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690426"
                        ],
                        "name": "A. D. Silva",
                        "slug": "A.-D.-Silva",
                        "structuredName": {
                            "firstName": "Altigran",
                            "lastName": "Silva",
                            "middleNames": [
                                "Soares",
                                "da"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. D. Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733769"
                        ],
                        "name": "E. Moura",
                        "slug": "E.-Moura",
                        "structuredName": {
                            "firstName": "Edleno",
                            "lastName": "Moura",
                            "middleNames": [
                                "Silva",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Moura"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18655394,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c3bb21fe391d8f3e574a8170faec8599fdc58cf",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a proposal for the implementation and evaluation of a novel method for automatically using data-rich text for filling form-based input interfaces. Our solution takes a text as input, extracts implicit data values from it and fills appropriate fields. For this task, we rely on knowledge obtained from values of previous submissions for each field, which are freely obtained from the usage of the interfaces. Our approach, called iForm, exploits features related to the content and the style of these values, which are combined through a Bayesian framework. Through extensive experimentation, we show that our approach is feasible and effective, and that it works well even when only a few previous submissions to the input interface are available."
            },
            "slug": "A-Probabilistic-Approach-for-Automatically-Filling-Toda-Vilarinho",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Approach for Automatically Filling Form-Based Web Interfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper proposes a novel method for automatically using data-rich text for filling form-based input interfaces, called iForm, which exploits features related to the content and the style of these values, which are combined through a Bayesian framework."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115385149"
                        ],
                        "name": "Luying Chen",
                        "slug": "Luying-Chen",
                        "structuredName": {
                            "firstName": "Luying",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luying Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695582"
                        ],
                        "name": "Stefano Ortona",
                        "slug": "Stefano-Ortona",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Ortona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefano Ortona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35203250"
                        ],
                        "name": "G. Orsi",
                        "slug": "G.-Orsi",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Orsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orsi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750856"
                        ],
                        "name": "M. Benedikt",
                        "slug": "M.-Benedikt",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Benedikt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Benedikt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "For more details on some of these aspects, see [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5421275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6341545215fff2c9d20bd916323cd0a50301e3f7",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "A growing number of resources are available for enriching documents with semantic annotations. While originally focused on a few standard classes of annotations, the ecosystem of annotators is now becoming increasingly diverse. Although annotators often have very different vocabularies, with both high-level and specialist concepts, they also have many semantic interconnections. We will show that both the overlap and the diversity in annotator vocabularies motivate the need for semantic annotation integration: middleware that produces a unified annotation on top of diverse semantic annotators. On the one hand, the diversity of vocabulary allows applications to benefit from the much richer vocabulary available in an integrated vocabulary. On the other hand, we present evidence that the most widely-used annotators on the web suffer from serious accuracy deficiencies: the overlap in vocabularies from individual annotators allows an integrated annotator to boost accuracy by exploiting inter-annotator agreement and disagreement. \n \nThe integration of semantic annotations leads to new challenges, both compared to usual data integration scenarios and to standard aggregation of machine learning tools. We overview an approach to these challenges that performs ontology-aware aggregation. We introduce an approach that requires no training data, making use of ideas from database repair. We experimentally compare this with a supervised approach, which adapts maximal entropy Markov models to the setting of ontology-based annotations. We further experimentally compare both these approaches with respect to ontology-unaware supervised approaches, and to individual annotators."
            },
            "slug": "Aggregating-Semantic-Annotators-Chen-Ortona",
            "title": {
                "fragments": [],
                "text": "Aggregating Semantic Annotators"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that both the overlap and the diversity in annotator vocabularies motivate the need for semantic annotation integration: middleware that produces a unified annotation on top of diverse semantic annotators, and an approach to these challenges that performs ontology-aware aggregation."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1853199"
                        ],
                        "name": "Ali Mesbah",
                        "slug": "Ali-Mesbah",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Mesbah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Mesbah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737202"
                        ],
                        "name": "A. Deursen",
                        "slug": "A.-Deursen",
                        "structuredName": {
                            "firstName": "Arie",
                            "lastName": "Deursen",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Deursen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586374"
                        ],
                        "name": "S. Lenselink",
                        "slug": "S.-Lenselink",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Lenselink",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lenselink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 78
                            }
                        ],
                        "text": "DIADEM\u2019s exploration combines focused crawling [7] and automatic form filling [29, 31, 38]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1351916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e8775cd38f7b11545696dd0d3ae56e67f77c446",
            "isKey": false,
            "numCitedBy": 285,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Using JavaScript and dynamic DOM manipulation on the client side of Web applications is becoming a widespread approach for achieving rich interactivity and responsiveness in modern Web applications. At the same time, such techniques---collectively known as Ajax---shatter the concept of webpages with unique URLs, on which traditional Web crawlers are based. This article describes a novel technique for crawling Ajax-based applications through automatic dynamic analysis of user-interface-state changes in Web browsers. Our algorithm scans the DOM tree, spots candidate elements that are capable of changing the state, fires events on those candidate elements, and incrementally infers a state machine that models the various navigational paths and states within an Ajax application. This inferred model can be used in program comprehension and in analysis and testing of dynamic Web states, for instance, or for generating a static version of the application. In this article, we discuss our sequential and concurrent Ajax crawling algorithms. We present our open source tool called Crawljax, which implements the concepts and algorithms discussed in this article. Additionally, we report a number of empirical studies in which we apply our approach to a number of open-source and industrial Web applications and elaborate on the obtained results."
            },
            "slug": "Crawling-Ajax-Based-Web-Applications-through-of-Mesbah-Deursen",
            "title": {
                "fragments": [],
                "text": "Crawling Ajax-Based Web Applications through Dynamic Analysis of User Interface State Changes"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel technique for crawling Ajax-based applications through automatic dynamic analysis of user-interface-state changes in Web browsers, and incrementally infers a state machine that models the various navigational paths and states within an Ajax application."
            },
            "venue": {
                "fragments": [],
                "text": "TWEB"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2239271"
                        ],
                        "name": "Weifeng Su",
                        "slug": "Weifeng-Su",
                        "structuredName": {
                            "firstName": "Weifeng",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weifeng Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110165806"
                        ],
                        "name": "Jiying Wang",
                        "slug": "Jiying-Wang",
                        "structuredName": {
                            "firstName": "Jiying",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiying Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2182929"
                        ],
                        "name": "F. Lochovsky",
                        "slug": "F.-Lochovsky",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Lochovsky",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lochovsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 182
                            }
                        ],
                        "text": "Attempts to automate the extraction process via unsupervised learning of hidden page templates by discovering structural and visual regularities lead to unsupervised data extraction [9, 23, 27, 28, 34, 43, 44, 35, 40]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 65
                            }
                        ],
                        "text": "Domain knowledge has been used in existing extraction approaches [35, 13, 14], however, DIADEM uses knowledge in a unique fashion: Its domain knowledge, the DIADEM ontology, not only includes a schema of the domain and entity recognisers for the schema types, but also classifies and constrains these types with respect to their appearance on web sites."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 239
                            }
                        ],
                        "text": "Domain knowledge has recently been increasingly employed in record identification, mostly for reducing supervision in wrapper induction via automatic annotation of training samples [13, 33] or for schema-based validation of the extraction [14, 35]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1072853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95679bc58a0cfe7f0dbdcc2c200005dd4ae2fb9d",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Online databases respond to a user query with result records encoded in HTML files. Data extraction, which is important for many applications, extracts the records from the HTML files automatically. We present a novel data extraction method, ODE (Ontology-assisted Data Extraction), which automatically extracts the query result records from the HTML pages. ODE first constructs an ontology for a domain according to information matching between the query interfaces and query result pages from different Web sites within the same domain. Then, the constructed domain ontology is used during data extraction to identify the query result section in a query result page and to align and label the data values in the extracted records. The ontology-assisted data extraction method is fully automatic and overcomes many of the deficiencies of current automatic data extraction methods. Experimental results show that ODE is extremely accurate for identifying the query result section in an HTML page, segmenting the query result section into query result records, and aligning and labeling the data values in the query result records."
            },
            "slug": "ODE:-Ontology-assisted-data-extraction-Su-Wang",
            "title": {
                "fragments": [],
                "text": "ODE: Ontology-assisted data extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work presents a novel data extraction method, ODE (Ontology-assisted Data Extraction), which automatically extracts the query result records from the HTML pages, and shows that ODE is extremely accurate for identifying the queryresult section in an HTML page, segmenting the query results section into query result record records, and aligning and labeling the data values in thequery result records."
            },
            "venue": {
                "fragments": [],
                "text": "TODS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2239271"
                        ],
                        "name": "Weifeng Su",
                        "slug": "Weifeng-Su",
                        "structuredName": {
                            "firstName": "Weifeng",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weifeng Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477116"
                        ],
                        "name": "Hejun Wu",
                        "slug": "Hejun-Wu",
                        "structuredName": {
                            "firstName": "Hejun",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hejun Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110450959"
                        ],
                        "name": "Yafei Li",
                        "slug": "Yafei-Li",
                        "structuredName": {
                            "firstName": "Yafei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yafei Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150659192"
                        ],
                        "name": "Jing Zhao",
                        "slug": "Jing-Zhao",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2182929"
                        ],
                        "name": "F. Lochovsky",
                        "slug": "F.-Lochovsky",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Lochovsky",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lochovsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40443271"
                        ],
                        "name": "Hongmin Cai",
                        "slug": "Hongmin-Cai",
                        "structuredName": {
                            "firstName": "Hongmin",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongmin Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2394065"
                        ],
                        "name": "Tianqiang Huang",
                        "slug": "Tianqiang-Huang",
                        "structuredName": {
                            "firstName": "Tianqiang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianqiang Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "ICQ dataset HA [15] ExQ [41] StatParser [36] DIADEM [18]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "Table 3 summarises the form labeling accuracy (F1-score) of DIADEM and compares it to HA [15], ExQ [41], and StatParser [36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14262133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5aaab8cbf449fccb0be24c416c4f9f9b4901e37c",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Users submit queries to an online database via its query interface. Query interface parsing, which is important for many applications, understands the query capabilities of a query interface. Since most query interfaces are organized hierarchically, we present a novel query interface parsing method, StatParser (Statistical Parser), to automatically extract the hierarchical query capabilities of query interfaces. StatParser automatically learns from a set of parsed query interfaces and parses new query interfaces. StatParser starts from a small grammar and enhances the grammar with a set of probabilities learned from parsed query interfaces under the maximum-entropy principle. Given a new query interface, the probability-enhanced grammar identifies the parse tree with the largest global probability to be the query capabilities of the query interface. Experimental results show that StatParser very accurately extracts the query capabilities and can effectively overcome the problems of existing query interface parsers."
            },
            "slug": "Understanding-query-interfaces-by-statistical-Su-Wu",
            "title": {
                "fragments": [],
                "text": "Understanding query interfaces by statistical parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental results show that StatParser very accurately extracts the query capabilities and can effectively overcome the problems of existing query interface parsers."
            },
            "venue": {
                "fragments": [],
                "text": "TWEB"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69026873"
                        ],
                        "name": "S. Abiteboul",
                        "slug": "S.-Abiteboul",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Abiteboul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Abiteboul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765187"
                        ],
                        "name": "V. Vianu",
                        "slug": "V.-Vianu",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Vianu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vianu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135808"
                        ],
                        "name": "Bradley S. Fordham",
                        "slug": "Bradley-S.-Fordham",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Fordham",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bradley S. Fordham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711175"
                        ],
                        "name": "Y. Yesha",
                        "slug": "Y.-Yesha",
                        "structuredName": {
                            "firstName": "Yelena",
                            "lastName": "Yesha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yesha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "DIADEM extends relational transducers from [1] with (1) resuming, (2) scoping, and (3) dependencies."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "/(//div[3]//li[1]/foll-sibl::li[@class=\u2019paging-next\u2019]/a[@class=\u2019pagingbutton\u2019]/{nextclick /})* \u00c3"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "//h1/span/span[1]/text()[1]:<search_results_number=norm(."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6267677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7907fa04f1adf6163c704de51ff08a185ca577dd",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Electronic commerce is emerging as one of the major Web-supported applications requiring database support. We introduce and study high-level declarative specifications of business models, using an approach in the spirit of active databases. More precisely, business models are specified as relational transducers that map sequences of input relations into sequences of output relations. The semantically meaningful trace of an input?output exchange is kept as a sequence of log relations. We consider problems motivated by electronic commerce applications, such as log validation, verifying temporal properties of transducers, and comparing two relational transducers. Positive results are obtained for a restricted class of relational transducers called Spocus transducers (for semi-positive outputs and cumulative state). We argue that despite the restrictions, these capture a wide range of practically significant business models."
            },
            "slug": "Relational-transducers-for-electronic-commerce-Abiteboul-Vianu",
            "title": {
                "fragments": [],
                "text": "Relational transducers for electronic commerce"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work introduces and study high-level declarative specifications of business models, specified as relational transducers that map sequences of input relations into sequences of output relations, and argues that these capture a wide range of practically significant business models."
            },
            "venue": {
                "fragments": [],
                "text": "PODS '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144491891"
                        ],
                        "name": "N. Leone",
                        "slug": "N.-Leone",
                        "structuredName": {
                            "firstName": "Nicola",
                            "lastName": "Leone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Leone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144025951"
                        ],
                        "name": "G. Pfeifer",
                        "slug": "G.-Pfeifer",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Pfeifer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Pfeifer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50484601"
                        ],
                        "name": "Wolfgang Faber",
                        "slug": "Wolfgang-Faber",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Faber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Faber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72431510"
                        ],
                        "name": "Thomas Eiter",
                        "slug": "Thomas-Eiter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Eiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Eiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684745"
                        ],
                        "name": "G. Gottlob",
                        "slug": "G.-Gottlob",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Gottlob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gottlob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9950515"
                        ],
                        "name": "S. Perri",
                        "slug": "S.-Perri",
                        "structuredName": {
                            "firstName": "Simona",
                            "lastName": "Perri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Perri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764248"
                        ],
                        "name": "Francesco Scarcello",
                        "slug": "Francesco-Scarcello",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Scarcello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francesco Scarcello"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The DLV system for knowledge representation and reasoning."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "The current version of DIADEM uses DLV [26] as Datalog\u00ac engine for most of the transducers, except some parts that communicate with the browser or external tools, that are implemented in Java."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1189466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1888bbaf6203ddfacffa4ff70f5e01a102c29895",
            "isKey": false,
            "numCitedBy": 1257,
            "numCiting": 199,
            "paperAbstract": {
                "fragments": [],
                "text": "Disjunctive Logic Programming (DLP) is an advanced formalism for knowledge representation and reasoning, which is very expressive in a precise mathematical sense: it allows one to express every property of finite structures that is decidable in the complexity class \u03a3P2 (NPNP). Thus, under widely believed assumptions, DLP is strictly more expressive than normal (disjunction-free) logic programming, whose expressiveness is limited to properties decidable in NP. Importantly, apart from enlarging the class of applications which can be encoded in the language, disjunction often allows for representing problems of lower complexity in a simpler and more natural fashion.This article presents the DLV system, which is widely considered the state-of-the-art implementation of disjunctive logic programming, and addresses several aspects. As for problem solving, we provide a formal definition of its kernel language, function-free disjunctive logic programs (also known as disjunctive datalog), extended by weak constraints, which are a powerful tool to express optimization problems. We then illustrate the usage of DLV as a tool for knowledge representation and reasoning, describing a new declarative programming methodology which allows one to encode complex problems (up to \u0394P3-complete problems) in a declarative fashion. On the foundational side, we provide a detailed analysis of the computational complexity of the language of DLV, and by deriving new complexity results we chart a complete picture of the complexity of this language and important fragments thereof.Furthermore, we illustrate the general architecture of the DLV system, which has been influenced by these results. As for applications, we overview application front-ends which have been developed on top of DLV to solve specific knowledge representation tasks, and we briefly describe the main international projects investigating the potential of the system for industrial exploitation. Finally, we report about thorough experimentation and benchmarking, which has been carried out to assess the efficiency of the system. The experimental results confirm the solidity of DLV and highlight its potential for emerging application areas like knowledge management and information integration."
            },
            "slug": "The-DLV-system-for-knowledge-representation-and-Leone-Pfeifer",
            "title": {
                "fragments": [],
                "text": "The DLV system for knowledge representation and reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The experimental results confirm the solidity of DLV and highlight its potential for emerging application areas like knowledge management and information integration, and the main international projects investigating the potential of the system for industrial exploitation are described."
            },
            "venue": {
                "fragments": [],
                "text": "TOCL"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A core of semantic knowledge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Can we learn a template-independent wrapper for news article extraction from a single training site? In KDD"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 143
                            }
                        ],
                        "text": "Successful applications of AFE have been limited to narrow settings with simple structure, such as title and body extraction for news articles [39] or search engine results (ViNTs [44])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": ", news [39], or on the structure of the results, e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Can we learn a template-independent wrapper for news article extraction from a single training site? In KDD, p"
            },
            "venue": {
                "fragments": [],
                "text": "1345\u20131354,"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Online retail in the united states"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "Through an extensive evaluation spanning over 10000 web sites from multiple application domains, we show that automatic, yet accurate full-site extraction is no longer a distant dream."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Online retail in the united states On-line at http://www.marketresearch.com/MarketLine-v3883/ Online-Retail-United-States-7760207"
            },
            "venue": {
                "fragments": [],
                "text": "Online retail in the united states On-line at http://www.marketresearch.com/MarketLine-v3883/ Online-Retail-United-States-7760207"
            },
            "year": 2013
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 20,
            "methodology": 22,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 48,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/DIADEM:-Thousands-of-Websites-to-a-Single-Database-Furche-Gottlob/ee6196f097453aa897b0712e3a31c315b8ae9894?sort=total-citations"
}