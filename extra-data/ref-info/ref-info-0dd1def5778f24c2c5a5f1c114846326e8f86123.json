{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144739319"
                        ],
                        "name": "R. Lienhart",
                        "slug": "R.-Lienhart",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Lienhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lienhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083891040"
                        ],
                        "name": "F. Stuber",
                        "slug": "F.-Stuber",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Stuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Stuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14147742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "778a307aa0cf8b2ed273b9089cb9aa8210f49f24",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed algorithms for automatic character segmentation in motion pictures which extract automatically and reliably the text in pre-title sequences, credit titles, and closing sequences with title and credits. The algorithms we propose make use of typical characteristics of text in videos in order to enhance segmentation and, consequently, recognition performance. As a result, we get segmented characters from video pictures. These can be parsed by any OCR software. The recognition results of multiple instances of the same character throughout subsequent frames are combined to enhance recognition result and to compute the final output. We have tested our segmentation algorithms in a series of experiments with video clips recorded from television and achieved good segmentation results."
            },
            "slug": "Automatic-text-recognition-in-digital-videos-Lienhart-Stuber",
            "title": {
                "fragments": [],
                "text": "Automatic text recognition in digital videos"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "Algorithms for automatic character segmentation in motion pictures which extract automatically and reliably the text in pre-title sequences, credit titles, and closing sequences with title and credits are developed."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144973459"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784312"
                        ],
                        "name": "C. Low",
                        "slug": "C.-Low",
                        "structuredName": {
                            "firstName": "Chien",
                            "lastName": "Low",
                            "middleNames": [
                                "Yong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Low"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743808"
                        ],
                        "name": "S. Smoliar",
                        "slug": "S.-Smoliar",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smoliar",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Smoliar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588714"
                        ],
                        "name": "D. Zhong",
                        "slug": "D.-Zhong",
                        "structuredName": {
                            "firstName": "Di",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zhong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2469411,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16daa3e4fd7fb7c3b8fa843ca79ef27a34ebce1f",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an integrated solution for computer assisted video parsing and content-based video retrieval and browsing. The uniqueness and effectiveness of this solution lies in its use of video content information provided by a parsing process driven by visual feature analysis. More specifically, parsing will temporally segment and abstract a video source, based on low-level image analyses; then retrieval and browsing of video will be based on key-frames selected during abstraction and spatial-temporal variations of visual features, as well as some shot-level semantics derived from camera operation and motion analysis. These processes, as well as video retrieval and browsing tools, are presented in detail as functions of an integrated system. Also, experimental results on automatic key-frame detection are given."
            },
            "slug": "Video-parsing,-retrieval-and-browsing:-an-and-Zhang-Low",
            "title": {
                "fragments": [],
                "text": "Video parsing, retrieval and browsing: an integrated and content-based solution"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper presents an integrated solution for computer assisted video parsing and content-based video retrieval and browsing that uses video content information provided by a parsing process driven by visual feature analysis."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152736800"
                        ],
                        "name": "M. Smith",
                        "slug": "M.-Smith",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15525071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94c4141cdd7615e8e6fccbfa864abd518a62efd8",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital video is rapidly becoming an important source for information, entertainment and a host of multimedia applications. With the size of these collections growing to thousands of hours, technology is needed to effectively browse segments in a short time without losing the content of the video. We propose a method to extract the significant audio and video information and create a \u201cskim\u201d video which represents a short synopsis of the original. The extraction of significant information, such as specific objects, audio keywords and relevant video structure, is made possible through the integration of techniques in image and language understanding. The resulting skim is much smaller, and retains the essential content of the original segment. This research is sponsored by the National Science Foundation under grant no. IRI9411299, the National Space and Aeronautics Administration, and the Advanced Research Projects Agency. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing official policies or endorsements, either expressed or implied, of the United States Government."
            },
            "slug": "Video-Skimming-for-Quick-Browsing-based-on-Audio-Smith",
            "title": {
                "fragments": [],
                "text": "Video Skimming for Quick Browsing based on Audio and Image Characterization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The extraction of significant information, such as specific objects, audio keywords and relevant video structure, is made possible through the integration of techniques in image and language understanding and a \u201cskim\u201d video is proposed which represents a short synopsis of the original."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692339"
                        ],
                        "name": "B. Yeo",
                        "slug": "B.-Yeo",
                        "structuredName": {
                            "firstName": "Boon-Lock",
                            "lastName": "Yeo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yeo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108661679"
                        ],
                        "name": "Bede Liu",
                        "slug": "Bede-Liu",
                        "structuredName": {
                            "firstName": "Bede",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bede Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62189337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac83336e50496b9a75714f1024531fe7d698d33b",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Embedded captions in TV programs such as news broadcasts, documentaries and coverage of sports events provide important information on the underlying events. In digital video libraries, such captions represent a highly condensed form of key information on the contents of the video. In this paper we propose a scheme to automatically detect the presence of captions embedded in video frames. The proposed method operates on reduced image sequences which are efficiently reconstructed from compressed MPEG video and thus does not require full frame decompression. The detection, extraction and analysis of embedded captions help to capture the highlights of visual contents in video documents for better organization of video, to present succinctly the important messages embedded in the images, and to facilitate browsing, searching and retrieval of relevant clips."
            },
            "slug": "Visual-content-highlighting-via-automatic-of-on-Yeo-Liu",
            "title": {
                "fragments": [],
                "text": "Visual content highlighting via automatic extraction of embedded captions on MPEG compressed video"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A scheme to automatically detect the presence of captions embedded in video frames which operates on reduced image sequences which are efficiently reconstructed from compressed MPEG video and thus does not require full frame decompression."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713407"
                        ],
                        "name": "S. Pfeiffer",
                        "slug": "S.-Pfeiffer",
                        "structuredName": {
                            "firstName": "Silvia",
                            "lastName": "Pfeiffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pfeiffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144739319"
                        ],
                        "name": "R. Lienhart",
                        "slug": "R.-Lienhart",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Lienhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lienhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061646861"
                        ],
                        "name": "Stephan Fischer",
                        "slug": "Stephan-Fischer",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephan Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750165"
                        ],
                        "name": "W. Effelsberg",
                        "slug": "W.-Effelsberg",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Effelsberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Effelsberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43383351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01f7baa4bfc99e0b6805a7e10300e96ac1839cf3",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Large video on demand databases consisting of thousands of digital movies are not easy to handle: the user must have an attractive means to retrieve his movie of choice. For analog video, movie trailers are produced to allow a quick preview and perhaps stimulate possible buyers. This paper presents techniques to automatically produce such movie abstracts of digtial videos. We define a video abstract to be a sequence of still or moving images presenting the content of a video in such a way that the resprective target groupis rapidly provided with concise information about the content while the essential message of the original is preserved. We therefore mainly distinguish video abstracts consisting of a collection of salient still images and video abstracts consisting of a collection of scenes (sequences of images) which are therefore a video themselves. Still-images abstracting systems have been reported often in the literature. We propose a moving-images abstracting system, called VAbstract, and explain its concept, algorithmic realization and advantages. The paper also describes a series of abstracting experiments in which we compared our automatically produced abstracts to manually produced trailers of TV series."
            },
            "slug": "Abstracting-Digital-Movies-Automatically-Pfeiffer-Lienhart",
            "title": {
                "fragments": [],
                "text": "Abstracting Digital Movies Automatically"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A moving-images abstracting system, called VAbstract, is proposed, and its concept, algorithmic realization and advantages are explained, and a series of abstracting experiments are described in which the automatically produced abstracts are compared to manually produced trailers of TV series."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2471449"
                        ],
                        "name": "R. Hjelsvold",
                        "slug": "R.-Hjelsvold",
                        "structuredName": {
                            "firstName": "Rune",
                            "lastName": "Hjelsvold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hjelsvold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406379755"
                        ],
                        "name": "Stein Lang\u00f8rgen",
                        "slug": "Stein-Lang\u00f8rgen",
                        "structuredName": {
                            "firstName": "Stein",
                            "lastName": "Lang\u00f8rgen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stein Lang\u00f8rgen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2735340"
                        ],
                        "name": "Roger Midtstraum",
                        "slug": "Roger-Midtstraum",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Midtstraum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roger Midtstraum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3333353"
                        ],
                        "name": "O. Sandst\u00e5",
                        "slug": "O.-Sandst\u00e5",
                        "structuredName": {
                            "firstName": "Olav",
                            "lastName": "Sandst\u00e5",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Sandst\u00e5"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5266586,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5db12987c190e65b14ef10423f0720598780768d",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In traditional video archives, video data are stored on analogue video tapes while meta-data, such as textual descriptions of the contents of the video tapes, are stored and handled digitally by computers. In a fully digital video archive, both video data and meta-data are managed by computers and, thus, more powerful tools can be developed. In this paper, we discuss what kind of tools a digital video archive should ooer its users, and we describe an experimental video archive system which consists of tools for playing, browsing, searching and indexing video information. All tools in the system are based on a generic database platform called VideoSTAR (Video STorage And Retrieval) and they share video and meta-data via the common database. The tools are managed by a video archive tool manager which provides mechanisms for communication and cooperation between different tools. The system has been demonstrated to professional archivists and librarians who have given positive response, and as the next step we will have the system tested in a real video archive environment."
            },
            "slug": "Integrated-video-archive-tools-Hjelsvold-Lang\u00f8rgen",
            "title": {
                "fragments": [],
                "text": "Integrated video archive tools"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An experimental video archive system which consists of tools for playing, browsing, searching and indexing video information, which is based on a generic database platform called VideoSTAR (Video STorage And Retrieval) and they share video and meta-data via the common database."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708785"
                        ],
                        "name": "J. Ohya",
                        "slug": "J.-Ohya",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ohya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2019875"
                        ],
                        "name": "A. Shio",
                        "slug": "A.-Shio",
                        "structuredName": {
                            "firstName": "Akio",
                            "lastName": "Shio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49052113"
                        ],
                        "name": "S. Akamatsu",
                        "slug": "S.-Akamatsu",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Akamatsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Akamatsu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1565945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e94d1ff801fce49eea8d8aa51a477b130ca755de",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "An effective algorithm for character recognition in scene images is studied. Scene images are segmented into regions by an image segmentation method based on adaptive thresholding. Character candidate regions are detected by observing gray-level differences between adjacent regions. To ensure extraction of multisegment characters as well as single-segment characters, character pattern candidates are obtained by associating the detected regions according to their positions and gray levels. A character recognition process selects patterns with high similarities by calculating the similarities between character pattern candidates and the standard patterns in a dictionary and then comparing the similarities to the thresholds. A relaxational approach to determine character patterns updates the similarities by evaluating the interactions between categories of patterns, and finally character patterns and their recognition results are obtained. Highly promising experimental results have been obtained using the method on 100 images involving characters of different sizes and formats under uncontrolled lighting. >"
            },
            "slug": "Recognizing-Characters-in-Scene-Images-Ohya-Shio",
            "title": {
                "fragments": [],
                "text": "Recognizing Characters in Scene Images"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "An effective algorithm for character recognition in scene images is studied and highly promising experimental results have been obtained using the method on 100 images involving characters of different sizes and formats under uncontrolled lighting."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144973459"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743808"
                        ],
                        "name": "S. Smoliar",
                        "slug": "S.-Smoliar",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smoliar",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Smoliar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153635925"
                        ],
                        "name": "Shuang Yeo Tan",
                        "slug": "Shuang-Yeo-Tan",
                        "structuredName": {
                            "firstName": "Shuang",
                            "lastName": "Tan",
                            "middleNames": [
                                "Yeo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuang Yeo Tan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35961225,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05edc783def10174ca1d9952deb444f1e1c5baa1",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Video content parsing is possible when one has an a priori model of a video's structure based on domain knowledge. This paper presents work on using domain knowledge to parse content of news video programs. Approaches to locating and identifying frame structure models based on temporal and spatial structure of news video data, along with algorithms to apply these models in parsing news video, have been developed and are presented in detail in this paper. Experimental results are also discussed in detail to evaluate the approaches and algorithms. Finally, proposals for future work are summarized.<<ETX>>"
            },
            "slug": "Automatic-parsing-of-news-video-Zhang-Gong",
            "title": {
                "fragments": [],
                "text": "Automatic parsing of news video"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Approaches to locating and identifying frame structure models based on temporal and spatial structure of news video data, along with algorithms to apply these models in parsing news video, have been developed and are presented in detail in this paper."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE International Conference on Multimedia Computing and Systems"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068925080"
                        ],
                        "name": "L. T. Sin",
                        "slug": "L.-T.-Sin",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Sin",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. T. Sin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15895994"
                        ],
                        "name": "C. H. Chuan",
                        "slug": "C.-H.-Chuan",
                        "structuredName": {
                            "firstName": "Chua",
                            "lastName": "Chuan",
                            "middleNames": [
                                "Hock"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. H. Chuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144973459"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780232"
                        ],
                        "name": "M. Sakauchi",
                        "slug": "M.-Sakauchi",
                        "structuredName": {
                            "firstName": "Masao",
                            "lastName": "Sakauchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sakauchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206474326,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "564649846003db680733697947f974a1ef03c4ea",
            "isKey": false,
            "numCitedBy": 380,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "While automatic parsing of general video images are difficult or nearly impossible, parsing a specific type of video image can be achieved if the video structure can be explicitly identified and its model can be constructed. The paper presents ongoing work on using domain knowledge to parse content of soccer video programs. The proposed system can classify a sequence of soccer frames into various play categories, such as shot at left goal, top left corner kick play in right penalty area, in midfield, etc, based on a priori model comprising four major components: a soccer court, a ball, the players and the motion vectors. Approaches in applying the model for parsing soccer programs are presented in detail. Experimental results are included to evaluate the performance of the system."
            },
            "slug": "Automatic-parsing-of-TV-soccer-programs-Gong-Sin",
            "title": {
                "fragments": [],
                "text": "Automatic parsing of TV soccer programs"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The proposed system can classify a sequence of soccer frames into various play categories, such as shot at left goal, top left corner kick play in right penalty area, in midfield, etc, based on a priori model comprising four major components: a soccer court, a ball, the players and the motion vectors."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Conference on Multimedia Computing and Systems"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778053"
                        ],
                        "name": "Christopher Lindblad",
                        "slug": "Christopher-Lindblad",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Lindblad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Lindblad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144252510"
                        ],
                        "name": "D. Wetherall",
                        "slug": "D.-Wetherall",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wetherall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wetherall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2489859"
                        ],
                        "name": "William F. Stasior",
                        "slug": "William-F.-Stasior",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Stasior",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William F. Stasior"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1849542"
                        ],
                        "name": "J. Adam",
                        "slug": "J.-Adam",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Adam",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3073913"
                        ],
                        "name": "H. Houh",
                        "slug": "H.-Houh",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Houh",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Houh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3291233"
                        ],
                        "name": "Michael Ismert",
                        "slug": "Michael-Ismert",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ismert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Ismert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33700593"
                        ],
                        "name": "David R. Bacher",
                        "slug": "David-R.-Bacher",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bacher",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Bacher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055794918"
                        ],
                        "name": "B. M. Phillips",
                        "slug": "B.-M.-Phillips",
                        "structuredName": {
                            "firstName": "Brent",
                            "lastName": "Phillips",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. M. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755120"
                        ],
                        "name": "D. Tennenhouse",
                        "slug": "D.-Tennenhouse",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tennenhouse",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tennenhouse"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206444791,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3aab6d499ddc04283d5978f0f6a13267edbad0a0",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes applications built on the ViewStation, a distributed multimedia system based on Unix workstations and a gigabit per second local area network. A key tenet of the ViewStation project is the delivery of media data not just to the desktop but all the way to the application program. As processing power continues to improve, our approach enables applications that perform intensive processing of audio and video data. We hypothesize that as media data are shaped by this software-based processing, the resultant network traffic patterns will be dominated more by software behavior than by so-called real-time issues. We have written applications that directly process live video to provide more responsive human-computer interaction. We have also developed applications to explore the potential of media processing to support content-based retrieval of prerecorded television broadcasts. These applications perform intelligent processing on video, as well as straightforward presentation. They demonstrate the utility of network-based multimedia systems that deliver audio and video data all the way to the application. The network requirements of the applications are modeled as a combination of bursty transfers and periodic packet-trains. >"
            },
            "slug": "ViewStation-Applications:-Implications-for-Network-Lindblad-Wetherall",
            "title": {
                "fragments": [],
                "text": "ViewStation Applications: Implications for Network Traffic"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Applications built on the ViewStation, a distributed multimedia system based on Unix workstations and a gigabit per second local area network, perform intelligent processing on video, as well as straightforward presentation and demonstrate the utility of network-based multimedia systems that deliver audio and video data all the way to the application."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE J. Sel. Areas Commun."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068153936"
                        ],
                        "name": "S. L. Horowitz",
                        "slug": "S.-L.-Horowitz",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Horowitz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. L. Horowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 32760436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9c8cc989558e6f464ac184743c67ccccad9bb12",
            "isKey": false,
            "numCitedBy": 569,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In the past, picture segmentation has been performed by merging small primitive regions or by recursively splitting the whole picture. This paper combines the two approaches with significant increase in processing speed while maintaining small memory requirements. The data structure is described in detail and examples of implementations are given."
            },
            "slug": "Picture-Segmentation-by-a-Tree-Traversal-Algorithm-Horowitz-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Picture Segmentation by a Tree Traversal Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper combines the two approaches with significant increase in processing speed while maintaining small memory requirements and the data structure is described in detail."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144321599"
                        ],
                        "name": "M. McGill",
                        "slug": "M.-McGill",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "McGill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. McGill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43685115,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "49af3e80343eb80c61e727ae0c27541628c7c5e2",
            "isKey": false,
            "numCitedBy": 12606,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Some people may be laughing when looking at you reading in your spare time. Some may be admired of you. And some may want be like you who have reading hobby. What about your own feel? Have you felt right? Reading is a need and a hobby at once. This condition is the on that will make you feel that you must read. If you know are looking for the book enPDFd introduction to modern information retrieval as the choice of reading, you can find here."
            },
            "slug": "Introduction-to-Modern-Information-Retrieval-Salton-McGill",
            "title": {
                "fragments": [],
                "text": "Introduction to Modern Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Reading is a need and a hobby at once and this condition is the on that will make you feel that you must read."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2199747"
                        ],
                        "name": "N. Wirth",
                        "slug": "N.-Wirth",
                        "structuredName": {
                            "firstName": "Niklaus",
                            "lastName": "Wirth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wirth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 3215652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "381ab7f1e7da5fdddc07598339b3ab63c78a733d",
            "isKey": false,
            "numCitedBy": 720,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The book reflects the development of the use of computers and sophisticated algorithms to prepare and automatically typeset documents. It develops programs in step-wise fashion and express them in a well structured, detailed presentation. The book stresses the importance of performance analysis and demonstrates how algorithm selection and refinement are used most effectively in program design. Presents tested programs"
            },
            "slug": "Algorithms-and-Data-Structures-Wirth",
            "title": {
                "fragments": [],
                "text": "Algorithms and Data Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The book stresses the importance of performance analysis and demonstrates how algorithm selection and refinement are used most effectively in program design."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144562609"
                        ],
                        "name": "Marc Davis",
                        "slug": "Marc-Davis",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 44813239,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "3e8802e33f9efe150ac9a5f56ec2a4fc9738c041",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 177,
            "paperAbstract": {
                "fragments": [],
                "text": "Thesis (Ph. D.)--Massachusetts Institute of Technology, Program in Media Arts & Sciences, 1995."
            },
            "slug": "Media-streams:-representing-video-for-retrieval-and-Davis",
            "title": {
                "fragments": [],
                "text": "Media streams: representing video for retrieval and repurposing"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Thesis (Ph. D.)--Massachusetts Institute of Technology, Program in Media Arts & Sciences, 1995."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5246200,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "0efb841403aa6252b39ae6975c1cc5410554ef7b",
            "isKey": false,
            "numCitedBy": 10767,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points. This rule is independent of the underlying joint distribution on the sample points and their classifications, and hence the probability of error R of such a rule must be at least as great as the Bayes probability of error R^{\\ast} --the minimum probability of error over all decision rules taking underlying probability structure into account. However, in a large sample analysis, we will show in the M -category case that R^{\\ast} \\leq R \\leq R^{\\ast}(2 --MR^{\\ast}/(M-1)) , where these bounds are the tightest possible, for all suitably smooth underlying distributions. Thus for any number of categories, the probability of error of the nearest neighbor rule is bounded above by twice the Bayes probability of error. In this sense, it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor."
            },
            "slug": "Nearest-neighbor-pattern-classification-Cover-Hart",
            "title": {
                "fragments": [],
                "text": "Nearest neighbor pattern classification"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points, so it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153312185"
                        ],
                        "name": "S. Mori",
                        "slug": "S.-Mori",
                        "structuredName": {
                            "firstName": "Shunji",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143686714"
                        ],
                        "name": "Kazuhiko Yamamoto",
                        "slug": "Kazuhiko-Yamamoto",
                        "structuredName": {
                            "firstName": "Kazuhiko",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuhiko Yamamoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58021636,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0627cb9872115ea4c4d3484538a2f440923d8f13",
            "isKey": false,
            "numCitedBy": 940,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Research and development of OCR systems are considered from a historical point of view. The historical development of commercial systems is included. Both template matching and structure analysis approaches to R&D are considered. It is noted that the two approaches are coming closer and tending to merge. Commercial products are divided into three generations, for each of which some representative OCR systems are chosen and described in some detail. Some comments are made on recent techniques applied to OCR, such as expert systems and neural networks, and some open problems are indicated. The authors' views and hopes regarding future trends are presented. >"
            },
            "slug": "Historical-review-of-OCR-research-and-development-Mori-Suen",
            "title": {
                "fragments": [],
                "text": "Historical review of OCR research and development"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Both template matching and structure analysis approaches to R&D are considered and it is noted that the two approaches are coming closer and tending to merge."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2199747"
                        ],
                        "name": "N. Wirth",
                        "slug": "N.-Wirth",
                        "structuredName": {
                            "firstName": "Niklaus",
                            "lastName": "Wirth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wirth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57661252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4719c7a6acd699c824026c82e5de5f8fe386fa99",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithms-&-data-structures-Wirth",
            "title": {
                "fragments": [],
                "text": "Algorithms & data structures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IT-13"
            },
            "venue": {
                "fragments": [],
                "text": "IT-13"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Algorithms and Data Structures Jun Ohya, Akio Shio, and Shigeru Akamatsu. Recognizing Characters in Scene Images"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Methods of Automatic Character Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Methods of Automatic Character Recognition"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picture Segmentation by a Traversal Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graphics Image Process"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gray Scale Image Processing Technology Applied to Vehicle License Number Recogni- tion System"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int. Workshop Industrial Applications of Machine Vision and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boon-Lock Yeo and Bede Liu. Vkual Content High- lighting via Automatic Extraction of Embedded Captions on MPEG Compressed Video"
            },
            "venue": {
                "fragments": [],
                "text": "Digital Video Compression: Algorithms and Technologies"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Frequently Asked Questions about Colour. <ftp:llftp.inforamp. netlpubluserslpoyn- totidoclcolourl>"
            },
            "venue": {
                "fragments": [],
                "text": "Frequently Asked Questions about Colour. <ftp:llftp.inforamp. netlpubluserslpoyn- totidoclcolourl>"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 24,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Automatic-text-recognition-for-video-indexing-Lienhart/0dd1def5778f24c2c5a5f1c114846326e8f86123?sort=total-citations"
}