{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153317938"
                        ],
                        "name": "Sui Ching Lin",
                        "slug": "Sui-Ching-Lin",
                        "structuredName": {
                            "firstName": "Sui",
                            "lastName": "Lin",
                            "middleNames": [
                                "Ching"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sui Ching Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14720139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e81d91493c93ce00378d017d2aceea38f42d7fe",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "With the rapid technological advances in machine learning and data mining, it is now possible to train computers with hundreds of semantic concepts for the purpose of annotating images automatically using keywords and textual descriptions. We have developed a system, the automatic linguistic indexing of pictures (ALIP) system, using a 2-D multiresolution hidden Markov model. The evaluation of such approaches opens up challenges and interesting research questions. The goals of linguistic indexing are often different from those of other fields including image retrieval, image classification, and computer vision. In many application domains, computer programs that can provide semantically relevant keyword annotations are desired, even if the predicted annotations are different from those of the gold standard. In this paper, we discuss evaluation strategies for automatic linguistic indexing of pictures. We provide both objective and subjective evaluation methods. Finally, we report experimental results using our ALIP system."
            },
            "slug": "Evaluation-strategies-for-automatic-linguistic-of-Wang-Li",
            "title": {
                "fragments": [],
                "text": "Evaluation strategies for automatic linguistic indexing of pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper develops a system, the automatic linguistic indexing of pictures (ALIP) system, using a 2-D multiresolution hidden Markov model and provides both objective and subjective evaluation methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3715563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7ce4bb8d5a700ec96d5e87bb31a20b3627fd9b6",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic linguistic indexing of pictures is an important but highly challenging problem for researchers in computer vision and content-based image retrieval. In this paper, we introduce a statistical modeling approach to this problem. Categorized images are used to train a dictionary of hundreds of concepts automatically based on statistical modeling. Images of any given concept category are regarded as instances of a stochastic process that characterizes the category. To measure the extent of association between an image and the textual description of a category of images, the likelihood of the occurrence of the image based on the stochastic process derived from the category is computed. A high likelihood indicates a strong association. In our experimental implementation, the ALIP (Automatic Linguistic Indexing of Pictures) system, we focus on a particular group of stochastic processes for describing images, that is, the two-dimensional multiresolution hidden Markov models (2-D MHMMs). We implemented and tested the system on a photographic image database of 600 different semantic cat- egories, each with about 40 training images. Tested using 3,000 images outside the training database, the system has demonstrated good accuracy and high potential in linguistic indexing of these test images."
            },
            "slug": "Learning-based-linguistic-indexing-of-pictures-with-Wang-Li",
            "title": {
                "fragments": [],
                "text": "Learning-based linguistic indexing of pictures with 2--d MHMMs"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A statistical modeling approach to automatic linguistic indexing of pictures by focusing on a particular group of stochastic processes for describing images, that is, the two-dimensional multiresolution hidden Markov models (2-D MHMMs)."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3028284,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f39d3e88cce063ccd3ca01100efd44dcabc9d3b4",
            "isKey": false,
            "numCitedBy": 1187,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic linguistic indexing of pictures is an important but highly challenging problem for researchers in computer vision and content-based image retrieval. In this paper, we introduce a statistical modeling approach to this problem. Categorized images are used to train a dictionary of hundreds of statistical models each representing a concept. Images of any given concept are regarded as instances of a stochastic process that characterizes the concept. To measure the extent of association between an image and the textual description of a concept, the likelihood of the occurrence of the image based on the characterizing stochastic process is computed. A high likelihood indicates a strong association. In our experimental implementation, we focus on a particular group of stochastic processes, that is, the two-dimensional multiresolution hidden Markov models (2D MHMMs). We implemented and tested our ALIP (Automatic Linguistic Indexing of Pictures) system on a photographic image database of 600 different concepts, each with about 40 training images. The system is evaluated quantitatively using more than 4,600 images outside the training database and compared with a random annotation scheme. Experiments have demonstrated the good accuracy of the system and its high potential in linguistic indexing of photographic images."
            },
            "slug": "Automatic-Linguistic-Indexing-of-Pictures-by-a-Li-Wang",
            "title": {
                "fragments": [],
                "text": "Automatic Linguistic Indexing of Pictures by a Statistical Modeling Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper implemented and tested the ALIP (Automatic Linguistic Indexing of Pictures) system on a photographic image database of 600 different concepts, each with about 40 training images and demonstrated the good accuracy of the system and its high potential in linguistic indexing of photographic images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 868535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e",
            "isKey": false,
            "numCitedBy": 1760,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann's hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et al.), and a multi-modal extension to mixture of latent Dirichlet allocation (MoM-LDA). All models are assessed using a large collection of annotated images of real scenes. We study in depth the difficult problem of measuring performance. For the annotation task, we look at prediction performance on held out data. We present three alternative measures, oriented toward different types of task. Measuring the performance of correspondence methods is harder, because one must determine whether a word has been placed on the right region of an image. We can use annotation performance as a proxy measure, but accurate measurement requires hand labeled data, and thus must occur on a smaller scale. We show results using both an annotation proxy, and manually labeled data."
            },
            "slug": "Matching-Words-and-Pictures-Barnard-Sahin",
            "title": {
                "fragments": [],
                "text": "Matching Words and Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text, is presented, and a number of models for the joint distribution of image regions and words are developed, including several which explicitly learn the correspondence between regions and Words."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40490812"
                        ],
                        "name": "R. Datta",
                        "slug": "R.-Datta",
                        "structuredName": {
                            "firstName": "Ritendra",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Datta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Progresses made in the field after 2000 is documented in a recent survey article [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5964689,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24b0d89b1df469be8aa12fb797081be87251727a",
            "isKey": false,
            "numCitedBy": 531,
            "numCiting": 125,
            "paperAbstract": {
                "fragments": [],
                "text": "The last decade has witnessed great interest in research on content-based image retrieval. This has paved the way for a large number of new techniques and systems, and a growing interest in associated fields to support such systems. Likewise, digital imagery has expanded its horizon in many directions, resulting in an explosion in the volume of image data required to be organized. In this paper, we discuss some of the key contributions in the current decade related to image retrieval and automated image annotation, spanning 120 references. We also discuss some of the key challenges involved in the adaptation of existing image retrieval techniques to build useful systems that can handle real-world data. We conclude with a study on the trends in volume and impact of publications in the field with respect to venues/journals and sub-topics."
            },
            "slug": "Content-based-image-retrieval:-approaches-and-of-Datta-Li",
            "title": {
                "fragments": [],
                "text": "Content-based image retrieval: approaches and trends of the new age"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Some of the key contributions in the current decade related to image retrieval and automated image annotation are discussed, spanning 120 references, and a study on the trends in volume and impact of publications in the field with respect to venues/journals and sub-topics is concluded."
            },
            "venue": {
                "fragments": [],
                "text": "MIR '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1824057"
                        ],
                        "name": "Florent Monay",
                        "slug": "Florent-Monay",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Monay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florent Monay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403029865"
                        ],
                        "name": "D. G\u00e1tica-P\u00e9rez",
                        "slug": "D.-G\u00e1tica-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "G\u00e1tica-P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G\u00e1tica-P\u00e9rez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1007967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c253729d6170b31972ded6bfec1ea502f3ff86e",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Image auto-annotation, i.e., the association of words to whole images, has attracted considerable attention. In particular, unsupervised, probabilistic latent variable models of text and image features have shown encouraging results, but their performance with respect to other approaches remains unknown. In this paper, we apply and compare two simple latent space models commonly used in text analysis, namely Latent Semantic Analysis (LSA) and Probabilistic LSA (PLSA). Annotation strategies for each model are discussed. Remarkably, we found that, on a 8000-image dataset, a classic LSA model defined on keywords and a very basic image representation performed as well as much more complex, state-of-the-art methods. Furthermore, non-probabilistic methods (LSA and direct image matching) outperformed PLSA on the same dataset."
            },
            "slug": "On-image-auto-annotation-with-latent-space-models-Monay-G\u00e1tica-P\u00e9rez",
            "title": {
                "fragments": [],
                "text": "On image auto-annotation with latent space models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper applies and compares two simple latent space models commonly used in text analysis, namely Latent Semantic Analysis (LSA) and Probabilistic LSA (PLSA), and found that, on a 8000-image dataset, a classic LSA model defined on keywords and a very basic image representation performed as well as much more complex, state-of-the-art methods."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747647"
                        ],
                        "name": "S. Santini",
                        "slug": "S.-Santini",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Santini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Santini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722619"
                        ],
                        "name": "Amarnath Gupta",
                        "slug": "Amarnath-Gupta",
                        "structuredName": {
                            "firstName": "Amarnath",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amarnath Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2827898,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b7c4096ed697696a5f4fc8f3a6a750dc0cdecfe",
            "isKey": false,
            "numCitedBy": 6727,
            "numCiting": 410,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a review of 200 references in content-based image retrieval. The paper starts with discussing the working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap. Subsequent sections discuss computational steps for image retrieval systems. Step one of the review is image processing for retrieval sorted by color, texture, and local geometry. Features for retrieval are discussed next, sorted by: accumulative and global features, salient points, object and shape features, signs, and structural combinations thereof. Similarity of pictures and objects in pictures is reviewed for each of the feature types, in close connection to the types and means of feedback the user of the systems is capable of giving by interaction. We briefly discuss aspects of system engineering: databases, system architecture, and evaluation. In the concluding section, we present our view on: the driving force of the field, the heritage from computer vision, the influence on computer vision, the role of similarity and of interaction, the need for databases, the problem of evaluation, and the role of the semantic gap."
            },
            "slug": "Content-Based-Image-Retrieval-at-the-End-of-the-Smeulders-Worring",
            "title": {
                "fragments": [],
                "text": "Content-Based Image Retrieval at the End of the Early Years"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap are discussed, as well as aspects of system engineering: databases, system architecture, and evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726249"
                        ],
                        "name": "T. Quack",
                        "slug": "T.-Quack",
                        "structuredName": {
                            "firstName": "Till",
                            "lastName": "Quack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Quack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "23144093"
                        ],
                        "name": "Ullrich J. M\u00f6nich",
                        "slug": "Ullrich-J.-M\u00f6nich",
                        "structuredName": {
                            "firstName": "Ullrich",
                            "lastName": "M\u00f6nich",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ullrich J. M\u00f6nich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065641340"
                        ],
                        "name": "L. Thiele",
                        "slug": "L.-Thiele",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Thiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Thiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "Examples of histograms of image distances based on different features and over large data sets are provided in [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13338212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f5104f5ad7e29d0782cda10e274fc87b89333bc",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in processing and networking capabilities of computers have led to an accumulation of immense amounts of multimedia data such as images. One of the largest repositories for such data is the World Wide Web (WWW). We present Cortina, a large-scale image retrieval system for the WWW. It handles over 3 million images to date. The system retrieves images based on visual features and collateral text. We show that a search process which consists of an initial query-by-keyword or query-by-image and followed by relevance feedback on the visual appearance of the results is possible for large-scale data sets. We also show that it is superior to the pure text retrieval commonly used in large-scale systems. Semantic relationships in the data are explored and exploited by data mining, and multiple feature spaces are included in the search process."
            },
            "slug": "Cortina:-a-system-for-large-scale,-content-based-Quack-M\u00f6nich",
            "title": {
                "fragments": [],
                "text": "Cortina: a system for large-scale, content-based web image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Cortina is presented, a large-scale image retrieval system for the WWW that retrieves images based on visual features and collateral text and is superior to the pure text retrieval commonly used in large- scale systems."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145575177"
                        ],
                        "name": "G. Carneiro",
                        "slug": "G.-Carneiro",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Carneiro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Carneiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3651407"
                        ],
                        "name": "Antoni B. Chan",
                        "slug": "Antoni-B.-Chan",
                        "structuredName": {
                            "firstName": "Antoni",
                            "lastName": "Chan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoni B. Chan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47690405"
                        ],
                        "name": "P. Moreno",
                        "slug": "P.-Moreno",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Moreno",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Moreno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2717049,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e638e2c7f7bbc788eb4adb5b5c67bde5ffc11bc5",
            "isKey": false,
            "numCitedBy": 955,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "A probabilistic formulation for semantic image annotation and retrieval is proposed. Annotation and retrieval are posed as classification problems where each class is defined as the group of database images labeled with a common semantic label. It is shown that, by establishing this one-to-one correspondence between semantic labels and semantic classes, a minimum probability of error annotation and retrieval are feasible with algorithms that are 1) conceptually simple, 2) computationally efficient, and 3) do not require prior semantic segmentation of training images. In particular, images are represented as bags of localized feature vectors, a mixture density estimated for each image, and the mixtures associated with all images annotated with a common semantic label pooled into a density estimate for the corresponding semantic class. This pooling is justified by a multiple instance learning argument and performed efficiently with a hierarchical extension of expectation-maximization. The benefits of the supervised formulation over the more complex, and currently popular, joint modeling of semantic label and visual feature distributions are illustrated through theoretical arguments and extensive experiments. The supervised formulation is shown to achieve higher accuracy than various previously published methods at a fraction of their computational cost. Finally, the proposed method is shown to be fairly robust to parameter tuning"
            },
            "slug": "Supervised-Learning-of-Semantic-Classes-for-Image-Carneiro-Chan",
            "title": {
                "fragments": [],
                "text": "Supervised Learning of Semantic Classes for Image Annotation and Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The supervised formulation is shown to achieve higher accuracy than various previously published methods at a fraction of their computational cost and to be fairly robust to parameter tuning."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116664201"
                        ],
                        "name": "Yixin Chen",
                        "slug": "Yixin-Chen",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1265628,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a8665ada37b8a26f2a68c0b9c3f3ceb1e0f655a",
            "isKey": false,
            "numCitedBy": 685,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Designing computer programs to automatically categorize images using low-level features is a challenging research topic in computer vision. In this paper, we present a new learning technique, which extends Multiple-Instance Learning (MIL), and its application to the problem of region-based image categorization. Images are viewed as bags, each of which contains a number of instances corresponding to regions obtained from image segmentation. The standard MIL problem assumes that a bag is labeled positive if at least one of its instances is positive; otherwise, the bag is negative. In the proposed MIL framework, DD-SVM, a bag label is determined by some number of instances satisfying various properties. DD-SVM first learns a collection of instance prototypes according to a Diverse Density (DD) function. Each instance prototype represents a class of instances that is more likely to appear in bags with the specific label than in the other bags. A nonlinear mapping is then defined using the instance prototypes and maps every bag to a point in a new feature space, named the bag feature space. Finally, standard support vector machines are trained in the bag feature space. We provide experimental results on an image categorization problem and a drug activity prediction problem."
            },
            "slug": "Image-Categorization-by-Learning-and-Reasoning-with-Chen-Wang",
            "title": {
                "fragments": [],
                "text": "Image Categorization by Learning and Reasoning with Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a new learning technique, which extends Multiple-Instance Learning (MIL), and its application to the problem of region-based image categorization, and provides experimental results on an image categorizing problem and a drug activity prediction problem."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111935840"
                        ],
                        "name": "Yanping Du",
                        "slug": "Yanping-Du",
                        "structuredName": {
                            "firstName": "Yanping",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanping Du"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13790019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e57ae1b5d2598ad1091d4be8c99d419869b7929a",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical clustering is critical in designing scalable image retriev al systems. In this paper, we present a scalable algorithm for indexing and retrieving images based on region segmentation. The method uses statistical clustering on region features and IRM (Integrated Region Matching), a measure developed to evaluate overall similarity between images that incorporates properties of all the regions in the images by a region-matching scheme. Compared with retrieval based on individual regions, our overall similarity approach (a) reduces the influence of inaccurate segmentation, (b) helps to clarify the semantics of a particular region, and (c) enables a simple querying interface for region-based image retrieval systems. The algorithm has been implemented as a part of our experimental SIMPLIcity image retrieval system and tested on large-scale image databases of both general-purpose images and pathology slides. Experiments have demonstrated that this technique maintains the accuracy and robustness of the original system while reducing the matching time significantly."
            },
            "slug": "Scalable-integrated-region-based-image-retrieval-Wang-Du",
            "title": {
                "fragments": [],
                "text": "Scalable integrated region-based image retrieval using IRM and statistical clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An overall similarity approach that reduces the influence of inaccurate segmentation, helps to clarify the semantics of a particular region, and enables a simple querying interface for region-based image retrieval systems is presented."
            },
            "venue": {
                "fragments": [],
                "text": "JCDL '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116439170"
                        ],
                        "name": "J. Z. Wang",
                        "slug": "J.-Z.-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Zijun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Z. Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7395481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c799dead9425b715ffe5e08db1091b823c07e7e",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Searching digital biomedical images is a challenges problem. Prevalent retrieval techniques involve human-supplied text annotations to describe image contents. Biomedical images, such as pathology slides, usually have higher resolution than general-purpose pictures, making it additionally difficut to index. Precise object segmentation is also extremely difficult and is still an open problem. We are developing a multiresolution region-based retreival system for high-resolution biomedical image databases. The system, based on wavelets, the IRM (Integrated Region Matching) distance, and image classification, is highly robust to inacurate image segmentation and various visual alterations. Tested on a database of more than 70,000 pathology image fragments, the system has demonstrated high accuracy and fast speed."
            },
            "slug": "Region-based-retrieval-of-biomedical-images-Wang",
            "title": {
                "fragments": [],
                "text": "Region-based retrieval of biomedical images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A multiresolution region-based retreival system for high-resolution biomedical image databases, based on wavelets, the IRM (Integrated Region Matching) distance, and image classification, which is highly robust to inacurate image segmentation and various visual alterations."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110288622"
                        ],
                        "name": "Ching Chen",
                        "slug": "Ching-Chen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ching Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2909970,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76db622fc5a2683f42c44e09f798eb506911de84",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, with the advent of fast-speed, broadband telecommunications networks, and information technology research for digital libraries, more and more distributed digital libraries with multimedia information have been developed everywhere in the world. While technologies are available, there is insufficient large-scale and coordinated digital content development. Furthermore, state-ofthe-art technologies developed in the research labs are rarely used to assist the content development and content analysis. This paper first discusses how the NSF/IDLP Project, Chinese Memory Net has capitalized on the rich multimedia resources in both analog and digital formats of an earlier cultural documentaries products, the awardwinning The First Emperor of China videodisc and multimedia CD, to further build large-scale digital contents of significant museum and historical/cultural/heritage materials for productive international collaboration among experts from interdisciplinary fields. The content has been used as a testbed for technology research in the area of semantics-sensitive region-based image retrieval. We demonstrate the use of the SIMPLIcity technology in browsing and retrieving of images."
            },
            "slug": "LARGE-SCALE-EMPEROR-DIGITAL-LIBRARY-AND-RETRIEVAL-Chen-Wang",
            "title": {
                "fragments": [],
                "text": "LARGE-SCALE EMPEROR DIGITAL LIBRARY AND SEMANTICS-SENSITIVE REGION-BASED RETRIEVAL"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper discusses how the NSF/IDLP Project, Chinese Memory Net has capitalized on the rich multimedia resources in both analog and digital formats of an earlier cultural documentaries products, the awardwinning The First Emperor of China videodisc and multimedia CD, to further build large-scale digital contents of significant museum and historical/cultural/heritage materials for productive international collaboration among experts from interdisciplinary fields."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116664201"
                        ],
                        "name": "Yixin Chen",
                        "slug": "Yixin-Chen",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1872595"
                        ],
                        "name": "Robert Krovetz",
                        "slug": "Robert-Krovetz",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Krovetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Krovetz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4227250,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21b777cd55bb76be5205ae582482d2a446085397",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In a typical content-based image retrieval (CBIR) system, query results are a set of images sorted by feature similarities with respect to the query. However, images with high feature similarities to the query may be very different from the query in terms of semantics. This is known as the semantic gap. We introduce a novel image retrieval scheme, CLUster-based rEtrieval of images by unsupervised learning (CLUE), which tackles the semantic gap problem based on a hypothesis: semantically similar images tend to be clustered in some feature space. CLUE attempts to capture semantic concepts by learning the way that images of the same semantics are similar and retrieving image clusters instead of a set of ordered images. Clustering in CLUE is dynamic. In particular, clusters formed depend on which images are retrieved in response to the query. Therefore, the clusters give the algorithm as well as the users semantic relevant clues as to where to navigate. CLUE is a general approach that can be combined with any real-valued symmetric similarity measure (metric or nonmetric). Thus it may be embedded in many current CBIR systems. Experimental results based on a database of about 60, 000 images from COREL demonstrate improved performance."
            },
            "slug": "Content-based-image-retrieval-by-clustering-Chen-Wang",
            "title": {
                "fragments": [],
                "text": "Content-based image retrieval by clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A novel image retrieval scheme, CLUster-based rEtrieval of images by unsupervised learning (CLUE), which tackles the semantic gap problem based on a hypothesis: semantically similar images tend to be clustered in some feature space."
            },
            "venue": {
                "fragments": [],
                "text": "MIR '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40490812"
                        ],
                        "name": "R. Datta",
                        "slug": "R.-Datta",
                        "structuredName": {
                            "firstName": "Ritendra",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Datta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5113463"
                        ],
                        "name": "D. Joshi",
                        "slug": "D.-Joshi",
                        "structuredName": {
                            "firstName": "Dhiraj",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Joshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7060187,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0dfa5679a15d0125ecec8539b79e8ba0babb8f73",
            "isKey": false,
            "numCitedBy": 3618,
            "numCiting": 325,
            "paperAbstract": {
                "fragments": [],
                "text": "We have witnessed great interest and a wealth of promise in content-based image retrieval as an emerging technology. While the last decade laid foundation to such promise, it also paved the way for a large number of new techniques and systems, got many new people involved, and triggered stronger association of weakly related fields. In this article, we survey almost 300 key theoretical and empirical contributions in the current decade related to image retrieval and automatic image annotation, and in the process discuss the spawning of related subfields. We also discuss significant challenges involved in the adaptation of existing image retrieval techniques to build systems that can be useful in the real world. In retrospect of what has been achieved so far, we also conjecture what the future may hold for image retrieval research."
            },
            "slug": "Image-retrieval:-Ideas,-influences,-and-trends-of-Datta-Joshi",
            "title": {
                "fragments": [],
                "text": "Image retrieval: Ideas, influences, and trends of the new age"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Almost 300 key theoretical and empirical contributions in the current decade related to image retrieval and automatic image annotation are surveyed, and the spawning of related subfields are discussed, to discuss the adaptation of existing image retrieval techniques to build systems that can be useful in the real world."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37395525"
                        ],
                        "name": "Jingrui He",
                        "slug": "Jingrui-He",
                        "structuredName": {
                            "firstName": "Jingrui",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingrui He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8163721"
                        ],
                        "name": "Hanghang Tong",
                        "slug": "Hanghang-Tong",
                        "structuredName": {
                            "firstName": "Hanghang",
                            "lastName": "Tong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanghang Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8392859"
                        ],
                        "name": "Mingjing Li",
                        "slug": "Mingjing-Li",
                        "structuredName": {
                            "firstName": "Mingjing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingjing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14966740"
                        ],
                        "name": "Changshui Zhang",
                        "slug": "Changshui-Zhang",
                        "structuredName": {
                            "firstName": "Changshui",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changshui Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 757348,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a355e9cfd2d60ce2364f579340fe65077ce8629",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In content-based image retrieval, relevance feedback has been introduced to narrow the gap between low-level image feature and high-level semantic concept. Furthermore, to speed up the convergence to the query concept, several active learning methods have been proposed instead of random sampling to select images for labeling by the user. In this paper, we propose a novel active learning method named mean version space, aiming to select the optimal image in each round of relevance feedback. Firstly, by diving into the lemma that motivates support vector machine active learning method (SVM<i><inf>active</inf></i>), we come up with a new criterion which is tailored for each specific learning task and will lead to the fastest shrinkage of the version space in all cases. The criterion takes both the size of the version space and the posterior probabilities into consideration, while existing methods are only based on one of them. Moreover, although our criterion is designed for SVM, it can be justified in a general framework. Secondly, to reduce processing time, we design two schemes to construct a small candidate set and evaluate the criterion for images in the set instead of all the unlabeled images. Systematic experimental results demonstrate the superiority of our method over existing active learning methods"
            },
            "slug": "Mean-version-space:-a-new-active-learning-method-He-Tong",
            "title": {
                "fragments": [],
                "text": "Mean version space: a new active learning method for content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a novel active learning method named mean version space, aiming to select the optimal image in each round of relevance feedback, and proposes a new criterion which will lead to the fastest shrinkage of the version space in all cases."
            },
            "venue": {
                "fragments": [],
                "text": "MIR '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683556"
                        ],
                        "name": "G. Wiederhold",
                        "slug": "G.-Wiederhold",
                        "structuredName": {
                            "firstName": "Gio",
                            "lastName": "Wiederhold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wiederhold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9590512,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a41681900f295a3098592c1040b35b6e3767c96",
            "isKey": false,
            "numCitedBy": 1739,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "We present here SIMPLIcity (semantics-sensitive integrated matching for picture libraries), an image retrieval system, which uses semantics classification methods, a wavelet-based approach for feature extraction, and integrated region matching based upon image segmentation. An image is represented by a set of regions, roughly corresponding to objects, which are characterized by color, texture, shape, and location. The system classifies images into semantic categories. Potentially, the categorization enhances retrieval by permitting semantically-adaptive searching methods and narrowing down the searching range in a database. A measure for the overall similarity between images is developed using a region-matching scheme that integrates properties of all the regions in the images. The application of SIMPLIcity to several databases has demonstrated that our system performs significantly better and faster than existing ones. The system is fairly robust to image alterations."
            },
            "slug": "SIMPLIcity:-Semantics-Sensitive-Integrated-Matching-Wang-Li",
            "title": {
                "fragments": [],
                "text": "SIMPLIcity: Semantics-sensitive Integrated Matching for Picture Libraries"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "SIMPLIcity (semantics-sensitive integrated matching for picture libraries), an image retrieval system, which uses semantics classification methods, a wavelet-based approach for feature extraction, and integrated region matching based upon image segmentation to improve retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "VISUAL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109082247"
                        ],
                        "name": "William Chen",
                        "slug": "William-Chen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145372008"
                        ],
                        "name": "H. Sundaram",
                        "slug": "H.-Sundaram",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Sundaram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sundaram"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Generative modeling [2], [16], statistical boosting [28], visual templates [6], Support Vector Machines [30], multiple instance learning, active learning [34], [13], latent space models [20], spatial context models [25], feedback learning [24] and manifold learning [31], [14] have been applied to image classification, annotation, and retrieval."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1244131,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bffbeb793d1ee5be07e1fd9dd5c260ce03313044",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The rapid growth of visual data over the last few years has lead to many schemes for retrieving such data. With content-based systems today, there exists a significant gap between the user's information needs and what the systems can deliver. We propose to bridge this gap, by introducing the novel idea of semantic visual templates (SVT). Each template represents a personalized view of concepts (e.g. slalom, meetings, sunsets, etc.). The SVT is represented using a set of successful queries, which are generated by a two-way interaction between the user and the system. We have developed algorithms that interact with the user and converge upon a small set of exemplar queries that maximize recall. The SVTs emphasize intuitive models that allow for easy manipulation and queries to be composited. The resulting system performs well, for example with small number of queries in the \"sunset\" template, we are able to achieve 50% recall and 24% precision over a large unannotated database."
            },
            "slug": "Semantic-visual-templates:-linking-visual-features-Chang-Chen",
            "title": {
                "fragments": [],
                "text": "Semantic visual templates: linking visual features to semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Algorithms that interact with the user and converge upon a small set of exemplar queries that maximize recall are developed, which are able to achieve 50% recall and 24% precision over a large unannotated database."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1998 International Conference on Image Processing. ICIP98 (Cat. No.98CB36269)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116664201"
                        ],
                        "name": "Yixin Chen",
                        "slug": "Yixin-Chen",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1872595"
                        ],
                        "name": "Robert Krovetz",
                        "slug": "Robert-Krovetz",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Krovetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Krovetz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9928903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8eb8c57be21c84e4f0dbbb697ebebef1e3c631a8",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "\"Semantic gap\" is an open challenging problem in content-based image retrieval. It rejects the discrepancy between low-level imagery features used by the retrieval algorithm and high-level concepts required by system users. This paper introduces a novel image retrieval scheme, CLUster-based rEtrieval of images by unsupervised learning (CLUE), to tackle the semantic gap problem. CLUE is built on a hypothesis that images of the same semantics tend to be clustered. It attempts to narrow the semantic gap by retrieving image clusters based on not only the feature similarity of images to the query, but also how images are similar to each other. CLUE has been tested using examples from a database of about 60,000 general-purpose images. Empirical results demonstrate the effectiveness of CLUE."
            },
            "slug": "An-unsupervised-learning-approach-to-content-based-Chen-Wang",
            "title": {
                "fragments": [],
                "text": "An unsupervised learning approach to content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel image retrieval scheme, CLUster-based rEtrieval of images by unsupervised learning (CLUE), to tackle the semantic gap problem and empirical results demonstrate the effectiveness of CLUE."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Symposium on Signal Processing and Its Applications, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808594"
                        ],
                        "name": "A. Lippman",
                        "slug": "A.-Lippman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lippman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lippman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15164796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24cae1c5a0f7af56f2acae0f7648d9e88656b91c",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Accounting for spatial image transformations is a requirement for multimedia problems such as video classification and retrieval, face/object recognition or the creation of image mosaics from video sequences. We analyze a transformation invariant metric recently proposed in the machine learning literature to measure the distance between image manifolds - the tangent distance (TD) - and show that it is closely related to alignment techniques from the motion analysis literature. Exposing these relationships results in benefits for the two domains. On one hand, it allows leveraging on the knowledge acquired in the alignment literature to build better classifiers. On the other, it provides a new interpretation of alignment techniques as one component of a decomposition that has interesting properties for the classification of video. In particular, we embed the TD into a multiresolution framework that makes it significantly less prone to local minima. The new metric - multiresolution tangent distance (MRTD) - can be easily combined with robust estimation procedures, and exhibits significantly higher invariance to image transformations than the TD and the Euclidean distance (ED). For classification, this translates into significant improvements in face recognition accuracy. For video characterization, it leads to a decomposition of image dissimilarity into \"differences due to camera motion\" plus \"differences due to scene activity\" that is useful for classification. Experimental results on a movie database indicate that the distance could be used as a basis for the extraction of semantic primitives such as action and romance."
            },
            "slug": "A-multiresolution-manifold-distance-for-invariant-Vasconcelos-Lippman",
            "title": {
                "fragments": [],
                "text": "A multiresolution manifold distance for invariant image similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A transformation invariant metric recently proposed in the machine learning literature to measure the distance between image manifolds - the tangent distance (TD) - is analyzed and shows that it is closely related to alignment techniques from the motion analysis literature."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Multimedia"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401302503"
                        ],
                        "name": "Michael Ortega-Binderberger",
                        "slug": "Michael-Ortega-Binderberger",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ortega-Binderberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Ortega-Binderberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144156242"
                        ],
                        "name": "S. Mehrotra",
                        "slug": "S.-Mehrotra",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Mehrotra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mehrotra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Generative modeling [2], [16], statistical boosting [28], visual templates [6], Support Vector Machines [30], multiple instance learning, active learning [34], [13], latent space models [20], spatial context models [25], feedback learning [ 24 ] and manifold learning [31], [14] have been applied to image classification, annotation, and retrieval."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3888393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "460c7b1c0d13a403b3a25a31a86692bb0443002b",
            "isKey": false,
            "numCitedBy": 2027,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Content-based image retrieval (CBIR) has become one of the most active research areas in the past few years. Many visual feature representations have been explored and many systems built. While these research efforts establish the basis of CBIR, the usefulness of the proposed approaches is limited. Specifically, these efforts have relatively ignored two distinct characteristics of CBIR systems: (1) the gap between high-level concepts and low-level features, and (2) the subjectivity of human perception of visual content. This paper proposes a relevance feedback based interactive retrieval approach, which effectively takes into account the above two characteristics in CBIR. During the retrieval process, the user's high-level query and perception subjectivity are captured by dynamically updated weights based on the user's feedback. The experimental results over more than 70000 images show that the proposed approach greatly reduces the user's effort of composing a query, and captures the user's information need more precisely."
            },
            "slug": "Relevance-feedback:-a-power-tool-for-interactive-Rui-Huang",
            "title": {
                "fragments": [],
                "text": "Relevance feedback: a power tool for interactive content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A relevance feedback based interactive retrieval approach that effectively takes into account the subjectivity of human perception of visual content and the gap between high-level concepts and low-level features in CBIR."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Circuits Syst. Video Technol."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683556"
                        ],
                        "name": "G. Wiederhold",
                        "slug": "G.-Wiederhold",
                        "structuredName": {
                            "firstName": "Gio",
                            "lastName": "Wiederhold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wiederhold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6477258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37217f11b576b2b43f245295553f1aca413d59ae",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Content-based image retrieval using region segmentation has been an active research area. We present IRM (Integrated Region Matching), a novel similarity measure for region-based image similarity comparison. The targeted image retrieval systems represent an image by a set of regions, roughly corresponding to objects, which are characterized by features reflecting color, texture, shape, and location properties. The IRM measure for evaluating overall similarity between images incorporates properties of all the regions in the images by a region-matching scheme. Compared with retrieval based on individual regions, the overall similarity approach reduces the influence of inaccurate segmentation, helps to clarify the semantics of a particular region, and enables a simple querying interface for region-based image retrieval systems. The IRM has been implemented as a part of our experimental SIMPLIcity image retrieval system. The application to a database of about 200,000 general-purpose images shows exceptional robustness to image alterations such as intensity variation, sharpness variation, color distortions, shape distortions, cropping, shifting, and rotation. Compared with several existing systems, our system in general achieves more accurate retrieval at higher speed."
            },
            "slug": "IRM:-integrated-region-matching-for-image-retrieval-Li-Wang",
            "title": {
                "fragments": [],
                "text": "IRM: integrated region matching for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The IRM measure for evaluating overall similarity between images incorporates properties of all the regions in the images by a region-matching scheme, which achieves more accurate retrieval at higher speed than several existing systems."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109292017"
                        ],
                        "name": "Cha Zhang",
                        "slug": "Cha-Zhang",
                        "structuredName": {
                            "firstName": "Cha",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cha Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40894914"
                        ],
                        "name": "Tsuhan Chen",
                        "slug": "Tsuhan-Chen",
                        "structuredName": {
                            "firstName": "Tsuhan",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsuhan Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1297870,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f51815ba488c5e8417a94e34a3488bec92a93a6",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a general active learning framework for content-based information retrieval. We use this framework to guide hidden annotations in order to improve the retrieval performance. For each object in the database, we maintain a list of probabilities, each indicating the probability of this object having one of the attributes. During training, the learning algorithm samples objects in the database and presents them to the annotator to assign attributes. For each sampled object, each probability is set to be one or zero depending on whether or not the corresponding attribute is assigned by the annotator. For objects that have not been annotated, the learning algorithm estimates their probabilities with biased kernel regression. Knowledge gain is then defined to determine, among the objects that have not been annotated, which one the system is the most uncertain. The system then presents it as the next sample to the annotator to which it is assigned attributes. During retrieval, the list of probabilities works as a feature vector for us to calculate the semantic distance between two objects, or between the user query and an object in the database. The overall distance between two objects is determined by a weighted sum of the semantic distance and the low-level feature distance. The algorithm is tested on both synthetic databases and real databases of 3D models. In both cases, the retrieval performance of the system improves rapidly with the number of annotated samples. Furthermore, we show that active learning outperforms learning based on random sampling."
            },
            "slug": "An-active-learning-framework-for-content-based-Zhang-Chen",
            "title": {
                "fragments": [],
                "text": "An active learning framework for content-based information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work proposes a general active learning framework for content-based information retrieval and uses this framework to guide hidden annotations in order to improve the retrieval performance."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Multim."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118965263"
                        ],
                        "name": "John R. Smith",
                        "slug": "John-R.-Smith",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "Smith and Chang developed of a Web image retrieval system [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17464838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa8af1c28f8ab2011339627bf8e13e267c57abdb",
            "isKey": false,
            "numCitedBy": 2203,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a highly functional prototype system for searching by visual features in an image database. The VisualSEEk system is novel in that the user forms the queries by diagramming spatial arrangements of color regions. The system nds the images that contain the most similar arrangements of similar regions. Prior to the queries, the system automatically extracts and indexes salient color regions from the images. By utilizing e cient indexing techniques for color information, region sizes and absolute and relative spatial locations, a wide variety of complex joint color/spatial queries may be computed."
            },
            "slug": "VisualSEEk:-a-fully-automated-content-based-image-Smith-Chang",
            "title": {
                "fragments": [],
                "text": "VisualSEEk: a fully automated content-based image query system"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The VisualSEEk system is novel in that the user forms the queries by diagramming spatial arrangements of color regions by utilizing color information, region sizes and absolute and relative spatial locations."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '96"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111935840"
                        ],
                        "name": "Yanping Du",
                        "slug": "Yanping-Du",
                        "structuredName": {
                            "firstName": "Yanping",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanping Du"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10201400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31b636413e331ba07aa2a692396a0fefad55e002",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The region-based approach has become a popular research trend in the field of multimedia database retrieval. We present the Region Frequency and Inverse Picture Frequency (RF/sup */IPF) weighting, a measure developed to unify region-based multimedia retrieval systems with text-based information retrieval systems. The weighting measure gives the highest weight to regions that occur often in a small number of images in the database. These regions are considered discriminators. With this weighting measure, we can blend image retrieval techniques with TF/sup */IDF-based text retrieval techniques for large-scale Web applications. The RF/sup */IPF weighting has been implemented as a part of our experimental SIMPLIcity image retrieval system and tested on a database of about 200000 general-purpose images. Experiments have shown that this technique is effective in discriminating images of different semantics. Additionally, the overall similarity approach enables a simple querying interface for multimedia information retrieval systems."
            },
            "slug": "RF/sup-*/IPF:-a-weighting-scheme-for-multimedia-Wang-Du",
            "title": {
                "fragments": [],
                "text": "RF/sup */IPF: a weighting scheme for multimedia information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The Region Frequency and Inverse Picture Frequency (RF/sup */IPF) weighting, a measure developed to unify region-based multimedia retrieval systems with text-based information retrieval systems, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 11th International Conference on Image Analysis and Processing"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829696"
                        ],
                        "name": "Y. Rubner",
                        "slug": "Y.-Rubner",
                        "structuredName": {
                            "firstName": "Yossi",
                            "lastName": "Rubner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rubner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A well-known image distance used in retrieval, namely the Earth Mover\u2019s Distance (EMD) [ 23 ] is closely related to the Mallows distance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18648233,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b7934a6f3a23940b7562df4cf58366b1adce55a3",
            "isKey": false,
            "numCitedBy": 1779,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new distance between two distributions that we call the Earth Mover's Distance (EMD), which reflects the minimal amount of work that must be performed to transform one distribution into the other by moving \"distribution mass\" around. This is a special case of the transportation problem from linear optimization, for which efficient algorithms are available. The EMD also allows for partial matching. When used to compare distributions that have the same overall mass, the EMD is a true metric, and has easy-to-compute lower bounds. In this paper we focus on applications to image databases, especially color and texture. We use the EMD to exhibit the structure of color-distribution and texture spaces by means of Multi-Dimensional Scaling displays. We also propose a novel approach to the problem of navigating through a collection of color images, which leads to a new paradigm for image database search."
            },
            "slug": "A-metric-for-distributions-with-applications-to-Rubner-Tomasi",
            "title": {
                "fragments": [],
                "text": "A metric for distributions with applications to image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper uses the Earth Mover's Distance to exhibit the structure of color-distribution and texture spaces by means of Multi-Dimensional Scaling displays, and proposes a novel approach to the problem of navigating through a collection of color images, which leads to a new paradigm for image database search."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116439170"
                        ],
                        "name": "J. Z. Wang",
                        "slug": "J.-Z.-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Zijun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Z. Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1827338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa9f5cf00fe0d3fd0cb38ae0d7759a22ffeea5d3",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The fast growth of digitized pathology slides has created great challenges in research on image database retrieval. The prevalent retrieval technique involves human-supplied text annotations to describe slide contents. These pathology images typically have very high resolution, making it difficult to search based on image content. In this paper, we present Pathfinder, an efficient multiresolution region-based searching system for high-resolution pathology image libraries. The system uses wavelets and the IRM (Integrated Region Matching) distance. Experiments with a database of 70,000 pathology image fragments have demonstrated high retrieval accuracy and high speed. The algorithm can be combined with our previously developed wavelet-based progressive pathology image transmission and browsing algorithm and is expandable for medical image databases."
            },
            "slug": "Pathfinder:-multiresolution-region-based-searching-Wang",
            "title": {
                "fragments": [],
                "text": "Pathfinder: multiresolution region-based searching of pathology images using IRM"
            },
            "venue": {
                "fragments": [],
                "text": "AMIA"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111935840"
                        ],
                        "name": "Yanping Du",
                        "slug": "Yanping-Du",
                        "structuredName": {
                            "firstName": "Yanping",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanping Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10726926,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d29d58a02e8756cdd6707ae47f51d01f2c95bf61",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a scalable algorithm for indexing and retrieving images based on region segmentation. The method uses statistical clustering on region features and IRM (integrated region matching), a measure developed to evaluate overall similarity between images. It incorporates properties of all the regions in the images by a region-matching scheme. The algorithm has been implemented as a part of our experimental SIMPLIcity (Semantics-sensitive Integrated Matching for Picture LIbraries) image retrieval system and tested on large-scale image databases of both general-purpose images and pathology slides. Experiments have demonstrated that this technique maintains the accuracy of the original system while reducing the matching time significantly."
            },
            "slug": "A-scalable-integrated-region-based-image-retrieval-Du-Wang",
            "title": {
                "fragments": [],
                "text": "A scalable integrated region-based image retrieval system"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A scalable algorithm for indexing and retrieving images based on region segmentation using statistical clustering on region features and IRM (integrated region matching), a measure developed to evaluate overall similarity between images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145163573"
                        ],
                        "name": "A. Singhal",
                        "slug": "A.-Singhal",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Singhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singhal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33642939"
                        ],
                        "name": "Jiebo Luo",
                        "slug": "Jiebo-Luo",
                        "structuredName": {
                            "firstName": "Jiebo",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiebo Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34763422"
                        ],
                        "name": "W. Zhu",
                        "slug": "W.-Zhu",
                        "structuredName": {
                            "firstName": "Weiyu",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14356209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01c2f706c107c9853a86d1a2d6cd8e6f82b31db1",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene content understanding facilitates a large number of applications, ranging from content-based image retrieval to other multimedia applications. Material detection refers to the problem of identifying key semantic material types (such as sky, grass, foliage, water, and snow in images). In this paper, we present a holistic approach to determining scene content, based on a set of individual material detection algorithms, as well as probabilistic spatial context models. A major limitation of individual material detectors is the significant number of misclassifications that occur because of the similarities in color and texture characteristics of various material types. We have developed a spatial context-aware material detection system that reduces misclassification by constraining the beliefs to conform to the probabilistic spatial context models. Experimental results show that the accuracy of materials detection is improved by 13% using the spatial context models over the individual material detectors themselves."
            },
            "slug": "Probabilistic-spatial-context-models-for-scene-Singhal-Luo",
            "title": {
                "fragments": [],
                "text": "Probabilistic spatial context models for scene content understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A spatial context-aware material detection system that reduces misclassification by constraining the beliefs to conform to the probabilistic spatial context models is developed."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 773679,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "9724f7686913adf13b88951b3a2bee6579e51739",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper addresses learning-based characterization of fine art painting styles. The research has the potential to provide a powerful tool to art historians for studying connections among artists or periods in the history of art. Depending on specific applications, paintings can be categorized in different ways. We focus on comparing the painting styles of artists. To profile the style of an artist, a mixture of stochastic models is estimated using training images. The two-dimensional (2D) multiresolution hidden Markov model (MHMM) is used in the experiment. These models form an artist's distinct digital signature. For certain types of paintings, only strokes provide reliable information to distinguish artists. Chinese ink paintings are a prime example of the above phenomenon; they do not have colors or even tones. The 2D MHMM analyzes relatively large regions in an image, which in turn makes it more likely to capture properties of the painting strokes. The mixtures of 2D MHMMs established for artists can be further used to classify paintings and compare paintings or artists. We implemented and tested the system using high-resolution digital photographs of some of China's most renowned artists. Experiments have demonstrated good potential of our approach in automatic analysis of paintings. Our work can be applied to other domains."
            },
            "slug": "Studying-digital-imagery-of-ancient-paintings-by-of-Li-Wang",
            "title": {
                "fragments": [],
                "text": "Studying digital imagery of ancient paintings by mixtures of stochastic models"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This work implemented and tested a learning-based characterization of fine art painting styles using high-resolution digital photographs of some of China's most renowned artists, and demonstrated good potential in automatic analysis of paintings."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058177533"
                        ],
                        "name": "Simon Tong",
                        "slug": "Simon-Tong",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Tong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10743717,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63861fbeb7ec41986b85965b9780b428d919919e",
            "isKey": false,
            "numCitedBy": 1510,
            "numCiting": 101,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback is often a critical component when designing image databases. With these databases it is difficult to specify queries directly and explicitly. Relevance feedback interactively determinines a user's desired output or query concept by asking the user whether certain proposed images are relevant or not. For a relevance feedback algorithm to be effective, it must grasp a user's query concept accurately and quickly, while also only asking the user to label a small number of images. We propose the use of a support vector machine active learning algorithm for conducting effective relevance feedback for image retrieval. The algorithm selects the most informative images to query a user and quickly learns a boundary that separates the images that satisfy the user's query concept from the rest of the dataset. Experimental results show that our algorithm achieves significantly higher search accuracy than traditional query refinement schemes after just three to four rounds of relevance feedback."
            },
            "slug": "Support-vector-machine-active-learning-for-image-Tong-Chang",
            "title": {
                "fragments": [],
                "text": "Support vector machine active learning for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes the use of a support vector machine active learning algorithm for conducting effective relevance feedback for image retrieval and achieves significantly higher search accuracy than traditional query refinement schemes after just three to four rounds of relevance feedback."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7692065"
                        ],
                        "name": "K. Tieu",
                        "slug": "K.-Tieu",
                        "structuredName": {
                            "firstName": "Kinh",
                            "lastName": "Tieu",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tieu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 510936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bab4b6bbd10d264caf9ac01b79750d113efe03bd",
            "isKey": false,
            "numCitedBy": 383,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach for image retrieval using a very large number of highly selective features and efficient learning of queries. Our approach is predicated on the assumption that each image is generated by a sparse set of visual \u201ccauses\u201d and that images which are visually similar share causes. We propose a mechanism for computing a very large number of highly selective features which capture some aspects of this causal structure (in our implementation there are over 46,000 highly selective features). At query time a user selects a few example images, and the AdaBoost algorithm is used to learn a classification function which depends on a small number of the most appropriate features. This yields a highly efficient classification function. In addition we show that the AdaBoost framework provides a natural mechanism for the incorporation of relevance feedback. Finally we show results on a wide variety of image queries."
            },
            "slug": "Boosting-Image-Retrieval-Tieu-Viola",
            "title": {
                "fragments": [],
                "text": "Boosting Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This work proposes a mechanism for computing a very large number of highly selective features which capture some aspects of this causal structure and shows results on a wide variety of image queries."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116664201"
                        ],
                        "name": "Yixin Chen",
                        "slug": "Yixin-Chen",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1791876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2a0a5fc0a33a8df662b840ecc80ad5530ae4bf5",
            "isKey": false,
            "numCitedBy": 490,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a fuzzy logic approach, UFM (unified feature matching), for region-based image retrieval. In our retrieval system, an image is represented by a set of segmented regions, each of which is characterized by a fuzzy feature (fuzzy set) reflecting color, texture, and shape properties. As a result, an image is associated with a family of fuzzy features corresponding to regions. Fuzzy features naturally characterize the gradual transition between regions (blurry boundaries) within an image and incorporate the segmentation-related uncertainties into the retrieval algorithm. The resemblance of two images is then defined as the overall similarity between two families of fuzzy features and quantified by a similarity measure, UFM measure, which integrates properties of all the regions in the images. Compared with similarity measures based on individual regions and on all regions with crisp-valued feature representations, the UFM measure greatly reduces the influence of inaccurate segmentation and provides a very intuitive quantification. The UFM has been implemented as a part of our experimental SIMPLIcity image retrieval system. The performance of the system is illustrated using examples from an image database of about 60,000 general-purpose images."
            },
            "slug": "A-Region-Based-Fuzzy-Feature-Matching-Approach-to-Chen-Wang",
            "title": {
                "fragments": [],
                "text": "A Region-Based Fuzzy Feature Matching Approach to Content-Based Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A fuzzy logic approach, UFM (unified feature matching), for region-based image retrieval, which greatly reduces the influence of inaccurate segmentation and provides a very intuitive quantification."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3945955"
                        ],
                        "name": "Xiaofei He",
                        "slug": "Xiaofei-He",
                        "structuredName": {
                            "firstName": "Xiaofei",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofei He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9650912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2772c2bab5609f194cbb3e2cf4cf383d03f57987",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning a mapping function from low-level feature space to high-level semantic space. Under the assumption that the data lie on a submanifold embedded in a high dimensional Euclidean space, we propose a relevance feedback scheme which is naturally conducted only on the image manifold in question rather than the total ambient space. While images are typically represented by feature vectors in Rn, the natural distance is often different from the distance induced by the ambient space Rn. The geodesic distances on manifold are used to measure the similarities between images. However, when the number of data points is small, it is hard to discover the intrinsic manifold structure. Based on user interactions in a relevance feedback driven query-by-example system, the intrinsic similarities between images can be accurately estimated. We then develop an algorithmic framework to approximate the optimal mapping function by a Radial Basis Function (RBF) neural network. The semantics of a new image can be inferred by the RBF neural network. Experimental results show that our approach is effective in improving the performance of content-based image retrieval systems."
            },
            "slug": "Learning-an-image-manifold-for-retrieval-He-Ma",
            "title": {
                "fragments": [],
                "text": "Learning an image manifold for retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A relevance feedback scheme which is naturally conducted only on the image manifold in question rather than the total ambient space, and an algorithmic framework to approximate the optimal mapping function by a Radial Basis Function (RBF) neural network."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683556"
                        ],
                        "name": "G. Wiederhold",
                        "slug": "G.-Wiederhold",
                        "structuredName": {
                            "firstName": "Gio",
                            "lastName": "Wiederhold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wiederhold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1149168,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d607b773d2719a5948bab0c16500e4f00fd61df8",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised segmentation of images with low depth of field (DOF) is highly useful in various applications. This paper describes a novel multiresolution image segmentation algorithm for low DOF images. The algorithm is designed to separate a sharply focused object-of-interest from other foreground or background objects. The algorithm is fully automatic in that all parameters are image independent. A multi-scale approach based on high frequency wavelet coefficients and their statistics is used to perform context-dependent classification of individual blocks of the image. Unlike other edge-based approaches, our algorithm does not rely on the process of connecting object boundaries. The algorithm has achieved high accuracy when tested on more than 100 low DOF images, many with inhomogeneous foreground or background distractions. Compared with he state of the art algorithms, this new algorithm provides better accuracy at higher speed."
            },
            "slug": "Unsupervised-Multiresolution-Segmentation-for-with-Wang-Li",
            "title": {
                "fragments": [],
                "text": "Unsupervised Multiresolution Segmentation for Images with Low Depth of Field"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel multiresolution image segmentation algorithm designed to separate a sharply focused object-of-interest from other foreground or background objects and provides better accuracy at higher speed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749498"
                        ],
                        "name": "Andrew D. Bagdanov",
                        "slug": "Andrew-D.-Bagdanov",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Bagdanov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew D. Bagdanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795847"
                        ],
                        "name": "Lamberto Ballan",
                        "slug": "Lamberto-Ballan",
                        "structuredName": {
                            "firstName": "Lamberto",
                            "lastName": "Ballan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lamberto Ballan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801509"
                        ],
                        "name": "M. Bertini",
                        "slug": "M.-Bertini",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Bertini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bertini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "For instance, bags of SIFT features [17] are used to characterize and subsequently detect advertisement logos in video frames [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2333686,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3f5f4fedb670dadfe9a77c16ff567985adf34c4",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a system for detection and retrieval of trademarks appearing in sports videos. We propose a compact representation of trademarks and video frame content based on SIFT feature points. This representation can be used to robustly detect, localize, and retrieve trademarks as they appear in a variety of different sports video types. Classification of trademarks is performed by matching a set of SIFT feature descriptors for each trademark instance against the set of SIFT features detected in each frame of the video. Localization is performed through robust clustering of matched feature points in the video frame. Experimental results are provided, along with an analysis of the precision and recall. Results show that the our proposed technique is efficient and effectively detects and classifies trademarks."
            },
            "slug": "Trademark-matching-and-retrieval-in-sports-video-Bagdanov-Ballan",
            "title": {
                "fragments": [],
                "text": "Trademark matching and retrieval in sports video databases"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A compact representation of trademarks and video frame content based on SIFT feature points is proposed that can be used to robustly detect, localize, and retrieve trademarks as they appear in a variety of different sports video types."
            },
            "venue": {
                "fragments": [],
                "text": "MIR '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62531491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89121ed4d0d3db9bc192fd79f541fc299eba7d6b",
            "isKey": false,
            "numCitedBy": 304,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer vision researchers are developing new approaches to object recognition and detection that are based almost directly on images and avoid the use of intermediate three-dimensional models. Many of these techniques depend on a representation of images that induces a linear vector space structure and in principle requires dense feature correspondence. This image representation allows the use of learning techniques for the analysis of images (for computer vision) as well as for the synthesis of images (for computer graphics)."
            },
            "slug": "Image-Representations-for-Visual-Learning-Beymer-Poggio",
            "title": {
                "fragments": [],
                "text": "Image Representations for Visual Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Computer vision researchers are developing new approaches to object recognition and detection that are based almost directly on images and avoid the use of intermediate three-dimensional models."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683556"
                        ],
                        "name": "G. Wiederhold",
                        "slug": "G.-Wiederhold",
                        "structuredName": {
                            "firstName": "Gio",
                            "lastName": "Wiederhold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wiederhold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8204609,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science",
                "Mathematics"
            ],
            "id": "20151deaae70f8ef33046bf4508936274920fa23",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The classification of general-purpose photographs into textured and non-textured images is critical for developing accurate content-based image retrieval systems for large-scale image databases. With the accurate detection of textured images, we may retrieve images based on features tailored for the corresponding image type. In this paper, we present an algorithm to classify a photographic image as textured or non-textured using region segmentation and statistical testing. The application of the system to a database of about 60,000 general-purpose images shows much improved accuracy in retrieval."
            },
            "slug": "Classification-of-textured-and-non-textured-images-Li-Wang",
            "title": {
                "fragments": [],
                "text": "Classification of textured and non-textured images using region segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "An algorithm to classify a photographic image as textured or non-textured using region segmentation and statistical testing is presented and the application to a database of about 60,000 general-purpose images shows much improved accuracy in retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2000 International Conference on Image Processing (Cat. No.00CH37101)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761784"
                        ],
                        "name": "R. Tibshirani",
                        "slug": "R.-Tibshirani",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tibshirani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tibshirani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some initial efforts have recently been devoted to automatically annotating pictures, leveraging decades of research in computer vision, image understanding, image processing, and statistical learning [3], [11], [ 12 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "clustering [ 12 ]. The main difficulty encountered here is the unusual nature of space \u2126. Our approach is inspired by the intrinsic connection between k-means clustering and mixture modeling."
                    },
                    "intents": []
                }
            ],
            "corpusId": 40654213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bee570503aaa0ed5bc5dd4cf6aa742df0b5cef87",
            "isKey": false,
            "numCitedBy": 13814,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book.\n\nThis major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for ``wide'' data (p bigger than n), including multiple testing and false discovery rates.\n\nTrevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie co-developed much of the statistical modeling software and environment in R/S-PLUS and invented principal curves and surfaces. Tibshirani proposed the lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, projection pursuit and gradient boosting."
            },
            "slug": "The-Elements-of-Statistical-Learning:-Data-Mining,-Hastie-Tibshirani",
            "title": {
                "fragments": [],
                "text": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd Edition"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering."
            },
            "venue": {
                "fragments": [],
                "text": "Springer Series in Statistics"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116439170"
                        ],
                        "name": "J. Z. Wang",
                        "slug": "J.-Z.-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Zijun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Z. Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12233545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2b9b626b05419cef188a6df13f2c932ba130ebf",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this demonstration, we present SIMPLIcity, an image retrieval system for picture libraries and biomedical image databases. The system uses a wavelet-based approach for feature extraction, real-time region segmentation, the Integration Region Matching (IRM) metric, and image classification methods. Tested on large-scale picture libraries and a database of pathology images, the system has demonstrated accurate and fast retrieval. It also exceptionally robust to image alterations."
            },
            "slug": "SIMPLIcity:-a-region-based-retrieval-system-for-and-Wang",
            "title": {
                "fragments": [],
                "text": "SIMPLIcity: a region-based retrieval system for picture libraries and biomedical image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "SIMPLIcity, an image retrieval system for picture libraries and biomedical image databases, uses a wavelet-based approach for feature extraction, real-time region segmentation, the Integration Region Matching (IRM) metric, and image classification methods."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116664201"
                        ],
                        "name": "Yixin Chen",
                        "slug": "Yixin-Chen",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3856639,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6d9a272c8defb827b7e4e2d11cd0212e1cd5c05",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of most region-based image retrieval systems depend critically on the accuracy of object segmentation. We propose a region matching approach, unified feature matching (UFM), which greatly increases the robustness of the retrieval system against segmentation related uncertainties. In our retrieval system, an image is represented by a set of segmented regions each of which is characterized by a fuzzy feature reflecting color, texture, and shape properties. The resemblance between two images is then defined as the overall similarity between two families of fuzzy features, and quantified by the UFM measure. The system has been tested on a database of about 60,000 general-purpose images. Experimental results demonstrate improved accuracy and robustness."
            },
            "slug": "Looking-beyond-region-boundaries:-a-robust-image-Chen-Wang",
            "title": {
                "fragments": [],
                "text": "Looking beyond region boundaries: a robust image similarity measure using fuzzified region features"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This work proposes a region matching approach, unified feature matching (UFM), which greatly increases the robustness of the retrieval system against segmentation related uncertainties and demonstrates improved accuracy and robustness."
            },
            "venue": {
                "fragments": [],
                "text": "The 12th IEEE International Conference on Fuzzy Systems, 2003. FUZZ '03."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116664201"
                        ],
                        "name": "Yixin Chen",
                        "slug": "Yixin-Chen",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14911022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9724941f36c681963f7c2b7592c566e8eaee676",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose FIRM (Fuzzily Integrated Region Matching), an efficient and robust similarity measure for region-based image retrieval. Each image in our retrieval system is represented by a set of regions that are characterized by fuzzy sets. The FIRM measure, representing the overall similarity between two images, is defined as the similarity between two families of fuzzy sets. Compared with similarity measures based on individual regions and on all regions with crisp feature representations, our approach greatly reduces the influence of inaccurate segmentation. Experimental results based on a database of about 200,000 general-purpose images demonstrate improved accuracy, robustness, and high speed."
            },
            "slug": "FIRM:-fuzzily-integrated-region-matching-for-image-Chen-Wang",
            "title": {
                "fragments": [],
                "text": "FIRM: fuzzily integrated region matching for content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "Fuzzily Integrated Region Matching is proposed, an efficient and robust similarity measure for region-based image retrieval that greatly reduces the influence of inaccurate segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116664201"
                        ],
                        "name": "Yixin Chen",
                        "slug": "Yixin-Chen",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5101951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d70b5dd40951dc97cb0296668c7affa482f3c970",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "To design a fuzzy rule-based classification system (fuzzy classifier) with good generalization ability in a high dimensional feature space has been an active research topic for a long time. As a powerful machine learning approach for pattern recognition problems, the support vector machine (SVM) is known to have good generalization ability. More importantly, an SVM can work very well on a high- (or even infinite) dimensional feature space. This paper investigates the connection between fuzzy classifiers and kernel machines, establishes a link between fuzzy rules and kernels, and proposes a learning algorithm for fuzzy classifiers. We first show that a fuzzy classifier implicitly defines a translation invariant kernel under the assumption that all membership functions associated with the same input variable are generated from location transformation of a reference function. Fuzzy inference on the IF-part of a fuzzy rule can be viewed as evaluating the kernel function. The kernel function is then proven to be a Mercer kernel if the reference functions meet a certain spectral requirement. The corresponding fuzzy classifier is named positive definite fuzzy classifier (PDFC). A PDFC can be built from the given training samples based on a support vector learning approach with the IF-part fuzzy rules given by the support vectors. Since the learning process minimizes an upper bound on the expected risk (expected prediction error) instead of the empirical risk (training error), the resulting PDFC usually has good generalization. Moreover, because of the sparsity properties of the SVMs, the number of fuzzy rules is irrelevant to the dimension of input space. In this sense, we avoid the \"curse of dimensionality.\" Finally, PDFCs with different reference functions are constructed using the support vector learning approach. The performance of the PDFCs is illustrated by extensive experimental results. Comparisons with other methods are also provided."
            },
            "slug": "Support-vector-learning-for-fuzzy-rule-based-Chen-Wang",
            "title": {
                "fragments": [],
                "text": "Support vector learning for fuzzy rule-based classification systems"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper investigates the connection between fuzzy classifiers and kernel machines, establishes a link between fuzzy rules and kernels, and proposes a learning algorithm for fuzzy classifier (PDFC) using the support vector learning approach."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Fuzzy Syst."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143808488"
                        ],
                        "name": "E. Levina",
                        "slug": "E.-Levina",
                        "structuredName": {
                            "firstName": "Elizaveta",
                            "lastName": "Levina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678771"
                        ],
                        "name": "P. Bickel",
                        "slug": "P.-Bickel",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bickel",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bickel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "In fact, as discussed in [15], EMD is equivalent to the Mallows distance when the same total mass is assigned to both distributions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "4 Mallows Distance between Distributions To compute the distanceD\u00f0 1; 2\u00de between two distributions 1 and 2, we use the Mallows distance [19], [15] introduced in 1972."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9682419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "554ed92c2af92d5a1456bed2ddc85fe59d5dae00",
            "isKey": false,
            "numCitedBy": 503,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The Earth Mover's distanc1e was first introduced as a purely empirical ways to measure texture and color similarities. We show that it has a rigorous probabilistic interpretation and is conceptually equivalent to the Mallows distance on probability distributions. The two distances are exactly the same when applied to probability distributions, but behave differently when applied to unnormalized distributions with different masses, called signatures. We discuss the advantages and disadvantages of both distances, and statistical issues involved in computing them from data. We also report some texture classification results for the Mallows distance applied to texture features and compare several ways of estimating feature distributions. In addition, we list some known probabilistic properties of this distance."
            },
            "slug": "The-Earth-Mover's-distance-is-the-Mallows-distance:-Levina-Bickel",
            "title": {
                "fragments": [],
                "text": "The Earth Mover's distance is the Mallows distance: some insights from statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The Earth Mover's distanc1e has a rigorous probabilistic interpretation and is conceptually equivalent to the Mallows distance on probability distributions, but behave differently when applied to unnormalized distributions with different masses, called signatures."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "For instance, bags of SIFT features [17] are used to characterize and subsequently detect advertisement logos in video frames [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25505,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51019281"
                        ],
                        "name": "R. E. Wheeler",
                        "slug": "R.-E.-Wheeler",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Wheeler",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. E. Wheeler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 17132681,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f20cfc546dd3815df9fc7742747453e2f0f5bae2",
            "isKey": false,
            "numCitedBy": 701,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We present probability integrals and inverses for common continuous statisticaldistribution functions. The probability integrals are evaluated by series or continued fractions, identified for the most part by their equation numbers in Abramowitz and Stegun [I]. Sufficient terms are used to insure full accuracy on a machine with 18 decimal digits; the inclusion of additional terms is not difficult, because of the obvious nature of the coefficients in the series and continued fractions. The inverses are obtained by Newtonian iteration, which is terminated when the probability integral is nearly equal to the desired probability."
            },
            "slug": "Statistical-distributions-Wheeler",
            "title": {
                "fragments": [],
                "text": "Statistical distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The probability integrals are evaluated by series or continued fractions, identified by their equation numbers in Abramowitz and Stegun, and the inverses are obtained by Newtonian iteration."
            },
            "venue": {
                "fragments": [],
                "text": "APLQ"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116664201"
                        ],
                        "name": "Yixin Chen",
                        "slug": "Yixin-Chen",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18405668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c91d5cc8cec930baf39fdeafba1394558393b8e7",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the connection between additive fuzzy systems and kernel machines. We prove that, under quite general conditions, these two seemingly quite distinct models are essentially equivalent. As a result, algorithms based upon support vector (SV) learning are proposed to build fuzzy systems for classification and function approximation. The performance of the proposed algorithm is illustrated using extensive experimental results."
            },
            "slug": "Kernel-machines-and-additive-fuzzy-systems:-and-Chen-Wang",
            "title": {
                "fragments": [],
                "text": "Kernel machines and additive fuzzy systems: classification and function approximation"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "It is proved that, under quite general conditions, these two seemingly quite distinct models are essentially equivalent and algorithms based upon support vector learning are proposed to build fuzzy systems for classification and function approximation."
            },
            "venue": {
                "fragments": [],
                "text": "The 12th IEEE International Conference on Fuzzy Systems, 2003. FUZZ '03."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737063"
                        ],
                        "name": "I. Daubechies",
                        "slug": "I.-Daubechies",
                        "structuredName": {
                            "firstName": "Ingrid",
                            "lastName": "Daubechies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Daubechies"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 58524360,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "7e63bf9af3f70abd5771c06d459a0d3fbfbb2909",
            "isKey": false,
            "numCitedBy": 15558,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction Preliminaries and notation The what, why, and how of wavelets The continuous wavelet transform Discrete wavelet transforms: Frames Time-frequency density and orthonormal bases Orthonormal bases of wavelets and multiresolutional analysis Orthonormal bases of compactly supported wavelets More about the regularity of compactly supported wavelets Symmetry for compactly supported wavelet bases Characterization of functional spaces by means of wavelets Generalizations and tricks for orthonormal wavelet bases References Indexes."
            },
            "slug": "Ten-Lectures-on-Wavelets-Daubechies",
            "title": {
                "fragments": [],
                "text": "Ten Lectures on Wavelets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a meta-analyses of the wavelet transforms of Coxeter\u2019s inequality and its applications to multiresolutional analysis and orthonormal bases."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678771"
                        ],
                        "name": "P. Bickel",
                        "slug": "P.-Bickel",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bickel",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32854168"
                        ],
                        "name": "D. Freedman",
                        "slug": "D.-Freedman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Freedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Freedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "The Mallows distance is proved to be a true metric [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123476590,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "00cce17fec8074e35d797c937b32452348237d8f",
            "isKey": false,
            "numCitedBy": 1576,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Some-Asymptotic-Theory-for-the-Bootstrap-Bickel-Freedman",
            "title": {
                "fragments": [],
                "text": "Some Asymptotic Theory for the Bootstrap"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145654437"
                        ],
                        "name": "M. Evans",
                        "slug": "M.-Evans",
                        "structuredName": {
                            "firstName": "Merran",
                            "lastName": "Evans",
                            "middleNames": [
                                "Gael",
                                "Anderson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Evans"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 126011226,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "be231dfbeb5bd5da4cedca7d73398ff02370de9c",
            "isKey": false,
            "numCitedBy": 1551,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-Distributions-Evans",
            "title": {
                "fragments": [],
                "text": "Statistical Distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2655181"
                        ],
                        "name": "C. Mallows",
                        "slug": "C.-Mallows",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Mallows",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mallows"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To compute the distance D(\u03b31 ,\u03b3 2) between two distributions \u03b31 and \u03b32, we use the Mallows distance [ 19 ], [15] introduced in 1972."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122333431,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "65c71ba7eabc196fbb5f91190208bbb7f3242335",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Note-on-Asymptotic-Joint-Normality-Mallows",
            "title": {
                "fragments": [],
                "text": "A Note on Asymptotic Joint Normality"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144666740"
                        ],
                        "name": "S. Rachev",
                        "slug": "S.-Rachev",
                        "structuredName": {
                            "firstName": "Svetlozar",
                            "lastName": "Rachev",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rachev"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The optimization problem involved in computing the Mallows distance is the same as that for solving the mass transportation problem [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120424253,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dd3db834acb2522339ce70d937b39901f49dea69",
            "isKey": false,
            "numCitedBy": 285,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Monge\u2013Kantorovich-Mass-Transference-Problem-and-Rachev",
            "title": {
                "fragments": [],
                "text": "The Monge\u2013Kantorovich Mass Transference Problem and Its Stochastic Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4527458"
                        ],
                        "name": "P. Deb",
                        "slug": "P.-Deb",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Deb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Deb"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118113311,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "954f688810694e53b136ea9b1c8945dd34091b17",
            "isKey": false,
            "numCitedBy": 3101,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Finite mixture models provide a natural way of modeling continuous or discrete outcomes that are observed from populations consisting of a finite number of homogeneous subpopulations. Applications of finite mixture models are abundant in the social and behavioral sciences, biological and environmental sciences, engineering and finance. Such models have a natural representation of heterogeneity in a finite, usually small, number of latent classes, each of which may be regarded as a type. More generally, the finite mixture model can be shown to approximate any unknown distribution under suitable regularity conditions. The Stata package -fmm- implements a maximum likelihood estimator for a class of finite mixture models. In this talk, I will begin by introducing finite mixture models using a number of examples and discuss issues of estimation, testing and model selection. I will then describe estimation using fmm, calculations of predictions, marginal effects, and posterior class probabilities, and illustrate these using examples from econometrics and finance."
            },
            "slug": "Finite-Mixture-Models-Deb",
            "title": {
                "fragments": [],
                "text": "Finite Mixture Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "where \u00f0 \u00de is the di-gamma function [10]"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical Distributions, third ed"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computerized Annotation of Pictures,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the ACM Multimedia Conference,"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Past Performance and Future Results"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combining (14) and (15), we have proved the ML estimator in Equation"
            },
            "venue": {
                "fragments": [],
                "text": "Combining (14) and (15), we have proved the ML estimator in Equation"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 201
                            }
                        ],
                        "text": "Some initial efforts have recently been devoted to automatically annotating pictures, leveraging decades of research in computer vision, image understanding, image processing, and statistical learning [2, 8, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Elements of Statistical Learning: Data Mining, Inferences, and Prediction, Springer-Verlag"
            },
            "venue": {
                "fragments": [],
                "text": "New York,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "and statistical learning [3], [11], [12]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Digital Image Processing, second ed"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 59,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Real-Time-Computerized-Annotation-of-Pictures-Li-Wang/09932c4c63a2b15987baec125eb70440aaa9c9d6?sort=total-citations"
}