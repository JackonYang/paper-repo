{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116942721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68c95bb0440a6ef3537060a387890f9c9b614215",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter surveys the contributions of projective geometry to computer vision. Projective geometry deals elegantly with the general case of perspective projection and therefore provides interesting understanding of the geometric aspect of image formation. It also provides useful tools like perspective invariants. First the major definitions and results of this geometry are presented. Applications are then provided for several domains of 3-D computer vision, including location of the viewer for uncalibrated cameras, properties of epipolar lines in stereovision and object recognition."
            },
            "slug": "Projective-Geometry-and-Computer-Vision-Mohr",
            "title": {
                "fragments": [],
                "text": "Projective Geometry and Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This chapter surveys the contributions of projective geometry to computer vision, which deals elegantly with the general case of perspective projection and therefore provides interesting understanding of the geometric aspect of image formation."
            },
            "venue": {
                "fragments": [],
                "text": "Handbook of Pattern Recognition and Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2556432"
                        ],
                        "name": "St\u00e9phane Laveau",
                        "slug": "St\u00e9phane-Laveau",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Laveau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "St\u00e9phane Laveau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15470059,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71bdcccf752a089aa6ecea971a49aa4b9a8155c0",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an extension of the usual projective geometric framework for computer vision which can nicely take into account an information that was previously not used, i.e. the fact that the pixels in an image correspond to points which lie in front of the camera. This framework, called the oriented projective geometry, retains all the advantages of the unoriented projective geometry, namely its simplicity for expressing the viewing geometry of a system of cameras, while extending its adequation to model realistic situations."
            },
            "slug": "Oriented-Projective-Geometry-for-Computer-Vision-Laveau-Faugeras",
            "title": {
                "fragments": [],
                "text": "Oriented Projective Geometry for Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "An extension of the usual projective geometric framework for computer vision which can nicely take into account an information that was previously not used, i.e. the fact that the pixels in an image correspond to points which lie in front of the camera."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40309692"
                        ],
                        "name": "C. G. Harris",
                        "slug": "C.-G.-Harris",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Harris",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40365651"
                        ],
                        "name": "M. Stephens",
                        "slug": "M.-Stephens",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Stephens",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stephens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1694378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6818668fb895d95861a2eb9673ddc3a41e27b3b3",
            "isKey": false,
            "numCitedBy": 14111,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed."
            },
            "slug": "A-Combined-Corner-and-Edge-Detector-Harris-Stephens",
            "title": {
                "fragments": [],
                "text": "A Combined Corner and Edge Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem the authors are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work."
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19010305,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4aab079346f7824dc982071ce948d0d7c73d3b5a",
            "isKey": false,
            "numCitedBy": 1067,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of determining the kind of three-dimensional reconstructions that can be obtained from a binocular stereo rig for which no three-dimensional metric calibration data is available. The only information at our disposal is a set of pixel correspondences between the two retinas which we assume are obtained by some correlation technique or any other means. We show that even in this case some very rich non-metric reconstructions of the environment can nonetheless be obtained."
            },
            "slug": "What-can-be-seen-in-three-dimensions-with-an-stereo-Faugeras",
            "title": {
                "fragments": [],
                "text": "What can be seen in three dimensions with an uncalibrated stereo rig"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper addresses the problem of determining the kind of three- dimensional reconstructions that can be obtained from a binocular stereo rig for which no three-dimensional metric calibration data is available, and shows that even in this case some very rich non-metric reconstructions of the environment can nonetheless be obtained."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1909232"
                        ],
                        "name": "Frederic Devernay",
                        "slug": "Frederic-Devernay",
                        "structuredName": {
                            "firstName": "Frederic",
                            "lastName": "Devernay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederic Devernay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12984769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ada702d5dabc1e2b59d6ac7e4f3116fa961c1f0",
            "isKey": false,
            "numCitedBy": 247,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Most algorithms in 3D computer vision rely on the pinhole camera model because of its simplicity, whereas video optics, especially low-cost wide-angle lens, generate a lot of nonlinear distortion which can be critical. To find the distortion parameters of a camera, we use the following fundamental property: a camera follows the pinhole model if and only if the projection of every line in space onto the camera is a line. Consequently, if we find the transformation on the video image so that every line in space is viewed in the transformed image as a line, then we know how to remove the distortion from the image. The algorithm consists of first doing edge extraction on a possibly distorted video sequence, then doing polygonal approximation with a large tolerance on these edges to extract possible lines from the sequence, and then finding the parameters of our distortion model that best transform these edges to segments. Results are presented on real video images, compared with distortion calibration obtained by a full camera calibration method which uses a calibration grid."
            },
            "slug": "Automatic-calibration-and-removal-of-distortion-of-Devernay-Faugeras",
            "title": {
                "fragments": [],
                "text": "Automatic calibration and removal of distortion from scenes of structured environments"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The algorithm consists of first doing edge extraction on a possibly distorted video sequence, then doing polygonal approximation with a large tolerance on these edges to extract possible lines from the sequence, and then finding the parameters of the distortion model that best transform these edge to segments."
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5766562,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f7e5e9e219ca9fecf3962c195ddbfbf0784f5f8d",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a recent approach to recognition that uses regions to determine the pose of objects while allowing for partial occlusion of the regions. We further analyze properties of the method for planar objects undergoing projective transformations. We prove that three visible regions are sufficient to determine the transformation uniquely, and that for a large class of objects two regions are insufficient. However, we show that when several regions are available, the pose of the object can generally be recovered even when all but two regions are significantly occluded. Our analysis is based on investigating the flow patterns of points under projective transformations in the presence of fixed points."
            },
            "slug": "Projective-alignment-with-regions-Basri-Jacobs",
            "title": {
                "fragments": [],
                "text": "Projective alignment with regions"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is proved that three visible regions are sufficient to determine the transformation uniquely, and that for a large class of objects two regions are insufficient, but it is shown that when several regions are available, the pose of the object can generally be recovered even when all but three regions are significantly occluded."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2312379,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35a43d5c5755cdc3509bd3282d5cadc75d78d64a",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The objective of this work is the automatic detection and grouping of imaged elements which repeat on a plane in a scene (for example tiled floorings). It is shown that structures that repeat on a scene plane are related by particular parametrized transformations in perspective images. These image transformations provide powerful grouping constraints, and can be used at the heart of hypothesize and verify grouping algorithms. The parametrized transformations are global across the image plane and may be computed without knowledge of the pose of the plane or camera calibration. \n \nParametrized transformations are given for severalcl asses of repeating operation in the world as well as groupers based on these. These groupers are demonstrated on a number of real images, where both the elements and the grouping are determined automatically. \n \nIt is shown that the repeating element can be learnt from the image, and hence provides an image descriptor. Also, information on the plane pose, such as its vanishing line, can be recovered from the grouping."
            },
            "slug": "Geometric-Grouping-of-Repeated-Elements-within-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "Geometric Grouping of Repeated Elements within Images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that structures that repeat on a scene plane are related by particular parametrized transformations in perspective images, which provide powerful grouping constraints and can be used at the heart of hypothesize and verify grouping algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713563"
                        ],
                        "name": "F. Kahl",
                        "slug": "F.-Kahl",
                        "structuredName": {
                            "firstName": "Fredrik",
                            "lastName": "Kahl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kahl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34792947,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6fb1df2106bcb5ff9b9fc0d21827f28c20292f11",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis is concerned with one of the core problems in computer vision, namely to reconstruct a real world scene from several images of it. The interplay between the geometry of the scene, the cameras and the images is analyzed. The framework is based on projective geometry, which is the natural language for describing the geometry of multiple views. The affine and Euclidean geometries are regarded as special cases of projective geometry. First, the projection of several different geometric primitives in multiple views is described and analyzed. The analysis includes points, lines, quadrics and curved surfaces. The cameras are assumed to be uncalibrated and both the perspective/projective and the affine camera model are considered. Several new reconstruction methods are developed. Some features of these methods include the possibility of handling: (i) missing data, (ii) several different primitives simultaneously and (iii) minimal cases. Then, focus is turned to the process of obtaining a Euclidean reconstruction of the scene from uncalibrated images. This problem is known as auto-calibration. A reconstruction method which imposes regularity constraints on the camera motion is introduced which makes the auto-calibration problem more stable. The last part of the thesis is devoted to a theoretical study of necessary and sufficient conditions for obtaining a unique scene reconstruction. One classical result is that for two images of a 3D scene this happens if and only if the scene points and the camera centres do not lie on a ruled quadric. This is generalized to any number of views. Furthermore, analogous critical configurations for the 1D camera are derived. In auto-calibration, it is shown that the critical configurations depend only on the camera motion. Complete classifications of such critical motions which lead to ambiguous reconstructions are given under different settings. (Less)"
            },
            "slug": "Geometry-and-Critical-Configurations-of-Multiple-Kahl",
            "title": {
                "fragments": [],
                "text": "Geometry and Critical Configurations of Multiple Views"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This thesis is concerned with one of the core problems in computer vision, namely to reconstruct a real world scene from several images of it, and a reconstruction method which imposes regularity constraints on the camera motion is introduced which makes the auto-calibration problem more stable."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37767210,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "fc62d436ac9ea7fad76b47793151c3793ec82e1a",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In the general case, a trilinear relationship between three perspective views is shown to exist. The trilinearity result is shown to be of much practical use in visual recognition by alignment \u2014 yielding a direct method superior to the conventional epipolar line intersection method. The proof of the central result may be of further interest as it demonstrates certain regularities across homographies of the plane."
            },
            "slug": "Trilinearity-in-Visual-Recognition-by-Alignment-Shashua",
            "title": {
                "fragments": [],
                "text": "Trilinearity in Visual Recognition by Alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The trilinearity result is shown to be of much practical use in visual recognition by alignment \u2014 yielding a direct method superior to the conventional epipolar line intersection method."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16919747,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162dbe4400ca576bc5f7daea2fe20d92d46ee8a8",
            "isKey": false,
            "numCitedBy": 1675,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The fundamental matrix is a basic tool in the analysis of scenes taken with two uncalibrated cameras, and the eight-point algorithm is a frequently cited method for computing the fundamental matrix from a set of eight or more point matches. It has the advantage of simplicity of implementation. The prevailing view is, however, that it is extremely susceptible to noise and hence virtually useless for most purposes. This paper challenges that view, by showing that by preceding the algorithm with a very simple normalization (translation and scaling) of the coordinates of the matched points, results are obtained comparable with the best iterative algorithms. This improved performance is justified by theory and verified by extensive experiments on real images."
            },
            "slug": "In-Defense-of-the-Eight-Point-Algorithm-Hartley",
            "title": {
                "fragments": [],
                "text": "In Defense of the Eight-Point Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper shows that by preceding the eight-point algorithm with a very simple normalization (translation and scaling) of the coordinates of the matched points, results are obtained comparable with the best iterative algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2404667"
                        ],
                        "name": "C. Strecha",
                        "slug": "C.-Strecha",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Strecha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Strecha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14568994,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b2604a69a97bbd2c7da34a04b75b9f5640d25b6",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes a method for depth extraction from multiple, calibrated images. Emphasis lies on the integration of multiple views during the matching process. This process is guided by the relative confidence that the system has in the data coming from the different views. This weighing is fine-grained in that it is determined for every pixel at every iteration. Reliable information spreads fast at the expense of less reliable data, both in terms of spatial communications and in terms of exchange between views. The resulting system can handle large disparities, depth discontinuities and occlusions. Moreover provisions are made to deal with intensity changes between corresponding pixels. Experimental results corroborate the viability of the approach and the improved results that can be expected from the system's ability to deal with variable intensities."
            },
            "slug": "PDE-based-multi-view-depth-estimation-Strecha-Gool",
            "title": {
                "fragments": [],
                "text": "PDE-based multi-view depth estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A method for depth extraction from multiple, calibrated images with emphasis on the integration of multiple views during the matching process that can handle large disparities, depth discontinuities and occlusions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. First International Symposium on 3D Data Processing Visualization and Transmission"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782918"
                        ],
                        "name": "I. Shimshoni",
                        "slug": "I.-Shimshoni",
                        "structuredName": {
                            "firstName": "Ilan",
                            "lastName": "Shimshoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Shimshoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747801"
                        ],
                        "name": "E. Rivlin",
                        "slug": "E.-Rivlin",
                        "structuredName": {
                            "firstName": "Ehud",
                            "lastName": "Rivlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rivlin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11087835,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "8ef9f6d609c49e9d53e3438009759fc5c992d244",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a geometric interpretation of the problem of motion recovery from three weak-perspective images. Our interpretation is based on reducing the problem of estimating the motion to a problem of finding triangles on a sphere whose angles are known. Using this geometric interpretation, a simple method to completely recover the motion parameters using three images is developed. The results of running the algorithm on real images are presented. In addition, we describe which of the various motion parameters can be recovered already from two images."
            },
            "slug": "A-Geometric-Interpretation-of-Weak-Perspective-Shimshoni-Basri",
            "title": {
                "fragments": [],
                "text": "A Geometric Interpretation of Weak-Perspective Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A simple method to completely recover the motion parameters using three images is developed using a geometric interpretation based on reducing the problem of estimating the motion to a problem of finding triangles on a sphere whose angles are known."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7221785,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f797936661223654d192181f52779bb9b850810c",
            "isKey": false,
            "numCitedBy": 212,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method is presented for robustly estimating multiple view relations from image point correspondences. There are three new contributions, the first is a general purpose method of parametrizing these relations using point correspondences. The second contribution is the formulation of a common Maximum Likelihood Estimate (MLE) for each of the multiple view relations. The parametrization facilitates a constrained optimization to obtain this MLE. The third contribution is a new robust algorithm, MLESAC, for obtaining the point correspondences. The method is general and its use is illustrated for the estimation of fundamental matrices, image to image homographies and quadratic transformations. Results are given for both synthetic and real images. It is demonstrated that the method gives results equal or superior to previous approaches."
            },
            "slug": "Robust-computation-and-parametrization-of-multiple-Torr-Zisserman",
            "title": {
                "fragments": [],
                "text": "Robust computation and parametrization of multiple view relations"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A new method is presented for robustly estimating multiple view relations from image point correspondences and its use is illustrated for the estimation of fundamental matrices, image to image homographies and quadratic transformations."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18830219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec18c9850d5521685bd7c96ae08255a46c4926af",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives a widely applicable technique for solving many of the parameter estimation problems encountered in geometric computer vision. A commonly used approach is to minimize an algebraic error function instead of a possibly preferable geometric error function. It is claimed in this paper that minimizing algebraic error will usually give excellent results, and in fact the main problem with most algorithms minimizing algebraic distance is that they do not take account of mathematical constraints that should be imposed on the quantity being estimated. This paper gives an efficient method of minimizing algebraic distance while taking account of the constraints. This provides new algorithms for the problems of resectioning a pinhole camera, computing the fundamental matrix, and computing the tri-focal tensor. Evaluation results are given for the resectioning and tri-focal tensor estimation algorithms."
            },
            "slug": "Minimizing-algebraic-error-in-geometric-estimation-Hartley",
            "title": {
                "fragments": [],
                "text": "Minimizing algebraic error in geometric estimation problems"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper gives an efficient method of minimizing algebraic distance while taking account of the constraints and provides new algorithms for the problems of resectioning a pinhole camera, computing the fundamental matrix, and computing the tri-focal tensor."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713056"
                        ],
                        "name": "P. Sturm",
                        "slug": "P.-Sturm",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Sturm",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sturm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10083976,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "c9e96b0173b7c915aa3e7f0e175655e7330058e9",
            "isKey": false,
            "numCitedBy": 722,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method for the recovery of projective shape and motion from multiple images of a scene by the factorization of a matrix containing the images of all points in all views. This factorization is only possible when the image points are correctly scaled. The major technical contribution of this paper is a practical method for the recovery of these scalings, using only fundamental matrices and epipoles estimated from the image data. The resulting projective reconstruction algorithm runs quickly and provides accurate reconstructions. Results are presented for simulated and real images."
            },
            "slug": "A-Factorization-Based-Algorithm-for-Multi-Image-and-Sturm-Triggs",
            "title": {
                "fragments": [],
                "text": "A Factorization Based Algorithm for Multi-Image Projective Structure and Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A practical method for the recovery of projective shape and motion from multiple images of a scene by the factorization of a matrix containing the images of all points in all views, using only fundamental matrices and epipoles estimated from the image data."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69944522"
                        ],
                        "name": "Lund UniversityBox",
                        "slug": "Lund-UniversityBox",
                        "structuredName": {
                            "firstName": "Lund",
                            "lastName": "UniversityBox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lund UniversityBox"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18164201,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6eb429915d214ad3b90f474400de847fc2e1bc6c",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a novel method to make reconstruction from any number of uncalibrated cameras is presented. The novelty lies in the fact that the algorithm relies only on subspace methods, which implies that it is independent of the chosen coordinate system in the images. Furthermore , it does not distinguish between the diierent points in each image and can deal with any number of images and points in a uniied manner. Finally, it is possible to obtain a result that is independent on the chosen ordering of the images. The performance of this iterative algorithm is shown on both simulated and real data. In general, for n points in m images, it is suucient to make only 10 iterations, where each iteration involves the calculation of the four eigenvectors corresponding to the largest eigenvalues to an nn matrix and calculations of the eigenvector corresponding to the smallest eigenvalue to m diierent n n matrices."
            },
            "slug": "Projective-Structure-and-Motion-from-Image-Using-UniversityBox",
            "title": {
                "fragments": [],
                "text": "Projective Structure and Motion from Image Sequences Using Subspace Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A novel method to make reconstruction from any number of uncalibrated cameras that relies only on subspace methods, which implies that it is independent of the chosen coordinate system in the images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742208"
                        ],
                        "name": "M. Pollefeys",
                        "slug": "M.-Pollefeys",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Pollefeys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pollefeys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144839904"
                        ],
                        "name": "R. Koch",
                        "slug": "R.-Koch",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2980469,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d0326761a0f3da1394ed710eb1cd436cb822bbab",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a new rectification method is proposed. The method is both simple and efficient and can deal with all possible camera motions. A minimal image size without any pixel loss is guaranteed. The only required information is the oriented fundamental matrix. The whole rectification process is carried out directly in the images. The idea consists of using a polar parametrization of the image around the epipole. The transfer between the images is obtained through the fundamental matrix. The proposed method has important advantages compared to the traditional rectification schemes. In some cases these approaches yield very large images or can not rectify at all. Even the recently proposed cylindrical rectification method can encounter problems in some cases. These problems are mainly due to the fact that the matching ambiguity is not reduced to half epipolar lines. Although this last method is more complex than the one proposed in this paper the resulting images are in general larger. The performance of the new approach is illustrated with some results on real image pairs."
            },
            "slug": "A-simple-and-efficient-rectification-method-for-Pollefeys-Koch",
            "title": {
                "fragments": [],
                "text": "A simple and efficient rectification method for general motion"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A new rectification method is proposed that consists of using a polar parametrization of the image around the epipole to rectify the image and the transfer between the images is obtained through the fundamental matrix."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076817912"
                        ],
                        "name": "P. Pritchett",
                        "slug": "P.-Pritchett",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Pritchett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pritchett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46527015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4da91ba2e80a4d8deb597b1c884cda890f086653",
            "isKey": false,
            "numCitedBy": 351,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically. This facilitates matching between quite disparate views-wide baseline stereo. Two extensions are made to the current small baseline algorithms: first, and most importantly, a viewpoint invariant measure is developed for assessing the affinity of corner neighbourhoods over image pairs; second, algorithms are given for generating putative corner matches between image pairs using local homographies. Two novel infrastructure developments are also described: the automatic generation of local homographies, and the combination of possibly conflicting sets of matches prior to RANSAC estimation. The wide baseline matching algorithm is demonstrated on a number of image pairs with varying relative motion, and for different scene types. All processing is automatic."
            },
            "slug": "Wide-baseline-stereo-matching-Pritchett-Zisserman",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo matching"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically, and to facilitate matching between quite disparate views-wide baseline stereo."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16242306,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "03ce1779bff26648490516eb4c9a13feaaf61f06",
            "isKey": false,
            "numCitedBy": 303,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "In the general case, a trilinear relationship between three perspective views is shown to exist. The trilinearity result is shown to be of much practical use in visual recognition by alignment-yielding a direct reprojection method that cuts through the computations of camera transformation, scene structure and epipolar geometry. Moreover, the direct method is linear and sets a new lower theoretical bound on the minimal number of points that are required for a linear solution for the task of reprojection. The proof of the central result may be of further interest as it demonstrates certain regularities across homographics of the plane and introduces new view invariants. Experiments on simulated and real image data were conducted, including a comparative analysis with epipolar intersection and the linear combination methods, with results indicating a greater degree of robustness in practice and a higher level of performance in reprojection tasks. >"
            },
            "slug": "Algebraic-Functions-For-Recognition-Shashua",
            "title": {
                "fragments": [],
                "text": "Algebraic Functions For Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The trilinearity result is shown to be of much practical use in visual recognition by alignment-yielding a direct reprojection method that cuts through the computations of camera transformation, scene structure and epipolar geometry."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145246674"
                        ],
                        "name": "A. Heyden",
                        "slug": "A.-Heyden",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Heyden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Heyden"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7789642,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cc7b012ff75cf72d4dbf1df21d25ad742c87c329",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper deals with the problem of reconstructing the locations of n points in space from m different images without camera calibration. It shows how these problems can be put into a similar theoretical framework.A new concept, the reduced fundamental matrix, is introduced. It contains just 4 parameters and can be used to predict locations of points in the images and to make reconstruction. We also introduce the concept of reduced fundamental tensor, which describes the relations between points in 3 images. It has 15 components and depends on 9 parameters. Necessary and sufficient conditions for a tensor to be a reduced fundamental tensor are derived. This framework can be generalised to a sequence of images. The dependencies between the different representations are investigated. Furthermore a canonical form of the camera matrices in a sequence are presented."
            },
            "slug": "Reconstruction-from-Image-Sequences-by-Means-of-Heyden",
            "title": {
                "fragments": [],
                "text": "Reconstruction from Image Sequences by Means of Relative Depths"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "The paper shows how the problems of reconstructing the locations of n points in space from m different images without camera calibration can be put into a similar theoretical framework and a new concept, the reduced fundamental matrix, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7004756,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "196a6e6c0cc5084e26d33e52833a052807d1187e",
            "isKey": false,
            "numCitedBy": 697,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers, the determination of internal camera parameters from two views of a point set in three dimensions. A non-iterative algorithm is given for determining the focal lengths of the two cameras, as well as their relative placement, assuming all other internal camera parameters to be known. It is shown that this is all the information that may be deduced from a set of image correspondences."
            },
            "slug": "Estimation-of-Relative-Camera-Positions-for-Cameras-Hartley",
            "title": {
                "fragments": [],
                "text": "Estimation of Relative Camera Positions for Uncalibrated Cameras"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A non-iterative algorithm is given for determining the focal lengths of the two cameras, as well as their relative placement, assuming all other internal camera parameters to be known."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92269846"
                        ],
                        "name": "H. C. Longuet-Higgins",
                        "slug": "H.-C.-Longuet-Higgins",
                        "structuredName": {
                            "firstName": "Hugh",
                            "lastName": "Longuet-Higgins",
                            "middleNames": [
                                "Christopher"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. C. Longuet-Higgins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4327732,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d7730295185f1e98ef087525e2dc1518114a9306",
            "isKey": false,
            "numCitedBy": 2681,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A simple algorithm for computing the three-dimensional structure of a scene from a correlated pair of perspective projections is described here, when the spatial relationship between the two projections is unknown. This problem is relevant not only to photographic surveying1 but also to binocular vision2, where the non-visual information available to the observer about the orientation and focal length of each eye is much less accurate than the optical information supplied by the retinal images themselves. The problem also arises in monocular perception of motion3, where the two projections represent views which are separated in time as well as space. As Marr and Poggio4 have noted, the fusing of two images to produce a three-dimensional percept involves two distinct processes: the establishment of a 1:1 correspondence between image points in the two views\u2014the \u2018correspondence problem\u2019\u2014and the use of the associated disparities for determining the distances of visible elements in the scene. I shall assume that the correspondence problem has been solved; the problem of reconstructing the scene then reduces to that of finding the relative orientation of the two viewpoints."
            },
            "slug": "A-computer-algorithm-for-reconstructing-a-scene-two-Longuet-Higgins",
            "title": {
                "fragments": [],
                "text": "A computer algorithm for reconstructing a scene from two projections"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A simple algorithm for computing the three-dimensional structure of a scene from a correlated pair of perspective projections is described here, when the spatial relationship between the two projections is unknown."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144555237"
                        ],
                        "name": "S. Maybank",
                        "slug": "S.-Maybank",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Maybank",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maybank"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206636383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80d088324bf9326815b50496fed3cd401572cbff",
            "isKey": false,
            "numCitedBy": 1059,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of finding the internal orientation of a camera (camera calibration) is extremely important for practical applications. In this paper a complete method for calibrating a camera is presented. In contrast with existing methods it does not require a calibration object with a known 3D shape. The new method requires only point matches from image sequences. It is shown, using experiments with noisy data, that it is possible to calibrate a camera just by pointing it at the environment, selecting points of interest and then tracking them in the image as the camera moves. It is not necessary to know the camera motion."
            },
            "slug": "Camera-Self-Calibration:-Theory-and-Experiments-Faugeras-Luong",
            "title": {
                "fragments": [],
                "text": "Camera Self-Calibration: Theory and Experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown, using experiments with noisy data, that it is possible to calibrate a camera just by pointing it at the environment, selecting points of interest and then tracking them in the image as the camera moves."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145093203"
                        ],
                        "name": "G. Cross",
                        "slug": "G.-Cross",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Cross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11311367,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f732c8e8c8faa8cfb2b237e32660cc3e2fe08dbf",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the multiple view geometry of smooth surfaces and a plane, where the plane provides a planar homography mapping between the views. Innovations are made in three areas: first, new solutions are given for the computation of epipolar and trifocal geometry for this type of scene. In particular it is shown that the epipole may be determined from bitangents between the homography registered occluding contours, and a new minimal solution is given for computing the trifocal tensor: Second, algorithms are demonstrated for automatically estimating the fundamental matrix and trifocal tensor from images of such scenes. Third, a method is developed for estimating camera matrices for a sequence of images of these scenes. These three areas are combined in a \"freehand scanner\" application where 3D texture-mapped graphical models of smooth objects are acquired directly from a video sequence of the object and plane."
            },
            "slug": "Parallax-geometry-of-smooth-surfaces-in-multiple-Cross-Fitzgibbon",
            "title": {
                "fragments": [],
                "text": "Parallax geometry of smooth surfaces in multiple views"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "This paper investigates the multiple view geometry of smooth surfaces and a plane, where the plane provides a planar homography mapping between the views, and new solutions are given for the computation of epipolar and trifocal geometry for this type of scene."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878635"
                        ],
                        "name": "Tom\u00e1\u0161 Werner",
                        "slug": "Tom\u00e1\u0161-Werner",
                        "structuredName": {
                            "firstName": "Tom\u00e1\u0161",
                            "lastName": "Werner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom\u00e1\u0161 Werner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758039"
                        ],
                        "name": "T. Pajdla",
                        "slug": "T.-Pajdla",
                        "structuredName": {
                            "firstName": "Tom\u00e1s",
                            "lastName": "Pajdla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pajdla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10464923,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "aace56678aa918a5c6bdb9269424cf22e8d322a2",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Well-known matching constraints for points and lines in muliple images are necessary but not sufficient condition for the existence of real structure and cameras, underlying the image correspondences. To obtain sufficient conditions, the following additional constraints must be imposed: positive scales, the existence of a plane at infinity not intersecting the scene, and the existence of handedness preserving cameras. We present modifications of the well-known matching constraints and also some new constraints, taking into account some of this additional knowledge. Not only conventional but also central panoramic cameras are naturally described. To achieve this, we have generalized and simplified Hartley\u2019s ch(e)irality theory by formulating it in the language of oriented projective geometry and Grassmann tensors."
            },
            "slug": "Oriented-Matching-Constraints-Werner-Pajdla",
            "title": {
                "fragments": [],
                "text": "Oriented Matching Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Hartley\u2019s ch(e)irality theory is generalized and simplified by formulating it in the language of oriented projective geometry and Grassmann tensors to obtain sufficient conditions for the existence of real structure and cameras."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713563"
                        ],
                        "name": "F. Kahl",
                        "slug": "F.-Kahl",
                        "structuredName": {
                            "firstName": "Fredrik",
                            "lastName": "Kahl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145246674"
                        ],
                        "name": "A. Heyden",
                        "slug": "A.-Heyden",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Heyden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Heyden"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40660670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "559185e42c3b822b6bc940fdf9bab91443d26025",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present an integrated approach that solves the structure and motion problem for affine cameras. Given images of corresponding points, lines and conics in any number of views, a reconstruction of the scene structure and the camera motion is calculated, up to an affine transformation. Starting with three views, two novel concepts are introduced. The first one is a quasi-tensor consisting of 20 components and the second one is another quasitensor consisting of 12 components. These tensors describe the viewing geometry for three views taken by an affine camera. It is shown how correspondences of points, lines and conics can be used to constrain the tensor components. A set of affine camera matrices compatible with the quasi-tensors can easily be calculated from the tensor components. The resulting camera matrices serve as an initial guess in a factorisation method, using points, lines and conics concurrently, generalizing the well-known factorisation method by Tomasi-Kanade. Finally, examples are given that illustrate the developed methods on both simulated and real data."
            },
            "slug": "Structure-and-Motion-from-Points,-Lines-and-Conics-Kahl-Heyden",
            "title": {
                "fragments": [],
                "text": "Structure and Motion from Points, Lines and Conics with Affine Cameras"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An integrated approach that solves the structure and motion problem for affine cameras, using points, lines and conics concurrently, generalizing the well-known factorisation method by Tomasi-Kanade."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713563"
                        ],
                        "name": "F. Kahl",
                        "slug": "F.-Kahl",
                        "structuredName": {
                            "firstName": "Fredrik",
                            "lastName": "Kahl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145246674"
                        ],
                        "name": "A. Heyden",
                        "slug": "A.-Heyden",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Heyden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Heyden"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14456610,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "442eb8934dd9b27c84a6814d2fd3d122f83c8472",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper it is shown hour corresponding conics in two images can be used to estimate the epipolar geometry in terms of the fundamental/essential matrix. The corresponding conics can, be images of either planar celtics or silhouettes of quadrics. It is shown that one conic correspondence gives two independent constraints on the fundamental matrix and a method to estimate the fundamental matrix from at least four corresponding conics is presented. Furthermore, a new type of fundamental matrix for describing conic correspondences is introduced. Finally, it is shown that the problem of estimating the fundamental matrix from 5 point correspondences and 1 conic correspondence in general has 10 different solutions. A method to calculate these solutions is also given together with an experimental validation."
            },
            "slug": "Using-conic-correspondences-in-two-images-to-the-Kahl-Heyden",
            "title": {
                "fragments": [],
                "text": "Using conic correspondences in two images to estimate the epipolar geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "It is shown that the corresponding conics in two images can be used to estimate the epipolar geometry in terms of the fundamental/essential matrix and a new type of fundamental matrix for describing conic correspondences is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14791448,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d13ea495aef1744f38802ef76791c3fec1bdb914",
            "isKey": false,
            "numCitedBy": 306,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a family of factorization-based algorithms that recover 3D projective structure and motion from multiple uncalibrated perspective images of 3D points and lines. They can be viewed as generalizations of the Tomasi-Kanade algorithm from affine to fully perspective cameras, and from points to lines. They make no restrictive assumptions about scene or camera geometry, and unlike most existing reconstruction methods they do not rely on 'privileged' points or images. All of the available image data is used, and each feature in each image is treated uniformly. The key to projective factorization is the recovery of a consistent set of projective depths (scale factors) for the image points: this is done using fundamental matrices and epipoles estimated from the image data. We compare the performance of the new techniques with several existing ones, and also describe an approximate factorization method that gives similar results to SVD-based factorization, but runs much more quickly for large problems."
            },
            "slug": "Factorization-methods-for-projective-structure-and-Triggs",
            "title": {
                "fragments": [],
                "text": "Factorization methods for projective structure and motion"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This paper describes a family of factorization-based algorithms that recover 3D projective structure and motion from multiple uncalibrated perspective images of 3D points and lines that can be viewed as generalizations of the Tomasi-Kanade algorithm from affine to fully perspective cameras, and from points to lines."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144199437"
                        ],
                        "name": "D. Huynh",
                        "slug": "D.-Huynh",
                        "structuredName": {
                            "firstName": "Du",
                            "lastName": "Huynh",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huynh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145246674"
                        ],
                        "name": "A. Heyden",
                        "slug": "A.-Heyden",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Heyden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Heyden"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18868897,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce2b31e2651b961d842fe89b59da2ec5067e1c78",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "It is widely known that, for the affine camera model, both shape and motion can be factorized directly from the so-called image measurement matrix constructed from image point coordinates. The ability to extract both shape and motion from this matrix by a single SVD operation makes this shape-from-motion approach attractive; however, it can not deal with missing feature points and, in the presence of outliers, a direct SVD to the matrix would yield highly unreliable shape and motion components. Here, we present an outlier correction scheme that iteratively updates the elements of the image measurement matrix. The magnitude and sign of the update to each element is dependent upon the residual robustly estimated in each iteration. The result is that outliers are corrected and retained, giving improved reconstruction and smaller reprojection errors. Our iterative outlier correction scheme has been applied to both synthesized and real video sequences. The results obtained are remarkably good."
            },
            "slug": "Outlier-correction-in-image-sequences-for-the-Huynh-Hartley",
            "title": {
                "fragments": [],
                "text": "Outlier correction in image sequences for the affine camera"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work presents an outlier correction scheme that iteratively updates the elements of the image measurement matrix, with the result that outliers are corrected and retained, giving improved reconstruction and smaller reprojection errors."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144555237"
                        ],
                        "name": "S. Maybank",
                        "slug": "S.-Maybank",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Maybank",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maybank"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12083884,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ade62d806dccfb3e8ad1cda891db8805db5531ca",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss briefly a number of areas where epipolar geometry is currently central in carrying out visual tasks. In contrast we demonstrate configurations for which 3D projective invariants can be computed from perspective stereo pairs, but epipolar geometry (and full projective structure) cannot. We catalogue a number of these configurations which generally involve isotropies under the 3D projective group, and investigate the connection with camera calibration. Examples are given of the invariants recovered from real images. We also indicate other areas where a strong reliance on epipolar geometry should be avoided, in particular for image transfer."
            },
            "slug": "A-Case-Against-Epipolar-Geometry-Zisserman-Maybank",
            "title": {
                "fragments": [],
                "text": "A Case Against Epipolar Geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "It is demonstrated configurations for which 3D projective invariants can be computed from perspective stereo pairs, but epipolar geometry (and full projective structure) cannot, and the connection with camera calibration is investigated."
            },
            "venue": {
                "fragments": [],
                "text": "Applications of Invariance in Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2718434"
                        ],
                        "name": "S. Christy",
                        "slug": "S.-Christy",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Christy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Christy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794229"
                        ],
                        "name": "R. Horaud",
                        "slug": "R.-Horaud",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Horaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Horaud"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2103274,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d673013620f48591169237a5262a7af318be4ecb",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for solving the Euclidean reconstruction problem with a perspective camera model by incrementally performing Euclidean reconstruction with either a weak or a paraperspective camera model. With respect to other methods that compute shape and motion from a sequence of images with a calibrated camera, this method converges in a few iterations, is computationally efficient, and solves for the sign (reversal) ambiguity. We give a detailed account of the method, analyze its convergence, and test it with both synthetic and real data."
            },
            "slug": "Euclidean-Shape-and-Motion-from-Multiple-Views-by-Christy-Horaud",
            "title": {
                "fragments": [],
                "text": "Euclidean Shape and Motion from Multiple Perspective Views by Affine Iterations"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A method for solving the Euclidean reconstruction problem with a perspective camera model by incrementally performing Euclideans reconstruction with either a weak or a paraperspective camera model that converges in a few iterations, is computationally efficient, and solves for the sign (reversal) ambiguity."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51064498"
                        ],
                        "name": "Zhengyou Zhang",
                        "slug": "Zhengyou-Zhang",
                        "structuredName": {
                            "firstName": "Zhengyou",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengyou Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1150626,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "6bdacaf992b0394cc73ff94fcbf6b31483406286",
            "isKey": false,
            "numCitedBy": 11606,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a flexible technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use."
            },
            "slug": "A-Flexible-New-Technique-for-Camera-Calibration-Zhang",
            "title": {
                "fragments": [],
                "text": "A Flexible New Technique for Camera Calibration"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A flexible technique to easily calibrate a camera that only requires the camera to observe a planar pattern shown at a few (at least two) different orientations is proposed and advances 3D computer vision one more step from laboratory environments to real world use."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7625742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3b2c316a2d89d2e38263de87bdb0738404d2214",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents a new method for matching individual line segments between images. The method uses both grey-level information and the multiple view geometric relations between the images. For image pairs epipolar geometry facilitates the computation of a cross-correlation based matching score for putative line correspondences. For image triplets cross-correlation matching scores are used in conjunction with line transfer based on the trifocal geometry. Algorithms are developed for both short and long range motion. In the case of long range motion the algorithm involves evaluating a one parameter family of plane induced homographies. The algorithms are robust to deficiencies in the line segment extraction and partial occlusion. Experimental results are given for image pairs and triplets, for varying motions between views, and for different scene types. The three view algorithm eliminates all mismatches."
            },
            "slug": "Automatic-line-matching-across-views-Schmid-Zisserman",
            "title": {
                "fragments": [],
                "text": "Automatic line matching across views"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The paper presents a new method for matching individual line segments between images that uses both grey-level information and the multiple view geometric relations between the images and eliminates all mismatches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2556432"
                        ],
                        "name": "St\u00e9phane Laveau",
                        "slug": "St\u00e9phane-Laveau",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Laveau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "St\u00e9phane Laveau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70306555"
                        ],
                        "name": "L. Robert",
                        "slug": "L.-Robert",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Robert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Robert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69931662"
                        ],
                        "name": "Gabriella Csurka",
                        "slug": "Gabriella-Csurka",
                        "structuredName": {
                            "firstName": "Gabriella",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabriella Csurka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2788557"
                        ],
                        "name": "C. Zeller",
                        "slug": "C.-Zeller",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Zeller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Zeller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17184226,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ca64673a4d170de9f381528e9433a0048876ebce",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of the recovery of the Euclidean geometry of a scene from a sequence of images without any prior knowledge either about the parameters of the cameras, or about the motion of the cam-era(s). We do not require any knowledge of the absolute coordinates of some control points in the scene to achieve this goal. Using various computer vision tools, we establish correspondences between images and recover the epipolar geometry of the set of images, from which we show how to compute the complete set of perspective projection matrices for each camera position. These being known, we proceed to reconstruct the scene. This reconstruction is defined up to an unknown projective transformation (i.e. is parameterized with 15 arbitrary parameters). Next we show how to go from this reconstruction to a more constrained class of reconstructions, defined up to an unknown affine transformation (i.e. parameterized with 12 arbitrary parameters) by exploiting known geometric relations between features in the scene such as parallelism. Finally, we show how to go from this reconstruction to another class, defined up to an unknown similitude (i.e. parameterized with 7 arbitrary parameters). This means that in an Euclidean frame attached to the scene or to one of the cameras, the reconstruction depends only upon one parameter, the global scale. This parameter is easily fixed as soon as one absolute length measurement is known. We see this vision system as a building block, a vision server, of a CAD system that is used by a human to model a scene for such applications as simulation, virtual or augmented reality. We believe that such a system can save a lot of tedious work to the human observer as well as play a leading role in keeping the geometric data base accurate and coherent."
            },
            "slug": "3-D-Reconstruction-of-Urban-Scenes-from-Sequences-Faugeras-Laveau",
            "title": {
                "fragments": [],
                "text": "3-D Reconstruction of Urban Scenes from Sequences of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper addresses the problem of the recovery of the Euclidean geometry of a scene from a sequence of images without any prior knowledge either about the parameters of the cameras, or about the motion of the cam-era(s)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790502"
                        ],
                        "name": "T. Vi\u00e9ville",
                        "slug": "T.-Vi\u00e9ville",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Vi\u00e9ville",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vi\u00e9ville"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 744111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a50cacd9cce40ebaa3f8d53159cbdc4a12b39c7",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "This work is in the context of motion and stereo analysis. It presents a new unified representation which will be useful when dealing with multiple views in the case of uncalibrated cameras. Several levels of information might be considered, depending on the availability of information. Among other things, an algebraic description of the epipolar geometry ofNviews is introduced, as well as a framework for camera self-calibration, calibration updating, and structure from motion in an image sequence taken by a camera which is zooming and moving at the same time. We show how a special decomposition of a set of two or three general projection matrices, calledcanonical, enables us to build geometric descriptions for a system of cameras which are invariant with respect to a given group of transformations. These representations are minimal and capture completely the properties of each level of description considered, Euclidean (in the context of calibration, and in the context of structure from motion, which we distinguish clearly), affine, and projective, that we also relate to each other. In the last case, a new decomposition of the well-knownfundamental matrixis obtained. Dependencies, which appear when three or more views are available, are studied in the context of the canonic decomposition, and new composition formulas are established. The theory is illustrated by tutorial examples with real images."
            },
            "slug": "Canonical-Representations-for-the-Geometries-of-Luong-Vi\u00e9ville",
            "title": {
                "fragments": [],
                "text": "Canonical Representations for the Geometries of Multiple Projective Views"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This work presents a new unified representation which will be useful when dealing with multiple views in the case of uncalibrated cameras, and shows how a special decomposition of a set of two or three general projection matrices, called canonic, enables us to build geometric descriptions for a system of cameras which are invariant with respect to a given group of transformations."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18656431,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a94f6e4e6488583ae5dca295298ef3e2044dc5db",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In the eight-point linear algorithm for determining 3D motion/structure from two perspective views using point correspondences, the E matrix plays a central role. The E matrix is defined as a skew-symmetrical matrix (containing the translation components) postmultiplied by a rotation matrix. The authors show that a necessary and sufficient condition for a 3*3 matrix to be so decomposable is that one of its singular values is zero and the other two are equal. Several other forms of this property are presented. Some applications are briefly described. >"
            },
            "slug": "Some-Properties-of-the-E-Matrix-in-Two-View-Motion-Huang-Faugeras",
            "title": {
                "fragments": [],
                "text": "Some Properties of the E Matrix in Two-View Motion Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The authors show that a necessary and sufficient condition for a 3*3 matrix to be so decomposable is that one of its singular values is zero and the other two are equal."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14393936,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "897504ed2c187f962f2557072b2929ef99b4b53f",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives a practical and accurate algorithm for the computation of the quadrifocal tensor and extraction of camera matrices from it. Previous methods for using the quadrifocal tensor in projective scene reconstruction have not emphasized accuracy of the algorithm in conditions of noise. Methods given in this paper minimize algebraic error either through a non-iterative linear algorithm, or two alternative iterative algorithms. It is shown by experiments with synthetic data that the iterative methods, though minimizing algebraic, rather than more correctly geometric error measured in the image, give almost optimal results."
            },
            "slug": "Computation-of-the-Quadrifocal-Tensor-Hartley",
            "title": {
                "fragments": [],
                "text": "Computation of the Quadrifocal Tensor"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown by experiments with synthetic data that the iterative methods, though minimizing algebraic error, rather than more correctly geometric error measured in the image, give almost optimal results."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145093203"
                        ],
                        "name": "G. Cross",
                        "slug": "G.-Cross",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Cross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9663967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75208455ecd784a5c4601c8cf7e558cc63b6f491",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "As virtual worlds demand ever more realistic 3D models, attention is being focussed on systems that can acquire graphical models from real objects. This paper describes a system which, given a sequence of images of an object rotating about a single axis, generates a textured 3D model fully automatically. In contrast to previous approaches, the technique described here requires no prior information about the cameras or scene, and does not require that the turntable angles be known (or even constant through the sequence). \n \nFrom an analysis ofthe projective geometry of the situation, it is shown that the rotation angles may be determined unambiguously, and that camera calibration, camera positions and 3D structure may be determined to within a two parameter family. An algorithm has been implemented to compute this reconstruction fully automatically. The two parameter reconstruction ambiguity may be removed by specifying, for example, camera aspect ratio and parallel scene lines. Examples are presented on four turn-table sequences."
            },
            "slug": "Automatic-3D-Model-Construction-for-Turn-Table-Fitzgibbon-Cross",
            "title": {
                "fragments": [],
                "text": "Automatic 3D Model Construction for Turn-Table Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A system which, given a sequence of images of an object rotating about a single axis, generates a textured 3D model fully automatically, and requires no prior information about the cameras or scene, and does not require that the turntable angles be known."
            },
            "venue": {
                "fragments": [],
                "text": "SMILE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36153647"
                        ],
                        "name": "M. Agrawal",
                        "slug": "M.-Agrawal",
                        "structuredName": {
                            "firstName": "Motilal",
                            "lastName": "Agrawal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Agrawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16606111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d16205ac5754f57d288a866d5a5bf8107936df1",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Camera calibration is a fundamental problem in computer vision and photogrammetry. We present a new algorithm to calibrate cameras using spheres. In general, an occluding contour of a sphere projects to an ellipse in the image. Our algorithm uses the projection of the occluding contours of three spheres and solves for the intrinsic parameters and the locations of the spheres. The problem is formulated in the dual space and the parameters are solved for optimally and efficiently using semi-definite programming. The technique is flexible, accurate and easy to use. In addition, it can be used to simultaneously calibrate multiple cameras with a common field of view. Experimental results from computer simulated data and real world data, both for a single camera and multiple cameras, are presented."
            },
            "slug": "Complete-camera-calibration-using-spheres-:-A-Agrawal-Davis",
            "title": {
                "fragments": [],
                "text": "Complete camera calibration using spheres : A dual-space approach"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A new algorithm to calibrate cameras using spheres is presented, which uses the projection of the occluding contours of three spheres and solves for the intrinsic parameters and the locations of the spheres."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143685110"
                        ],
                        "name": "W. Wolfe",
                        "slug": "W.-Wolfe",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Wolfe",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wolfe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2362152"
                        ],
                        "name": "Donald W. Mathis",
                        "slug": "Donald-W.-Mathis",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Mathis",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald W. Mathis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405514016"
                        ],
                        "name": "Cheryl Weber-Sklair",
                        "slug": "Cheryl-Weber-Sklair",
                        "structuredName": {
                            "firstName": "Cheryl",
                            "lastName": "Weber-Sklair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheryl Weber-Sklair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16339756"
                        ],
                        "name": "M. Magee",
                        "slug": "M.-Magee",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Magee",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Magee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41446148,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "11fc6533dab3a4f08ffd05aed2f4deabc15ca441",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The perspective view of three noncollinear points whose image-to-object correspondence is known is studied. Such measurements are known to be ambiguous, resulting in as many as four possible solutions to the perspective three-point problem. Although there can be four solutions, it is quite often the case that there are triangle configurations that cause one, two, three, or four solutions. The results also provide a justification for the common wisdom that there are usually two solutions. >"
            },
            "slug": "The-Perspective-View-of-Three-Points-Wolfe-Mathis",
            "title": {
                "fragments": [],
                "text": "The Perspective View of Three Points"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "The perspective view of three noncollinear points whose image-to-object correspondence is known is studied and provides a justification for the common wisdom that there are usually two solutions to the perspective three-point problem."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70306555"
                        ],
                        "name": "L. Robert",
                        "slug": "L.-Robert",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Robert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Robert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 33630527,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "65c30b1185dc6098717db21c1e482d79baad4921",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors show some very recent results using the weak-calibration idea. Assuming that only the epipolar geometry is known of a pair of stereo images, encoded in the so-called fundamental matrix, it is shown that some useful three-dimensional information such as relative positions of points and planes and 3-D convex hulls can be computed. The notion of visibility is introduced, which allows deriving those properties. Results of both synthetic and real data are shown.<<ETX>>"
            },
            "slug": "Relative-3D-positioning-and-3D-convex-hull-from-a-Robert-Faugeras",
            "title": {
                "fragments": [],
                "text": "Relative 3D positioning and 3D convex hull computation from a weakly calibrated stereo pair"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is shown that some useful and intuitive three-dimensional information, such as relative positions of points and planes and 3D convex hulls, can be computed in the images without performing any three- dimensional reconstruction."
            },
            "venue": {
                "fragments": [],
                "text": "1993 (4th) International Conference on Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864114"
                        ],
                        "name": "N. Y. Dano",
                        "slug": "N.-Y.-Dano",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Dano",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Y. Dano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8569298,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4a81367344535a6180b8a545d982354ff3386eb0",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is given for computing projective structure from a set of six points seen in a sequence of many images. The method is based on the notion of duality between cameras and points first pointed out by Carlsson and Weinshall. The current implementation avoids the weakness inherent in previous implementations of this method in which numerical accuracy is compromised by the distortion of image point error distributions under projective transformation. It is shown in this paper that one may compute the dual fundamental matrix by minimizing a cost function giving a first-order approximation to geometric distance error in the original untransformed image measurements. This is done by a modification of a standard near-optimal method for computing the fundamental matrix. Subsequently, the error measurements are adjusted optimally to conform with exact imaging geometry by application of the triangulation method of Hartley-Sturm."
            },
            "slug": "Reconstruction-from-six-point-sequences-Hartley-Dano",
            "title": {
                "fragments": [],
                "text": "Reconstruction from six-point sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown in this paper that one may compute the dual fundamental matrix by minimizing a cost function giving a first-order approximation to geometric distance error in the original untransformed image measurements."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7530813,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "57c5a58a84667dc687838717a2c4a0cd5f7c89ba",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies the geometry of perspective projection into multiple images and the matching constraints that this induces between the images. The combined projections produce a 3D subspace of the space of combined image coordinates called the joint image. This is a complete projective replica of the 3D world defined entirely in terms of image coordinates, up to an arbitrary choice of certain scale factors. Projective reconstruction is a canonical process in the joint image requiring only the rescaling of image coordinates. The matching constraints tell whether a set of image points is the projection of a single world point. In 3D there are only three types of matching constraint: the fundamental matrix, Shashua's trilinear tensor, and a new quadrilinear 4 image tensor. All of these fit into a single geometric object, the joint image Grassmannian tensor. This encodes exactly the information needed for reconstruction: the location of the joint image in the space of combined image coordinates."
            },
            "slug": "The-Geometry-of-Projective-Reconstruction-I:-and-Triggs",
            "title": {
                "fragments": [],
                "text": "The Geometry of Projective Reconstruction I: Matching Constraints and the Joint Image"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122841655,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9797742db492a512dfd381db4cacb794707d7c81",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "A conceptual framework is provided in which to think of the relationships between the three-dimensional structure of physical space and the geometric properties of a set of cameras that provide pictures from which measurements can be made. We usually think of physical space as being embedded in a three-dimensional Euclidean space, in which measurements of lengths and angles do make sense. It turns out that for artificial systems, such as robots, this is not a mandatory viewpoint and that it is sometimes sufficient to think of physical space as being embedded in an affine or even a projective space. The question then arises of how to relate these models to image measurements and to geometric properties of sets of cameras. It is shown that, in the case of two cameras, a stereo rig, the projective structure of the world can be recovered as soon as the epipolar geometry of the stereo rig is known and that this geometry is summarized by a single 3 \u00d7 3 matrix, which is called the fundamental matrix. The affine structure can then be recovered if to this information is added a projective transformation between the two images that is induced by the plane at infinity. Finally, the Euclidean structure (up to a similitude) can be recovered if to these two elements is added the knowledge of two conics (one for each camera) that are the images of the absolute conic, a circle of radius -1 in the plane at infinity. In all three cases it is shown how the three-dimensional information can be recovered directly from the images without explicit reconstruction of the scene structure. This defines a natural hierarchy of geometric structures, a set of three strata that is overlaid upon the physical world and that is shown to be recoverable by simple procedures that rely on two items, the physical space itself together with possibly, but not necessarily, some a priori information about it, and some voluntary motions of the set of cameras."
            },
            "slug": "Stratification-of-three-dimensional-vision:-affine,-Faugeras",
            "title": {
                "fragments": [],
                "text": "Stratification of three-dimensional vision: projective, affine, and metric representations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "93596028"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Heung-yeung",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207211698,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44cdc67c183e33fee698228ead2bfdc118f34c35",
            "isKey": false,
            "numCitedBy": 972,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach to creating full view panoramic mosaics from image sequences. Unlike current panoramic stitching methods, which usually require pure horizontal camera panning, our system does not require any controlled motions or constraints on how the images are taken (as long as there is no strong motion parallax). For example, images taken from a hand-held digital camera can be stitched seamlessly into panoramic mosaics. Because we represent our image mosaics using a set of transforms, there are no singularity problems such as those existing at the top and bottom of cylindrical or spherical maps. Our algorithm is fast and robust because it directly recovers 3D rotations instead of general 8 parameter planar perspective transforms. Methods to recover camera focal length are also presented. We also present an algorithm for efficiently extracting environment maps from our image mosaics. By mapping the mosaic onto an artibrary texture-mapped polyhedron surrounding the origin, we can explore the virtual environment using standard 3D graphics viewers and hardware without requiring special-purpose players. CR"
            },
            "slug": "Creating-full-view-panoramic-image-mosaics-and-maps-Szeliski-Shum",
            "title": {
                "fragments": [],
                "text": "Creating full view panoramic image mosaics and environment maps"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper presents a novel approach to creating full view panoramic mosaics from image sequences that does not require any controlled motions or constraints on how the images are taken (as long as there is no strong motion parallax)."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 439654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b55c7955e92dc09da0fd9b7ffd5820969fa7819",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a linear algorithm for the simultaneous computation of 3D points and camera positions from multiple perspective views, based on having four points on a reference plane visible in all views. The reconstruction and camera recovery is achieved, in a single step, by finding the null-space of a matrix using singular value decomposition. Unlike factorization algorithms, the presented algorithm does not require all points to be visible in all views. By simultaneously reconstructing points and views the numerically stabilizing effect of having wide spread cameras with large mutual baselines is exploited. Experimental results are presented for both finite and infinite reference planes. An especially interesting application of this method is the reconstruction of architectural scenes with the reference plane taken as the plane at infinity which is visible via three orthogonal vanishing points. This is demonstrated by reconstructing the outside and inside (courtyard) of a building on the basis of 35 views in one single SVD."
            },
            "slug": "Linear-multi-view-reconstruction-and-camera-Rother-Carlsson",
            "title": {
                "fragments": [],
                "text": "Linear multi view reconstruction and camera recovery"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A linear algorithm for the simultaneous computation of 3D points and camera positions from multiple perspective views, based on having four points on a reference plane visible in all views, which is demonstrated by reconstructing the outside and inside of a building on the basis of 35 views in one single SVD."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1025787,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f4f924aa7c29557953990da770db466722a109b7",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A new practical method is given for the self-calibration of a camera. In this method, at least three images are taken from the same point in space with different orientations of the camera and calibration is computed from an analysis of point matches between the images. The method requires no knowledge of the orientations of the camera. Calibration is based on the image correspondences only. This method differs fundamentally from previous results by Maybank and Faugeras on selfcalibration using the epipolar structure of image pairs. In the method of this paper, there is no epipolar structure since all images are taken from the same point in space. Since the images are all taken from the same point in space, determination of point matches is considerably easier than for images taken with a moving camera, since problems of occlusion or change of aspect or illumination do not occur. The calibration method is evaluated on several sets of synthetic and real image data."
            },
            "slug": "Self-Calibration-from-Multiple-Views-with-a-Camera-Hartley",
            "title": {
                "fragments": [],
                "text": "Self-Calibration from Multiple Views with a Rotating Camera"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "There is no epipolar structure since all images are taken from the same point in space and determination of point matches is considerably easier than for images taken with a moving camera, since problems of occlusion or change of aspect or illumination do not occur."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3377447"
                        ],
                        "name": "L. Agapito",
                        "slug": "L.-Agapito",
                        "structuredName": {
                            "firstName": "Lourdes",
                            "lastName": "Agapito",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Agapito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2901127"
                        ],
                        "name": "E. Hayman",
                        "slug": "E.-Hayman",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Hayman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hayman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950884"
                        ],
                        "name": "I. Reid",
                        "slug": "I.-Reid",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Reid",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Reid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1135461,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "89c496bd9fa02dc51f1140c9cb95a54114d2c596",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for self-calibration of a camera which is free to rotate and change its intrinsic parameters, but which cannot translate. The method is based on the so-called infinite homography constraint which leads to a non-linear minimisation routine to find the unknown camera intrinsics over an extended sequence of images. We give experimental results using real image sequences for which ground truth data was available."
            },
            "slug": "Self-Calibration-of-a-Rotating-Camera-with-Varying-Agapito-Hayman",
            "title": {
                "fragments": [],
                "text": "Self-Calibration of a Rotating Camera with Varying Intrinsic Parameters"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work presents a method for self-calibration of a camera which is free to rotate and change its intrinsic parameters, but which cannot translate and gives experimental results using real image sequences for which ground truth data was available."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790502"
                        ],
                        "name": "T. Vi\u00e9ville",
                        "slug": "T.-Vi\u00e9ville",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Vi\u00e9ville",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vi\u00e9ville"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 24907759,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "db28ea00e4b6c0c81b905bc8bf02f70deac7efe7",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how a special decomposition of general projection matrices, called canonic enables us to build geometric descriptions for a system of cameras which are invariant with respect to a given group of transformations. These representations are minimal and capture completely the properties of each level of description considered: Euclidean (in the context of calibration, and in the context of structure from motion, which we distinguish clearly), affine, and projective, that we also relate to each other. In the last case, a new decomposition of the well-known fundamental matrix is obtained. Dependencies, which appear when three or more views are available, are studied in the context of the canonic decomposition, and new composition formulas are established, as well as the link between local (ie for pairs of views) representations and global (ie for a sequence of images) representations."
            },
            "slug": "Canonic-Representations-for-the-Geometries-of-Views-Luong-Vi\u00e9ville",
            "title": {
                "fragments": [],
                "text": "Canonic Representations for the Geometries of Multiple Projective Views"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is shown how a special decomposition of general projection matrices, called canonic, enables us to build geometric descriptions for a system of cameras which are invariant with respect to a given group of transformations."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14743585,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "214ffb957fd12801f6dd0f5a927cd4347532d227",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates projective invariants of geometric configurations in 3 dimensional projective space P, and most particularly the computation of invariants from two or more independent images. A basic tool in this investigation is the essential matrix defined by Longuet-Higgins ([10]), for this matrix describes the epipolar correspondence between image pairs. It is proven that once the epipolar geometry is known, the configurations of many geometric structures (for instance sets of points or lines) are determined up to a collineation of Pby their projection in two independent images. This theorem is the key to a method for the computation of invariants of the geometry. Invariants of 6 points in Pand of four lines in Pare defined and discussed in detail. An example with real images shows that they are effective in distinguishing different geometrical configurations. Since the essential matrix is a fundamental tool in the computation of these invariants, new methods of computing the essential matrix from 7 point correspondences in two images, 6 point correspondences in 3 images or 13 line correspondences in three images are described."
            },
            "slug": "Invariants-of-Points-Seen-in-Multiple-Images-Hartley",
            "title": {
                "fragments": [],
                "text": "Invariants of Points Seen in Multiple Images"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This paper investigates projective invariants of geometric configurations in 3 dimensional projective space P, and most particularly the computation of invariants from two or more independent images, and the essential matrix defined by Longuet-Higgins is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40166275"
                        ],
                        "name": "D. Liebowitz",
                        "slug": "D.-Liebowitz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Liebowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Liebowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14667994,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e8686936c7572c6b3d683720d68acafe676f58c5",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We present methods for creating 3D graphical models of scenes from a limited numbers of images, i.e. one or two, in situations where no scene co\u2010ordinate measurements are available. The methods employ constraints available from geometric relationships that are common in architectural scenes \u2013 such as parallelism and orthogonality \u2013 together with constraints available from the camera. In particular, by using the circular points of a plane simple, linear algorithms are given for computing plane rectification, plane orientation and camera calibration from a single image. Examples of image based 3D modelling are given for both single images and image pairs."
            },
            "slug": "Creating-Architectural-Models-from-Images-Liebowitz-Criminisi",
            "title": {
                "fragments": [],
                "text": "Creating Architectural Models from Images"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "Methods for creating 3D graphical models of scenes from a limited numbers of images, i.e. one or two, in situations where no scene co\u2010ordinate measurements are available are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Forum"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418842"
                        ],
                        "name": "T. Drummond",
                        "slug": "T.-Drummond",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Drummond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Drummond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34574494"
                        ],
                        "name": "D. Robertson",
                        "slug": "D.-Robertson",
                        "structuredName": {
                            "firstName": "Duncan",
                            "lastName": "Robertson",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Robertson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15125627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77822ed97da9f8d7deb59aafb869c8234803f05a",
            "isKey": false,
            "numCitedBy": 240,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of recovering 3D models from uncalibrated images of architectural scenes. We propose a simple, geometrically intuitive method which exploits the strong rigidity constraints of paral-lelism and orthogonality present in indoor and outdoor architectural scenes. We present a n o vel algorithm that uses these simple constraints to recover the projection matrices for each viewpoint and relate our method to the algorithm of Caprile and Torre 2]. The projection matrices are used to recover partial 3D models of the scene and these can be used to visualise new viewpoints. Our approach d o e s not need any a priori information about the cameras being used. A w orking system called PhotoBuilder has been designed and implemented to allow a user to interactively build a VRML model of a building from uncalibrated images from arbitrary viewpoints 3, 4 ]."
            },
            "slug": "Camera-Calibration-from-Vanishing-Points-in-Image-Cipolla-Drummond",
            "title": {
                "fragments": [],
                "text": "Camera Calibration from Vanishing Points in Image of Architectural Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A simple, geometrically intuitive method which exploits the strong rigidity constraints of paral-lelism and orthogonality present in indoor and outdoor architectural scenes to recover the projection matrices for each viewpoint is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713563"
                        ],
                        "name": "F. Kahl",
                        "slug": "F.-Kahl",
                        "structuredName": {
                            "firstName": "Fredrik",
                            "lastName": "Kahl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18817667,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f1d19581dddbed3e01fb52a10fed9e3b9d3e1c7c",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of recovering scene structure and camera motion from images has a number of inherent ambiguities. In this paper, configurations of points and cameras are analyzed for which the image points alone are insufficient to recover the scene geometry uniquely. Such configurations are said to be critical. For two views, it is well-known that a configuration is critical only if the two camera centres and all points lie on a ruled quadric. However, this is only a necessary condition. We give a complete characterization of the critical surfaces for two calibrated cameras and any number of points. Both algebraic and geometric characterizations of such surfaces are given. The existence of critical sets for n-view projective reconstruction has recently been reported in the literature. We show that there are critical sets for n-view Euclidean reconstruction as well. For example, it is shown that for any placement of three calibrated cameras, there always exists a critical set consisting of any number of points on a fourth-degree curve."
            },
            "slug": "Critical-Curves-and-Surfaces-for-Euclidean-Kahl-Hartley",
            "title": {
                "fragments": [],
                "text": "Critical Curves and Surfaces for Euclidean Reconstruction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper gives a complete characterization of the critical surfaces for two calibrated cameras and any number of points and shows that there are critical sets for n-view Euclidean reconstruction as well."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31823376,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e38407d8c13df79015dea96503f821a7d26ca0a",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper there are two innovations. First, the geometry of imaged curves is developed in two and three views. A set of results are given for both conics and non-algebraic curves. It is shown that the homography between the images induced by the plane of the curve can be computed from two views given only the epipolar geometry, and that the trifocal tensor can be used to transfer a conic or the curvature from two views to a third. The second innovation is an algorithm for automatically matching individual curves between images. The algorithm uses both photometric information and the multiple view geometric results. For image pairs the homography facilitates the computation of a neighbourhood cross-correlation based matching score for putative curve correspondences. For image triplets cross-correlation matching scores are used in conjunction with curve transfer based on the trifocal geometry to disambiguate matches. Algorithms are developed for both short and wide baselines. The algorithms are robust to deficiencies in the curve segment extraction and partial occlusion. Experimental results are given for image pairs and triplets, for varying motions between views, and for different scene types. The method is applicable to curve matching in stereo and trinocular rigs, and as a starting point for curve matching through monocular image sequences."
            },
            "slug": "The-Geometry-and-Matching-of-Curves-in-Multiple-Schmid-Zisserman",
            "title": {
                "fragments": [],
                "text": "The Geometry and Matching of Curves in Multiple Views"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the homography between the images induced by the plane of the curve can be computed from two views given only the epipolar geometry, and that the trifocal tensor can be used to transfer a conic or the curvature from twoViews to a third."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3453447"
                        ],
                        "name": "J. Mundy",
                        "slug": "J.-Mundy",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Mundy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mundy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108385944"
                        ],
                        "name": "Jane Liu",
                        "slug": "Jane-Liu",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jane Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417659"
                        ],
                        "name": "Nic Pillow",
                        "slug": "Nic-Pillow",
                        "structuredName": {
                            "firstName": "Nic",
                            "lastName": "Pillow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nic Pillow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144760431"
                        ],
                        "name": "Charlie Rothwell",
                        "slug": "Charlie-Rothwell",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Rothwell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charlie Rothwell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2326267"
                        ],
                        "name": "S. Utcke",
                        "slug": "S.-Utcke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Utcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Utcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18028987,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d117a8aa2bd465b9a4a9428bb0d237f693ceb86",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In any object recognition system a major and primary task is to associate those image features, within an image of a complex scene, that arise from an individual object. The key idea here is that a geometric class defined in 3D induces relationships in the image which must hold between points on the image outline (the perspective projection of the object). The resulting image constraints enable both identification and grouping of image features belonging to objects of that class. The classes include surfaces of revolution, canal surfaces (pipes) and polyhedra. Recognition proceeds by first recognising an object as belonging to one of the classes (for example a surface of revolution) and subsequently identifying the object (for example as a particular vase). This differs from conventional object recognition systems where recognition is generally targetted at particular objects. These classes also support the computation of 3D invariant descriptions including symmetry axes, canonical coordinate frames and projective signatures. The constraints and grouping methods are viewpoint invariant, and proceed with no information on object pose. We demonstrate the effectiveness of this class-based grouping on real, cluttered scenes using grouping algorithms developed for rotationally symmetric surfaces, canal-surfaces and polyhedra.<<ETX>>"
            },
            "slug": "Class-based-grouping-in-perspective-images-Zisserman-Mundy",
            "title": {
                "fragments": [],
                "text": "Class-based grouping in perspective images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The key idea here is that a geometric class defined in 3D induces relationships in the image which must hold between points on the image outline (the perspective projection of the object) to enable both identification and grouping of image features belonging to objects of that class."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143814637"
                        ],
                        "name": "Berthold K. P. Horn",
                        "slug": "Berthold-K.-P.-Horn",
                        "structuredName": {
                            "firstName": "Berthold",
                            "lastName": "Horn",
                            "middleNames": [
                                "K.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berthold K. P. Horn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6205250,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0f9733fcf7232621fe112b2d09d130b494273737",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Relative orientation is the recovery of the position and orientation of one imaging system relative to another from correspondences among five or more ray pairs. It is one of four core problems in photogrammetry and is of central importance in binocular stereo as well as in long-range motion vision. While five ray correspondences are sufficient to yield a finite number of solutions, more than five correspondences are used in practice to ensure an accurate solution with least-squares methods. Most iterative schemes for minimizing the sum of the squares of weighted errors require a good guess as a starting value. The author has previously published a method that results in the best solution without requiring an initial guess [ \nJ. Opt. Soc. Am. A4, \n629 ( \n1987)] An even simpler method is presented here that utilizes the representation of rotations by unit quaternions."
            },
            "slug": "Relative-orientation-revisited-Horn",
            "title": {
                "fragments": [],
                "text": "Relative orientation revisited"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299436"
                        ],
                        "name": "R. Kaucic",
                        "slug": "R.-Kaucic",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Kaucic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kaucic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864114"
                        ],
                        "name": "N. Y. Dano",
                        "slug": "N.-Y.-Dano",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Dano",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Y. Dano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8162094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c3b30b4a74ff4182b174f12113613885f7ef568",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A linear method for computing a projective reconstruction from a large number of images is presented and then evaluated. The method uses planar homographies between views to linearize the resecting of the cameras. Constraints based on the fundamental matrix, trifocus tensor or quadrifocal tensor are used to derive relationship between the position vectors of all the cameras at once. The resulting set of equations are solved using a SVD. The algorithm is computationally efficient as it is linear in the number of matched points used. A key feature of the algorithm is that all of the images are processed simultaneously, as in the Sturm-Triggs factorization method, but it differs in not requiring that all points be visible in all views. An additional advantage is that it works with any mixture of line and point correspondence through the constraints these impose on the multilinear tensors. Experiments on both synthetic and real data confirm the method's utility."
            },
            "slug": "Plane-based-projective-reconstruction-Kaucic-Hartley",
            "title": {
                "fragments": [],
                "text": "Plane-based projective reconstruction"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A linear method for computing a projective reconstruction from a large number of images is presented and then evaluated, finding that it works with any mixture of line and point correspondence through the constraints these impose on the multilinear tensors."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713056"
                        ],
                        "name": "P. Sturm",
                        "slug": "P.-Sturm",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Sturm",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sturm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144555237"
                        ],
                        "name": "S. Maybank",
                        "slug": "S.-Maybank",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Maybank",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maybank"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 328795,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "41ed16367fc6492e99fe7ef48de83dfeff7afff8",
            "isKey": false,
            "numCitedBy": 638,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a general algorithm for plane-based calibration that can deal with arbitrary numbers of views and calibration planes. The algorithm can simultaneously calibrate different views from a camera with variable intrinsic parameters and it is easy to incorporate known values of intrinsic parameters. For some minimal cases, we describe all singularities, naming the parameters that can not be estimated. Experimental results of our method are shown that exhibit the singularities while revealing good performance in non-singular conditions. Several applications of plane-based 3D geometry inference are discussed as well."
            },
            "slug": "On-plane-based-camera-calibration:-A-general-Sturm-Maybank",
            "title": {
                "fragments": [],
                "text": "On plane-based camera calibration: A general algorithm, singularities, applications"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A general algorithm for plane-based calibration that can deal with arbitrary numbers of views and calibration planes and it is easy to incorporate known values of intrinsic parameters is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40166275"
                        ],
                        "name": "D. Liebowitz",
                        "slug": "D.-Liebowitz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Liebowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Liebowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 737311,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "759edca39bb50f7df8ad23a4857169eba71ef5fc",
            "isKey": false,
            "numCitedBy": 422,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the geometry constraints and algorithmic implementation for metric rectification of planes. The rectification allows metric properties, such as angles and length ratios, to be measured on the world plane from a perspective image. The novel contributions are: first, that in a stratified context the various forms of providing metric information, which include a known angle, two equal though unknown angles, and a known length ratio; can all be represented as circular constraints on the parameters of an affine transformation of the plane-this provides a simple and uniform framework for integrating constraints; second, direct rectification from right angles in the plane; third, it is shown that metric rectification enables calibration of the internal camera parameters; fourth, vanishing points are estimated using a Maximum Likelihood estimator; fifth, an algorithm for automatic rectification. Examples are given for a number of images, and applications demonstrated for texture map acquisition and metric measurements."
            },
            "slug": "Metric-rectification-for-perspective-images-of-Liebowitz-Zisserman",
            "title": {
                "fragments": [],
                "text": "Metric rectification for perspective images of planes"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The novel contributions are that in a stratified context the various forms of providing metric information can be represented as circular constraints on the parameters of an affine transformation of the plane, providing a simple and uniform framework for integrating constraints."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739995"
                        ],
                        "name": "Y. Horry",
                        "slug": "Y.-Horry",
                        "structuredName": {
                            "firstName": "Youichi",
                            "lastName": "Horry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Horry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794380"
                        ],
                        "name": "K. Anjyo",
                        "slug": "K.-Anjyo",
                        "structuredName": {
                            "firstName": "Ken-ichi",
                            "lastName": "Anjyo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Anjyo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144050755"
                        ],
                        "name": "K. Arai",
                        "slug": "K.-Arai",
                        "structuredName": {
                            "firstName": "Kiyoshi",
                            "lastName": "Arai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Arai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6914801,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "d30c530bfebfa6e6d31ccb2bd503ebb17845aab6",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method called TIP (Tour Into the Picture) is presented for easily making animations from one 2D picture or photograph of a scene. In TIP, animation is created from the viewpoint of a camera which can be three-dimensionally \"walked or flownthrough\" the 2D picture or photograph. To make such animation, conventional computer vision techniques cannot be applied in the 3D modeling process for the scene, using only a single 2D image. Instead a spidery mesh is employed in our method to obtain a simple scene model from the 2D image of the scene using a graphical user interface. Animation is thus easily generated without the need of multiple 2D images. Unlike existing methods, our method is not intended to construct a precise 3D scene model. The scene model is rather simple, and not fully 3D-structured. The modeling process starts by specifying the vanishing point in the 2D image. The background in the scene model then consists of at most five rectangles, whereas hierarchical polygons are used as a model for each foreground object. Furthermore a virtual camera is moved around the 3D scene model, with the viewing angle being freely controlled. This process is easily and effectively performed using the spidery mesh interface. We have obtained a wide variety of animated scenes which demonstrate the efficiency of TIP. CR"
            },
            "slug": "Tour-into-the-picture:-using-a-spidery-mesh-to-make-Horry-Anjyo",
            "title": {
                "fragments": [],
                "text": "Tour into the picture: using a spidery mesh interface to make animation from a single image"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A new method called TIP (Tour Into the Picture) is presented for easily making animations from one 2D picture or photograph of a scene using a graphical user interface, which is not intended to construct a precise 3D scene model."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143980462"
                        ],
                        "name": "R. Collins",
                        "slug": "R.-Collins",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Collins",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143905691"
                        ],
                        "name": "J. Beveridge",
                        "slug": "J.-Beveridge",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Beveridge",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beveridge"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3227586,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "3fc19bebc1f2bb0e0400e082a70cd480ad407521",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of matching perspective views of coplanar structures composed of line segments is considered. Both model-to-image and image-to-image correspondence matching are given a consistent treatment. These matching scenarios generally require discovery of an eight-parameter projective mapping. When the horizon line of the object plane can be found in the image, which is accomplished in this case by using vanishing point analysis, these problems reduce to a simpler six-parameter affine matching problem. When the intrinsic lens parameters of the camera are known, the problem further reduces to four-parameter affine similarity matching.<<ETX>>"
            },
            "slug": "Matching-perspective-views-of-coplanar-structures-Collins-Beveridge",
            "title": {
                "fragments": [],
                "text": "Matching perspective views of coplanar structures using projective unwarping and similarity matching"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The problem of matching perspective views of coplanar structures composed of line segments is considered and both model-to-image and image- to-image correspondence matching are given a consistent treatment."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2185915"
                        ],
                        "name": "Gilles Debunne",
                        "slug": "Gilles-Debunne",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "Debunne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gilles Debunne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13928508,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "61ae7275a597d52be4d3a83ae4125b32c897f66d",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "It has been known since the work of Carlsson [2] and Weinshall [17] that there is a dualization principle that allows one to interchange the role of points being viewed by several cameras and the camera centres themselves. In principle this implies the possibility of dualizing projective reconstruction algorithms to obtain new algorithms. In this paper, this theme is developed at a theoretical and algorithmic level. The nature of the duality mapping is explored and its application to reconstruction ambiguity is discussed. An explicit method for dualizing any projective reconstruction algorithm is given. At the practical implementation level, however, it is shown that there are difficulties which have so far defeated successful application of this dualization method to produce working algorithms."
            },
            "slug": "Dualizing-Scene-Reconstruction-Algorithms-Hartley-Debunne",
            "title": {
                "fragments": [],
                "text": "Dualizing Scene Reconstruction Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The nature of the duality mapping is explored and its application to reconstruction ambiguity is discussed and an explicit method for dualizing any projective reconstruction algorithm is given."
            },
            "venue": {
                "fragments": [],
                "text": "SMILE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1909232"
                        ],
                        "name": "Frederic Devernay",
                        "slug": "Frederic-Devernay",
                        "structuredName": {
                            "firstName": "Frederic",
                            "lastName": "Devernay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederic Devernay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5154080,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f2cd652da1d432e84829c8cb9cd434d2832ee171",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "To make a Euclidean reconstruction of the world seen through a stereo rig, we can either use a calibration grid, and the results will rely on the precision Of the grid and the extracted points of interest, or use self-calibration. Past work on self-calibration is focussed on the use of only one camera, and gives sometimes very unstable results. In this paper, we use a stereo rig which is supposed to be weakly calibrated using a method such as the one described in Deriche et al. (1994). Then, by matching two sets of points of the same scene reconstructed from different points of view, we try to find both the homography that maps the projective reconstruction to the Euclidean space and the displacement from the first set of points to the second set of points. We present results of the Euclidean reconstruction of a whole object from uncalibrated cameras using the method proposed here."
            },
            "slug": "From-projective-to-Euclidean-reconstruction-Devernay-Faugeras",
            "title": {
                "fragments": [],
                "text": "From projective to Euclidean reconstruction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper uses a stereo rig to be weakly calibrated using a method such as the one described in Deriche et al. (1994), and tries to find both the homography that maps the projective reconstruction to the Euclidean space and the displacement from the first set of points to the secondSet of points."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950884"
                        ],
                        "name": "I. Reid",
                        "slug": "I.-Reid",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Reid",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Reid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2499410,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d77d5c4c55a223512460793669f3016a4efb37db",
            "isKey": false,
            "numCitedBy": 750,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe how 3D affine measurements may be computed from a single perspective view of a scene given only minimal geometric information determined from the image. This minimal information is typically the vanishing line of a reference plane, and a vanishing point for a direction not parallel to the plane. It is shown that affine scene structure may then be determined from the image, without knowledge of the camera's internal calibration (e.g. focal length), nor of the explicit relation between camera and world (pose).In particular, we show how to (i) compute the distance between planes parallel to the reference plane (up to a common scale factor); (ii) compute area and length ratios on any plane parallel to the reference plane; (iii) determine the camera's location. Simple geometric derivations are given for these results. We also develop an algebraic representation which unifies the three types of measurement and, amongst other advantages, permits a first order error propagation analysis to be performed, associating an uncertainty with each measurement.We demonstrate the technique for a variety of applications, including height measurements in forensic images and 3D graphical modelling from single images."
            },
            "slug": "Single-View-Metrology-Criminisi-Reid",
            "title": {
                "fragments": [],
                "text": "Single View Metrology"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An algebraic representation is developed which unifies the three types of measurement and permits a first order error propagation analysis to be performed, associating an uncertainty with each measurement."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11470337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7de98f9a73ee006bddc33f51ef6291af6bb83c15",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper has two main contributions: The first is a set of methods for computing structure and motion for m \u2265 3 views of 6 points. It is shown that a geometric image error can be minimized over all views by a simple three parameter numerical optimization. Then, that an algebraic image error can be minimized over all views by computing the solution to a cubic in one variable. Finally, a minor point, is that this \"quasi-linear\" linear solution enables a more concise algorithm, than any given previously, for the reconstruction of 6 points in 3 views. \n \nThe second contribution is an m view n \u2265 6 point robust reconstruction algorithm which uses the 6 point method as a search engine. This extends the successful RANSAC based algorithms for 2-views and 3-views to m views. The algorithm can cope with missing data and mismatched data and may be used as an efficient initializer for bundle adjustment. \n \nThe new algorithms are evaluated on synthetic and real image sequences, and compared to optimal estimation results (bundle adjustment)."
            },
            "slug": "A-Six-Point-Solution-for-Structure-and-Motion-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "A Six Point Solution for Structure and Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An m view n \u2265 6 point robust reconstruction algorithm which uses the 6 point method as a search engine and extends the successful RANSAC based algorithms for 2-views and 3-views to m views."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145246674"
                        ],
                        "name": "A. Heyden",
                        "slug": "A.-Heyden",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Heyden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Heyden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725762"
                        ],
                        "name": "Kalle \u00c5str\u00f6m",
                        "slug": "Kalle-\u00c5str\u00f6m",
                        "structuredName": {
                            "firstName": "Kalle",
                            "lastName": "\u00c5str\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kalle \u00c5str\u00f6m"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14241857,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a6fc67c43a858b29af55a8050ae43cdc96624fec",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we will investigate the different algebraic varieties and ideals that can be generated from multiple view geometry with uncalibrated cameras. The natural descriptor, Vn, is the image of \\(\\mathcal{P}^3\\) in \\(\\mathcal{P}^2 \\times \\mathcal{P}^2 \\times \\cdot \\cdot \\cdot \\times \\mathcal{P}^2\\) under n different projections. However, we will show that Vn is not a variety."
            },
            "slug": "Algebraic-Varieties-in-Multiple-View-Geometry-Heyden-\u00c5str\u00f6m",
            "title": {
                "fragments": [],
                "text": "Algebraic Varieties in Multiple View Geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This paper investigates the different algebraic varieties and ideals that can be generated from multiple view geometry with uncalibrated cameras and shows that Vn, the natural descriptor, is not a variety."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3019042"
                        ],
                        "name": "G. Stein",
                        "slug": "G.-Stein",
                        "structuredName": {
                            "firstName": "Gideon",
                            "lastName": "Stein",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11685982,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "57cb95d04aa25f72ee705ecdea121342dfc8523c",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the linear degeneracies of projective structure estimation from line features across three views. We show that the rank of the linear system of equations for recovering the trilinear tensor of three views reduces to 23 (instead of 26) when the scene is a linear line complex [LLC] (a set of lines in space intersecting at a common line). The LLC situation is only linearly degenerate, and one can obtain a unique solution when the admissibility constraints of the tensor are accounted for. The line configuration described by an LLC, rather than being some obscure case, is in fact quite typical. It includes, as a particular example, the case of a camera moving down a hallway in an office environment or down an urban street. Furthermore, an LLC situation may occur as an artifact such as in direct estimation from spatio-temporal derivatives of image brightness. Therefore, an investigation into degeneracies and their remedy is important also in practice."
            },
            "slug": "On-Degeneracy-of-Linear-Reconstruction-From-Three-Stein-Shashua",
            "title": {
                "fragments": [],
                "text": "On Degeneracy of Linear Reconstruction From Three Views: Linear Line Complex and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is shown that the rank of the linear system of equations for recovering the trilinear tensor of three views reduces to 23 (instead of 26) when the scene is a linear line complex [LLC], a set of lines in space intersecting at a common line."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713563"
                        ],
                        "name": "F. Kahl",
                        "slug": "F.-Kahl",
                        "structuredName": {
                            "firstName": "Fredrik",
                            "lastName": "Kahl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725762"
                        ],
                        "name": "Kalle \u00c5str\u00f6m",
                        "slug": "Kalle-\u00c5str\u00f6m",
                        "structuredName": {
                            "firstName": "Kalle",
                            "lastName": "\u00c5str\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kalle \u00c5str\u00f6m"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205791,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6043d9682b13eb727b51978c01eb155b5d12e6e0",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we give a characterization of critical configurations for projective reconstruction with any number of points and views. A set of cameras and points is said to be critical if the projected image points are insufficient to determine the placement of the points and the cameras uniquely, up to a projective transformation. For two views, the critical configurations are well-known. In this paper it is shown that a configuration of n 3 cameras and in points all lying on the intersection of two distinct ruled quadrics is critical. In distinction to the two-view case, which in general allows two alternative solutions, there is a family of ambiguous reconstructions for the n-view case. As a partial converse, it Is shown that for any critical configuration, all the points lie on the intersection of two ruled quadrics."
            },
            "slug": "Critical-configurations-for-n-view-projective-Kahl-Hartley",
            "title": {
                "fragments": [],
                "text": "Critical configurations for n-view projective reconstruction"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "It is shown that a configuration of n 3 cameras and in points all lying on the intersection of two distinct ruled quadrics is critical for projective reconstruction with any number of points and views."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777539"
                        ],
                        "name": "P. Beardsley",
                        "slug": "P.-Beardsley",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Beardsley",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Beardsley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45380280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92e9d8d6ed560f58cd32a72ede6c6252fb1b8311",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for matching image primitives through a sequence is described, for the purpose of acquiring 3D geometric models. The method includes a novel robust estimator of the trifocal tensor, based on a minimum number of token correspondences across an image triplet; and a novel tracking algorithm in which corners and line segments are matched over image triplets in an integrated framework. The matching techniques are both robust (detecting and discarding mismatches) and fully automatic."
            },
            "slug": "3D-Model-Acquisition-from-Extended-Image-Sequences-Beardsley-Torr",
            "title": {
                "fragments": [],
                "text": "3D Model Acquisition from Extended Image Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A method for matching image primitives through a sequence is described, for the purpose of acquiring 3D geometric models, which includes a novel robust estimator of the trifocal tensor, based on a minimum number of token correspondences across an image triplet."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760976"
                        ],
                        "name": "P. McLauchlan",
                        "slug": "P.-McLauchlan",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "McLauchlan",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. McLauchlan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16479277,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "249b0a02995f7f4c9244655b076a1e43ef3bd806",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We attack the problem of coordinate frame dependence and gauge freedoms in structure-from-motion. We are able to formulate a bundle adjustment algorithm whose results are independent of both the coordinate frame chosen to represent the scene and the ordering of the images. This method is more efficient that existing approaches to the problem in photogrammetry. \n \nWe demonstrate that to achieve coordinate frame independent results, (i) Rotations should be represented by quaternions or local rotation parameters, not angles, and (ii) the translation vector describing the camera/ scene motion should be represented in scene 3D coordinates, not camera 3D coordinates, two representations which are normally treated as interchangeable. The algorithm allows 3D point and line features to be reconstructed. Implementation is via the efficient recursive partitioning algorithm common in photogrammetry. Results are presented demonstrating the advantages of the new method in terms of the stability of the bundle adjustment iterations."
            },
            "slug": "Gauge-Independence-in-Optimization-Algorithms-for-McLauchlan",
            "title": {
                "fragments": [],
                "text": "Gauge Independence in Optimization Algorithms for 3D Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A bundle adjustment algorithm is formulated whose results are independent of both the coordinate frame chosen to represent the scene and the ordering of the images, which is more efficient that existing approaches to the problem in photogrammetry."
            },
            "venue": {
                "fragments": [],
                "text": "Workshop on Vision Algorithms"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657603"
                        ],
                        "name": "J. Porrill",
                        "slug": "J.-Porrill",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Porrill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Porrill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145099732"
                        ],
                        "name": "S. Pollard",
                        "slug": "S.-Pollard",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pollard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pollard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1495618,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "58362becd8bde071c2545c7b3899f0d44505a0d7",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Curve-matching-and-stereo-calibration-Porrill-Pollard",
            "title": {
                "fragments": [],
                "text": "Curve matching and stereo calibration"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689382"
                        ],
                        "name": "M. Oskarsson",
                        "slug": "M.-Oskarsson",
                        "structuredName": {
                            "firstName": "Magnus",
                            "lastName": "Oskarsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oskarsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725762"
                        ],
                        "name": "Kalle \u00c5str\u00f6m",
                        "slug": "Kalle-\u00c5str\u00f6m",
                        "structuredName": {
                            "firstName": "Kalle",
                            "lastName": "\u00c5str\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kalle \u00c5str\u00f6m"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9180357,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8cb32a361f355bbfc127a4c5dfe18a507827e26d",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Minimal-projective-reconstruction-for-combinations-Oskarsson-Zisserman",
            "title": {
                "fragments": [],
                "text": "Minimal projective reconstruction for combinations of points and lines in three views"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144611617"
                        ],
                        "name": "M. Irani",
                        "slug": "M.-Irani",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Irani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Irani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789171"
                        ],
                        "name": "D. Weinshall",
                        "slug": "D.-Weinshall",
                        "structuredName": {
                            "firstName": "Daphna",
                            "lastName": "Weinshall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Weinshall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 332551,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "6369afb5c547dea9a98ce1afc53bebe8513039dd",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new framework for analyzing the geometry of multiple 3D scene points from multiple uncalibrated images, based on decomposing the projection of these points on the images into two stages: (i) the projection of the scene points onto a (real or virtual) physical reference planar surface in the scene; this creates a virtual \u201cimage\u201d on the reference plane, and (ii) the re-projection of the virtual image onto the actual image plane of the camera. The positions of the virtual image points are directly related to the 3D locations of the scene points and the camera centers relative to the reference plane alone. All dependency on the internal camera calibration parameters and the orientation of the camera are folded into homographies relating each image plane to the reference plane."
            },
            "slug": "From-Reference-Frames-to-Reference-Planes:-Parallax-Irani-Anandan",
            "title": {
                "fragments": [],
                "text": "From Reference Frames to Reference Planes: Multi-View Parallax Geometry and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper presents a new framework for analyzing the geometry of multiple 3D scene points from multiple uncalibrated images, based on decomposing the projection of these points on the images into two stages; all dependency on the internal camera calibration parameters and the orientation of the camera are folded into homographies relating each image plane to the reference plane."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733393"
                        ],
                        "name": "H. Sawhney",
                        "slug": "H.-Sawhney",
                        "structuredName": {
                            "firstName": "Harpreet",
                            "lastName": "Sawhney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sawhney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145693144"
                        ],
                        "name": "S. Hsu",
                        "slug": "S.-Hsu",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Hsu",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108437389"
                        ],
                        "name": "Rakesh Kumar",
                        "slug": "Rakesh-Kumar",
                        "structuredName": {
                            "firstName": "Rakesh",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rakesh Kumar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14500750,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "66c8046c556eedea0ea7030f78d39ed5bfc76ca5",
            "isKey": false,
            "numCitedBy": 282,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of piecing together individual frames in a video sequence to create seamless panoramas (video mosaics) has attracted increasing attention in recent times. One challenge in this domain has been to rapidly and automatically create high quality seamless mosaics using inexpensive cameras and relatively free hand motions."
            },
            "slug": "Robust-Video-Mosaicing-through-Topology-Inference-Sawhney-Hsu",
            "title": {
                "fragments": [],
                "text": "Robust Video Mosaicing through Topology Inference and Local to Global Alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This research attacked the problem of piecing together individual frames in a video sequence to create seamless panoramas using inexpensive cameras and relatively free hand motions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713056"
                        ],
                        "name": "P. Sturm",
                        "slug": "P.-Sturm",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Sturm",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sturm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144555237"
                        ],
                        "name": "S. Maybank",
                        "slug": "S.-Maybank",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Maybank",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maybank"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6667946,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62bdf4743c5ad00a32790a18dd593be0813e571e",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach for 3D reconstruction of objects from a single image. Obviously, constraints on the 3D structure are needed to perform this task. Our approach is based on user-provided coplanarity, perpendicularity and parallelism constraints. These are used to calibrate the image and perform 3D reconstruction. The method is described in detail and results are provided."
            },
            "slug": "A-Method-for-Interactive-3D-Reconstruction-of-from-Sturm-Maybank",
            "title": {
                "fragments": [],
                "text": "A Method for Interactive 3D Reconstruction of Piecewise Planar Objects from Single Images"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work presents an approach for 3D reconstruction of objects from a single image based on user-provided coplanarity, perpendicularity and parallelism constraints, used to calibrate the image and perform3D reconstruction."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40166275"
                        ],
                        "name": "D. Liebowitz",
                        "slug": "D.-Liebowitz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Liebowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Liebowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2770778,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "52cfc7974bf707611f2ff3df2112cf858bb9a79d",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple approach to combining scene and auto-calibration constraints for the calibration of cameras from single views and stereo pairs. Calibration constraints are provided by imaged scene structure, such as vanishing points of orthogonal directions, or rectified planes. In addition, constraints are available from the nature of the cameras and the motion between views. We formulate these constraints in terms of the geometry of the imaged absolute conic and its relationship to pole-polar pairs and the imaged circular points of planes. Three significant advantages result: first, constraints from scene features, camera characteristics and auto-calibration constraints provide linear equations in the elements of the image of the absolute conic. This means that constraints may easily be combined, and their solution is straightforward. Second, the degeneracies that occur when constraints are not independent may be easily identified. Lastly, the constraints from scene planes and image planes may be treated uniformly. Examples of various cases of constraint combination and degeneracy as well as computational techniques are presented."
            },
            "slug": "Combining-scene-and-auto-calibration-constraints-Liebowitz-Zisserman",
            "title": {
                "fragments": [],
                "text": "Combining scene and auto-calibration constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A simple approach to combining scene and auto-calibration constraints for the calibration of cameras from single views and stereo pairs and examples of various cases of constraint combination and degeneracy as well as computational techniques are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1845996"
                        ],
                        "name": "T. Th\u00f3rhallsson",
                        "slug": "T.-Th\u00f3rhallsson",
                        "structuredName": {
                            "firstName": "Torfi",
                            "lastName": "Th\u00f3rhallsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Th\u00f3rhallsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48121727"
                        ],
                        "name": "D. W. Murray",
                        "slug": "D.-W.-Murray",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Murray",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. W. Murray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11496951,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "7e71f85ae0ba4217fa721da585520c51ec1009bc",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we specialize the projective unifocal, bifocal, and trifocal tensors to the affine case, and show how the tensors obtained relate to the registered tensors encountered in previous work. This enables us to obtain an affine specialization of known projective relations connecting points and lines across two or three views. In the simpler case of affine cameras we give neccessary and sufficient constraints on the components of the trifocal tensor together with a simple geometric interpretation. Finally, we show how the estimation of the tensors from point correspondences is achieved through factorization, and discuss the estimation from line correspondences."
            },
            "slug": "The-tensors-of-three-affine-views-Th\u00f3rhallsson-Murray",
            "title": {
                "fragments": [],
                "text": "The tensors of three affine views"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper shows how the estimation of the tensors from point correspondences is achieved through factorization, and discusses the estimation from line correspondences."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878635"
                        ],
                        "name": "Tom\u00e1\u0161 Werner",
                        "slug": "Tom\u00e1\u0161-Werner",
                        "structuredName": {
                            "firstName": "Tom\u00e1\u0161",
                            "lastName": "Werner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom\u00e1\u0161 Werner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6214897,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "07ac85026b95d96f4bdf328312882a9ab3932720",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "It is well-known that epipolar geometry relating two uncalibrated images is determined by at least seven correspondences. If there are more than seven of them, their positions cannot be arbitrary if they are to be projections of any world points by any two cameras. Less than seven matches have been thought not to be constrained in any way. We show that there is a constraint even on five matches, i.e., that there exist forbidden configurations of five points in two images. The constraint is obtained by requiring orientation consistence points on the wrong side of rays are not allowed. For allowed configurations, we show that epipoles must lie in domains with piecewise-conic boundaries, and how to compute them. We present a concise algorithm deciding whether a configuration is allowed or forbidden."
            },
            "slug": "Constraint-on-five-points-in-two-images-Werner",
            "title": {
                "fragments": [],
                "text": "Constraint on five points in two images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that there is a constraint even on five matches, i.e., that there exist forbidden configurations of five points in two images, and a concise algorithm deciding whether a configuration is allowed or forbidden."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153382032"
                        ],
                        "name": "R. Gupta",
                        "slug": "R.-Gupta",
                        "structuredName": {
                            "firstName": "Rajiv",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114160741"
                        ],
                        "name": "Tom Chang",
                        "slug": "Tom-Chang",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3529048,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "79ec7aaf9aa41ac4cc5b9aa1960422d5c1a1aa04",
            "isKey": false,
            "numCitedBy": 527,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of computing placement of points in 3-D space, given two uncalibrated perspective views, is considered. The main theorem shows that the placement of the points is determined only up to an arbitrary projective transformation of 3-space. Given additional ground control points, however, the location of the points and the camera parameters may be determined. The method is linear and noniterative, whereas previously known methods for solving the camera calibration and placement problem to take proper account of both ground-control points and image correspondences are unsatisfactory in requiring either iterative methods or model restrictions. As a result of the main theorem, it is possible to determine projective invariants of 3-D geometric configurations from two perspective views.<<ETX>>"
            },
            "slug": "Stereo-from-uncalibrated-cameras-Hartley-Gupta",
            "title": {
                "fragments": [],
                "text": "Stereo from uncalibrated cameras"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The problem of computing placement of points in 3-D space, given two uncalibrated perspective views, is considered and it is possible to determine projective invariants of3-D geometric configurations from two perspective views."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144611617"
                        ],
                        "name": "M. Irani",
                        "slug": "M.-Irani",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Irani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Irani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5586199,
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "id": "81324332b73b1a82344aab3cce6a1eefbbb98a7d",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Shows that the set of all flow fields in a sequence of frames imaging a rigid scene resides in a low-dimensional linear subspace. Based on this observation, we develop a method for simultaneous estimation of optical flow across multiple frames, which uses these subspace constraints. The multi-frame subspace constraints are strong constraints, and they replace commonly used heuristic constraints, such as spatial or temporal smoothness. The subspace constraints are geometrically meaningful and are not violated at depth discontinuities or when the camera motion changes abruptly. Furthermore, we show that the subspace constraints on flow fields apply for a variety of imaging models, scene models and motion models. Hence, the presented approach for constrained multi-frame flow estimation is general. However, our approach does not require prior knowledge of the underlying world or camera model. Although linear subspace constraints have been used successfully in the past for recovering 3D information, it has been assumed that 2D correspondences are given. However, correspondence estimation is a fundamental problem in motion analysis. In this paper, we use multi-frame subspace constraints to constrain the 2D correspondence estimation process itself, and not for 3D recovery."
            },
            "slug": "Multi-frame-optical-flow-estimation-using-subspace-Irani",
            "title": {
                "fragments": [],
                "text": "Multi-frame optical flow estimation using subspace constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper develops a method for simultaneous estimation of optical flow across multiple frames, which uses multi-frame subspace constraints to constrain the 2D correspondence estimation process itself, and not for 3D recovery."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145594978"
                        ],
                        "name": "T. Saxena",
                        "slug": "T.-Saxena",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Saxena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Saxena"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 240307,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "210befdf690987850a3b405898eb4079edbc541b",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an implementation of the Cubic Rational Polynomial Camera model developed as part of the FOCUS project. FOCUS ([1]) is on ongoing \u201cshared vision\u201d IR&D project jointly sponsored by Lockheed Martin Missiles and Space (LMMSS/Sunnyvale) and General Electric CR&D. A cubic camera has the advantage that all cameras, such as projective, affine and the linear pushbroom, which map the image points as rational polynomial functions (of degree no greater than 3) of the coordinates of a world point, can be treated as special cases of the cubic camera. This paper demonstrates that the cubic camera can very effectively model even those cameras which express the image points as complicated functions of world coordinates, such as radicals. In particular, it is empirically demonstrated that a SAR sensor is very accurately approximated by a cubic camera, but not by any linear camera model. The paper also outlines an algorithm for estimating the parameters of the cubic camera, given a set of image to world correspondences. The non-linear nature of this camera can make parameter estimation a very unstable process. The slightest noise in the coefficients of the nonlinear terms can lead to a completely unrealistic model of the camera. This paper discusses some refinements such as avoiding degeneracies, data normalization, and regularization which are necessary for accurate estimation of the cubic camera parameters and minimization of noise in the coefficients of the higher degree terms."
            },
            "slug": "The-Cubic-Rational-Polynomial-Camera-Model-Hartley-Saxena",
            "title": {
                "fragments": [],
                "text": "The Cubic Rational Polynomial Camera Model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144645904"
                        ],
                        "name": "Long Quan",
                        "slug": "Long-Quan",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Quan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Quan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8367515"
                        ],
                        "name": "F. Veillon",
                        "slug": "F.-Veillon",
                        "structuredName": {
                            "firstName": "Francoise",
                            "lastName": "Veillon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Veillon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6466206,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "aa86a940c7cc752f873c6933c50125b8845a8355",
            "isKey": false,
            "numCitedBy": 224,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article we show how relative 3D reconstruction from point correspondences of multiple uncalibrated images can be achieved through reference points. The original contributions with respect to related works in the field are mainly a direct global method for relative 3D reconstruction and a geometric method to select a correct set of reference points among all im age points. Experimental results from both simulated and real image sequences are presented, and robustness of the method and reconstruction precision of the results are discussed."
            },
            "slug": "Relative-3D-Reconstruction-Using-Multiple-Images-Mohr-Quan",
            "title": {
                "fragments": [],
                "text": "Relative 3D Reconstruction Using Multiple Uncalibrated Images"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "It is shown how relative 3-D reconstruction for point correspondence of multiple images from uncalibrated cameras can be achieved through reference points."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108188"
                        ],
                        "name": "W. Niem",
                        "slug": "W.-Niem",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Niem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Niem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144053060"
                        ],
                        "name": "R. Buschmann",
                        "slug": "R.-Buschmann",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Buschmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Buschmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2183349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "851af603c2c6a2ddfe6a1453be7ff040cdbdf887",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for the fast automatic construction of a 3D model of any real object using images from multiple views is presented. The images are taken from a real object rotating in front of a stationary calibrated CCD TV camera. The presented algorithm generates the object shape in a first step. For that purpose an effective implementation of the method of occluding contours is used to obtain a convex volume model of the object. This model is refined in order to detect shape concavities by using additional depth information from disparity estimation and finally approximated by a triangle mesh. In a second step the texture is estimated from the image sequence and projected onto the surface model to obtain natural looking models. Results with real image sequences have confirmed the suitability of the developed algorithm even for the modelling of real objects with highly detailed and complex surfaces."
            },
            "slug": "Automatic-Modelling-of-3D-Natural-Objects-from-Niem-Buschmann",
            "title": {
                "fragments": [],
                "text": "Automatic Modelling of 3D Natural Objects from Multiple Views"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "An algorithm for the fast automatic construction of a 3D model of any real object using images from multiple views is presented and results with real image sequences have confirmed the suitability of the developed algorithm even for the modelling of real objects with highly detailed and complex surfaces."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144645904"
                        ],
                        "name": "Long Quan",
                        "slug": "Long-Quan",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Quan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Quan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 42556832,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5b14507fee56a8da7013f9cf3799cc8edae9e298",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "There are three projective invariants of a set of six points in general position in space. It is well known that these invariants cannot be recovered from one image, however an invariant relationship does exist between space invariants and image invariants. This invariant relationship will first be derived for a single image. Then this invariant relationship is used to derive the space invariants, when multiple images are available."
            },
            "slug": "Invariants-of-6-Points-from-3-Uncalibrated-Images-Quan",
            "title": {
                "fragments": [],
                "text": "Invariants of 6 Points from 3 Uncalibrated Images"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "There are three projective invariants of a set of six points in general position in space that cannot be recovered from one image, however an invariant relationship does exist between space invariants and image invariants."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6793964,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6ab0f2b186f0b9c99919ca9efee01ca085eab1d1",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe two direct quasilinear methods for camera pose (absolute orientation) and calibration from a single image of 4 or 5 known 3D points. They generalize the 6 point 'Direct Linear Transform' method by incorporating partial prior camera knowledge, while still allowing some unknown calibration parameters to be recovered. Only linear algebra is required, the solution is unique in non-degenerate cases, and additional points can be included for improved stability. Both methods fail for coplanar points, but we give an experimental eigendecomposition based one that handles both planar and nonplanar cases. Our methods use recent polynomial solving technology, and we give a brief summary of this. One of our aims was to try to understand the numerical behaviour of modern polynomial solvers on some relatively simple test cases, with a view to other vision applications."
            },
            "slug": "Camera-pose-and-calibration-from-4-or-5-known-3D-Triggs",
            "title": {
                "fragments": [],
                "text": "Camera pose and calibration from 4 or 5 known 3D points"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "Two direct quasilinear methods for camera pose and calibration from a single image of 4 or 5 known 3D points are described, and an experimental eigendecomposition based one is given that handles both planar and nonplanar cases."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123548189,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e80799341e4828f86aaf7a7d9701abf452529bd3",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Given multiple image data from a set of points in 3D, there are two fundamental questions that can be addressed: (1) What is the structure of the set of points in 3D? (2) What are the positions of the cameras relative to the points? In this paper, we show that for projective views and with structure- and position-defined modulo linear transformations, these problems are are dual in the sense that their solution arises from constraint equations where space point and camera positions occur in a reciprocal way. The problem of computing camera positions from m points in n views can be solved with the same algorithm as the problem of directly reconstructing n+4 points in m-4 views. This unifies different approaches for projective reconstruction: methods based on external calibration and direct methods exploiting constraints that exist between space and image invariants."
            },
            "slug": "Duality-of-reconstruction-and-positioning-from-Carlsson",
            "title": {
                "fragments": [],
                "text": "Duality of reconstruction and positioning from projective views"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The problem of computing camera positions from m points in n views can be solved with the same algorithm as the problem of directly reconstructing n+4 points in m-4 views with similar results."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Workshop on Representation of Visual Scenes (In Conjunction with ICCV'95)"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3377447"
                        ],
                        "name": "L. Agapito",
                        "slug": "L.-Agapito",
                        "structuredName": {
                            "firstName": "Lourdes",
                            "lastName": "Agapito",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Agapito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950884"
                        ],
                        "name": "I. Reid",
                        "slug": "I.-Reid",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Reid",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Reid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2901127"
                        ],
                        "name": "E. Hayman",
                        "slug": "E.-Hayman",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Hayman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hayman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13269265,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e187db6d25b5b05f73e4540d14fd19013a6fa985",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers the problem of self-calibration of a camera from an image sequence in the case where the camera's internal parameters (most notably focal length) may change. The problem of camera self-calibration from a sequence of images has proven to be a difficult one in practice, due to the need ultimately to resort to non-linear methods, which have often proven to be unreliable. In a stratified approach to self-calibration, a projective reconstruction is obtained first and this is successively refined first to an affine and then to a Euclidean (or metric) reconstruction. It has been observed that the difficult step is to obtain the affine reconstruction, or equivalently to locate the plane at infinity in the projective coordinate frame. The problem is inherently non-linear and requires iterative methods that risk not finding the optimal solution. The present paper overcomes this difficulty by imposing chirality constraints to limit the search for the plane at infinity to a 3-dimensional cubic region of parameter space. It is then possible to carry out a dense search over this cube in reasonable time. For each hypothesised placement of the plane at infinity, the calibration problem is reduced to one of calibration of a nontranslating camera, for which fast non-iterative algorithms exist. A cost function based on the result of the trial calibration is used to determine the best placement of the plane at infinity. Because of the simplicity of each trial, speeds of over 10,000 trials per second are achieved on a 256 MHz processor. It is shown that this dense search allows one to avoid areas of local minima effectively and find global minima of the cost function."
            },
            "slug": "Camera-calibration-and-the-search-for-infinity-Hartley-Agapito",
            "title": {
                "fragments": [],
                "text": "Camera calibration and the search for infinity"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Imposing chirality constraints to limit the search for the plane at infinity to a 3-dimensional cubic region of parameter space is imposed and it is shown that this dense search allows one to avoid areas of local minima effectively and find global minima of the cost function."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16608494,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccb20b59755f17735768aff7c857753b1a58dd5a",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Planar-grouping-for-automatic-detection-of-lines-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "Planar grouping for automatic detection of vanishing lines and points"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51064498"
                        ],
                        "name": "Zhengyou Zhang",
                        "slug": "Zhengyou-Zhang",
                        "structuredName": {
                            "firstName": "Zhengyou",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengyou Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702017"
                        ],
                        "name": "R. Deriche",
                        "slug": "R.-Deriche",
                        "structuredName": {
                            "firstName": "Rachid",
                            "lastName": "Deriche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Deriche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5858737,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3ec4ceea040b7b4129ee5d71b4f95539bf876b7",
            "isKey": false,
            "numCitedBy": 1625,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Robust-Technique-for-Matching-two-Uncalibrated-of-Zhang-Deriche",
            "title": {
                "fragments": [],
                "text": "A Robust Technique for Matching two Uncalibrated Images Through the Recovery of the Unknown Epipolar Geometry"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49735940"
                        ],
                        "name": "C. Baillard",
                        "slug": "C.-Baillard",
                        "structuredName": {
                            "firstName": "Caroline",
                            "lastName": "Baillard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Baillard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11848036,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "625d24014e0d22d9ad63131476a6d88926ffd174",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method is described for automatically reconstructing 3D planar faces from multiple images of a scene. The novelty of the approach lies in the use of inter-image homographies to validate and best estimate the plane, and in the minimal initialization requirements-only a single 3D line with a textured neighbourhood is required to generate a plane hypothesis. The planar facets enable line grouping and also the construction of parts of the wireframe which were missed due to the inevitable shortcomings of feature detection and matching. The method allows a piecewise planar model of a scene to be built completely automatically, with no user intervention at any stage, given only the images and camera projection matrices as input. The robustness and reliability of the method are illustrated on several examples, from both aerial and interior views."
            },
            "slug": "Automatic-reconstruction-of-piecewise-planar-models-Baillard-Zisserman",
            "title": {
                "fragments": [],
                "text": "Automatic reconstruction of piecewise planar models from multiple views"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "The novelty of the approach lies in the use of inter-image homographies to validate and best estimate the plane, and in the minimal initialization requirements-only a single 3D line with a textured neighbourhood is required to generate a plane hypothesis."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145413827"
                        ],
                        "name": "Guang Jiang",
                        "slug": "Guang-Jiang",
                        "structuredName": {
                            "firstName": "Guang",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guang Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145985024"
                        ],
                        "name": "H. Tsui",
                        "slug": "H.-Tsui",
                        "structuredName": {
                            "firstName": "Hung-Tat",
                            "lastName": "Tsui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Tsui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144645904"
                        ],
                        "name": "Long Quan",
                        "slug": "Long-Quan",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Quan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Quan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17392380,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bb5fb531d6f22980a325af8d348d38eba9b3dd81",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a new approach for recovering 3D geometry from an uncalibrated image sequence of a single axis (turntable) motion. Unlike previous methods, the computation of multiple views encoded by the fundamental matrix or trifocal tensor is not required. Instead, the new approach is based on fitting a conic locus to corresponding image points over multiple views. It is then shown that the geometry of single axis motion can be recovered given at least two such conics. In the case of two conics the reconstruction may have a two fold ambiguity, but this ambiguity is removed if three conics are used.The approach enables the geometry of the single axis motion (the 3D rotation axis and Euclidean geometry in planes perpendicular to this axis) to be estimated using the minimal number of parameters. It is demonstrated that a Maximum Likelihood Estimation results in measurements that are as good as or superior to those obtained by previous methods, and with a far simpler algorithm. Examples are given on various real sequences, which show the accuracy and robustness of the new algorithm."
            },
            "slug": "Single-Axis-Geometry-by-Fitting-Conics-Jiang-Tsui",
            "title": {
                "fragments": [],
                "text": "Single Axis Geometry by Fitting Conics"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A new approach for recovering 3D geometry from an uncalibrated image sequence of a single axis (turntable) motion based on fitting a conic locus to corresponding image points over multiple views is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109165"
                        ],
                        "name": "M. Proesmans",
                        "slug": "M.-Proesmans",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Proesmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Proesmans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45161166,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3ecfe09f7e6bf4928badf06884a6c4290ca06367",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Planar-homologies-as-a-basis-for-grouping-and-Gool-Proesmans",
            "title": {
                "fragments": [],
                "text": "Planar homologies as a basis for grouping and recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18495389,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "27be0f66c38013302db815c41f745936f651df8c",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a finite difference expansion for closely spaced cameras in projective vision, and use it to derive differential analogues of the finite-displacement projective matching tensors and constraints. The results are simpler, more general and easier to use than Astrom & Heyden's time-derivative based 'continuous time matching constraints'. We suggest how to use the formalism for 'tensor tracking'-propagation of matching relations against a fixed base image along an image sequence. We relate this to non-linear tensor estimators and show how 'unwrapping the optimization loop' along the sequence allows simple 'linear n point' update estimates to converge rapidly to statistically near-optimal, near-consistent tensor estimates as the sequence proceeds. We also give guidelines as to when difference expansion is likely to be worthwhile as compared to a discrete approach."
            },
            "slug": "Differential-matching-constraints-Triggs",
            "title": {
                "fragments": [],
                "text": "Differential matching constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A finite difference expansion for closely spaced cameras in projective vision is introduced, and it is shown how 'unwrapping the optimization loop' along the sequence allows simple 'linear n point' update estimates to converge rapidly to statistically near-optimal, near-consistent tensor estimates as the sequence proceeds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1714689,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "51cd6defa26c4ab6ddde8f42729b030130bd0775",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Discusses the basic role of the trifocal tensor in scene reconstruction. This 3/spl times/3/spl times/3 tensor plays a role in the analysis of scenes from three views analogous to the role played by the fundamental matrix in the two-view case. In particular, the trifocal tensor maybe computed by a linear algorithm from a set of 13 line correspondences in three views. It is further shown in this paper to be essentially identical to a set of coefficients introduced by Shashua (1994) to effect point transfer in the three-view case. This observation means that the 13-line algorithm may be extended to allow for the computation of the trifocal tensor given any mixture of sufficiently many line and point correspondences. From the trifocal tensor, the camera image matrices may be computed, and the scene may be reconstructed. For unrelated uncalibrated cameras, this reconstruction is unique up to projectivity. Thus, projective reconstruction of a set of lines and points may be reconstructed linearly from three views.<<ETX>>"
            },
            "slug": "A-linear-method-for-reconstruction-from-lines-and-Hartley",
            "title": {
                "fragments": [],
                "text": "A linear method for reconstruction from lines and points"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The trifocal tensor is shown to be essentially identical to a set of coefficients introduced by Shashua (1994) to effect point transfer in the three-view case and to be extended to allow for the computation of the trifoc tensor given any mixture of sufficiently many line and point correspondences."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145246674"
                        ],
                        "name": "A. Heyden",
                        "slug": "A.-Heyden",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Heyden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Heyden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725762"
                        ],
                        "name": "Kalle \u00c5str\u00f6m",
                        "slug": "Kalle-\u00c5str\u00f6m",
                        "structuredName": {
                            "firstName": "Kalle",
                            "lastName": "\u00c5str\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kalle \u00c5str\u00f6m"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9187048,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c9a5b2c81487591785e00ab29b3c9140e01072d9",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The special case of reconstruction from image sequences taken by cameras with skew equal to 0 and aspect ratio equal to 1 has been treated. These type of cameras, here called cameras with Euclidean image planes, represent rigid projections where neither the principal point nor the focal length is known, it is shown that it is possible to reconstruct an unknown object from images taken by a camera with Euclidean image plane up to similarity transformations, i.e., Euclidean transformations plus changes in the global scale. An algorithm, using bundle adjustment techniques, has been implemented. The performance of the algorithm is shown on simulated data."
            },
            "slug": "Euclidean-reconstruction-from-image-sequences-with-Heyden-\u00c5str\u00f6m",
            "title": {
                "fragments": [],
                "text": "Euclidean reconstruction from image sequences with varying and unknown focal length and principal point"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The special case of reconstruction from image sequences taken by cameras with skew equal to 0 and aspect ratio equal to 1 has been treated and it is shown that it is possible to reconstruct an unknown object from images taken by a camera with Euclidesan image plane up to similarity transformations, i.e., Euclidean transformations plus changes in the global scale."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11739428,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ebab564f8634a16adce0d55579ec5426e5febcc",
            "isKey": false,
            "numCitedBy": 541,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The author describes a new method for camera autocalibration and scaled Euclidean structure and motion, from three or more views taken by a moving camera with fixed but unknown intrinsic parameters. The motion constancy of these is used to rectify an initial projective reconstruction. Euclidean scene structure is formulated in terms of the absolute quadric-the singular dual 3D quadric (4/spl times/4 rank 3 matrix) giving the Euclidean dot-product between plane normals. This is equivalent to the traditional absolute conic but simpler to use. It encodes both affine and Euclidean structure, and projects very simply to the dual absolute image conic which encodes camera calibration. Requiring the projection to be constant gives a bilinear constraint between the absolute quadric and image conic, from which both can be recovered nonlinearly from m/spl ges/3 images, or quasi-linearly from m/spl ges/4. Calibration and Euclidean structure follow easily. The nonlinear method is stabler, faster, more accurate and more general than the quasi-linear one. It is based on a general constrained optimization technique-sequential quadratic programming-that may well be useful in other vision problems."
            },
            "slug": "Autocalibration-and-the-absolute-quadric-Triggs",
            "title": {
                "fragments": [],
                "text": "Autocalibration and the absolute quadric"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "The author describes a new method for camera autocalibration and scaled Euclidean structure and motion, from three or more views taken by a moving camera with fixed but unknown intrinsic parameters, based on a general constrained optimization technique-sequential quadratic programming-that may well be useful in other vision problems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585959"
                        ],
                        "name": "A. V. van Doorn",
                        "slug": "A.-V.-van-Doorn",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "van Doorn",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. V. van Doorn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1663567,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8b77030426b39ddb083e5a729f7f2bbaaae37cdb",
            "isKey": false,
            "numCitedBy": 869,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A mobile observer samples sequences of narrow-field projections of configurations in ambient space. The so-called structure-from-motion problem is to infer the structure of these spatial configurations from the sequence of projections. For rigid transformations, a unique metrical reconstruction is known to be possible from three orthographic views of four points. However, human observers seem able to obtain much shape information from a mere pair of views, as is evident in the case of binocular stereo. Moreover, human observers seem to find little use for the information provided by additional views, even though some improvement certainly occurs. The rigidity requirement in its strict form is also relaxed. We indicate how solutions of the structure-from-motion problem can be stratified in such a way that one explicitly knows at which stages various a priori assumptions enter and specific geometrical expertise is required. An affine stage is identified at which only smooth deformation is assumed (thus no rigidity constraint is involved) and no metrical concepts are required. This stage allows one to find the spatial configuration (modulo an affinity) from two views. The addition of metrical methods allows one to find shape from two views, modulo a relief transformation (depth scaling and shear). The addition of a third view then merely serves to settle the calibration. Results of a numerical experiment are discussed."
            },
            "slug": "Affine-structure-from-motion.-Koenderink-Doorn",
            "title": {
                "fragments": [],
                "text": "Affine structure from motion."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is indicated how solutions of the structure-from-motion problem can be stratified in such a way that one explicitly knows at which stages various a priori assumptions enter and specific geometrical expertise is required."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987598"
                        ],
                        "name": "B. Mourrain",
                        "slug": "B.-Mourrain",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Mourrain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Mourrain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13888023,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ebf8a07cd7485105adbdbb94dade77848a3096b1",
            "isKey": false,
            "numCitedBy": 297,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore the geometric and algebraic relations that exist between correspondences of points and lines in an arbitrary number of images. We propose to use the formalism of the Grassmann-Cayley algebra as the simplest way to make both geometric and algebraic statements in a very synthetic and effective way (i.e. allowing actual computation if needed). We have a fairly complete picture of the situation in the case of points; there are only three types of algebraic relations which are satisfied by the coordinates of the images of a 3-D point: bilinear relations arising when we consider pairs of images among the N and which are the well-known epipolar constraints, trilinear relations arising when we consider triples of images among the N, and quadrilinear relations arising when we consider four-tuples of images among the N. In the case of lines, we show how the traditional perspective projection equation can be suitably generalized and that in the case of three images there exist two independent trilinear relations between the coordinates of the images of a 3-D line.<<ETX>>"
            },
            "slug": "On-the-geometry-and-algebra-of-the-point-and-line-N-Faugeras-Mourrain",
            "title": {
                "fragments": [],
                "text": "On the geometry and algebra of the point and line correspondences between N images"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The formalism of the Grassmann-Cayley algebra is proposed to use as the simplest way to make both geometric and algebraic statements in a very synthetic and effective way (i.e. allowing actual computation if needed)."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8954390,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ce690e23da1a1f4cb5f335631c68a9545b48be40",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This correspondence investigates projective reconstruction of geometric configurations seen in two or more perspective views, and the computation of projective invariants of these configurations from their images. A basic tool in this investigation is the fundamental matrix that describes the epipolar correspondence between image pairs. It is proven that once the epipolar geometry is known, the configurations of many geometric structures (for instance sets of points or lines) are determined up to a collineation of projective 3-space /spl Pscrsup 3/ by their projection in two independent images. This theorem is the key to a method for the computation of invariants of the geometry. Invariants of six points in /spl Pscrsup 3/ and of four lines in /spl Pscrsup 3/ are defined and discussed. An example with real images shows that they are effective in distinguishing different geometrical configurations. Since the fundamental matrix is a basic tool in the computation of these invariants, new methods of computing the fundamental matrix from seven-point correspondences in two images or six-point correspondences in three images are given. >"
            },
            "slug": "Projective-Reconstruction-and-Invariants-from-Hartley",
            "title": {
                "fragments": [],
                "text": "Projective Reconstruction and Invariants from Multiple Images"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "It is proven that once the epipolar geometry is known, the configurations of many geometric structures are determined up to a collineation of projective 3-space /spl Pscrsup 3/ by their projection in two independent images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10254283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84128cee474bef797d968e59ade7d2042022a3f9",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 141,
            "paperAbstract": {
                "fragments": [],
                "text": "Reconstructing a 3-dimensional scene from a set of2-dimensional images is a fundamental problem in computervision. A system capable of performing this task can be used inmany applications in roboti ..."
            },
            "slug": "Multi-View-Reconstruction-and-Camera-Recovery-using-Rother",
            "title": {
                "fragments": [],
                "text": "Multi-View Reconstruction and Camera Recovery using a Real or Virtual Reference Plane"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This work reconstructs a 3-dimensional scene from a set of 2-dimensional images and develops a system capable of performing this task, which can be used in many applications in roboti ..."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950884"
                        ],
                        "name": "I. Reid",
                        "slug": "I.-Reid",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Reid",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Reid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11446049,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ffd47833751a063561b04b9afa512bd9e4507c5",
            "isKey": false,
            "numCitedBy": 247,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-plane-measuring-device-Criminisi-Reid",
            "title": {
                "fragments": [],
                "text": "A plane measuring device"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713056"
                        ],
                        "name": "P. Sturm",
                        "slug": "P.-Sturm",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Sturm",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sturm"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8100596,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "50eb7786a554bc70b82c462fb1181b7761d36cef",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Critical-motion-sequences-for-the-self-calibration-Sturm",
            "title": {
                "fragments": [],
                "text": "Critical motion sequences for the self-calibration of cameras and stereo systems with variable focal length"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738740"
                        ],
                        "name": "S. B. Kang",
                        "slug": "S.-B.-Kang",
                        "structuredName": {
                            "firstName": "Sing",
                            "lastName": "Kang",
                            "middleNames": [
                                "Bing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. B. Kang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1248103,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d10817fd815f2128443a496c3364075f6afe7caa",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper examines the fundamental ambiguities and uncertainties inherent in recovering structure from motion. By examining the eigenvectors associated with null or small eigenvalues of the Hessian matrix, we can quantify the exact nature of these ambiguities and predict how they will affect the accuracy of the reconstructed shape. Our results for orthographic cameras show that the bas-relief ambiguity is significant even with many images, unless a large amount of rotation is present. Similar results for perspective cameras suggest that three or more frames and a large amount of rotation are required for metrically accurate reconstruction."
            },
            "slug": "Shape-Ambiguities-in-Structure-From-Motion-Szeliski-Kang",
            "title": {
                "fragments": [],
                "text": "Shape Ambiguities in Structure From Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "By examining the eigenvectors associated with null or small eigenvalues of the Hessian matrix, this paper can quantify the exact nature of these ambiguities and predict how they will affect the accuracy of the reconstructed shape."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742208"
                        ],
                        "name": "M. Pollefeys",
                        "slug": "M.-Pollefeys",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Pollefeys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pollefeys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144839904"
                        ],
                        "name": "R. Koch",
                        "slug": "R.-Koch",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35608522,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "84544813dbe31fd317c2942df9bad8f63bf506e7",
            "isKey": false,
            "numCitedBy": 934,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper the feasibility of self-calibration in the presence of varying internal camera parameters is under investigation. A self-calibration method is presented which efficiently deals with all kinds of constraints on the internal camera parameters. Within this framework a practical method is proposed which can retrieve metric reconstruction from image sequences obtained with uncalibrated zooming/focusing cameras. The feasibility of the approach is illustrated on real and synthetic examples."
            },
            "slug": "Self-calibration-and-metric-reconstruction-in-spite-Pollefeys-Koch",
            "title": {
                "fragments": [],
                "text": "Self-calibration and metric reconstruction in spite of varying and unknown internal camera parameters"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A self-calibration method is presented which efficiently deals with all kinds of constraints on the internal camera parameters and a practical method is proposed which can retrieve metric reconstruction from image sequences obtained with uncalibrated zooming/focusing cameras."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713563"
                        ],
                        "name": "F. Kahl",
                        "slug": "F.-Kahl",
                        "structuredName": {
                            "firstName": "Fredrik",
                            "lastName": "Kahl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kahl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10482342,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "46df800f26bacdb0795908c63107d217e316be1e",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates critical configurations for projective reconstruction from multiple images taken by a camera moving in a straight line. Projective reconstruction refers to a determination of the 3D (three-dimensional) geometrical configuration of a set of 3D points and cameras, given only correspondences between points in the images. A configuration of points and cameras is critical if it cannot be determined uniquely (up to a projective transform) from the image coordinates of the points. It is shown that a configuration consisting of any number of cameras lying on a straight line, and any number of points lying on a twisted cubic constitutes a critical configuration. An alternative configuration consisting of a set of points and cameras all lying on a rational quartic curve exists."
            },
            "slug": "A-critical-configuration-for-reconstruction-from-Hartley-Kahl",
            "title": {
                "fragments": [],
                "text": "A critical configuration for reconstruction from rectilinear motion"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper investigates critical configurations for projective reconstruction from multiple images taken by a camera moving in a straight line, and it is shown that a configuration consisting of any number of cameras lying on a straightline, and any number on a twisted cubic constitutes a critical configuration."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13358989,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "41f81c88cfcc0553e043e81102115559546fcf3f",
            "isKey": false,
            "numCitedBy": 416,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the theory and a practical algorithm for the autocalibration of a moving projective camera, from m \u2265 5 views of a planar scene. The unknown camera calibration, motion and scene geometry are recovered up to scale, from constraints encoding the motion-invariance of the camera's internal parameters. This extends the domain of autocalibration from the classical non-planar case to the practically common planar one, in which the solution can not be bootstrapped from an intermediate projective reconstruction. It also generalizes Hartley's method for the internal calibration of a rotating camera, to allow camera translation and to provide 3D as well as calibration information. The basic constraint is that orthogonal directions (points at infinity) in the plane must project to orthogonal directions in the calibrated images. Abstractly, the plane's two circular points (representing its Euclidean structure) lie on the 3D absolute conic, so their projections must lie on the absolute image conic (representing the camera calibration). The resulting algorithm optimizes this constraint numerically over all circular points and all projective calibration parameters, using the inter-image homographies as a projective scene representation."
            },
            "slug": "Autocalibration-from-Planar-Scenes-Triggs",
            "title": {
                "fragments": [],
                "text": "Autocalibration from Planar Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The theory and a practical algorithm for the autocalibration of a moving projective camera, from m \u2265 5 views of a planar scene, which generalizes Hartley's method for the internal calibration of a rotating camera to allow camera translation and to provide 3D as well as calibration information."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2558901"
                        ],
                        "name": "E. Barrett",
                        "slug": "E.-Barrett",
                        "structuredName": {
                            "firstName": "Eamon",
                            "lastName": "Barrett",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Barrett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2972851"
                        ],
                        "name": "M. Brill",
                        "slug": "M.-Brill",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brill",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10245192"
                        ],
                        "name": "N. N. Haag",
                        "slug": "N.-N.-Haag",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Haag",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. N. Haag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33053165"
                        ],
                        "name": "P. M. Payton",
                        "slug": "P.-M.-Payton",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Payton",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. M. Payton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33340653,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a00feebf7532e386470d6e115def46c1be9a63e8",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "For several useful tasks in photogrammetry and in model-based vision, noniterative methods that require only the inversion of systems of linear equations are developed. The methods are based on the theory of projective invariants. The tasks addressed are resection, intersection, and transfer, or model matching (with or without ground control points). The following kinds of transfer are examined: (a) coplanar object points (transfer to image 2 done using four reference points in image 1); (b) stereo camera system (transfer to stereo camera pair 2 done using four reference points in stereo pair 1); (c) general multicamera configuration (transfer of a ninth point to image 3 done using eight tie points in images 1 and 2).<<ETX>>"
            },
            "slug": "Some-invariant-linear-methods-in-photogrammetry-and-Barrett-Brill",
            "title": {
                "fragments": [],
                "text": "Some invariant linear methods in photogrammetry and model-matching"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "For several useful tasks in photogrammetry and in model-based vision, noniterative methods that require only the inversion of systems of linear equations are developed, based on the theory of projective invariants."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50032052"
                        ],
                        "name": "Yi Ma",
                        "slug": "Yi-Ma",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715959"
                        ],
                        "name": "Stefano Soatto",
                        "slug": "Stefano-Soatto",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Soatto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefano Soatto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743020"
                        ],
                        "name": "J. Kosecka",
                        "slug": "J.-Kosecka",
                        "structuredName": {
                            "firstName": "Jana",
                            "lastName": "Kosecka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kosecka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144797536"
                        ],
                        "name": "S. Sastry",
                        "slug": "S.-Sastry",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Sastry",
                            "middleNames": [
                                "Shankar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sastry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 716079,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fff8169a57d8c5b398c7190291bea52928a84dce",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "The necessary and sufficient conditions for being able to estimate scene structure, motion and camera calibration from a sequence of images are very rarely satisfied in practice. What exactly can be estimated in sequences of practical importance, when such conditions are not satisfied? In this paper we give a complete answer to this question. For every camera motion that fails to meet the conditions, we give explicit formulas for the ambiguities in the reconstructed scene, motion and calibration. Such a characterization is crucial both for designing robust estimation algorithms (that do not try to recover parameters that cannot be recovered), and for generating novel views of the scene by controlling the vantage point. To this end, we characterize explicitly all the vantage points that give rise to a valid Euclidean reprojection regardless of the ambiguity in the reconstruction. We also characterize vantage points that generate views that are altogether invariant to the ambiguity. All the results are presented using simple notation that involves no tensors nor complex projective geometry, and should be accessible with basic background in linear algebra."
            },
            "slug": "Euclidean-Reconstruction-and-Reprojection-Up-to-Ma-Soatto",
            "title": {
                "fragments": [],
                "text": "Euclidean Reconstruction and Reprojection Up to Subgroups"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper characterize explicitly all the vantage points that give rise to a valid Euclidean reprojection regardless of the ambiguity in the reconstruction of the reconstructed scene, motion and calibration."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713235"
                        ],
                        "name": "B. Tordoff",
                        "slug": "B.-Tordoff",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Tordoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Tordoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48121727"
                        ],
                        "name": "D. W. Murray",
                        "slug": "D.-W.-Murray",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Murray",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. W. Murray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11292165,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "ba63bd52bf34ebfbbdd6844fb20695e5f2bbe340",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method for visual control of the zoom setting of an active camera during tracking. The method assumes an afne projection, and tracking is achieved using afne transfer, a process which is fundamentally invariant to zoom. However, the form of the projection matrices determined to achieve transfer allows the relative scale between the afne bases in different views to be determined, and hence controlled at unity. Unlike its projective equivalent, the method requires no self-calibration, the zooming camera may move quite generally, and no restriction need be applied to the nature of the scene being viewed. The performances of 3D and 2D versions of the algorithms are examined using synthetic data under varying levels of noise and under varying degrees of degeneracy in motion and structure. Real-time results are presented from imagery of laboratory scenes and off-line results obtained from an outdoor surveillance video sequence."
            },
            "slug": "Reactive-Zoom-Control-while-Tracking-Using-an-Tordoff-Murray",
            "title": {
                "fragments": [],
                "text": "Reactive Zoom Control while Tracking Using an Affine Camera"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This paper describes a method for visual control of the zoom setting of an active camera during tracking that requires no self-calibration, the zooming camera may move quite generally, and no restriction need be applied to the nature of the scene being viewed."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2276193,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "098ea12f5fd68b8d865819aae96fc53693564257",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "In a scene observed from a fixed viewpoint, the set of shadow boundaries in an image changes as a point light source (nearby or at infinity) assumes different locations. We show that for any finite set of point light sources illuminating an object viewed under either orthographic or perspective projection, there is an equivalence class of object shapes having the same set of shadows. Members of this equivalence class differ by a four-parameter family of projective transformations, and the shadows of a transformed object are identical when the same transformation is applied to the light source locations. Under orthographic projection, this family is the generalized bas-relief (GBR) transformation, and we show that the GBR transformation is the only family of transformations of an object's shape for which the complete set of imaged shadows is identical. Finally, we show that given multiple images under differing and unknown light source directions, it is possible to reconstruct both an object's surface and the light source locations up to this family of transformations from the shadows alone."
            },
            "slug": "What-Shadows-Reveal-about-Object-Structure-Kriegman-Belhumeur",
            "title": {
                "fragments": [],
                "text": "What Shadows Reveal about Object Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that for any finite set of point light sources illuminating an object viewed under either orthographic or perspective projection, there is an equivalence class of object shapes having the same set of shadows."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28509790"
                        ],
                        "name": "Joss Knight",
                        "slug": "Joss-Knight",
                        "structuredName": {
                            "firstName": "Joss",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joss Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950884"
                        ],
                        "name": "I. Reid",
                        "slug": "I.-Reid",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Reid",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Reid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9702693,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "cc883eef8a864d394fd45d81c04e7d8d6429015d",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Planar scenes would appear to be ideally suited for self-calibration because, by eliminating the problems of occlusion and parallax, high accuracy two-view relationships can be calculated without restricting motion to pure rotation. Unfortunately, the only monocular solutions so far devised involve costly nonlinear minimizations, which must be initialized with educated guesses for the calibration parameters. So far, this problem has been circumvented by using stereo or a known calibration object. In this work we show that when there is some control over the motion of the camera, a fast linear solution is available without these restrictions. For a camera undergoing a motion about a plane-normal rotation axis (typified for instance by a motion in the plane of the scene), the complex eigenvectors of a plane-induced homography are coincident with the circular points of the motion. Three such homographies provide sufficient information to solve for the image of the absolute conic (IAC), and therefore the calibration parameters. The required situation arises most commonly when the camera is viewing the ground plane, and either moving along it, or rotating about some vertical axis. We demonstrate a number of useful applications, and show the algorithm to be simple, fast, and accurate."
            },
            "slug": "Linear-auto-calibration-for-ground-plane-motion-Knight-Zisserman",
            "title": {
                "fragments": [],
                "text": "Linear auto-calibration for ground plane motion"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work shows that when there is some control over the motion of the camera, a fast linear solution is available without these restrictions, and shows the algorithm to be simple, fast, and accurate."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17458366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3c6bd6e5fef5336cafe6e1c794224ad58660542",
            "isKey": false,
            "numCitedBy": 509,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Deals with estimating motion parameters and the structure of the scene from point (or feature) correspondences between two perspective views. An algorithm is presented that gives a closed-form solution for motion parameters and the structure of the scene. The algorithm utilizes redundancy in the data to obtain more reliable estimates in the presence of noise. An approach is introduced to estimating the errors in the motion parameters computed by the algorithm. Specifically, standard deviation of the error is estimated in terms of the variance of the errors in the image coordinates of the corresponding points. The estimated errors indicate the reliability of the solution as well as any degeneracy or near degeneracy that causes the failure of the motion estimation algorithm. The presented approach to error estimation applies to a wide variety of problems that involve least-squares optimization or pseudoinverse. Finally the relationships between errors and the parameters of motion and imaging system are analyzed. The results of the analysis show, among other things, that the errors are very sensitive to the translation direction and the range of field view. Simulations are conducted to demonstrate the performance of the algorithms and error estimation as well as the relationships between the errors and the parameters of motion and imaging systems. The algorithms are tested on images of real-world scenes with point of correspondences computed automatically. >"
            },
            "slug": "Motion-and-Structure-From-Two-Perspective-Views:-Weng-Huang",
            "title": {
                "fragments": [],
                "text": "Motion and Structure From Two Perspective Views: Algorithms, Error Analysis, and Error Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The presented approach to error estimation applies to a wide variety of problems that involve least-squares optimization or pseudoinverse and shows, among other things, that the errors are very sensitive to the translation direction and the range of field view."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153382032"
                        ],
                        "name": "R. Gupta",
                        "slug": "R.-Gupta",
                        "structuredName": {
                            "firstName": "Rajiv",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gupta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1074247,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f7bd85220e64e47818103d940af24b08d0eb103a",
            "isKey": false,
            "numCitedBy": 357,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling and analyzing pushbroom sensors commonly used in satellite imagery is difficult and computationally intensive due to the motion of an orbiting satellite with respect to the rotating Earth, and the nonlinearity of the mathematical model involving orbital dynamics. In this paper, a simplified model of a pushbroom sensor (the linear pushbroom model) is introduced. It has the advantage of computational simplicity while at the same time giving very accurate results compared with the full orbiting pushbroom model. Besides remote sensing, the linear pushbroom model is also useful in many other imaging applications. Simple noniterative methods are given for solving the major standard photogrammetric problems for the linear pushbroom model: computation of the model parameters from ground-control points; determination of relative model parameters from image correspondences between two images; and scene reconstruction given image correspondences and ground-control points. The linear pushbroom model leads to theoretical insights that are approximately valid for the full model as well. The epipolar geometry of linear pushbroom cameras is investigated and shown to be totally different from that of a perspective camera. Nevertheless, a matrix analogous to the fundamental matrix of perspective cameras is shown to exist for linear pushbroom sensors. From this it is shown that a scene is determined up to an affine transformation from two views with linear pushbroom cameras."
            },
            "slug": "Linear-Pushbroom-Cameras-Hartley-Gupta",
            "title": {
                "fragments": [],
                "text": "Linear Pushbroom Cameras"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The linear pushbroom model introduced in this paper has the advantage of computational simplicity while at the same time giving very accurate results compared with the full orbiting push broom model."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144549270"
                        ],
                        "name": "M. Brand",
                        "slug": "M.-Brand",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Brand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17047667,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9d8f47ebf3fd68ee6d0e0858c68f1df0c81b47a",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Nonrigid 3D structure-from-motion and 2D optical flow can both be formulated as tensor factorization problems. The two problems can be made equivalent through a noisy affine transform, yielding a combined nonrigid structure-from-intensities problem that we solve via structured matrix decompositions. Often the preconditions for this factorization are violated by image noise and deficiencies of the data visa-vis the sample complexity of the problem. Both issues are remediated with careful use of rank constraints, norm constraints, and integration over uncertainty in the intensity values, yielding novel solutions for SVD under uncertainty, factorization under uncertainty, nonrigid factorization, and subspace optical flow. The resulting integrated algorithm can track and reconstruct in 3D nonrigid surfaces having very little texture, for example the smooth parts of the face. Working with low-resolution low-texture \"found video,\" these methods produce good tracking and 3D reconstruction results where prior algorithms fail."
            },
            "slug": "Morphable-3D-models-from-video-Brand",
            "title": {
                "fragments": [],
                "text": "Morphable 3D models from video"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The resulting integrated algorithm can track and reconstruct in 3D nonrigid surfaces having very little texture, for example the smooth parts of the face, via structured matrix decompositions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777539"
                        ],
                        "name": "P. Beardsley",
                        "slug": "P.-Beardsley",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Beardsley",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Beardsley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950884"
                        ],
                        "name": "I. Reid",
                        "slug": "I.-Reid",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Reid",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Reid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121873589,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4f50d1599b19113f677e37d2724ad170798261ed",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes a method to determine affine and metric calibration for a stereo rig. The method does not involve the use of calibration objects or special motions, but simply a single general motion of the rig with fixed parameters (i.e. camera parameters and relative orientation of the camera pair). The novel aspects of this work are: first, relating the distinguished objects of Euclidean geometry to fixed entities of a Euclidean transformation matrix; second, showing that these fixed entities are accessible from the conjugate Euclidean transformation arising from the projective transformation of the structure under a motion of the fixed stereo rig; and third, a robust and automatic implementation of the method. Results are included of affine and metric calibration and structure recovery using images of real scenes."
            },
            "slug": "Metric-calibration-of-a-stereo-rig-Zisserman-Beardsley",
            "title": {
                "fragments": [],
                "text": "Metric calibration of a stereo rig"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Workshop on Representation of Visual Scenes (In Conjunction with ICCV'95)"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2766153"
                        ],
                        "name": "S. Se",
                        "slug": "S.-Se",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Se",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Se"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1646930,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a539239ee9d2241ce9ac2fcd5c86887adfbb1994",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Zebra-crossings are useful road features for outdoor navigation in mobility aids for the partially sighted. In this paper, zebra-crossings are detected by looking for groups of concurrent lines, edges are then partitioned using intensity variation information. In order to tackle the ambiguity of the detection algorithm in distinguishing zebra-crossings and stair-cases, pose information is sought. Three methods are developed to estimate the pose: homography search approach using an a priori model; finding normal using the vanishing line computed from equally-spaced lines and with two vanishing points. These algorithms have been applied to real images with promising results and they are also useful in some other shape from texture applications."
            },
            "slug": "Zebra-crossing-detection-for-the-partially-sighted-Se",
            "title": {
                "fragments": [],
                "text": "Zebra-crossing detection for the partially sighted"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Zebra-crossings are detected by looking for groups of concurrent lines, edges are then partitioned using intensity variation information and three methods are developed to estimate the pose: homography search approach using an a priori model; finding normal using the vanishing line computed from equally-spaced lines and with two vanishing points."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10064959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d74086e6e571edecff8d2be85684f3e3a66718ef",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A robust approach is presented to estimation motion and structure from image sequences. The approach consists of two steps. The first step is estimating the motion parameters using a robust linear algorithm that gives a closed-form solution for motion parameters and scene structure. The second step is improving the results from the linear algorithm using maximum-likelihood estimation. An algorithm using point correspondences from monocular images is discussed in detail and experimented with. An algorithm using line correspondences is briefly discussed. The simulations show that maximum-likelihood estimation achieves remarkable improvement over the preliminary estimates given by the linear algorithm. The algorithm is also tested on images of real scenes from automatically computed displacement field. The proposed approach is independent of the exact tokens used to establish correspondences, e.g. displacement flow, optical flow, or discrete features. Two or more types of tokens may be used, for monocular or binocular images.<<ETX>>"
            },
            "slug": "Closed-form-solution+maximum-likelihood:-a-robust-Weng-Ahuja",
            "title": {
                "fragments": [],
                "text": "Closed-form solution+maximum likelihood: a robust approach to motion and structure estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A robust approach to estimation motion and structure from image sequences using a robust linear algorithm that gives a closed-form solution for motion parameters and scene structure and achieves remarkable improvement over the preliminary estimates given by the linear algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144555237"
                        ],
                        "name": "S. Maybank",
                        "slug": "S.-Maybank",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Maybank",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maybank"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11987934,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "a18ab523c143bebdec421d66bf01e1967262c919",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractIn this paper, we study the multiplicity of solutions of the motion problem. Given n point matches between two frames, how many solutions are there to the motion problem? We show that the maximum number of solutions is 10 when 5 point matches are available. This settles a question that has been around in the computer vision community for a while. We follow two tracks.\u2022 The first one attempts to recover the motion parameters by studying the essential matrix and has been followed by a number of researchers in the field. A natural extension of this is to use algebraic geometry to characterize the set of possible essential matrixes. We present some new results based on this approach.\u2022 The second question, based on projective geometry, dates from the previous century.\nWe show that the two approaches are compatible and yield the same result.We then describe a computer implementation of the second approach that uses MAPLE, a language for symbolic computation. The program allows us to compute exactly the solutions for any configuration of 5 points. Some experiments are described."
            },
            "slug": "Motion-from-point-matches:-Multiplicity-of-Faugeras-Maybank",
            "title": {
                "fragments": [],
                "text": "Motion from point matches: Multiplicity of solutions"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "It is shown that the maximum number of solutions to the motion problem is 10 when 5 point matches are available, which settles a question that has been around in the computer vision community for a while."
            },
            "venue": {
                "fragments": [],
                "text": "[1989] Proceedings. Workshop on Visual Motion"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187716"
                        ],
                        "name": "Gang Xu",
                        "slug": "Gang-Xu",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51064498"
                        ],
                        "name": "Zhengyou Zhang",
                        "slug": "Zhengyou-Zhang",
                        "structuredName": {
                            "firstName": "Zhengyou",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengyou Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10743562,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dbc9ba57a5dca326b8022679d789ba3e870cdce4",
            "isKey": false,
            "numCitedBy": 538,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": "Foreword Olivier Faugeras. Foreword Saburo Tsuji. Preface. 1. Introduction. 2. Camera Models and Epipolar Geometry. 3. Recovery of Epipolar Geometry From Points. 4. Recovery of Epipolar Geometry from Line Segments or Lines. 5. Redefining Stereo, Motion and Object Recognition via Epipolar Geometry. 6. Image Matching and Uncalibrated Stereo. 7. Multiple Rigid Motions: Correspondence and Segmentation. 8. 3D Object Recognition and Localization with Model Views. 9. Concluding Remarks. References. Index."
            },
            "slug": "Epipolar-Geometry-in-Stereo,-Motion-and-Object-Xu-Zhang",
            "title": {
                "fragments": [],
                "text": "Epipolar Geometry in Stereo, Motion and Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Redefining Stereo, Motion and Object Recognition via Ep bipolar Geometry via Epipolar Geometry, and Multiple Rigid Motions: Correspondence and Segmentation is redefined."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Imaging and Vision"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772880"
                        ],
                        "name": "David P. Capel",
                        "slug": "David-P.-Capel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Capel",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David P. Capel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14325799,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9ae88d8cf3ac74dfb7e24edd2d5c9d71caf326b7",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe mosaicing for a sequence of images acquired by a camera rotating about its centre. The novel contributions are in two areas. First, in the automation and estimation of image registration: images"
            },
            "slug": "Automated-mosaicing-with-super-resolution-zoom-Capel-Zisserman",
            "title": {
                "fragments": [],
                "text": "Automated mosaicing with super-resolution zoom"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "M mosaicing for a sequence of images acquired by a camera rotating about its centre is described, in the automation and estimation of image registration: images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3377447"
                        ],
                        "name": "L. Agapito",
                        "slug": "L.-Agapito",
                        "structuredName": {
                            "firstName": "Lourdes",
                            "lastName": "Agapito",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Agapito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2901127"
                        ],
                        "name": "E. Hayman",
                        "slug": "E.-Hayman",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Hayman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hayman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42925546,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "99f29646591590b4d252fa515c4ee52453dd704b",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A linear self-calibration method is given for computing the calibration of a stationary but rotating camera. The internal parameters of the camera are allowed to vary from image to image, allowing for zooming (change of focal length) and possible variation of the principal point of the camera. In order for calibration to be possible some constraints must be placed on the calibration of each image. The method works under the minimal assumption of zero-skew (rectangular pixels), or the more restrictive but reasonable conditions of square pixels, known pixel aspect ratio, and known principal point. Being linear the algorithm is extremely rapid, and avoids the convergence problems characteristic of iterative algorithms."
            },
            "slug": "Linear-self-calibration-of-a-rotating-and-zooming-Agapito-Hayman",
            "title": {
                "fragments": [],
                "text": "Linear self-calibration of a rotating and zooming camera"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A linear self-calibration method is given for computing the calibration of a stationary but rotating camera, which is extremely rapid, and avoids the convergence problems characteristic of iterative algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48121727"
                        ],
                        "name": "D. W. Murray",
                        "slug": "D.-W.-Murray",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Murray",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. W. Murray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123740333,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "646edc722edfcfffb4c792b337bbec49c7beb621",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for solving the problem of motion segmentation, identifying the objects within an image moving independently of the background. We utilize the fact that two views of a static 3D point set are linked by a 3 X 3 Fundamental Matrix (F). The Fundamental Matrix contains all the information on structure and motion from a given set of point correspondences and is derived by a least squares method under the assumption that the majority of the image is undergoing a rigid motion. Least squares is the most commonly used method of parameter estimation in computer vision algorithms. However the estimated parameters from a least squares fit can be corrupted beyond recognition in the presence of gross errors or outliers which plague any data from real imagery. Features with a motion independent of the background are those statistically inconsistent from the calculated value of (F). Well founded methods for detecting these outlying points are described."
            },
            "slug": "Outlier-detection-and-motion-segmentation-Torr-Murray",
            "title": {
                "fragments": [],
                "text": "Outlier detection and motion segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new method for solving the problem of motion segmentation, identifying the objects within an image moving independently of the background by utilizing the fact that two views of a static 3D point set are linked by a 3 X 3 Fundamental Matrix (F)."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742208"
                        ],
                        "name": "M. Pollefeys",
                        "slug": "M.-Pollefeys",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Pollefeys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pollefeys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2450841"
                        ],
                        "name": "F. Verbiest",
                        "slug": "F.-Verbiest",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Verbiest",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Verbiest"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17719219,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3fdfcdd59dc191db32e62009b663280962107906",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of uncalibrated structure and motion recovery from image sequences that contain dominant planes in some of the views. Traditional approaches fail when the features common to three consecutive views are all located on a plane. This happens because in the uncalibrated case there is a fundamental ambiguity in relating the structure before and after the plane. This is, however, a situation that is often hard to avoid in man-made environments. We propose a complete approach that detects the problem and defers the computation of parameters that are ambiguous in projective space (i.e. the registration between partial reconstructions only sharing a common plane and poses of cameras only seeing planar features) till after self-calibration. Also a new linear self-calibration algorithm is proposed that couples the intrinsics between multiple subsequences. The final result is a complete metric 3D reconstruction of both structure and motion for the whole sequence. Experimental results on real image sequences show that the approach yields very good results."
            },
            "slug": "Surviving-Dominant-Planes-in-Uncalibrated-Structure-Pollefeys-Verbiest",
            "title": {
                "fragments": [],
                "text": "Surviving Dominant Planes in Uncalibrated Structure and Motion Recovery"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A complete approach is proposed that detects the problem and defers the computation of parameters that are ambiguous in projective space (i.e. the registration between partial reconstructions only sharing a common plane and poses of cameras only seeing planar features) till after self-calibration."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742208"
                        ],
                        "name": "M. Pollefeys",
                        "slug": "M.-Pollefeys",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Pollefeys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pollefeys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769671"
                        ],
                        "name": "A. Oosterlinck",
                        "slug": "A.-Oosterlinck",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Oosterlinck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oosterlinck"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 901895,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c85d403330c6f30914a1d3303e7ee082369821db",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "To obtain a Euclidean reconstruction from images the cameras have to be calibrated. In recent years different approaches have been proposed to avoid explicit calibration. The problem with these methods is that several parameters have to be retrieved at once. Because of the non-linearity of the equations this is not an easy task and the methods often fail to converge. In the's paper a stratified approach is proposed which allows to first retrieve the affine calibration of the camera using the modulus constraint. Having the affine calibration it is easy to upgrade to Euclidean. The important advantage of this method is that only three parameters have to be evaluated at first. From a practical point of view, the major gain is that an affine reconstruction is obtained from arbitrary sequences of views, whereas so far affine reconstruction has been based on pairs of views with a pure translation in between. A short illustration of another application is also given. Once the affine calibration is known, the constraint can be used to retrieve the Euclidean calibration in the presence of a variable focal length."
            },
            "slug": "The-modulus-constraint:-a-new-constraint-Pollefeys-Gool",
            "title": {
                "fragments": [],
                "text": "The modulus constraint: a new constraint self-calibration"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A stratified approach is proposed which allows to first retrieve the affine calibration of the camera using the modulus constraint, which can be used to retrieve the Euclidean calibration in the presence of a variable focal length."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 439048,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a358dfe15b8eecfbfbd562a12ab6bcb25eaf645",
            "isKey": false,
            "numCitedBy": 470,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The possibility of calibrating a camera from image data alone, based on matched points identified in a series of images by a moving camera was suggested by Mayband and Faugeras. This result implies the possibility of Euclidean reconstruction from a series of images with a moving camera, or equivalently, Euclidean structure-from-motion from an uncalibrated camera. No tractable algorithm for implementing their methods for more than three images have been previously reported. This paper gives a practical algorithm for Euclidean reconstruction from several views with the same camera. The algorithm is demonstrated on synthetic and real data and is shown to behave very robustly in the presence of noise giving excellent calibration and reconstruction results."
            },
            "slug": "Euclidean-Reconstruction-from-Uncalibrated-Views-Hartley",
            "title": {
                "fragments": [],
                "text": "Euclidean Reconstruction from Uncalibrated Views"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A practical algorithm for Euclidean reconstruction from several views with the same camera is given and is shown to behave very robustly in the presence of noise giving excellent calibration and reconstruction results."
            },
            "venue": {
                "fragments": [],
                "text": "Applications of Invariance in Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700928"
                        ],
                        "name": "O. Chum",
                        "slug": "O.-Chum",
                        "structuredName": {
                            "firstName": "Ond\u0159ej",
                            "lastName": "Chum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878635"
                        ],
                        "name": "Tom\u00e1\u0161 Werner",
                        "slug": "Tom\u00e1\u0161-Werner",
                        "structuredName": {
                            "firstName": "Tom\u00e1\u0161",
                            "lastName": "Werner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom\u00e1\u0161 Werner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758039"
                        ],
                        "name": "T. Pajdla",
                        "slug": "T.-Pajdla",
                        "structuredName": {
                            "firstName": "Tom\u00e1s",
                            "lastName": "Pajdla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pajdla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11980107,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c5796cf7f7c32cd00a3b81d1cf8f546e174c996a",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "It is known that epipolar constraintcan be augmentedwith orientation by formulating it in the oriented projective geometry. This oriented epipolar constraint requires knowing the orientations (signs of overall scales) of epipoles and fundamental matrix. The current belief is that these orientations cannot be obtained from the fundamental matrix only and that additional information is needed, typically, a single correct pointcorrespondence. In contrary to this, we show that fundamental matrix alone encodes orientation of epipoles up to their common scale sign. We present two formulations of this fact. The algebraic formulation gives a closed formula to compute the second epipole from fundamental matrix and the first epipole. The geometric formulation is in terms of the conic formed by intersections of corresponding epipolar lines in the commonimage plane; we showthat the epipolesalways lie on different antipodal components of the spherical interpretation of this conic. Further, we show that, under mild assumptions, fundamental matrix can discriminate between two classes of mutual position of a pair of directional cameras."
            },
            "slug": "Joint-Orientation-of-Epipoles-Chum-Werner",
            "title": {
                "fragments": [],
                "text": "Joint Orientation of Epipoles"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that fundamental matrix alone encodes orientation of epipoles up to their common scale sign, and that, under mild assumptions, fundamental matrix can discriminate between two classes of mutual position of a pair of directional cameras."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114314602"
                        ],
                        "name": "D. Robotics",
                        "slug": "D.-Robotics",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Robotics",
                            "middleNames": [
                                "W.",
                                "Murray"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Robotics"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17729101,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2c5b50fd6fcc8b869b7ff286698e89059df721a3",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "b) c) d) Figure 5: Reprojection in diierent methods. a) Reprojection using epipolar line intersection. Fundamental Matrices computed with code distributed by INRIA. b) Reprojection using epipolar line intersection. Fundamental Matrices computed from tensor. c) Reprojection using the tensor equations. d) Original third image. Presented for comparison. with the standard summation convention that an index that appears as a subscript and superscript is summed over (known as a contraction). For details on the derivation of this equation see Appendix A. Hence, we have four trilinear equations (note that l; m = 1; 2). In more explicit form, these functions (referred to as \\trilineari-ties\") are: Since every corresponding triplet p; p 0 ; p 00 contributes four linearly independent equations, then seven corresponding points across the three views uniquely determine (up to scale) the tensor jk i. More details and applications can be found in 15]. Also worth noting is that these trilinear equations are an extension of the three equations derived by 19] under the context of unifying line and point geometry. The connection between the tensor and homography matrices comes from contraction properties described in Section 4, and from the homography matrices one can obtain the \\fundamental\" matrix F (the tensor produces 18 linear equations of rank 8 for F, for details see 18]). Fig. 5 shows an example of image reprojection (transfer) using the trilinearities, compared to using the epipolar geometry (recovered using INRIA code or using F recovered from the tensor). One can see that the best results are obtained from the trilinearities directly. a) b) c) d) Figure 3: Second sequence-close objects. a) First original frame. b) Second original frame. The camera was moving and rotating around the objects. c) average of the two original images. d) average of the two images after rotation cancelation. The remaining motion is only due to the original translation. A new robust method to recover the rotation of the camera was described. The main contribution to the robustness is the fact that we do not have to recover the epipoles, and the rotation is computed directly from three homography matrices assuming small rotations. The homography matrices are obtained from three images using the trilinear tensor parameters, and the recovery process does not assume any 3D model. The method can be extended to handle also the case of general rotations by using iterations. In this section we brieey present the trilinear \u2026"
            },
            "slug": "Motion-Clustering-using-the-Trilinear-Constraint-Torr-Zisserman",
            "title": {
                "fragments": [],
                "text": "Motion Clustering using the Trilinear Constraint over Three Views"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691192"
                        ],
                        "name": "V. Pratt",
                        "slug": "V.-Pratt",
                        "structuredName": {
                            "firstName": "Vaughan",
                            "lastName": "Pratt",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Pratt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16230907,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "67ecaf5395891a64ee58e505416ed1fa42cb4cc3",
            "isKey": false,
            "numCitedBy": 601,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In the course of developing a system for fitting smooth curves to camera input we have developed several direct (i.e. noniterative) methods for fitting a shape (line, circle, conic, cubic, plane, sphere, quadric, etc.) to a set of points, namely exact fit, simple fit, spherical fit, and blend fit. These methods are all dimension-independent, being just as suitable for 3D surfaces as for the 2D curves they were originally developed for.Exact fit generalizes to arbitrary shapes (in the sense of the term defined in this paper) the well-known determinant method for planar exact fit. Simple fit is a naive reduction of the general overconstrained case to the exact case. Spherical fit takes advantage of a special property of circles and spheres that permits robust fitting; no prior direct circle fitters have been as robust, and there have been no previous sphere fitters. Blend fit finds the best fit to a set of points of a useful generalization of Middleditch-Sears blending curves and surfaces, via a nonpolynomial generalization of planar fit.These methods all require (am+bn)n2 operations for fitting a surface of order n to m points, with a = 2 and b = 1/3 typically, except for spherical fit where b is larger due to the need to extract eigenvectors. All these methods save simple fit achieve a robustness previously attained by direct algorithms only for fitting planes. All admit incremental batched addition and deletion of points at cost an2 per point and bn3 per batch."
            },
            "slug": "Direct-least-squares-fitting-of-algebraic-surfaces-Pratt",
            "title": {
                "fragments": [],
                "text": "Direct least-squares fitting of algebraic surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "These methods all require (am+bn)n2 operations for fitting a surface of order n to m points, with a = 2 and b = 1/3 typically, except for spherical fit where b is larger due to the need to extract eigenvectors."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5793648,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d4b13f38cae95397603c012661fa656f81dd8114",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes how the fundamental matrix, F , the trifocal tensor T jk i and the quadrilinear relationship existing between corresponding points in four uncalibrated projective images may be derived in a common framework involving matrix determinants. Part of the paper contains a derivation of previous results, and is intended as a summary and reformulation. The derivations are based on the work of Faugeras and Mourrain [4] and Triggs [23, 22]. Tables of all the different relations involving the multi-view tensors are given. New results are obtained concerning the independence of the equations used to compute the trifocal and quadrilinear relationships, and methods of choosing those equations in a robust manner. Note to reviewers. This paper was presented at the International Sophus Lie Symposium in Norway in August 1995, and was intended for inclusion in a Springer Lecture Notes proceedings of the conference. Unfortunately, there were continuing delays in the production of those proceedings, and eventually they were abandoned. In the mean time, Anders Heyden discovered and presented similar results at the European Conference on Computer Vision, 1998. For this reason, some of the results here may be familiar. Nevertheless, having a reaonable claim to priority I am submitting this paper for your consideration."
            },
            "slug": "Multilinear-Relationships-between-Coordinates-of-Hartley",
            "title": {
                "fragments": [],
                "text": "Multilinear Relationships between Coordinates of Corresponding Image Points and Lines"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "How the fundamental matrix, F, the trifocal tensor T jk i and the quadrilinear relationship existing between corresponding points in four uncalibrated projective images may be derived in a common framework involving matrix determinants is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144645904"
                        ],
                        "name": "Long Quan",
                        "slug": "Long-Quan",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Quan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Quan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713056"
                        ],
                        "name": "P. Sturm",
                        "slug": "P.-Sturm",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Sturm",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sturm"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6331736,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "b96778a6a7b9344403869dd1adb243b13785e6d1",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the concept of self-calibration of a 1D projective camera from point correspondences, and describe a method for uniquely determining the two internal parameters of a 1D camera, based on the trifocal tensor of three 1D images. The method requires the estimation of the trifocal tensor which can be achieved linearly with no approximation unlike the trifocal tensor of 2D images and solving for the roots of a cubic polynomial in one variable. Interestingly enough, we prove that a 2D camera undergoing planar motion reduces to a 1D camera. From this observation, we deduce a new method for self-calibrating a 2D camera using planar motions. Both the self-calibration method for a 1D camera and its applications for 2D camera calibration are demonstrated on real image sequences."
            },
            "slug": "Self-Calibration-of-a-1D-Projective-Camera-and-Its-Faugeras-Quan",
            "title": {
                "fragments": [],
                "text": "Self-Calibration of a 1D Projective Camera and Its Application to the Self-Calibration of a 2D Projective Camera"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that a 2D camera undergoing planar motion reduces to a 1D camera, and a new method for self-calibrating a2D camera using planar motions is deduced."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732879"
                        ],
                        "name": "L. Torresani",
                        "slug": "L.-Torresani",
                        "structuredName": {
                            "firstName": "Lorenzo",
                            "lastName": "Torresani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Torresani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2217156"
                        ],
                        "name": "Danny B. Yang",
                        "slug": "Danny-B.-Yang",
                        "structuredName": {
                            "firstName": "Danny",
                            "lastName": "Yang",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danny B. Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31973323"
                        ],
                        "name": "E. Alexander",
                        "slug": "E.-Alexander",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Alexander",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Alexander"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1370215,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "85615a5f3604fbe571c8dcdb5701d9e1cc9d96b5",
            "isKey": false,
            "numCitedBy": 307,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel solution for flow-based tracking and 3D reconstruction of deforming objects in monocular image sequences. A non-rigid 3D object undergoing rotation and deformation can be effectively approximated using a linear combination of 3D basis shapes. This puts a bound on the rank of the tracking matrix. The rank constraint is used to achieve robust and precise low-level optical flow estimation without prior knowledge of the 3D shape of the object. The bound on the rank is also exploited to handle occlusion at the tracking level leading to the possibility of recovering the complete trajectories of occluded/disoccluded points. Following the same low-rank principle, the resulting flow matrix can be factored to get the 3D pose, configuration coefficients, and 3D basis shapes. The flow matrix is factored in an iterative manner, looping between solving for pose, configuration, and basis shapes. The flow-based tracking is applied to several video sequences and provides the input to the 3D non-rigid reconstruction task. Additional results on synthetic data and comparisons to ground truth complete the experiments."
            },
            "slug": "Tracking-and-modeling-non-rigid-objects-with-rank-Torresani-Yang",
            "title": {
                "fragments": [],
                "text": "Tracking and modeling non-rigid objects with rank constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A novel solution for flow-based tracking and 3D reconstruction of deforming objects in monocular image sequences using a linear combination of 3D basis shapes and the rank constraint is used to achieve robust and precise low-level optical flow estimation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299436"
                        ],
                        "name": "R. Kaucic",
                        "slug": "R.-Kaucic",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Kaucic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kaucic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9449556,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "37d75d3a961de7e9ae0362abfe9be9cdba66a40a",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A common practice when carrying out self-calibration and Euclidean reconstruction from one or more views is to start with a guess at the principal point of the camera. The general belief is that inaccuracies in the estimation of the principal point do not have a significant effect on the other calibration parameters, or on reconstruction accuracy. It is the purpose of this paper to refute that belief. Indeed, it is demonstrated that the determination of the focal length of the camera is tied up very closely with the estimate of the principal point. Small changes in the estimated (sometimes merely guessed) principal point can cause very large changes in the estimated focal length, and the accuracy of reconstruction. In fact, the relative uncertainty in the focal length is inversely proportional to the distance of the principal point to the epipolar line. This analysis is geometric and exact, rather than experimental."
            },
            "slug": "Sensitivity-of-Calibration-to-Principal-Point-Hartley-Kaucic",
            "title": {
                "fragments": [],
                "text": "Sensitivity of Calibration to Principal Point Position"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "It is demonstrated that the determination of the focallength of the camera is tied up very closely with the estimate of the principal point, and the relative uncertainty in the focal length is inversely proportional to the distance of thePrincipal point to the epipolar line."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144555237"
                        ],
                        "name": "S. Maybank",
                        "slug": "S.-Maybank",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Maybank",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maybank"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123668588,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b326af8af4ca14e5749f49a6c83578344ce4916d",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The projective geometry underlying the ambiguous case of scene reconstruction from image correspondences is developed. The am biguous case arises when reconstruction yields two or more essentially different surfaces in space, each capable of giving rise to the image correspondences. Such surfaces naturally occur in complementary pairs. Ambiguous surfaces are examples of rectangular hyperboloids. Complementary ambiguous surfaces intersect in a space curve of degree four, which splits into two components, namely a twisted cubic (space curve of degree three), and a straight line. For each ambiguous surface compatible with a given set of image correspondences, a complementary surface compatible with the same image correspondences can always be found such that both the original surface and the twisted cubic contained in the intersection of the two surfaces are invariant under the same rotation through 180\u00b0. In consequence, each ambiguous surface is subject to a cubic polynomial constraint. This constraint is the basis of a new proof of the known result that there are, in general, exactly ten scene reconstructions compatible with five given image correspondences. Ambiguity also arises in reconstruction based on image velocities rather than on image correspondences. The two types of ambiguity have m any sim ilarities because image velocities are obtained from image correspondences as a limit, when the distances between corresponding points become small. It is shown that the amount of similarity is restricted, in that when passing from image correspondences to image velocities, some of the detailed geometry of the ambiguous case is lost."
            },
            "slug": "The-projective-geometry-of-ambiguous-surfaces-Maybank",
            "title": {
                "fragments": [],
                "text": "The projective geometry of ambiguous surfaces"
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical Transactions of the Royal Society of London. Series A: Physical and Engineering Sciences"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719901"
                        ],
                        "name": "J. Stolfi",
                        "slug": "J.-Stolfi",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Stolfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stolfi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16393899,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "6c66db0541b67dbd7674f0d413b24564084d3e55",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Oriented projective geometry is a model for geometric computation that combines the elegance of classical projective geometry with the ability to talk about oriented lines and planes, signed angles, line segments, convex figures, and many other concepts that cannot be defined within the classical version. Classical projective geometry is the implicit framework of many geometric computations, since it underlies the well-known homogeneous coordinate representation. It is argued here that oriented projective geometry \u2014 and its analytic model, based on signed homogeneous coordinates \u2014 provide a better foundation for computational geometry than their classical counterparts.\nThe differences between the classical and oriented versions are largely confined to the mathematical formalism and its interpretation. Computationally, the changes are minimal and do not increase the cost and complexity of geometric algorithms. Geometric algorithms that use homogeneous coordinates can be easily converted to the oriented framework at little cost. The necessary changes are largely a matter of paying attention to the order of operands and to the signs of coordinates, which are frequently ignored or left unspecified in the classical framework."
            },
            "slug": "Oriented-projective-geometry-Stolfi",
            "title": {
                "fragments": [],
                "text": "Oriented projective geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is argued here that oriented projective geometry \u2014 and its analytic model, based on signed homogeneous coordinates \u2014 provide a better foundation for computational geometry than their classical counterparts."
            },
            "venue": {
                "fragments": [],
                "text": "SCG '87"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808423"
                        ],
                        "name": "G. Csurka",
                        "slug": "G.-Csurka",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Csurka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2444581"
                        ],
                        "name": "D. Demirdjian",
                        "slug": "D.-Demirdjian",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Demirdjian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Demirdjian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074149379"
                        ],
                        "name": "A. Ruf",
                        "slug": "A.-Ruf",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Ruf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ruf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794229"
                        ],
                        "name": "R. Horaud",
                        "slug": "R.-Horaud",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Horaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Horaud"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1089723,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a76609b9d5e57d4878b00392de7580a253b018d",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a method for estimating the internal parameters of the left and right cameras associated with a stereo image pair. The stereo pair has known epipolar geometry and therefore 3-D projective reconstruction of pairs of matched image points is available. The stereo pair is allowed to move and hence there is a collineation relating the two projective reconstructions computed before and after the motion. We show that this collineation has similar but different parameterizations for general and ground-plane rigid motions and we make explicit the relationship between the internal camera parameters and such a collineation. We devise a practical method for recovering four camera parameters from a single general motion or three camera parameters from a single ground-plane motion. Numerous experiments with simulated, calibrated and natural data validate the calibration method."
            },
            "slug": "Closed-Form-Solutions-for-the-Euclidean-Calibration-Csurka-Demirdjian",
            "title": {
                "fragments": [],
                "text": "Closed-Form Solutions for the Euclidean Calibration of a Stereo Rig"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper describes a method for estimating the internal parameters of the left and right cameras associated with a stereo image pair, and devise a practical method for recovering four camera parameters from a single general motion or three camera parametersFrom a single ground-plane motion."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256432"
                        ],
                        "name": "C. Poelman",
                        "slug": "C.-Poelman",
                        "structuredName": {
                            "firstName": "Conrad",
                            "lastName": "Poelman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Poelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6601890,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d20b0e6a129014f415feb823a8fe5e1f306092b3",
            "isKey": false,
            "numCitedBy": 402,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The factorization method, first developed by Tomasi and Kanade (1992), recovers both the shape of an object and its motion from a sequence of images, using many images and tracking many feature points to obtain highly redundant feature position information. The method robustly processes the feature trajectory information using singular value decomposition (SVD), taking advantage of the linear algebraic properties of orthographic projection. However, an orthographic formulation limits the range of motions the method can accommodate. Paraperspective projection, first introduced by Ohta et al. (1981), is a projection model that closely approximates perspective projection by modeling several effects not modeled under orthographic projection, while retaining linear algebraic properties. Our paraperspective factorization method can be applied to a much wider range of motion scenarios, including image sequences containing motion toward the camera and aerial image sequences of terrain taken from a low-altitude airplane."
            },
            "slug": "A-Paraperspective-Factorization-Method-for-Shape-Poelman-Kanade",
            "title": {
                "fragments": [],
                "text": "A Paraperspective Factorization Method for Shape and Motion Recovery"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work has shown that the paraperspective factorization method can be applied to a much wider range of motion scenarios, including image sequences containing motion toward the camera and aerial image sequences of terrain taken from a low-altitude airplane."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12560473,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "03de8f4f8a3d3080a9001d62ba65ec91f0400aea",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The critical configurations for projective reconstruction from three views are discussed. A set of cameras and points is said to be critical if the projected image points are insufficient to determine the placement of the points and cameras uniquely, up to projective transformation. For two views, the classification of critical configurations is well known - the configuration is critical if and only if the points and camera centres all lie on a ruled quadric. For three views the critical configurations have not been identified previously. In this paper it is shown that for any placement of three given cameras there always exists a critical set consisting of a fourth-degree curve - any number of points on the curve form a critical set for the three cameras. Dual to this result, for a set of seven points there exists a fourth-degree curve such that a configuration of any number of cameras placed on this curve is critical for the set of points. Other critical configurations exist in cases where the points all lie in a plane, or one of the cameras lies on a twisted cubic."
            },
            "slug": "Ambiguous-Configurations-for-3-View-Projective-Hartley",
            "title": {
                "fragments": [],
                "text": "Ambiguous Configurations for 3-View Projective Reconstruction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that for any placement of three given cameras there always exists a critical set consisting of a fourth-degree curve such that a configuration of any number of cameras placed on this curve is critical for the set of points."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772090"
                        ],
                        "name": "P. Giblin",
                        "slug": "P.-Giblin",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Giblin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Giblin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20701132"
                        ],
                        "name": "R. Weiss",
                        "slug": "R.-Weiss",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Weiss",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weiss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121700786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "025a221fae3643214a62c02a1723f49f9c3d618c",
            "isKey": false,
            "numCitedBy": 164,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "THIS PAPER PRESENTS AN ALGORITHM FOR COMPUTING A DEPTH MAP FOR A SMOOTH SURFACE FROM A SEQUENCE OF PROFILE CURVES. THE ALGORITHM REQURIES THAT THE VIEWING DIRECTIONS BE COPLANAR. IN ADDITION FORMULAE ARE DERIVED FOR COMPUTING DIRECTLY THE GAUSS AND MEAN CURVATURES WITHOUT FIRST COMPUTING A DEPTH MAP. WE HAVE USED THE ALGORITHM TO RECONSTRUCT CURVES FROM THEIR PROFILES WITH A HIGH DEGREE OF ACCURACY FROM SYNTHETIC, NOISE-FREE DATA."
            },
            "slug": "Reconstruction-of-Surfaces-from-Profiles-Giblin-Weiss",
            "title": {
                "fragments": [],
                "text": "Reconstruction of Surfaces from Profiles"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The algorithm has been used to reconstruct curves from their professors' studies with a high degree of accuracy from noise-free data."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV 1987"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777539"
                        ],
                        "name": "P. Beardsley",
                        "slug": "P.-Beardsley",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Beardsley",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Beardsley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950884"
                        ],
                        "name": "I. Reid",
                        "slug": "I.-Reid",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Reid",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Reid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48121727"
                        ],
                        "name": "D. W. Murray",
                        "slug": "D.-W.-Murray",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Murray",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. W. Murray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12601296,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "60db280a43f688041d3756b47b532bdfdb438c61",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Demonstrates a method of using nonmetric visual information derived from an uncalibrated active vision system to navigate an autonomous vehicle through free-space regions detected in a cluttered environment. The structure of 3-space is recovered modulo an affine transformation using an uncalibrated active stereo head carried by the vehicle. The plane at infinity, necessary for recovering affine structure from projective structure, is found in a novel manner by making controlled rotations of the head. The structure is composed of 3D points obtained by detecting and matching image corners through the stereo image sequence. Considerable care has been taken to ensure that the processing is reliable, robust and automatic. Driveable regions are determined from the projection of the affine structure onto a plane parallel to the ground determined using projective constructs. Two methods of negotiating the regions are explored. The first introduces metric information to allow control of a Euclidean vehicle. The second uses visual servoing of the active head to navigate in the affinely described free-space regions.<<ETX>>"
            },
            "slug": "Active-visual-navigation-using-non-metric-structure-Beardsley-Reid",
            "title": {
                "fragments": [],
                "text": "Active visual navigation using non-metric structure"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A method of using nonmetric visual information derived from an uncalibrated active vision system to navigate an autonomous vehicle through free-space regions detected in a cluttered environment is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123159999"
                        ],
                        "name": "Chung-Nan Lee",
                        "slug": "Chung-Nan-Lee",
                        "structuredName": {
                            "firstName": "Chung-Nan",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung-Nan Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397908956"
                        ],
                        "name": "Kars Ottenburg",
                        "slug": "Kars-Ottenburg",
                        "structuredName": {
                            "firstName": "Kars",
                            "lastName": "Ottenburg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kars Ottenburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2501393"
                        ],
                        "name": "M. N\u00f6lle",
                        "slug": "M.-N\u00f6lle",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "N\u00f6lle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. N\u00f6lle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5891919,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "9c1ffcfe061720035f5cc21cfbbac927c8cba452",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The major direct solutions to the three-point perspective pose estimation problems are reviewed from a unified perspective. The numerical stability of these three-point perspective solutions are discussed. It is shown that even in cases where the solution is not near the geometric unstable region considerable care must be exercised in the calculation. Depending on the order of the substitutions utilized, the relative error can change over a thousand to one. This difference is due entirely to the way the calculations are performed and not to any geometric structural instability of any problem instance. An analytical method is presented which produces a numerically stable calculation.<<ETX>>"
            },
            "slug": "Analysis-and-solutions-of-the-three-point-pose-Haralick-Lee",
            "title": {
                "fragments": [],
                "text": "Analysis and solutions of the three point perspective pose estimation problem"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that even in cases where the solution is not near the geometric unstable region considerable care must be exercised in the calculation, and an analytical method is presented which produces a numerically stable calculation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713056"
                        ],
                        "name": "P. Sturm",
                        "slug": "P.-Sturm",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Sturm",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sturm"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1699780,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5b1e71b397d62e36dfb77aa0db3ff0d3fd26b8f2",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of self-calibration of a camera whose intrinsic parameters are known, besides the focal length. In the past, algorithms were mainly proposed for estimating two values of the focal length, for two images taken with different zoom. While there exist closed form solutions based on the fundamental matrix, their applicability is limited due to a generic singularity that occurs whenever the optical axes intersect, leading to numerical instabilities in most practical situations. Here, we consider the case of two views with identical focal length. We derive closed form solutions (one quadratic and two linear equations). Their respective singularity conditions are studied analytically and experimental results on their stability are given."
            },
            "slug": "On-focal-length-calibration-from-two-views-Sturm",
            "title": {
                "fragments": [],
                "text": "On focal length calibration from two views"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work considers the problem of self-calibration of a camera whose intrinsic parameters are known, besides the focal length, and derives closed form solutions (one quadratic and two linear equations) for two views with identical focal length."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31210463"
                        ],
                        "name": "S. Bougnoux",
                        "slug": "S.-Bougnoux",
                        "structuredName": {
                            "firstName": "Sylvain",
                            "lastName": "Bougnoux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bougnoux"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206769189,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ab96439d51903bd2fa8fabfd5c5dde5f337b861d",
            "isKey": false,
            "numCitedBy": 275,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "For many practical applications it is important to relax the self-calibration conditions to allow for changing internal camera parameters (e.g. zooming/focusing...). Classical techniques failed for such conditions. We present the available constraints that allow us to right a projective calibration to a Euclidean one. Meanwhile, we found that the estimations of the internal parameters were rather inaccurate. We discuss theoretically this difficulty and above all the resulting effect on the 3D reconstruction. In fact, we show that the uncertainty on the focal length estimation leads to an Euclidean calibration up to a quasi anisotropic homothety whereas the error on the principal point can often be interpreted as a translation. Hopefully, the calibration we come up with, is quite acceptable for reconstruction of models."
            },
            "slug": "From-projective-to-Euclidean-space-under-any-a-of-Bougnoux",
            "title": {
                "fragments": [],
                "text": "From projective to Euclidean space under any practical situation, a criticism of self-calibration"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the uncertainty on the focal length estimation leads to an Euclidean calibration up to a quasi anisotropic homothety whereas the error on the principal point can often be interpreted as a translation."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144645904"
                        ],
                        "name": "Long Quan",
                        "slug": "Long-Quan",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Quan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Quan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10730369,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "65d4958be16e8e782d1207cb650528fba5a10b0d",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a linear algorithm to recover 3D affine shape/motion from line correspondences over three views with uncalibrated affine cameras. The key idea is the introduction of a one-dimensional projective camera. This converts the 3D affine reconstruction of \"lines\" into 2D projective reconstruction of \"points\". Using the full tensorial representation of three uncalibrated 1D views, we prove that the 3D affine reconstruction of lines from minimal data is unique up to a re-ordering of the views. 3D affine line reconstruction can be performed by properly rescaling image coordinates instead of using projection matrices. The algorithm is validated on both simulated and real image sequences."
            },
            "slug": "Uncalibrated-1D-projective-camera-and-3D-affine-of-Quan",
            "title": {
                "fragments": [],
                "text": "Uncalibrated 1D projective camera and 3D affine reconstruction of lines"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Using the full tensorial representation of three uncalibrated 1D views, it is proved that the 3D affine reconstruction of lines from minimal data is unique up to a re-ordering of the views."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678834"
                        ],
                        "name": "G. Newsam",
                        "slug": "G.-Newsam",
                        "structuredName": {
                            "firstName": "Garry",
                            "lastName": "Newsam",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Newsam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144199437"
                        ],
                        "name": "D. Huynh",
                        "slug": "D.-Huynh",
                        "structuredName": {
                            "firstName": "Du",
                            "lastName": "Huynh",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huynh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728401"
                        ],
                        "name": "M. Brooks",
                        "slug": "M.-Brooks",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brooks",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brooks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3170782"
                        ],
                        "name": "H. Pan",
                        "slug": "H.-Pan",
                        "structuredName": {
                            "firstName": "Heping",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Pan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15551622,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "efc78162d463f9d30d85a0233a8125f43ea2f146",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "If su ciently many pairs of corresponding points in a stereo image pair are available to construct the associated fundamental matrix, then it has been shown that 5 relative orientation parameters and 2 focal lengths can be recovered from this fundamental matrix. This paper presents a new and essentially linear algorithm for recovering focal lengths. Moreover the derivation of the algorithm also provides a complete characterisation of all degenerate con gurations in which focal lengths cannot be uniquely recovered. There are two classes of degenerate con gurations: either one of the optical axes of the cameras lies in the plane spanned by the baseline and the other optical axis; or one optical axis lies in the plane spanned by the baseline and the vector that is orthogonal to both the baseline and the other axis. The result that the rst class of con gurations (i.e. ones in which the optical axes are coplanar) is degenerate is of some practical importance since it shows that self-calibration of unknown focal lengths is not possible in certain stereo heads, a con guration widely used for binocular vision systems in robotics."
            },
            "slug": "Recovering-unknown-focal-lengths-in-an-essentially-Newsam-Huynh",
            "title": {
                "fragments": [],
                "text": "Recovering unknown focal lengths in self-calibration: an essentially linear algorithm and degenerate configurations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17964851,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a5fe19cedac17fac92647b6fb385677f47df61f0",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The modulus constraint is a constraint on the position of the plane at in nity ( 1) which applies to the problem of self-calibration in the case of constant internals. For any pair of cameras which are known to have the same internal parameters, the classical modulus constraint is the vanishing of a certain quartic polynomial whose coe cients are determined from the cameras. Given a projective three-view reconstruction, it is of practical interest to recover the plane at in nity by solving for the three parameters of 1. Geometrically this is the problem of intersecting three quartic surfaces in projective space, so one should expect to get 64 solutions. It is not clear how to carry out the process in practice because continuation methods are slow and non-linear optimization may produce a local minimum. This paper presents a new derivation of the classical constraints, and additionally shows how to derive novel cubic constraints which exist for any triple of views. For three views, it is shown how to use the new constraint to classify the 64 = 4 4 4 classical solutions into one spurious (namely the trifocal plane), 21 feasible and 2 21 which must be rejected on physical grounds. The ambiguity is thus reduced from 64 to 21. A numerical algorithm is given to compute all 21 feasible solutions."
            },
            "slug": "Direct-Solution-of-Modulus-Constraints-Schaffalitzky",
            "title": {
                "fragments": [],
                "text": "Direct Solution of Modulus Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper presents a new derivation of the classical constraints of the modulus constraint, and additionally shows how to derive novel cubic constraints which exist for any triple of views."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3083483"
                        ],
                        "name": "D. Nist\u00e9r",
                        "slug": "D.-Nist\u00e9r",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Nist\u00e9r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nist\u00e9r"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15534953,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcbfc756f590801e74bc86002c8a070cef076f53",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers projective reconstruction with a hierarchical computational structure of trifocal tensors that integrates feature tracking and geometrical validation of the feature tracks. The algorithm was embedded into a system aimed at completely automatic Euclidean reconstruction from uncalibrated handheld amateur video sequences. The algorithm was tested as part of this system on a number of sequences grabbed directly from a low-end video camera without editing. The proposed approach can be considered a generalisation of a scheme of [Fitzgibbon and Zisserman, ECCV '98]. The proposed scheme tries to adapt itself to the motion and frame rate in the sequence by finding good triplets of views from which accurate and unique trifocal tensors can be calculated. This is in contrast to the assumption that three consecutive views in the video sequence are a good choice. Using trifocal tensors with a wider span suppresses error accumulation and makes the scheme less reliant on bundle adjustment. The proposed computational structure may also be used with fundamental matrices as the basic building block."
            },
            "slug": "Reconstruction-from-Uncalibrated-Sequences-with-a-Nist\u00e9r",
            "title": {
                "fragments": [],
                "text": "Reconstruction from Uncalibrated Sequences with a Hierarchy of Trifocal Tensors"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "This paper considers projective reconstruction with a hierarchical computational structure of trifocal tensors that integrates feature tracking and geometrical validation of the feature tracks and may also be used with fundamental matrices as the basic building block."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143898851"
                        ],
                        "name": "S. Wolfram",
                        "slug": "S.-Wolfram",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Wolfram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wolfram"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31355518,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6555e4f1ca5bcb835cc77b45b7cdb930fb4f5bf0",
            "isKey": false,
            "numCitedBy": 2543,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This book will be released simultaneously with Release 2.0 of Mathematica and will cover all the new features of Release 2.0. This new edition maintains the format of the original book and is the single most important user guide and reference for Mathematica--all users of Mathematica will need this edition. Includes 16 pages of full-color graphics."
            },
            "slug": "Mathematica-a-system-for-doing-mathematics-by-2nd-Wolfram",
            "title": {
                "fragments": [],
                "text": "Mathematica - a system for doing mathematics by computer, 2nd Edition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This new edition maintains the format of the original book and is the single most important user guide and reference for Mathematica--all users ofMathematica will need this edition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144555237"
                        ],
                        "name": "S. Maybank",
                        "slug": "S.-Maybank",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Maybank",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maybank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13044278,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "fd081e9f1ca2bb5be97be1bf2a31801a6189a456",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Let S be a set of six points in space, let /spl psi/ be any hyperboloid of one sheet containing S, and let I be a sequence of images of S taken by an uncalibrated camera moving over /spl psi/. Then reconstruction from I is subject to a three way ambiguity which is unbroken as long as the optical centre of the camera remains on /spl psi/. Let p be an image of S taken from a point on /spl psi/. The images 'near' p define a tangent space which splits into a direct sum W/sub p//spl oplus/N/sub p//spl oplus/F/sub p/, where W/sub p/ corresponds to images near p for which the ambiguity is maintained, N/sub p/ corresponds to images for which the ambiguity is broken and F/sub p/ corresponds to images which are physically impossible."
            },
            "slug": "Ambiguity-in-reconstruction-from-images-of-six-Maybank-Shashua",
            "title": {
                "fragments": [],
                "text": "Ambiguity in reconstruction from images of six points"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "Reconstruction from I is subject to a three way ambiguity which is unbroken as long as the optical centre of the camera remains on /spl psi/."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14965587,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "9f0829019c57d284c0371b7663bd1f00e547d842",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the special form that the general multi-image tensor formalism takes under the plane + parallax decomposition, including matching tensors and constraints, closure and depth recovery relations, and inter-tensor consistency constraints. Plane + parallax alignment greatly simplifies the algebra, and uncovers the underlying geometric content. We relate plane + parallax to the geometry of translating, calibrated cameras, and introduce a new parallax-factorizing projective reconstruction method based on this. Initial plane + parallax alignment reduces the problem to a single rank-one factorization of a matrix of rescaled parallaxes into a vector of projection centres and a vector of projective heights above the reference plane. The method extends to 3D lines represented by via-points and 3D planes represented by homographies."
            },
            "slug": "Plane+Parallax,-Tensors-and-Factorization-Triggs",
            "title": {
                "fragments": [],
                "text": "Plane+Parallax, Tensors and Factorization"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "The special form that the general multi-image tensor formalism takes under the plane + parallax decomposition is studied, including matching tensors and constraints, closure and depth recovery relations, and inter-tensor consistency constraints."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750195"
                        ],
                        "name": "E. Trucco",
                        "slug": "E.-Trucco",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Trucco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Trucco"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61003302,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "2fdf3b848d2dded13caa0351376dae861a31f640",
            "isKey": false,
            "numCitedBy": 414,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Geometric Invariance in Computer Vision, edited by Joseph L. Mundy and Andrew Zisserman, the MIT Press, 1992, $70.95 in Europe."
            },
            "slug": "Geometric-Invariance-in-Computer-Vision-Trucco",
            "title": {
                "fragments": [],
                "text": "Geometric Invariance in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Geometric Invariance in Computer Vision, edited by Joseph L. Mundy and Andrew Zisserman, the MIT Press, 1992, $70.95 in Europe."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729041"
                        ],
                        "name": "J. Canny",
                        "slug": "J.-Canny",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Canny",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Canny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13284142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec",
            "isKey": false,
            "numCitedBy": 27659,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge."
            },
            "slug": "A-Computational-Approach-to-Edge-Detection-Canny",
            "title": {
                "fragments": [],
                "text": "A Computational Approach to Edge Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "There is a natural uncertainty principle between detection and localization performance, which are the two main goals, and with this principle a single operator shape is derived which is optimal at any scale."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713056"
                        ],
                        "name": "P. Sturm",
                        "slug": "P.-Sturm",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Sturm",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sturm"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1737335,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f12a0828e5efa9786d68395c99e5946bf312d891",
            "isKey": false,
            "numCitedBy": 283,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper sequences of camera motions that lead to inherent ambiguities in uncalibrated Euclidean reconstruction or self-calibration are studied. Our main contribution is a complete, detailed classification of these critical motion sequences (CMS). The practically important classes are identified and their degrees of ambiguity are derived. We also discuss some practical issues, especially concerning the reduction of the ambiguity of a reconstruction."
            },
            "slug": "Critical-motion-sequences-for-monocular-and-Sturm",
            "title": {
                "fragments": [],
                "text": "Critical motion sequences for monocular self-calibration and uncalibrated Euclidean reconstruction"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32163276"
                        ],
                        "name": "T. Boult",
                        "slug": "T.-Boult",
                        "structuredName": {
                            "firstName": "Terrance",
                            "lastName": "Boult",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Boult"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150187409"
                        ],
                        "name": "L. Gottesfeld Brown",
                        "slug": "L.-Gottesfeld-Brown",
                        "structuredName": {
                            "firstName": "L.M.",
                            "lastName": "Gottesfeld Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gottesfeld Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 122389226,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2b3cd93d168408d98601e8ca7ace7906b400a412",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors address the problem of motion segmentation using the singular value decomposition of a feature track matrix. It is shown that, under general assumptions, the number of numerically nonzero singular values can be used to determine the number of motions. Furthermore, motions can be separated using the right singular vectors associated with the nonzero singular values. A relationship is derived between a good segmentation, the number of nonzero singular values in the input and the sum of the number of nonzero singular values in the segments. The approach is demonstrated on real and synthetic examples. The paper ends with a critical analysis of the approach.<<ETX>>"
            },
            "slug": "Factorization-based-segmentation-of-motions-Boult-Brown",
            "title": {
                "fragments": [],
                "text": "Factorization-based segmentation of motions"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Workshop on Visual Motion"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790502"
                        ],
                        "name": "T. Vi\u00e9ville",
                        "slug": "T.-Vi\u00e9ville",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Vi\u00e9ville",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vi\u00e9ville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745498"
                        ],
                        "name": "D. Lingrand",
                        "slug": "D.-Lingrand",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Lingrand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lingrand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18412817,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b0502495aa7ca555ffa659aa14ef141402509401",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In the present paper, we review and complete the equations and the formalism which allow to achieve a minimal parameterization of the retinal displacement for a monocular visual system without calibration."
            },
            "slug": "Using-Singular-Displacements-for-Uncalibrated-Vi\u00e9ville-Lingrand",
            "title": {
                "fragments": [],
                "text": "Using Singular Displacements for Uncalibrated Monocular Visual Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "The equations and the formalism which allow to achieve a minimal parameterization of the retinal displacement for a monocular visual system without calibration are reviewed and complete."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41875245,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "cdd1216d4d3cc42abc20089ed1292304d95cdbea",
            "isKey": false,
            "numCitedBy": 509,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A new theorem is discussed that relates the apparent curvature of the occluding contour of a visual shape to the intrinsic curvature of the surface and the radial curvature. This theorem allows the formulation of general laws for the apparent curvature, independent of viewing distance and regardless of the fact that the rim (the boundary between the visible and invisible parts of the object) is a general, thus twisted, space curve. Consequently convexities, concavities, or inflextions of contours in the retinal image allow the observer to draw inferences about local surface geometry with certainty. These results appear to be counterintuitive, witness to the treatment of the problem by recent authors. It is demonstrated how well-known examples, used to show how concavities and convexities of the contour have no obvious relation to solid shape, are actually good illustrations of the fact that convexities are due to local ovoid shapes, concavities to local saddle shapes."
            },
            "slug": "What-Does-the-Occluding-Contour-Tell-Us-about-Solid-Koenderink",
            "title": {
                "fragments": [],
                "text": "What Does the Occluding Contour Tell Us about Solid Shape?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is demonstrated how well-known examples, used to show how concavities and convexities of the contour have no obvious relation to solid shape, are actually good illustrations of the fact that conveXities are due to local ovoid shapes, concavity to local saddle shapes."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19144160,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "8ceca527eb7df6c08112ba09c9f3c16cf0cf6ea1",
            "isKey": false,
            "numCitedBy": 500,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe progress in completely automatically recovering 3D scene structure together with 3D camera positions from a sequence of images acquired by an unknown camera undergoing unknown movement."
            },
            "slug": "Automatic-Camera-Recovery-for-Closed-or-Open-Image-Fitzgibbon-Zisserman",
            "title": {
                "fragments": [],
                "text": "Automatic Camera Recovery for Closed or Open Image Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "Progress in completely automatically recovering 3D scene structure together with 3D camera positions from a sequence of images acquired by an unknown camera undergoing unknown movement is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115246415"
                        ],
                        "name": "Duane Brown",
                        "slug": "Duane-Brown",
                        "structuredName": {
                            "firstName": "Duane",
                            "lastName": "Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Duane Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 56490170,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "1150007b62a3c7dac99c2c8f85c63bfab74891af",
            "isKey": false,
            "numCitedBy": 1445,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "For highest accuracies i t i s necessary in close range photogrammetry to account for the variation of lens distortion wi th in the photographic Jield. A theory to accomplish this i s developed along wi th a practical method for calibrating radial and decenfering distortion of close-range cameras. T h i s method, the analytical plumb line method, i s applied in a n experimental investigation leading to confirmation of the validity of the theoretical development accounting for variation of distortion wi th object distance. issue. Our concern in the present paper is with EXTENSION OF MAGILL'S MODEL one specific of close-range photoMagill (1955) derived and experimentally grammetry, t h a t of camera calibration. I n verified a formula which accounts for the particular, we shall be concerned with t h e of distortion with changing focus. variation of distortion within the photoMagill's result can be expressed as follows. grammetric model. This becomes a consideraLet: tion of increasing importance a s magnification increases. T h e essence of the problem as f =focal length of lens, s=distance of object plane for which lens is pointed ou t in Brown (1962) is a s follows: focussed, ~ ~ d i ~ l distortion is normally calibrated at 8ro=distortion function for focus on object infinity focus. Accuracies of zk2 microns rms plane at distance s, or better for the distortion function are not Gr,=distortion function of lens for infinity difficult to obtain from a rigorous stellar calibrafocus, tion. . H ~ ~ ~ ~ ~ ~ , optical ray tracing theory tells =distortion function of lens for inverted us that Gaussian radial distortion is a function infinity focus (i.e., distortion, if the lens is of object distance. Thus when the focal plane is reversed so that front element becomes set for a sensibly finite object distance, it is rear element and vice versa). necessary to employ the distortion function appropriate to that distance. Actually, i t is Then the magnificati0n the lens for the ject plane a t s is * Presented a t the Symposium on Close-Range Photogrammetry, Urbana, Illinois, January 1971. ma = f / ( s f )"
            },
            "slug": "Close-Range-Camera-Calibration-Brown",
            "title": {
                "fragments": [],
                "text": "Close-Range Camera Calibration"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The concern in the present paper is with extensions of photoMagill (1955) derived and experimentally grammetry, a practical method for calibrating radial and decenfering distortion of close-range cameras and the validity of the theoretical development accounting for variation of distortion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 972888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "278c9a78d4505cfaf6b709df364dbd1206a017c1",
            "isKey": false,
            "numCitedBy": 15951,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing"
            },
            "slug": "Random-sample-consensus:-a-paradigm-for-model-with-Fischler-Bolles",
            "title": {
                "fragments": [],
                "text": "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "New results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form that provide the basis for an automatic system that can solve the Location Determination Problem under difficult viewing."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145504846"
                        ],
                        "name": "Martin Armstrong",
                        "slug": "Martin-Armstrong",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Armstrong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Armstrong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14404087,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "5252d5c42c75fb5aa3faf9df880510d66dbd562c",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for determining affine and metric calibration of a camera with unchanging internal parameters undergoing planar motion. It is shown that affine calibration is recovered uniquely, and metric calibration up to a two fold ambiguity."
            },
            "slug": "Self-Calibration-from-Image-Triplets-Armstrong-Zisserman",
            "title": {
                "fragments": [],
                "text": "Self-Calibration from Image Triplets"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is shown that affine calibration is recovered uniquely, and metric calibration up to a two fold ambiguity."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690237"
                        ],
                        "name": "G. Taubin",
                        "slug": "G.-Taubin",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Taubin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Taubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16553641,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "27a790a0ca254006fbe37d41e1751516911607ca",
            "isKey": false,
            "numCitedBy": 1135,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "The author addresses the problem of parametric representation and estimation of complex planar curves in 2-D surfaces in 3-D, and nonplanar space curves in 3-D. Curves and surfaces can be defined either parametrically or implicitly, with the latter representation used here. A planar curve is the set of zeros of a smooth function of two variables x-y, a surface is the set of zeros of a smooth function of three variables x-y-z, and a space curve is the intersection of two surfaces, which are the set of zeros of two linearly independent smooth functions of three variables x-y-z For example, the surface of a complex object in 3-D can be represented as a subset of a single implicit surface, with similar results for planar and space curves. It is shown how this unified representation can be used for object recognition, object position estimation, and segmentation of objects into meaningful subobjects, that is, the detection of 'interest regions' that are more complex than high curvature regions and, hence, more useful as features for object recognition. >"
            },
            "slug": "Estimation-of-Planar-Curves,-Surfaces,-and-Space-by-Taubin",
            "title": {
                "fragments": [],
                "text": "Estimation of Planar Curves, Surfaces, and Nonplanar Space Curves Defined by Implicit Equations with Applications to Edge and Range Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown how this unified representation can be used for object recognition, object position estimation, and segmentation of objects into meaningful subobjects, that is, the detection of 'interest regions' that are more complex than high curvature regions and, hence, more useful as features for object Recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2592057"
                        ],
                        "name": "B. Bascle",
                        "slug": "B.-Bascle",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Bascle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bascle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17051792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23c8572f4431b21f0a2cb8fd7655d513410500b4",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore the application of facial tracking to automated re-animation. To this end, it is necessary to recover both head-pose and facial expression from the facial movement of a performer. However, both effects are coupled. This is a serious problem, which previous studies haven't fully considered. The solution to this interaction problem proposed here is to solve explicitly, at each timestep, for pose and expression variables. In principle this is a nonlinear inverse problem. However, appropriate parameterisation of pose in terms of affine transformations with parallax, and of expression in terms of key-frames, reduces the problem to a bilinear one. This can then be solved directly by Singular Value Decomposition. Thus actor-driven animation has ben implemented in real-time, at video field-rate, using two Indy desktop workstations."
            },
            "slug": "Separability-of-pose-and-expression-in-facial-and-Bascle-Blake",
            "title": {
                "fragments": [],
                "text": "Separability of pose and expression in facial tracking and animation"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work explores the application of facial tracking to automated re-animation in real-time, at video field-rate, using two Indy desktop workstations, and proposes a solution to solve explicitly, at each timestep, for pose and expression variables."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742208"
                        ],
                        "name": "M. Pollefeys",
                        "slug": "M.-Pollefeys",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Pollefeys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pollefeys"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60108003,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6af44c2575f2ffa4671e24837653169586aba02d",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 311,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesisdiscussesthe possibility to obtain threedimensionalreconstructionsof scenesfrom imagesequences.Traditional approachesare basedon a preliminary calibrationof thecamerasetup.This,however, is notalwayspossibleor practical.The goalof thiswork wasto investigatehow thiscalibrationconstraintcouldberelaxed. Theapproachwastwofold. First,theproblemof self-calibrationwasstudied.This is anapproachwhich retrievesthecalibrationfrom theimagesequenceonly. Several new methodswereproposed.Thesemethodswerevalidatedonbothrealandsynthetic data. The first methodis a stratifiedapproachwhich assumesconstantcalibration parametersduringtheacquisitionof theimages.A secondmethodis morepragmatic andallowssomeparametersto vary. Thisapproachmakesit possibleto dealwith the zoomandfocusavailableonmostcameras. Theotherimportantpartof thiswork consistedof developinganautomaticsystem for 3D acquisitionfrom imagesequences. This wasachievedby combining,adapting andintegratingseveralstate-of-the-art algorithmswith thenewly developedselfcalibrationalgorithms.Theresultingsystemoffersanunprecedented flexibility for the acquisitionof realisticthree-dimensional models.Thevisualquality of themodelsis very high. Themetricqualitieswereverifiedthroughseveralvalidationexperiments. Thissystemwassuccesfullyappliedto anumberof applications."
            },
            "slug": "Self-calibration-and-metric-3d-reconstruction-from-Pollefeys",
            "title": {
                "fragments": [],
                "text": "Self-calibration and metric 3d reconstruction from uncalibrated image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work investigated the possibility to obtain threedimensionalreconstructions of scenes from imagesences from imagesequences using state-of-the-art algorithms with thenewly developed self-calibrationalgorithms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925316"
                        ],
                        "name": "M. Pilu",
                        "slug": "M.-Pilu",
                        "structuredName": {
                            "firstName": "Maurizio",
                            "lastName": "Pilu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pilu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843592"
                        ],
                        "name": "Robert B. Fisher",
                        "slug": "Robert-B.-Fisher",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fisher",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert B. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1003509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3c27e9811b8ed9ec553277eb269265529d37bfa",
            "isKey": false,
            "numCitedBy": 775,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new efficient method for fitting ellipses to scattered data. Previous algorithms either fitted general conics or were computationally expensive. By minimizing the algebraic distance subject to the constraint 4ac-b/sup 2/=1 the new method incorporates the ellipticity constraint into the normalization factor. The new method combines several advantages: 1) it is ellipse-specific so that even bad data will always return an ellipse; 2) it can be solved naturally by a generalized eigensystem, and 3) it is extremely robust, efficient and easy to implement. We compare the proposed method to other approaches and show its robustness on several examples in which other nonellipse-specific approaches would fail or require computationally expensive iterative refinements."
            },
            "slug": "Direct-least-squares-fitting-of-ellipses-Fitzgibbon-Pilu",
            "title": {
                "fragments": [],
                "text": "Direct least squares fitting of ellipses"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper presents a new efficient method for fitting ellipses to scattered data that is ellipse-specific so that even bad data will always return an ellipso, and can be solved naturally by a generalized eigensystem."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2556432"
                        ],
                        "name": "St\u00e9phane Laveau",
                        "slug": "St\u00e9phane-Laveau",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Laveau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "St\u00e9phane Laveau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20020983,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "f78ad60964f4f0dfa0062c23b24ede627636902e",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Cette these developpe une approche basee sur la geometrie projective pour analyser et traiter des sequences d'images obtenues avec une camera mobile. Les derivations et demonstrations sont faites sans supposer qu'une information a priori est disponible sur les images, que ce soit sur le mouvement de la camera ou sur leurs parametres intrinseques, comme la distance focale ou les points principaux. Il peut meme s'agir de cameras differentes. La seule hypothese est que la scene est rigide."
            },
            "slug": "G\u00e9om\u00e9trie-d'un-syst\u00e8me-de-N-cam\u00e9ras-:-th\u00e9orie,-et-a-Laveau",
            "title": {
                "fragments": [],
                "text": "G\u00e9om\u00e9trie d'un syst\u00e8me de N cam\u00e9ras : th\u00e9orie, estimation et applications. (Geometry of a System of n Cameras. Theory. Estimation. Applications)"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "Cette these developpe une approche basee sur la geometrie projective pour analyser et traiter des sequences d'images obtenues avec une camera mobile avec un mouvement de la camera ou sur leurs parametres intrinseques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144555237"
                        ],
                        "name": "S. Maybank",
                        "slug": "S.-Maybank",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Maybank",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maybank"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 3064449,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "b79c870e3e59637cdd002125adc8f9cf9a06d818",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "When the geometry of 3D space is reconstructed from a pair of views, using the \\Fundamental matrix\" as the object of analysis, then it is known (as early as the 1940s) that there exists a \\critical surface\" for which the solution of 3-space is ambiguous. We show that when 3-space is reconstructed from a triplet of views, using the \\Trilinear Tensor\" as the object of analysis, there are no critical surfaces. In addition to theoretical interest of solving an open problem, this result has profound practical signiicance. The numerical instability associated with Structure from Motion is largely attributed to the existence of \\critical volumes\" that arise from the existence of critical surfaces coupled with errors in the image measurements. The lack of critical surfaces in the context of three views (provided that the trilinear tensor is used) suggests that better stability in the presence of errors can be gained."
            },
            "slug": "Degenerate-n-Point-Configura-tions-of-Three-Views:-Shashua-Maybank",
            "title": {
                "fragments": [],
                "text": "Degenerate n Point Configura-tions of Three Views: Do Critical Surfaces Exist"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808423"
                        ],
                        "name": "G. Csurka",
                        "slug": "G.-Csurka",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Csurka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2788557"
                        ],
                        "name": "C. Zeller",
                        "slug": "C.-Zeller",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Zeller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Zeller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51064498"
                        ],
                        "name": "Zhengyou Zhang",
                        "slug": "Zhengyou-Zhang",
                        "structuredName": {
                            "firstName": "Zhengyou",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengyou Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 23172963,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "68361be35dcc5e0419c9453986b8afce0a4b9d8a",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper deals with the analysis of the uncertainty of the fundamental matrix. The basic idea is to compute the fundamental matrix and its uncertainty at the same time. We give two different methods. The first one is a statistical approach. As in all statistical methods the precision of the results depends on the number of analyzed samples. This means that we can always improve our results if we increase the number of samples but this process is very time consuming. Alternatively, we propose a much simpler method which gives analytical results which are close to the results of the statistical method. Experiments with synthetic and real data have been conducted to validate the proposed methods. At the end of the paper, we provide three applications of the estimated uncertainty of the fundamental matrix: definition of the epipolar band for stereo matching, projective reconstruction, and self-calibration."
            },
            "slug": "Characterizing-the-Uncertainty-of-the-Fundamental-Csurka-Zeller",
            "title": {
                "fragments": [],
                "text": "Characterizing the Uncertainty of the Fundamental Matrix"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Two different methods to compute the fundamental matrix and its uncertainty at the same time are given and the definition of the epipolar band for stereo matching, projective reconstruction, and self-calibration is provided."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713563"
                        ],
                        "name": "F. Kahl",
                        "slug": "F.-Kahl",
                        "structuredName": {
                            "firstName": "Fredrik",
                            "lastName": "Kahl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kahl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38158996,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "28da5f3e9063d460fffbba3b64fc2853a57a52db",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The motions that lead to ambiguous Euclidean reconstructions in auto-calibration are investigated. Several auto-calibration constraints are considered: vanishing skew, known aspect ratio and internally calibrated cameras except for unknown focal lengths. We give a complete description of such critical motions in terms of algebraic manifolds and, in many cases, an explicit, geometric description for any number of cameras. For example, in the case of internally calibrated cameras except for unknown focal lengths, the only motions for which an affine reconstruction is ambiguous are either (i) rotations around (at most) two fired camera centres, or (ii) a planar motion on a conic with the optical axis tangent to the conic, or (iii) translation along the optical axis with arbitrary rotations around the optical axis. Moreover some practically important cases are also discussed."
            },
            "slug": "Critical-motions-and-ambiguous-Euclidean-in-Kahl",
            "title": {
                "fragments": [],
                "text": "Critical motions and ambiguous Euclidean reconstructions in auto-calibration"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The motions that lead to ambiguous Euclidean reconstructions in auto-calibration are investigated and a complete description in terms of algebraic manifolds and, in many cases, an explicit, geometric description for any number of cameras is given."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45530875,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "1e369fed47bd3e3442486f376576022ec9411789",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 104,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction: Accurate Measurements from Images. Why use Vision? Why is Visual Metrology Hard? Applications and Examples. Summary.- Related Work: Introduction. Using Images for Measuring and Reconstruction.- Background Geometry and Notation: Introduction. Notation. Camera Models and Perspective Mappings. Radial Distortion Correction. Vanishing Points and Vanishing Lines. Uncertainty Analysis.- Metrology on Planes: Estimating the Homography. Uncertainty Analysis. Application - A Plane Measuring Device. Duality and Homologies. Single View Metrology: Introduction. Geometry. Algebraic Representation. Uncertainty Analysis. Three-Dimensional Metrology from a Single View. Applications. Missing Base Point.- Metrology from Planar Parallax: Introduction. Background. Geometry and Duality. Scene Reconstruction. Uncertainty Analysis.- Gallery of Examples: Introduction. Reconstruction from Photographs. Reconstruction from Paintings. Discussion.- Conclusion: Summary. Discussion. Future Work.- Metrology on Planes, Computing Homography Uncertainty.- Maximum Likelehood Estimation of End Points for Isotropic Uncertainties.- Single View Metrology, Variance of Distance Between Planes.- Single View Metrology, Variance of the Affine Parameter alpha.- Metrology form Planar Parallax, Derivations.- Metrology form Planar Parallax, Variance of Distances.- Index."
            },
            "slug": "Accurate-Visual-Metrology-from-Single-and-Multiple-Criminisi",
            "title": {
                "fragments": [],
                "text": "Accurate Visual Metrology from Single and Multiple Uncalibrated Images"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work focuses on three-Dimensional Metrology from a Single View, which combines Geometry and Duality with Camera Models and Perspective Mappings, and Applications - A Plane Measuring Device."
            },
            "venue": {
                "fragments": [],
                "text": "Distinguished Dissertations"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059865207"
                        ],
                        "name": "W. B\u00f6hm",
                        "slug": "W.-B\u00f6hm",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "B\u00f6hm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. B\u00f6hm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2518881"
                        ],
                        "name": "H. Prautzsch",
                        "slug": "H.-Prautzsch",
                        "structuredName": {
                            "firstName": "Hartmut",
                            "lastName": "Prautzsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Prautzsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5216863,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "9786356974cb3c7f21b3c4e77816cfe19cd9fb5f",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This book is a comprehensive tool both for self-study and for use as a text in classical geometry. It explains the concepts that form the basis for computer-aided geometric design."
            },
            "slug": "Geometric-concepts-for-geometric-design-B\u00f6hm-Prautzsch",
            "title": {
                "fragments": [],
                "text": "Geometric concepts for geometric design"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This book explains the concepts that form the basis for computer-aided geometric design and is a comprehensive tool for self-study and for use as a text in classical geometry."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40166275"
                        ],
                        "name": "D. Liebowitz",
                        "slug": "D.-Liebowitz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Liebowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Liebowitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 117237793,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "f417d0fe108282f51ad0965a48d498f76f7af955",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "Thisthesisaddresses theissuesof combiningcameracalibrationconstraintsfromvarioussources andreconstructingscenegeometryfrom singleandmultiple views. A geometricapproachis taken, associatingbothstructurerecovery andcalibrationwith geometricentities. Threesourcesof calibrationconstraintsareconsidered:sceneconstraints,suchas the parallelism andorthogonalityof lines, constraintsfrom partial knowledgeof cameraparameters, and constraintsderivedfrom themotionbetweenviews. First, methodsof rectifying theprojective distortionin an imagedplaneareexamined.Metric rectificationconstraintsaredevelopedby constrainingtheimagedplanecircularpoints. Theinternalcameraparametersareassociatedwith theabsoluteconic. It is shown how imaged planecircular pointsconstrainthe imageof the absoluteconic, andareconstrainedby a known absoluteconic in return. A methodof usingplaneswith known metric structureasa calibration objectis developed. Next, calibrationandreconstructionfrom singleviewsis addressed. A well known configuration of the vanishingpointsof threeorthogonaldirectionsandknowledgethat the camerahassquare pixels is expressedgeometricallyandsubjectedto degenerac y anderroranalysis.Thesquarepixel constraintis shown to be geometricallyequivalent to treatingthe imageplaneas a metric scene plane. Useof thevanishingpointconfigurationis extendedto two views,wherethreevanishingpoints and known epipolargeometrydefinea threedimensionalaffine reconstruction.Calibrationand metricreconstructionfollows similarly to thesingleview case,with theadditionof auto-calibration constraintsfrom themotionbetweenviews. Theauto-calibrationconstraintsarederived from the geometricrepresentationof the squarepixel constraints,by transferringthe imageplanecircular points betweenviews. Degeneratecasesfor constraintsfrom squarepixels and camerashaving identicalinternalparametersaredescribed. Finally, a constrainton the metric rectificationof an affine reconstructionfrom the relative lengthsof a pair of 3D line segmentsis developed. The constraintis appliedto humanmotion capturefrom apairof affine cameras. Dedication For my father , FrederickLiebowitz. Acknowledgements My yearsin Oxfordhavebeenanapprenticeshipunderamasterof thecraft,Andrew Zisserman.His insightandguidancehave shapedthis thesis,andI remaindeeplygratefulfor all thathehastaught me. Andrew Fitzgibbonhasbeena greatsourceof help in all softwaremattersandalsopatiently explaineda greatdealof vision to me. Most of all I would like to thankhim for his boundlessand infectiousenthusiasm. Mostof thelastyearwasspentasaguestattheRoyal Instituteof Technology in Stockholm. I would like to thankStefan Carlssonfor makingthis a thoroughlyrewardingand enjoyableexperience. I learneda greatdealfrom my colleagues, andfriends,in theVisualGeometryGroup.FredSchaffalitzky, Phil Pritchett,AntonioCriminisi, David Capel,Geof CrossandNic Pillow createda lively environmentfor researchthatI continueto miss.I would alsolike to thankEric Hayman,Matthew BryantandSebastienRougeauxfor proofreadingpartsof this thesis."
            },
            "slug": "Camera-Calibration-and-Reconstruction-of-Geometry-Liebowitz",
            "title": {
                "fragments": [],
                "text": "Camera Calibration and Reconstruction of Geometry from Images"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This thesis addresses the issues of combiningcameracalibrationconstraints fromvarioussources andreconstructingscenegeometry from single andmultiple views, and shows how thesquarepixel constraint is shown to be geometricallyequivalent to treating the imageplane as a metric scene plane."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9003443"
                        ],
                        "name": "T. Papadopoulo",
                        "slug": "T.-Papadopoulo",
                        "structuredName": {
                            "firstName": "Th\u00e9odore",
                            "lastName": "Papadopoulo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Papadopoulo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 427508,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cb4f2336c52c59e6c67a1fdadeb65b1fdc3bb364",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how to use the Grassmann\u2013Cayley algebra to model systems of one, two and three cameras. We start with a brief introduction of the Grassmann\u2013Cayley or double algebra and proceed to demonstrate its use for modelling systems of cameras. In the case of three cameras, we give a new interpretation of the trifocal tensors and study in detail some of the constraints that they satisfy. In particular we prove that simple subsets of those constraints characterize the trifocal tensors, in other words, we give the algebraic equations of the manifold of trifocal tensors."
            },
            "slug": "Grassman\u2013Cayley-algebra-for-modelling-systems-of-of-Faugeras-Papadopoulo",
            "title": {
                "fragments": [],
                "text": "Grassman\u2013Cayley algebra for modelling systems of cameras and the algebraic equations of the manifold of trifocal tensors"
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical Transactions of the Royal Society of London. Series A: Mathematical, Physical and Engineering Sciences"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815078"
                        ],
                        "name": "S. Avidan",
                        "slug": "S.-Avidan",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Avidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Avidan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1008054,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6cb77180bd3ac9c87dc392c82f49cbccda46fe3e",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new function that operates on fundamental matrices across a sequence of views. The operation, we call \"threading\", connects two consecutive fundamental matrices using the trifocal tensor as the connecting thread. The threading operation guarantees that consecutive camera matrices are consistent with a unique 3D model, without ever recovering a 3D model. Applications include recovery of camera ego-motion from a sequence of views, image stabilization across a sequence, and multi-view image based rendering."
            },
            "slug": "Threading-Fundamental-Matrices-Avidan-Shashua",
            "title": {
                "fragments": [],
                "text": "Threading Fundamental Matrices"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Applications include recovery of camera ego-motion from a sequence of views, image stabilization across a sequence, and multi-view image based rendering."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744288"
                        ],
                        "name": "P. Gill",
                        "slug": "P.-Gill",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Gill",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143873253"
                        ],
                        "name": "W. Murray",
                        "slug": "W.-Murray",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Murray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Murray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122441374,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "7859a731f887213f85e120f421278c52f539949b",
            "isKey": false,
            "numCitedBy": 530,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a modification to the Gauss\u2013Newton method for the solution of nonlinear least-squares problems. The new method seeks to avoid the deficiencies in the Gauss\u2013Newton method by improving, when necessary, the Hessian approximation by specifically including or approximating some of the neglected terms. The method seeks to compute the search direction without the need to form explicitly either the Hessian approximation or a factorization of this matrix. The benefits of this are similar to that of avoiding the formation of the normal equations in the Gauss-Newton method. Three algorithms based on this method are described; one which assumes that second derivative information is available and two which only assume first derivatives can be computed."
            },
            "slug": "Algorithms-for-the-Solution-of-the-Nonlinear-Gill-Murray",
            "title": {
                "fragments": [],
                "text": "Algorithms for the Solution of the Nonlinear Least-Squares Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The new method seeks to avoid the deficiencies in the Gauss\u2013Newton method by improving, when necessary, the Hessian approximation by specifically including or approximating some of the neglected terms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105872"
                        ],
                        "name": "F. Bookstein",
                        "slug": "F.-Bookstein",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Bookstein",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bookstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120981329,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1f28637a8618fa76b4052f04293ddc0cf0c5b9b4",
            "isKey": false,
            "numCitedBy": 569,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Fitting-conic-sections-to-scattered-data-Bookstein",
            "title": {
                "fragments": [],
                "text": "Fitting conic sections to scattered data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1941450"
                        ],
                        "name": "P. Sampson",
                        "slug": "P.-Sampson",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Sampson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sampson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 205044984,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "57aa09e616382c8b111b8e2b6b36ebb9aa0a2d12",
            "isKey": false,
            "numCitedBy": 397,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Fitting-conic-sections-to-\"very-scattered\"-data:-An-Sampson",
            "title": {
                "fragments": [],
                "text": "Fitting conic sections to \"very scattered\" data: An iterative refinement of the bookstein algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Image Process."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145104875"
                        ],
                        "name": "T. Buchanan",
                        "slug": "T.-Buchanan",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Buchanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Buchanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 635260,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "35978861094d928b95f64238cc183a1b81756657",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-twisted-cubic-and-camera-calibration-Buchanan",
            "title": {
                "fragments": [],
                "text": "The twisted cubic and camera calibration"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402942224"
                        ],
                        "name": "P. Zsombor-Murray",
                        "slug": "P.-Zsombor-Murray",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Zsombor-Murray",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Zsombor-Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2062742120"
                        ],
                        "name": "M. John",
                        "slug": "M.-John",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "John",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. John"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121879994"
                        ],
                        "name": "D. Hayes",
                        "slug": "D.-Hayes",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hayes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hayes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145326299"
                        ],
                        "name": "M. Husty",
                        "slug": "M.-Husty",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Husty",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Husty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4121889,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b241746e7bea5390b1c2bb79947fac40294bf991",
            "isKey": false,
            "numCitedBy": 305,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "THIS book continues the translation of Klein's \u201cElementar Mathematik\u201d which Messrs. Hedrick and Noble began with their translation of the volume on arithmetic, algebra, and analysis. The volume under review is that devoted to geometry. It cannot be claimed that the translation is perfect; some sentences are English only in the sense that English words are used, but in construction they are essentially German, and there are some eccentricities in spelling, for example, \u201cparellelopiped\u201d. There are also some slips which may irritate the reader: for example, on p. 180 a footnote reads, \u201cIn the Sixth Memoir on Quantities [sic], already cited (p. 145),\u201d and it appears that the reference is to Cayley's memoir on quantics which is correctly quoted on p. 134, not p. 145.Elementary Mathematics from an Advanced Standpoint GeometryFelix Klein. Translated from the third German edition by E. R. Hedrick and Prof. C. A. Noble. Pp. ix + 214. (London: Macmillan and Co., Ltd., 1939.) 15s. net."
            },
            "slug": "Elementary-Mathematics-from-an-Advanced-Standpoint-Zsombor-Murray-John",
            "title": {
                "fragments": [],
                "text": "Elementary Mathematics from an Advanced Standpoint"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1940
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145104875"
                        ],
                        "name": "T. Buchanan",
                        "slug": "T.-Buchanan",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Buchanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Buchanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18273111,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "51cb56c79eb525596e9e97c7791acf89d1b4cc6d",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the geometrical limitations of algorithms for 3D reconstruction which use corresponding line tokens. In addition to announcing a description of the general critical set, we analyse the configurations defeating the Liu-Huang algorithm and study the relations between these sets."
            },
            "slug": "Critical-Sets-for-3D-Reconstruction-Using-Lines-Buchanan",
            "title": {
                "fragments": [],
                "text": "Critical Sets for 3D Reconstruction Using Lines"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The general critical set is described and the configurations defeating the Liu-Huang algorithm are analysed to study the relations between these sets."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32979967"
                        ],
                        "name": "I. Sutherland",
                        "slug": "I.-Sutherland",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Sutherland",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sutherland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3191926,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "47f2261792cef069622607ba74bf7e3178651667",
            "isKey": false,
            "numCitedBy": 2234,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "The Sketchpad system makes it possible for a man and a computer to converse rapidly through the medium of line drawings. Heretofore, most interaction between man and computers has been slowed down by the need to reduce all communication to written statements that can be typed; in the past, we have been writing letters to rather than conferring with our computers. For many types of communication, such as describing the shape of a mechanical part or the connections of an electrical circuit, typed statements can prove cumbersome. The Sketchpad system, by eliminating typed statements (except for legends) in favor of line drawings, opens up a new area of man-machine communication."
            },
            "slug": "Sketchpad:-a-man-machine-graphical-communication-Sutherland",
            "title": {
                "fragments": [],
                "text": "Sketchpad: a man-machine graphical communication system"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The Sketchpad system makes it possible for a man and a computer to converse rapidly through the medium of line drawings, and opens up a new area of man-machine communication."
            },
            "venue": {
                "fragments": [],
                "text": "AFIPS '63 (Spring)"
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713056"
                        ],
                        "name": "P. Sturm",
                        "slug": "P.-Sturm",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Sturm",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sturm"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9091765,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "id": "afdbdce1f7e817cafb2efa903204fcb3b0ef4182",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Cette these concerne la reconstruction tridimensionnelle d'objets a partir d'images prises par des cameras. Le schema classique s'appuie sur un calibrage hors ligne des cameras. Ce calibrage n'est malheureusement pas toujours possible (besoin d'un equipement special) et des applications dynamiques requierent frequemment une mise a jour du calibrage au vol. Il est donc clairement souhaitable de pouvoir s'affranchir du besoin d'un calibrage hors ligne. Dans cette these, nous nous concentrons d'une part sur des methodes de reconstruction non calibree et d'autre part sur le concept de calibrage en ligne ou auto-calibrage. Nous tachons d'obtenir des mesures tridimensionnelles meme avec des images prises par des cameras non calibrees. Les informations obtenues ne sont pas de nature metrique, mais elles sont neanmoins exploitables pour des taches de reconnaissance d'objets ou d'asservissement de robots. Nous avons developpe plusieurs methodes pratiques pour la reconstruction tridimensionnelle non calibree. L'auto-calibrage consiste a calibrer une camera uniquement a partir d'images d'objets inconnus. Les images prises au cours d'une application peuvent donc etre utilisees simultanement pour l'application elle-meme et pour le calibrage de la camera. Notre contribution majeure dans ce domaine est une etude des conditions de degenerescence pour l'auto-calibrage. Le probleme de degenerescence s'avere apparaitre frequemment en pratique et notre etude permet d'eviter les mouvements de camera qui causent l'instabilite de l'auto-calibrage."
            },
            "slug": "Vision-3D-non-calibr\u00e9e-:-contributions-\u00e0-la-et-des-Sturm",
            "title": {
                "fragments": [],
                "text": "Vision 3D non calibr\u00e9e : contributions \u00e0 la reconstruction projective et \u00e9tude des mouvements critiques pour l'auto-calibrage. (Uncalibrated 3D Vision: Contributions to Projective Reconstruction and Study of the Critical Motions for Self-Calibration)"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Le probleme de degenerescence s'avere apparaitre frequemment en pratique and notre etude permet d'eviter les mouvements de camera qui causent l'instabilite of l'auto-calibrage."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6354441,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "94930b7aefcaa413c0fcc8dd7a061769f950f018",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The purpose of this paper is to give a specific form for Kruppa's equations in terms of the fundamental matrix. Kruppa's equations can be written explicitly in terms of the singular value decomposition (SVD) of the fundamental matrix."
            },
            "slug": "Kruppa's-Equations-Derived-from-the-Fundamental-Hartley",
            "title": {
                "fragments": [],
                "text": "Kruppa's Equations Derived from the Fundamental Matrix"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Kruppa's equations can be written explicitly in terms of the singular value decomposition (SVD) of the fundamental matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102372669"
                        ],
                        "name": "J. Semple",
                        "slug": "J.-Semple",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Semple",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Semple"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40757850"
                        ],
                        "name": "G. T. Kneebone",
                        "slug": "G.-T.-Kneebone",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Kneebone",
                            "middleNames": [
                                "Thomas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. T. Kneebone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121269628,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9be07c4dddca42f70fa193ac2cbca10e42fbb9a9",
            "isKey": false,
            "numCitedBy": 796,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "PART 1: THE ORIGINS AND DEVELOPMENT OF GEOMETRICAL KNOWLEDGE PART 2: ABSTRACT PROJECTIVE GEOMETRY"
            },
            "slug": "Algebraic-Projective-Geometry-Semple-Kneebone",
            "title": {
                "fragments": [],
                "text": "Algebraic Projective Geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This chapter discusses the origins and development of chemical knowledge, and the role of atoms and molecules in the development of knowledge."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1953
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682208"
                        ],
                        "name": "K. Kanatani",
                        "slug": "K.-Kanatani",
                        "structuredName": {
                            "firstName": "Kenichi",
                            "lastName": "Kanatani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kanatani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17268830,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53b594689d74386eb6454b67574c710ceb904d7a",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Introducing a statistical model of noise in terms of the covariance matrix of the N-vector, we point out that the least-squares conic fitting is statistically biased. We present a new fitting scheme called renormalization for computing an unbiased estimate by automatically adjusting to noise. Relationships to existing methods are discussed, and our method is tested using real and synthetic data. >"
            },
            "slug": "Statistical-Bias-of-Conic-Fitting-and-Kanatani",
            "title": {
                "fragments": [],
                "text": "Statistical Bias of Conic Fitting and Renormalization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new fitting scheme called renormalization is presented for computing an unbiased estimate by automatically adjusting to noise in a statistical model of noise in terms of the covariance matrix of the N-vector."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065837385"
                        ],
                        "name": "Quang-Tuan Luong",
                        "slug": "Quang-Tuan-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quang-Tuan Luong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 170860374,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "84a2da1250494e3fd0b4bef471311cfe8c42641a",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Cette these s'attaque au probleme general de la calibration d'une camera mobile en utilisant uniquement des vues quelconques de l'environnement, donc sans utiliser de mire, ni de connaissance a priori sur le mouvement de la camera. La methode, appelee autocalibration, est fondee sur des proprietes algebriques de geometrie projective. Elle implique dans un premier temps le calcul de la transformation epipolaire grace a la matrice fondamentale, notion que nous avons definie, qui est d'une importance primordiale pour tous les problemes de vision ou nous ne disposons pas deja d'une calibration metrique complete. La determination sans ambiguite de cette matrice necessite un minimum de huit correspondances de points. Les premieres techniques que nous avons etudiees sont fondees sur la conservation du birapport et une methode due a sturm. Elles visent a calculer les epipoles. Nous avons ensuite introduit de multiples criteres et parametrages permettant l'estimation robuste de la matrice fondamentale par des techniques derivees de l'algorithme de longuet-higgins, que nous avons comparees. Nous mettons en evidence le fait qu'une configuration de points particuliere, les ensembles de plans, se prete a d'autres methodes de calcul qui leur sont propres, mais rend de toutes manieres l'estimation moins precise. L'influence du choix des mouvements eux-memes sur la stabilite du calcul est importante, nous le caracterisons par des calculs de covariance, et expliquons certaines situations grace a la surface critique dont nous proposons une etude operationnelle. Dans un second temps, lorsqu'un minimum de trois mouvements a ete effectue, nous pouvons obtenir les parametres intrinseques de la camera au moyen d'un systeme d'equations polynomiales dites de kruppa, dont nous avons etabli quelques importantes proprietes. Nous proposons d'abord une methode semi-analytique de resolution, puis une approche iterative performante qui nous permet de prendre en compte des longues sequences d'images, ainsi que l'incertitude. Le calcul des parametres extrinseques, et une extension de la methode a la calibration d'un systeme stereo par une nouvelle methode completent ce travail, dont la partie experimentale comporte de tres nombreuses simulations, ainsi que des exemples reels"
            },
            "slug": "Matrice-fondamentale-et-autocalibration-en-vision-Luong",
            "title": {
                "fragments": [],
                "text": "Matrice fondamentale et autocalibration en vision par ordinateur"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48590121"
                        ],
                        "name": "S. Teukolsky",
                        "slug": "S.-Teukolsky",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Teukolsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teukolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608024"
                        ],
                        "name": "W. Vetterling",
                        "slug": "W.-Vetterling",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Vetterling",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Vetterling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35046585"
                        ],
                        "name": "B. Flannery",
                        "slug": "B.-Flannery",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Flannery",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flannery"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61769312,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "ca2832d2c30287a9ee5b8584cc498d2b1cb14753",
            "isKey": false,
            "numCitedBy": 16689,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Note: Includes bibliographical references, 3 appendixes and 2 indexes.- Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08"
            },
            "slug": "Numerical-recipes-in-C-Press-Teukolsky",
            "title": {
                "fragments": [],
                "text": "Numerical recipes in C"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2218687"
                        ],
                        "name": "P. Rousseeuw",
                        "slug": "P.-Rousseeuw",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Rousseeuw",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Rousseeuw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152878142"
                        ],
                        "name": "A. Leroy",
                        "slug": "A.-Leroy",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Leroy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leroy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 61563242,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "ae3f31c841c460b15a81bf51655f4c0e39cacc79",
            "isKey": false,
            "numCitedBy": 5797,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction. 2. Simple Regression. 3. Multiple Regression. 4. The Special Case of One-Dimensional Location. 5. Algorithms. 6. Outlier Diagnostics. 7. Related Statistical Techniques. References. Table of Data Sets. Index."
            },
            "slug": "Robust-Regression-and-Outlier-Detection-Rousseeuw-Leroy",
            "title": {
                "fragments": [],
                "text": "Robust Regression and Outlier Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper presents the results of a two-year study of the statistical treatment of outliers in the context of one-Dimensional Location and its applications to discrete-time reinforcement learning."
            },
            "venue": {
                "fragments": [],
                "text": "Wiley Series in Probability and Statistics"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2649912"
                        ],
                        "name": "K. Bathe",
                        "slug": "K.-Bathe",
                        "structuredName": {
                            "firstName": "Klaus-J\u00fcrgen",
                            "lastName": "Bathe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bathe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "91249688"
                        ],
                        "name": "E. Wilson",
                        "slug": "E.-Wilson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Wilson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Wilson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119687361,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "f5a1e489ec458b3ea13892aceae8a3c6d4429d79",
            "isKey": false,
            "numCitedBy": 2126,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Numerical methods in finite element analysis , Numerical methods in finite element analysis , \u0645\u0631\u06a9\u0632 \u0641\u0646\u0627\u0648\u0631\u06cc \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u0648 \u0627\u0637\u0644\u0627\u0639 \u0631\u0633\u0627\u0646\u06cc \u06a9\u0634\u0627\u0648\u0631\u0632\u06cc"
            },
            "slug": "Numerical-methods-in-finite-element-analysis-Bathe-Wilson",
            "title": {
                "fragments": [],
                "text": "Numerical methods in finite element analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "Numerical methods in finite element analysis, Numerical techniques in finite elements analysis, and so on."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94725266"
                        ],
                        "name": "C. Springer",
                        "slug": "C.-Springer",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Springer",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Springer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120642771,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d2b8be343d9692bef5ba0f2c623074f1e8d3bb47",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Geometry-and-Analysis-of-Projective-Spaces-Springer",
            "title": {
                "fragments": [],
                "text": "Geometry and Analysis of Projective Spaces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145246674"
                        ],
                        "name": "A. Heyden",
                        "slug": "A.-Heyden",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Heyden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Heyden"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120498751,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fbb22aca8c03d940c47b9fb434f99fb27c165435",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Geometry-and-algebra-of-multiple-projective-Heyden",
            "title": {
                "fragments": [],
                "text": "Geometry and algebra of multiple projective transformations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47299467"
                        ],
                        "name": "H. Sanden",
                        "slug": "H.-Sanden",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Sanden",
                            "middleNames": [
                                "von",
                                "b."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sanden"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116966983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb30280f80615acba6ba2b96701b79c980a9733c",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Die-Bestimmung-der-Kernpunkte-in-der-Sanden",
            "title": {
                "fragments": [],
                "text": "Die Bestimmung der Kernpunkte in der Photogrammetrie"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1908
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2525101"
                        ],
                        "name": "T. Moons",
                        "slug": "T.-Moons",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Moons",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Moons"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2757352"
                        ],
                        "name": "M. V. Diest",
                        "slug": "M.-V.-Diest",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Diest",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. V. Diest"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3266794"
                        ],
                        "name": "E. Pauwels",
                        "slug": "E.-Pauwels",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Pauwels",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Pauwels"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117552673,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dab80df6fd62c9ff7fbff94640bb61203635251b",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Affine-reconstruction-from-perspective-image-pairs-Moons-Gool",
            "title": {
                "fragments": [],
                "text": "Affine reconstruction from perspective image pairs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84188873"
                        ],
                        "name": "James E. pLebensohn",
                        "slug": "James-E.-pLebensohn",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "pLebensohn",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James E. pLebensohn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 80152960,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "e940bb9bb85705149dfaacb6bc95a99c64a8159b",
            "isKey": false,
            "numCitedBy": 368,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Geometry-and-the-Imagination-pLebensohn",
            "title": {
                "fragments": [],
                "text": "Geometry and the Imagination"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1952
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682208"
                        ],
                        "name": "K. Kanatani",
                        "slug": "K.-Kanatani",
                        "structuredName": {
                            "firstName": "Kenichi",
                            "lastName": "Kanatani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kanatani"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60697397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efe44a5cadf1028723ba07681d49c406a7dea1b9",
            "isKey": false,
            "numCitedBy": 482,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Geometric-computation-for-machine-vision-Kanatani",
            "title": {
                "fragments": [],
                "text": "Geometric computation for machine vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145093203"
                        ],
                        "name": "G. Cross",
                        "slug": "G.-Cross",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Cross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 203663931,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1aa3564065d8c26916178603bfb7b3607204d9c4",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Quadric-Surface-Reconstruction-from-Dual-Space-Cross-Zisserman",
            "title": {
                "fragments": [],
                "text": "Quadric Surface Reconstruction from Dual-Space Geometry."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV 1998"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97581464"
                        ],
                        "name": "C. A. Hart",
                        "slug": "C.-A.-Hart",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Hart",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. A. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4110230,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6619dc31404c9b45ebefb15e3b30ec657920d23e",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Manual-of-Photogrammetry-Hart",
            "title": {
                "fragments": [],
                "text": "Manual of Photogrammetry"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1947
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2263388"
                        ],
                        "name": "P. K. Ghosh",
                        "slug": "P.-K.-Ghosh",
                        "structuredName": {
                            "firstName": "Pijush",
                            "lastName": "Ghosh",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. K. Ghosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3250452"
                        ],
                        "name": "S. Mudur",
                        "slug": "S.-Mudur",
                        "structuredName": {
                            "firstName": "Sudhir",
                            "lastName": "Mudur",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mudur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61523068,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b5cfa32dc382c468fd7410a28783b4b85712844",
            "isKey": false,
            "numCitedBy": 1464,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Three-Dimensional-Computer-Vision:-A-Geometric-Ghosh-Mudur",
            "title": {
                "fragments": [],
                "text": "Three-Dimensional Computer Vision: A Geometric Viewpoint"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144645904"
                        ],
                        "name": "Long Quan",
                        "slug": "Long-Quan",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Quan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Quan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 122677527,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "3d184ff5223e15dabcb8c35d9260b6a5de5f6901",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a linear algorithm for recovering 3D affine shape and motion from line correspondences with uncalibrated affine cameras. The algorithm requires a minimum of seven line correspondences over three views. The key idea is the introduction of a one-dimensional projective camera. This converts 3D affine reconstruction of \"line directions\" into 2D projective reconstruction of \"points\". In addition, a line-based factorization method is also proposed to handle redundant views. Experimental results both on simulated and real image sequences validate the robustness and the accuracy of the algorithm."
            },
            "slug": "Affine-structure-from-line-correspondences-with-Quan-Kanade",
            "title": {
                "fragments": [],
                "text": "Affine structure from line correspondences with uncalibrated affine cameras"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A linear algorithm for recovering 3D affine shape and motion from line correspondences with uncalibrated affine cameras with the introduction of a one-dimensional projective camera is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777539"
                        ],
                        "name": "P. Beardsley",
                        "slug": "P.-Beardsley",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Beardsley",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Beardsley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69325314"
                        ],
                        "name": "Andrew Zisserman Robotics",
                        "slug": "Andrew-Zisserman-Robotics",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Robotics",
                            "middleNames": [
                                "Zisserman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman Robotics"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60330269,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3ceea320f9a08a5dd9c461c16647c3b08ecbdb7",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Affine-Calibration-of-Mobile-Vehicles-Beardsley-Robotics",
            "title": {
                "fragments": [],
                "text": "Affine Calibration of Mobile Vehicles"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145504846"
                        ],
                        "name": "Martin Armstrong",
                        "slug": "Martin-Armstrong",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Armstrong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Armstrong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 32037068,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7fee4d5916c624ff6d7357b62ee997e7ac2a9a3",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Self-Calibration-from-Image-Sequences-Armstrong",
            "title": {
                "fragments": [],
                "text": "Self-Calibration from Image Sequences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reconstruction from multiple images by means of using relative depths"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ego-motion from six points"
            },
            "venue": {
                "fragments": [],
                "text": "Insight meeting,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Projective, Affine and Euclidean Calibration in Computer Vision and the Application of Three Dimensional Perception"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, RobotVis Group, INRIA Sophia-Antipolis,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shape descriptors: Bilinear, trilinear and quadrilinear relations for multi-point geometry and linear projective reconstruction algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "In IEEE Workshop on Representation of Visual Scenes,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiple image invariance using the double algebra"
            },
            "venue": {
                "fragments": [],
                "text": "In Applications of Invariance in Computer Vision, volume SLN Comp. Science"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The second edition. This new paperback edition has been expanded to include some of the developments since the original version"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experiments in Motion and Correspondence"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, University of Oxford,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analytical methods for uncalibrated stereo and motion measurement"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. 3rd European Conference on Computer Vision, Stockholm,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Notes on geometric invariance in vision"
            },
            "venue": {
                "fragments": [],
                "text": "Tutorial, British Machine Vision Conference,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Navigation using affine structure and motion"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. European Conference on Computer Vision,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Projective reconstruction from line correspondence"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. IEEE Conference on Computer Vision and Pattern Recognition,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shape and motion from image streams under orthography: A factorization approach"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theory of reconstruction from image"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Linear n \u2265 4-point pose determination"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. 6th International Conference on Computer"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A users guide to the trifocal tensor"
            },
            "venue": {
                "fragments": [],
                "text": "Dept. of Engineering Science, University of Oxford,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model based pose in 25 lines of code"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Resolving ambiguities in autocalibration"
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical Transactions of the Royal Society of London, SERIES A,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Motion segmentation and outlier detection"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, Dept. of Engineering Science, University of Oxford,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Monocular image measurements"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report Improofs-M12T21/1/P,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00dcber die bei der Hauptaufgabe der Luftphotogrammetrie auftretenden \u201cgef\u00e4hrlichen"
            },
            "venue": {
                "fragments": [],
                "text": "Fla\u0308chen. Bildmessung und Luftbildwesen (Beilage zur Allg. Vermessungs-Nachr.),"
            },
            "year": 1942
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the trilinear tensor of three perspective views and its underlying geometry"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. 5th International Conference on Computer Vision, Boston,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analytical photogrammetry applied to single terrestrial photograph mensuration"
            },
            "venue": {
                "fragments": [],
                "text": "In XIth International Conference of Photogrammetry,"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Euclidean reconstruction from uncalibrated images"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. British Machine Vision Conference,"
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 222,
        "totalPages": 23
    },
    "page_url": "https://www.semanticscholar.org/paper/Multiple-View-Geometry-in-Computer-Vision-Wrobel/339093c7ed71919ce59a7e78979a77abd25bad0c?sort=total-citations"
}