{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410019001"
                        ],
                        "name": "Shenchang Eric Chen",
                        "slug": "Shenchang-Eric-Chen",
                        "structuredName": {
                            "firstName": "Shenchang Eric",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shenchang Eric Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2955375"
                        ],
                        "name": "L. Williams",
                        "slug": "L.-Williams",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Williams",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7680709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f68cff502414a4ea054e154c880be150b2ca74eb",
            "isKey": false,
            "numCitedBy": 1271,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Image-space simplifications have been used to accelerate the calculation of computer graphic images since the dawn of visual simulation. Texture mapping has been used to provide a means by which images may themselves be used as display primitives. The work reported by this paper endeavors to carry this concept to its logical extreme by using interpolated images to portray three-dimensional scenes. The special-effects technique of morphing, which combines interpolation of texture maps and their shape, is applied to computing arbitrary intermediate frames from an array of prestored images. If the images are a structured set of views of a 3D object or scene, intermediate frames derived by morphing can be used to approximate intermediate 3D transformations of the object or scene. Using the view interpolation approach to synthesize 3D scenes has two main advantages. First, the 3D representation of the scene may be replaced with images. Second, the image synthesis time is independent of the scene complexity. The correspondence between images, required for the morphing method, can be predetermined automatically using the range data associated with the images. The method is further accelerated by a quadtree decomposition and a view-independent visible priority. Our experiments have shown that the morphing can be performed at interactive rates on today\u2019s high-end personal computers. Potential applications of the method include virtual holograms, a walkthrough in a virtual environment, image-based primitives and incremental rendering. The method also can be used to greatly accelerate the computation of motion blur and soft shadows cast by area light sources. CR Categories and Subject Descriptors: I.3.3 [Computer Graphics]: Picture/Image Generation; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. Additional Keywords: image morphing, interpolation, virtual reality, motion blur, shadow, incremental rendering, real-time display, virtual holography, motion compensation."
            },
            "slug": "View-interpolation-for-image-synthesis-Chen-Williams",
            "title": {
                "fragments": [],
                "text": "View interpolation for image synthesis"
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712839"
                        ],
                        "name": "K. Aizawa",
                        "slug": "K.-Aizawa",
                        "structuredName": {
                            "firstName": "Kiyoharu",
                            "lastName": "Aizawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Aizawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698996"
                        ],
                        "name": "H. Harashima",
                        "slug": "H.-Harashima",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Harashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Harashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144428073"
                        ],
                        "name": "T. Saito",
                        "slug": "T.-Saito",
                        "structuredName": {
                            "firstName": "Takahiro",
                            "lastName": "Saito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Saito"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21258033,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c192cb49ef5235b0a3e9f7c40f53e5c16bf684d5",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Model-based-analysis-synthesis-image-coding-system-Aizawa-Harashima",
            "title": {
                "fragments": [],
                "text": "Model-based analysis synthesis image coding (MBASIC) system for a person's face"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Process. Image Commun."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144757332"
                        ],
                        "name": "M. Oka",
                        "slug": "M.-Oka",
                        "structuredName": {
                            "firstName": "Masaaki",
                            "lastName": "Oka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52348163"
                        ],
                        "name": "Kyoya Tsutsui",
                        "slug": "Kyoya-Tsutsui",
                        "structuredName": {
                            "firstName": "Kyoya",
                            "lastName": "Tsutsui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyoya Tsutsui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32547312"
                        ],
                        "name": "A. Ohba",
                        "slug": "A.-Ohba",
                        "structuredName": {
                            "firstName": "Akio",
                            "lastName": "Ohba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ohba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32895089"
                        ],
                        "name": "Yoshitaka Kurauchi",
                        "slug": "Yoshitaka-Kurauchi",
                        "structuredName": {
                            "firstName": "Yoshitaka",
                            "lastName": "Kurauchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshitaka Kurauchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "148245673"
                        ],
                        "name": "Takashi Tago",
                        "slug": "Takashi-Tago",
                        "structuredName": {
                            "firstName": "Takashi",
                            "lastName": "Tago",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takashi Tago"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 246
                            }
                        ],
                        "text": "The more traditional approach to the analysis and especially the synthesis problem is based on explicit 3D models of the objects (Aizawa, Harashima and Saito, 19899 Nakaya et al. 19911 Choi et al. 19911 Li et al. 19933 Terzopoulos & Waters 1993, Oka et al. 19877 see Poggio, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8719653,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "33f89735e9347be686e6dfd2c205f0f851c684e1",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for real-time texture mapping was constructed, Here, \"real-time\" means that the system reacts to changes in parameter values which define the shape of surfaces and the viewing point that are given by its operator 30 times per second. This real-time processing enables interactive manipulation of texture-mapped free-form surfaces and various application software has been developed taking advantage of this ability. The system owes its performance to a new algorithm for texture mapping which is based on a newly proposed approximation scheme of mapping functions. In this scheme, a mapping function from the texture plane into the output screen is approximated by a linear function on each of the small regions which form the texture plane altogether. The algorithm is very simple and applicable to any smooth surface. It is especially efficient when implemented by a special-purpose hardware."
            },
            "slug": "Real-time-manipulation-of-texture-mapped-surfaces-Oka-Tsutsui",
            "title": {
                "fragments": [],
                "text": "Real-time manipulation of texture-mapped surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A system for real-time texture mapping was constructed which enables interactive manipulation of texture-mapped free-form surfaces and various application software has been developed taking advantage of this ability."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741830"
                        ],
                        "name": "Haibo Li",
                        "slug": "Haibo-Li",
                        "structuredName": {
                            "firstName": "Haibo",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haibo Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2402858"
                        ],
                        "name": "P. Roivainen",
                        "slug": "P.-Roivainen",
                        "structuredName": {
                            "firstName": "Pertti",
                            "lastName": "Roivainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Roivainen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767736"
                        ],
                        "name": "R. Forchheimer",
                        "slug": "R.-Forchheimer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Forchheimer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Forchheimer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 203
                            }
                        ],
                        "text": "The more traditional approach to the analysis and especially the synthesis problem is based on explicit 3D models of the objects (Aizawa, Harashima and Saito, 19899 Nakaya et al. 19911 Choi et al. 19911 Li et al. 19933 Terzopoulos & Waters 1993, Oka et al. 19877 see Poggio, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2860506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac38092add978eefedede183c0d07702fb05a711",
            "isKey": false,
            "numCitedBy": 415,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to estimating the motion of the head and facial expressions in model-based facial image coding is presented. An affine nonrigid motion model is set up. The specific knowledge about facial shape and facial expression is formulated in this model in the form of parameters. A direct method of estimating the two-view motion parameters that is based on the affine method is discussed. Based on the reasonable assumption that the 3-D motion of the face is almost smooth in the time domain, several approaches to predicting the motion of the next frame are proposed. Using a 3-D model, the approach is characterized by a feedback loop connecting computer vision and computer graphics. Embedding the synthesis techniques into the analysis phase greatly improves the performance of motion estimation. Simulations with long image sequences of real-world scenes indicate that the method not only greatly reduces computational complexity but also substantially improves estimation accuracy. >"
            },
            "slug": "3-D-Motion-Estimation-in-Model-Based-Facial-Image-Li-Roivainen",
            "title": {
                "fragments": [],
                "text": "3-D Motion Estimation in Model-Based Facial Image Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Simulations with long image sequences of real-world scenes indicate that the approach to estimating the motion of the head and facial expressions in model-based facial image coding not only greatly reduces computational complexity but also substantially improves estimation accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750924"
                        ],
                        "name": "Demetri Terzopoulos",
                        "slug": "Demetri-Terzopoulos",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Terzopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Demetri Terzopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398261"
                        ],
                        "name": "K. Waters",
                        "slug": "K.-Waters",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Waters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Waters"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 219
                            }
                        ],
                        "text": "The more traditional approach to the analysis and especially the synthesis problem is based on explicit 3D models of the objects (Aizawa, Harashima and Saito, 19899 Nakaya et al. 19911 Choi et al. 19911 Li et al. 19933 Terzopoulos & Waters 1993, Oka et al. 19877 see Poggio, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15057830,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f77296f889b56d871b9ba9408338dbfd9a0cdeb3",
            "isKey": false,
            "numCitedBy": 614,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to the analysis of dynamic facial images for the purposes of estimating and resynthesizing dynamic facial expressions is presented. The approach exploits a sophisticated generative model of the human face originally developed for realistic facial animation. The face model which may be simulated and rendered at interactive rates on a graphics workstation, incorporates a physics-based synthetic facial tissue and a set of anatomically motivated facial muscle actuators. The estimation of dynamical facial muscle contractions from video sequences of expressive human faces is considered. An estimation technique that uses deformable contour models (snakes) to track the nonrigid motions of facial features in video images is developed. The technique estimates muscle actuator controls with sufficient accuracy to permit the face model to resynthesize transient expressions. >"
            },
            "slug": "Analysis-and-Synthesis-of-Facial-Image-Sequences-Terzopoulos-Waters",
            "title": {
                "fragments": [],
                "text": "Analysis and Synthesis of Facial Image Sequences Using Physical and Anatomical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An estimation technique that uses deformable contour models (snakes) to track the nonrigid motions of facial features in video images is developed and estimates muscle actuator controls with sufficient accuracy to permit the face model to resynthesize transient expressions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 141
                            }
                        ],
                        "text": "Notice that there is a connection between this formu - lation and parametric eigenspace representation for visual learning and recognition ( Murase and Nayar , 1993 ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61999742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5648d1f511a5180cc0bf7af80a42d3dea3a4680",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation. In contrast to the traditional approach, they formulate the recognition problem as one of matching visual appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties of an object and are constant, pose and illumination vary from scene to scene. They present a new compact representation of object appearance that is parameterized by pose and illumination. They have conducted experiments using several objects with complex appearance characteristics.<<ETX>>"
            },
            "slug": "Learning-and-recognition-of-3D-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Learning and recognition of 3D objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation as one of matching visual appearance rather than shape and present a new compact representation of object appearance that is parameterized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "[1993] Proceedings IEEE Workshop on Qualitative Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 78
                            }
                        ],
                        "text": "A coarse - to - - ne strategy , currently implemented by Laplacian Pyramids ( Burt & Adelson , 1983 ) , estimates displacements at the coarser levels of the pyramid and reenes the estimates as ner levels are processed ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8018433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83074157d165b6245915508d891b2d0cd066f3ad",
            "isKey": false,
            "numCitedBy": 6693,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a technique for image encoding in which local operators of many scales but identical shape serve as the basis functions. The representation differs from established techniques in that the code elements are localized in spatial frequency as well as in space. Pixel-to-pixel correlations are first removed by subtracting a lowpass filtered copy of the image from the image itself. The result is a net data compression since the difference, or error, image has low variance and entropy, and the low-pass filtered image may represented at reduced sample density. Further data compression is achieved by quantizing the difference image. These steps are then repeated to compress the low-pass image. Iteration of the process at appropriately expanded scales generates a pyramid data structure. The encoding process is equivalent to sampling the image with Laplacian operators of many scales. Thus, the code tends to enhance salient image features. A further advantage of the present code is that it is well suited for many image analysis tasks as well as for image compression. Fast algorithms are described for coding and decoding."
            },
            "slug": "The-Laplacian-Pyramid-as-a-Compact-Image-Code-Burt-Adelson",
            "title": {
                "fragments": [],
                "text": "The Laplacian Pyramid as a Compact Image Code"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A technique for image encoding in which local operators of many scales but identical shape serve as the basis functions, which tends to enhance salient image features and is well suited for many image analysis tasks as well as for image compression."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 36
                            }
                        ],
                        "text": "Mundy et . al 19922 Weinshall 19933 Shashua 1993b ) , have also put new emphasis on achieving correspondence between model images stored in memory , prior to the actual 4 recognition of novel instances of objects ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29842427,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c7144a1181791c3a6d3f92a71d78b5f3f793d262",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The author addresses the problems of reconstructing 3-D space in a projective framework from two views and of artificially generating novel views of the scene from two given views. It is shown that with the correspondences coming from four non-coplanar points in the scene and the corresponding epipoles, it is possible to define and reconstruct a projective invariant, referred to as projective depth, that can be used later to reconstruct the projective or affine structure of the scene or directly to generate novel views of the scene. The derivation has the advantage that the viewing transformation matrix need not be recovered in the course of computations.<<ETX>>"
            },
            "slug": "Projective-depth:-A-geometric-invariant-for-3D-from-Shashua",
            "title": {
                "fragments": [],
                "text": "Projective depth: A geometric invariant for 3D reconstruction from two perspective/orthographic views and for visual recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that with the correspondences coming from four non-coplanar points in the scene and the corresponding epipoles, it is possible to define and reconstruct a projective invariant that can be used later to reconstruct the projective or affine structure of the scene or directly to generate novel views of thescene."
            },
            "venue": {
                "fragments": [],
                "text": "1993 (4th) International Conference on Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2320082"
                        ],
                        "name": "C. Choi",
                        "slug": "C.-Choi",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Choi",
                            "middleNames": [
                                "Seok"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698996"
                        ],
                        "name": "H. Harashima",
                        "slug": "H.-Harashima",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Harashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Harashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72636269"
                        ],
                        "name": "T. Takebe",
                        "slug": "T.-Takebe",
                        "structuredName": {
                            "firstName": "Tsuyosi",
                            "lastName": "Takebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Takebe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 185
                            }
                        ],
                        "text": "The more traditional approach to the analysis and especially the synthesis problem is based on explicit 3D models of the objects (Aizawa, Harashima and Saito, 19899 Nakaya et al. 19911 Choi et al. 19911 Li et al. 19933 Terzopoulos & Waters 1993, Oka et al. 19877 see Poggio, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62141870,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9955ed7be8a3c59e4468101486a1e7f848ecc1b4",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is proposed which analyzes and synthesizes image sequences, and updates a three-dimensional facial model in knowledge-based image coding. Rules for synthesizing the output images are formulated to simulate the facial muscular actions. The input image analysis technique estimates the head motion and the facial actions directly and robustly without any correspondences. This technique also provides good reproduction of the original images because it is incorporated with the synthesis rules. The presented method for updating the facial model improves analysis accuracy and quality of the synthesized images.<<ETX>>"
            },
            "slug": "Analysis-and-synthesis-of-facial-expressions-in-of-Choi-Harashima",
            "title": {
                "fragments": [],
                "text": "Analysis and synthesis of facial expressions in knowledge-based coding of facial image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The presented method for updating the facial model improves analysis accuracy and quality of the synthesized images and provides good reproduction of the original images because it is incorporated with the synthesis rules."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18282894,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c862b612c8b14130640f6e6206f188651adc90e",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Even if represented in a way which is invariant to illumination conditions, a 3D object gives rise to an infinite number of 2D views, depending on its pose. It has been recently shown ([13]) that it is possible to synthesize a module that can recognize a specific 3D object from any viewpoint, by using a new technique of learning from examples, which are, in this case, a small set of 2D views of the object. In this paper we extend the technique, a) to deal with real objects (isolated paper clips) that suffer from noise and occlusions and b) to exploit negative examples during the learning phase. We also compare different versions of the multi-layer networks corresponding to our technique among themselves and with a standard Nearest Neighbor classifier. The simplest version, which is a Radial Basis Functions network, performs less well than a Nearest Neighbor classi-fier. The more powerful versions, trained with positive and negative examples, perform significantly better. Our results, which may have interesting implications for computer vision despite the relative simplicity of the task studied, are especially interesting for understanding the process of object recognition in biological vision. 1 Introduction Shape-based visual recognition of 3D objects may be solved by first hypothesizing the viewpoint (e.g., using information on feature correspondences between the image and a 3D model), then computing the appearance of the model of the object to be recognized from that viewpoint and comparing it with the actual image ([6; 20; 9; 11; 21]). Most recognition schemes developed in computer vision over the last few years employ 3D models of objects. Automatic learning of 3D models, however, is in itself a difficult problem that has not been much addressed in the past and which presents difficulties, especially for any theory that wants to account for human ability in visual recognition. Recently, recognition schemes have been suggested that, relying on a set of 2D views of the object instead of a 3D model ([2; 5; 13]), offer a natural solution to the problem of model acquisition. In particular, Poggio and Edelman ([13]) have argued that for each object there exists a smooth function mapping any perspective view into a \"standard\" view of the object and that this mul-tivariate function may be approximatevely synthesized from a small number of views of the object. Such a function would be object specific, with different functions corresponding to different 3D objects. \u2026"
            },
            "slug": "HyperBF-Networks-for-Real-Object-Recognition-Brunelli-Poggio",
            "title": {
                "fragments": [],
                "text": "HyperBF Networks for Real Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper extends the technique of learning from examples to deal with real objects that suffer from noise and occlusions and to exploit negative examples during the learning phase, and compares different versions of the multi-layer networks corresponding to the technique among themselves and with a standard Nearest Neighbor classifier."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 273
                            }
                        ],
                        "text": "\u2026b e useful in teleconferencing applications and propose con - nections between that mapping and recent t e c hniques in visual recognition applied to non - rigid objects ( Ullman & , Basri 19911 Poggio , 1990 ) and certain classes of ob - jects called \\Linear Classes \" ( Poggio & Vetter , 1992 ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 272
                            }
                        ],
                        "text": "\u2026generating novel views from a single image of, say, a face without any 3D model but simply by \\learning\" the appropriate transformations from example views of a prototype face, extending a technique originally suggested by P oggio and Brunelli (see also Poggio, 1991 and Poggio and Vetter, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 145
                            }
                        ],
                        "text": "This idea of generating \\virtual \" views of an object by using class - speciic knowledge has been discussed before in ( Poggio , 1991 , see also Poggio and Vetter , 1992 ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3893740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82962da5c273a9e6627a040d56c8a7973fe22440",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this note we discuss how recognition can be achieved from a single 2D model view exploiting prior knowledge of an object''s structure (e.g. symmetry). We prove that for any bilaterally symmetric 3D object one non- accidental 2D model view is sufficient for recognition. Symmetries of higher order allow the recovery of structure from one 2D view. Linear transformations can be learned exactly from a small set of examples in the case of \"linear object classes\" and used to produce new views of an object from a single view."
            },
            "slug": "Recognition-and-Structure-from-one-2D-Model-View:-Poggio-Vetter",
            "title": {
                "fragments": [],
                "text": "Recognition and Structure from one 2D Model View: Observations on Prototypes, Object Classes and Symmetries"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is proved that for any bilaterally symmetric 3D object one non- accidental 2D model view is sufficient for recognition and linear transformations can be learned exactly from a small set of examples in the case of \"linear object classes\"."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 142
                            }
                        ],
                        "text": "In this paper we suggest using the densest possible representation { one feature per pixel , originally sug - gested for visual recognition ( Shashua , 1991 ) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We t h e n 3 compute the interpolated image img inter ( x ) b y y vect ( img 2 i m g 1 ) img int ( x ) ( 1 ; x ) rend ( x y i m g 1 0 ) + x rend ( x y img 2 y ) Note that img 1 is reproduced exactly when x = 0 img 2 , when x = 1 ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15785342,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6726e2264c3a35c6a4b4da88520706665005835a",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents a simple model for recovering affine shape and correspondence from two orthographic views of a 3D object. It is shown that four corresponding points along two orthographic views, taken under similar illumination conditions, determine affine shape and correspondence for all other points. The scheme is useful for purposes of visual recognition by generating novel views of an object given two model views. It is also shown that the scheme can handle objects with smooth boundaries, to a good approximation, without introducing any modifications or additional model views."
            },
            "slug": "Correspondence-and-Affine-Shape-from-Two-Views:-and-Shashua",
            "title": {
                "fragments": [],
                "text": "Correspondence and Affine Shape from Two Orthographic Views: Motion and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "It is shown that four corresponding points along two orthographic views, taken under similar illumination conditions, determine affine shape and correspondence for all other points and the scheme is useful for purposes of visual recognition by generating novel views of an object given two model views."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588702"
                        ],
                        "name": "B. D. Lucas",
                        "slug": "B.-D.-Lucas",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lucas",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2121536,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd",
            "isKey": false,
            "numCitedBy": 13329,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between the images than existing techniques Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show how our technique can be adapted tor use in a stereo vision system."
            },
            "slug": "An-Iterative-Image-Registration-Technique-with-an-Lucas-Kanade",
            "title": {
                "fragments": [],
                "text": "An Iterative Image Registration Technique with an Application to Stereo Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration, and can be generalized to handle rotation, scaling and shearing."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41895215,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1844c55a8f76c09257c84e886a7bf10fc7e98e3f",
            "isKey": false,
            "numCitedBy": 654,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Aligning-pictorial-descriptions:-An-approach-to-Ullman",
            "title": {
                "fragments": [],
                "text": "Aligning pictorial descriptions: An approach to object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076400"
                        ],
                        "name": "B. Caprile",
                        "slug": "B.-Caprile",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Caprile",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caprile"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 118
                            }
                        ],
                        "text": ") as the approximation scheme , that is a network with one \\hidden \" layer and linear output units ( see for instance Poggio and Girosi , 1989 ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10243731,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "898c01de58eb3b8e790b60e0fe0db2230d88f15b",
            "isKey": false,
            "numCitedBy": 699,
            "numCiting": 152,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning an input-output mapping from a set of examples, of the type that many neural networks have been constructed to perform, can be regarded as synthesizing an approximation of a multi-dimensional function. We develop a theoretical framework for approximation based on regularization techniques that leads to a class of three-layer networks that we call Generalized Radial Basis Functions (GRBF). GRBF networks are not only equivalent to generalized splines, but are also closely related to several pattern recognition methods and neural network algorithms. The paper introduces several extensions and applications of the technique and discusses intriguing analogies with neurobiological data."
            },
            "slug": "Extensions-of-a-Theory-of-Networks-for-and-Learning-Girosi-Poggio",
            "title": {
                "fragments": [],
                "text": "Extensions of a Theory of Networks for Approximation and Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A theoretical framework for approximation based on regularization techniques that leads to a class of three-layer networks that is called Generalized Radial Basis Functions (GRBF), which is not only equivalent to generalized splines, but is closely related to several pattern recognition methods and neural network algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27836752"
                        ],
                        "name": "Y. Nakaya",
                        "slug": "Y.-Nakaya",
                        "structuredName": {
                            "firstName": "Yuichiro",
                            "lastName": "Nakaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nakaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2432594"
                        ],
                        "name": "Y. C. Chuah",
                        "slug": "Y.-C.-Chuah",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Chuah",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. C. Chuah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698996"
                        ],
                        "name": "H. Harashima",
                        "slug": "H.-Harashima",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Harashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Harashima"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 165
                            }
                        ],
                        "text": "The more traditional approach to the analysis and especially the synthesis problem is based on explicit 3D models of the objects (Aizawa, Harashima and Saito, 19899 Nakaya et al. 19911 Choi et al. 19911 Li et al. 19933 Terzopoulos & Waters 1993, Oka et al. 19877 see Poggio, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62711762,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "id": "4dbb6dfea948d36b50985002c0145ce391160a54",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "An image coding method that combines model-based coding with conventional waveform coding is presented. Despite its potential to realize image communication at very low rates, model-based coding still has many glitches that need to be solved before any practical use. The major problems are the difficulty in modeling unknown objects and the presence of analysis errors. To cope with these difficulties, waveform coding is incorporated into model-based coding. The incorporated waveform coder can code unmodeled objects and cancel errors of the analysis system. A general model of model-based/waveform hybrid coding is discussed. Preliminary simulation results of a model-based/MC-DCT hybrid coding system show that this hybrid coding method is effective at very low transmission rates, such as 16 kb/s.<<ETX>>"
            },
            "slug": "Model-based/waveform-hybrid-coding-for-images-Nakaya-Chuah",
            "title": {
                "fragments": [],
                "text": "Model-based/waveform hybrid coding for videotelephone images"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "An image coding method that combines model-based coding with conventional waveform coding is presented and preliminary simulation results show that this hybrid coding method is effective at very low transmission rates, such as 16 kb/s."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 28
                            }
                        ],
                        "text": "We found however ( see also Shashua 1992b , Jones and Poggio , in preparation ) that several correspondence algorithms per - form satisfactorily for nding pixel level correspondence between grey level images of faces that are not too diier - ent ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120989821,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "39c1352a5b70ad3c2dbe29f5f0ceebf163b414bd",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 193,
            "paperAbstract": {
                "fragments": [],
                "text": "The report addresses the problem of visual recognition under two sources of variability: geometric and photometric. The geometric deals with the relation between 3D objects and their views under orthographic and perspective projection. The photometric deals with the relation between 3D matte objects and their images under changing illumination conditions. Taken together, an alignment-based method is presented for recognizing objects viewed from arbitrary viewing positions and illuminated by arbitrary settings of light sources."
            },
            "slug": "Geometry-and-Photometry-in-3D-Visual-Recognition-Shashua",
            "title": {
                "fragments": [],
                "text": "Geometry and Photometry in 3D Visual Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684073"
                        ],
                        "name": "A. Hurlbert",
                        "slug": "A.-Hurlbert",
                        "structuredName": {
                            "firstName": "Anya",
                            "lastName": "Hurlbert",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hurlbert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2441722,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "3ee07fc62801c8e76c8d31292c120580b03b2176",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper sketches a hypothetical cortical architecture for visual 3D object recognition based on a recent computational model. The view-centered scheme relies on modules for learning from examples, such as Hyperbf-like networks. Such models capture a class of explanations we call Memory-Based Models (MBM) that contains sparse population coding, memory-based recognition, and codebooks of prototypes. Unlike the sigmoidal units of some artificial neural networks, the units of MBMs are consistent with the description of cortical neurons. We describe how an example of MBM may be realized in terms of cortical circuitry and biophysical mechanisms, consistent with psychophysical and physiological data."
            },
            "slug": "Observations-on-Cortical-Mechanisms-for-Object-and-Poggio-Hurlbert",
            "title": {
                "fragments": [],
                "text": "Observations on Cortical Mechanisms for Object Recognition and Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper sketches a hypothetical cortical architecture for visual 3D object recognition based on a recent computational model that contains sparse population coding, memory-based recognition, and codebooks of prototypes that is consistent with the description of cortical neurons."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14892653,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "089a76dbc62a06ad30ae1925530e8733e850268e",
            "isKey": false,
            "numCitedBy": 3701,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of the approximation of nonlinear mapping, (especially continuous mappings) is considered. Regularization theory and a theoretical framework for approximation (based on regularization techniques) that leads to a class of three-layer networks called regularization networks are discussed. Regularization networks are mathematically related to the radial basis functions, mainly used for strict interpolation tasks. Learning as approximation and learning as hypersurface reconstruction are discussed. Two extensions of the regularization approach are presented, along with the approach's corrections to splines, regularization, Bayes formulation, and clustering. The theory of regularization networks is generalized to a formulation that includes task-dependent clustering and dimensionality reduction. Applications of regularization networks are discussed. >"
            },
            "slug": "Networks-for-approximation-and-learning-Poggio-Girosi",
            "title": {
                "fragments": [],
                "text": "Networks for approximation and learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40019208"
                        ],
                        "name": "Thaddeus Beier",
                        "slug": "Thaddeus-Beier",
                        "structuredName": {
                            "firstName": "Thaddeus",
                            "lastName": "Beier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thaddeus Beier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094398048"
                        ],
                        "name": "Shawn Neely",
                        "slug": "Shawn-Neely",
                        "structuredName": {
                            "firstName": "Shawn",
                            "lastName": "Neely",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shawn Neely"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 32
                            }
                        ],
                        "text": "Morphing in computer graphics ( Beier and Neely , 1992 ) faces a similar correspondence problem that is typ - ically solved with time - consuming manual intervention ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9124441,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "be73726c6a538bc3ed05e62ba5faec183f777ff6",
            "isKey": false,
            "numCitedBy": 833,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "2.1 Conventional Metamorphosis Techniques Mc[:ml(wpht)iii twlween lWo or mor\u2019c imafys (wer lime i) u uwi\u2019ul \\ i~u;ii tcchniquc. (Jflen uwd f\u2019orCducaliomd (n\u2019tMCid;liMll Cnt purpt>wi. \u20181\u2019l-:idi(ional Iilmmahing techniques for (his cflcc[ include ~\u2019lckcr c\u2019ut~(iuc\u2019h LISu chwwwr cxhibi(ing ch:mgm while running thr(mgll ;! toreil and prosing behind several trws ) tind op[ic:d cro\\\\diswdv<\u2019. in which onc image is f:ide(i out while wwther is sinwlt:lnLNNI\\l)f\u2019:idcdin (Mith makeup ch:mge. tippliwcm, or nhjecl subs[i [u[I(m ). Sc\\\u2019~\u2019riilclawic horror lilm~ illu$tfiite [he process: who ctwld hnycl ~hc b:lir-tai~ing (fiiniform;ilml of the Woitman. or the drw m:itic lllct;itll(~rpll(~sii from Dr. Jchyll [o Mr. Hyde\u2019? This pupcr prcwmls ii c(mtcnlp{mmy w~lu(i(mto the vi~u:d translonmrtion pnh lL\u2019nl."
            },
            "slug": "Feature-based-image-metamorphosis-Beier-Neely",
            "title": {
                "fragments": [],
                "text": "Feature-based image metamorphosis"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "2.1 Conventional Metamorphosis Techniques Mc[:ml(wpht)iii twlween lWo or mor\u2019c imafys (wer lime i) u uwi\u2019ul \\ i~u;ii tcchniquc."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 142
                            }
                        ],
                        "text": "In this paper we suggest using the densest possible representation { one feature per pixel , originally sug - gested for visual recognition ( Shashua , 1991 ) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11612280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12ba0366bb58059e0f0bad1885959653816b207a",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that both changes in viewing position and illumination conditions can be compensated for, prior to recognition, using combinations of images taken from different viewing positions and different illumination conditions. It is also shown that, in agreement with psychophysical findings, the computation requires at least a sign-bit image as input -- contours alone are not sufficient."
            },
            "slug": "Illumination-and-View-Position-in-3D-Visual-Shashua",
            "title": {
                "fragments": [],
                "text": "Illumination and View Position in 3D Visual Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "It is shown that both changes in viewing position and illumination conditions can be compensated for, prior to recognition, using combinations of images taken from different viewing positions and different illumination conditions."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32129023"
                        ],
                        "name": "L. Stringa",
                        "slug": "L.-Stringa",
                        "structuredName": {
                            "firstName": "Luigi",
                            "lastName": "Stringa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Stringa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 7
                            }
                        ],
                        "text": "1989 , Stringa 1991 , Beymer 1993 , de - scribe automatic techniques for nding the eyes ) ."
                    },
                    "intents": []
                }
            ],
            "corpusId": 205592126,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa3c0c6945bf5b7459f927b8fc00abb0f8074b06",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A correlation-based approach to automatic face recognition requires adequate normalization techniques. If the positioning of the face in the image is accurate, the need for shifting to obtain the best matching between the unknown subject and a template is drastically reduced, with considerable advantages in computing costs. In this paper, a novel technique is presented based on a very efficient eyes localization algorithm. The technique has been implemented as part of the \u201celectronic librarian\u201d of MAIA, the experimental platform of the integrated Al project under development at IRST. Preliminary experimental results on a set of 220 facial images of 55 people disclose excellent recognition rates and processing speed."
            },
            "slug": "Eyes-detection-for-face-recognition-Stringa",
            "title": {
                "fragments": [],
                "text": "Eyes detection for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel technique is presented based on a very efficient eyes localization algorithm that has been implemented as part of the \u201celectronic librarian\u201d of MAIA, the experimental platform of the integrated Al project under development at IRST."
            },
            "venue": {
                "fragments": [],
                "text": "Appl. Artif. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 125
                            }
                        ],
                        "text": "Section 5 also describes how linear combination of images { in the appropriate representation { is intimately related to the Regularization Networks but can also be justiied in independent w ays."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 89
                            }
                        ],
                        "text": "It may reeect the organization of human vision for object recognition ( see for instance Poggio , 1990 and Poggio and Hurlbert , 1993 ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 71
                            }
                        ],
                        "text": "When we rst introduced our technique based on Regularization Networks (Poggio and Girosi, 1990) to \\solve\" the analysis problem { from images to \\pose\" parameters { w e demonstrated it only for artiicial, very simple images (see Poggio and Edelman, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 24
                            }
                        ],
                        "text": "First, we summarize the Regularization Networks technique that we use for learning-fromexampless second, we i n troduce solutions to the correspondence problem between images that represent a k ey step for automatizing the whole process."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 196
                            }
                        ],
                        "text": "\u2026b e useful in teleconferencing applications and propose con - nections between that mapping and recent t e c hniques in visual recognition applied to non - rigid objects ( Ullman & , Basri 19911 Poggio , 1990 ) and certain classes of ob - jects called \\Linear Classes \" ( Poggio & Vetter , 1992 ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3648459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb2cca58ac24c45210079378e3085a55401b9c81",
            "isKey": true,
            "numCitedBy": 341,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "I propose a speculative new version of the grandmother cell theory to explain how the brain may work, discuss how the visual system may learn to recognize 3D objects, and relate our theory to existing models of the cerebellum and motor control. The main points are: 1) the brain uses modules for multivariate function approximation as components of several information processing subsystems, 2) these modules are realized as HyperBF networks, and 3) HyperBF networks can be implemented in terms of biologically plausible mechanisms and circuitry. The theory predicts a type of population coding that represents an extension of schemes such as look-up tables."
            },
            "slug": "A-theory-of-how-the-brain-might-work.-Poggio",
            "title": {
                "fragments": [],
                "text": "A theory of how the brain might work."
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A speculative new version of the grandmother cell theory is proposed to explain how the brain may work, discuss how the visual system may learn to recognize 3D objects, and relate the theory to existing models of the cerebellum and motor control."
            },
            "venue": {
                "fragments": [],
                "text": "Cold Spring Harbor symposia on quantitative biology"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 31
                            }
                        ],
                        "text": "Our approach (see for instance Poggio and Brunelli, 1992) is to represent images in terms of a vector of x, y of corresponding feature locations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 186
                            }
                        ],
                        "text": "The approximation argument on the other hand does not depend on the particular view represen - tation , as long as the mapping between the pose input and the view output is smooth ( see Poggio and Brunelli , 1992 for the argument and an example ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Poggio and Brunelli (1992) had suggested ways to extend the approach from line drawings to grey-level images and demonstrated the extension in a simple case of video images of a walking person."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Poggio & Brunelli ( 1992 ) suggested that the synthesis problem could be viewed in terms of the associate , in - verse mapping ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 272
                            }
                        ],
                        "text": "\u2026generating novel views from a single image of, say, a face without any 3D model but simply by \\learning\" the appropriate transformations from example views of a prototype face, extending a technique originally suggested by P oggio and Brunelli (see also Poggio, 1991 and Poggio and Vetter, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A n o vel approach t o graphics"
            },
            "venue": {
                "fragments": [],
                "text": "A n o vel approach t o graphics"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52048182"
                        ],
                        "name": "Stephen E. Librande",
                        "slug": "Stephen-E.-Librande",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Librande",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen E. Librande"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 117
                            }
                        ],
                        "text": "The same representation has been recently ap - plied to generating images of hand - drawn colored illus - trations ( Librande , 1992 ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 49
                            }
                        ],
                        "text": "As it is clear from the theory ( see examples in Librande , 1992 ) , the input space may h a ve a n y dimen - sion , provided there is a suucient n umber of examples ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 237
                            }
                        ],
                        "text": "On the synthesis problem we w ere able to demonstrate that our approach is eeective for storing, interpolating among, and even extrapolating from professional quality, hand-drawn and colored illustrations (see Poggio and Brunelli, 19922 Librande , 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 269
                            }
                        ],
                        "text": "The 2D control points used in the internal representations of these objects were then obtained semi-automatically using recently developed algorithms for automatic contour tracing (Lines, pers. com.) and contour matching from a small number of manually matched points (Librande, 1992))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53926178,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1737f5965e5d0150212825ea97ede4de7923b287",
            "isKey": true,
            "numCitedBy": 32,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Example-based-character-drawing-Librande",
            "title": {
                "fragments": [],
                "text": "Example-based character drawing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 255
                            }
                        ],
                        "text": "\u2026generating novel views from a single image of, say, a face without any 3D model but simply by \\learning\" the appropriate transformations from example views of a prototype face, extending a technique originally suggested by P oggio and Brunelli (see also Poggio, 1991 and Poggio and Vetter, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 267
                            }
                        ],
                        "text": "The more traditional approach to the analysis and especially the synthesis problem is based on explicit 3D models of the objects (Aizawa, Harashima and Saito, 19899 Nakaya et al. 19911 Choi et al. 19911 Li et al. 19933 Terzopoulos & Waters 1993, Oka et al. 19877 see Poggio, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 172
                            }
                        ],
                        "text": "For instance , pose and expres - sion of faces can be estimated by tting a generic model of a face to the image of a speciic face ( Aizawa , Ha - rashima and Saito , 19899 Poggio , 1991 ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 120
                            }
                        ],
                        "text": "This idea of generating \\virtual \" views of an object by using class - speciic knowledge has been discussed before in ( Poggio , 1991 , see also Poggio and Vetter , 1992 ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3D object recognition and prototypes: one 2D view may be suucient"
            },
            "venue": {
                "fragments": [],
                "text": "I.R.S.T"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 125
                            }
                        ],
                        "text": "Section 5 also describes how linear combination of images { in the appropriate representation { is intimately related to the Regularization Networks but can also be justiied in independent w ays."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 89
                            }
                        ],
                        "text": "It may reeect the organization of human vision for object recognition ( see for instance Poggio , 1990 and Poggio and Hurlbert , 1993 ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 71
                            }
                        ],
                        "text": "When we rst introduced our technique based on Regularization Networks (Poggio and Girosi, 1990) to \\solve\" the analysis problem { from images to \\pose\" parameters { w e demonstrated it only for artiicial, very simple images (see Poggio and Edelman, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 24
                            }
                        ],
                        "text": "First, we summarize the Regularization Networks technique that we use for learning-fromexampless second, we i n troduce solutions to the correspondence problem between images that represent a k ey step for automatizing the whole process."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 87
                            }
                        ],
                        "text": "This example - based approach to estimat - ing pose parameters for simple 3D objects was rst sug - gested and demonstrated by P oggio and Edelman ( 1990 , see gure 4 ) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 196
                            }
                        ],
                        "text": "\u2026b e useful in teleconferencing applications and propose con - nections between that mapping and recent t e c hniques in visual recognition applied to non - rigid objects ( Ullman & , Basri 19911 Poggio , 1990 ) and certain classes of ob - jects called \\Linear Classes \" ( Poggio & Vetter , 1992 ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 5
                            }
                        ],
                        "text": "Once the example images are vectorized the learning stage can take place ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3D object recognition: on a result of Basri and Ullman"
            },
            "venue": {
                "fragments": [],
                "text": "3D object recognition: on a result of Basri and Ullman"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We t h e n 3 compute the interpolated image img inter ( x ) b y y vect ( img 2 i m g 1 ) img int ( x ) ( 1 ; x ) rend ( x y i m g 1 0 ) + x rend ( x y img 2 y ) Note that img 1 is reproduced exactly when x = 0 img 2 , when x = 1 ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 117
                            }
                        ],
                        "text": "The same representation has been recently ap - plied to generating images of hand - drawn colored illus - trations ( Librande , 1992 ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 269
                            }
                        ],
                        "text": "The 2D control points used in the internal representations of these objects were then obtained semi-automatically using recently developed algorithms for automatic contour tracing (Lines, pers. com.) and contour matching from a small number of manually matched points (Librande, 1992))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 49
                            }
                        ],
                        "text": "As it is clear from the theory ( see examples in Librande , 1992 ) , the input space may h a ve a n y dimen - sion , provided there is a suucient n umber of examples ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 237
                            }
                        ],
                        "text": "On the synthesis problem we w ere able to demonstrate that our approach is eeective for storing, interpolating among, and even extrapolating from professional quality, hand-drawn and colored illustrations (see Poggio and Brunelli, 19922 Librande , 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Example-based character drawing. Master's thesis, M.S., Media Arts and Science Section , School of Architecture and Planning"
            },
            "venue": {
                "fragments": [],
                "text": "Massachusetts Institute of Technology"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21451088"
                        ],
                        "name": "P. Ekman",
                        "slug": "P.-Ekman",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Ekman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ekman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31542887,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "612b6f9e5e16ead6ea5d4b8001ed05a25d7e6d81",
            "isKey": false,
            "numCitedBy": 367,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Evidence on universals in facial expression of emotion and renewed controversy about how to interpret that evidence is discussed. New findings on the capability of voluntary facial action to generate changes in both autonomic and central nervous system activity are presented, as well as a discussion of the possible mechanisms relevant to this phenomenon. Finally, new work on the nature of smiling is reviewed which shows that it is possible to distinguish the smile when enjoyment is occurring from other types of smiling. Implications for the differences between voluntary and involuntary expression are considered."
            },
            "slug": "Facial-expressions-of-emotion:-an-old-controversy-Ekman",
            "title": {
                "fragments": [],
                "text": "Facial expressions of emotion: an old controversy and new findings."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "New work on the nature of smiling shows that it is possible to distinguish the smile when enjoyment is occurring from other types of smiling, and implications for the differences between voluntary and involuntary expression are considered."
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical transactions of the Royal Society of London. Series B, Biological sciences"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 106
                            }
                        ],
                        "text": "In any case a sparse xx y representation , originally suggested for object recognition ( see for instance Ullman and Basri , 1989 ) was also used by P oggio and Brunelli ( 1992 ) for synthesis of real images in which features ( in the order of 20 or so ) were located and brought i n to\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8989489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d781d5e651e12bf666cf993ae307db785113b9ae",
            "isKey": false,
            "numCitedBy": 951,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed. It is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views. For objects with sharp edges, the linear combination representation is exact. For objects with smooth boundaries, it is an approximation that often holds over a wide range of viewing angles. Rigid transformations (with or without scaling) can be distinguished from more general linear transformations of the object by testing certain constraints placed on the coefficients of the linear combinations. Three alternative methods of determining the transformation that matches a model to a given image are proposed. >"
            },
            "slug": "Recognition-by-Linear-Combinations-of-Models-Ullman-Basri",
            "title": {
                "fragments": [],
                "text": "Recognition by Linear Combinations of Models"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed and it is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2546027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e5949d95c53dd041c721bf40e67b3966805e385",
            "isKey": false,
            "numCitedBy": 488,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers in computer vision and pattern recognition have worked on automatic techniques for recognizing human faces for the last 20 years. While some systems, especially template-based ones, have been quite successful on expressionless, frontal views of faces with controlled lighting, not much work has taken face recognizers beyond these narrow imaging conditions. Our goal is to build a face recognizer that works under varying pose, the difficult part of which is to handle face relations in depth. Building on successful template-based systems, our basic approach is to represent faces with templates from multiple model views that cover different poses from the viewing sphere. To recognize a novel view, the recognizer locates the eyes and nose features, uses these locations to geometrically register the input with model views, and then uses correlation on model templates to find the best match in the data base of people. Our system has achieved a recognition rate of 98% on a data base of 62 people containing 10 testing and 15 modeling views per person.<<ETX>>"
            },
            "slug": "Face-recognition-under-varying-pose-Beymer",
            "title": {
                "fragments": [],
                "text": "Face recognition under varying pose"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The goal is to build a face recognizer that works under varying pose, the difficult part of which is to handle face relations in depth."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 142
                            }
                        ],
                        "text": "In this paper we suggest using the densest possible representation { one feature per pixel , originally sug - gested for visual recognition ( Shashua , 1991 ) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Correspondence and aane shape from two orthographic views: Motion and Recognition. A.I. Memo No"
            },
            "venue": {
                "fragments": [],
                "text": "Correspondence and aane shape from two orthographic views: Motion and Recognition. A.I. Memo No"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Priors, stabilizers and basis functions: From regularization to radial, tensor and additive splines. A.I. Memo No. 1430, Artiicial Intelligence Laboratory, M a s sachusetts Institute of Technology"
            },
            "venue": {
                "fragments": [],
                "text": "Priors, stabilizers and basis functions: From regularization to radial, tensor and additive splines. A.I. Memo No. 1430, Artiicial Intelligence Laboratory, M a s sachusetts Institute of Technology"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 34
                            }
                        ],
                        "text": "Ekman & Friesen 19788 Ekman 19922 Essa 1993 ) ."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual interpretation of facial expressions using dynamic modeling"
            },
            "venue": {
                "fragments": [],
                "text": "Visual interpretation of facial expressions using dynamic modeling"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3-D model alignment without computing pose"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Image Understanding Workshop"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3D object recognition: on a result by Basri and Ullman"
            },
            "venue": {
                "fragments": [],
                "text": "3D object recognition: on a result by Basri and Ullman"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A novel approach to graphics. A.I. Memo No"
            },
            "venue": {
                "fragments": [],
                "text": "A novel approach to graphics. A.I. Memo No"
            },
            "year": 1354
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical, computationally eecient motion estimation algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 229
                            }
                        ],
                        "text": "When we rst introduced our technique based on Regularization Networks (Poggio and Girosi, 1990) to \\solve\" the analysis problem { from images to \\pose\" parameters { w e demonstrated it only for artiicial, very simple images (see Poggio and Edelman, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A network that learns to recognize 3D objects"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 144
                            }
                        ],
                        "text": "\u2026value of corresponding points does not change much , then we h a ve the following equation , known as the \\con - stant brightness equation \" ( Horn & Schunk , 1981 ) : rI v + I t = 0 ( 5 ) where rI is the gradient at point p , and I t is the tem - poral derivative a t p , a n d v is the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Determining optical ow"
            },
            "venue": {
                "fragments": [],
                "text": "Artiicial Intelligence"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 29
                            }
                        ],
                        "text": "This observation was made by Basri ( 1990 ) in the con - text of articulated objects ( objects composed of links , like scissors ) , but may be also valid to more natural ob - jects ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The recognition of 3-D solid objects from 2-D images"
            },
            "venue": {
                "fragments": [],
                "text": "Weizmann Institute of Science"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Priors, stabilizers and basis functions: From regularization to radial, tensor and additive splines. A.I. Memo No"
            },
            "venue": {
                "fragments": [],
                "text": "Priors, stabilizers and basis functions: From regularization to radial, tensor and additive splines. A.I. Memo No"
            },
            "year": 1430
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 159
                            }
                        ],
                        "text": "The coarse - to - - ne gradient - based optical ow a l g o - rithm used in the examples of this paper follows ( Lu - cas & Kanade 19811 Bergen & Adelson 19877 Bergen & Hingorani 1990 ) and is applied after a normalization stage for compensating for certain image plane trans - formations ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical motionbased frame rate conversion"
            },
            "venue": {
                "fragments": [],
                "text": "Hierarchical motionbased frame rate conversion"
            },
            "year": 1990
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 19
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 43,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Example-Based-Image-Analysis-and-Synthesis-Beymer-Shashua/8abe2824f9851d3c465b1aa11849661430d60ca0?sort=total-citations"
}