{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 166
                            }
                        ],
                        "text": "Here again we start with minimizing the empirical risk functional Remp[f] plus a regularization termkP\u0302f k(2) defined by a regularization operator\u0302 P in the sense of Tikhonov and Arsenin (1977), i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 693,
                                "start": 0
                            }
                        ],
                        "text": "Vapnik, 1995). In other words it allows to choose an appropriate kernel given the data and the problem specific knowledge. For completeness an explicit construction of the regularization operators for polynomial kernels has been given in order to provide corresponding operators not only for translation invariant kernels. To make things more transparent Appendix A contains a worked through example for computing a SV kernel for a specific choice of regularization operators. Note that the regularized risk approach can also be dealt with in a reproducing kernel Hilbert space (RKHS) approach which may lead to sometimes more elegant exposition of the subject, see Kimeldorf and Wahba (1971); Micchelli (1986); Wahba (1990); Girosi (1997); Scho \u0308lk pf (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 167309,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "20f6d89f13d8397b51f938f795e2666b4c0f33a9",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive the correspondence between regularization operators used in Regularization Networks and Hilbert Schmidt Kernels appearing in Support Vector Machines. More specifically, we prove that the Green's Functions associated with regularization operators are suitable Support Vector Kernels with equivalent regularization properties. As a by-product we show that a large number of Radial Basis Functions namely conditionally positive definite functions may be used as Support Vector kernels."
            },
            "slug": "From-Regularization-Operators-to-Support-Vector-Smola-Sch\u00f6lkopf",
            "title": {
                "fragments": [],
                "text": "From Regularization Operators to Support Vector Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "It is proved that the Green's Functions associated with regularization operators are suitable Support Vector Kernels with equivalent regularization properties and a large number of Radial Basis Functions namely conditionally positive definite functions may be used as Support Vector kernels."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166443669"
                        ],
                        "name": "M. Jones",
                        "slug": "M.-Jones",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 101
                            }
                        ],
                        "text": "B\nConsequently, one may use kernels like those proposed in the context of regularization networks by Girosi et al. (1993) as SV kernels:\nk(x, y) \u00bc e\u00b9 bkx \u00b9 yk 2 Gaussian, (m\u00bc 0) (47)\nk(x, y) \u00bc \u00b9 kx \u00b9 yk2 \u00fe c2 q multiquadric, (m\u00bc 1) (48)\nk(x, y) \u00bc 1 kx \u00b9 yk2 \u00fe c2 q inverse multiquadric, (m\u00bc\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 71
                            }
                        ],
                        "text": "Following the exposition of Yuille and Grzywacz (1988) as described in Girosi et al. (1993), one can see that for kP\u0302fk2 \u00bc \u222b\ndx \u2211 m j2m m!"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 70
                            }
                        ],
                        "text": "In Appendix A, we provide a worked through example (mainly taken from Girosi et al., 1993) for a simple regularization operator to illustrate our reasoning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 94
                            }
                        ],
                        "text": "These two problems can be solved by employing the concept of Green\u2019s functions as described in Girosi et al. (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 71
                            }
                        ],
                        "text": "We will follow the lines of Madych and Nelson (1990) as pointed out by Girosi et al. (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 165
                            }
                        ],
                        "text": "In this section we will construct a support vector kernel for the regularization operator kP\u0302fk2 \u00bc \u3008P\u0302f\u00b7P\u0302f \u3009 \u00bc \u3008f\u00b7P\u0302pP\u0302f \u3009 \u00bc kf k22 \u00fe \u2211n i \u00bc 1 k]xi f k 2 2 (A1)\nThis example is taken from Girosi et al. (1993) and used to illustrate our reasoning in detail."
                    },
                    "intents": []
                }
            ],
            "corpusId": 53854,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "1b76ef6f839cc03559ae7ce5ded915c55c2214ab",
            "isKey": true,
            "numCitedBy": 111,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Poggio and Girosi showed that regularization principles lead to approximation schemes which are equivalent to networks with one layer of hidden units, called regularization networks. They summarize their results (1993) that show that regularization networks encompass a much broader range of approximation schemes, including many of the general additive models and some of the neural networks. In particular, additive splines as well as some tensor product splines can be obtained from appropriate classes of smoothness functionals. The same extension that extends radial basis functions to hyper basis functions leads from additive models to ridge approximation models, containing as special cases Breiman's hinge functions and some forms of projection pursuit regression. The authors propose to use the term generalized regularization networks for this broad class of approximation schemes that follow from an extension of regularization.<<ETX>>"
            },
            "slug": "From-regularization-to-radial,-tensor-and-additive-Poggio-Girosi",
            "title": {
                "fragments": [],
                "text": "From regularization to radial, tensor and additive splines"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The authors propose to use the term generalized regularization networks for this broad class of approximation schemes that follow from an extension of regularization, including many of the general additive models and some of the neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing III - Proceedings of the 1993 IEEE-SP Workshop"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 101
                            }
                        ],
                        "text": "P\u0302 is a positive semidefinite operator 1 Portions of this work have been published in Smola and Scho \u0308lkopf (1998). 638 A."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 62
                            }
                        ],
                        "text": "By computing Wolfe\u2019s dual (for details of the calculations see Smola and Scho\u00a8lk pf, 1997), and using\nDij : \u00bc \u3008(P\u0302k)(xi , :)\u00b7(P\u0302k)(xj , :)\u3009 (11)\n(\u3008f\u00b7g\u3009 denotes the dot product of the functionsf and g in Hilbert Space, e.g. \u222b f\u0304 (x)g(x)dx), we get\n~a \u00bc D\u00b9 1K(~b \u00b9 ~bp), with b i, bpi being the solution of\nminimize 1 2 \u2211l i, j \u00bc 1 (bpi \u00b9 bi)(b p j \u00b9 bj)\u00f0KD \u00b9 1K)ij\n\u00b9 \u2211l i \u00bc 1 ((bpi \u00b9 bi)yi \u00b9 (bpi \u00fe bi)e)\nsubject to \u2211l i \u00bc 1 (bi \u00b9bpi ) \u00bc 0, bi ; bpi [ 0, 1 ll : \u00f012\u00de\nUnfortunately, this setting of the problem does not preserve sparsity in terms of the coefficients, as a potentially sparse decomposition in terms ofb i and b p i is spoiled byD\n-1K, which in general is not diagonal (Eq."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 279
                            }
                        ],
                        "text": "Here again we start with minimizing the empirical risk functional Remp[f] plus a regularization termkP\u0302f k2 defined by a regularization operator\u0302P in the sense of Tikhonov and Arsenin (1977), i.e.P\u0302 is a positive semidefinite operator 1 Portions of this work have been published in Smola and Scho\u00a8lkopf (1998).\nmapping from the Hilbert SpaceH of functions f under consideration to a dot product spaceD such that the expression \u3008P\u0302f\u00b7P\u0302g\u3009 is well defined."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 101
                            }
                        ],
                        "text": "P\u0302 is a positive semidefinite operator 1 Portions of this work have been published in Smola and Scho \u0308lkopf (1998). 638 A.J. Smola et al. / Neural Networks 11 (1998) 637\u2013649"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 30
                            }
                        ],
                        "text": "For a detailed discussion see Smola and Scho\u00a8lk pf (1997); Smola et al. (1998)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11652139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0366ce5be03f003f8b28078f8e154a79baa80987",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. We present a kernel-based framework for pattern recognition, regression estimation, function approximation, and multiple operator inversion. Adopting a regularization-theoretic framework, the above are formulated as constrained optimization problems. Previous approaches such as ridge regression, support vector methods, and regularization networks are included as special cases. We show connections between the cost function and some properties up to now believed to apply to support vector machines only. For appropriately chosen cost functions, the optimal solution of all the problems described above can be found by solving a simple quadratic programming problem."
            },
            "slug": "On-a-Kernel-Based-Method-for-Pattern-Recognition,-Smola-Sch\u00f6lkopf",
            "title": {
                "fragments": [],
                "text": "On a Kernel-Based Method for Pattern Recognition, Regression, Approximation, and Operator Inversion"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A kernel-based framework for pattern recognition, regression estimation, function approximation, and multiple operator inversion is presented, adopting a regularization-theoretic framework."
            },
            "venue": {
                "fragments": [],
                "text": "Algorithmica"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 249
                            }
                        ],
                        "text": "Note that the regularized risk approach can also be dealt with in a reproducing kernel Hilbert space (RKHS) approach which may lead to sometimes more elegant exposition of the subject, see Kimeldorf and Wahba (1971); Micchelli (1986); Wahba (1990); Girosi (1997); Scho\u00a8lk pf (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 143
                            }
                        ],
                        "text": "Another possible setting also might be an operatorP\u0302 mapping from L2(Rn) into some reproducing kernel Hilbert space (Kimeldorf and Wahba, 1971; Girosi, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6082464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d27c7569fdbcbb57ff511f5293e32b547acca7b3",
            "isKey": false,
            "numCitedBy": 572,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "This article shows a relationship between two different approximation techniques: the support vector machines (SVM), proposed by V. Vapnik (1995) and a sparse approximation scheme that resembles the basis pursuit denoising algorithm (Chen, 1995; Chen, Donoho, & Saunders, 1995). SVM is a technique that can be derived from the structural risk minimization principle (Vapnik, 1982) and can be used to estimate the parameters of several different approximation schemes, including radial basis functions, algebraic and trigonometric polynomials, B-splines, and some forms of multilayer perceptrons. Basis pursuit denoising is a sparse approximation technique in which a function is reconstructed by using a small number of basis functions chosen from a large set (the dictionary). We show that if the data are noiseless, the modified version of basis pursuit denoising proposed in this article is equivalent to SVM in the following sense: if applied to the same data set, the two techniques give the same solution, which is obtained by solving the same quadratic programming problem. In the appendix, we present a derivation of the SVM technique in the framework of regularization theory, rather than statistical learning theory, establishing a connection between SVM, sparse approximation, and regularization theory."
            },
            "slug": "An-Equivalence-Between-Sparse-Approximation-and-Girosi",
            "title": {
                "fragments": [],
                "text": "An Equivalence Between Sparse Approximation and Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "If the data are noiseless, the modified version of basis pursuit denoising proposed in this article is equivalent to SVM in the following sense: if applied to the same data set, the two techniques give the same solution, which is obtained by solving the same quadratic programming problem."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6674407,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3f600e6c6cf93e78c9e6e690443d6d22c4bf18b9",
            "isKey": false,
            "numCitedBy": 7883,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for performing a nonlinear form of principal component analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in high-dimensional feature spaces, related to input space by some nonlinear mapfor instance, the space of all possible five-pixel products in 16 16 images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition."
            },
            "slug": "Nonlinear-Component-Analysis-as-a-Kernel-Eigenvalue-Sch\u00f6lkopf-Smola",
            "title": {
                "fragments": [],
                "text": "Nonlinear Component Analysis as a Kernel Eigenvalue Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new method for performing a nonlinear form of principal component analysis by the use of integral operator kernel functions is proposed and experimental results on polynomial feature extraction for pattern recognition are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 28
                            }
                        ],
                        "text": "Following the exposition of Yuille and Grzywacz (1988) as described in Girosi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 3
                            }
                        ],
                        "text": "In Vapnik et al. (1997) the use of Bq-splines was proposed (see Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 3
                            }
                        ],
                        "text": "In Vapnik et al. (1997), a class of kernels generating Fourier expansions was introduced for interpolating data onRn,\nk(x) \u00bc sin(2N \u00fe 1)x=2\nsinx=2 (27)\n(As in example 3 considerx [ R1 to avoid tedious notation.)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 75
                            }
                        ],
                        "text": "The SV algorithm for regression estimation, as described in Vapnik (1995); Vapnik et al. (1997), exploits the idea of computing a linear function in high dimensional feature spaceF (furnished with a dot product)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 44422404,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ad3fdd0b3746845b69f21a4ee30de0dd0f74c3c6",
            "isKey": true,
            "numCitedBy": 84,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The Support Vector (SV) method is a new general method of function estimation which does not depend explicitly on the dimensionality of input space. It was applied for pattern recognition, regression estimation, and density estimation problems as well as for problems of solving linear operator equations. In this article we describe the general idea of the SV method and present theorems demonstrating that the generalization ability of the SV method is based on factors which classical statistics do not take into account. We also describe the SV method for density estimation in a set of functions defined by a mixture of an infinite number of Gaussians."
            },
            "slug": "The-Support-Vector-Method-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Support Vector Method"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The general idea of the Support Vector method is described and theorems demonstrating that the generalization ability of the SV method is based on factors which classical statistics do not take into account are presented."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145807836"
                        ],
                        "name": "M. Ferraro",
                        "slug": "M.-Ferraro",
                        "structuredName": {
                            "firstName": "Mario",
                            "lastName": "Ferraro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ferraro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861262"
                        ],
                        "name": "T. Caelli",
                        "slug": "T.-Caelli",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Caelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Caelli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12561610,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "852f28e35e92cde8bbaad8abc7a822d1f4a6e846",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers image representations based on integral transforms which are invariant under certain transformations, while preserving the uniqueness of the encoding. Necessary and sufficient conditions are determined for the existence of such representations and a method to determine the kernels of the related integral transforms is presented. Finally, the possible relevance of such considerations for the understanding of invariant recognition systems in biological vision is also explored."
            },
            "slug": "Lie-transformation-groups,-integral-transforms,-and-Ferraro-Caelli",
            "title": {
                "fragments": [],
                "text": "Lie transformation groups, integral transforms, and invariant pattern recognition."
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Nile and sufficient conditions are determined for the existence of image representations based on integral transforms which are invariant under certain transformations, while preserving the uniqueness of the encoding, and a method to determine the kernels of the related integral transforms is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Spatial vision"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770745"
                        ],
                        "name": "P. Niyogi",
                        "slug": "P.-Niyogi",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Niyogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Niyogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 49
                            }
                        ],
                        "text": "Training a SV machine with Gaussian RBF kernels (Scho\u00a8lkopf et al., 1997) corresponds to minimizing the specific cost function with a regularization operator of type Eq."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1900499,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4a422669ec9b6a60b05d2d2595314008a5fb419",
            "isKey": false,
            "numCitedBy": 1314,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The support vector (SV) machine is a novel type of learning machine, based on statistical learning theory, which contains polynomial classifiers, neural networks, and radial basis function (RBF) networks as special cases. In the RBF case, the SV algorithm automatically determines centers, weights, and threshold that minimize an upper bound on the expected test error. The present study is devoted to an experimental comparison of these machines with a classical approach, where the centers are determined by X-means clustering, and the weights are computed using error backpropagation. We consider three machines, namely, a classical RBF machine, an SV machine with Gaussian kernel, and a hybrid system with the centers determined by the SV method and the weights trained by error backpropagation. Our results show that on the United States postal service database of handwritten digits, the SV machine achieves the highest recognition accuracy, followed by the hybrid system. The SV approach is thus not only theoretically well-founded but also superior in a practical application."
            },
            "slug": "Comparing-support-vector-machines-with-Gaussian-to-Sch\u00f6lkopf-Sung",
            "title": {
                "fragments": [],
                "text": "Comparing support vector machines with Gaussian kernels to radial basis function classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The results show that on the United States postal service database of handwritten digits, the SV machine achieves the highest recognition accuracy, followed by the hybrid system, and the SV approach is thus not only theoretically well-founded but also superior in a practical application."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30545896,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "356125478f5d06b564b420755a4944254045bbbe",
            "isKey": false,
            "numCitedBy": 627,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "Foreword The Support Vector Machine has recently been introduced as a new technique for solving various function estimation problems, including the pattern recognition problem. To develop such a technique, it was necessary to rst extract factors responsible for future generalization, to obtain bounds on generalization that depend on these factors, and lastly to develop a technique that constructively minimizes these bounds. The subject of this book are methods based on combining advanced branches of statistics and functional analysis, developing these theories into practical algorithms that perform better than existing heuristic approaches. The book provides a comprehensive analysis of what can be done using Support Vector Machines, achieving record results in real-life pattern recognition problems. In addition, it proposes a new form of nonlinear Principal Component Analysis using Support Vector kernel techniques, which I consider as the most natural and elegant way for generalization of classical Principal Component Analysis. In many ways the Support Vector machine became so popular thanks to works of Bernhard Schh olkopf. The work, submitted for the title of Doktor der Naturwis-senschaften, appears as excellent. It is a substantial contribution to Machine Learning technology."
            },
            "slug": "Support-vector-learning-Sch\u00f6lkopf",
            "title": {
                "fragments": [],
                "text": "Support vector learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This book provides a comprehensive analysis of what can be done using Support vector Machines, achieving record results in real-life pattern recognition problems, and proposes a new form of nonlinear Principal Component Analysis using Support Vector kernel techniques, which it is considered as the most natural and elegant way for generalization of classical Principal Component analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51027413"
                        ],
                        "name": "M. Unser",
                        "slug": "M.-Unser",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Unser",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Unser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743465"
                        ],
                        "name": "A. Aldroubi",
                        "slug": "A.-Aldroubi",
                        "structuredName": {
                            "firstName": "Akram",
                            "lastName": "Aldroubi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aldroubi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144967468"
                        ],
                        "name": "M. Eden",
                        "slug": "M.-Eden",
                        "structuredName": {
                            "firstName": "Murray",
                            "lastName": "Eden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Eden"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 52
                            }
                        ],
                        "text": "Recalling the definition (up to scaling factors) by Unser et al. (1991)\nBq \u00bc # q\u00fe 1 1[ \u00b9 0:5,0:5] (23)\nwe can utilize the above result and the Fourier\u2013Plancherel identity to construct the Fourier representation of the corresponding regularization operator."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 52
                            }
                        ],
                        "text": "Recalling the definition (up to scaling factors) by Unser et al. (1991) Bq 1\u20444 # q\u00fe 1 1[ 1 0:5,0:5] (23)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42151621,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "669ef0dc34bb56a1e8531ee3954e4b395b73cfe3",
            "isKey": false,
            "numCitedBy": 593,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Efficient algorithms for the continuous representation of a discrete signal in terms of B-splines (direct B-spline transform) and for interpolative signal reconstruction (indirect B-spline transform) with an expansion factor m are described. Expressions for the z-transforms of the sampled B-spline functions are determined and a convolution property of these kernels is established. It is shown that both the direct and indirect spline transforms involve linear operators that are space invariant and are implemented efficiently by linear filtering. Fast computational algorithms based on the recursive implementations of these filters are proposed. A B-spline interpolator can also be characterized in terms of its transfer function and its global impulse response (cardinal spline of order n). The case of the cubic spline is treated in greater detail. The present approach is compared with previous methods that are reexamined from a critical point of view. It is concluded that B-spline interpolation correctly applied does not result in a loss of image resolution and that this type of interpolation can be performed in a very efficient manner. >"
            },
            "slug": "Fast-B-spline-Transforms-for-Continuous-Image-and-Unser-Aldroubi",
            "title": {
                "fragments": [],
                "text": "Fast B-spline Transforms for Continuous Image Representation and Interpolation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is concluded that B-spline interpolation correctly applied does not result in a loss of image resolution and that this type of interpolation can be performed in a very efficient manner."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50456127"
                        ],
                        "name": "I. J. Schoenberg",
                        "slug": "I.-J.-Schoenberg",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Schoenberg",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. J. Schoenberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 234
                            }
                        ],
                        "text": "This is very useful as the property of being cpd often is easier to verify than Mercer\u2019s condition, especially when combined with the results of Schoenberg and Micchelli on the connection between cpd and completely monotonic functions Schoenberg (1938a); Schoenberg (1938b); Micchelli (1986)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 125
                            }
                        ],
                        "text": "A function h(x) is called completely monotonic of order m if\n( \u00b9 1)n dn\ndxn h(x) $ 0 for x [ R\u00fe0 andn $ m (45)\nIt can be shown (Schoenberg, 1938a; Schoenberg, 1938b; Micchelli, 1986) that a functionh(x2) is conditionally positive definite if and only ifh(x) is completely monotonic of the same order."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18673721,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b9a933d2aaeed93d99064f64a8e58814017695ef",
            "isKey": false,
            "numCitedBy": 758,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "As poo we get the space Em with the distance function maxi-, ... I xi X. Let, furthermore, lP stand for the space of real sequences with the series of pth powers of the absolute values convergent. Similarly let LP denote the space of real measurable functions in the interval (0, 1) which are summable to the pth power, while C shall mean the space of real continuous functions in the same interval. In all these spaces a distance function is assumed to be defined as usual. t L2 is equivalent to the real Hilbert space t. The spaces EmP, IP and LP are metric only if p > 1, but we shall consider them also for positive values of p O). A general theorem of Banach and Mazur ([1], p. 187) states that any separable metric space (5 may be imbedded isometrically in the space C. Furthermore, as a special case of a well known theorem of Urysohn, any such space (E may be imbedded topologically in t. Isometric imbeddability of (E in '& is, however, a much more restricted property of (B. The chief purpose of this paper is to point out the intimate relationship between the problem of isometric imbedding and the concept of positive definite functions, if this concept is properly enlarged. As a first approach to this connection we consider here isometric imbedding in Hilbert space only. It turns out that the possibility of imbedding$ in 6& is very easily expressible in terms of the elementary function e-t2 and the concept of positive definite functions (Theorem 1). The author's previous result ([10]) to the effect that i(,y), (O <,y < 1), which is the space arising from 6& by raising its metric to a"
            },
            "slug": "Metric-spaces-and-positive-definite-functions-Schoenberg",
            "title": {
                "fragments": [],
                "text": "Metric spaces and positive definite functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1938
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 167
                            }
                        ],
                        "text": "The idea of flatnessis derived from pattern recognition where this corresponds to finding a hyperplane that has maximum distance in F from the classes to be separated Boser et al. (1992); Cortes and Vapnik (1995). As shown in Vapnik (1995) for the case of e-insensitive cost functions,"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 192
                            }
                        ],
                        "text": "Instead of evaluating this mapping explicitly, one uses integral operator kernelsk(x, y) which correspond to dot products of the mapped data in high dimensional space, Aizerman et al. (1964); Boser et al. (1992), i.e.\nk(x, y) \u00bc \u3008F(x)\u00b7F(y)\u3009 (1) with F: Rn \u2192 F denoting the map into feature spaceF."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 167
                            }
                        ],
                        "text": "The idea of flatnessis derived from pattern recognition where this corresponds to finding a hyperplane that has maximum distance in F from the classes to be separated Boser et al. (1992); Cortes and Vapnik (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207165665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2599131a4bc2fa957338732a37c744cfe3e17b24",
            "isKey": false,
            "numCitedBy": 10843,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms."
            },
            "slug": "A-training-algorithm-for-optimal-margin-classifiers-Boser-Guyon",
            "title": {
                "fragments": [],
                "text": "A training algorithm for optimal margin classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented, applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2634385"
                        ],
                        "name": "W. Madych",
                        "slug": "W.-Madych",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Madych",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Madych"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143758670"
                        ],
                        "name": "S. Nelson",
                        "slug": "S.-Nelson",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Nelson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 15
                            }
                        ],
                        "text": "In Dyn (1991); Madych and Nelson (1990) it was shown that cpd functionsh of orderm generate semi-norms k.kh by\nkf k2h :\u00bc \u222b dxidxjh(kxi \u00b9 xjk 2)f (xi)f (xj) (46)\nprovided that the projection off ontoPnm is zero."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 28
                            }
                        ],
                        "text": "We will follow the lines of Madych and Nelson (1990) as pointed out by Girosi et al. (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 217
                            }
                        ],
                        "text": "Note that the regularized risk approach can also be dealt with in a reproducing kernel Hilbert space (RKHS) approach which may lead to sometimes more elegant exposition of the subject, see Kimeldorf and Wahba (1971); Micchelli (1986); Wahba (1990); Girosi (1997); Scho \u0308lk pf (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 40802283,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "da041bbf08388c7f83982acfe0c8bfc23b12d4c6",
            "isKey": false,
            "numCitedBy": 562,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We continue an earlier study of certain spaces that provide a variational framework for multivariate interpolation. Using the Fourier transform to analyze these spaces, we obtain error estimates of arbitrarily high order for a class of interpolation methods that includes multiquadrics"
            },
            "slug": "Multivariate-interpolation-and-condi-tionally-Madych-Nelson",
            "title": {
                "fragments": [],
                "text": "Multivariate interpolation and condi-tionally positive definite functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144241870"
                        ],
                        "name": "J. J. Mor\u00e9",
                        "slug": "J.-J.-Mor\u00e9",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Mor\u00e9",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. J. Mor\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2982477"
                        ],
                        "name": "G. Toraldo",
                        "slug": "G.-Toraldo",
                        "structuredName": {
                            "firstName": "Gerardo",
                            "lastName": "Toraldo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Toraldo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "More and Toraldo, 1991; Vanderbei, 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 43057564,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f0dbfff278448637e6f0453b70b205bed58d706a",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is proposed that uses the conjugate gradient method to explore the face of the feasible region defined by the current iterate, and the gradient projection method to move to a different face. It is proved that for strictly convex problems the algorithm converges to the solution, and that if the solution is nondegenerate, then the algorithm terminates at the solution in a finite number of steps. Numerical results are presented for the obstacle problem, the elastic-plastic torsion problem, and the journal bearing problems. On a selection of these problems with dimensions ranging from 5000 to 15,000, the algorithm determines the solution in fewer than 15 iterations, and with a small number of function-gradient evaluations and Hessian-vector products per iteration."
            },
            "slug": "On-the-Solution-of-Large-Quadratic-Programming-with-Mor\u00e9-Toraldo",
            "title": {
                "fragments": [],
                "text": "On the Solution of Large Quadratic Programming Problems with Bound Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is proved that for strictly convex problems the algorithm converges to the solution, and that if the solution is nondegenerate, then the algorithm terminates at the solution in a finite number of steps."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Optim."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3092674"
                        ],
                        "name": "Joseph Segman",
                        "slug": "Joseph-Segman",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Segman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Segman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144866196"
                        ],
                        "name": "J. Rubinstein",
                        "slug": "J.-Rubinstein",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Rubinstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rubinstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804190"
                        ],
                        "name": "Y. Zeevi",
                        "slug": "Y.-Zeevi",
                        "structuredName": {
                            "firstName": "Yehoshua",
                            "lastName": "Zeevi",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Zeevi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39290518,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "fde0f39c995014bc27423533dc7121227e21c175",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for the analysis of deformed patterns is presented and analyzed. The image is transformed into a new set of coordinates in which the deformation has a particular simple form. A number of deformations are considered. The practical implementation of the method is discussed. Similar aspects of biological vision are also considered. >"
            },
            "slug": "The-Canonical-Coordinates-Method-for-Pattern-and-Segman-Rubinstein",
            "title": {
                "fragments": [],
                "text": "The Canonical Coordinates Method for Pattern Deformation: Theoretical and Computational Considerations"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A method for the analysis of deformed patterns is presented and analyzed where the image is transformed into a new set of coordinates in which the deformation has a particular simple form."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35224059"
                        ],
                        "name": "S. Golowich",
                        "slug": "S.-Golowich",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Golowich",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Golowich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19196574,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43ffa2c1a06a76e58a333f2e7d0bd498b24365ca",
            "isKey": false,
            "numCitedBy": 2604,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The Support Vector (SV) method was recently proposed for estimating regressions, constructing multidimensional splines, and solving linear operator equations [Vapnik, 1995]. In this presentation we report results of applying the SV method to these problems."
            },
            "slug": "Support-Vector-Method-for-Function-Approximation,-Vapnik-Golowich",
            "title": {
                "fragments": [],
                "text": "Support Vector Method for Function Approximation, Regression Estimation and Signal Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This presentation reports results of applying the Support Vector method to problems of estimating regressions, constructing multidimensional splines, and solving linear operator equations."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3224336"
                        ],
                        "name": "L. Niklasson",
                        "slug": "L.-Niklasson",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Niklasson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Niklasson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867541"
                        ],
                        "name": "M. Bod\u00e9n",
                        "slug": "M.-Bod\u00e9n",
                        "structuredName": {
                            "firstName": "Mikael",
                            "lastName": "Bod\u00e9n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bod\u00e9n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2491309"
                        ],
                        "name": "T. Ziemke",
                        "slug": "T.-Ziemke",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Ziemke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ziemke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 58
                            }
                        ],
                        "text": "For a detailed discussion see Smola and Scho\u00a8lk pf (1997); Smola et al. (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18411295,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8fcfa240acf5d462793d708bb85872182211caf8",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The concept of Support Vector Regression is extended to a more general class of convex cost functions. It is shown how the resulting convex constrained optimization problems can be efficiently solved by a Primal-Dual Interior Point path following method. Both computational feasibility and improvement of estimation is demonstrated in the experiments."
            },
            "slug": "Convex-Cost-Functions-for-Support-Vector-Regression-Smola-Sch\u00f6lkopf",
            "title": {
                "fragments": [],
                "text": "Convex Cost Functions for Support Vector Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "The concept of Support Vector Regression is extended and it is shown how the resulting convex constrained optimization problems can be efficiently solved by a Primal-Dual Interior Point path following method."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1986103"
                        ],
                        "name": "R. Vanderbei",
                        "slug": "R.-Vanderbei",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Vanderbei",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vanderbei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 218
                            }
                        ],
                        "text": "This can lead to numerical instabilities for quadratic programming codes as they usually assume the quadratic matrix to be positive semidefinite not only in the feasible region of the parameters but on the whole space (cf. More and Toraldo, 1991; Vanderbei, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 24
                            }
                        ],
                        "text": "More and Toraldo, 1991; Vanderbei, 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 80868,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ff9b1158ff89903e7d8e21ebad37d0906bdf3cf0",
            "isKey": false,
            "numCitedBy": 550,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a software package, called LOQO, which implements a primal-dual interior-point method for general nonlinear programming. We focus in this paper mainly on the algorithm as it applies to linear and quadratic programming with only brief mention of the extensions to convex and general nonlinear programming, since a detailed paper describing these extensions was published recently elsewhere. In particular, we emphasize the importance of establishing and maintaining symmetric quasidefiniteness of the reduced KKT system. We show that the industry standard MPS format can be nicely formulated in such a way to provide quasidefiniteness. Computational results are included for a variety of linear and quadratic programming problems."
            },
            "slug": "LOQO:an-interior-point-code-for-quadratic-Vanderbei",
            "title": {
                "fragments": [],
                "text": "LOQO:an interior point code for quadratic programming"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper describes a software package, called LOQO, which implements a primal-dual interior-point method for general nonlinear programming, and shows that the industry standard MPS format can be nicely formulated in such a way to provide quasidefiniteness."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145833095"
                        ],
                        "name": "S. Kothari",
                        "slug": "S.-Kothari",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Kothari",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kothari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681982"
                        ],
                        "name": "H. Oh",
                        "slug": "H.-Oh",
                        "structuredName": {
                            "firstName": "Heekuck",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Oh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 107
                            }
                        ],
                        "text": "Besides that model selection principles like structural risk minimization (Vapnik, 1982), cross validation (Bishop, 1995; Amari et al., 1997; Kearns, 1997), MDL (Rissanen, 1985), Bayesian methods (MacKay, 1991; Bishop, 1995), etc."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 62
                            }
                        ],
                        "text": ", 1997; Kearns, 1997), MDL (Rissanen, 1985), Bayesian methods (MacKay, 1991; Bishop, 1995), etc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1103,
                                "start": 108
                            }
                        ],
                        "text": "Besides that model selection principles like structural risk minimization (Vapnik, 1982), cross validation (Bishop, 1995; Amari et al., 1997; Kearns, 1997), MDL (Rissanen, 1985), Bayesian methods (MacKay, 1991; Bishop, 1995), etc. can be employed. Choosing a small width of the kernels leads to high generalization error as it effectively decouples the separate basis functions of the kernel expansion into very localized functions which is equivalent to memorizing the data, whereas a wide kernel tends to oversmooth. Note that the choice of the width may be more important than the actual functional form of the kernel. There may be little difference in the relevant part of the filter properties between e.g. aB-spline and a Gaussian kernel (cf. Fig. 6). The invariance of the kernels presented so far has been exploited only in the context of invariance with respect to the translation symmetry group in R. Yet they could also be applied to other symmetry transformations corresponding to other canonical coordinate systems such as the rotation and scaling group as proposed by Segman et al. (1992); Ferraro and Caelli (1994), i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 177751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbc0a468ab103ae29717703d4aa9f682f6a2b664",
            "isKey": false,
            "numCitedBy": 15339,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Networks-for-Pattern-Recognition-Kothari-Oh",
            "title": {
                "fragments": [],
                "text": "Neural Networks for Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9100510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17f00d448fbdc78708f9d8fe22c8b3d0a032233f",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We give a theoretical and experimental analysis of the generalization error of cross validation using two natural measures of the problem under consideration. The approximation rate measures the accuracy to which the target function can be ideally approximated as a function of the number of parameters, and thus captures the complexity of the target function with respect to the hypothesis model. The estimation rate measures the deviation between the training and generalization errors as a function of the number of parameters, and thus captures the extent to which the hypothesis model suffers from overfitting. Using these two measures, we give a rigorous and general bound on the error of the simplest form of cross validation. The bound clearly shows the dangers of making the fraction of data saved for testingtoo large or too small. By optimizing the bound with respect to , we then argue that the following qualitative properties of cross-validation behavior should be quite robust to significant changes in the underlying model selection problem: When the target function complexity is small compared to the sample size, the performance of cross validation is relatively insensitive to the choice of . The importance of choosing optimally increases, and the optimal value for decreases, as the target function becomes more complex relative to the sample size. There is nevertheless a single fixed value for that works nearly optimally for a wide range of target function complexity."
            },
            "slug": "A-Bound-on-the-Error-of-Cross-Validation-Using-the-Kearns",
            "title": {
                "fragments": [],
                "text": "A Bound on the Error of Cross Validation Using the Approximation and Estimation Rates, with Consequences for the Training-Test Split"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is argued that the following qualitative properties of cross-validation behavior should be quite robust to significant changes in the underlying model selection problem: when the target function complexity is small compared to the sample size, the performance of cross validation is relatively insensitive to the choice of ."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15109515,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51c1519a57a65351a713a3d74f8d477105df0ec3",
            "isKey": false,
            "numCitedBy": 352,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore methods for incorporating prior knowledge about a problem at hand in Support Vector learning machines. We show that both invariances under group transformations and prior knowledge about locality in images can be incorporated by constructing appropriate kernel functions."
            },
            "slug": "Prior-Knowledge-in-Support-Vector-Kernels-Sch\u00f6lkopf-Simard",
            "title": {
                "fragments": [],
                "text": "Prior Knowledge in Support Vector Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "It is shown that both invariances under group transformations and prior knowledge about locality in images can be incorporated by constructing appropriate kernel functions by exploring methods for incorporating prior knowledge in Support Vector learning machines."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145733439"
                        ],
                        "name": "G. Wahba",
                        "slug": "G.-Wahba",
                        "structuredName": {
                            "firstName": "Grace",
                            "lastName": "Wahba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wahba"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 235
                            }
                        ],
                        "text": "Note that the regularized risk approach can also be dealt with in a reproducing kernel Hilbert space (RKHS) approach which may lead to sometimes more elegant exposition of the subject, see Kimeldorf and Wahba (1971); Micchelli (1986); Wahba (1990); Girosi (1997); Scho\u00a8lk pf (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121858740,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e786caa59202d923ccaae00ae6a4682eec92699b",
            "isKey": false,
            "numCitedBy": 5073,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Foreword 1. Background 2. More splines 3. Equivalence and perpendicularity, or, what's so special about splines? 4. Estimating the smoothing parameter 5. 'Confidence intervals' 6. Partial spline models 7. Finite dimensional approximating subspaces 8. Fredholm integral equations of the first kind 9. Further nonlinear generalizations 10. Additive and interaction splines 11. Numerical methods 12. Special topics Bibliography Author index."
            },
            "slug": "Spline-Models-for-Observational-Data-Wahba",
            "title": {
                "fragments": [],
                "text": "Spline Models for Observational Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 82
                            }
                        ],
                        "text": "(6), on the other hand, does typically have many vanishing coefficients, see e.g. Scho\u00a8lkopf et al., 1995; Vapnik, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6636078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ec8029e5855b6efbac161488a2e68f83298091c",
            "isKey": false,
            "numCitedBy": 650,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We report a novel possibility for extracting a small subset of a data base which contains all the information necessary to solve a given classification task: using the Support Vector Algorithm to train three different types of handwritten digit classifiers, we observed that these types of classifiers construct their decision surface from strongly overlapping small (\u2248 4%) subsets of the data base. This finding opens up the possibility of compressing data bases significantly by disposing of the data which is not important for the solution of a given task. \n \nIn addition, we show that the theory allows us to predict the classifier that will have the best generalization ability, based solely on performance on the training set and characteristics of the learning machines. This finding is important for cases where the amount of available data is limited."
            },
            "slug": "Extracting-Support-Data-for-a-Given-Task-Sch\u00f6lkopf-Burges",
            "title": {
                "fragments": [],
                "text": "Extracting Support Data for a Given Task"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is observed that three different types of handwritten digit classifiers construct their decision surface from strongly overlapping small subsets of the data base, which opens up the possibility of compressing data bases significantly by disposing of theData which is not important for the solution of a given task."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2653061"
                        ],
                        "name": "N. Murata",
                        "slug": "N.-Murata",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Murata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Murata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48427153"
                        ],
                        "name": "M. Finke",
                        "slug": "M.-Finke",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Finke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Finke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8896870"
                        ],
                        "name": "H. Yang",
                        "slug": "H.-Yang",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Yang",
                            "middleNames": [
                                "Hua"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7503267,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5520c0808945f4ba1a8ca4f661b2ffada29aade",
            "isKey": false,
            "numCitedBy": 351,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "A statistical theory for overtraining is proposed. The analysis treats general realizable stochastic neural networks, trained with Kullback-Leibler divergence in the asymptotic case of a large number of training examples. It is shown that the asymptotic gain in the generalization error is small if we perform early stopping, even if we have access to the optimal stopping time. Based on the cross-validation stopping we consider the ratio the examples should be divided into training and cross-validation sets in order to obtain the optimum performance. Although cross-validated early stopping is useless in the asymptotic region, it surely decreases the generalization error in the nonasymptotic region. Our large scale simulations done on a CM5 are in good agreement with our analytical findings."
            },
            "slug": "Asymptotic-statistical-theory-of-overtraining-and-Amari-Murata",
            "title": {
                "fragments": [],
                "text": "Asymptotic statistical theory of overtraining and cross-validation"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A statistical theory for overtraining is proposed and it is shown that the asymptotic gain in the generalization error is small if the authors perform early stopping, even if they have access to the optimal stopping time."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101750654"
                        ],
                        "name": "G. Kimeldorf",
                        "slug": "G.-Kimeldorf",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Kimeldorf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kimeldorf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145733439"
                        ],
                        "name": "G. Wahba",
                        "slug": "G.-Wahba",
                        "structuredName": {
                            "firstName": "Grace",
                            "lastName": "Wahba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wahba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120654716,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5f75d859e750961d1d094f166fc3b564d9cfe99b",
            "isKey": false,
            "numCitedBy": 975,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The report presents classes of prior distributions for which the Bayes' estimate of an unknown function given certain observations is a spline function. (Author)"
            },
            "slug": "A-Correspondence-Between-Bayesian-Estimation-on-and-Kimeldorf-Wahba",
            "title": {
                "fragments": [],
                "text": "A Correspondence Between Bayesian Estimation on Stochastic Processes and Smoothing by Splines"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190508"
                        ],
                        "name": "N. Grzywacz",
                        "slug": "N.-Grzywacz",
                        "structuredName": {
                            "firstName": "Norberto",
                            "lastName": "Grzywacz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Grzywacz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39137023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "884886d3c701104083311ce57af00c9091bc1a37",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Tliere are a number of important phenom- ena in motion perception involving colicrcnce. Examples include motion capture and motion cooperativity. We propose a theoretical model, called the motion coherence tlieory, that gives a possible explanation for these effects (Yuille and Grzywacz, 1988a,b). In this framework, the aperture problem can also be thought of as a problem of coherence and given a similar explanation. We propose the concept of a velocity field dcfined everywhere in the image, even where there is no explicit motion information available. Through a cost function, tlie model imposes smoothness on the velocity field in a more general way than previous theories. In this paper, we provide a de- tailed theoretical analysis of the motion coherence theory. We discuss its relations with previous theories and show that some of t1ic.m arc approximations to it. A sccorid pa- per (Grzywacz, Smith, and Yuillc, 1088) provides exten- sions and cletnilcd comparisons to psychophysical plienom- cna. Tlic theory applies to both short-range and long- range motion. It places them in the same computational framework aiid provides a way to define interactions be- twcr:11 the two 1)roccsses."
            },
            "slug": "The-Motion-Coherence-Theory-Yuille-Grzywacz",
            "title": {
                "fragments": [],
                "text": "The Motion Coherence Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes the concept of a velocity field everywhere in the image, even where there is no explicit motion information available, through a cost function, which imposes smoothness on the velocity field in a more general way than previous theories."
            },
            "venue": {
                "fragments": [],
                "text": "[1988 Proceedings] Second International Conference on Computer Vision"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 73
                            }
                        ],
                        "text": "Future work will be necessary for understanding Vapnik\u2019s capacity bounds (Vapnik, 1995) from a regularization network point of view."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 199
                            }
                        ],
                        "text": "The idea of flatnessis derived from pattern recognition where this corresponds to finding a hyperplane that has maximum distance in F from the classes to be separated Boser et al. (1992); Cortes and Vapnik (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 106
                            }
                        ],
                        "text": "(6), on the other hand, does typically have many vanishing coefficients, see e.g. Scho\u00a8lkopf et al., 1995; Vapnik, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 60
                            }
                        ],
                        "text": "The SV algorithm for regression estimation, as described in Vapnik (1995); Vapnik et al. (1997), exploits the idea of computing a linear function in high dimensional feature spaceF (furnished with a dot product)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 226
                            }
                        ],
                        "text": "The newly established link to regularization theory can thus be seen as a tool for constructing the structure consisting of sets of functions in which the SV machine (approximately) performs structural risk minimization (e.g. Vapnik, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 12
                            }
                        ],
                        "text": "As shown in Vapnik\n(1995) for the case ofe-insensitive cost functions,\nc(f (x), y) \u00bc lf (x) \u00b9 yl\u00b9 e for lf (x) \u00b9 yl $ e\n0 otherwise\n( (4)\nEq."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 24
                            }
                        ],
                        "text": "1 2\nDm0 (34)\nExample 7 (Vapnik, 1995)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": true,
            "numCitedBy": 38756,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2545803"
                        ],
                        "name": "M. Aizerman",
                        "slug": "M.-Aizerman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Aizerman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Aizerman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60493317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3caf34c1c86633b6e80dca29e3cb2b6367a0f93",
            "isKey": false,
            "numCitedBy": 1692,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theoretical-Foundations-of-the-Potential-Function-Aizerman",
            "title": {
                "fragments": [],
                "text": "Theoretical Foundations of the Potential Function Method in Pattern Recognition Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 16
                            }
                        ],
                        "text": "It can be shown (Schoenberg, 1938a; Schoenberg, 1938b; Micchelli, 1986) that a functionh(x(2)) is conditionally positive definite if and only ifh(x) is completely monotonic of the same order."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 274
                            }
                        ],
                        "text": "This is very useful as the property of being cpd often is easier to verify than Mercer\u2019s condition, especially when combined with the results of Schoenberg and Micchelli on the connection between cpd and completely monotonic functions Schoenberg (1938a); Schoenberg (1938b); Micchelli (1986)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 217
                            }
                        ],
                        "text": "Note that the regularized risk approach can also be dealt with in a reproducing kernel Hilbert space (RKHS) approach which may lead to sometimes more elegant exposition of the subject, see Kimeldorf and Wahba (1971); Micchelli (1986); Wahba (1990); Girosi (1997); Scho\u00a8lk pf (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 163
                            }
                        ],
                        "text": "A function h(x) is called completely monotonic of order m if\n( \u00b9 1)n dn\ndxn h(x) $ 0 for x [ R\u00fe0 andn $ m (45)\nIt can be shown (Schoenberg, 1938a; Schoenberg, 1938b; Micchelli, 1986) that a functionh(x2) is conditionally positive definite if and only ifh(x) is completely monotonic of the same order."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 189914732,
            "fieldsOfStudy": [],
            "id": "dcd98d1ec373dacb37fc9aeb806fd6fb3d3c9158",
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Interpolation of scattered data: Distance matrices and conditionally positive definite functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103244631"
                        ],
                        "name": "F. Riesz",
                        "slug": "F.-Riesz",
                        "structuredName": {
                            "firstName": "Frigyes",
                            "lastName": "Riesz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Riesz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 232496889,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cd653a94047dde50610db0e0227813f21e42b3e4",
            "isKey": false,
            "numCitedBy": 217,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "FUNCTIONAL-ANALYSIS-Riesz",
            "title": {
                "fragments": [],
                "text": "FUNCTIONAL ANALYSIS"
            },
            "venue": {
                "fragments": [],
                "text": "Systems Engineering Principles and Practice"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69498854"
                        ],
                        "name": "R. V. Churchill",
                        "slug": "R.-V.-Churchill",
                        "structuredName": {
                            "firstName": "Ruel",
                            "lastName": "Churchill",
                            "middleNames": [
                                "Vance"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. V. Churchill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12873112"
                        ],
                        "name": "S. Bochner",
                        "slug": "S.-Bochner",
                        "structuredName": {
                            "firstName": "Salomon",
                            "lastName": "Bochner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bochner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577510"
                        ],
                        "name": "Morris Tenenbaum",
                        "slug": "Morris-Tenenbaum",
                        "structuredName": {
                            "firstName": "Morris",
                            "lastName": "Tenenbaum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Morris Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49849336"
                        ],
                        "name": "H. Pollard",
                        "slug": "H.-Pollard",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Pollard",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Pollard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 57
                            }
                        ],
                        "text": "In fact the above is a special case of Bochner\u2019s theorem (Bochner, 1959) stating that the Fourier transform of a positive measure constitutes a positive Hilbert Schmidt kernel."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124432796,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "df0eb0bee6fb77b53fb20c622a0994f7ba75ab44",
            "isKey": false,
            "numCitedBy": 382,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lectures-on-Fourier-Integrals-Churchill-Bochner",
            "title": {
                "fragments": [],
                "text": "Lectures on Fourier Integrals"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143639508"
                        ],
                        "name": "A. Tikhonov",
                        "slug": "A.-Tikhonov",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Tikhonov",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tikhonov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102992139"
                        ],
                        "name": "Vasiliy Yakovlevich Arsenin",
                        "slug": "Vasiliy-Yakovlevich-Arsenin",
                        "structuredName": {
                            "firstName": "Vasiliy",
                            "lastName": "Arsenin",
                            "middleNames": [
                                "Yakovlevich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vasiliy Yakovlevich Arsenin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 148
                            }
                        ],
                        "text": "\u2026start with minimizing the empirical risk functional Remp[f] plus a regularization termkP\u0302f k2 defined by a regularization operator\u0302P in the sense of Tikhonov and Arsenin (1977), i.e.P\u0302 is a positive semidefinite operator 1 Portions of this work have been published in Smola and Scho\u00a8lkopf\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122072756,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bc14819e745cd7af37efd09ea29773dc0065119e",
            "isKey": false,
            "numCitedBy": 7884,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Solutions-of-ill-posed-problems-Tikhonov-Arsenin",
            "title": {
                "fragments": [],
                "text": "Solutions of ill-posed problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50456127"
                        ],
                        "name": "I. J. Schoenberg",
                        "slug": "I.-J.-Schoenberg",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Schoenberg",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. J. Schoenberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123282658,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "026c5719b82bda94d69022b2fac307ec0aa2e850",
            "isKey": false,
            "numCitedBy": 907,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Metric-spaces-and-completely-monotone-functions-Schoenberg",
            "title": {
                "fragments": [],
                "text": "Metric spaces and completely monotone functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1938
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145698858"
                        ],
                        "name": "T. Downs",
                        "slug": "T.-Downs",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Downs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Downs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40073871"
                        ],
                        "name": "Marcus Frean",
                        "slug": "Marcus-Frean",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Frean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcus Frean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36589297"
                        ],
                        "name": "M. Gallagher",
                        "slug": "M.-Gallagher",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Gallagher",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gallagher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117940753,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5a4569e2a120ef410e9ca7abbb25066c05453678",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "General-cost-functions-for-support-vector-Smola-Sch\u00f6lkopf",
            "title": {
                "fragments": [],
                "text": "General cost functions for support vector regression."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114788213"
                        ],
                        "name": "D. Signorini",
                        "slug": "D.-Signorini",
                        "structuredName": {
                            "firstName": "DavidF.",
                            "lastName": "Signorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Signorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4137433"
                        ],
                        "name": "J. Slattery",
                        "slug": "J.-Slattery",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Slattery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Slattery"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058057862"
                        ],
                        "name": "S. Dodds",
                        "slug": "S.-Dodds",
                        "structuredName": {
                            "firstName": "Sally",
                            "lastName": "Dodds",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dodds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51934565"
                        ],
                        "name": "V. Lane",
                        "slug": "V.-Lane",
                        "structuredName": {
                            "firstName": "V",
                            "lastName": "Lane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095059657"
                        ],
                        "name": "P. Littlejohns",
                        "slug": "P.-Littlejohns",
                        "structuredName": {
                            "firstName": "P",
                            "lastName": "Littlejohns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Littlejohns"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 3
                            }
                        ],
                        "text": "In Vapnik et al. (1997) the use of Bq-splines was proposed (see Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 3
                            }
                        ],
                        "text": "In Vapnik et al. (1997), a class of kernels generating Fourier expansions was introduced for interpolating data onRn,\nk(x) \u00bc sin(2N \u00fe 1)x=2\nsinx=2 (27)\n(As in example 3 considerx [ R1 to avoid tedious notation.)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 75
                            }
                        ],
                        "text": "The SV algorithm for regression estimation, as described in Vapnik (1995); Vapnik et al. (1997), exploits the idea of computing a linear function in high dimensional feature spaceF (furnished with a dot product)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2878979,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "20b844e395355b40fa5940c61362ec40e56027aa",
            "isKey": false,
            "numCitedBy": 4707,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-networks-Signorini-Slattery",
            "title": {
                "fragments": [],
                "text": "Neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "The Lancet"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052516042"
                        ],
                        "name": "G. Schwarz",
                        "slug": "G.-Schwarz",
                        "structuredName": {
                            "firstName": "Gideon",
                            "lastName": "Schwarz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Schwarz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 123722079,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "37e44d1de8003d8394d158ec6afd1ff0e87e595b",
            "isKey": false,
            "numCitedBy": 39572,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Estimating-the-Dimension-of-a-Model-Schwarz",
            "title": {
                "fragments": [],
                "text": "Estimating the Dimension of a Model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Priors, stabilizers and basis functions, From regularization to radial, tensor and additive splines. A.I. Memo No"
            },
            "venue": {
                "fragments": [],
                "text": "Priors, stabilizers and basis functions, From regularization to radial, tensor and additive splines. A.I. Memo No"
            },
            "year": 1430
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 62
                            }
                        ],
                        "text": ", 1997; Kearns, 1997), MDL (Rissanen, 1985), Bayesian methods (MacKay, 1991; Bishop, 1995), etc."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian modelling and neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. thesis, Computation and Neural Systems, California Institute of Technology, Pasadena, CA."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "for function approximation, regression estimation, and signal processing"
            },
            "venue": {
                "fragments": [],
                "text": "for function approximation, regression estimation, and signal processing"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 235
                            }
                        ],
                        "text": "Note that the regularized risk approach can also be dealt with in a reproducing kernel Hilbert space (RKHS) approach which may lead to sometimes more elegant exposition of the subject, see Kimeldorf and Wahba (1971); Micchelli (1986); Wahba (1990); Girosi (1997); Scho\u00a8lk pf (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Splines Models for Observational Data, Series in Applied Mathematics, vol"
            },
            "venue": {
                "fragments": [],
                "text": "59. Philadelphia: SIAM."
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 3
                            }
                        ],
                        "text": "In Dyn (1991); Madych and Nelson (1990) it was shown that cpd functionsh of orderm generate semi-norms k.kh by\nkf k2h :\u00bc \u222b dxidxjh(kxi \u00b9 xjk 2)f (xi)f (xj) (46)\nprovided that the projection off ontoPnm is zero."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Interpolation and approximation by radial and related functions Approximation Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Interpolation and approximation by radial and related functions Approximation Theory"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 148
                            }
                        ],
                        "text": "\u2026start with minimizing the empirical risk functional Remp[f] plus a regularization termkP\u0302f k2 defined by a regularization operator\u0302P in the sense of Tikhonov and Arsenin (1977), i.e.P\u0302 is a positive semidefinite operator 1 Portions of this work have been published in Smola and Scho\u00a8lkopf\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Solution of Ill-Posed Problems"
            },
            "venue": {
                "fragments": [],
                "text": "Solution of Ill-Posed Problems"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 3
                            }
                        ],
                        "text": "In Dyn (1991); Madych and Nelson (1990) it was shown that cpd functionsh of orderm generate semi-norms k.kh by\nkf k2h :\u00bc \u222b dxidxjh(kxi \u00b9 xjk 2)f (xi)f (xj) (46)\nprovided that the projection off ontoPnm is zero."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 3
                            }
                        ],
                        "text": "In Dyn (1991); Madych and Nelson (1990) it was shown that cpd functions h of orderm generate semi-norms k."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Interpolation and approximation by radial and related functions"
            },
            "venue": {
                "fragments": [],
                "text": "In: C.K. Chui, L.L. Schumaker, D.J. Ward, (Eds.), Approximation Theory, vol. VI. New York: Academic Press, pp. 211\u2013232."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Asymp - totic statistical theory of overtraining and cross - validation"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans . Neural Networks"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 20,
            "methodology": 8,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 44,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/The-connection-between-regularization-operators-and-Smola-Sch\u00f6lkopf/8985a9637540daa0b7b8295f8a5bbda3a3be1dea?sort=total-citations"
}