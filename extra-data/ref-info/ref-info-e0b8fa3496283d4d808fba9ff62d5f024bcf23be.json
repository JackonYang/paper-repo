{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722243"
                        ],
                        "name": "N. Linial",
                        "slug": "N.-Linial",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Linial",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Linial"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144830983"
                        ],
                        "name": "Y. Mansour",
                        "slug": "Y.-Mansour",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Mansour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Mansour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113911099"
                        ],
                        "name": "R. Rivest",
                        "slug": "R.-Rivest",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rivest",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rivest"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12405514,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "907f58a77ef4909d0e96c352cd5c7379eb22d5f5",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of learning a concept from examples in a distribution-free model is considered. The notion of dynamic sampling, wherein the number of examples examined can increase with the complexity of the target concept, is introduced. This method is used to establish the learnability of various concept classes with an infinite Vapnik-Chervonenkis (VC) dimension. An important variation on the problem of learning from examples, called approximating from examples, is also discussed. The problem of computing the VC dimension of a finite concept set defined on a finite domain is considered.<<ETX>>"
            },
            "slug": "Results-on-learnability-and-the-Vapnik-Chervonenkis-Linial-Mansour",
            "title": {
                "fragments": [],
                "text": "Results on learnability and the Vapnik-Chervonenkis dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The notion of dynamic sampling, wherein the number of examples examined can increase with the complexity of the target concept, is introduced and is used to establish the learnability of various concept classes with an infinite Vapnik-Chervonenkis (VC) dimension."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings 1988] 29th Annual Symposium on Foundations of Computer Science"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7165930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e02d1ffa45de336af35ae6fde2e8f6f19d5e50ff",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Equivalence-of-models-for-polynomial-learnability-Haussler-Kearns",
            "title": {
                "fragments": [],
                "text": "Equivalence of models for polynomial learnability"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725956"
                        ],
                        "name": "J. Vitter",
                        "slug": "J.-Vitter",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Vitter",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vitter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710610"
                        ],
                        "name": "Jyh-Han Lin",
                        "slug": "Jyh-Han-Lin",
                        "structuredName": {
                            "firstName": "Jyh-Han",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jyh-Han Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1912267,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bfb5c94f70187d1a1fd7a28b2c7d3100fbc8170",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-in-parallel-Vitter-Lin",
            "title": {
                "fragments": [],
                "text": "Learning in parallel"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150652510"
                        ],
                        "name": "Ming Li",
                        "slug": "Ming-Li",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47494927"
                        ],
                        "name": "L. Pitt",
                        "slug": "L.-Pitt",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Pitt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pitt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These notions of polynomial learnability, both closely related to the model introduced in [59] and elaborated in [ 36 ] and [52], are discussed in Sections 3.1 and 3.2, respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The above example shows that it is not only useful to parameterize learning algorithms and learnability results by the dimension of the domain, but also by some natural measure of the syntactic complexity of the target concept, in this case the number of intervals used to define it. Both of these considerations are emphasized in [ 36 ] and [52] in the investigation into the learnability of Boolean functions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Usually the class of target concepts and hypothesis space are the same and the same representation is used, but this is not always so (see, e.g., [ 36 ])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The functional and oracle models of polynomial learnability are shown to be equivalent in [30], along with another variant of the oracle model in which there are two probability distributions on the domain X, and two oracles, one for positive examples of the target concept and one for negative examples (e.g., [ 36 ] and [52])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "It is also possible to allow the computation time to depend explicitly on the accuracy and confidence parameters t and 6. Since this, and other extensions of the above model, are allowed in the definition of polynomial learnability in [52] and [59], we now introduce a second model of polynomial learnability, which we call the oracle model (see also [3] and [ 36 ])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1053873,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3948494b79dcda6d53237397123efdbb7a9954b2",
            "isKey": true,
            "numCitedBy": 315,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the computational feasibility of learning boolean expressions from examples. Our goals are to prove results and develop general techniques that shed light on the boundary between the classes of expressions that are learnable in polynomial time and those that are apparently not. The elucidation of this boundary, for boolean expressions and possibly other knowledge representations, is an example of the potential contribution of complexity theory to artificial intelligence. We employ the distribution-free model of learning introduced in /lo]. A more complete discussion and justification of this model can be found in [4,10,11,12]. [4] includes some discussion that is relevant more particularly to infinite representations, such as geometric ones, rather than the finite case of boolean functions. For other recent related work see [1,2,7,&g]. The results of this paper fall into three categories: closure properties of learnable classes, negative results, and distribution-specific positive results. The closure properties are of two kinds. In section 3 we discuss closure under boolean operations on the members of the learnable classes. The assumption that the classes are learnable from positive or negative ex-"
            },
            "slug": "On-the-learnability-of-Boolean-formulae-Kearns-Li",
            "title": {
                "fragments": [],
                "text": "On the learnability of Boolean formulae"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The goals are to prove results and develop general techniques that shed light on the boundary between the classes of expressions that are learnable in polynomial time and those that are apparently not, and to employ the distribution-free model of learning."
            },
            "venue": {
                "fragments": [],
                "text": "STOC"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150652510"
                        ],
                        "name": "Ming Li",
                        "slug": "Ming-Li",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47494927"
                        ],
                        "name": "L. Pitt",
                        "slug": "L.-Pitt",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Pitt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pitt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18958417,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebc3afef7c5455ab8bd0c06755ce926f8fe707fb",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recent-Results-on-Boolean-Concept-Learning-Kearns-Li",
            "title": {
                "fragments": [],
                "text": "Recent Results on Boolean Concept Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Is C polynomially learnable by H for any hypothesis space H as defined in Section 3.1? This is a variant of one of the problems posed in [ 59 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These notions of polynomial learnability, both closely related to the model introduced in [ 59 ] and elaborated in [36] and [52], are discussed in Sections 3.1 and 3.2, respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "It is also possible to allow the computation time to depend explicitly on the accuracy and confidence parameters t and 6. Since this, and other extensions of the above model, are allowed in the definition of polynomial learnability in [52] and [ 59 ], we now introduce a second model of polynomial learnability, which we call the oracle model (see also [3] and [36])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "They also bring up the issues of misclassification in the examples and the possibility of stochastically defined target concepts, discussed in Section A3 of the Appendix, and the possibility of combining random examples with other types of information, for example, the various oracles and queries discussed in [2], [3], and [ 59 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12837541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fc0c7afc6bb27fb3752eae0ea5869413b1259b7",
            "isKey": true,
            "numCitedBy": 1647,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learned using it in a reasonable (polynomial) number of steps. Although inherent algorithmic complexity appears to set serious limits to the range of concepts that can be learned, we show that there are some important nontrivial classes of propositional concepts that can be learned in a realistic sense."
            },
            "slug": "A-theory-of-the-learnable-Valiant",
            "title": {
                "fragments": [],
                "text": "A theory of the learnable"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper regards learning as the phenomenon of knowledge acquisition in the absence of explicit programming, and gives a precise methodology for studying this phenomenon from a computational viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 36671080,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a35203c70c6ed6a95faacd4f1c71a51692af37fb",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The probably approximately correct (PAC) model of learning from examples is generalized. The problem of learning functions from a set X into a set Y is considered, assuming only that the examples are generated by independent draws according to an unknown probability measure on X*Y. The learner's goal is to find a function in a given hypothesis space of functions from X into Y that on average give Y values that are close to those observed in random examples. The discrepancy is measured by a bounded real-valued loss function. The average loss is called the error of the hypothesis. A theorem on the uniform convergence of empirical error estimates to true error rates is given for certain hypothesis spaces, and it is shown how this implies learnability. A generalized notion of VC dimension that applies to classes of real-valued functions and a notion of capacity for classes of functions that map into a bounded metric space are given. These measures are used to bound the rate of convergence of empirical error estimates to true error rates, giving bounds on the sample size needed for learning using hypotheses in these classes. As an application, a distribution-independent uniform convergence result for certain classes of functions computed by feedforward neural nets is obtained. Distribution-specific uniform convergence results for classes of functions that are uniformly continuous on average are also obtained.<<ETX>>"
            },
            "slug": "Generalizing-the-PAC-model:-sample-size-bounds-from-Haussler",
            "title": {
                "fragments": [],
                "text": "Generalizing the PAC model: sample size bounds from metric dimension-based uniform convergence results"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The probably approximately correct (PAC) model of learning from examples is generalized, and a distribution-independent uniform convergence result for certain classes of functions computed by feedforward neural nets is obtained."
            },
            "venue": {
                "fragments": [],
                "text": "30th Annual Symposium on Foundations of Computer Science"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1925579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b83396caf4762c906530c9219a9e4dd0658232b0",
            "isKey": false,
            "numCitedBy": 499,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-general-lower-bound-on-the-number-of-examples-for-Ehrenfeucht-Haussler",
            "title": {
                "fragments": [],
                "text": "A general lower bound on the number of examples needed for learning"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The techniques we have described in this paper are easily applied to these domains, and generally give better results than the simple counting argument of Theorem 2.2 [ 28 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27204621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b814ad3055d6bfd7828effdbfbf1372646b7c22",
            "isKey": false,
            "numCitedBy": 551,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Quantifying-Inductive-Bias:-AI-Learning-Algorithms-Haussler",
            "title": {
                "fragments": [],
                "text": "Quantifying Inductive Bias: AI Learning Algorithms and Valiant's Learning Framework"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 5119145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5609ee7a8c7432c0f502b2a6dcfe9c0039206ab",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We consider the problem of predicting {0, 1}-valued functions on Rn and smaller domains, based on their values on randomly drawn points. Our model is related to Valiant\u2032s PAC learning model, but does not require the hypotheses used for prediction to be represented in any specified form. In our main result we show how to construct prediction strategies that are optimal to within a constant factor for any reasonable class F of target functions. This result is based on new combinatorial results about classes of functions of finite VC dimension. We also discuss more computationally efficient algorithms for predicting indicator functions of axis-parallel rectangles, more general intersection closed concept classes, and halfspaces in Rn. These are also optimal to within a constant factor. Finally, we compare the general performance of prediction strategies derived by our method to that of those derived from methods in PAC learning theory."
            },
            "slug": "Predicting-{0,1}-functions-on-randomly-drawn-points-Haussler-Littlestone",
            "title": {
                "fragments": [],
                "text": "Predicting {0,1}-functions on randomly drawn points"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This model is related to Valiant\u2032s PAC learning model, but does not require the hypotheses used for prediction to be represented in any specified form and shows how to construct prediction strategies that are optimal to within a constant factor for any reasonable class F of target functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153023666"
                        ],
                        "name": "B. K. Natarajan",
                        "slug": "B.-K.-Natarajan",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Natarajan",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. K. Natarajan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17570811,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "08472125e7df513d71c1269f562f07fa24d02993",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This paper concerns algorithms that learn functions from examples. Functions on strings of a finite alphabet are considered and the notion of dimensionality defined for families of such functions. Using this notion, a theorem is proved identifying the most general conditions under which a family of functions can be efficiently learned from examples. Turning to some familiar families, we present strong evidence against the existence of efficient algorithms for learning the regular functions and the polynomial time computable functions, even if the size of the encoding of the function to be learned is given. Our arguments hinge in a new complexity measure--the constraint complexity."
            },
            "slug": "Learning-Functions-from-Examples-Natarajan",
            "title": {
                "fragments": [],
                "text": "Learning Functions from Examples"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A theorem is proved identifying the most general conditions under which a family of functions can be efficiently learned from examples, and strong evidence against the existence of efficient algorithms for learning the regular functions and the polynomial time computable functions is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2270210"
                        ],
                        "name": "R. S. Wenocur",
                        "slug": "R.-S.-Wenocur",
                        "structuredName": {
                            "firstName": "Roberta",
                            "lastName": "Wenocur",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. S. Wenocur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 204985985,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5e6dfb46ed298ff037e166291c128a465f90bfc0",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Some-special-vapnik-chervonenkis-classes-Wenocur-Dudley",
            "title": {
                "fragments": [],
                "text": "Some special vapnik-chervonenkis classes"
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Math."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6334230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1dace286582d91916fe470d08f30381cf453f20",
            "isKey": false,
            "numCitedBy": 1612,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant (1984) and others have studied the problem of learning various classes of Boolean functions from examples. Here we discuss incremental learning of these functions. We consider a setting in which the learner responds to each example according to a current hypothesis. Then the learner updates the hypothesis, if necessary, based on the correct classification of the example. One natural measure of the quality of learning in this setting is the number of mistakes the learner makes. For suitable classes of functions, learning algorithms are available that make a bounded number of mistakes, with the bound independent of the number of examples seen by the learner. We present one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions. The basic method can be expressed as a linear-threshold algorithm. A primary advantage of this algorithm is that the number of mistakes grows only logarithmically with the number of irrelevant attributes in the examples. At the same time, the algorithm is computationally efficient in both time and space."
            },
            "slug": "Learning-Quickly-When-Irrelevant-Attributes-Abound:-Littlestone",
            "title": {
                "fragments": [],
                "text": "Learning Quickly When Irrelevant Attributes Abound: A New Linear-Threshold Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions."
            },
            "venue": {
                "fragments": [],
                "text": "28th Annual Symposium on Foundations of Computer Science (sfcs 1987)"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39419622"
                        ],
                        "name": "B. Natarajan",
                        "slug": "B.-Natarajan",
                        "structuredName": {
                            "firstName": "Balas",
                            "lastName": "Natarajan",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Natarajan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Using the techniques of [30], [ 47 ], [48], and [52], we can cast these requirements in the form of a characterization of proper polynomial learnability."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13998435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cad8e85d332dd635dcdb78e2a1aef9c3c3e58f5",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper deals with the learnability of Boolean functions. An intuitively appealing notion of dimensionality is developed and used to identify the most general class of Boolean function families that are learnable from polynomially many positive examples with one-sided error. It is then argued that although bounded DNF expressions lie outside this class, they must have efficient learning algorithms as they are well suited for expressing many human concepts. A framework that permits efficient learning of bounded DNF functions is identified."
            },
            "slug": "On-learning-Boolean-functions-Natarajan",
            "title": {
                "fragments": [],
                "text": "On learning Boolean functions"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An intuitively appealing notion of dimensionality is developed and used to identify the most general class of Boolean function families that are learnable from polynomially many positive examples with one-sided error."
            },
            "venue": {
                "fragments": [],
                "text": "STOC"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47494927"
                        ],
                        "name": "L. Pitt",
                        "slug": "L.-Pitt",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Pitt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pitt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For the \u201conly if\u201d part, note first that by Theorem 2.l(ii)(b), any learning algorithm for C must use a sample size that grows linearly in the VC dimension of C,,, and hence if the VC dimension of C, is not polynomial in ~1, then C is not poly-learnable by any hypothesis space H. To show that C being poly-learnable implies that there is an r-poly hy-fi for C, we use a construction from [ 52 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The above example shows that it is not only useful to parameterize learning algorithms and learnability results by the dimension of the domain, but also by some natural measure of the syntactic complexity of the target concept, in this case the number of intervals used to define it. Both of these considerations are emphasized in [36] and [ 52 ] in the investigation into the learnability of Boolean functions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The functional and oracle models of polynomial learnability are shown to be equivalent in [30], along with another variant of the oracle model in which there are two probability distributions on the domain X, and two oracles, one for positive examples of the target concept and one for negative examples (e.g., [36] and [ 52 ])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "It is also possible to allow the computation time to depend explicitly on the accuracy and confidence parameters t and 6. Since this, and other extensions of the above model, are allowed in the definition of polynomial learnability in [ 52 ] and [59], we now introduce a second model of polynomial learnability, which we call the oracle model (see also [3] and [36])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These notions of polynomial learnability, both closely related to the model introduced in [59] and elaborated in [36] and [ 52 ], are discussed in Sections 3.1 and 3.2, respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Using the techniques of [30], [47], [48], and [ 52 ], we can cast these requirements in the form of a characterization of proper polynomial learnability."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18940285,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93849122caf1b10c9611eddb707e0720441c73f6",
            "isKey": true,
            "numCitedBy": 541,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The computational complexity of learning Boolean concepts from examples is investigated. It is shown for various classes of concept representations that these cannot be learned feasibly in a distribution-free sense unless R = NP. These classes include (a) disjunctions of two monomials, (b) Boolean threshold functions, and (c) Boolean formulas in which each variable occurs at most once. Relationships between learning of heuristics and finding approximate solutions to NP-hard optimization problems are given."
            },
            "slug": "Computational-limitations-on-learning-from-examples-Pitt-Valiant",
            "title": {
                "fragments": [],
                "text": "Computational limitations on learning from examples"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "It is shown for various classes of concept representations that these cannot be learned feasibly in a distribution-free sense unless R = NP, and relationships between learning of heuristics and finding approximate solutions to NP-hard optimization problems are given."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "They also bring up the issues of misclassification in the examples and the possibility of stochastically defined target concepts, discussed in Section A3 of the Appendix, and the possibility of combining random examples with other types of information, for example, the various oracles and queries discussed in [2], [3], and [59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11873053,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "225331d1700a9544545cc7c54a63c1b485269ce7",
            "isKey": false,
            "numCitedBy": 2036,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-Regular-Sets-from-Queries-and-Angluin",
            "title": {
                "fragments": [],
                "text": "Learning Regular Sets from Queries and Counterexamples"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409749316"
                        ],
                        "name": "S. Ben-David",
                        "slug": "S.-Ben-David",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Ben-David",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ben-David"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821511"
                        ],
                        "name": "Gyora M. Benedek",
                        "slug": "Gyora-M.-Benedek",
                        "structuredName": {
                            "firstName": "Gyora",
                            "lastName": "Benedek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyora M. Benedek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144830983"
                        ],
                        "name": "Y. Mansour",
                        "slug": "Y.-Mansour",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Mansour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Mansour"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18345203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10b86c311232af7d6d526cf13f400b436f497688",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a systematic framework for classifying, comparing and defining models of computational learnability. Apart from the obvious \u2018uniformity\u2019 parameters we present a novel \u2018solid learnability\u2019 notion that captures the difference between \u2018Guess and Test\u2019 learning algorithms and learnability notions for which consistency with the samples guarantees success."
            },
            "slug": "A-parametrization-scheme-for-classifying-models-of-Ben-David-Benedek",
            "title": {
                "fragments": [],
                "text": "A parametrization scheme for classifying models of learnability"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel \u2018solid learnability\u2019 notion is presented that captures the difference between \u2018Guess and Test\u2019 learning algorithms and learnability notions for which consistency with the samples guarantees success."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '89"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706816"
                        ],
                        "name": "N. Megiddo",
                        "slug": "N.-Megiddo",
                        "structuredName": {
                            "firstName": "Nimrod",
                            "lastName": "Megiddo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Megiddo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 703519,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7dc32567604f52144dc59561c1ee3020425c4ed0",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "It is NP-complete to recognize whether two sets of points in general space can be separated by two hyperplanes. It is NP-complete to recognize whether two sets of points in the plane can be separated withk lines. For every fixedk in any fixed dimension, it takes polynomial time to recognize whether two sets of points can be separated withk hyperplanes."
            },
            "slug": "On-the-complexity-of-polyhedral-separability-Megiddo",
            "title": {
                "fragments": [],
                "text": "On the complexity of polyhedral separability"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper states that for every fixedk in any fixed dimension, it takes polynomial time to recognize whether two sets of points can be separated withk hyperplanes."
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Comput. Geom."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18251470,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "445ad69010658097fc317f7b83f1198179eebae8",
            "isKey": false,
            "numCitedBy": 1840,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops the separating capacities of families of nonlinear decision surfaces by a direct application of a theorem in classical combinatorial geometry. It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes. Applying these ideas to the vertices of a binary n-cube yields bounds on the number of spherically, quadratically, and, in general, nonlinearly separable Boolean functions of n variables. It is shown that the set of all surfaces which separate a dichotomy of an infinite, random, separable set of pattern vectors can be characterized, on the average, by a subset of only 2d extreme pattern vectors. In addition, the problem of generalizing the classifications on a labeled set of pattern points to the classification of a new point is defined, and it is found that the probability of ambiguous generalization is large unless the number of training patterns exceeds the capacity of the set of separating surfaces."
            },
            "slug": "Geometrical-and-Statistical-Properties-of-Systems-Cover",
            "title": {
                "fragments": [],
                "text": "Geometrical and Statistical Properties of Systems of Linear Inequalities with Applications in Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Electron. Comput."
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16252030,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "65479e8e0c748244a46c7a94c839b092d272a8cf",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper extends the notions of capacity and distribution-free error estimation to nonlinear Boolean classifiers on patterns with binary-valued features. We establish quantitative relationships between the dimensionality of the feature vectors (d), the combinational complexity of the decision rule (c), the number of samples in the training set (n), and the classification performance of the resulting classifier. Our results state that the discriminating capacity of Boolean classifiers is given by the product dc, and the probability of ambiguous generalization is asymptotically given by (n/dc-1)-1 0(log d)/d) for large d, and n=0(dc). In addition we show that if a fraction \u00bf of the training samples is misclassified then the probability of error (\u00bf) in subsequent samples satisfies P(|\u00bf-\u00bf| \u00bf) m=<2.773 exp (dc-e2n/8) for all distributions, regardless of how the classifier was discovered."
            },
            "slug": "Capacity-and-Error-Estimates-for-Boolean-with-Pearl",
            "title": {
                "fragments": [],
                "text": "Capacity and Error Estimates for Boolean Classifiers with Limited Complexity"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This paper extends the notions of capacity and distribution-free error estimation to nonlinear Boolean classifiers on patterns with binary-valued features and establishes quantitative relationships between the dimensionality of the feature vectors, the combinational complexity of the decision rule, the number of samples in the training set, and the classification performance of the resulting classifier."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150652510"
                        ],
                        "name": "Ming Li",
                        "slug": "Ming-Li",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1507349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25875a29eded2acdad72cf897df11c2df2d92ec1",
            "isKey": false,
            "numCitedBy": 395,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper an extension of the distribution-free model of learning introduced by Valiant [Comm. ACM, 27(1984), pp. 1134\u20131142] that allows the presence of malicious errors in the examples given to a learning algorithm is studied. Such errors are generated by an adversary with unbounded computational power and access to the entire history of the learning algorithm\u2019s computation. Thus, a worst-case model of errors is studied.The results of this research include general methods for bounding the rate of error tolerable by any learning algorithm, efficient algorithms tolerating nontrivial rates of malicious errors, and equivalences between problems of learning with errors and standard combinatorial optimization problems."
            },
            "slug": "Learning-in-the-presence-of-malicious-errors-Kearns-Li",
            "title": {
                "fragments": [],
                "text": "Learning in the presence of malicious errors"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "General methods for bounding the rate of error tolerable by any learning algorithm, efficient algorithms tolerating nontrivial rates of malicious errors, and equivalences between problems of learning with errors and standard combinatorial optimization problems are studied."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6686370,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e85a68602abf92fcc1efb8b7aa90d27d141a80c2",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 149,
            "paperAbstract": {
                "fragments": [],
                "text": "A test sequence is used to select the best rule from a class of discrimination rules defined in terms of the training sequence. The Vapnik-Chervonenkis and related inequalities are used to obtain distribution-free bounds on the difference between the probability of error of the selected rule and the probability of error of the best rule in the given class. The bounds are used to prove the consistency and asymptotic optimality for several popular classes, including linear discriminators, nearest-neighbor rules, kernel-based rules, histogram rules, binary tree classifiers, and Fourier series classifiers. In particular, the method can be used to choose the smoothing parameter in kernel-based rules, to choose k in the k-nearest neighbor rule, and to choose between parametric and nonparametric rules. >"
            },
            "slug": "Automatic-Pattern-Recognition:-A-Study-of-the-of-Devroye",
            "title": {
                "fragments": [],
                "text": "Automatic Pattern Recognition: A Study of the Probability of Error"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The Vapnik-Chervonenkis method can be used to choose the smoothing parameter in kernel-based rules, to choose k in the k-nearest neighbor rule, and to choose between parametric and nonparametric rules."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378746"
                        ],
                        "name": "N. Karmarkar",
                        "slug": "N.-Karmarkar",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Karmarkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Karmarkar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7257867,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "dbf8aa1e547c863f509a5a4c03a39fa9c92c9651",
            "isKey": false,
            "numCitedBy": 4005,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new polynomial-time algorithm for linear programming. In the worst case, the algorithm requiresO(n3.5L) arithmetic operations onO(L) bit numbers, wheren is the number of variables andL is the number of bits in the input. The running-time of this algorithm is better than the ellipsoid algorithm by a factor ofO(n2.5). We prove that given a polytopeP and a strictly interior point a \u03b5P, there is a projective transformation of the space that mapsP, a toP\u2032, a\u2032 having the following property. The ratio of the radius of the smallest sphere with center a\u2032, containingP\u2032 to the radius of the largest sphere with center a\u2032 contained inP\u2032 isO(n). The algorithm consists of repeated application of such projective transformations each followed by optimization over an inscribed sphere to create a sequence of points which converges to the optimal solution in polynomial time."
            },
            "slug": "A-new-polynomial-time-algorithm-for-linear-Karmarkar",
            "title": {
                "fragments": [],
                "text": "A new polynomial-time algorithm for linear programming"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is proved that given a polytopeP and a strictly interior point a \u03b5P, there is a projective transformation of the space that mapsP, a toP\u2032, a\u2032 having the following property: the ratio of the radius of the smallest sphere with center a\u2032, containingP\u2032 to theradius of the largest sphere withCenter a\u2032 contained inP\u2032 isO(n)."
            },
            "venue": {
                "fragments": [],
                "text": "Comb."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145634459"
                        ],
                        "name": "M. Garey",
                        "slug": "M.-Garey",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Garey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150444582"
                        ],
                        "name": "David S. Johnson",
                        "slug": "David-S.-Johnson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Johnson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2211006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdede1e17c947540b50e6e2db9e8467ddc6e7336",
            "isKey": false,
            "numCitedBy": 47653,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Horn formulae play a prominent role in artificial intelligence and logic programming. In this paper we investigate the problem of optimal compression of propositional Horn production rule knowledge bases. The standard approach to this problem, consisting in the removal of redundant rules from a knowledge base, leads to an \"irredundant\" but not necessarily optimal knowledge base. We prove here that the number of rules in any irredundant Horn knowledge base involving n propositional variables is at most n 0 1 times the minimum possible number of rules. In order to formalize the optimal compression problem, we define a Boolean function of a knowledge base as being the function whose set of true points is the set of models of the knowledge base. In this way the optimal compression of production rule knowledge bases becomes a problem of Boolean function minimization. In this paper we prove that the minimization of Horn functions (i.e. Boolean functions associated to Horn knowledge bases) is..."
            },
            "slug": "Computers-and-Intractability:-A-Guide-to-the-Theory-Garey-Johnson",
            "title": {
                "fragments": [],
                "text": "Computers and Intractability: A Guide to the Theory of NP-Completeness"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This is the second edition of a quarterly column the purpose of which is to provide a continuing update to the list of problems (NP-complete and harder) presented by M. R. Garey and myself in the authors' book \u2018\u2018Computers and Intractability: A Guide to the Theory of NP-Completeness\u2019\u2019."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150444582"
                        ],
                        "name": "David S. Johnson",
                        "slug": "David-S.-Johnson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Johnson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 42632644,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "4315baed930e06dac39875eba9e289e95d964309",
            "isKey": false,
            "numCitedBy": 2377,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Simple, polynomial-time, heuristic algorithms for finding approximate solutions to various polynomial complete optimization problems are analyzed with respect to their worst case behavior, measured by the ratio of the worst solution value that can be chosen by the algorithm to the optimal value. For certain problems, such as a simple form of the knapsack problem and an optimization problem based on satisfiability testing, there are algorithms for which this ratio is bounded by a constant, independent of the problem size. For a number of set covering problems, simple algorithms yield worst case ratios which can grow with the log of the problem size. And for the problem of finding the maximum clique in a graph, no algorithm has been found for which the ratio does not grow at least as fast as 0(n\u03b5), where n is the problem size and \u03b5> 0 depends on the algorithm."
            },
            "slug": "Approximation-algorithms-for-combinatorial-problems-Johnson",
            "title": {
                "fragments": [],
                "text": "Approximation Algorithms for Combinatorial Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "For the problem of finding the maximum clique in a graph, no algorithm has been found for which the ratio does not grow at least as fast as 0(n\u03b5), where n is the problem size and \u03b5> 0 depends on the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 1279641,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2bab38d12c4ee82319cc89d16bca21b301a7138",
            "isKey": false,
            "numCitedBy": 666,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The main purpose of this paper is to give techniques for analysing the probabilistic performance of certain kinds of algorithms, and hence to suggest some fast algorithms with provably desirable probabilistic behaviour. The particular problems we consider are: finding Hamiltonian circuits in directed graphs (DHC), finding Hamiltonian circuits in undirected graphs (UHC), and finding perfect matchings in undirected graphs (PM). We show that for each problem there is an algorithm that is extremely fast (0(n(log n)2) for DHC and UHC, and 0(nlog n) for PM), and which with probability tending to one finds a solution in randomly chosen graphs of sufficient density. These results contrast with the known NP-completeness of the first two problems [2,12] and the best worst-case upper bound known of 0(n2.5) for the last [9]."
            },
            "slug": "Fast-probabilistic-algorithms-for-hamiltonian-and-Angluin-Valiant",
            "title": {
                "fragments": [],
                "text": "Fast Probabilistic Algorithms for Hamiltonian Circuits and Matchings"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that for each problem there is an algorithm that is extremely fast, and which with probability tending to one finds a solution in randomly chosen graphs of sufficient density, and the results contrast with the known NP-completeness of the first two problems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721914"
                        ],
                        "name": "H. Edelsbrunner",
                        "slug": "H.-Edelsbrunner",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Edelsbrunner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Edelsbrunner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695738"
                        ],
                        "name": "F. Preparata",
                        "slug": "F.-Preparata",
                        "structuredName": {
                            "firstName": "Franco",
                            "lastName": "Preparata",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Preparata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 1185658,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "4a6aaf71906b31a2ad1db8facdc87495691fcbd3",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Minimum-Polygonal-Separation-Edelsbrunner-Preparata",
            "title": {
                "fragments": [],
                "text": "Minimum Polygonal Separation"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60729830,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "398e1d8b7ac885268e75a2dc7bc6297a5540c29a",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Applying-valiant's-learning-framework-to-Al-Haussler",
            "title": {
                "fragments": [],
                "text": "Applying valiant's learning framework to Al concept-learning problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410164694"
                        ],
                        "name": "D. T. Lee",
                        "slug": "D.-T.-Lee",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Lee",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. T. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695738"
                        ],
                        "name": "F. Preparata",
                        "slug": "F.-Preparata",
                        "structuredName": {
                            "firstName": "Franco",
                            "lastName": "Preparata",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Preparata"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 3240445,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a595e1947ee5f4e6c7d37ae05abbb895e47aed9e",
            "isKey": false,
            "numCitedBy": 254,
            "numCiting": 368,
            "paperAbstract": {
                "fragments": [],
                "text": "We survey the state of the art of computational geometry, a discipline that deals with the complexity of geometric problems within the framework of the analysis of algorithms. This newly emerged area of activities has found numerous applications in various other disciplines, such as computer-aided design, computer graphics, operations research, pattern recognition, robotics, and statistics. Five major problem areas\u2014convex hulls, intersections, searching, proximity, and combinatorial optimizations\u2014are discussed. Seven algorithmic techniques\u2014incremental construction, plane-sweep, locus, divide-and-conquer, geometric transformation, prune-and-search, and dynamization\u2014are each illustrated with an example. A collection of problem transformations to establish lower bounds for geo-metric problems in the algebraic computation/decision model is also included."
            },
            "slug": "Computational-Geometry&#8212;A-Survey-Lee-Preparata",
            "title": {
                "fragments": [],
                "text": "Computational Geometry&#8212;A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The state of the art of computational geometry is surveyed, a discipline that deals with the complexity of geometric problems within the framework of the analysis of algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69046239"
                        ],
                        "name": "\u5ba4 \u7ae0\u6cbb\u90ce",
                        "slug": "\u5ba4-\u7ae0\u6cbb\u90ce",
                        "structuredName": {
                            "firstName": "\u5ba4",
                            "lastName": "\u7ae0\u6cbb\u90ce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u5ba4 \u7ae0\u6cbb\u90ce"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 160726595,
            "fieldsOfStudy": [
                "History"
            ],
            "id": "023476b43f3d3acdc80e589fd50aa8e12c4ae0f4",
            "isKey": false,
            "numCitedBy": 424,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Michael-R.Garey/David-S.Johnson-\u8457,-\"COMPUTERS-AND-A-\u7ae0\u6cbb\u90ce",
            "title": {
                "fragments": [],
                "text": "Michael R.Garey/David S.Johnson \u8457, \"COMPUTERS AND INTRACTABILITY A guide to the Theory of NP-Completeness\", FREEMAN, A5\u5224\u5909\u5f62\u5224, 338+xii, \\5,217, 1979"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715952"
                        ],
                        "name": "A. Aho",
                        "slug": "A.-Aho",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Aho",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706504"
                        ],
                        "name": "J. Hopcroft",
                        "slug": "J.-Hopcroft",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopcroft",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopcroft"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29599075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10a463bb00b44bdd3a8620f2bedb9e1564bfcf32",
            "isKey": false,
            "numCitedBy": 9234,
            "numCiting": 138,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nWith this text, you gain an understanding of the fundamental concepts of algorithms, the very heart of computer science. It introduces the basic data structures and programming techniques often used in efficient algorithms. Covers use of lists, push-down stacks, queues, trees, and graphs. Later chapters go into sorting, searching and graphing algorithms, the string-matching algorithms, and the Schonhage-Strassen integer-multiplication algorithm. Provides numerous graded exercises at the end of each chapter. \n \n \n0201000296B04062001"
            },
            "slug": "The-Design-and-Analysis-of-Computer-Algorithms-Aho-Hopcroft",
            "title": {
                "fragments": [],
                "text": "The Design and Analysis of Computer Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This text introduces the basic data structures and programming techniques often used in efficient algorithms, and covers use of lists, push-down stacks, queues, trees, and graphs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "introduced in [29]* to arbitrary probability distributions on E\u201d. For a fixed distribution, an E-transversal for R is a finite set of points N G E\u201d such that every region in R of probability at least E contains at least one point in N. Se:ction A2 uses the notion of an c-transversal to provide the primary machinery for Theorem 2.1, following [29] and [ 62 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A2. Proof of Theorem 2.1 (ii)(a) For the next two lemmas let R G 2x be a fixed nonempty class of sets and P be a distribution on X such that QT and Jz\u201d are measurable for all m 2 1 and t > 0. The proofs of these lemmas are analogous to those of Lemma and Theorem 2 of [ 62 ]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "To show that these classes are also uniformly learnable, we use a concept first introduced in [ 62 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We note only that it employs techniques similar to those used in [ 62 ], which form the basis of Lemmas A2.1 and A2.2 given above."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Since the above bound is O( l/c(log( l/6) + n log( l/E))), for small t it is significantly better than the O( l/~\u2018(log( l/F) + nlog(n/t))) bound given in [51] (eq. 29) derived directly from [ 151 and [ 62 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8142232,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a36b028d024bf358c4af1a5e1dc3ca0aed23b553",
            "isKey": true,
            "numCitedBy": 3709,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter reproduces the English translation by B. Seckler of the paper by Vapnik and Chervonenkis in which they gave proofs for the innovative results they had obtained in a draft form in July 1966 and announced in 1968 in their note in Soviet Mathematics Doklady. The paper was first published in Russian as \u0412\u0430\u043f\u043d\u0438\u043a \u0412. \u041d. and \u0427\u0435\u0440\u0432\u043e\u043d\u0435\u043d\u043a\u0438\u0441 \u0410. \u042f. \u041e \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0419 \u0441\u0445\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u0447\u0430\u0441\u0442\u043e\u0442 \u043f\u043e\u044f\u0432\u043b\u0435\u043d\u0438\u044f \u0441\u043e\u0431\u044b\u0442\u0438\u0419 \u043a \u0438\u0445 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044f\u043c. \u0422\u0435\u043e\u0440\u0438\u044f \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0435\u0419 \u0438 \u0435\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044f 16(2), 264\u2013279 (1971)."
            },
            "slug": "Chervonenkis:-On-the-uniform-convergence-of-of-to-Vapnik",
            "title": {
                "fragments": [],
                "text": "Chervonenkis: On the uniform convergence of relative frequencies of events to their probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter reproduces the English translation by B. Seckler of the paper by Vapnik and Chervonenkis in which they gave proofs for the innovative results they had obtained in a draft form in July 1966 and announced in 1968 in their note in Soviet Mathematics Doklady."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403454"
                        ],
                        "name": "E. Baum",
                        "slug": "E.-Baum",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Baum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 135
                            }
                        ],
                        "text": "The application of the results given here to learning methods that use connectionist or neural network representations is discussed in [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15659829,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "25406e6733a698bfc4ac836f8e74f458e75dad4f",
            "isKey": false,
            "numCitedBy": 1696,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the question of when a network can be expected to generalize from m random training examples chosen from some arbitrary probability distribution, assuming that future test examples are drawn from the same distribution. Among our results are the following bounds on appropriate sample vs. network size. Assume 0 < \u220a 1/8. We show that if m O(W/\u220a log N/\u220a) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 \u220a/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 1 \u220a of future test examples drawn from the same distribution. Conversely, for fully-connected feedforward nets with one hidden layer, any learning algorithm using fewer than (W/\u220a) random training examples will, for some distributions of examples consistent with an appropriate weight choice, fail at least some fixed fraction of the time to find a weight choice that will correctly classify more than a 1 \u220a fraction of the future test examples."
            },
            "slug": "What-Size-Net-Gives-Valid-Generalization-Baum-Haussler",
            "title": {
                "fragments": [],
                "text": "What Size Net Gives Valid Generalization?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that if m O(W/ \u220a log N/\u220a) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 \u220a/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 2 \u220a of future test examples drawn from the same distribution."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61447029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80c82e8e212ad03d5456088127b50e480631334c",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The connection between the simplicity of scientific theories and the credence attributed to their predictions seems to permeate the practice of scientific discovery. When a scientist succeeds in explaining a set of nobservations using a model Mof complexity c then it is generally believed that the likelihood of finding another explanatory model with similar complexity but leading to opposite predictions decreases with increasing nand decreasing c. This paper derives formal relationships between n, c and the probability of ambiguous predictions by examining three modeling languages under binary classification tasks: perceptrons, Boolean formulae, and Boolean networks. Bounds are also derived for the probability of error associated with the policy of accepting only models of complexity not exceeding c. Human tendency to regard the simpler as the more trustworthy is given a qualified justification."
            },
            "slug": "ON-THE-CONNECTION-BETWEEN-THE-COMPLEXITY-AND-OF-Pearl",
            "title": {
                "fragments": [],
                "text": "ON THE CONNECTION BETWEEN THE COMPLEXITY AND CREDIBILITY OF INFERRED MODELS"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper derives formal relationships between n, c and the probability of ambiguous predictions by examining three modeling languages under binary classification tasks: perceptrons, Boolean formulae, and Boolean networks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706816"
                        ],
                        "name": "N. Megiddo",
                        "slug": "N.-Megiddo",
                        "structuredName": {
                            "firstName": "Nimrod",
                            "lastName": "Megiddo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Megiddo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12686747,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "c7da923e40627eb2e8e93248ffe525a0809112e0",
            "isKey": false,
            "numCitedBy": 692,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "It is demonstrated that the linear programming problem in d variables and n constraints can be solved in O(n) time when d is fixed. This bound follows from a multidimensional search technique which is applicable for quadratic programming as well. There is also developed an algorithm that is polynomial in both n and d provided d is bounded by a certain slowly growing function of n."
            },
            "slug": "Linear-Programming-in-Linear-Time-When-the-Is-Fixed-Megiddo",
            "title": {
                "fragments": [],
                "text": "Linear Programming in Linear Time When the Dimension Is Fixed"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "It is demonstrated that the linear programming problem in d variables and n constraints can be solved in O(n) time when d is fixed, following from a multidimensional search technique which is applicable for quadratic programming."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143689789"
                        ],
                        "name": "D. Pollard",
                        "slug": "D.-Pollard",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pollard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pollard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "can easily be shown to be universally separable (see exercises 4, 5 and 7 in chapter II of [ 54 ])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This problem is addressed in [ 171, [ 181, [23], [ 54 ], and [61] from a purely statistical point of view."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "countably S-coverable in [7a]; see the appendix of [ 54 ] for a discussion of other approaches)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122104450,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "01a1d065a5292be740e75029622a3ab5e71e3150",
            "isKey": true,
            "numCitedBy": 1852,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "I Functional on Stochastic Processes.- 1. Stochastic Processes as Random Functions.- Notes.- Problems.- II Uniform Convergence of Empirical Measures.- 1. Uniformity and Consistency.- 2. Direct Approximation.- 3. The Combinatorial Method.- 4. Classes of Sets with Polynomial Discrimination.- 5. Classes of Functions.- 6. Rates of Convergence.- Notes.- Problems.- III Convergence in Distribution in Euclidean Spaces.- 1. The Definition.- 2. The Continuous Mapping Theorem.- 3. Expectations of Smooth Functions.- 4. The Central Limit Theorem.- 5. Characteristic Functions.- 6. Quantile Transformations and Almost Sure Representations.- Notes.- Problems.- IV Convergence in Distribution in Metric Spaces.- 1. Measurability.- 2. The Continuous Mapping Theorem.- 3. Representation by Almost Surely Convergent Sequences.- 4. Coupling.- 5. Weakly Convergent Subsequences.- Notes.- Problems.- V The Uniform Metric on Spaces of Cadlag Functions.- 1. Approximation of Stochastic Processes.- 2. Empirical Processes.- 3. Existence of Brownian Bridge and Brownian Motion.- 4. Processes with Independent Increments.- 5. Infinite Time Scales.- 6. Functional of Brownian Motion and Brownian Bridge.- Notes.- Problems.- VI The Skorohod Metric on D(0, ?).- 1. Properties of the Metric.- 2. Convergence in Distribution.- Notes.- Problems.- VII Central Limit Theorems.- 1. Stochastic Equicontinuity.- 2. Chaining.- 3. Gaussian Processes.- 4. Random Covering Numbers.- 5. Empirical Central Limit Theorems.- 6. Restricted Chaining.- Notes.- Problems.- VIII Martingales.- 1. A Central Limit Theorem for Martingale-Difference Arrays.- 2. Continuous Time Martingales.- 3. Estimation from Censored Data.- Notes.- Problems.- Appendix A Stochastic-Order Symbols.- Appendix B Exponential Inequalities.- Notes.- Problems.- Appendix C Measurability.- Notes.- Problems.- References.- Author Index."
            },
            "slug": "Convergence-of-stochastic-processes-Pollard",
            "title": {
                "fragments": [],
                "text": "Convergence of stochastic processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 122230395,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c59250736174b8d80c40de6e1d5e1641366ef416",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "When \\(\\mathfrak{F}\\) is a universal Donsker class, then for independent, indetically distributed (i.i.d) observation \\(\\mathbf{X}_1,\\ldots,\\mathbf{X}_n\\) with an unknown law P, for any \\(\\mathfrak{f}_i\\)in \\(\\mathfrak{F},\\) \\(i=1,\\ldots,m,\\quad n^{-1/2}\\left\\{ \\mathfrak{f}_1\\left(\\mathbf{X}_1\\right)+\\ldots+\\mathfrak{f}_i\\left(\\mathbf{X}_n\\right)\\right\\}_{1\\leq i\\leq m}\\) is asymptotically normal with mean Vector \\(n^{1/2}\\left\\{\\int\\mathfrak{f}_i\\left(\\mathbf{X}_n\\right)d\\mathbf{P}\\left(x\\right)\\right\\}_{1_\\leq i\\leq m}\\) and covariance matrix \\(\\int\\mathfrak{f}_i\\mathfrak{f}_j d\\mathbf{P}-\\int\\mathfrak{f}_id\\mathbf{P}\\int\\mathfrak{f}_jd\\mathbf{P},\\) uniformly for \\({\\mathfrak{f}_i}\\in \\mathfrak{F}.\\) Then, for certain Statistics formed frome the \\(\\mathfrak{f}_i\\left(\\mathbf{X}_k\\right),\\) even where \\(\\mathfrak{f}_i\\) may be chosen depending on the \\(\\mathbf{X}_k\\) there will be asymptotic distribution as \\(n \\rightarrow \\infty.\\) For example, for \\(\\mathbf{X}^2\\) statistics, where \\(f_i\\) are indicators of disjoint intervals, depending suitably on \\(\\mathbf{X}_1,\\ldots,\\mathbf{X}_n\\), whose union is the real line, \\(\\mathbf{X}^2\\) quadratic forms have limiting distributions [Roy (1956) and Watson (1958)] which may, however, not be \\(\\mathbf{X}^2\\) distributions and may depend on P [Chernoff and Lehmann (1954)]. Universal Donsker classes of sets are, up to mild measurability conditions, just classes satisfying the Vapnik\u2013Cervonenkis comdinatorial conditions defined later in this section Donsker the Vapnik-Cervonenkis combinatorial conditions defined later in this section [Durst and Dudley (1981) and Dudley (1984) Chapter 11]. The use of such classes allows a variety of extensions of the Roy\u2013Watson results to general (multidimensional) sample spaces [Pollard (1979) and Moore and Subblebine (1981)]. Vapnik and Cervonenkis (1974) indicated application of their families of sets to classification (pattern recognition) problems. More recently, the classes have been applied to tree-structured classifiacation [Breiman, Friedman, Olshen and Stone (1984), Chapter 12]."
            },
            "slug": "Universal-Donsker-Classes-and-Metric-Entropy-Dudley",
            "title": {
                "fragments": [],
                "text": "Universal Donsker Classes and Metric Entropy"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707322"
                        ],
                        "name": "Oded Goldreich",
                        "slug": "Oded-Goldreich",
                        "structuredName": {
                            "firstName": "Oded",
                            "lastName": "Goldreich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oded Goldreich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706681"
                        ],
                        "name": "S. Goldwasser",
                        "slug": "S.-Goldwasser",
                        "structuredName": {
                            "firstName": "Shafi",
                            "lastName": "Goldwasser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goldwasser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689467"
                        ],
                        "name": "S. Micali",
                        "slug": "S.-Micali",
                        "structuredName": {
                            "firstName": "Silvio",
                            "lastName": "Micali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Micali"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17064126,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "990842135e0c3adf1cea5dcaaffcaa38ec2c7b47",
            "isKey": false,
            "numCitedBy": 1943,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "A constructive theory of randomness for functions, based on computational complexity, is developed, and a pseudorandom function generator is presented. This generator is a deterministic polynomial-time algorithm that transforms pairs (<italic>g</italic>, <italic>r</italic>), where <italic>g</italic> is <italic>any</italic> one-way function and <italic>r</italic> is a random <italic>k</italic>-bit string, to polynomial-time computable functions \u0192<italic><subscrpt>r</subscrpt></italic>: {1, \u2026 , 2<italic><supscrpt>k</supscrpt></italic>} \u2192 {1, \u2026 , 2<italic><supscrpt>k</supscrpt></italic>}. These \u0192<italic><subscrpt>r</subscrpt></italic>'s cannot be distinguished from <italic>random</italic> functions by any probabilistic polynomial-time algorithm that asks and receives the value of a function at arguments of its choice. The result has applications in cryptography, random constructions, and complexity theory."
            },
            "slug": "How-to-construct-random-functions-Goldreich-Goldwasser",
            "title": {
                "fragments": [],
                "text": "How to construct random functions"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A constructive theory of randomness for functions, based on computational complexity, is developed, and a pseudorandom function generator is presented that has applications in cryptography, random constructions, and complexity theory."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717081"
                        ],
                        "name": "E. Welzl",
                        "slug": "E.-Welzl",
                        "structuredName": {
                            "firstName": "Emo",
                            "lastName": "Welzl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Welzl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8530681,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f52e66066c129bb87f6a4f12f1c17fd4a2b440b3",
            "isKey": false,
            "numCitedBy": 434,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new technique for half-space and simplex range query using <italic>&Ogr;</italic>(<italic>n</italic>) space and <italic>&Ogr;</italic>(<italic>n</italic><supscrpt><italic>a</italic></supscrpt>) query time, where <italic>a</italic> < <italic>d</italic>(d-1)/<italic>d</italic>(<italic>d</italic>-1) + 1 + \u03b3 for all dimensions <italic>d</italic> \u2265 2 and <italic>\u03b3</italic> > 0. These bounds are better than those previously published for all <italic>d</italic> \u2265 2. The technique uses random sampling to build a partition-tree structure. We introduce the concept of an <italic>\u03b5</italic>-net for an abstract set of ranges to describe the desired result of this random sampling and give necessary and sufficient conditions that a random sample is an <italic>\u03b5</italic>-net with high probability. We illustrate the application of these ideas to other range query problems."
            },
            "slug": "Epsilon-nets-and-simplex-range-queries-Haussler-Welzl",
            "title": {
                "fragments": [],
                "text": "Epsilon-nets and simplex range queries"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A new technique for half-space and simplex range query using random sampling to build a partition-tree structure and introduces the concept of an\u03b5-net for an abstract set of ranges to describe the desired result of this random sampling."
            },
            "venue": {
                "fragments": [],
                "text": "SCG '86"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69046239"
                        ],
                        "name": "\u5ba4 \u7ae0\u6cbb\u90ce",
                        "slug": "\u5ba4-\u7ae0\u6cbb\u90ce",
                        "structuredName": {
                            "firstName": "\u5ba4",
                            "lastName": "\u7ae0\u6cbb\u90ce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u5ba4 \u7ae0\u6cbb\u90ce"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 160726595,
            "fieldsOfStudy": [
                "History"
            ],
            "id": "023476b43f3d3acdc80e589fd50aa8e12c4ae0f4",
            "isKey": false,
            "numCitedBy": 424,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Michael-R.Garey/David-S.Johnson-\u8457,-\"COMPUTERS-AND-A-\u7ae0\u6cbb\u90ce",
            "title": {
                "fragments": [],
                "text": "Michael R.Garey/David S.Johnson \u8457, \"COMPUTERS AND INTRACTABILITY A guide to the Theory of NP-Completeness\", FREEMAN, A5\u5224\u5909\u5f62\u5224, 338+xii, \\5,217, 1979"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341779"
                        ],
                        "name": "J. R. Quinlan",
                        "slug": "J.-R.-Quinlan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Quinlan",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Quinlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113911099"
                        ],
                        "name": "R. Rivest",
                        "slug": "R.-Rivest",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rivest",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rivest"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "relationship between a kind of data compression and learning (see also [ 55 ] and [651)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 613410,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84dae6a2870c68005732b9db6890f375490f2d4e",
            "isKey": false,
            "numCitedBy": 804,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Inferring-Decision-Trees-Using-the-Minimum-Length-Quinlan-Rivest",
            "title": {
                "fragments": [],
                "text": "Inferring Decision Trees Using the Minimum Description Length Principle"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16926,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940156"
                        ],
                        "name": "T. Wagner",
                        "slug": "T.-Wagner",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Wagner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wagner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18051841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae46caa3db61087e27d970997b27f1ccb52622ea",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that distribution-free confidence intervals can be placed about the resubstitution estimate of the probability of error of any linear discrimination procedure."
            },
            "slug": "A-distribution-free-performance-bound-in-error-Devroye-Wagner",
            "title": {
                "fragments": [],
                "text": "A distribution-free performance bound in error estimation (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "It is shown that distribution-free confidence intervals can be placed about the resubstitution estimate of the probability of error of any linear discrimination procedure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717081"
                        ],
                        "name": "E. Welzl",
                        "slug": "E.-Welzl",
                        "structuredName": {
                            "firstName": "Emo",
                            "lastName": "Welzl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Welzl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Using Proposition A2.5, they generalize Lemmas 3.4 and 3.5 of [ 29 ] to arbitrary probability distributions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "introduced in [ 29 ]* to arbitrary probability distributions on E\u201d. For a fixed distribution, an E-transversal for R is a finite set of points N G E\u201d such that every region in R of probability at least E contains at least one point in N. Se:ction A2 uses the notion of an c-transversal to provide the primary machinery for Theorem 2.1, following [29] and [62]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We sketch the proof for completeness, using the notation from [ 29 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A. BLUMER ET AL. function II,(m) (see [ 29 ])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our characterization of learnability uses a simple combinatorial parameter called the Vapnik-Chervonenkis (VC) dimension of the class C of concepts [ 29 ].\u2019 We show that there is a learning function satisfying (3) if and only if the VC dimension of C is finite."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This result is based directly on the work of Vapnik and Chervonenkis [61-631; following [ 29 ], we have simplified some of their more general arguments to obtain sharper bounds on the sample complexity of functions satisfying (3) in the special case we consider."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "2 What we call an e-transversal is called an c-net in [ 29 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "introduced in [29]* to arbitrary probability distributions on E\u201d. For a fixed distribution, an E-transversal for R is a finite set of points N G E\u201d such that every region in R of probability at least E contains at least one point in N. Se:ction A2 uses the notion of an c-transversal to provide the primary machinery for Theorem 2.1, following [ 29 ] and [62]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This definition of an E-transversal generalizes the notion of an t-net from [ 29 ] to arbitrary probability distributions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Vapnik and Chervonenkis [63], Dudley [ 171, Wenocur and Dudley [66], Assouad [6], and Haussler and Welzl [ 29 ] give numerous additional examples of concept classes of finite VC dimension."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27638326,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dbdfc10b6af746580bd48f2f3757e9060326e5ab",
            "isKey": false,
            "numCitedBy": 674,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractWe demonstrate the existence of data structures for half-space and simplex range queries on finite point sets ind-dimensional space,d\u22652, with linear storage andO(n\u03b1) query time,\n% MathType!MTEF!2!1!+-% feaafiart1ev1aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr% 4rNCHbGeaGqiVC0xe9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Gqpi0x% c9q8qqaqFj0df9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x% fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaGaeqySdeMaey% ypa0ZaaSaaaeaacaWGKbGaaiikaiaadsgacqGHsislcaaIXaGaaiyk% aaqaaiaadsgacaGGOaGaamizaiabgkHiTiaaigdacaGGPaGaey4kaS% IaaGymaaaacqGHRaWkcqaHZoWzieaacaWFGaGaa8hiaiaa-bcacaWF% GaGaa8hiaiaa-bcacaWFGaGaa8Nzaiaa-9gacaWFYbGaa8hiaiaa-f% gacaWFSbGaa8hBaiaa-bcacaWFGaGaa8hiaiabeo7aNjaa-5dacaWF% Waaaaa!574F!\n\n$$\\alpha = \\frac{{d(d - 1)}}{{d(d - 1) + 1}} + \\gamma for all \\gamma > 0$$\n.These bounds are better than those previously published for alld\u22652. Based on ideas due to Vapnik and Chervonenkis, we introduce the concept of an \u025b-net of a set of points for an abstract set of ranges and give sufficient conditions that a random sample is an \u025b-net with any desired probability. Using these results, we demonstrate how random samples can be used to build a partition-tree structure that achieves the above query time."
            },
            "slug": "\u025b-nets-and-simplex-range-queries-Haussler-Welzl",
            "title": {
                "fragments": [],
                "text": "\u025b-nets and simplex range queries"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The concept of an \u025b-net of a set of points for an abstract set of ranges is introduced and sufficient conditions that a random sample is an \u00c3\u201a-net with any desired probability are given."
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Comput. Geom."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717349"
                        ],
                        "name": "D. Knuth",
                        "slug": "D.-Knuth",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Knuth",
                            "middleNames": [
                                "Ervin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Knuth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 65140997,
            "fieldsOfStudy": [
                "Engineering",
                "Physics"
            ],
            "id": "748f27587c37d8b0882a20692967901b81429fce",
            "isKey": false,
            "numCitedBy": 11594,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A fuel pin hold-down and spacing apparatus for use in nuclear reactors is disclosed. Fuel pins forming a hexagonal array are spaced apart from each other and held-down at their lower end, securely attached at two places along their length to one of a plurality of vertically disposed parallel plates arranged in horizontally spaced rows. These plates are in turn spaced apart from each other and held together by a combination of spacing and fastening means. The arrangement of this invention provides a strong vibration free hold-down mechanism while avoiding a large pressure drop to the flow of coolant fluid. This apparatus is particularly useful in connection with liquid cooled reactors such as liquid metal cooled fast breeder reactors."
            },
            "slug": "The-Art-of-Computer-Programming-Knuth",
            "title": {
                "fragments": [],
                "text": "The Art of Computer Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The arrangement of this invention provides a strong vibration free hold-down mechanism while avoiding a large pressure drop to the flow of coolant fluid."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060896"
                        ],
                        "name": "P. Winston",
                        "slug": "P.-Winston",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Winston",
                            "middleNames": [
                                "Henry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Winston"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "More complex learning problems in which the domain consists of a set of labeled graphs representing descriptions of visual scenes and the target classes are defined by certain types of first-order formulas (e.g., Winston\u2019s \u201carch\u201d concept in a blocks world domain [ 67 ]) are considered in [26] and [60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 106617047,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "a7eb50210a468d0878666e8f82fb55f2b179f802",
            "isKey": false,
            "numCitedBy": 1208,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Massachusetts Institute of Technology. Dept. of Electrical Engineering. Thesis. 1970. Ph.D."
            },
            "slug": "Learning-Structural-Descriptions-From-Examples-Winston",
            "title": {
                "fragments": [],
                "text": "Learning Structural Descriptions From Examples"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69046239"
                        ],
                        "name": "\u5ba4 \u7ae0\u6cbb\u90ce",
                        "slug": "\u5ba4-\u7ae0\u6cbb\u90ce",
                        "structuredName": {
                            "firstName": "\u5ba4",
                            "lastName": "\u7ae0\u6cbb\u90ce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u5ba4 \u7ae0\u6cbb\u90ce"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 160726595,
            "fieldsOfStudy": [
                "History"
            ],
            "id": "023476b43f3d3acdc80e589fd50aa8e12c4ae0f4",
            "isKey": false,
            "numCitedBy": 424,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Michael-R.Garey/David-S.Johnson-\u8457,-\"COMPUTERS-AND-A-\u7ae0\u6cbb\u90ce",
            "title": {
                "fragments": [],
                "text": "Michael R.Garey/David S.Johnson \u8457, \"COMPUTERS AND INTRACTABILITY A guide to the Theory of NP-Completeness\", FREEMAN, A5\u5224\u5909\u5f62\u5224, 338+xii, \\5,217, 1979"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2019 This parameter is called the capacity of C in [61] (named after a similar notion from [ 131) and S(C) in [ 17 ]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 120994616,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3e211ab5f8fe33612149727fb3e5b1ad4af65d34",
            "isKey": false,
            "numCitedBy": 396,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-course-on-empirical-processes-Dudley",
            "title": {
                "fragments": [],
                "text": "A course on empirical processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29961301"
                        ],
                        "name": "P. Laird",
                        "slug": "P.-Laird",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Laird",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Laird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117133936,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "96020b1bafcc5b06ed7d9d2986c554837cff4e9a",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-from-good-data-and-bad-Laird",
            "title": {
                "fragments": [],
                "text": "Learning from good data and bad"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2658455"
                        ],
                        "name": "E. Gin\u00e9",
                        "slug": "E.-Gin\u00e9",
                        "structuredName": {
                            "firstName": "Eva",
                            "lastName": "Gin\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gin\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715480"
                        ],
                        "name": "J. Zinn",
                        "slug": "J.-Zinn",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Zinn",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zinn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117520631,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f9b4d52539cb54db78e2b3d40cc0f6eb291fcc9b",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lectures-on-the-central-limit-theorem-for-empirical-Gin\u00e9-Zinn",
            "title": {
                "fragments": [],
                "text": "Lectures on the central limit theorem for empirical processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59746611,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "78ecaabe915ba7df950671d36f92678192802df4",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Estimation-of-Dependences-Based-on-Empirical-Data:-Vapnik",
            "title": {
                "fragments": [],
                "text": "Estimation of Dependences Based on Empirical Data: Springer Series in Statistics (Springer Series in Statistics)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109503620"
                        ],
                        "name": "Temple F. Smith",
                        "slug": "Temple-F.-Smith",
                        "structuredName": {
                            "firstName": "Temple",
                            "lastName": "Smith",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Temple F. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4276691,
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "id": "0b4d43ef0051a225e07af8194e81007ebba8d787",
            "isKey": false,
            "numCitedBy": 705,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Occam's-razor-Smith",
            "title": {
                "fragments": [],
                "text": "Occam's razor"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The consequences of introducing syntactic complexity into an abstract theory of learnability have recently been explored independently from our work in [8] and [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19457773,
            "fieldsOfStudy": [],
            "id": "fe9c43c67cd2bac32aeb0a7e9f44e5f2a5b444a6",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nonuniform Learnability"
            },
            "venue": {
                "fragments": [],
                "text": "ICALP"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760676"
                        ],
                        "name": "S. Muroga",
                        "slug": "S.-Muroga",
                        "structuredName": {
                            "firstName": "Saburo",
                            "lastName": "Muroga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Muroga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In [ 46 ], it is shown that 2\u201d(\u201c-\u2018)\u201c2 I ] c\u2019] 5 2\u201d*."
                    },
                    "intents": []
                }
            ],
            "corpusId": 35807921,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d08191e5a15b1c01446897083be5d14f2f05f8f9",
            "isKey": false,
            "numCitedBy": 850,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Threshold-logic-and-its-applications-Muroga",
            "title": {
                "fragments": [],
                "text": "Threshold logic and its applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122051864"
                        ],
                        "name": "S. Boucheron",
                        "slug": "S.-Boucheron",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Boucheron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Boucheron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733472"
                        ],
                        "name": "J. Sallantin",
                        "slug": "J.-Sallantin",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Sallantin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sallantin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27272436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f710e0d7ed8df8c982516db74b995c53502b275a",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Some-remarks-about-space-complexity-of-learning,-of-Boucheron-Sallantin",
            "title": {
                "fragments": [],
                "text": "Some remarks about space-complexity of learning, and circuit complexity of recognizing"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "hard to learn\u201d classes include the class of all concepts represented by Boolean formulas of size bounded by a fixed polynomial in y1 [ 35 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 536357,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "05e0d765b024b743520971c5a25569d92c204ad7",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we consider the problem of learning from examples classes of functions when there are no restrictions on the allowed hypotheses other than that they are polynomial time evaluatable. We prove that for Boolean formulae, finite automata, and constant depth threshold circuits (simplified neural nets), this problem is computationally as difficult as the quadratic residue problem, inverting the RSA function and factoring Blum integers (composite number p q where p and q are both primes congruent to 3 modulo 4). These results are for the distributionfree model of learning [31]. They hold even when the inference task is that of deriving a probabilistic polynomial-time classification algorithm that predicts the correct value of a random input with probability $ + &, where s is the size of the formula, automaton or circuit, and p is any polynomial. (We call this model weak learning). Previously the only nonlearnability results that were similarly independent of hypothesis representation were those implied by the work of Goldreich, Goldwasser and Micali [17], for such classes as unrestricted Boolean circuits [25,31]. In addition to the particular results stated above we can abstract from our method a general technique for proving nonlearnability based on the existence of trapdoor functions in the sense of Yao [34]."
            },
            "slug": "Crytographic-limitations-on-learning-Boolean-and-Kearns-Valiant",
            "title": {
                "fragments": [],
                "text": "Crytographic limitations on learning Boolean formulae and finite automata"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that for Boolean formulae, finite automata, and constant depth threshold circuits (simplified neural nets), this problem is computationally as difficult as the quadratic residue problem, inverting the RSA function and factoring Blum integers."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '89"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DensitC et Dimension"
            },
            "venue": {
                "fragments": [],
                "text": "Ann. Inst. Fourier, Grenoble"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Approximation algorithms for combinatorial problems . . I . Cornput"
            },
            "venue": {
                "fragments": [],
                "text": ". Syst . Sci ."
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theory of Pattern Recognition (in Russian)"
            },
            "venue": {
                "fragments": [],
                "text": "Theory of Pattern Recognition (in Russian)"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Minimal polygonal separation"
            },
            "venue": {
                "fragments": [],
                "text": "Ann . Prob ."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computational geometry - A survey"
            },
            "venue": {
                "fragments": [],
                "text": "Learning from good data and bad . Tech . Rep . YALEU / DCS / TR - 55 1"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic Turing machines"
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Comput"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A theory of the learnable 1134-I 142. 60. VALIANT, L. G. Learning disjunctions of conjunctions"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 9th International Confirence on ArtiJicial Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The fastest descent method for covering problems (in Russian)"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings qf a Symposium on Questions of Precision and Efficiency of Computer Algorithms"
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Minimal polygonal separation"
            },
            "venue": {
                "fragments": [],
                "text": "Inj Comput"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computational geometry-A survey"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trun.;. Comput"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convergence ofStochastic Processes"
            },
            "venue": {
                "fragments": [],
                "text": "Convergence ofStochastic Processes"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 9
                            }
                        ],
                        "text": "RECEIVED MARCH 1986; REVISED NOVEMBER 1987 AND OCTOBER 1988; ACCEPTED NOVEMBER 1988\nJournal of the Association for Computing Machinery, Vol. 36, No. 4, October 1989."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "REVISED NOVEMBER 1987 AND OCTOBER 1988; ACCEPTED NOVEMBER"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Association for Computing Machinery"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic Turing machines"
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J . Comput ."
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Some NP-complete set cover problems"
            },
            "venue": {
                "fragments": [],
                "text": "Some NP-complete set cover problems"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Approximation algorithms for combinatorial problems A new polynomial-time algorithm for linear programming"
            },
            "venue": {
                "fragments": [],
                "text": "I. Cornput. Syst. Sci"
            },
            "year": 1974
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 8,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 71,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Learnability-and-the-Vapnik-Chervonenkis-dimension-Blumer-Ehrenfeucht/e0b8fa3496283d4d808fba9ff62d5f024bcf23be?sort=total-citations"
}