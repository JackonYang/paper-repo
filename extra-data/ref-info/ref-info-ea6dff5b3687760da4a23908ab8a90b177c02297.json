{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3198903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e79272fe3d65197100eae8be9fec6469107969ae",
            "isKey": false,
            "numCitedBy": 9375,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI--SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function."
            },
            "slug": "Object-Detection-with-Discriminatively-Trained-Part-Felzenszwalb-Girshick",
            "title": {
                "fragments": [],
                "text": "Object Detection with Discriminatively Trained Part Based Models"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An object detection system based on mixtures of multiscale deformable part models that is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9385043"
                        ],
                        "name": "W. R. Schwartz",
                        "slug": "W.-R.-Schwartz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "Robson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2684226"
                        ],
                        "name": "Aniruddha Kembhavi",
                        "slug": "Aniruddha-Kembhavi",
                        "structuredName": {
                            "firstName": "Aniruddha",
                            "lastName": "Kembhavi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aniruddha Kembhavi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145298122"
                        ],
                        "name": "D. Harwood",
                        "slug": "D.-Harwood",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Harwood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harwood"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5717894,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efc0cb142588a6dd571e52b30217c4a7905f254d",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Significant research has been devoted to detecting people in images and videos. In this paper we describe a human detection method that augments widely used edge-based features with texture and color information, providing us with a much richer descriptor set. This augmentation results in an extremely high-dimensional feature space (more than 170,000 dimensions). In such high-dimensional spaces, classical machine learning algorithms such as SVMs are nearly intractable with respect to training. Furthermore, the number of training samples is much smaller than the dimensionality of the feature space, by at least an order of magnitude. Finally, the extraction of features from a densely sampled grid structure leads to a high degree of multicollinearity. To circumvent these data characteristics, we employ Partial Least Squares (PLS) analysis, an efficient dimensionality reduction technique, one which preserves significant discriminative information, to project the data onto a much lower dimensional subspace (20 dimensions, reduced from the original 170,000). Our human detection system, employing PLS analysis over the enriched descriptor set, is shown to outperform state-of-the-art techniques on three varied datasets including the popular INRIA pedestrian dataset, the low-resolution gray-scale DaimlerChrysler pedestrian dataset, and the ETHZ pedestrian dataset consisting of full-length videos of crowded scenes."
            },
            "slug": "Human-detection-using-partial-least-squares-Schwartz-Kembhavi",
            "title": {
                "fragments": [],
                "text": "Human detection using partial least squares analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper describes a human detection method that augments widely used edge-based features with texture and color information, providing us with a much richer descriptor set, and is shown to outperform state-of-the-art techniques on three varied datasets."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045340"
                        ],
                        "name": "Tomasz Malisiewicz",
                        "slug": "Tomasz-Malisiewicz",
                        "structuredName": {
                            "firstName": "Tomasz",
                            "lastName": "Malisiewicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomasz Malisiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14448882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d124f004fed2ee15860f624005b2215cfaeff276",
            "isKey": false,
            "numCitedBy": 892,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a conceptually simple but surprisingly powerful method which combines the effectiveness of a discriminative object detector with the explicit correspondence offered by a nearest-neighbor approach. The method is based on training a separate linear SVM classifier for every exemplar in the training set. Each of these Exemplar-SVMs is thus defined by a single positive instance and millions of negatives. While each detector is quite specific to its exemplar, we empirically observe that an ensemble of such Exemplar-SVMs offers surprisingly good generalization. Our performance on the PASCAL VOC detection task is on par with the much more complex latent part-based model of Felzenszwalb et al., at only a modest computational cost increase. But the central benefit of our approach is that it creates an explicit association between each detection and a single training exemplar. Because most detections show good alignment to their associated exemplar, it is possible to transfer any available exemplar meta-data (segmentation, geometric structure, 3D model, etc.) directly onto the detections, which can then be used as part of overall scene understanding."
            },
            "slug": "Ensemble-of-exemplar-SVMs-for-object-detection-and-Malisiewicz-Gupta",
            "title": {
                "fragments": [],
                "text": "Ensemble of exemplar-SVMs for object detection and beyond"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper proposes a conceptually simple but surprisingly powerful method which combines the effectiveness of a discriminative object detector with the explicit correspondence offered by a nearest-neighbor approach."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": false,
            "numCitedBy": 29266,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37581938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47980c6e42f1a3381e6c5f3db7230e6a64c40218",
            "isKey": false,
            "numCitedBy": 369,
            "numCiting": 218,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis targets the detection of humans and other object classes in images and videos. Our focus is on developing robust feature extraction algorithms that encode image regions as highdimensional feature vectors that support high accuracy object/non-object decisions. To test our feature sets we adopt a relatively simple learning framework that uses linear Support Vector Machines to classify each possible image region as an object or as a non-object. The approach is data-driven and purely bottom-up using low-level appearance and motion vectors to detect objects. As a test case we focus on person detection as people are one of the most challenging object classes with many applications, for example in film and video analysis, pedestrian detection for smart cars and video surveillance. Nevertheless we do not make any strong class specific assumptions and the resulting object detection framework also gives state-of-the-art performance for many other classes including cars, motorbikes, cows and sheep. This thesis makes four main contributions. Firstly, we introduce grids of locally normalised Histograms of Oriented Gradients (HOG) as descriptors for object detection in static images. The HOG descriptors are computed over dense and overlapping grids of spatial blocks, with image gradient orientation features extracted at fixed resolution and gathered into a highdimensional feature vector. They are designed to be robust to small changes in image contour locations and directions, and significant changes in image illumination and colour, while remaining highly discriminative for overall visual form. We show that unsmoothed gradients, fine orientation voting, moderately coarse spatial binning, strong normalisation and overlapping blocks are all needed for good performance. Secondly, to detect moving humans in videos, we propose descriptors based on oriented histograms of differential optical flow. These are similar to static HOG descriptors, but instead of image gradients, they are based on local differentials of dense optical flow. They encode the noisy optical flow estimates into robust feature vectors in a manner that is robust to the overall camera motion. Several variants are proposed, some capturing motion boundaries while others encode the relative motions of adjacent image regions. Thirdly, we propose a general method based on kernel density estimation for fusing multiple overlapping detections, that takes into account the number of detections, their confidence scores and the scales of the detections. Lastly, we present work in progress on a parts based approach to person detection that first detects local body parts like heads, torso, and legs and then fuses them to create a global overall person detector."
            },
            "slug": "Finding-People-in-Images-and-Videos-Dalal",
            "title": {
                "fragments": [],
                "text": "Finding People in Images and Videos"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This thesis introduces grids of locally normalised Histograms of Oriented Gradients (HOG) as descriptors for object detection in static images and proposes descriptors based on oriented histograms of differential optical flow to detect moving humans in videos."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719780"
                        ],
                        "name": "Yan Ke",
                        "slug": "Yan-Ke",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Ke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Ke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694199"
                        ],
                        "name": "R. Sukthankar",
                        "slug": "R.-Sukthankar",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Sukthankar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sukthankar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 288876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a46f093f587eaa29c4d87c755b4b1fa3eabecdb",
            "isKey": false,
            "numCitedBy": 1998,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Stable local feature detection and representation is a fundamental component of many image registration and object recognition algorithms. Mikolajczyk and Schmid (June 2003) recently evaluated a variety of approaches and identified the SIFT [D. G. Lowe, 1999] algorithm as being the most resistant to common image deformations. This paper examines (and improves upon) the local image descriptor used by SIFT. Like SIFT, our descriptors encode the salient aspects of the image gradient in the feature point's neighborhood; however, instead of using SIFT's smoothed weighted histograms, we apply principal components analysis (PCA) to the normalized gradient patch. Our experiments demonstrate that the PCA-based local descriptors are more distinctive, more robust to image deformations, and more compact than the standard SIFT representation. We also present results showing that using these descriptors in an image retrieval application results in increased accuracy and faster matching."
            },
            "slug": "PCA-SIFT:-a-more-distinctive-representation-for-Ke-Sukthankar",
            "title": {
                "fragments": [],
                "text": "PCA-SIFT: a more distinctive representation for local image descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper examines (and improves upon) the local image descriptor used by SIFT, and demonstrates that the PCA-based local descriptors are more distinctive, more robust to image deformations, and more compact than the standard SIFT representation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 144074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "207232070372a1dea58013b6b93f3d1e0ca4dd15",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a structured output model for object category detection that explicitly accounts for alignment, multiple aspects and partial truncation in both training and inference. The model is formulated as large margin learning with latent variables and slack rescaling, and both training and inference are computationally efficient. We make the following contributions: (i) we note that extending the Structured Output Regression formulation of Blaschko and Lampert [1] to include a bias term significantly improves performance; (ii) that alignment (to account for small rotations and anisotropic scalings) can be included as a latent variable and efficiently determined and implemented; (iii) that the latent variable extends to multiple aspects (e.g. left facing, right facing, front) with the same formulation; and (iv), most significantly for performance, that truncated and truncated instances can be included in both training and inference with an explicit truncation mask. \n \nWe demonstrate the method by training and testing on the PASCAL VOC 2007 data set - training includes the truncated examples, and in testing object instances are detected at multiple scales, alignments, and with significant truncations."
            },
            "slug": "Structured-output-regression-for-detection-with-Vedaldi-Zisserman",
            "title": {
                "fragments": [],
                "text": "Structured output regression for detection with partial truncation"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A structured output model for object category detection that explicitly accounts for alignment, multiple aspects and partial truncation in both training and inference is developed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685300"
                        ],
                        "name": "J. Hespanha",
                        "slug": "J.-Hespanha",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Hespanha",
                            "middleNames": [
                                "Pedro"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hespanha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30582,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be86da00efdd8c2a7fdeb2334605796c24b370f0",
            "isKey": false,
            "numCitedBy": 11723,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking a pattern classification approach, we consider each pixel in an image as a coordinate in a high-dimensional space. We take advantage of the observation that the images of a particular face, under varying illumination but fixed pose, lie in a 3D linear subspace of the high dimensional image space-if the face is a Lambertian surface without shadowing. However, since faces are not truly Lambertian surfaces and do indeed produce self-shadowing, images will deviate from this linear subspace. Rather than explicitly modeling this deviation, we linearly project the image into a subspace in a manner which discounts those regions of the face with large deviation. Our projection method is based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variation in lighting and facial expressions. The eigenface technique, another method based on linearly projecting the image space to a low dimensional subspace, has similar computational requirements. Yet, extensive experimental results demonstrate that the proposed \"Fisherface\" method has error rates that are lower than those of the eigenface technique for tests on the Harvard and Yale face databases."
            },
            "slug": "Eigenfaces-vs.-Fisherfaces:-Recognition-Using-Class-Belhumeur-Hespanha",
            "title": {
                "fragments": [],
                "text": "Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A face recognition algorithm which is insensitive to large variation in lighting direction and facial expression is developed, based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variations in lighting and facial expressions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6611218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef768a5c9bd0aaeddafea1d56b08b0c8180760c0",
            "isKey": false,
            "numCitedBy": 1493,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of automatically learning object models for recognition and pose estimation is addressed. In contrast to the traditional approach, the recognition problem is formulated as one of matching appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties and constant for a rigid object, pose and illumination vary from scene to scene. A compact representation of object appearance is proposed that is parametrized by pose and illumination. For each object of interest, a large set of images is obtained by automatically varying pose and illumination. This image set is compressed to obtain a low-dimensional subspace, called the eigenspace, in which the object is represented as a manifold. Given an unknown input image, the recognition system projects the image to eigenspace. The object is recognized based on the manifold it lies on. The exact position of the projection on the manifold determines the object's pose in the image.A variety of experiments are conducted using objects with complex appearance characteristics. The performance of the recognition and pose estimation algorithms is studied using over a thousand input images of sample objects. Sensitivity of recognition to the number of eigenspace dimensions and the number of learning samples is analyzed. For the objects used, appearance representation in eigenspaces with less than 20 dimensions produces accurate recognition results with an average pose estimation error of about 1.0 degree. A near real-time recognition system with 20 complex objects in the database has been developed. The paper is concluded with a discussion on various issues related to the proposed learning and recognition methodology."
            },
            "slug": "Visual-learning-and-recognition-of-3-d-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Visual learning and recognition of 3-d objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A near real-time recognition system with 20 complex objects in the database has been developed and a compact representation of object appearance is proposed that is parametrized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2381913"
                        ],
                        "name": "Tianshi Gao",
                        "slug": "Tianshi-Gao",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409971380"
                        ],
                        "name": "Ben Packer",
                        "slug": "Ben-Packer",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Packer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ben Packer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6885511,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc45ff69110f7bbe4d89f98f2d75715913468fba",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The bounding box representation employed by many popular object detection models [3, 6] implicitly assumes all pixels inside the box belong to the object. This assumption makes this representation less robust to the object with occlusion [16]. In this paper, we augment the bounding box with a set of binary variables each of which corresponds to a cell indicating whether the pixels in the cell belong to the object. This segmentation-aware representation explicitly models and accounts for the supporting pixels for the object within the bounding box thus more robust to occlusion. We learn the model in a structured output framework, and develop a method that efficiently performs both inference and learning using this rich representation. The method is able to use segmentation reasoning to achieve improved detection results with richer output (cell level segmentation) on the Street Scenes and Pascal VOC 2007 datasets. Finally, we present a globally coherent object model using our rich representation to account for object-object occlusion resulting in a more coherent image understanding."
            },
            "slug": "A-segmentation-aware-object-detection-model-with-Gao-Packer",
            "title": {
                "fragments": [],
                "text": "A segmentation-aware object detection model with occlusion handling"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This paper augments the bounding box with a set of binary variables each of which corresponds to a cell indicating whether the pixels in the cell belong to the object, making this representation more robust to occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14955,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14848918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "isKey": false,
            "numCitedBy": 12819,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging."
            },
            "slug": "Normalized-cuts-and-image-segmentation-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats image segmentation as a graph partitioning problem and proposes a novel global criterion, the normalized cut, for segmenting the graph, which measures both the total dissimilarity between the different groups as well as the total similarity within the groups."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805742"
                        ],
                        "name": "Benjamin M Marlin",
                        "slug": "Benjamin-M-Marlin",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Marlin",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin M Marlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145610994"
                        ],
                        "name": "Mark W. Schmidt",
                        "slug": "Mark-W.-Schmidt",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Schmidt",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark W. Schmidt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14305014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78632b7db6110de5f86c00ec18f0ce76eab7ca44",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently it has become popular to learn sparse Gaussian graphical models (GGMs) by imposing l1 or group l1, 2 penalties on the elements of the precision matrix. This penalized likelihood approach results in a tractable convex optimization problem. In this paper, we reinterpret these results as performing MAP estimation under a novel prior which we call the group l1 and l1, 2 positive-definite matrix distributions. This enables us to build a hierarchical model in which the l1 regularization terms vary depending on which group the entries are assigned to, which in turn allows us to learn block structured sparse GGMs with unknown group assignments. Exact inference in this hierarchical model is intractable, due to the need to compute the normalization constant of these matrix distributions. However, we derive upper bounds on the partition functions, which lets us use fast variational inference (optimizing a lower bound on the joint posterior). We show that on two real world data sets (motion capture and financial data), our method which infers the block structure outperforms a method that uses a fixed block structure, which in turn outperforms baseline methods that ignore block structure."
            },
            "slug": "Group-Sparse-Priors-for-Covariance-Estimation-Marlin-Schmidt",
            "title": {
                "fragments": [],
                "text": "Group Sparse Priors for Covariance Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper reinterprets results as performing MAP estimation under a novel prior which enables a hierarchical model in which the l1 regularization terms vary depending on which group the entries are assigned to, which in turn allows to learn block structured sparse GGMs with unknown group assignments."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769383"
                        ],
                        "name": "Lubomir D. Bourdev",
                        "slug": "Lubomir-D.-Bourdev",
                        "structuredName": {
                            "firstName": "Lubomir",
                            "lastName": "Bourdev",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lubomir D. Bourdev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9320620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55b29a2505149d06d8c1d616cd30edca40cb029c",
            "isKey": false,
            "numCitedBy": 1048,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the classic problems of detection, segmentation and pose estimation of people in images with a novel definition of a part, a poselet. We postulate two criteria (1) It should be easy to find a poselet given an input image (2) it should be easy to localize the 3D configuration of the person conditioned on the detection of a poselet. To permit this we have built a new dataset, H3D, of annotations of humans in 2D photographs with 3D joint information, inferred using anthropometric constraints. This enables us to implement a data-driven search procedure for finding poselets that are tightly clustered in both 3D joint configuration space as well as 2D image appearance. The algorithm discovers poselets that correspond to frontal and profile faces, pedestrians, head and shoulder views, among others. Each poselet provides examples for training a linear SVM classifier which can then be run over the image in a multiscale scanning mode. The outputs of these poselet detectors can be thought of as an intermediate layer of nodes, on top of which one can run a second layer of classification or regression. We show how this permits detection and localization of torsos or keypoints such as left shoulder, nose, etc. Experimental results show that we obtain state of the art performance on people detection in the PASCAL VOC 2007 challenge, among other datasets. We are making publicly available both the H3D dataset as well as the poselet parameters for use by other researchers."
            },
            "slug": "Poselets:-Body-part-detectors-trained-using-3D-pose-Bourdev-Malik",
            "title": {
                "fragments": [],
                "text": "Poselets: Body part detectors trained using 3D human pose annotations"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A new dataset, H3D, is built of annotations of humans in 2D photographs with 3D joint information, inferred using anthropometric constraints, to address the classic problems of detection, segmentation and pose estimation of people in images with a novel definition of a part, a poselet."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791548"
                        ],
                        "name": "A. Hyv\u00e4rinen",
                        "slug": "A.-Hyv\u00e4rinen",
                        "structuredName": {
                            "firstName": "Aapo",
                            "lastName": "Hyv\u00e4rinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hyv\u00e4rinen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3346683"
                        ],
                        "name": "J. Hurri",
                        "slug": "J.-Hurri",
                        "structuredName": {
                            "firstName": "Jarmo",
                            "lastName": "Hurri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hurri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35211061"
                        ],
                        "name": "P. Hoyer",
                        "slug": "P.-Hoyer",
                        "structuredName": {
                            "firstName": "Patrik",
                            "lastName": "Hoyer",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 362991,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3596cc61267bdae97bb1df9b01a8e9a1b8dca450",
            "isKey": false,
            "numCitedBy": 614,
            "numCiting": 181,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the most successful frameworks in computational neuroscience is modeling visual processing using the statistical structure of natural images. In this framework, the visual system of the brain constructs a model of the statistical regularities of the incoming visual data. This enables the visual system to perform efficient probabilistic inference. The same framework is also very useful in engineering applications such as image processing and computer vision. This book is the first comprehensive introduction to the multidisciplinary field of natural image statistics. The book starts with a review of background material in signal processing and neuroscience, which makes it accessible to a wide audience. The book then explains both the basic theory and the most recent advances in a coherent and user-friendly manner. This structure, together with the included exercises and computer assignments, also make it an excellent textbook. \"Natural Image Statistics\" is a timely and valuable resource for advanced students and researchers in any discipline related to vision, such as neuroscience, computer science, psychology, electrical engineering, cognitive science or statistics."
            },
            "slug": "Natural-Image-Statistics-A-Probabilistic-Approach-Hyv\u00e4rinen-Hurri",
            "title": {
                "fragments": [],
                "text": "Natural Image Statistics - A Probabilistic Approach to Early Computational Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book is the first comprehensive introduction to the multidisciplinary field of natural image statistics and explains both the basic theory and the most recent advances in a coherent and user-friendly manner."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Imaging and Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61615905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a2ed19ac684022aa3186887cd4893484ab8f80c",
            "isKey": false,
            "numCitedBy": 2169,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006). Details of the challenge, data, and evaluation are presented. Participants in the challenge submitted descriptions of their methods, and these have been included verbatim. This document should be considered preliminary, and subject to change."
            },
            "slug": "The-PASCAL-visual-object-classes-challenge-2006-Everingham-Zisserman",
            "title": {
                "fragments": [],
                "text": "The PASCAL visual object classes challenge 2006 (VOC2006) results"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3444394"
                        ],
                        "name": "E. Ziegel",
                        "slug": "E.-Ziegel",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Ziegel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ziegel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46701966,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "e41ba5dc12c79a64dfa905c0328f95976252ffe0",
            "isKey": false,
            "numCitedBy": 12393,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Chapter 11 includes more case studies in other areas, ranging from manufacturing to marketing research. Chapter 12 concludes the book with some commentary about the scienti\u008e c contributions of MTS. The Taguchi method for design of experiment has generated considerable controversy in the statistical community over the past few decades. The MTS/MTGS method seems to lead another source of discussions on the methodology it advocates (Montgomery 2003). As pointed out by Woodall et al. (2003), the MTS/MTGS methods are considered ad hoc in the sense that they have not been developed using any underlying statistical theory. Because the \u201cnormal\u201d and \u201cabnormal\u201d groups form the basis of the theory, some sampling restrictions are fundamental to the applications. First, it is essential that the \u201cnormal\u201d sample be uniform, unbiased, and/or complete so that a reliable measurement scale is obtained. Second, the selection of \u201cabnormal\u201d samples is crucial to the success of dimensionality reduction when OAs are used. For example, if each abnormal item is really unique in the medical example, then it is unclear how the statistical distance MD can be guaranteed to give a consistent diagnosis measure of severity on a continuous scale when the larger-the-better type S/N ratio is used. Multivariate diagnosis is not new to Technometrics readers and is now becoming increasingly more popular in statistical analysis and data mining for knowledge discovery. As a promising alternative that assumes no underlying data model, The Mahalanobis\u2013Taguchi Strategy does not provide suf\u008e cient evidence of gains achieved by using the proposed method over existing tools. Readers may be very interested in a detailed comparison with other diagnostic tools, such as logistic regression and tree-based methods. Overall, although the idea of MTS/MTGS is intriguing, this book would be more valuable had it been written in a rigorous fashion as a technical reference. There is some lack of precision even in several mathematical notations. Perhaps a follow-up with additional theoretical justi\u008e cation and careful case studies would answer some of the lingering questions."
            },
            "slug": "The-Elements-of-Statistical-Learning-Ziegel",
            "title": {
                "fragments": [],
                "text": "The Elements of Statistical Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "Chapter 11 includes more case studies in other areas, ranging from manufacturing to marketing research, and a detailed comparison with other diagnostic tools, such as logistic regression and tree-based methods."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2194841"
                        ],
                        "name": "H. Rue",
                        "slug": "H.-Rue",
                        "structuredName": {
                            "firstName": "H\u00e5vard",
                            "lastName": "Rue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144433364"
                        ],
                        "name": "L. Held",
                        "slug": "L.-Held",
                        "structuredName": {
                            "firstName": "Leonhard",
                            "lastName": "Held",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Held"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60632241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f714b82aff5370bec8990671b30b9af743b147ba",
            "isKey": false,
            "numCitedBy": 1961,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Gaussian Markov Random Field (GMRF) models are most widely used in spatial statistics, a very active area of research in which few up-to-date reference works are available. Gaussian Markov Random Field: Theory and Applications is the first book on the subject that provides a unified framework of GMRFs with particular emphasis on the computational aspects. The book includes extensive case studies and online a c-library for fast and exact simulation. With chapters contributed by leading researchers in the field, this volume is essential reading for statisticians working in spatial theory and its applications, as well as quantitative researchers in a wide range of science fields where spatial data analysis is important."
            },
            "slug": "Gaussian-Markov-Random-Fields:-Theory-and-Rue-Held",
            "title": {
                "fragments": [],
                "text": "Gaussian Markov Random Fields: Theory and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This volume is essential reading for statisticians working in spatial theory and its applications, as well as quantitative researchers in a wide range of science fields where spatial data analysis is important."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 117
                            }
                        ],
                        "text": "LDA has been used before in computer vision, one of the earliest and most popular appications being face recognition [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "Our observations mirror those of Belhumeur et al [8] who showed that in the context of face recognition, the directions retained by PCA often correspond to variations in illumination and viewing direction, rather than variations that would be discriminative of the identity of the face."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[8] conclude that Fisher\u2019s discriminant analysis outperforms PCA on face recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eigenfaces vs"
            },
            "venue": {
                "fragments": [],
                "text": "fisherfaces: Recognition using class specific linear projection. TPAMI 19"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141732326"
                        ],
                        "name": "Jianguo Zhang",
                        "slug": "Jianguo-Zhang",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63925014,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "0ec48ac86456cea3d6d6172ca81ef68e98b21a61",
            "isKey": false,
            "numCitedBy": 3322,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-PASCAL-Visual-Object-Classes-Challenge-Zhang",
            "title": {
                "fragments": [],
                "text": "The PASCAL Visual Object Classes Challenge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49353544"
                        ],
                        "name": "R. Fisher",
                        "slug": "R.-Fisher",
                        "structuredName": {
                            "firstName": "Rory",
                            "lastName": "Fisher",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29084021,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "ab21376e43ac90a4eafd14f0f02a0c87502b6bbf",
            "isKey": false,
            "numCitedBy": 13266,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-USE-OF-MULTIPLE-MEASUREMENTS-IN-TAXONOMIC-Fisher",
            "title": {
                "fragments": [],
                "text": "THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1936
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pattern recognition and scene analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern recognition and scene analysis"
            },
            "year": 1973
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 1,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 22,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Discriminative-Decorrelation-for-Clustering-and-Hariharan-Malik/ea6dff5b3687760da4a23908ab8a90b177c02297?sort=total-citations"
}