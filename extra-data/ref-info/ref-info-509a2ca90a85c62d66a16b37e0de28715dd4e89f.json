{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2647414"
                        ],
                        "name": "T. Rogers",
                        "slug": "T.-Rogers",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Rogers",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rogers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701656"
                        ],
                        "name": "James L. McClelland",
                        "slug": "James-L.-McClelland",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McClelland",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. McClelland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 103
                            }
                        ],
                        "text": "Recently there has been some progress in learning distributed representations of conceptual relations (Rogers & McClelland, 2004), although the input to these learning models is still quite idealized, in the form of hand-coded databases of simple propositions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2979028,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c84f76770b820d69a6a1f3914a1c84e7c20a8271",
            "isKey": false,
            "numCitedBy": 1006,
            "numCiting": 357,
            "paperAbstract": {
                "fragments": [],
                "text": "This groundbreaking monograph offers a mechanistic theory of the representation and use of semantic knowledge, integrating the strengths and overcoming many of the weaknesses of hierarchical, categorization-based approaches, similarity-based approaches, and the approach often called \"theory theory.\" Building on earlier models by Geoffrey Hinton in the 1980s and David Rumelhart in the early 1990s, the authors propose that performance in semantic tasks arises through the propagation of graded signals in a system of interconnected processing units. The representations used in performing these tasks are patterns of activation across units, governed by weighted connections among them. Semantic knowledge is acquired through the gradual adjustment of the strengths of these connections in the course of day-to-day experience. The authors show how a simple computational model proposed by Rumelhart exhibits a progressive differentiation of conceptual knowledge, paralleling aspects of cognitive development seen in the work of Frank Keil and Jean Mandler. The authors extend the model to address aspects of conceptual knowledge acquisition in infancy, disintegration of conceptual knowledge in dementia, \"basic-level\" effects and their interaction with expertise, and many findings introduced to support the idea that semantic cognition is guided by naive, domain-specific theories."
            },
            "slug": "Semantic-Cognition:-A-Parallel-Distributed-Approach-Rogers-McClelland",
            "title": {
                "fragments": [],
                "text": "Semantic Cognition: A Parallel Distributed Processing Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The authors propose that performance in semantic tasks arises through the propagation of graded signals in a system of interconnected processing units, and show how a simple computational model proposed by Rumelhart exhibits a progressive differentiation of conceptual knowledge, paralleling aspects of cognitive development seen in the work of Frank Keil and Jean Mandler."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804885"
                        ],
                        "name": "M. Steyvers",
                        "slug": "M.-Steyvers",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steyvers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steyvers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2355175"
                        ],
                        "name": "R. Shiffrin",
                        "slug": "R.-Shiffrin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Shiffrin",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shiffrin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46973696"
                        ],
                        "name": "D. Nelson",
                        "slug": "D.-Nelson",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Nelson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1813261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0040dedc57890ac4a483ef96479c11b6be49b1dc",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "A common assumption of theories of memory is that the meaning of a word can be represented by a vector which places a word as a point in a multidimensional semantic space (e.g. Landauer & Dumais, 1997; Burgess & Lund, 2000; Osgood, Suci, & Tannenbaum, 1957). Representing words as vectors in a multidimensional space allows simple geometric operations such as the Euclidian distance or the angle between the vectors to compute the semantic (dis)similarity between arbitrary pairs or groups of words. This representation makes it possible to make predictions about performance in psychological tasks where the semantic distance between pairs or groups of words is assumed to play a role. One recent framework for placing words in a multidimensional space is Latent Semantic Analysis or LSA (Derweester, Dumais, Furnas, Landauer, & Harshman, 1990; Landauer & Dumais, 1997; Landauer, Foltz, & Laham, 1998). The main assumption is that the similarity between words can be inferred by analyzing the statistical regularities between words and text samples in which they occur. For example, a textbook with a paragraph that mentions \u201ccats\u201d might also mention \u201cdogs\u201d, \u201cfur\u201d, \u201cpets\u201d etc. This knowledge can be used to infer that \u201ccats\u201d and \u201cdogs\u201d are related in meaning. The technique underlying LSA is singular value decomposition (SVD). This procedure is applied to the matrix of word-context frequencies in a high dimensional space (typically with 200-400 dimensions) in which words that appear in similar contexts are placed in similar regions of the space. Interestingly, some words that never occur in the same context might still be similar in LSA space if they co-occurred with other words that do occur together in text samples. Landauer and Dumais (1997) applied the LSA approach to over 60,000 words appearing in over 30,000 contexts of a large encyclopedia. More recently, LSA was applied to over 90,000 words appearing in over 37,000 contexts of reading material that an English reader might be exposed to from 3 grade up to 1 year of college from various sources such as textbooks, novels, and newspaper articles. The LSA representation has been successfully applied to multiple choice vocabulary tests, domain knowledge tests and content evaluation (see Landauer & Dumais, 1997; Landauer et al. 1998). In this research, we will apply scaling techniques such as SVD as well as Multidimensional Scaling on a large database of free association collected by Nelson, McEvoy, and Schreiber (1999) containing norms for first associates for over 5000 words. By applying scaling methods on the free association norms, we hope to uncover the latent information available in the free association norms that is not directly available by investigating simple measures for associative strengths based on the direct and indirect associative strengths through short chains of associates (e.g., Nelson & Zhang, 2000). The basic approach is illustrated in Figure 1. The free association norms were represented in matrix form with the rows representing the cues and the columns representing the responses. The entries in the matrix are filled by some measure of associative strength between cues and responses. By applying scaling methods on the matrix, words are placed in a high dimensional space such that words with similar associative patterns are placed in similar regions of *Send correspondence to: Mark Steyvers, Department of Cognitive Sciences, 3151 Social Sciences Plaza, University of California, Irvine, CA 92697-5100. msteyver@uci.edu the space. We will refer to the resulting space as the"
            },
            "slug": "Word-Association-Spaces-for-Predicting-Semantic-in-Steyvers-Shiffrin",
            "title": {
                "fragments": [],
                "text": "Word Association Spaces for Predicting Semantic Similarity Effects in Episodic Memory."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This research will apply scaling techniques such as SVD as well as Multidimensional Scaling on a large database of free association collected by Nelson, McEvoy, and Schreiber (1999) containing norms for first associates for over 5000 words to uncover the latent information available in the free association norms that is not directly available by investigating simple measures for associative strengths."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2125361"
                        ],
                        "name": "J. Rodd",
                        "slug": "J.-Rodd",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Rodd",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rodd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145357226"
                        ],
                        "name": "M. Gaskell",
                        "slug": "M.-Gaskell",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Gaskell",
                            "middleNames": [
                                "Gareth"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gaskell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400881722"
                        ],
                        "name": "W. Marslen-Wilson",
                        "slug": "W.-Marslen-Wilson",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Marslen-Wilson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Marslen-Wilson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 119
                            }
                        ],
                        "text": "This is the strategy taken in many connectionist models of semantic representation (e.g., Kawamoto, 1993; Plaut, 1997; Rodd et al., 2004), in which different points in space are used to represent different meanings or senses of words."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14214370,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1d8d5b866e19b4072d5cd1a2c0659468db300b57",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Modelling-the-effects-of-semantic-ambiguity-in-word-Rodd-Gaskell",
            "title": {
                "fragments": [],
                "text": "Modelling the effects of semantic ambiguity in word recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40591835"
                        ],
                        "name": "K. Lund",
                        "slug": "K.-Lund",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50611682"
                        ],
                        "name": "C. Burgess",
                        "slug": "C.-Burgess",
                        "structuredName": {
                            "firstName": "Curt",
                            "lastName": "Burgess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burgess"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 157
                            }
                        ],
                        "text": "A second thrust of recent research has been exploring methods for extracting semantic spaces directly from real linguistic corpora (Landauer & Dumais, 1997; Lund & Burgess, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 181
                            }
                        ],
                        "text": "A similar assumption is made by LSA, but this is not true of all methods for automatically extracting semantic representations from text (e.g., Dennis, 2004; Jones & Mewhort, 2007; Lund & Burgess, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 185
                            }
                        ],
                        "text": "In previous work, the extraction and use of gist has been modeled using associative semantic networks (e.g., Collins & Loftus, 1975) and semantic spaces (e.g., Landauer & Dumais, 1997; Lund & Burgess, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 190
                            }
                        ],
                        "text": "This simplicity has its advantages: There has recently been considerable success in learning the structure of such models from large-scale linguistic corpora (e.g., Landauer & Dumais, 1997; Lund & Burgess, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61090106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7093913b4daa0f34d9d58a41ceb0475cc3cc9f4",
            "isKey": true,
            "numCitedBy": 1721,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A procedure that processes a corpus of text and produces numeric vectors containing information about its meanings for each word is presented. This procedure is applied to a large corpus of natural language text taken from Usenet, and the resulting vectors are examined to determine what information is contained within them. These vectors provide the coordinates in a high-dimensional space in which word relationships can be analyzed. Analyses of both vector similarity and multidimensional scaling demonstrate that there is significant semantic information carried in the vectors. A comparison of vector similarity with human reaction times in a single-word priming experiment is presented. These vectors provide the basis for a representational model of semantic memory, hyperspace analogue to language (HAL)."
            },
            "slug": "Producing-high-dimensional-semantic-spaces-from-Lund-Burgess",
            "title": {
                "fragments": [],
                "text": "Producing high-dimensional semantic spaces from lexical co-occurrence"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A procedure that processes a corpus of text and produces numeric vectors containing information about its meanings for each word, which provide the basis for a representational model of semantic memory, hyperspace analogue to language (HAL)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 270
                            }
                        ],
                        "text": "\u2026interpretation of sentences requires semantic knowledge that goes beyond these contextual associative relationships, many theories still identify this level of knowledge as playing an important role in the early stages of language processing (Ericsson & Kintsch, 1995; Kintsch, 1988; Potter, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 195
                            }
                        ],
                        "text": "\u2026such as word-association norms (e.g., Nelson, McEvoy, & Schreiber, 1998), word reading times in sentence processing (e.g., Sereno, Pacht, & Rayner, 1992), semantic priming (e.g., Till, Mross, & Kintsch, 1988), and effects of semantic context in free recall (e.g., Roediger & McDermott, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 307,
                                "start": 252
                            }
                        ],
                        "text": "While the interpretation of sentences requires semantic knowledge that goes beyond these contextual associative relationships, many theories still identify this level of knowledge as playing an important role in the early stages of language processing (Ericsson & Kintsch, 1995; Kintsch, 1988; Potter, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 17
                            }
                        ],
                        "text": "Till, Mross, and Kintsch (1988) examined the time-course of the processing of word meanings using a priming study in which participants read sentences containing ambiguous words and then performed a lexical decision task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 176
                            }
                        ],
                        "text": "One way to do this is to use the semantic context\u2014the gist of a sentence, conversation, or document\u2014to predict related concepts and disambiguate words (Ericsson & Kintsch, 1995; Kintsch, 1988; Potter, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 155
                            }
                        ],
                        "text": "One way to do this is to use the semantic context \u2013 the gist of a sentence, conversation, or document \u2013 to predict related concepts and disambiguate words (Ericsson & Kintsch, 1995; Kintsch, 1988; Potter, 1993)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15246663,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "289d3a9562f57d0182d1aae9376b0e3793d80272",
            "isKey": true,
            "numCitedBy": 3131,
            "numCiting": 105,
            "paperAbstract": {
                "fragments": [],
                "text": "Publisher Summary This chapter discusses data concerning the time course of word identification in a discourse context. A simulation of arithmetic word-problem understanding provides a plausible account for some well-known phenomena. The current theories use representations with several mutually constraining layers. There is typically a linguistic level of representation, conceptual levels to represent both the local and global meaning and structure of a text, and a level at which the text itself has lost its individuality and its information content. Knowledge provides part of the context within which a discourse interpreted. The integration phase is the price the model pays for the necessary flexibility in the construction process."
            },
            "slug": "The-role-of-knowledge-in-discourse-comprehension:-a-Kintsch",
            "title": {
                "fragments": [],
                "text": "The role of knowledge in discourse comprehension: a construction-integration model."
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "This chapter discusses data concerning the time course of word identification in a discourse context and a simulation of arithmetic word-problem understanding provides a plausible account for some well-known phenomena."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31533192"
                        ],
                        "name": "A. Collins",
                        "slug": "A.-Collins",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Collins",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69960817"
                        ],
                        "name": "M. R. Quillian",
                        "slug": "M.-R.-Quillian",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Quillian",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. R. Quillian"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 180
                            }
                        ],
                        "text": "\u2026such as the development of conceptual hierarchies that support propositional knowledge (e.g., Keil, 1979), reaction time to verify conceptual propositions in normal adults (e.g., Collins & Quillian, 1969), and the decay of propositional knowledge with aging or brain damage (e.g., Warrington, 1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 108
                            }
                        ],
                        "text": "Representations of abstract semantic knowledge of this kind have traditionally been hand-coded by modelers (Collins & Quillian, 1969), in part because it is not clear how they could be learned automatically."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 143
                            }
                        ],
                        "text": "This knowledge is traditionally represented in terms of systems of abstract propositions, such as is-a canary bird, has bird wings, and so on (Collins & Quillian, 1969)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60922154,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06cb835bda3420186e2c6f6fa2dbc1613a9b2d75",
            "isKey": false,
            "numCitedBy": 2946,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Retrieval-time-from-semantic-memory-Collins-Quillian",
            "title": {
                "fragments": [],
                "text": "Retrieval time from semantic memory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1341,
                                "start": 0
                            }
                        ],
                        "text": "Landauer and Dumais (1997) suggested that this effect could be explained by LSA, using the cosine between the ambiguous word and the targets to model priming at short delays and the cosine between the entire sentence and the targets to model priming at long delays. They showed that effects similar to those reported by Till et al. emerged from this analysis. We reproduced the analysis of Landauer and Dumais (1997) using the representations we extracted from the TASA corpus. Of the 28 pairs of sentences used by Till et al. (1988), there were 20 for which the ambiguous primes and all four target words appeared in our vocabulary. To simulate priming early in processing, we computed the cosine and inner product between the primes and the target words using the representation extracted by LSA. To simulate priming in the later stages of processing, we computed the cosine and inner product between the average vectors for each of the full sentences (including only those words that appeared in our vocabulary) and the target words. The values produced by these analyses were then averaged over all 20 pairs. The results for the 700-dimensional solution are shown in Table 2 (similar results were obtained with different numbers of dimensions). The results of this analysis illustrate the trends identified by Landauer and Dumais (1997). Both the cosine and the inner product give reasonably high scores to the two meanings when just the prime is used (relative to the distributions shown in Figure 10) and shift to give higher scores to the meaning and inferentially related target appropriate to the sentence when the entire sentence 229 TOPICS IN SEMANTIC REPRESENTATION"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 30
                            }
                        ],
                        "text": "We reproduced the analysis of Landauer and Dumais (1997) using the representations we extracted from the TASA corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Landauer and Dumais (1997) reported that LSA (trained on the TASA corpus but with a larger vocabulary than we used here) produced 64.4% correct answers, close to the average of 64.5% produced by college applicants from non-English-speaking countries."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 160
                            }
                        ],
                        "text": "In previous work, the extraction and use of gist has been modeled using associative semantic networks (e.g., Collins & Loftus, 1975) and semantic spaces (e.g., Landauer & Dumais, 1997; Lund & Burgess, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 132
                            }
                        ],
                        "text": "A second thrust of recent research has been exploring methods for extracting semantic spaces directly from real linguistic corpora (Landauer & Dumais, 1997; Lund & Burgess, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 148
                            }
                        ],
                        "text": "\u2026one theoretical and the other practical: Previous analyses have suggested that the performance of LSA was best with only a few hundred dimensions (Landauer & Dumais, 1997), an observation that was consistent with performance on our task, and 700 dimensions is the limit of standard algorithms for\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 103
                            }
                        ],
                        "text": "We obtained predictions from the two models by deriving semantic representations from the TASA corpus (Landauer & Dumais, 1997), which is a collection of excerpts from reading materials commonly encountered between the first year of school and the first year of college."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 65
                            }
                        ],
                        "text": "The results of this analysis illustrate the trends identified by Landauer and Dumais (1997)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 417,
                                "start": 0
                            }
                        ],
                        "text": "Landauer and Dumais (1997) suggested that this effect could be explained by LSA, using the cosine between the ambiguous word and the targets to model priming at short delays and the cosine between the entire sentence and the targets to model priming at long delays. They showed that effects similar to those reported by Till et al. emerged from this analysis. We reproduced the analysis of Landauer and Dumais (1997) using the representations we extracted from the TASA corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 150
                            }
                        ],
                        "text": "Applications of LSA often evaluate the similarity between two documents by computing the cosine between the average word vectors for those documents (Landauer & Dumais, 1997; Rehder et al., 1998; Wolfe et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 189
                            }
                        ],
                        "text": "The cosine of the angle between the vectors corresponding to words in the semantic space defined by U has proven to be an effective measure of the semantic association between those words (Landauer & Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 136
                            }
                        ],
                        "text": "The matrix shown in Figure 2 is a portion of the full co-occurrence matrix for the Touchstone Applied Science Associates (TASA) corpus (Landauer & Dumais, 1997), a collection of passages excerpted from educational texts used in curricula from the first year of school to the first year of college."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 86
                            }
                        ],
                        "text": "Because the topic model uses exactly the same input as latent semantic analysis (LSA;\nLandauer & Dumais, 1997), a leading model of the acquisition of semantic knowledge in which the association between words depends on the distance between them in a semantic space, we can compare these two models\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 175
                            }
                        ],
                        "text": "We did not use this model because it uses additional information about the structure of the documents, making it harder to compare against alternative approaches such as LSA (Landauer & Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 267
                            }
                        ],
                        "text": "\u2026in predicting human judgments is typically better when one uses only the first few hundred derived dimensions, because reducing the dimensionality of the representation can decrease the effects of statistical noise and emphasize the latent correlations among words (Landauer & Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 534,
                                "start": 0
                            }
                        ],
                        "text": "Landauer and Dumais (1997) suggested that this effect could be explained by LSA, using the cosine between the ambiguous word and the targets to model priming at short delays and the cosine between the entire sentence and the targets to model priming at long delays. They showed that effects similar to those reported by Till et al. emerged from this analysis. We reproduced the analysis of Landauer and Dumais (1997) using the representations we extracted from the TASA corpus. Of the 28 pairs of sentences used by Till et al. (1988), there were 20 for which the ambiguous primes and all four target words appeared in our vocabulary."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Landauer and Dumais (1997) reported that LSA (trained on the TASA corpus but with a larger vocabulary than we used here) produced 64."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 177
                            }
                        ],
                        "text": "One of the original applications of LSA was to the synonyms task of the Test of English as a Foreign Language (TOEFL), used to assess fluency in English for nonnative speakers (Landauer & Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Landauer and Dumais (1997) suggested that this effect could be explained by LSA, using the cosine between the ambiguous word and the targets to model priming at short delays and the cosine between the entire sentence and the targets to model priming at long delays."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 165
                            }
                        ],
                        "text": "This simplicity has its advantages: There has recently been considerable success in learning the structure of such models from large-scale linguistic corpora (e.g., Landauer & Dumais, 1997; Lund & Burgess, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1144461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68dd4b89ce1407372a29d05ca9e4e1a2e0513617",
            "isKey": true,
            "numCitedBy": 5789,
            "numCiting": 210,
            "paperAbstract": {
                "fragments": [],
                "text": "How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched."
            },
            "slug": "A-Solution-to-Plato's-Problem:-The-Latent-Semantic-Landauer-Dumais",
            "title": {
                "fragments": [],
                "text": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50582151"
                        ],
                        "name": "S. Dennis",
                        "slug": "S.-Dennis",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Dennis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dennis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 115
                            }
                        ],
                        "text": "These norms provide a rich body of data, which has only recently begun to be addressed using computational models (Dennis, 2003; Nelson, McEvoy, & Dennis, 2000; Steyvers, Shiffrin, & Nelson, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17050256,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74afa62f0f35a3153230c488ab223a5afb4e8b3e",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The Syntagmatic Paradigmatic model (SP; Dennis & Harrington 2001, Dennis submitted) and the Pooled Adjacent Context model (PAC; Redington, Chater & Finch 1998) are compared on their ability to extract syntactic, semantic and associative information from a corpus of text. On a measure of syntactic class (and subclass) information based on the WordNet lexical database (Miller 1990), the models performed similarly with a small advantage for the PAC model. On a measure of semantic structure based on the similarities produced by Latent Semantic Analysis (LSA; Landauer & Dumais 1997), the models performed equivalently with a small advantage for the SP model. On a measure of associative information based on the free association norms of Nelson, McEvoy & Schreiber (1999), the SP model shows a substantive advantage over the PAC model producing more than twice as many associates."
            },
            "slug": "A-Comparison-of-Statistical-Models-for-the-of-from-Dennis",
            "title": {
                "fragments": [],
                "text": "A Comparison of Statistical Models for the Extraction of Lexical Information from Text Corpor"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The Syntagmatic Paradigmatic model shows a substantive advantage over the PAC model producing more than twice as many associates, and on a measure of associative information based on the free association norms of Nelson, McEvoy & Schreiber, the SP model shows an substantive advantage."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111327888"
                        ],
                        "name": "Michael N. Jones",
                        "slug": "Michael-N.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael N. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821878"
                        ],
                        "name": "D. Mewhort",
                        "slug": "D.-Mewhort",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Mewhort",
                            "middleNames": [
                                "J.",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mewhort"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 158
                            }
                        ],
                        "text": "A similar assumption is made by LSA, but this is not true of all methods for automatically extracting semantic representations from text (e.g., Dennis, 2004; Jones & Mewhort, 2007; Lund & Burgess, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 226
                            }
                        ],
                        "text": "Generative models can be used to overcome a major weakness of most statistical models of language: that they tend to model either syntax or semantics (although recent work provides some exceptions, including Dennis, 2004, and Jones & Mewhort, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7819391,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d3cf28ab36ff7f7601a55c1e832736b2473a07f0",
            "isKey": false,
            "numCitedBy": 576,
            "numCiting": 164,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a computational model that builds a holographic lexicon representing both word meaning and word order from unsupervised experience with natural language. The model uses simple convolution and superposition mechanisms (cf. B. B. Murdock, 1982) to learn distributed holographic representations for words. The structure of the resulting lexicon can account for empirical data from classic experiments studying semantic typicality, categorization, priming, and semantic constraint in sentence completions. Furthermore, order information can be retrieved from the holographic representations, allowing the model to account for limited word transitions without the need for built-in transition rules. The model demonstrates that a broad range of psychological data can be accounted for directly from the structure of lexical representations learned in this way, without the need for complexity to be built into either the processing mechanisms or the representations. The holographic representations are an appropriate knowledge representation to be used by higher order models of language comprehension, relieving the complexity required at the higher level."
            },
            "slug": "Representing-word-meaning-and-order-information-in-Jones-Mewhort",
            "title": {
                "fragments": [],
                "text": "Representing word meaning and order information in a composite holographic lexicon."
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A computational model that builds a holographic lexicon representing both word meaning and word order from unsupervised experience with natural language demonstrates that a broad range of psychological data can be accounted for directly from the structure of lexical representations learned in this way, without the need for complexity to be built into either the processing mechanisms or the representations."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804885"
                        ],
                        "name": "M. Steyvers",
                        "slug": "M.-Steyvers",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steyvers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steyvers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 157
                            }
                        ],
                        "text": "An algorithm similar to that described in Appendix A can be used to infer the distributions over words associated with the topics and classes from a corpus (Griffiths et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 218
                            }
                        ],
                        "text": "The model performs about as well as a standard hidden Markov model\u2014which is a state-of-the-art method\u2014at identifying syntactic classes, and it outperforms distributional clustering (Redington et al., 1998) in this task (Griffiths et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11408454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ecc5ffeae38689dd2fe6ed4c32a6745744d7641",
            "isKey": false,
            "numCitedBy": 593,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical approaches to language learning typically focus on either short-range syntactic dependencies or long-range semantic dependencies between words. We present a generative model that uses both kinds of dependencies, and can be used to simultaneously find syntactic classes and semantic topics despite having no representation of syntax or semantics beyond statistical dependency. This model is competitive on tasks like part-of-speech tagging and document classification with models that exclusively use short- and long-range dependencies respectively."
            },
            "slug": "Integrating-Topics-and-Syntax-Griffiths-Steyvers",
            "title": {
                "fragments": [],
                "text": "Integrating Topics and Syntax"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work presents a generative model that uses both kinds of dependencies, and can be used to simultaneously find syntactic classes and semantic topics despite having no representation of syntax or semantics beyond statistical dependency."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 199
                            }
                        ],
                        "text": "\u2026models have recently become popular in both computational linguistics (e.g., Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999) and psycholinguistics (e.g., Baldewein & Keller, 2004; Jurafsky, 1996), although this work has tended to emphasize syntactic structure over semantics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 90
                            }
                        ],
                        "text": ", Charniak, 1993; Jurafsky & Martin, 2000; Manning & Sch\u00fctze, 1999) and psycholinguistics (e.g., Baldewein & Keller, 2004; Jurafsky, 1996), although this work has tended to emphasize syntactic structure over semantics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16059014,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "e12699afd17766df7df17edf8319cc3bddc029fe",
            "isKey": false,
            "numCitedBy": 572,
            "numCiting": 194,
            "paperAbstract": {
                "fragments": [],
                "text": "The problems of access\u2014retrieving linguistic structure from some mental grammar \u2014and disambiguation\u2014choosing among these structures to correctly parse ambiguous linguistic input\u2014are fundamental to language understanding. The literature abounds with psychological results on lexical access, the access of idioms, syntactic rule access, parsing preferences, syntactic disambiguation, and the processing of garden-path sentences. Unfortunately, it has been difficult to combine models which account for these results to build a general, uniform model of access and disambiguation at the lexical, idiomatic, and syntactic levels. For example, psycholinguistic theories of lexical access and idiom access and parsing theories of syntactic rule access have almost no commonality in methodology or coverage of psycholinguistic data. This article presents a single probabilistic algorithm which models both the access and disambiguation of linguistic knowledge. The algorithm is based on a parallel parser which ranks constructions for access, and interpretations for disambiguation, by their conditional probability. Low-ranked constructions and interpretations are pruned through beam-search; this pruning accounts, among other things, for the garden-path effect. I show that this motivated probabilistic treatment accounts for a wide variety of psycholinguistic results, arguing for a more uniform representation of linguistic knowledge and for the use of probabilistically-enriched grammars and interpreters as models of human knowledge of and processing of language."
            },
            "slug": "A-Probabilistic-Model-of-Lexical-and-Syntactic-and-Jurafsky",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Model of Lexical and Syntactic Access and Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A single probabilistic algorithm is presented, based on a parallel parser which ranks constructions for access, and interpretations for disambiguation, by their conditional probability, arguing for a more uniform representation of linguistic knowledge and for the use of probabilistically-enriched grammars and interpreters as models of human knowledge of and processing of language."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50582151"
                        ],
                        "name": "S. Dennis",
                        "slug": "S.-Dennis",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Dennis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dennis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 144
                            }
                        ],
                        "text": "A similar assumption is made by LSA, but this is not true of all methods for automatically extracting semantic representations from text (e.g., Dennis, 2004; Jones & Mewhort, 2007; Lund & Burgess, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 208
                            }
                        ],
                        "text": "Generative models can be used to overcome a major weakness of most statistical models of language: that they tend to model either syntax or semantics (although recent work provides some exceptions, including Dennis, 2004, and Jones & Mewhort, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1406330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d821880a991edba5549aa1eb0d7eea30824e0546",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments in question-answering systems have demonstrated that approaches based on propositional analysis of source text, in conjunction with formal inference systems, can produce substantive improvements in performance over surface-form approaches. [Voorhees, E. M. (2002) in Eleventh Text Retrieval Conference, eds. Voorhees, E. M. & Buckland, L. P., http://trec.nist.gov/pubs/trec11/t11_proceedings.html]. However, such systems are hampered by the need to create broad-coverage knowledge bases by hand, making them difficult to adapt to new domains and potentially fragile if critical information is omitted. To demonstrate how this problem might be addressed, the Syntagmatic Paradigmatic model, a memory-based account of sentence processing, is used to autonomously extract propositional knowledge from unannotated text. The Syntagmatic Paradigmatic model assumes that people store a large number of sentence instances. When trying to interpret a new sentence, similar sentences are retrieved from memory and aligned with the new sentence by using String Edit Theory. The set of alignments can be considered an extensional interpretation of the sentence. Extracting propositional information in this way not only permits the model to answer questions for which the relevant facts are explicitly stated in the text but also allows the model to take advantage of \u201cinference by coincidence,\u201d where implicit inference occurs as an emergent property of the mechanism. To illustrate the potential of this approach, the model is tested for its ability to determine the winners of tennis matches as reported on the Association of Tennis Professionals web site."
            },
            "slug": "An-unsupervised-method-for-the-extraction-of-from-Dennis",
            "title": {
                "fragments": [],
                "text": "An unsupervised method for the extraction of propositional information from text"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The Syntagmatic Paradigmatic model, a memory-based account of sentence processing, is used to autonomously extract propositional knowledge from unannotated text and allows the model to take advantage of \u201cinference by coincidence,\u201d where implicit inference occurs as an emergent property of the mechanism."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2546518"
                        ],
                        "name": "D. Plaut",
                        "slug": "D.-Plaut",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Plaut",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Plaut"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 106
                            }
                        ],
                        "text": "This is the strategy taken in many connectionist models of semantic representation (e.g., Kawamoto, 1993; Plaut, 1997; Rodd et al., 2004), in which different points in space are used to represent different meanings or senses of words."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 228
                            }
                        ],
                        "text": "First, connectionist models using distributed representations for words\u2014which are commonly interpreted as a form of spatial representation\u2014have been used to predict behavior on a variety of linguistic tasks (e.g., Kawamoto, 1993; Plaut, 1997; Rodd, Gaskell, & Marslen-Wilson, 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14769856,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3539d2becfefffdb6fa28f4e216c78b94e662d32",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 181,
            "paperAbstract": {
                "fragments": [],
                "text": "The traditional view of the lexical system stipulates word-specific representations and separate pathways for regular and exception words. An alternative approach views lexical knowledge as developing from general learning principles applied to mappings among distributed representations of written and spoken words and their meanings. On this distributed account, distinctions among words, and between words and nonwords, are not reified in the structure of the system but reflect the sensitivity of learning to the relative systematicity in the various mappings. Two computational simulations address findings that have seemed problematic for the distributed approach. Both involve a consideration of the role of semantics in normal and impaired lexical processing. The first simulation accounts for patients with impaired comprehension but intact reading in terms of individual differences in the division of labour between the semantic and phonological pathways. The second simulation demonstrates that a distributed..."
            },
            "slug": "Structure-and-Function-in-the-Lexical-System:-from-Plaut",
            "title": {
                "fragments": [],
                "text": "Structure and Function in the Lexical System: Insights from Distributed Models of Word Reading and Lexical Decision"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Two computational simulations address findings that have seemed problematic for the distributed approach to lexical knowledge and involve a consideration of the role of semantics in normal and impaired lexical processing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2819558"
                        ],
                        "name": "Ulrike Baldewein",
                        "slug": "Ulrike-Baldewein",
                        "structuredName": {
                            "firstName": "Ulrike",
                            "lastName": "Baldewein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ulrike Baldewein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143694777"
                        ],
                        "name": "Frank Keller",
                        "slug": "Frank-Keller",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Keller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Keller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 173
                            }
                        ],
                        "text": "\u2026models have recently become popular in both computational linguistics (e.g., Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999) and psycholinguistics (e.g., Baldewein & Keller, 2004; Jurafsky, 1996), although this work has tended to emphasize syntactic structure over semantics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9751081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9184d7398698f33c0ab5a7254bbb45a2d1e0ecb1",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an incremental, two-stage probabilistic model of human parsing for German. The model is broad coverage, i.e., it assigns sentence structure to previously unseen text with high accuracy. It also makes incremental predictions of the attachment decisions for PP attachment ambiguities. We test the model against reading time data from the literature and find that it makes correct predictions for verb second sentences; however, the model is not able to account for reading times data for verb final structures because attachment preferences in our training data do not match those determined experimentally. We argue that this points to more general limitations with our type of probabilistic model when it comes to realizing processing strategies that are independent of the data the parsing model is trained on."
            },
            "slug": "Modeling-Attachment-Decisions-with-a-Probabilistic-Baldewein-Keller",
            "title": {
                "fragments": [],
                "text": "Modeling Attachment Decisions with a Probabilistic Parser: The Case of Head Final Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "An incremental, two-stage probabilistic model of human parsing for German that makes incremental predictions of the attachment decisions for PP attachment ambiguities and makes correct predictions for verb second sentences is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 187
                            }
                        ],
                        "text": "Most computational approaches to natural language have tended to focus exclusively on either structured representations (e.g., Chomsky, 1965; Pinker, 1999) or sta-\ntistical learning (e.g., Elman, 1990; Plunkett & Marchman, 1993; Rumelhart & McClelland, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 213
                            }
                        ],
                        "text": "Our claim that models that can accurately predict which words are likely to arise in a given context can provide clues about human language processing is shared with the spirit of many connectionist models (e.g., Elman, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2763403,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "668087f0ae7ce1de6e0bd0965dbb480c08103260",
            "isKey": false,
            "numCitedBy": 9863,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction."
            },
            "slug": "Finding-Structure-in-Time-Elman",
            "title": {
                "fragments": [],
                "text": "Finding Structure in Time"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory and suggests a method for representing lexical categories and the type/token distinction is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31533192"
                        ],
                        "name": "A. Collins",
                        "slug": "A.-Collins",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Collins",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8661976"
                        ],
                        "name": "E. Loftus",
                        "slug": "E.-Loftus",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Loftus",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Loftus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 234
                            }
                        ],
                        "text": "Compared with approaches that focus on deeper conceptual relations, classic models of semantic association tend to invoke much simpler semantic representations, such as semantic spaces or holistic spreading activation networks (e.g., Collins & Loftus, 1975; Deese, 1959)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 109
                            }
                        ],
                        "text": "In previous work, the extraction and use of gist has been modeled using associative semantic networks (e.g., Collins & Loftus, 1975) and semantic spaces (e.g., Landauer & Dumais, 1997; Lund & Burgess, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 182
                            }
                        ],
                        "text": "In an associative semantic network, such as that shown in Figure 1a, a set of words or concepts is represented as nodes connected by edges that indicate pairwise associations (e.g., Collins & Loftus, 1975)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14217893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61374d14a581b03af7e4fe0342a722ea94911490",
            "isKey": false,
            "numCitedBy": 7409,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a spreading-acti vation theory of human semantic processing, which can be applied to a wide range of recent experimental results. The theory is based on Quillian's theory of semantic memory search and semantic preparation, or priming. In conjunction with this, several of the miscondeptions concerning Qullian's theory are discussed. A number of additional assumptions are proposed for his theory in order to apply it to recent experiments. The present paper shows how the extended theory can account for results of several production experiments by Loftus, Juola and Atkinson's multiple-category experiment, Conrad's sentence-verification experiments, and several categorization experiments on the effect of semantic relatedness and typicality by Holyoak and Glass, Rips, Shoben, and Smith, and Rosch. The paper also provides a critique of the Smith, Shoben, and Rips model for categorization judgments. Some years ago, Quillian1 (1962, 1967) proposed a spreading-acti vation theory of human semantic processing that he tried to implement in computer simulations of memory search (Quillian, 1966) and comprehension (Quillian, 1969). The theory viewed memory search as activation spreading from two or more concept nodes in a semantic network until an intersection was found. The effects of preparation (or priming) in semantic memory were also explained in terms of spreading activation from the node of the primed concept. Rather than a theory to explain data, it was a theory designed to show how to build human semantic structure and processing into a computer."
            },
            "slug": "A-spreading-activation-theory-of-semantic-Collins-Loftus",
            "title": {
                "fragments": [],
                "text": "A spreading-activation theory of semantic processing"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The present paper shows how the extended theory can account for results of several production experiments by Loftus, Juola and Atkinson's multiple-category experiment, Conrad's sentence-verification experiments, and several categorization experiments on the effect of semantic relatedness and typicality by Holyoak and Glass, Rips, Shoben, and Smith, and Rosch."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47927070"
                        ],
                        "name": "A. H. Kawamoto",
                        "slug": "A.-H.-Kawamoto",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Kawamoto",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. H. Kawamoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143910582,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "39dd78a689ba7bf2550bccc63eedea4cc7522bef",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A connectionist account of lexical ambiguity resolution is presented in which the nonlinear dynamics that arise during processing is emphasized. In the implementation, the spelling, pronunciation, part of speech, and meaning of both ambiguous and unambiguous words are represented as a distributed pattern of activity over a set of simple processing units in a fully recurrent network. After the network is trained on this lexicon using an error-correction algorithm, the performance of the network is assessed by presenting just part of a lexical entry (e.g., the spelling). The number of processing cycles to activate all the units representing the spelling, the pronunciation, or the meaning to their minimal or maximal activation are used as indices of lexical decision times, naming times, or reading times. respectively. Consistent with empirical results, the simulations demonstrate the effect of frequency and context on the processing of unambiguous words, as well as the effect of relative dominance and context on the time course of the activation of meanings of ambiguous words. Advantages of a distributed representation are also discussed."
            },
            "slug": "Nonlinear-dynamics-in-the-resolution-of-lexical-A-Kawamoto",
            "title": {
                "fragments": [],
                "text": "Nonlinear dynamics in the resolution of lexical ambiguity: A parallel distributed processing account."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5958691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d87ceda3042f781c341ac17109d1e94a717f5f60",
            "isKey": false,
            "numCitedBy": 13578,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet."
            },
            "slug": "WordNet-:-an-electronic-lexical-database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "WordNet : an electronic lexical database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The lexical database: nouns in WordNet, Katherine J. Miller a semantic network of English verbs, and applications of WordNet: building semantic concordances are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 123
                            }
                        ],
                        "text": "Many of the models used in computational linguistics, such as hidden Markov models and probabilistic context-free grammars (Charniak, 1993; Jurafsky & Martin, 2000; Manning & Sch\u00fctze, 1999), generate words purely on the basis of sequential dependencies among unobserved syntactic classes, not modeling the variation in content that occurs across documents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2019,
                                "start": 2
                            }
                        ],
                        "text": ", Charniak, 1993; Jurafsky & Martin, 2000; Manning & Sch\u00fctze, 1999) and psycholinguistics (e.g., Baldewein & Keller, 2004; Jurafsky, 1996), although this work has tended to emphasize syntactic structure over semantics. The combination of structured representations with statistical inference makes generative models the perfect tool for evaluating novel approaches to semantic representation. We use our formal framework to explore the idea that the gist of a set of words can be represented as a probability distribution over a set of topics. Each topic is a probability distribution over words, and the content of the topic is reflected in the words to which it assigns high probability. For example, high probabilities for woods and stream would suggest that a topic refers to the countryside, whereas high probabilities for federal and reserve would suggest that a topic refers to finance. A schematic illustration of this form of representation appears in Figure 1c. Following work in the information retrieval literature (Blei, Ng, & Jordan, 2003), we use a simple generative model that defines a probability distribution over a set of words, such as a list or a document, given a probability distribution over topics. With methods drawn from Bayesian statistics, a set of topics can be learned automatically from a collection of documents, as a computational analogue of how human learners might form semantic representations through their linguistic experience (Griffiths & Steyvers, 2002, 2003, 2004). The topic model provides a starting point for an investigation of new forms of semantic representation. Representing words using topics has an intuitive correspondence to feature-based models of similarity. Words that receive high probability under the same topics will tend to be highly predictive of one another, just as stimuli that share many features will be highly similar. We show that this intuitive correspondence is supported by a formal correspondence between the topic model and Tversky\u2019s (1977) featurebased approach to modeling similarity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 165
                            }
                        ],
                        "text": "The syntactic dependencies are introduced via a hidden Markov model, a popular probabilistic model for language that is essentially a probabilistic regular grammar (Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 164
                            }
                        ],
                        "text": "The syntactic dependencies are introduced via a hidden Markov model, a popular probabilistic model for language that is essentially a probabilistic regular grammar (Charniak, 1993; Jurafsky & Martin, 2000; Manning & Sch\u00fctze, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 101
                            }
                        ],
                        "text": "Most generative models that have been applied to language focus on latent syntactic structure (e.g., Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 106
                            }
                        ],
                        "text": "As a consequence, generative models have recently become popular in both computational linguistics (e.g., Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999) and psycholinguistics (e.g., Baldewein & Keller, 2004; Jurafsky, 1996), although this work has tended to emphasize syntactic\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 124
                            }
                        ],
                        "text": "Many of the models used in computational linguistics, such as hidden Markov models and probabilistic context-free grammars (Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999), generate words purely on the basis of sequential dependencies among unobserved syntactic classes, not\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5371566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b84276fe751ca4f1389549281383b151a746107b",
            "isKey": true,
            "numCitedBy": 1140,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nEugene Charniak breaks new ground in artificial intelligence research by presenting statistical language processing from an artificial intelligence point of view in a text for researchers and scientists with a traditional computer science background. \nNew, exacting empirical methods are needed to break the deadlock in such areas of artificial intelligence as robotics, knowledge representation, machine learning, machine translation, and natural language processing (NLP). It is time, Charniak observes, to switch paradigms. This text introduces statistical language processing techniques -- word tagging, parsing with probabilistic context free grammars, grammar induction, syntactic disambiguation, semantic word classes, word-sense disambiguation -- along with the underlying mathematics and chapter exercises. \nCharniak points out that as a method of attacking NLP problems, the statistical approach has several advantages. It is grounded in real text and therefore promises to produce usable results, and it offers an obvious way to approach learning: \"one simply gathers statistics.\" \nLanguage, Speech, and Communication"
            },
            "slug": "Statistical-language-learning-Charniak",
            "title": {
                "fragments": [],
                "text": "Statistical language learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Eugene Charniak points out that as a method of attacking NLP problems, the statistical approach has several advantages and is grounded in real text and therefore promises to produce usable results, and it offers an obvious way to approach learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804885"
                        ],
                        "name": "M. Steyvers",
                        "slug": "M.-Steyvers",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steyvers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steyvers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50860274"
                        ],
                        "name": "Padhraic Smyth",
                        "slug": "Padhraic-Smyth",
                        "structuredName": {
                            "firstName": "Padhraic",
                            "lastName": "Smyth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Padhraic Smyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398315116"
                        ],
                        "name": "M. Rosen-Zvi",
                        "slug": "M.-Rosen-Zvi",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Rosen-Zvi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosen-Zvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 0
                            }
                        ],
                        "text": "Steyvers and Tenenbaum (2005) conducted similar analyses using Roget\u2019s (1911) thesaurus and WordNet (Miller & Fellbaum, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1940239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcb426cd5f9ca9a0d58e852fb8757202bfc36d37",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new unsupervised learning technique for extracting information from large text collections. We model documents as if they were generated by a two-stage stochastic process. Each author is represented by a probability distribution over topics, and each topic is represented as a probability distribution over words for that topic. The words in a multi-author paper are assumed to be the result of a mixture of each authors' topic mixture. The topic-word and author-topic distributions are learned from data in an unsupervised manner using a Markov chain Monte Carlo algorithm. We apply the methodology to a large corpus of 160,000 abstracts and 85,000 authors from the well-known CiteSeer digital library, and learn a model with 300 topics. We discuss in detail the interpretation of the results discovered by the system including specific topic and author models, ranking of authors by topic and topics by author, significant trends in the computer science literature between 1990 and 2002, parsing of abstracts by topics and authors and detection of unusual papers by specific authors. An online query interface to the model is also discussed that allows interactive exploration of author-topic models for corpora such as CiteSeer."
            },
            "slug": "Probabilistic-author-topic-models-for-information-Steyvers-Smyth",
            "title": {
                "fragments": [],
                "text": "Probabilistic author-topic models for information discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The methodology is applied to a large corpus of 160,000 abstracts and 85,000 authors from the well-known CiteSeer digital library, and a model with 300 topics is learned using a Markov chain Monte Carlo algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153592298"
                        ],
                        "name": "S. McDonald",
                        "slug": "S.-McDonald",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "McDonald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. McDonald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2662086"
                        ],
                        "name": "R. Shillcock",
                        "slug": "R.-Shillcock",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Shillcock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shillcock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 243
                            }
                        ],
                        "text": "\u2026memory has suggested that the number of contexts in which words appear might explain why some words are more likely than others to be confused for items appearing on the study list in recognition memory experiments (Dennis & Humphreys, 2001; McDonald & Shillcock, 2001; Steyvers & Malmberg, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2548744,
            "fieldsOfStudy": [
                "Psychology",
                "Linguistics"
            ],
            "id": "7e687a99b10e0190322999e307fe9d638fb51a08",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Attempts to quantify lexical variation have produced a large number of theoretical and empirical constructs, such as Word Frequency, Concreteness, and Ambiguity, which have been claimed to predict between-word differences in lexical processing behavior. Models of word recognition that have been developed to account for the effects of these variables have typically lacked adequate semantic representations, and have dealt with words as if they exist in isolation from their environment. We present a new dimension of lexical variation that is addressed to this concern. Contextual Distinctiveness(CD), a corpus-derived summary measure of the frequency distribution of the contexts in which a word occurs, is naturally compatible with contextual theories of semantic representation and meaning. Experiment 1 demonstrates that CD is a significantly better predictor of lexical decision latencies than occurrence frequency, suggesting that CD is the more psychologically relevant variable. We additionally explore the relationship between CD and six subjectively-defined measures: Concreteness, Context Availability, Number of Contexts, Ambiguity, Age of Acquisition and Familiarity and find CD to be reliably related to Ambiguity only. We argue for the priority of immediate context in determining the representation and processing of language."
            },
            "slug": "Rethinking-the-Word-Frequency-Effect:-The-Neglected-McDonald-Shillcock",
            "title": {
                "fragments": [],
                "text": "Rethinking the Word Frequency Effect: The Neglected Role of Distributional Information in Lexical Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Contextual Distinctiveness (CD), a corpus-derived summary measure of the frequency distribution of the contexts in which a word occurs, is naturally compatible with contextual theories of semantic representation and meaning and is argued for the priority of immediate context in determining the representation and processing of language."
            },
            "venue": {
                "fragments": [],
                "text": "Language and speech"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 206
                            }
                        ],
                        "text": "The syntactic dependencies are introduced via a hidden Markov model, a popular probabilistic model for language that is essentially a probabilistic regular grammar (Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 152
                            }
                        ],
                        "text": "We now take a step back from these specific proposals and consider the abstract computational problem that they are intended to solve, in the spirit of Marr\u2019s (1982) notion of the computational level and Anderson\u2019s (1990) rational analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 147
                            }
                        ],
                        "text": "\u2026used in computational linguistics, such as hidden Markov models and probabilistic context-free grammars (Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999), generate words purely on the basis of sequential dependencies among unobserved syntactic classes, not modeling the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 142
                            }
                        ],
                        "text": "Most generative models that have been applied to language focus on latent syntactic structure (e.g., Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 147
                            }
                        ],
                        "text": "As a consequence, generative models have recently become popular in both computational linguistics (e.g., Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999) and psycholinguistics (e.g., Baldewein & Keller, 2004; Jurafsky, 1996), although this work has tended to emphasize syntactic\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52800448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "084c55d6432265785e3ff86a2e900a49d501c00a",
            "isKey": true,
            "numCitedBy": 7803,
            "numCiting": 294,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications."
            },
            "slug": "Foundations-of-statistical-natural-language-Manning-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Foundations of statistical natural language processing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear and provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804885"
                        ],
                        "name": "M. Steyvers",
                        "slug": "M.-Steyvers",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steyvers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steyvers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14588679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca95bf87cf9f898390ef847d71949a99e2e5038e",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore the consequences of viewing semantic association as the result of attempting to predict the concepts likely to arise in a particular context. We argue that the success of existing accounts of semantic representation comes as a result of indirectly addressing this problem, and show that a closer correspondence to human data can be obtained by taking a probabilistic approach that explicitly models the generative structure of language."
            },
            "slug": "Prediction-and-Semantic-Association-Griffiths-Steyvers",
            "title": {
                "fragments": [],
                "text": "Prediction and Semantic Association"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is argued that the success of existing accounts of semantic representation comes as a result of indirectly addressing this problem, and that a closer correspondence to human data can be obtained by taking a probabilistic approach that explicitly models the generative structure of language."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2738421"
                        ],
                        "name": "B. Bigi",
                        "slug": "B.-Bigi",
                        "structuredName": {
                            "firstName": "Brigitte",
                            "lastName": "Bigi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bigi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8899009"
                        ],
                        "name": "R. de Mori",
                        "slug": "R.-de-Mori",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "de Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. de Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388702976"
                        ],
                        "name": "M. El-B\u00e8ze",
                        "slug": "M.-El-B\u00e8ze",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "El-B\u00e8ze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. El-B\u00e8ze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071427597"
                        ],
                        "name": "T. Spriet",
                        "slug": "T.-Spriet",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Spriet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Spriet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16633428,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8ec475634217696aa403526fab0287768200262",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A new statistical method for language modeling and spoken document classification is proposed. It is based on a mixture of topic dependent probabilities. Each topic dependent probability is in turn a mixture of n-gram probabilities and the probability of Kullback-Lieber (KL) distances between keyword unigrams and distribution obtained from the content of a cache memory. Experimental result on topic classification using a corpus of 60 Mword from the French newspaper Le Monde show the excellent performance of the cache memory and its complementary role in providing different statistics for the decision process."
            },
            "slug": "Combined-models-for-topic-spotting-and-language-Bigi-Mori",
            "title": {
                "fragments": [],
                "text": "Combined models for topic spotting and topic-dependent language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental result on topic classification using a corpus of 60 Mword from the French newspaper Le Monde show the excellent performance of the cache memory and its complementary role in providing different statistics for the decision process."
            },
            "venue": {
                "fragments": [],
                "text": "1997 IEEE Workshop on Automatic Speech Recognition and Understanding Proceedings"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2653356"
                        ],
                        "name": "R. E. Till",
                        "slug": "R.-E.-Till",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Till",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. E. Till"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3831099"
                        ],
                        "name": "E. F. Mross",
                        "slug": "E.-F.-Mross",
                        "structuredName": {
                            "firstName": "Ernest",
                            "lastName": "Mross",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. F. Mross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 29
                            }
                        ],
                        "text": "The basic result reported by Till et al. (1988) was that both of the meanings of the ambiguous word and neither of the inference targets were primed when there was a short delay between sentence presentation and lexical decision, and that there was a subsequent shift to favor the appropriate\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "Of the 28 pairs of sentences used by Till et al. (1988), there were 20 for which the ambiguous primes and all four target words appeared in our vocabulary."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Till et al. (1988) examined the time course of the processing of word meanings using a priming study in which participants read sentences containing ambiguous words and then performed a lexical decision task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42653521,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c7e8f3b6f78a770b3e2e51d58421b311452ab2fe",
            "isKey": true,
            "numCitedBy": 225,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The construction of word meanings in a discourse context was conceptualized as a process of sense activation, sense selection, and sense elaboration. In three experiments, subjects read texts presented by a rapid serial visual procedure and performed a lexical decision on visually presented targets that followed ambiguous prime words. When the target was a word, it was either an associate of the prime word, a probable inference suggested by the discourse, or an unrelated word. For associates, lexical decisions that related to either the appropriate or the inappropriate sense of the ambiguous word were generally facilitated at short (200-400 msec) prime-target stimulus onset asynchronies (SOAs). At longer SOAs, responses were faster to appropriate than to inappropriate associates. For the thematic inferences, there was no difference between these (appropriate) inferences and (inappropriate) control words at short SOAs. At long SOAs (1,000 and 1,500 msec), however, inference words were facilitated. The results are interpreted as consistent with a model of lexical processing in which sense activation functions independently of context. Discourse context effects, whether on sense selection (suppression of inappropriate associates) or on sense elaboration (creation of inferences), are seen as postlexical."
            },
            "slug": "Time-course-of-priming-for-associate-and-inference-Till-Mross",
            "title": {
                "fragments": [],
                "text": "Time course of priming for associate and inference words in a discourse context"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The construction of word meanings in a discourse context was conceptualized as a process of sense activation, sense selection, and sense elaboration and the results are interpreted as consistent with a model of lexical processing in which sense activation functions independently of context."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50582151"
                        ],
                        "name": "S. Dennis",
                        "slug": "S.-Dennis",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Dennis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dennis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2232163"
                        ],
                        "name": "M. Humphreys",
                        "slug": "M.-Humphreys",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Humphreys",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Humphreys"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 180
                            }
                        ],
                        "text": "The explanation for this effect is that when a word is encountered in a larger number of contexts, the study list context becomes less discriminable from these previous exposures (Dennis & Humphreys, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 217
                            }
                        ],
                        "text": "\u2026memory has suggested that the number of contexts in which words appear might explain why some words are more likely than others to be confused for items appearing on the study list in recognition memory experiments (Dennis & Humphreys, 2001; McDonald & Shillcock, 2001; Steyvers & Malmberg, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8480013,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6d1be78e133a06c884ca978434aba043d7014ac5",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "Item noise models of recognition assert that interference at retrieval is generated by the words from the study list. Context noise models of recognition assert that interference at retrieval is generated by the contexts in which the test word has appeared. The authors introduce the bind cue decide model of episodic memory, a Bayesian context noise model, and demonstrate how it can account for data from the item noise and dual-processing approaches to recognition memory. From the item noise perspective, list strength and list length effects, the mirror effect for word frequency and concreteness, and the effects of the similarity of other words in a list are considered. From the dual-processing perspective, process dissociation data on the effects of length, temporal separation of lists, strength, and diagnosticity of context are examined. The authors conclude that the context noise approach to recognition is a viable alternative to existing approaches."
            },
            "slug": "A-context-noise-model-of-episodic-word-recognition.-Dennis-Humphreys",
            "title": {
                "fragments": [],
                "text": "A context noise model of episodic word recognition."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The authors introduce the bind cue decide model of episodic memory, a Bayesian context noise model, and demonstrate how it can account for data from the item noise and dual-processing approaches to recognition memory."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49901168"
                        ],
                        "name": "G. Mandler",
                        "slug": "G.-Mandler",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Mandler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mandler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 245
                            }
                        ],
                        "text": "These models distinguish between different routes to retrieve information from memory: a verbatim memory route, based on the physical occurrence of an input, and a gist memory route, based on semantic content (e.g., Brainerd et al., 1999, 2002; Mandler, 1980)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 274
                            }
                        ],
                        "text": "The gist-based retrieval process would have to be complemented with a verbatim retrieval process in order to account for the relatively high retrieval probability for words on the study list, as assumed in the dual-route models mentioned above (Brainerd et al., 1999, 2002; Mandler, 1980)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 249
                            }
                        ],
                        "text": "Results of this kind have led to the development of dual-route memory models, which suggest that people encode not just the verbatim content of a list of words but also their gist (Brainerd, Reyna, & Mojardin, 1999; Brainerd, Wright, & Reyna, 2002; Mandler, 1980)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2166238,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "07d55f7d861faec460c077a75aa212d61640e96d",
            "isKey": false,
            "numCitedBy": 2600,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "Several suggestions for a class of theories of recognition memory have been proposed during the past decade. These models address predictions about judgments of prior occurrence of an event, not the identification of what it is, The history and current status of one of these models is discussed. The model postulates the detection of familiarity and the utilization of retrieval mechanisms as additive and separate processes. The phenomenal experience of familiarity is assigned to intraevent organizational integrative processes; retrieval depends on interevent elaborative processes. Other current theoretical options are described, and relevant supportive data from the literature are reviewed. New tests of the model involving both free recall and word pair paradigms are presented. The dual process model is extended to the word frequency effect and to the recognition difficulties of amnesic patients. In general English usage the verb to recognize usually is denned as the act of perceiving something as previously known. It is an apparently clear as well as etymologically correct usage, that is, to know again. In this article the process of recognizing will be analyzed, but it will be restricted to the recognition of the prior occurrence of an event. This restriction follows psychological rather than common usage. Experimentation that addresses problems of recognition has typically required subjects to make judg. nents about prior encounters with some tar"
            },
            "slug": "Recognizing:-The-judgment-of-previous-occurrence.-Mandler",
            "title": {
                "fragments": [],
                "text": "Recognizing: The judgment of previous occurrence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804885"
                        ],
                        "name": "M. Steyvers",
                        "slug": "M.-Steyvers",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steyvers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steyvers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "Steyvers and Tenenbaum (2005) conducted similar analyses using Roget\u2019s Thesaurus (Roget, 1911) and the WordNet lexical database (Miller & Fellbaum, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "Steyvers and Tenenbaum (2005) found that the clustering coefficient of semantic networks is far greater than that of a random graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 3
                            }
                        ],
                        "text": "As Steyvers and Tenenbaum (2005) pointed out, this kind of phenomenon is difficult to reproduce in a spatial representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "Steyvers and Tenenbaum (2005) analyzed the large-scale properties of both directed and undirected\nsemantic networks formed from the word-association norms of Nelson, McEvoy, and Schreiber (1998), finding that they have some statistical properties that distinguish them from classical random graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 0
                            }
                        ],
                        "text": "Steyvers and Tenenbaum (2005) found that semantic networks constructed from word-association data have power-law degree distributions. We reproduced their analyses for our subset of Nelson, McEvoy, and Schreiber\u2019s (1998) norms, computing the degree of each word for both directed and undirected graphs constructed from the norms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 0
                            }
                        ],
                        "text": "Steyvers and Tenenbaum (2005) analyzed the large-scale properties of both directed and undirected semantic networks formed from the word-association norms of Nelson, McEvoy, and Schreiber (1998), finding that they have some statistical properties that distinguish them from classical random graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "Steyvers and Tenenbaum (2005) found that semantic networks constructed from word-association data have power-law degree distributions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6000627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "498a304a452fa4c3fb7ab91da7485bf0a405feac",
            "isKey": false,
            "numCitedBy": 1171,
            "numCiting": 128,
            "paperAbstract": {
                "fragments": [],
                "text": "We present statistical analyses of the large-scale structure of 3 types of semantic networks: word associations, WordNet, and Roget's Thesaurus. We show that they have a small-world structure, characterized by sparse connectivity, short average path lengths between words, and strong local clustering. In addition, the distributions of the number of connections follow power laws that indicate a scale-free pattern of connectivity, with most nodes having relatively few connections joined together through a small number of hubs with many connections. These regularities have also been found in certain other complex natural networks, such as the World Wide Web, but they are not consistent with many conventional models of semantic organization, based on inheritance hierarchies, arbitrarily structured networks, or high-dimensional vector spaces. We propose that these structures reflect the mechanisms by which semantic networks grow. We describe a simple model for semantic growth, in which each new word or concept is connected to an existing network by differentiating the connectivity pattern of an existing node. This model generates appropriate small-world statistics and power-law connectivity distributions, and it also suggests one possible mechanistic basis for the effects of learning history variables (age of acquisition, usage frequency) on behavioral performance in semantic processing tasks."
            },
            "slug": "The-Large-Scale-Structure-of-Semantic-Networks:-and-Steyvers-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "The Large-Scale Structure of Semantic Networks: Statistical Analyses and a Model of Semantic Growth"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple model for semantic growth is described, in which each new word or concept is connected to an existing network by differentiating the connectivity pattern of an existing node, which generates appropriate small-world statistics and power-law connectivity distributions."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39952106"
                        ],
                        "name": "Michael B. W. Wolfe",
                        "slug": "Michael-B.-W.-Wolfe",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wolfe",
                            "middleNames": [
                                "B.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael B. W. Wolfe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144029655"
                        ],
                        "name": "M. E. Schreiner",
                        "slug": "M.-E.-Schreiner",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Schreiner",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. E. Schreiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2197285"
                        ],
                        "name": "B. Rehder",
                        "slug": "B.-Rehder",
                        "structuredName": {
                            "firstName": "Bob",
                            "lastName": "Rehder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rehder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2444937"
                        ],
                        "name": "Darrell Laham",
                        "slug": "Darrell-Laham",
                        "structuredName": {
                            "firstName": "Darrell",
                            "lastName": "Laham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Darrell Laham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2036336"
                        ],
                        "name": "P. Foltz",
                        "slug": "P.-Foltz",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Foltz",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Foltz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 196
                            }
                        ],
                        "text": "Applications of LSA often evaluate the similarity between two documents by computing the cosine between the average word vectors for those documents (Landauer & Dumais, 1997; Rehder et al., 1998; Wolfe et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62526953,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0cb6eb8776d372f76be62c95252162086b46eff",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This study examines the hypothesis that the ability of a reader to learn from text depends on the match between the background knowledge of the reader and the difficulty of the text information. Latent Semantic Analysis (LSA), a statistical technique that represents the content of a document as a vector in high\u2010dimensional semantic space based on a large text corpus, is used to predict how much readers will learn from texts based on the estimated conceptual match between their topic knowledge and the text information. Participants completed tests to assess their knowledge of the human heart and circulatory system, then read one of four texts that ranged in difficulty from elementary to medical school level, then completed the tests again. Results show a nonmonotonic relation in which learning was greatest for texts that were neither too easy nor too difficult. LSA proved as effective at predicting learning from these texts as traditional knowledge assessment measures. For these texts, optimal assignment o..."
            },
            "slug": "Learning-from-text:-Matching-readers-and-texts-by-Wolfe-Schreiner",
            "title": {
                "fragments": [],
                "text": "Learning from text: Matching readers and texts by latent semantic analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Results show a nonmonotonic relation in which learning was greatest for texts that were neither too easy nor too difficult, and LSA proved as effective at predicting learning from these texts as traditional knowledge assessment measures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804885"
                        ],
                        "name": "M. Steyvers",
                        "slug": "M.-Steyvers",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steyvers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steyvers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 141
                            }
                        ],
                        "text": "The user of the algorithm can specify and , which are hyperparameters that affect the granularity of the topics discovered by the model (see Griffiths & Steyvers, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 245
                            }
                        ],
                        "text": "With methods drawn from Bayesian statistics, a set of topics can be learned automatically from a collection of documents, as a computational analogue of how human learners might form semantic representations through their linguistic experience (Griffiths & Steyvers, 2002, 2003, 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 49
                            }
                        ],
                        "text": "Further details of the algorithm are provided in Griffiths and Steyvers (2004), where we show how it can be used to analyze the content of document collections."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 154
                            }
                        ],
                        "text": "An algorithm for extracting a set of topics is described in Appendix A, and a more detailed description and application of this algorithm can be found in Griffiths and Steyvers (2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 225
                            }
                        ],
                        "text": "\u20261999), variational expectation maximization (Blei et al., 2003; Buntine, 2002), ex-\npectation propagation (Minka & Lafferty, 2002), and several forms of Markov chain Monte Carlo (MCMC; Buntine & Jakulin, 2004; Erosheva, 2002; Griffiths & Steyvers, 2002, 2003, 2004; Pritchard et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15671300,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e99f196cf21e0781ef1e119d14e6db45cd71bf3b",
            "isKey": false,
            "numCitedBy": 5574,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A first step in identifying the content of a document is determining which topics that document addresses. We describe a generative model for documents, introduced by Blei, Ng, and Jordan [Blei, D. M., Ng, A. Y. & Jordan, M. I. (2003) J. Machine Learn. Res. 3, 993-1022], in which each document is generated by choosing a distribution over topics and then choosing each word in the document from a topic selected according to this distribution. We then present a Markov chain Monte Carlo algorithm for inference in this model. We use this algorithm to analyze abstracts from PNAS by using Bayesian model selection to establish the number of topics. We show that the extracted topics capture meaningful structure in the data, consistent with the class designations provided by the authors of the articles, and outline further applications of this analysis, including identifying \u201chot topics\u201d by examining temporal dynamics and tagging abstracts to illustrate semantic content."
            },
            "slug": "Finding-scientific-topics-Griffiths-Steyvers",
            "title": {
                "fragments": [],
                "text": "Finding scientific topics"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A generative model for documents is described, introduced by Blei, Ng, and Jordan, and a Markov chain Monte Carlo algorithm is presented for inference in this model, which is used to analyze abstracts from PNAS by using Bayesian model selection to establish the number of topics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2797476"
                        ],
                        "name": "M. Redington",
                        "slug": "M.-Redington",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Redington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Redington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803359"
                        ],
                        "name": "N. Chater",
                        "slug": "N.-Chater",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Chater",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Chater"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145204549"
                        ],
                        "name": "S. Finch",
                        "slug": "S.-Finch",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Finch",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Finch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 181
                            }
                        ],
                        "text": "The model performs about as well as a standard hidden Markov model\u2014which is a state-of-the-art method\u2014at identifying syntactic classes, and it outperforms distributional clustering (Redington et al., 1998) in this task (Griffiths et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 180
                            }
                        ],
                        "text": "The model performs about as well as a standard hidden Markov model\u2014which is a state-of-the-art method\u2014at identifying syntactic classes, and it outperforms distributional clustering (Redington et al., 1998) in this task (Griffiths et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2596605,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "fd63e4f9e2497daa2c6a3f6b08445c2ef69fa901",
            "isKey": false,
            "numCitedBy": 481,
            "numCiting": 131,
            "paperAbstract": {
                "fragments": [],
                "text": "Many theorists have dismissed a priori the idea that distributional information could play a significant role in syntactic category acquisition. We demonstrate empirically that such information provides a powerful cue to syntactic category membership, which can be exploited by a variety of simple, psychologically plausible mechanisms. We present a range of results using a large corpus of child-directed speech and explore their psychological implications. While our results show that a considerable amount of information concerning the syntactic categories can be obtained from distributional information alone, we stress that many other sources of information may also be potential contributors to the identification of syntactic classes."
            },
            "slug": "Distributional-Information:-A-Powerful-Cue-for-Redington-Chater",
            "title": {
                "fragments": [],
                "text": "Distributional Information: A Powerful Cue for Acquiring Syntactic Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "It is demonstrated empirically that distributional information provides a powerful cue to syntactic category membership, which can be exploited by a variety of simple, psychologically plausible mechanisms."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701656"
                        ],
                        "name": "James L. McClelland",
                        "slug": "James-L.-McClelland",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McClelland",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. McClelland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 227
                            }
                        ],
                        "text": "Most computational approaches to natural language have tended to focus exclusively on either structured representations (e.g., Chomsky, 1965; Pinker, 1999) or sta-\ntistical learning (e.g., Elman, 1990; Plunkett & Marchman, 1993; Rumelhart & McClelland, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 56499839,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "4fa569625b5ab35e955a8d5be11a4aa9f59ca424",
            "isKey": false,
            "numCitedBy": 1468,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This paper presents an alternative to the standard rule based account of a child's acquisition of the past tense in English. Children are typically said to pass through a three-phase acquisition process in which they first learn past tense by rote, then learn the past tense rule and over regularize, and then finally learn the exceptions to the rule. We show that the acquisition data can be accounted for in more detail by dispensing with the assumption that the child learns rules and substituting in its place a simple homogeneous learning procedure. We show how rule-like behavior can emerge from the interactions among a network of units encoding the root form to past tense mapping. A large computer simulation of the learning process demonstrates the operating principles of our alternative account, shows how details of the acquisition process not captured by the rule account emerge, and makes predictions about other details of the acquisition process not yet observed. Keywords: Learning; networks; Language; Verbs; Perceptions; Morphology."
            },
            "slug": "On-learning-the-past-tenses-of-English-verbs:-rules-Rumelhart-McClelland",
            "title": {
                "fragments": [],
                "text": "On learning the past-tenses of English verbs: implicit rules or parallel distributed processing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown how rule-like behavior can emerge from the interactions among a network of units encoding the root form to past tense mapping, and how details of the acquisition process not captured by the rule account emerge."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46973696"
                        ],
                        "name": "D. Nelson",
                        "slug": "D.-Nelson",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Nelson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2327242"
                        ],
                        "name": "C. McEvoy",
                        "slug": "C.-McEvoy",
                        "structuredName": {
                            "firstName": "Cathy",
                            "lastName": "McEvoy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. McEvoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2853950"
                        ],
                        "name": "T. A. Schreiber",
                        "slug": "T.-A.-Schreiber",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Schreiber",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. A. Schreiber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 21
                            }
                        ],
                        "text": "We used the norms of Nelson, McEvoy, and Schreiber (1998) to evaluate the performance of LSA and the topic model in predicting human word association."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 125
                            }
                        ],
                        "text": "We then examined how well solutions with\n500, 900, 1,300, and 1,700 topics predicted the word-association norms collected by Nelson, McEvoy, and Schreiber (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 158
                            }
                        ],
                        "text": "Steyvers and Tenenbaum (2005) analyzed the large-scale properties of both directed and undirected\nsemantic networks formed from the word-association norms of Nelson, McEvoy, and Schreiber (1998), finding that they have some statistical properties that distinguish them from classical random graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8890546,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "78466285abd953288db4a9832e4616e1249dba19",
            "isKey": false,
            "numCitedBy": 1983,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Preexisting word knowledge is accessed in many cognitive tasks, and this article offers a means for indexing this knowledge so that it can be manipulated or controlled. We offer free association data for 72,000 word pairs, along with over a million entries of related data, such as forward and backward strength, number of competing associates, and printed frequency. A separate file contains the 5,019 normed words, their statistics, and thousands of independently normed rhyme, stem, and fragment cues. Other files providen \u00d7 n associative networks for more than 4,000 words and a list of idiosyncratic responses for each normed word. The database will be useful for investigators interested in cuing, priming, recognition, network theory, linguistics, and implicit testing applications. They also will be useful for evaluating the predictive value of free association probabilities as compared with other measures, such as similarity ratings and co-occurrence norms. Of several procedures for measuring preexisting strength between two words, the best remains to be determined. The norms may be downloaded fromwww.psychonomic.org/archive/."
            },
            "slug": "The-University-of-South-Florida-free-association,-Nelson-McEvoy",
            "title": {
                "fragments": [],
                "text": "The University of South Florida free association, rhyme, and word fragment norms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The database will be useful for investigators interested in cuing, priming, recognition, network theory, linguistics, and implicit testing applications, and for evaluating the predictive value of free association probabilities as compared with other measures, such as similarity ratings and co-occurrence norms."
            },
            "venue": {
                "fragments": [],
                "text": "Behavior research methods, instruments, & computers : a journal of the Psychonomic Society, Inc"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38232647"
                        ],
                        "name": "R. Iyer",
                        "slug": "R.-Iyer",
                        "structuredName": {
                            "firstName": "Rukmini",
                            "lastName": "Iyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Iyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144339506"
                        ],
                        "name": "Mari Ostendorf",
                        "slug": "Mari-Ostendorf",
                        "structuredName": {
                            "firstName": "Mari",
                            "lastName": "Ostendorf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mari Ostendorf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 253
                            }
                        ],
                        "text": "\u2026in information retrieval and statistical natural language processing, with different models making different assumptions about the origins of the distribution over topics (e.g., Bigi, De Mori, El-Beze, & Spriet, 1997; Blei et al., 2003; Hofmann, 1999; Iyer & Ostendorf, 1999; Ueda & Saito, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 163
                            }
                        ],
                        "text": "The notion that a topic can be represented as a probability distribution over words appears in several places in the natural language processing literature (e.g., Iyer & Ostendorf, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16217683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bf29693c91924958f6a6427a1bcbe96b244aa66",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard statistical language models use n-grams to capture local dependencies, or use dynamic modeling techniques to track dependencies within an article. In this paper, we investigate a new statistical language model that captures topic-related dependencies of words within and across sentences. First, we develop a topic-dependent, sentence-level mixture language model which takes advantage of the topic constraints in a sentence or article. Second, we introduce topic-dependent dynamic adaptation techniques in the framework of the mixture model, using n-gram caches and content word unigram caches. Experiments with the static (or unadapted) mixture model on the North American Business (NAB) task show a 21% reduction in perplexity and a 3-4% improvement in recognition accuracy over a general n-gram model, giving a larger gain than that obtained with supervised dynamic cache modeling. Further experiments on the Switchboard corpus also showed a small improvement in performance with the sentence-level mixture model. Cache modeling techniques introduced in the mixture framework contributed a further 14% reduction in perplexity and a small improvement in recognition accuracy on the NAB task for both supervised and unsupervised adaptation."
            },
            "slug": "Modeling-long-distance-dependence-in-language:-Iyer-Ostendorf",
            "title": {
                "fragments": [],
                "text": "Modeling long distance dependence in language: topic mixtures versus dynamic cache models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper develops a topic-dependent, sentence-level mixture language model which takes advantage of the topic constraints in a sentence or article, and introduces topic- dependent dynamic adaptation techniques in the framework of the mixture model, using n-gram caches and content word unigram caches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5490327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e49da956b23ed295541c80939d4a1261d0a1022f",
            "isKey": false,
            "numCitedBy": 1030,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Topic models, such as latent Dirichlet allocation (LDA), can be useful tools for the statistical analysis of document collections and other discrete data. The LDA model assumes that the words of each document arise from a mixture of topics, each of which is a distribution over the vocabulary. A limitation of LDA is the inability to model topic correlation even though, for example, a document about genetics is more likely to also be about disease than x-ray astronomy. This limitation stems from the use of the Dirichlet distribution to model the variability among the topic proportions. In this paper we develop the correlated topic model (CTM), where the topic proportions exhibit correlation via the logistic normal distribution [1]. We derive a mean-field variational inference algorithm for approximate posterior inference in this model, which is complicated by the fact that the logistic normal is not conjugate to the multinomial. The CTM gives a better fit than LDA on a collection of OCRed articles from the journal Science. Furthermore, the CTM provides a natural way of visualizing and exploring this and other unstructured data sets."
            },
            "slug": "Correlated-Topic-Models-Blei-Lafferty",
            "title": {
                "fragments": [],
                "text": "Correlated Topic Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The correlated topic model (CTM) is developed, where the topic proportions exhibit correlation via the logistic normal distribution and a mean-field variational inference algorithm is derived for approximate posterior inference in this model, which is complicated by the fact that the Logistic normal is not conjugate to the multinomial."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47277215"
                        ],
                        "name": "S. Duffy",
                        "slug": "S.-Duffy",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Duffy",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Duffy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33070393"
                        ],
                        "name": "R. Morris",
                        "slug": "R.-Morris",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Morris",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Morris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148762"
                        ],
                        "name": "K. Rayner",
                        "slug": "K.-Rayner",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Rayner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rayner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 2
                            }
                        ],
                        "text": ", Elman, 1990). However, the strongest parallels between our approach and work being done on spatial representations of semantics are perhaps those that exist between the topic model and LSA. Indeed, the probabilistic topic model developed by Hofmann (1999) was motivated by the success of LSA and provided the inspiration for the model introduced by Blei et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 145425957,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "469825f3135b6cc426e55783f080735e792bec0c",
            "isKey": false,
            "numCitedBy": 553,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lexical-ambiguity-and-fixation-times-in-reading-Duffy-Morris",
            "title": {
                "fragments": [],
                "text": "Lexical ambiguity and fixation times in reading"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2556348"
                        ],
                        "name": "K. Plunkett",
                        "slug": "K.-Plunkett",
                        "structuredName": {
                            "firstName": "Kim",
                            "lastName": "Plunkett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Plunkett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831087"
                        ],
                        "name": "V. Marchman",
                        "slug": "V.-Marchman",
                        "structuredName": {
                            "firstName": "Virginia",
                            "lastName": "Marchman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Marchman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 200
                            }
                        ],
                        "text": "Most computational approaches to natural language have tended to focus exclusively on either structured representations (e.g., Chomsky, 1965; Pinker, 1999) or sta-\ntistical learning (e.g., Elman, 1990; Plunkett & Marchman, 1993; Rumelhart & McClelland, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17126604,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "f24970d1498624f4567915917f0a95fa0dab92a7",
            "isKey": false,
            "numCitedBy": 636,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "From-rote-learning-to-system-building:-acquiring-in-Plunkett-Marchman",
            "title": {
                "fragments": [],
                "text": "From rote learning to system building: acquiring verb morphology in children and connectionist nets"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493778"
                        ],
                        "name": "D. McNeill",
                        "slug": "D.-McNeill",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McNeill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. McNeill"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 153
                            }
                        ],
                        "text": "It is not our goal to develop a model of word association, as many factors other than semantic association are involved in this task (e.g., Ervin, 1961; McNeill, 1966), but we believe that issues raised by wordassociation data can provide insight into models of semantic representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 220
                            }
                        ],
                        "text": "However, it is clear that word order is important to many aspects of linguistic processing, including the simple word-association task that we discussed extensively earlier in the article (Ervin, 1961; Hutchinson, 2003; McNeill, 1966)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 143922776,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "fcfaac57f007d4272234706117d8935adb9acaad",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-study-of-word-association-McNeill",
            "title": {
                "fragments": [],
                "text": "A study of word association"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 45
                            }
                        ],
                        "text": "We will use a generative model introduced by Blei et al. (2003) called latent Dirichlet allocation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "\u2026algorithms have been proposed for learning topics, including expectation maximization (Hofmann, 1999), variational expectation maximization (Blei et al., 2003; Buntine, 2002), ex-\npectation propagation (Minka & Lafferty, 2002), and several forms of Markov chain Monte Carlo (MCMC; Buntine &\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 159
                            }
                        ],
                        "text": "Indeed, the probabilistic topic model developed by Hofmann (1999) was motivated by the success of LSA and provided the inspiration for the model introduced by Blei et al. (2003) that we use here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Blei et al. (2003) extended this approach by introducing a prior on the distribution over topics, turning the model into a genuine generative model for collections of documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 41
                            }
                        ],
                        "text": "Under the generative model introduced by Blei et al. (2003), the gist of each document, g, is encoded using a multinomial distribution over the T topics, with parameters (d), and so for a word in document d, P(z g) z(d)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 219
                            }
                        ],
                        "text": "\u2026in information retrieval and statistical natural language processing, with different models making different assumptions about the origins of the distribution over topics (e.g., Bigi, De Mori, El-Beze, & Spriet, 1997; Blei et al., 2003; Hofmann, 1999; Iyer & Ostendorf, 1999; Ueda & Saito, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3177797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f198043a866e9187925a8d8db9a55e3bfdd47f2c",
            "isKey": true,
            "numCitedBy": 30950,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Latent-Dirichlet-Allocation-Blei-Ng",
            "title": {
                "fragments": [],
                "text": "Latent Dirichlet Allocation"
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Blei et al. (2004) provided an algorithm that simultaneously learns the structure of a topic hierarchy and the topics that are contained within that hierarchy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Indeed, the probabilistic topic model developed by Hofmann (1999) was motivated by the success of LSA and provided the inspiration for the model introduced by Blei et al. (2003) that we use here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1269561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28e245ce0e06f398dd26a9d6ab6bb04ef4c016e6",
            "isKey": false,
            "numCitedBy": 1065,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of learning topic hierarchies from data. The model selection problem in this domain is daunting\u2014which of the large collection of possible trees to use? We take a Bayesian approach, generating an appropriate prior via a distribution on partitions that we refer to as the nested Chinese restaurant process. This nonparametric prior allows arbitrarily large branching factors and readily accommodates growing data collections. We build a hierarchical topic model by combining this prior with a likelihood that is based on a hierarchical variant of latent Dirichlet allocation. We illustrate our approach on simulated data and with an application to the modeling of NIPS abstracts."
            },
            "slug": "Hierarchical-Topic-Models-and-the-Nested-Chinese-Blei-Griffiths",
            "title": {
                "fragments": [],
                "text": "Hierarchical Topic Models and the Nested Chinese Restaurant Process"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A Bayesian approach is taken to generate an appropriate prior via a distribution on partitions that allows arbitrarily large branching factors and readily accommodates growing data collections."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3029245"
                        ],
                        "name": "K. Hutchison",
                        "slug": "K.-Hutchison",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Hutchison",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hutchison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35854055,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2ae3e96170a91c6b6b9c3157bd5911943e4f0159",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 142,
            "paperAbstract": {
                "fragments": [],
                "text": "In a recent meta-analysis, Lucas (2000) concluded that there is strong evidence of an overall pure semantic priming effect but no evidence of priming based purely on association. In the present review, I critically examine the individual studies claiming evidence of featural and associative relations in semantic memory. The most important conclusion is that automatic priming appears to be due to both association strength and feature overlap. Mediated associates provide the strongest evidence of automatic associative priming, whereas functional associates, synonyms, and antonyms instead support priming based on feature overlap. In contrast, automatic priming does not occur for category coordinates or perceptually similar items, at least when presented in the visual modality. The status of other relations, such as collocates, episodic relatives, and script relations, is unclear and requires further experimentation. Implications for current models of semantic representation and priming are discussed."
            },
            "slug": "Is-semantic-priming-due-to-association-strength-or-Hutchison",
            "title": {
                "fragments": [],
                "text": "Is semantic priming due to association strength or feature overlap? A microanalytic review"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is concluded that Mediated associates provide the strongest evidence of automatic associative priming, whereas functional associates, synonyms, and antonyms instead support priming based on feature overlap."
            },
            "venue": {
                "fragments": [],
                "text": "Psychonomic bulletin & review"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158597261"
                        ],
                        "name": "John R. Anderson",
                        "slug": "John-R.-Anderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Anderson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John R. Anderson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1065,
                                "start": 259
                            }
                        ],
                        "text": "Association has been part of the theoretical armory of cognitive psychologists since Thomas Hobbes used the notion to account for the structure of our \u201ctrayne of thoughts\u201d (Hobbes, 1651/1998; detailed histories of association are provided by Deese, 1965, and Anderson & Bower, 1974). One of the first experimental studies of association was conducted by Galton (1880), who used a wordassociation task to study different kinds of association. Since Galton, several psychologists have tried to classify kinds of association or to otherwise divine its structure (e.g., Deese, 1962, 1965). This theoretical work has been supplemented by the development of extensive word-association norms, listing commonly named associates for a variety of words (e.g., Cramer, 1968; Kiss, Armstrong, Milroy, & Piper, 1973; Nelson, McEvoy, & Schreiber, 1998). These norms provide a rich body of data, which has only recently begun to be addressed using computational models (Dennis, 2003; Nelson, McEvoy, & Dennis, 2000; Steyvers, Shiffrin, & Nelson, 2004). Though unlike Deese (1965), we suspect that there may be more fascinating psychological data than tables of association, word association provides a useful benchmark for evaluating models of human semantic representation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 86
                            }
                        ],
                        "text": "These methods are closely related to the rational model of categorization proposed by Anderson (1990), which represents categories in terms of a set of clusters, with new clusters added automatically as more data become available (see Neal, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 954,
                                "start": 2
                            }
                        ],
                        "text": ", Anderson, 1983; Norman, Rumelhart, & The LNR Research Group, 1975). In addition to excitatory connections, in which activation of one node increases activation of another, some semantic networks feature inhibitory connections, allowing activation of one node to decrease activation of another. The need for inhibitory connections is indicated by empirical results in the literature on priming. A simple network without inhibitory connections can explain why priming might facilitate lexical decision, making it easier to recognize that a target is an English word. For example, a word like nurse primes the word doctor because it activates concepts that are closely related to doctor, and the spread of activation ultimately activates doctor. However, not all priming effects are of this form. For example, Neely (1976) showed that priming with irrelevant cues could have an inhibitory effect on lexical decision. To use an example from Markman (1998), priming with hockey could produce a slower reaction time for doctor than presenting a completely neutral prime."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 822,
                                "start": 2
                            }
                        ],
                        "text": ", Anderson, 1983; Norman, Rumelhart, & The LNR Research Group, 1975). In addition to excitatory connections, in which activation of one node increases activation of another, some semantic networks feature inhibitory connections, allowing activation of one node to decrease activation of another. The need for inhibitory connections is indicated by empirical results in the literature on priming. A simple network without inhibitory connections can explain why priming might facilitate lexical decision, making it easier to recognize that a target is an English word. For example, a word like nurse primes the word doctor because it activates concepts that are closely related to doctor, and the spread of activation ultimately activates doctor. However, not all priming effects are of this form. For example, Neely (1976) showed that priming with irrelevant cues could have an inhibitory effect on lexical decision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 368,
                                "start": 259
                            }
                        ],
                        "text": "Association has been part of the theoretical armory of cognitive psychologists since Thomas Hobbes used the notion to account for the structure of our \u201ctrayne of thoughts\u201d (Hobbes, 1651/1998; detailed histories of association are provided by Deese, 1965, and Anderson & Bower, 1974). One of the first experimental studies of association was conducted by Galton (1880), who used a wordassociation task to study different kinds of association."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 204
                            }
                        ],
                        "text": "Most semantic networks that are used as components of cognitive models are considerably more complex than the example shown in Figure 1a, allowing multiple different kinds of nodes and connections (e.g., Anderson, 1983; Norman, Rumelhart, & The LNR Research Group, 1975)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 204
                            }
                        ],
                        "text": "We now take a step back from these specific proposals and consider the abstract computational problem that they are intended to solve, in the spirit of Marr\u2019s (1982) notion of the computational level and Anderson\u2019s (1990) rational analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1741,
                                "start": 150
                            }
                        ],
                        "text": "Many aspects of perception and cognition can be understood by considering the computational problem that is addressed by a particular human capacity (Anderson, 1990; Marr, 1982). Perceptual capacities such as identifying shape from shading (Freeman, 1994), motion perception (Weiss, Simoncelli, & Adelson, 2002), and sensorimotor integration (K\u00f6rding & Wolpert, 2004; Wolpert, Ghahramani, & Jordan, 1995) appear to closely approximate optimal statistical inferences. Cognitive capacities such as memory and categorization can be seen as systems for efficiently making predictions about the properties of an organism\u2019s environment (e.g., Anderson, 1990). Solving problems of inference and prediction requires sensitivity to the statistics of the environment. Surprisingly subtle aspects of human vision can be explained in terms of the statistics of natural scenes (Geisler, Perry, Super, & Gallogly, 2001; Simoncelli & Olshausen, 2001), and human memory seems to be tuned to the probabilities with which particular events occur in the world (Anderson & Schooler, 1991). Sensitivity to relevant world statistics also seems to guide important classes of cognitive judgments, such as inductive inferences about the properties of categories (Kemp, Perfors, & Tenenbaum, 2004), predictions about the durations or magnitudes of events (Griffiths & Tenenbaum, 2006), and inferences about hidden common causes from patterns of coincidence (Griffiths & Tenenbaum, in press). In this article, we examine how the statistics of one very important aspect of the environment\u2014natural language\u2014 influence human memory. Our approach is motivated by an analysis of some of the computational problems addressed by semantic memory, in the spirit of Marr (1982) and Anderson (1990)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1761,
                                "start": 150
                            }
                        ],
                        "text": "Many aspects of perception and cognition can be understood by considering the computational problem that is addressed by a particular human capacity (Anderson, 1990; Marr, 1982). Perceptual capacities such as identifying shape from shading (Freeman, 1994), motion perception (Weiss, Simoncelli, & Adelson, 2002), and sensorimotor integration (K\u00f6rding & Wolpert, 2004; Wolpert, Ghahramani, & Jordan, 1995) appear to closely approximate optimal statistical inferences. Cognitive capacities such as memory and categorization can be seen as systems for efficiently making predictions about the properties of an organism\u2019s environment (e.g., Anderson, 1990). Solving problems of inference and prediction requires sensitivity to the statistics of the environment. Surprisingly subtle aspects of human vision can be explained in terms of the statistics of natural scenes (Geisler, Perry, Super, & Gallogly, 2001; Simoncelli & Olshausen, 2001), and human memory seems to be tuned to the probabilities with which particular events occur in the world (Anderson & Schooler, 1991). Sensitivity to relevant world statistics also seems to guide important classes of cognitive judgments, such as inductive inferences about the properties of categories (Kemp, Perfors, & Tenenbaum, 2004), predictions about the durations or magnitudes of events (Griffiths & Tenenbaum, 2006), and inferences about hidden common causes from patterns of coincidence (Griffiths & Tenenbaum, in press). In this article, we examine how the statistics of one very important aspect of the environment\u2014natural language\u2014 influence human memory. Our approach is motivated by an analysis of some of the computational problems addressed by semantic memory, in the spirit of Marr (1982) and Anderson (1990). Under many accounts of language processing, understanding sentences requires retrieving a variety of concepts from memory in response to an ongoing stream of information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2359,
                                "start": 259
                            }
                        ],
                        "text": "Association has been part of the theoretical armory of cognitive psychologists since Thomas Hobbes used the notion to account for the structure of our \u201ctrayne of thoughts\u201d (Hobbes, 1651/1998; detailed histories of association are provided by Deese, 1965, and Anderson & Bower, 1974). One of the first experimental studies of association was conducted by Galton (1880), who used a wordassociation task to study different kinds of association. Since Galton, several psychologists have tried to classify kinds of association or to otherwise divine its structure (e.g., Deese, 1962, 1965). This theoretical work has been supplemented by the development of extensive word-association norms, listing commonly named associates for a variety of words (e.g., Cramer, 1968; Kiss, Armstrong, Milroy, & Piper, 1973; Nelson, McEvoy, & Schreiber, 1998). These norms provide a rich body of data, which has only recently begun to be addressed using computational models (Dennis, 2003; Nelson, McEvoy, & Dennis, 2000; Steyvers, Shiffrin, & Nelson, 2004). Though unlike Deese (1965), we suspect that there may be more fascinating psychological data than tables of association, word association provides a useful benchmark for evaluating models of human semantic representation. The relationship between word association and semantic representation is analogous to that between similarity judgments and conceptual representation, being an accessible behavior that provides clues and constraints that guide the construction of psychological models. Also, like similarity judgments, association scores are highly predictive of other aspects of human behavior. Word-association norms are commonly used in constructing memory experiments, and statistics derived from these norms have been shown to be important in predicting cued recall (Nelson, McKinney, Gee, & Janczura, 1998), recognition (Nelson, McKinney, et al., 1998; Nelson, Zhang, & McKinney, 2001), and false memories (Deese, 1959; McEvoy et al., 1999; Roediger et al., 2001). It is not our goal to develop a model of word association, as many factors other than semantic association are involved in this task (e.g., Ervin, 1961; McNeill, 1966), but we believe that issues raised by wordassociation data can provide insight into models of semantic representation. We used the norms of Nelson, McEvoy, and Schreiber (1998) to evaluate the performance of LSA and the topic model in predicting human word association."
                    },
                    "intents": []
                }
            ],
            "corpusId": 145802193,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b369f7f9e0ba0aa28418576bf801fb7be9cd01bf",
            "isKey": true,
            "numCitedBy": 1548,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-spreading-activation-theory-of-memory.-Anderson",
            "title": {
                "fragments": [],
                "text": "A spreading activation theory of memory."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2197285"
                        ],
                        "name": "B. Rehder",
                        "slug": "B.-Rehder",
                        "structuredName": {
                            "firstName": "Bob",
                            "lastName": "Rehder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rehder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144029655"
                        ],
                        "name": "M. E. Schreiner",
                        "slug": "M.-E.-Schreiner",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Schreiner",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. E. Schreiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39952106"
                        ],
                        "name": "Michael B. W. Wolfe",
                        "slug": "Michael-B.-W.-Wolfe",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wolfe",
                            "middleNames": [
                                "B.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael B. W. Wolfe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2444937"
                        ],
                        "name": "Darrell Laham",
                        "slug": "Darrell-Laham",
                        "structuredName": {
                            "firstName": "Darrell",
                            "lastName": "Laham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Darrell Laham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 118
                            }
                        ],
                        "text": "However, in a few applications, it has been found that the unnormalized inner product gives better predictions (e.g., Rehder et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 175
                            }
                        ],
                        "text": "Applications of LSA often evaluate the similarity between two documents by computing the cosine between the average word vectors for those documents (Landauer & Dumais, 1997; Rehder et al., 1998; Wolfe et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1935697,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "a41a040d683c66d2e63ed9d5015e7dd8e9ddbb4b",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In another article (Wolfe et al., 1998/this issue) we showed how Latent Semantic Analysis (LSA) can be used to assess student knowledge\u2014how essays can be graded by LSA and how LSA can match students with appropriate instructional texts. We did this by comparing an essay written by a student with one or more target instructional texts in terms of the cosine between the vector representation of the student's essay and the instructional text in question. This simple method was effective for the purpose, but questions remain about how LSA achieves its results and how the results might be improved. Here, we address four such questions: (a) What role does the use of technical vocabulary play? (b) how long should the student essays be? (c) is the cosine the optimal measure of semantic relatedness? and (d) how does one deal with the directionality of knowledge in the high\u2010dimensional space?"
            },
            "slug": "Using-latent-semantic-analysis-to-assess-knowledge:-Rehder-Schreiner",
            "title": {
                "fragments": [],
                "text": "Using latent semantic analysis to assess knowledge: Some technical considerations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2849116"
                        ],
                        "name": "E. Warrington",
                        "slug": "E.-Warrington",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Warrington",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Warrington"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 282
                            }
                        ],
                        "text": "\u2026such as the development of conceptual hierarchies that support propositional knowledge (e.g., Keil, 1979), reaction time to verify conceptual propositions in normal adults (e.g., Collins & Quillian, 1969), and the decay of propositional knowledge with aging or brain damage (e.g., Warrington, 1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2178636,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "397cc5c44ced1616b2a68c3c3711828a69a5ce26",
            "isKey": false,
            "numCitedBy": 1413,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "The selective impairment of semantic memory is described in three patients with diffuse cerebrallesions. These patients, selected on the basis of a failure to recognize or identify common objects (agnosia for objects), were investigated in detail. In particular, their perceptual, language and memory functions were assessed, and the limits and properties of their recognition difficulties explored. It was found that knowledge of pictorial representations of objects, and of words, was impaired or impoverished, and in both instances knowledge of subordinate categories was more vulnerable than superordinate categories. Evidence is presented that this impairment of semantic memory cannot be accounted for by intellectual impairment, sensory or perceptual deficits, or expressive language disorder. The implications of damage to the semantic memory system for the operation of other cognitive systems, in particular short and long-term memory functions, are considered. Some tentative evidence for the structural basis for a hierarchically organized modality-specific semantic memory system is discussed."
            },
            "slug": "The-Selective-Impairment-of-Semantic-Memory-Warrington",
            "title": {
                "fragments": [],
                "text": "The Selective Impairment of Semantic Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Evidence is presented that this impairment of semantic memory cannot be accounted for by intellectual impairment, sensory or perceptual deficits, or expressive language disorder, and some tentative evidence for the structural basis for a hierarchically organized modality-specific semantic memory system is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "The Quarterly journal of experimental psychology"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145300792"
                        ],
                        "name": "Charles Kemp",
                        "slug": "Charles-Kemp",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Kemp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Kemp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2841005"
                        ],
                        "name": "Amy Perfors",
                        "slug": "Amy-Perfors",
                        "structuredName": {
                            "firstName": "Amy",
                            "lastName": "Perfors",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amy Perfors"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11850955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae6ce1a2a739c6d0fbffc0e3c723d71dbdd7826a",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning Domain Structures Charles Kemp, Amy Perfors & Joshua B. Tenenbaum {ckemp, perfors, jbt}@mit.edu Department of Brain and Cognitive Sciences Massachusetts Institute of Technology structure, although with repeated training, its hidden unit representations may implicitly come to approximate the taxonomic relations between biological species. This paper proposes an alternative approach \u2013 struc- ture learning \u2013 that combines important insights from both of these traditions. Our key contribution is to show how structured domain representations can be ac- quired within a domain-general framework for Bayesian inference. Like nativists, we suggest that different do- mains are represented with qualitatively different struc- tures, and we show how these structured representations serve as critical constraints on inductive generalization. Like empiricists, though, we emphasize the importance of learning, and attempt to show how domain structures can be acquired through domain-general statistical in- ference. This is not only more parsimonious than the nativist position, but allows us to explain the origin of structured representations in novel domains, where the prior existence of domain-specific innate structure is highly implausible. After describing our structure learning framework, we present two empirical tests of its performance. First, we show that it chooses the appropriate domain structure for both synthetic and real-world data sets. It correctly chooses a tree structure for a biological domain (animal feature judgments), and a linear structure for a politi- cal domain (US Supreme Court decisions). Second, we model two classic data sets of inductive judgments in bi- ology [13] and show that our framework performs better than an unstructured connectionist approach. Abstract How do people acquire and use knowledge about do- main structures, such as the tree-structured taxonomy of folk biology? These structures are typically seen ei- ther as consequences of innate domain-speci c knowl- edge or as epiphenomena of domain-general associative learning. We present an alternative: a framework for statistical inference that discovers the structural princi- ples that best account for di erent domains of objects and their properties. Our approach infers that a tree structure is best for a biological dataset, and a linear structure (\u201cleft\u201d\u2013\u201cright\u201d) is best for a dataset of peo- ple and their political views. We compare our proposal with unstructured associative learning and argue that our structured approach gives the better account of in- ductive generalization in the domain of folk biology. Psychologists have argued that cognition in differ- ent domains draws on qualitatively different mental representations. Tree structures appear well-suited to representing relationships between animal species [1, 2, 10], while a one-dimensional structure (the liberal- conservative spectrum) seems better for representing people\u2019s political views. The possibility of different structures raises a fundamental question: how do peo- ple learn what kind of structure is appropriate in each domain? The standard approach to this question is to reject one of its assumptions. Nativists deny that core struc- tures are learned, at least for evolutionarily important domains like folkbiology. Instead, infants come equipped with innate knowledge about which structures are appro- priate for which domains. Atran [1], for example, argues that folkbiology is a core domain of human knowledge, and that the tendency to group living kinds into hier- archies re ects an \u201cinnately determined cognitive struc- ture.\u201d More generally, Keil [8] has argued that ontologi- cal knowledge obeys an innate \u201cM-constraint\u201d, requiring the extensions of predicates to conform to rigidly tree- structured hierarchies of objects. Alternatively, empiricists generally deny that struc- tured representations are present at all. Domain-specific representations are merely emergent properties of un- structured, domain-general associative learning architec- tures. McClelland and Rogers [12], for example, have re- cently suggested that the acquisition of semantic knowl- edge in domains such as intuitive biology can be ex- plained as learning in a generic connectionist network. Their architecture never explicitly represents any tree Bayesian structure learning Our proposal takes the form of a rational analysis. We aim to demonstrate the computational plausibility and explanatory value of Bayesian structure learning, but leave for future work the question of how these com- putations might be implemented or approximated by cognitive processes. Assume the learner\u2019s data consist of a binary-valued object-feature matrix D specifying the features of each object in a given domain. In bi- ology, for instance, the rows of D might correspond to species, and the columns to anatomical and behavioral attributes. The entry in row i and column j would then specify the value of feature j for species i. Structure- learning includes computational problems at two levels. First, which structure class is most appropriate for the domain? Second, given a structure class, which structure"
            },
            "slug": "Learning-Domain-Structures-Kemp-Perfors",
            "title": {
                "fragments": [],
                "text": "Learning Domain Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a framework for statistical inference that discovers the structural princi- ples that best account for domains of objects and their properties, and argues that the structured approach gives the better account of in- ductive generalization in the domain of folk biology."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148762"
                        ],
                        "name": "K. Rayner",
                        "slug": "K.-Rayner",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Rayner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rayner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144803172"
                        ],
                        "name": "L. Frazier",
                        "slug": "L.-Frazier",
                        "structuredName": {
                            "firstName": "Lyn",
                            "lastName": "Frazier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Frazier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 25481191,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "0f3f667dfad9830278c74aa2da879cf36419009d",
            "isKey": false,
            "numCitedBy": 242,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Readers' eye movements were monitored as they read sentences containing lexically ambiguous words. The ambiguous words were either biased (one strongly dominant interpretation) or nonbiased. Readers' gaze durations were longer on nonbiased than biased words when the disambiguating information followed the target word. In Experiment 1, reading times on the disambiguating word did not differ whether the disambiguation followed the target word immediately or occurred several words later. In Experiment 2, prior disambiguation eliminated the long gaze durations on nonbiased target words but resulted in long gaze durations on biased target words if the context demanded the subordinate meaning. The results indicate that successful integration of one meaning with prior context terminates the search for alternative meanings of that word. This results in selective (single meaning) access when integration of a dominant meaning is fast (due to a biasing context) and identification of a subordinate meaning is slow (a strongly biased ambiguity with a low-frequency meaning)."
            },
            "slug": "Selection-mechanisms-in-reading-lexically-ambiguous-Rayner-Frazier",
            "title": {
                "fragments": [],
                "text": "Selection mechanisms in reading lexically ambiguous words."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The results indicate that successful integration of one meaning with prior context terminates the search for alternative meanings of that word and results in selective access when integration of a dominant meaning is fast (due to a biasing context) and identification of a subordinate meaning is slow (a strongly biased ambiguity with a low-frequency meaning)."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Learning, memory, and cognition"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3345436"
                        ],
                        "name": "S. Sereno",
                        "slug": "S.-Sereno",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Sereno",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sereno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7230616"
                        ],
                        "name": "J. Pacht",
                        "slug": "J.-Pacht",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Pacht",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pacht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148762"
                        ],
                        "name": "K. Rayner",
                        "slug": "K.-Rayner",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Rayner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rayner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 13
                            }
                        ],
                        "text": "The study of Sereno et al. (1992) is particularly conducive to modeling, as all three target words are substituted into the same sentence frame, meaning that the results are not affected by sentences differing in number of words, by the vocabulary of the models, or by other factors that introduce\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 97
                            }
                        ],
                        "text": "We used the 1,700-topic solution to compute this quantity for the 21 of the 24 sentences used by Sereno et al. (1992) for which all three target words appeared in our vocabulary, and averaged the resulting log probabilities over all sentences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 118
                            }
                        ],
                        "text": "The inner product, which is sensitive to word frequency, produces predictions that are consistent with the results of Sereno et al. (1992)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 46
                            }
                        ],
                        "text": "The topic model predicts the results found by Sereno et al. (1992): The ambiguous words are assigned lower probabilities than the high-frequency controls, although not quite as low as the low-frequency controls."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Sereno et al. (1992) conducted a study in which the eye movements of participants were monitored while they read sentences containing ambiguous words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 145473593,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7a655f30260115fe54da4ad389af01c1a0d864b6",
            "isKey": true,
            "numCitedBy": 84,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Subjects read sentences containing lexically ambiguous words while their eye movements were monitored Biased ambiguous words (those that have one highly dominant sense) were used in sentences containing a prior context that instantiated their subordinate sense Control words were matched in frequency both to the dominant and to the subordinate meaning of the ambiguous word (high- and low-frequency controls) Subjects fixated longer on both the ambiguous word and the low-frequency control than on the high-frequency control When the target was ambiguous, however, the duration of posttarget fixations was longer and the likelihood of making a regression to the target was greater than when the target was an unambiguous control The results are discussed in relation to current models of lexical ambiguity resolution"
            },
            "slug": "The-Effect-of-Meaning-Frequency-on-Processing-from-Sereno-Pacht",
            "title": {
                "fragments": [],
                "text": "The Effect of Meaning Frequency on Processing Lexically Ambiguous Words: Evidence from Eye Fixations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46973696"
                        ],
                        "name": "D. Nelson",
                        "slug": "D.-Nelson",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Nelson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4933118"
                        ],
                        "name": "V. M. McKinney",
                        "slug": "V.-M.-McKinney",
                        "structuredName": {
                            "firstName": "Vanesa",
                            "lastName": "McKinney",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. M. McKinney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3572043"
                        ],
                        "name": "N. Gee",
                        "slug": "N.-Gee",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Gee",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4608115"
                        ],
                        "name": "G. A. Janczura",
                        "slug": "G.-A.-Janczura",
                        "structuredName": {
                            "firstName": "Gerson",
                            "lastName": "Janczura",
                            "middleNames": [
                                "Am\u00e9rico"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. A. Janczura"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38130817,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "760abb23b1d6cfe9a9e742168a886ee9c11c93b5",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "A model concerning the influence of implicitly activated information on cued recall and recognition is presented. The model assumes that studying a familiar word activates its associates and creates an implicit representation in long-term working memory. Test cues also activate their associates, with memory performance determined by a sampling process that operates on the intersection of information activated by the test cue with information previously activated by the studied word. Successful sampling is enhanced by preexisting connections among the associates of the studied word and by preexisting connections between it and the retrieval cue. However, the usefulness of the implicit representation is reduced by the activation of competing associates and by shifts of attention before testing. Experiments designed to test predictions of the model indicate that the associates of a familiar word can exert a powerful effect on its cued recall and recognition."
            },
            "slug": "Interpreting-the-influence-of-implicitly-activated-Nelson-McKinney",
            "title": {
                "fragments": [],
                "text": "Interpreting the influence of implicitly activated memories on recall and recognition."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experiments designed to test predictions of the model indicate that the associates of a familiar word can exert a powerful effect on its cued recall and recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46973696"
                        ],
                        "name": "D. Nelson",
                        "slug": "D.-Nelson",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Nelson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107110683"
                        ],
                        "name": "N. Zhang",
                        "slug": "N.-Zhang",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4933118"
                        ],
                        "name": "V. M. McKinney",
                        "slug": "V.-M.-McKinney",
                        "structuredName": {
                            "firstName": "Vanesa",
                            "lastName": "McKinney",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. M. McKinney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 21
                            }
                        ],
                        "text": ", 1998), recognition (Nelson et al., 2001), and priming effects (Nelson & Goodmon, 2002), although this quantity is typically referred to as the \u201cconnectivity\u201d of a word."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 151
                            }
                        ],
                        "text": "\u2026Cw have been found to be useful in predicting various phenomena in human memory, including cued recall (Nelson, McKinney, et al., 1998), recognition (Nelson et al., 2001), and priming effects (Nelson & Goodmon, 2002), although this quantity is typically referred to as the \u201cconnectivity\u201d of a word."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30339998,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a490c7f0ca9f336be3b2a27b7f629ed4571039db",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognition success varies with how information is encoded (e.g., level of processing) and with what is already known as a result of past learning (e.g., word frequency). This article presents the results of experiments showing that preexisting connections involving the associates of studied words facilitate their recognition regardless of whether the words are intentionally encoded or are incidentally encoded under semantic or nonsemantic conditions. Words are more likely to be recognized when they have either more resonant connections coming back to them from their associates or more connections among their associates. Such results occur even though attention is never drawn to these associates. Regression analyses showed that these connections affect recognition independently of frequency, so the present results add to the literature showing that prior lexical knowledge contributes to episodic recognition. In addition, equations that use free-association data to derive composite strength indices of resonance and connectivity were evaluated. Implications for theories of recognition are discussed."
            },
            "slug": "The-ties-that-bind-what-is-known-to-the-recognition-Nelson-Zhang",
            "title": {
                "fragments": [],
                "text": "The ties that bind what is known to the recognition of what is new."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The results of experiments showing that preexisting connections involving the associates of studied words facilitate their recognition regardless of whether the words are intentionally encoded or are incidentally encoded under semantic or nonsemantic conditions are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Learning, memory, and cognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50288999"
                        ],
                        "name": "Randall Davis",
                        "slug": "Randall-Davis",
                        "structuredName": {
                            "firstName": "Randall",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Randall Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716356"
                        ],
                        "name": "H. Shrobe",
                        "slug": "H.-Shrobe",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Shrobe",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shrobe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679873"
                        ],
                        "name": "Peter Szolovits",
                        "slug": "Peter-Szolovits",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Szolovits",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Szolovits"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 23
                            }
                        ],
                        "text": "To use an example from Markman (1998), priming with hockey could produce a slower reaction time for doctor than presenting a completely neutral prime."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1527228,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "8df1e4d7a7c2f288b7ca4645b444b128b076a572",
            "isKey": false,
            "numCitedBy": 1354,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Although knowledge representation is one of the central and, in some ways, most familiar concepts in AI, the most fundamental question about it -- What is it? -- has rarely been answered directly. Numerous papers have lobbied for one or another variety of representation, other papers have argued for various properties a representation should have, and still others have focused on properties that are important to the notion of representation in general. In this article, we go back to basics to address the question directly. We believe that the answer can best be understood in terms of five important and distinctly different roles that a representation plays, each of which places different and, at times, conflicting demands on the properties a representation should have. We argue that keeping in mind all five of these roles provides a usefully broad perspective that sheds light on some longstanding disputes and can invigorate both research and practice in the field."
            },
            "slug": "What-Is-a-Knowledge-Representation-Davis-Shrobe",
            "title": {
                "fragments": [],
                "text": "What Is a Knowledge Representation?"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is argued that keeping in mind all five of these roles that a representation plays provides a usefully broad perspective that sheds light on some longstanding disputes and can invigorate both research and practice in the field."
            },
            "venue": {
                "fragments": [],
                "text": "AI Mag."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701461"
                        ],
                        "name": "Matthew Purver",
                        "slug": "Matthew-Purver",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Purver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Purver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3282030"
                        ],
                        "name": "Konrad Paul Kording",
                        "slug": "Konrad-Paul-Kording",
                        "structuredName": {
                            "firstName": "Konrad",
                            "lastName": "Kording",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Konrad Paul Kording"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3077921,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6b1b41ade015e2ea3eec1a7d84afdb64af555c5",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for unsupervised topic modelling which adapts methods used in document classification (Blei et al., 2003; Griffiths and Steyvers, 2004) to unsegmented multi-party discourse transcripts. We show how Bayesian inference in this generative model can be used to simultaneously address the problems of topic segmentation and topic identification: automatically segmenting multi-party meetings into topically coherent segments with performance which compares well with previous unsupervised segmentation-only methods (Galley et al., 2003) while simultaneously extracting topics which rate highly when assessed for coherence by human judges. We also show that this method appears robust in the face of off-topic dialogue and speech recognition errors."
            },
            "slug": "Unsupervised-Topic-Modelling-for-Multi-Party-Spoken-Purver-Kording",
            "title": {
                "fragments": [],
                "text": "Unsupervised Topic Modelling for Multi-Party Spoken Discourse"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown how Bayesian inference in this generative model can be used to simultaneously address the problems of topic segmentation and topic identification: automatically segmenting multi-party meetings into topically coherent segments with performance which compares well with previous unsupervised segmentation-only methods."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 141
                            }
                        ],
                        "text": "\u2026expectation maximization (Hofmann, 1999), variational expectation maximization (Blei et al., 2003; Buntine, 2002), ex-\npectation propagation (Minka & Lafferty, 2002), and several forms of Markov chain Monte Carlo (MCMC; Buntine & Jakulin, 2004; Erosheva, 2002; Griffiths & Steyvers, 2002,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1768942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45b4dde8e0945912a39666f2715cdf10a4445b1c",
            "isKey": false,
            "numCitedBy": 537,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The generative aspect model is an extension of the multinomial model for text that allows word probabilities to vary stochastically across documents. Previous results with aspect models have been promising, but hindered by the computational difficulty of carrying out inference and learning. This paper demonstrates that the simple variational methods of Blei et al. (2001) can lead to inaccurate inferences and biased learning for the generative aspect model. We develop an alternative approach that leads to higher accuracy at comparable cost. An extension of Expectation-Propagation is used for inference and then embedded in an EM algorithm for learning. Experimental results are presented for both synthetic and real data sets."
            },
            "slug": "Expectation-Propogation-for-the-Generative-Aspect-Minka-Lafferty",
            "title": {
                "fragments": [],
                "text": "Expectation-Propogation for the Generative Aspect Model"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper demonstrates that the simple variational methods of Blei et al. (2001) can lead to inaccurate inferences and biased learning for the generative aspect model, and develops an alternative approach that leads to higher accuracy at comparable cost."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29391409"
                        ],
                        "name": "J. H. Neely",
                        "slug": "J.-H.-Neely",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Neely",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Neely"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 13
                            }
                        ],
                        "text": "For example, Neely (1976) showed that priming with irrelevant cues could have an inhibitory effect on lexical decision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20087830,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d1634f5eee336ebd73851db65690afbc62f5e106",
            "isKey": false,
            "numCitedBy": 569,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Immediately prior to each visually presented target letter string to which the subject made a speeded word-nonword classification response, a visually presented prime to which no overt response was required was shown for 360, 600, or 2,000 msec. For word (W) target trials, the priming event was either a semantically neutral warning signal (Condition NX), a word semantically related to the target word (Condition R), or a word semantically unrelated to the target word (Condition U); for nonword (N) target trials, the priming event was either the neutral warning signal (Condition NX) or a word prime (Condition WP). For the W target trials, reaction times (RTs) were slower in Condition U than in Condition NX and equally so for all three prime durations; RTs were faster in Condition R than in Condition NX and to a greater degree for the 600- and 2,000-msec prime durations than for the 360-msec prime duration. For the N targets, RTs were faster in Condition WP than in Condition NX and equally so for all prime durations. These results were interpreted within the framework of a two-factor theory of attention proposed by Posner and Snyder (1975a)."
            },
            "slug": "Semantic-priming-and-retrieval-from-lexical-memory:-Neely",
            "title": {
                "fragments": [],
                "text": "Semantic priming and retrieval from lexical memory: Evidence for facilitatory and inhibitory processes"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "These results were interpreted within the framework of a two-factor theory of attention proposed by Posner and Snyder (1975a)."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064181"
                        ],
                        "name": "A. Tversky",
                        "slug": "A.-Tversky",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Tversky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tversky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 469,
                                "start": 404
                            }
                        ],
                        "text": "Landauer & Dumais, 1997), a leading model of the acquisition of semantic knowledge in which the association between words depends on the distance between them in a semantic space, we can compare these two models as a means of examining the implications of different kinds of semantic representation, just as featural and spatial representations have been compared as models of human similarity judgments (Tversky, 1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "Features of similarity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 126
                            }
                        ],
                        "text": "These phenomena are analogues of the phenomena of similarity judgments that are problematic for spatial models of similarity (Tversky, 1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 233
                            }
                        ],
                        "text": "\u2026space, we can compare these two models as a means of examining the implications of different kinds of semantic representation, just as featural and spatial representations have been compared as models of human similarity judgments (Tversky, 1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 31
                            }
                        ],
                        "text": "Appendix B\nTopics and Features\nTversky (1977) considered a number of different models for the similarity between two stimuli, based on the idea of combining common and distinctive features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9173202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f718309706172d6fb1e89f583927274f9a4cdf4f",
            "isKey": true,
            "numCitedBy": 7350,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "The metric and dimensional assumptions that underlie the geometric representation of similarity are questioned on both theoretical and empirical grounds. A new set-theoretical approach to similarity is developed in which objects are represented as collections of features, and similarity is described as a feature-matching process. Specifically, a set of qualitative assumptions is shown to imply the contrast model, which expresses the similarity between objects as a linear combination of the measures of their common and distinctive features. Several predictions of the contrast model are tested in studies of similarity with both semantic and perceptual stimuli. The model is used to uncover, analyze, and explain a variety of empirical phenomena such as the role of common and distinctive features, the relations between judgments of similarity and difference, the presence of asymmetric similarities, and the effects of context on judgments of similarity. The contrast model generalizes standard representations of similarity data in terms of clusters and trees. It is also used to analyze the relations of prototypicality and family resemblance"
            },
            "slug": "Features-of-Similarity-Tversky",
            "title": {
                "fragments": [],
                "text": "Features of Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The metric and dimensional assumptions that underlie the geometric representation of similarity are questioned on both theoretical and empirical grounds and a set of qualitative assumptions are shown to imply the contrast model, which expresses the similarity between objects as a linear combination of the measures of their common and distinctive features."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3345436"
                        ],
                        "name": "S. Sereno",
                        "slug": "S.-Sereno",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Sereno",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sereno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058070532"
                        ],
                        "name": "Patrick J. O'Donnell",
                        "slug": "Patrick-J.-O'Donnell",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "O'Donnell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. O'Donnell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148762"
                        ],
                        "name": "K. Rayner",
                        "slug": "K.-Rayner",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Rayner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rayner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 55
                            }
                        ],
                        "text": "Table 3 Predictions of Models for Reading Time Task of Sereno et al. (1992)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 345,
                                "start": 97
                            }
                        ],
                        "text": "We used the 1,700-topic solution to compute this quantity for the 21 of the 24 sentences used by Sereno et al. (1992) for which all three target words appeared in our vocabulary, and averaged the resulting log probabilities over all sentences. The results are shown in Table 3. The topic model predicts the results found by Sereno et al. (1992): The ambiguous words are assigned lower probabilities than the high-frequency controls, although not quite as low as the low-frequency controls."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 97
                            }
                        ],
                        "text": "We used the 1,700-topic solution to compute this quantity for the 21 of the 24 sentences used by Sereno et al. (1992) for which all three target words appeared in our vocabulary, and averaged the resulting log probabilities over all sentences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1588,
                                "start": 97
                            }
                        ],
                        "text": "We used the 1,700-topic solution to compute this quantity for the 21 of the 24 sentences used by Sereno et al. (1992) for which all three target words appeared in our vocabulary, and averaged the resulting log probabilities over all sentences. The results are shown in Table 3. The topic model predicts the results found by Sereno et al. (1992): The ambiguous words are assigned lower probabilities than the high-frequency controls, although not quite as low as the low-frequency controls. The model predicts this effect because the distribution over topics P(z|wsentence) favors those topics that incorporate the subordinate sense. As a consequence, the probability of the target word is reduced, because P(wtarget|z) is lower for those topics. However, if there is any uncertainty, providing some residual probability to topics in which the target word occurs in its dominant sense, the probability of the ambiguous word will be slightly higher than the raw frequency of the subordinate sense suggests. For comparison, we computed the cosine and inner product for the three values of wtarget and the average vectors for wsentence in the 700-dimensional LSA solution. The results are shown in Table 3. The cosine does not predict this effect, with the highest mean cosines being obtained by the control words, with little effect of frequency. This is due to the fact that the cosine is relatively insensitive to word frequency, as discussed above. The inner product, which is sensitive to word frequency, produces predictions that are consistent with the results of Sereno et al. (1992)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 23199149,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "370ed258e5a6d70908d98fb0013b6939a5c76545",
            "isKey": true,
            "numCitedBy": 98,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent debates on lexical ambiguity resolution have centered on the subordinate-bias effect, in which reading time is longer on a biased ambiguous word in a subordinate-biasing context than on a control word. The nature of the control word--namely, whether it matched the frequency of the ambiguous word's overall word form or its contextually instantiated word meaning (a higher or lower frequency word, respectively)--was examined. In addition, contexts that were singularly supportive of the ambiguous word's subordinate meaning were used. Eye movements were recorded as participants read contextually biasing passages that contained an ambiguous word target or a word-form or word-meaning control. A comparison of fixation times on the 2 control words revealed a significant effect of word frequency. Fixation times on the ambiguous word generally fell between those on the 2 controls and were significantly different than both. Results are discussed in relation to the reordered access model, in which both meaning frequency and prior context affect access procedures."
            },
            "slug": "Eye-movements-and-lexical-ambiguity-resolution:-the-Sereno-O'Donnell",
            "title": {
                "fragments": [],
                "text": "Eye movements and lexical ambiguity resolution: investigating the subordinate-bias effect."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A comparison of fixation times on the 2 control words revealed a significant effect of word frequency, and results are discussed in relation to the reordered access model, in which both meaning frequency and prior context affect access procedures."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46973696"
                        ],
                        "name": "D. Nelson",
                        "slug": "D.-Nelson",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Nelson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50496643"
                        ],
                        "name": "Leilani B. Goodmon",
                        "slug": "Leilani-B.-Goodmon",
                        "structuredName": {
                            "firstName": "Leilani",
                            "lastName": "Goodmon",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leilani B. Goodmon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 194
                            }
                        ],
                        "text": "\u2026Cw have been found to be useful in predicting various phenomena in human memory, including cued recall (Nelson, McKinney, et al., 1998), recognition (Nelson et al., 2001), and priming effects (Nelson & Goodmon, 2002), although this quantity is typically referred to as the \u201cconnectivity\u201d of a word."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 21480723,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6ab4039255f3e1bd3cfbb1cf598b14f70ed98c77",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports the results of manipulations of word features for the magnitude of priming effects. In Experiment 1, the printed frequency of the target words and the number of connections among their associates were varied, and during testing participants were given cues and asked to produce the first word to come to mind as rapidly as possible in implicit free association. Priming effects were greater for low-frequency words and for those with many connections among their associates. In Experiments 2 and 3, target words were presented under incidental or intentional learning conditions during study, and the presence of direct preexisting connections from target to cue and from cue to target was varied. Priming effects were greater when either connection was present, with each connection having additive effects. In Experiments 4 and 5, priming effects for indirect links (shared associates and mediators) were examined. The results of these experiments indicate that priming in free association depends on both the general accessibility of the target as a response and the strengthening of direct target-to-cue connections. These findings raise problems for theories that attribute priming only to target accessibility or only to target-to-cue association."
            },
            "slug": "Experiencing-a-word-can-prime-its-accessibility-and-Nelson-Goodmon",
            "title": {
                "fragments": [],
                "text": "Experiencing a word can prime its accessibility and its associative connections to related words"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The results of manipulations of word features for the magnitude of priming effects indicate that priming in free association depends on both the general accessibility of the target as a response and the strengthening of direct target-to-cue connections."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804885"
                        ],
                        "name": "M. Steyvers",
                        "slug": "M.-Steyvers",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steyvers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steyvers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35018525"
                        ],
                        "name": "K. Malmberg",
                        "slug": "K.-Malmberg",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Malmberg",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Malmberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Steyvers and Malmberg (2003) operationally defined context variability as the number of documents in which a word appears in a large database of text, a measure we refer to as document frequency."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 150
                            }
                        ],
                        "text": "To understand how topic variability compares with word frequency and contextual variability, we performed analyses on the data from the experiment by Steyvers and Malmberg (2003). There were 287 distinct words in the experiment each being used as either a target or a distractor."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 271
                            }
                        ],
                        "text": "\u2026memory has suggested that the number of contexts in which words appear might explain why some words are more likely than others to be confused for items appearing on the study list in recognition memory experiments (Dennis & Humphreys, 2001; McDonald & Shillcock, 2001; Steyvers & Malmberg, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 150
                            }
                        ],
                        "text": "To understand how topic variability compares with word frequency and contextual variability, we performed analyses on the data from the experiment by Steyvers and Malmberg (2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2571728,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "4c828dee053e00800714342e95c51e9f9005956d",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "According to some theories of recognition memory (e.g., S. Dennis & M. S. Humphreys, 2001), the number of different contexts in which words appear determines how memorable individual occurrences of words will be: A word that occurs in a small number of different contexts should be better recognized than a word that appears in a larger number of different contexts. To empirically test this prediction, a normative measure is developed, referred to here as context variability, that estimates the number of different contexts in which words appear in everyday life. These findings confirm the prediction that words low in context variability are better recognized (on average) than words that are high in context variability."
            },
            "slug": "The-effect-of-normative-context-variability-on-Steyvers-Malmberg",
            "title": {
                "fragments": [],
                "text": "The effect of normative context variability on recognition memory."
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A normative measure is developed, referred to here as context variability, that estimates the number of different contexts in which words appear in everyday life and confirms the prediction that words low in context variability are better recognized (on average) than words that are high incontext variability."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Learning, memory, and cognition"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148762"
                        ],
                        "name": "K. Rayner",
                        "slug": "K.-Rayner",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Rayner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rayner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47277215"
                        ],
                        "name": "S. Duffy",
                        "slug": "S.-Duffy",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Duffy",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Duffy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 409,
                                "start": 19
                            }
                        ],
                        "text": ", Duffy, Morris, & Rayner, 1988; Rayner & Duffy, 1986; Rayner & Frazier, 1989). Developing a complete account of how the kind of contextual information we have been discussing influences reading time is beyond the scope of this article. However, we used the topic model to predict the results of one such study, to provide an illustration of how it can be applied to a task of this kind. Sereno et al. (1992) conducted a study in which the eye movements of participants were monitored while they read sentences containing ambiguous words."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 141
                            }
                        ],
                        "text": "In particular, several studies have used reading time to explore the representation of ambiguous words (e.g., Duffy, Morris, & Rayner, 1988; Rayner & Duffy, 1986; Rayner & Frazier, 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34091980,
            "fieldsOfStudy": [
                "Psychology",
                "Linguistics"
            ],
            "id": "3c565c81a1e3f5d6556eedc49fc130ce6f2c5688",
            "isKey": false,
            "numCitedBy": 1026,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "Two experiments investigated whether lexical complexity increases a word\u2019s processing time. Subjects read sentences, each containing a target word, while their eye movements were monitored. In experiment 1, mean fixation time on infrequent words was longer than on their more frequent controls, as was the first fixation after the Infrequent Target. Fixation Times on Causative, factive, and negative verbs and ambiguous nouns were no longer than on their controls. Further analyses on the ambiguous nouns, however, suggested that the likelihood of their various meanings affected fixation time. This factor was investigated in experiment 2. subjects spent a longer time fixating ambiguous words with two equally likely meanings than fixating ambiguous words with one highly likely meaning. The results suggest that verb complexity does not affect lexical access time, and that word frequency And the presence of two highly likely meanings may affect lexical access and/or postaccess integration."
            },
            "slug": "Lexical-complexity-and-fixation-times-in-reading:-Rayner-Duffy",
            "title": {
                "fragments": [],
                "text": "Lexical complexity and fixation times in reading: Effects of word frequency, verb complexity, and lexical ambiguity"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results suggest that verb complexity does not affect lexical access time, and that word frequency and the presence of two highly likely meanings may affect lexicals access and/or postaccess integration."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2804760"
                        ],
                        "name": "C. Brainerd",
                        "slug": "C.-Brainerd",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Brainerd",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Brainerd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48466798"
                        ],
                        "name": "R. Wright",
                        "slug": "R.-Wright",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Wright",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2436806"
                        ],
                        "name": "V. Reyna",
                        "slug": "V.-Reyna",
                        "structuredName": {
                            "firstName": "Valerie",
                            "lastName": "Reyna",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Reyna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50692031"
                        ],
                        "name": "D. G. Payne",
                        "slug": "D.-G.-Payne",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Payne",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G. Payne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 216
                            }
                        ],
                        "text": "These models distinguish between different routes to retrieve information from memory: a verbatim memory route, based on the physical occurrence of an input, and a gist memory route, based on semantic content (e.g., Brainerd et al., 1999, 2002; Mandler, 1980)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 245
                            }
                        ],
                        "text": "The gist-based retrieval process would have to be complemented with a verbatim retrieval process in order to account for the relatively high retrieval probability for words on the study list, as assumed in the dual-route models mentioned above (Brainerd et al., 1999, 2002; Mandler, 1980)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3829229,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "89c3c2f8fea6e16038a91aa95537910e969ee53e",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 104,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent dual-retrieval accounts of free recall postulate that a memory target can be recalled either by directly accessing its verbatim trace or by reconstructing it from semantic or other relational information. We introduce a simple paradigm, derived from the classic Estes RTT procedure, that separates direct access from reconstruction and that separates reconstruction from a metacognitive judgment process that authorizes reconstructed targets for output. Results are reported from four experiments, two that applied the paradigm to free recall and two that extended it to associative recall. The principal findings were that (a) direct access was enhanced by manipulations that made targets' surface forms easier to process or that focused recall on individual targets, (b) reconstruction was enhanced by manipulations that made targets' meaning content easier to process or that focused recall on groups of targets, and (c) such manipulations produced single dissociations, double dissociations, and reversed associations between direct access, reconstruction, and metacognitive judgment. We discuss how this paradigm might be exploited to unify dual-retrieval conceptions of recall and recognition."
            },
            "slug": "Dual-retrieval-processes-in-free-and-associative-Brainerd-Wright",
            "title": {
                "fragments": [],
                "text": "Dual-retrieval processes in free and associative recall."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 29
                            }
                        ],
                        "text": "The basic result reported by Till et al. (1988) was that both of the meanings of the ambiguous word and neither of the inference targets were primed when there was a short delay between sentence presentation and lexical decision, and that there was a subsequent shift to favor the appropriate meaning and inferentially related target when the delay was increased."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 34
                            }
                        ],
                        "text": "This result is similar to that of Tenenbaum and Griffiths (2001), who showed that their Bayesian model of generalization was equivalent to the ratio model."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 6723405,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "caa359864efb289d43afc50f2020cf38dcf6fad2",
            "isKey": false,
            "numCitedBy": 673,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Shepard has argued that a universal law should govern generalization across different domains of perception and cognition, as well as across organisms from different species or even different planets. Starting with some basic assumptions about natural kinds, he derived an exponential decay function as the form of the universal generalization gradient, which accords strikingly well with a wide range of empirical data. However, his original formulation applied only to the ideal case of generalization from a single encountered stimulus to a single novel stimulus, and for stimuli that can be represented as points in a continuous metric psychological space. Here we recast Shepard's theory in a more general Bayesian framework and show how this naturally extends his approach to the more realistic situation of generalizing from multiple consequential stimuli with arbitrary representational structure. Our framework also subsumes a version of Tversky's set-theoretic model of similarity, which is conventionally thought of as the primary alternative to Shepard's continuous metric space model of similarity and generalization. This unification allows us not only to draw deep parallels between the set-theoretic and spatial approaches, but also to significantly advance the explanatory power of set-theoretic models."
            },
            "slug": "Generalization,-similarity,-and-Bayesian-inference.-Tenenbaum-Griffiths",
            "title": {
                "fragments": [],
                "text": "Generalization, similarity, and Bayesian inference."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Here Shepard's theory is recast in a more general Bayesian framework and it is shown how this naturally extends his approach to the more realistic situation of generalizing from multiple consequential stimuli with arbitrary representational structure."
            },
            "venue": {
                "fragments": [],
                "text": "The Behavioral and brain sciences"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144006592"
                        ],
                        "name": "K. A. Ericsson",
                        "slug": "K.-A.-Ericsson",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Ericsson",
                            "middleNames": [
                                "Anders"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. A. Ericsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 244
                            }
                        ],
                        "text": "\u2026interpretation of sentences requires semantic knowledge that goes beyond these contextual associative relationships, many theories still identify this level of knowledge as playing an important role in the early stages of language processing (Ericsson & Kintsch, 1995; Kintsch, 1988; Potter, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 150
                            }
                        ],
                        "text": "One way to do this is to use the semantic context\u2014the gist of a sentence, conversation, or document\u2014to predict related concepts and disambiguate words (Ericsson & Kintsch, 1995; Kintsch, 1988; Potter, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5309157,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "9bb1d22898302da0bbd3eb90bd7e2db106460198",
            "isKey": false,
            "numCitedBy": 2958,
            "numCiting": 186,
            "paperAbstract": {
                "fragments": [],
                "text": "To account for the large demands on working memory during text comprehension and expert performance, the traditional models of working memory involving temporary storage must be extended to include working memory based on storage in long-term memory. In the proposed theoretical framework cognitive processes are viewed as a sequence of stable states representing end products of processing. In skilled activities, acquired memory skills allow these end products to be stored in long-term memory and kept directly accessible by means of retrieval cues in short-term memory, as proposed by skilled memory theory. These theoretical claims are supported by a review of evidence on memory in text comprehension and expert performance in such domains as mental calculation, medical diagnosis, and chess."
            },
            "slug": "Long-term-working-memory.-Ericsson-Kintsch",
            "title": {
                "fragments": [],
                "text": "Long-term working memory."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "To account for the large demands on working memory during text comprehension and expert performance, the traditional models of working memory involving temporary storage must be extended to include working memory based on storage in long-term memory."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398315116"
                        ],
                        "name": "M. Rosen-Zvi",
                        "slug": "M.-Rosen-Zvi",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Rosen-Zvi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosen-Zvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804885"
                        ],
                        "name": "M. Steyvers",
                        "slug": "M.-Steyvers",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steyvers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steyvers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50860274"
                        ],
                        "name": "Padhraic Smyth",
                        "slug": "Padhraic-Smyth",
                        "structuredName": {
                            "firstName": "Padhraic",
                            "lastName": "Smyth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Padhraic Smyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1997763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6436dce0e39f15a1ca9269e6ca813dfebb0af3a2",
            "isKey": false,
            "numCitedBy": 1584,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the author-topic model, a generative model for documents that extends Latent Dirichlet Allocation (LDA; Blei, Ng, & Jordan, 2003) to include authorship information. Each author is associated with a multinomial distribution over topics and each topic is associated with a multinomial distribution over words. A document with multiple authors is modeled as a distribution over topics that is a mixture of the distributions associated with the authors. We apply the model to a collection of 1,700 NIPS conference papers and 160,000 CiteSeer abstracts. Exact inference is intractable for these datasets and we use Gibbs sampling to estimate the topic and author distributions. We compare the performance with two other generative models for documents, which are special cases of the author-topic model: LDA (a topic model) and a simple author model in which each author is associated with a distribution over words rather than a distribution over topics. We show topics recovered by the author-topic model, and demonstrate applications to computing similarity between authors and entropy of author output."
            },
            "slug": "The-Author-Topic-Model-for-Authors-and-Documents-Rosen-Zvi-Griffiths",
            "title": {
                "fragments": [],
                "text": "The Author-Topic Model for Authors and Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The author-topic model is introduced, a generative model for documents that extends Latent Dirichlet Allocation to include authorship information, and applications to computing similarity between authors and entropy of author output are demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143772984"
                        ],
                        "name": "G. Davidson",
                        "slug": "G.-Davidson",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Davidson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Davidson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Steyvers and Tenenbaum (2005) conducted similar analyses using Rogets Thesaurus (Roget, 1911) and the WordNet lexical database (Miller & Fellbaum, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58373740,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "79f35f583ce9910d7dc5a0127d257574c60a41cb",
            "isKey": false,
            "numCitedBy": 380,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "\"Roget's Thesaurus\" is the world's most famous and trusted word-finder. First published in 1852, it has now sold over 32 million copies worldwide and has become the indispensable desk companion for generations of speakers and writers of English. Unlike most other thesauruses, it groups words thematically rather than in a straight A-Z sequence, thus offering the writer and speaker a much more creative and subtle means of finding new ways to express their thoughts: it is essential for anyone who wants to improve their command, creative use and enjoyment of English, and is perfect for composing speeches, or for writing all manner of prose and poetry. It remains, definitively, a writer's best friend. \"Roget's Thesaurus\" is part of the Penguin Reference Library and draws on over 70 years of experience in bringing reliable, useful and clear information to millions of readers around the world - making knowledge everybody's property."
            },
            "slug": "Roget's-Thesaurus-of-English-Words-and-Phrases-Davidson",
            "title": {
                "fragments": [],
                "text": "Roget's Thesaurus of English Words and Phrases"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "\"Roget's Thesaurus\" is the world's most famous and trusted word-finder, essential for anyone who wants to improve their command, creative use and enjoyment of English, and is perfect for composing speeches, or for writing all manner of prose and poetry."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 158
                            }
                        ],
                        "text": "\u2026such as inductive inferences about the properties of categories (Kemp, Perfors, & Tenenbaum, 2004), predictions about the durations or magnitudes of events (Griffiths & Tenenbaum, 2006), and inferences about hidden common causes from patterns of coincidence (Griffiths & Tenenbaum, in press)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 161
                            }
                        ],
                        "text": "\u2026of human intelligence as rational adaptations to the statistical structure of the environment (Anderson, 1990; Anderson & Schooler, 1991; Geisler et al., 2001; Griffiths & Tenenbaum, 2006, in press; Kemp et al., 2004; Ko\u0308rding & Wolpert, 2004; Simoncelli & Olshausen, 2001; Wolpert et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12834830,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "53bb2ab17b18a5b8ab27223a19327481b0428fb3",
            "isKey": false,
            "numCitedBy": 467,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Human perception and memory are often explained as optimal statistical inferences that are informed by accurate prior probabilities. In contrast, cognitive judgments are usually viewed as following error-prone heuristics that are insensitive to priors. We examined the optimality of human cognition in a more realistic context than typical laboratory studies, asking people to make predictions about the duration or extent of everyday phenomena such as human life spans and the box-office take of movies. Our results suggest that everyday cognitive judgments follow the same optimal statistical principles as perception and memory, and reveal a close correspondence between people's implicit probabilistic models and the statistics of the world."
            },
            "slug": "Optimal-Predictions-in-Everyday-Cognition-Griffiths-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "Optimal Predictions in Everyday Cognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work examined the optimality of human cognition in a more realistic context than typical laboratory studies, asking people to make predictions about the duration or extent of everyday phenomena such as human life spans and the box-office take of movies."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological science"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701656"
                        ],
                        "name": "James L. McClelland",
                        "slug": "James-L.-McClelland",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McClelland",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. McClelland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 227
                            }
                        ],
                        "text": "Most computational approaches to natural language have tended to focus exclusively on either structured representations (e.g., Chomsky, 1965; Pinker, 1999) or sta-\ntistical learning (e.g., Elman, 1990; Plunkett & Marchman, 1993; Rumelhart & McClelland, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15291527,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff2c2e3e83d1e8828695484728393c76ee07a101",
            "isKey": false,
            "numCitedBy": 15710,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The fundamental principles, basic mechanisms, and formal analyses involved in the development of parallel distributed processing (PDP) systems are presented in individual chapters contributed by leading experts. Topics examined include distributed representations, PDP models and general issues in cognitive science, feature discovery by competitive learning, the foundations of harmony theory, learning and relearning in Boltzmann machines, and learning internal representations by error propagation. Consideration is given to linear algebra in PDP, the logic of additive functions, resource requirements of standard and programmable nets, and the P3 parallel-network simulating system."
            },
            "slug": "Parallel-distributed-processing:-explorations-in-of-Rumelhart-McClelland",
            "title": {
                "fragments": [],
                "text": "Parallel distributed processing: explorations in the microstructure of cognition, vol. 1: foundations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2327242"
                        ],
                        "name": "C. McEvoy",
                        "slug": "C.-McEvoy",
                        "structuredName": {
                            "firstName": "Cathy",
                            "lastName": "McEvoy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. McEvoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46973696"
                        ],
                        "name": "D. Nelson",
                        "slug": "D.-Nelson",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Nelson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116808153"
                        ],
                        "name": "T. Komatsu",
                        "slug": "T.-Komatsu",
                        "structuredName": {
                            "firstName": "Takehiro",
                            "lastName": "Komatsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Komatsu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 254
                            }
                        ],
                        "text": "\u2026and statistics derived from these norms have been shown to be important in predicting cued recall (Nelson, McKinney, Gee, & Janczura, 1998), recognition (Nelson, McKinney, et al., 1998; Nelson, Zhang, & McKinney, 2001), and false memories (Deese, 1959; McEvoy et al., 1999; Roediger et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 40354936,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "50df2ce5b9bc8440ff9d82424e439462fd93cb6a",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Veridical memory for presented list words and false memory for nonpresented but related items were tested using the Deese/Roediger and McDermott paradigm. The strength and density of preexisting connections among the list words, and from the list words to the critical items, were manipulated. The likelihood of producing false memories in free recall varied with the strength of connections from the list words to the critical items but was inversely related to the density of the interconnections among the list words. In contrast, veridical recall of list words was positively related to the density of the interconnections. A final recognition test showed that both false and veridical memories were more likely when the list words were more densely interconnected. The results are discussed in terms of an associative model of memory, Processing Implicit and Explicit Representations (PIER 2) that describes the influence of implicitly activated preexisting information on memory performance."
            },
            "slug": "What-is-the-connection-between-true-and-false-The-McEvoy-Nelson",
            "title": {
                "fragments": [],
                "text": "What is the connection between true and false memories? The differential roles of interitem associations in recall and recognition."
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An associative model of memory, Processing Implicit and Explicit Representations (PIER 2) that describes the influence of implicitly activated preexisting information on memory performance, showed that both false and veridical memories were more likely when the list words were more densely interconnected."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Learning, memory, and cognition"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114531657"
                        ],
                        "name": "Noam Chomsky",
                        "slug": "Noam-Chomsky",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Chomsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam Chomsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 127
                            }
                        ],
                        "text": "Most computational approaches to natural language have tended to focus exclusively on either structured representations (e.g., Chomsky, 1965; Pinker, 1999) or sta-\ntistical learning (e.g., Elman, 1990; Plunkett & Marchman, 1993; Rumelhart & McClelland, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Most computational approaches to natural language have tended to focus exclusively on either structured representations (eg, Chomsky, 1965; Pinker, 1999) or statistical learning (eg, Elman, 1990; Plunkett & Marchman, 1993; Rumelhart & McClelland, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12867884,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "16c762445f11fa2020994918dc4f93e76264df17",
            "isKey": false,
            "numCitedBy": 14181,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Contents: Methodological preliminaries: Generative grammars as theories of linguistic competence; theory of performance; organization of a generative grammar; justification of grammars; formal and substantive grammars; descriptive and explanatory theories; evaluation procedures; linguistic theory and language learning; generative capacity and its linguistic relevance Categories and relations in syntactic theory: Scope of the base; aspects of deep structure; illustrative fragment of the base component; types of base rules Deep structures and grammatical transformations Residual problems: Boundaries of syntax and semantics; structure of the lexicon"
            },
            "slug": "\u0935\u093e\u0915\u094d\u092f\u0935\u093f\u0928\u094d\u092f\u093e\u0938-\u0915\u093e-\u0938\u0948\u0926\u094d\u0927\u093e\u0928\u094d\u0924\u093f\u0915-\u092a\u0915\u094d\u0937-=-Aspects-of-the-Chomsky",
            "title": {
                "fragments": [],
                "text": "\u0935\u093e\u0915\u094d\u092f\u0935\u093f\u0928\u094d\u092f\u093e\u0938 \u0915\u093e \u0938\u0948\u0926\u094d\u0927\u093e\u0928\u094d\u0924\u093f\u0915 \u092a\u0915\u094d\u0937 = Aspects of the theory of syntax"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "Methodological preliminaries of generative grammars as theories of linguistic competence; theory of performance; organization of a generative grammar; justification of grammar; descriptive and explanatory theories; evaluation procedures; linguistic theory and language learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158597261"
                        ],
                        "name": "John R. Anderson",
                        "slug": "John-R.-Anderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Anderson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John R. Anderson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 86
                            }
                        ],
                        "text": "These methods are closely related to the rational model of categorization proposed by Anderson (1990), which represents categories in terms of a set of clusters, with new clusters added automatically as more data become available (see Neal, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 149
                            }
                        ],
                        "text": "\u2026offer a unifying framework for understanding aspects of human intelligence as rational adaptations to the statistical structure of the environment (Anderson, 1990; Anderson & Schooler, 1991; Geisler et al., 2001; Griffiths & Tenenbaum, 2006, in press; Kemp et al., 2004; Ko\u0308rding & Wolpert, 2004;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 457,
                                "start": 257
                            }
                        ],
                        "text": "Across many areas of cognition, perception, and action, probabilistic generative models have recently come to offer a unifying framework for understanding aspects of human intelligence as rational adaptations to the statistical structure of the environment (Anderson, 1990; Anderson & Schooler, 1991; Geisler et al., 2001; Griffiths & Tenenbaum, 2006, in press; Kemp et al., 2004; K\u00f6rding & Wolpert, 2004; Simoncelli & Olshausen, 2001; Wolpert et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 142
                            }
                        ],
                        "text": "Our approach is motivated by an analysis of some of the computational problems addressed by semantic memory, in the spirit of Marr (1982) and Anderson (1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 262
                            }
                        ],
                        "text": "Keywords: probabilistic models, Bayesian models, semantic memory, semantic representation, computational models\nMany aspects of perception and cognition can be understood by considering the computational problem that is addressed by a particular human capacity (Anderson, 1990; Marr, 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 169
                            }
                        ],
                        "text": "Cognitive capacities such as memory and categorization can be seen as systems for efficiently making predictions about the properties of an organism\u2019s environment (e.g., Anderson, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 149
                            }
                        ],
                        "text": "Many aspects of perception and cognition can be understood by considering the computational problem that is addressed by a particular human capacity (Anderson, 1990; Marr, 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 145600408,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33025edfa79cc676cd0126ba4c481f6bbac0a3b8",
            "isKey": true,
            "numCitedBy": 1624,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Contents: Part I:Introduction. Preliminaries. Levels of a Cognitive Theory. Current Formulation of the Levels Issues. The New Theoretical Framework. Is Human Cognition Rational? The Rest of This Book. Appendix: Non-Identifiability and Response Time. Part II:Memory. Preliminaries. A Rational Analysis of Human Memory. The History Factor. The Contextual Factor. Relationship of Need and Probability to Probability and Latency of Recall. Combining Information From Cues. Implementation in the ACT Framework. Effects of Subject Strategy. Conclusions. Part III:Categorization. Preliminaries. The Goal of Categorization. The Structure of the Environment. Recapitulation of Goals and Environment. The Optimal Solution. An Iterative Algorithm for Categorization. Application of the Algorithm. Survey of the Experimental Literature. Conclusion. Appendix: The Ideal Algorithm. Part IV:Causal Inference. Preliminaries. Basic Formulation of the Causal Inference Problem. Causal Estimation. Cues for Causal Inference. Integration of Statistical and Temporal Cues. Discrimination. Abstraction of Causal Laws. Implementation in a Production System. Conclusion. Appendix. Part V:Problem Solving. Preliminaries. Making a Choice Among Simple Actions. Combining Steps. Studies of Hill Climbing. Means-Ends Analysis. Instantiation of Indefinite Objects. Conclusions on Rational Analysis of Problem Solving. Implementation in ACT. Appendix: Problem Solving and Clotheslines. Part VI:Retrospective. Preliminaries. Twelve Questions About Rational Analysis."
            },
            "slug": "The-Adaptive-Character-of-Thought-Anderson",
            "title": {
                "fragments": [],
                "text": "The Adaptive Character of Thought"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158597261"
                        ],
                        "name": "John R. Anderson",
                        "slug": "John-R.-Anderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Anderson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John R. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1985440"
                        ],
                        "name": "L. Schooler",
                        "slug": "L.-Schooler",
                        "structuredName": {
                            "firstName": "Lael",
                            "lastName": "Schooler",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Schooler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 272
                            }
                        ],
                        "text": "\u2026subtle aspects of human vision can be explained in terms of the statistics of natural scenes (Geisler, Perry, Super, & Gallogly, 2001; Simoncelli & Olshausen, 2001), and human memory seems to be tuned to the probabilities with which particular events occur in the world (Anderson & Schooler, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 148
                            }
                        ],
                        "text": "\u2026framework for understanding aspects of human intelligence as rational adaptations to the statistical structure of the environment (Anderson, 1990; Anderson & Schooler, 1991; Geisler et al., 2001; Griffiths & Tenenbaum, 2006, in press; Kemp et al., 2004; Ko\u0308rding & Wolpert, 2004; Simoncelli &\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8511110,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6b2e11d45e5592b55d522310f6c9c6198f76daaf",
            "isKey": false,
            "numCitedBy": 1019,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Availability of human memories for specific items shows reliable relationships to frequency, recency, and pattern of prior exposures to the item. These relationships have defied a systematic theoretical treatment. A number of environmental sources (New York Times, parental speech, electronic mail) are examined to show that the probability that a memory will be needed also shows reliable relationships to frequency, recency, and pattern of prior exposures. Moreover, the environmental relationships are the same as the memory relationships. It is argued that human memory has the form it does because it is adapted to these environmental relationships. Models for both the environment and human memory are described. Among the memory phenomena addressed are the practice function, the retention function, the effect of spacing of practice, and the relationship between degree of practice and retention."
            },
            "slug": "Reflections-of-the-Environment-in-Memory-Anderson-Schooler",
            "title": {
                "fragments": [],
                "text": "Reflections of the Environment in Memory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773821"
                        ],
                        "name": "Matthew J. Beal",
                        "slug": "Matthew-J.-Beal",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Beal",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew J. Beal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7934949,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "b90d922ff07d0eb8d77b8687aba7f55bd3926436",
            "isKey": false,
            "numCitedBy": 3577,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider problems involving groups of data where each observation within a group is a draw from a mixture model and where it is desirable to share mixture components between groups. We assume that the number of mixture components is unknown a priori and is to be inferred from the data. In this setting it is natural to consider sets of Dirichlet processes, one for each group, where the well-known clustering property of the Dirichlet process provides a nonparametric prior for the number of mixture components within each group. Given our desire to tie the mixture models in the various groups, we consider a hierarchical model, specifically one in which the base measure for the child Dirichlet processes is itself distributed according to a Dirichlet process. Such a base measure being discrete, the child Dirichlet processes necessarily share atoms. Thus, as desired, the mixture models in the different groups necessarily share mixture components. We discuss representations of hierarchical Dirichlet processes in terms of a stick-breaking process, and a generalization of the Chinese restaurant process that we refer to as the \u201cChinese restaurant franchise.\u201d We present Markov chain Monte Carlo algorithms for posterior inference in hierarchical Dirichlet process mixtures and describe applications to problems in information retrieval and text modeling."
            },
            "slug": "Hierarchical-Dirichlet-Processes-Teh-Jordan",
            "title": {
                "fragments": [],
                "text": "Hierarchical Dirichlet Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This work considers problems involving groups of data where each observation within a group is a draw from a mixture model and where it is desirable to share mixture components between groups, and considers a hierarchical model, specifically one in which the base measure for the childDirichlet processes is itself distributed according to a Dirichlet process."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14423895,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "399e552c79934f3b1056a252226cc3dcf0c37f13",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "From-mere-coincidences-to-meaningful-discoveries-Griffiths-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "From mere coincidences to meaningful discoveries"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944906"
                        ],
                        "name": "M. Potter",
                        "slug": "M.-Potter",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Potter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Potter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 285
                            }
                        ],
                        "text": "\u2026interpretation of sentences requires semantic knowledge that goes beyond these contextual associative relationships, many theories still identify this level of knowledge as playing an important role in the early stages of language processing (Ericsson & Kintsch, 1995; Kintsch, 1988; Potter, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 310,
                                "start": 255
                            }
                        ],
                        "text": "Although the interpretation of sentences requires semantic knowledge that goes beyond these contextual associative relationships, many theories still identify this level of knowledge as playing an important role in the early stages of language processing (Ericsson & Kintsch, 1995; Kintsch, 1988; Potter, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 191
                            }
                        ],
                        "text": "One way to do this is to use the semantic context\u2014the gist of a sentence, conversation, or document\u2014to predict related concepts and disambiguate words (Ericsson & Kintsch, 1995; Kintsch, 1988; Potter, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16790561,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "4dd6067fff567576034c84e424bb69a9a3dd0d9c",
            "isKey": false,
            "numCitedBy": 275,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Short-term memory for conceptual information is largely missing from current models of short-term memory. Several phenomena are discussed that give evidence for very brief conceptual representations of stimuli. Although these fleeting representations do not surface readily with many of the standard methods for studying and testing short-term memory, I argue that they are fundamental to cognitive processing and to the form that long-term memory takes."
            },
            "slug": "Very-short-term-conceptual-memory-Potter",
            "title": {
                "fragments": [],
                "text": "Very short-term conceptual memory"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is argued that very brief conceptual representations of stimuli are fundamental to cognitive processing and to the form that long-term memory takes."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70219052"
                        ],
                        "name": "Wray L. Buntine",
                        "slug": "Wray-L.-Buntine",
                        "structuredName": {
                            "firstName": "Wray",
                            "lastName": "Buntine",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wray L. Buntine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2962063"
                        ],
                        "name": "Aleks Jakulin",
                        "slug": "Aleks-Jakulin",
                        "structuredName": {
                            "firstName": "Aleks",
                            "lastName": "Jakulin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aleks Jakulin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 184
                            }
                        ],
                        "text": "\u20261999), variational expectation maximization (Blei et al., 2003; Buntine, 2002), ex-\npectation propagation (Minka & Lafferty, 2002), and several forms of Markov chain Monte Carlo (MCMC; Buntine & Jakulin, 2004; Erosheva, 2002; Griffiths & Steyvers, 2002, 2003, 2004; Pritchard et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1082260,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5874d7079cea119f56a5de12a7ff56f1e30f2056",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Methods for analysis of principal components in discrete data have existed for some time under various names such as grade of membership modelling, probabilistic latent semantic analysis, and genotype inference with admixture. In this paper we explore a number of extensions to the common theory, and present some application of these methods to some common statistical tasks. We show that these methods can be interpreted as a discrete version of ICA. We develop a hierarchical version yielding components at different levels of detail, and additional techniques for Gibbs sampling. We compare the algorithms on a text prediction task using support vector machines, and to information retrieval."
            },
            "slug": "Applying-Discrete-PCA-in-Data-Analysis-Buntine-Jakulin",
            "title": {
                "fragments": [],
                "text": "Applying Discrete PCA in Data Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A hierarchical version of these methods for analysis of principal components in discrete data can be interpreted as a discrete version of ICA, and a hierarchical version yielding components at different levels of detail is developed."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2966196"
                        ],
                        "name": "W. Geisler",
                        "slug": "W.-Geisler",
                        "structuredName": {
                            "firstName": "Wilson",
                            "lastName": "Geisler",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Geisler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16656212"
                        ],
                        "name": "J. Perry",
                        "slug": "J.-Perry",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Perry",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Perry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3221174"
                        ],
                        "name": "B. Super",
                        "slug": "B.-Super",
                        "structuredName": {
                            "firstName": "Boaz",
                            "lastName": "Super",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Super"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4536179"
                        ],
                        "name": "D. P. Gallogly",
                        "slug": "D.-P.-Gallogly",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Gallogly",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. P. Gallogly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 147
                            }
                        ],
                        "text": "\u2026aspects of human intelligence as rational adaptations to the statistical structure of the environment (Anderson, 1990; Anderson & Schooler, 1991; Geisler et al., 2001; Griffiths & Tenenbaum, 2006, in press; Kemp et al., 2004; Ko\u0308rding & Wolpert, 2004; Simoncelli & Olshausen, 2001; Wolpert et\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 457,
                                "start": 257
                            }
                        ],
                        "text": "Across many areas of cognition, perception, and action, probabilistic generative models have recently come to offer a unifying framework for understanding aspects of human intelligence as rational adaptations to the statistical structure of the environment (Anderson, 1990; Anderson & Schooler, 1991; Geisler et al., 2001; Griffiths & Tenenbaum, 2006, in press; Kemp et al., 2004; K\u00f6rding & Wolpert, 2004; Simoncelli & Olshausen, 2001; Wolpert et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2362588,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "5777e5fb5d0c00aa9e6a8edc8893f174486a235d",
            "isKey": false,
            "numCitedBy": 653,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Edge-co-occurrence-in-natural-images-predicts-Geisler-Perry",
            "title": {
                "fragments": [],
                "text": "Edge co-occurrence in natural images predicts contour grouping performance"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70219052"
                        ],
                        "name": "Wray L. Buntine",
                        "slug": "Wray-L.-Buntine",
                        "structuredName": {
                            "firstName": "Wray",
                            "lastName": "Buntine",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wray L. Buntine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Buntine (2002) pointed out a formal correspondence between topic models and principalcomponents analysis, providing a further connection to LSA."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 150
                            }
                        ],
                        "text": "\u2026have been proposed for learning topics, including expectation maximization (Hofmann, 1999), variational expectation maximization (Blei et al., 2003; Buntine, 2002), ex-\npectation propagation (Minka & Lafferty, 2002), and several forms of Markov chain Monte Carlo (MCMC; Buntine & Jakulin, 2004;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17061190,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b0fc7cc73d8eee153a3ec1f6da32a909fdf7163",
            "isKey": false,
            "numCitedBy": 199,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Several authors in recent years have proposed discrete analogues to principle component analysis intended to handle discrete or positive only data, for instance suited to analyzing sets of documents. Methods include non-negative matrix factorization, probabilistic latent semantic analysis, and latent Dirichlet allocation. This paper begins with a review of the basic theory of the variational extension to the expectation-maximization algorithm, and then presents discrete component finding algorithms in that light. Experiments are conducted on both bigram word data and document bag-of-word to expose some of the subtleties of this new class of algorithms."
            },
            "slug": "Variational-Extensions-to-EM-and-Multinomial-PCA-Buntine",
            "title": {
                "fragments": [],
                "text": "Variational Extensions to EM and Multinomial PCA"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper begins with a review of the basic theory of the variational extension to the expectation-maximization algorithm, and then presents discrete component finding algorithms in that light."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46973696"
                        ],
                        "name": "D. Nelson",
                        "slug": "D.-Nelson",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Nelson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2327242"
                        ],
                        "name": "C. McEvoy",
                        "slug": "C.-McEvoy",
                        "structuredName": {
                            "firstName": "Cathy",
                            "lastName": "McEvoy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. McEvoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50582151"
                        ],
                        "name": "S. Dennis",
                        "slug": "S.-Dennis",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Dennis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dennis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 499,
                                "start": 22
                            }
                        ],
                        "text": ", 1998), recognition (Nelson et al., 2001), and priming effects (Nelson & Goodmon, 2002), although this quantity is typically referred to as the \u201cconnectivity\u201d of a word. Power-law degree distributions in semantic networks are significant because they indicate that some words have extremely large numbers of neighbors. In particular, the power law in in-degree indicates that there are a small number of words that appear as associates for a great variety of cues. As Steyvers and Tenenbaum (2005) pointed out, this kind of phenomenon is difficult to reproduce in a spatial representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 21478549,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1de2bda52d950facdb99c1f6b54a21ea89e82d52",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports the results of a study of free association in which participants were asked to produce the first two words to come to mind. The findings were used to estimate the reliability of indices of strength and set size for different types of items and to model free association as a retrieval task. When confined to first responses, reliability was generally high for both indices, particularly for words with smaller sets of associates and stronger primaries. When second responses were included, reliability declined. A second response added new but weak items to the set, and, when the primary associate was not produced on the first opportunity, it tended not to be produced on the second. Relative to when multiple responses are requested, first-response free association provides more reliable indices of the relative strength and set size for a word\u2019s strongest associates. A model of free association assuming that a strength distribution underlies each response provided a good fit to the data."
            },
            "slug": "What-is-free-association-and-what-does-it-measure-Nelson-McEvoy",
            "title": {
                "fragments": [],
                "text": "What is free association and what does it measure?"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "First-response free association provides more reliable indices of the relative strength and set size for a word\u2019s strongest associates, particularly for words with smaller sets of associates and stronger primaries."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1962505"
                        ],
                        "name": "W. Batchelder",
                        "slug": "W.-Batchelder",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Batchelder",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Batchelder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5407709"
                        ],
                        "name": "David M. Riefer",
                        "slug": "David-M.-Riefer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Riefer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Riefer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 196
                            }
                        ],
                        "text": "Computational modeling in this domain has been mostly concerned with the estimation of the relative strength of different memory routes within the framework of multinomial processing tree models (Batchelder & Riefer, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28396197,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c9a97df68c378cb0f833d3345b3e900b19bb594b",
            "isKey": false,
            "numCitedBy": 518,
            "numCiting": 192,
            "paperAbstract": {
                "fragments": [],
                "text": "We review a current and popular class of cognitive models calledmultinomial processing tree (MPT) models. MPT models are simple, substantively motivated statistical models that can be applied to categorical data. They are useful as data-analysis tools for measuring underlying or latent cognitive capacities and as simple models for representing and testing competing psychological theories. We formally describe the cognitive structure and parametric properties of the class of MPT models and provide an inferential statistical analysis for the entire class. Following this, we provide a comprehensive review of over 80 applications of MPT models to a variety of substantive areas in cognitive psychology, including various types of human memory, visual and auditory perception, and logical reasoning. We then address a number of theoretical issues relevant to the creation and evaluation of MPT models, including model development, model validity, discrete-state assumptions, statistical issues, and the relation between MPT models and other mathematical models. In the conclusion, we consider the current role of MPT models in psychological research and possible future directions."
            },
            "slug": "Theoretical-and-empirical-review-of-multinomial-Batchelder-Riefer",
            "title": {
                "fragments": [],
                "text": "Theoretical and empirical review of multinomial process tree modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A comprehensive review of over 80 applications of MPT models to a variety of substantive areas in cognitive psychology, including various types of human memory, visual and auditory perception, and logical reasoning is provided."
            },
            "venue": {
                "fragments": [],
                "text": "Psychonomic bulletin & review"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 61
                            }
                        ],
                        "text": "Perceptual capacities such as identifying shape from shading (Freeman, 1994), motion perception (Weiss, Adelson, & Simoncelli, 2002), and sensorimotor integration (Wolpert, Ghahramani, & Jordan, 1995; Koerding & Wolpert, 2004) appear to closely approximate optimal statistical inferences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 62
                            }
                        ],
                        "text": "Perceptual capacities such as identifying shape from shading (Freeman, 1994), motion perception (Weiss, Simoncelli, & Adelson, 2002), and sensorimotor integration (Ko\u0308rding & Wolpert, 2004; Wolpert, Ghahramani, & Jordan, 1995) appear to closely approximate optimal statistical inferences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4251957,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06d7c8dbd23aaf6ac8c758d43705657c289a756e",
            "isKey": false,
            "numCitedBy": 216,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A VISUAL system makes assumptions in order to interpret visual data. The assumption of 'generic view'1\u20134 states that the observer is not in a special position relative to the scene. Researchers commonly use a binary decision of generic or accidental view to disqualify scene interpretations that assume accidental viewpoints5\u201310. Here we show how to use the generic view assumption, and others like it, to quantify the likelihood of a view, adding a new term to the probability of a given image interpretation. The resulting framework better models the visual world and reduces the reliance on other prior assumptions. It may lead to computer vision algorithms of greater power and accuracy, or to better models of human vision. We show applications to the problems of inferring shape, surface reflectance properties, and motion from images."
            },
            "slug": "The-generic-viewpoint-assumption-in-a-framework-for-Freeman",
            "title": {
                "fragments": [],
                "text": "The generic viewpoint assumption in a framework for visual perception"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The generic view assumption is used to quantify the likelihood of a view, adding a new term to the probability of a given image interpretation, which better models the visual world and reduces the reliance on other prior assumptions."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735221"
                        ],
                        "name": "N. Ueda",
                        "slug": "N.-Ueda",
                        "structuredName": {
                            "firstName": "Naonori",
                            "lastName": "Ueda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ueda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727070"
                        ],
                        "name": "Kazumi Saito",
                        "slug": "Kazumi-Saito",
                        "structuredName": {
                            "firstName": "Kazumi",
                            "lastName": "Saito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazumi Saito"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 277
                            }
                        ],
                        "text": "\u2026in information retrieval and statistical natural language processing, with different models making different assumptions about the origins of the distribution over topics (e.g., Bigi, De Mori, El-Beze, & Spriet, 1997; Blei et al., 2003; Hofmann, 1999; Iyer & Ostendorf, 1999; Ueda & Saito, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Ueda and Saito (2003) explored a similar model, in which documents are balanced mixtures of a small set of topics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7323448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5388a48970e0fbea9dfcb23b607578e95537da6",
            "isKey": false,
            "numCitedBy": 349,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose probabilistic generative models, called parametric mixture models (PMMs), for multiclass, multi-labeled text categorization problem. Conventionally, the binary classification approach has been employed, in which whether or not text belongs to a category is judged by the binary classifier for every category. In contrast, our approach can simultaneously detect multiple categories of text using PMMs. We derive efficient learning and prediction algorithms for PMMs. We also empirically show that our method could significantly outperform the conventional binary methods when applied to multi-labeled text categorization using real World Wide Web pages."
            },
            "slug": "Parametric-Mixture-Models-for-Multi-Labeled-Text-Ueda-Saito",
            "title": {
                "fragments": [],
                "text": "Parametric Mixture Models for Multi-Labeled Text"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "It is shown that the proposed probabilistic generative models, called parametric mixture models (PMMs), could significantly outperform the conventional binary methods when applied to multi-labeled text categorization using real World Wide Web pages."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057448868"
                        ],
                        "name": "C. J. Brainerd",
                        "slug": "C.-J.-Brainerd",
                        "structuredName": {
                            "firstName": "C",
                            "lastName": "Brainerd",
                            "middleNames": [
                                "J"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Brainerd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2436806"
                        ],
                        "name": "V. Reyna",
                        "slug": "V.-Reyna",
                        "structuredName": {
                            "firstName": "Valerie",
                            "lastName": "Reyna",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Reyna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4678548"
                        ],
                        "name": "A. H. Mojard\u00edn",
                        "slug": "A.-H.-Mojard\u00edn",
                        "structuredName": {
                            "firstName": "Ambrocio",
                            "lastName": "Mojard\u00edn",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. H. Mojard\u00edn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 216
                            }
                        ],
                        "text": "These models distinguish between different routes to retrieve information from memory: a verbatim memory route, based on the physical occurrence of an input, and a gist memory route, based on semantic content (e.g., Brainerd et al., 1999, 2002; Mandler, 1980)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 245
                            }
                        ],
                        "text": "The gist-based retrieval process would have to be complemented with a verbatim retrieval process in order to account for the relatively high retrieval probability for words on the study list, as assumed in the dual-route models mentioned above (Brainerd et al., 1999, 2002; Mandler, 1980)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 36073472,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "818db735e07519c852c82ee2c570278828c5d453",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The process-dissociation model has stimulated important advances in the study of dual-process conceptions of memory. The authors review some limiting properties of that model and consider the degree of support for its parent theory (the recollection-familiarity distinction). A 2nd-generation model (conjoint recognition) is proposed that addresses these limitations and supplies additional capabilities, such as goodness-of-fit tests, the ability to measure dual processes for false-memory responses, and statistical procedures for testing within- and between-conditions hypotheses about its parameters. The conjoint-recognition model also implements an alternative theoretical interpretation (the identity-similarity distinction of fuzzy-trace theory). Worked applications to data are provided."
            },
            "slug": "Conjoint-recognition.-Brainerd-Reyna",
            "title": {
                "fragments": [],
                "text": "Conjoint recognition."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A 2nd-generation model (conjoint recognition) is proposed that addresses limitations of the process-dissociation model and supplies additional capabilities, such as goodness-of-fit tests, the ability to measure dual processes for false-memory responses, and statistical procedures for testing within- and between-conditions hypotheses about its parameters."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054882"
                        ],
                        "name": "S. Yantis",
                        "slug": "S.-Yantis",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Yantis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yantis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30524996"
                        ],
                        "name": "D. Meyer",
                        "slug": "D.-Meyer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Meyer",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Meyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153015954"
                        ],
                        "name": "J. E. Smith",
                        "slug": "J.-E.-Smith",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Smith",
                            "middleNames": [
                                "E.",
                                "Keith"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. E. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12361890,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2b625826a0bcb3a12fabbf8fbbccae154532627c",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Mixture distributions are formed from a weighted linear combination of 2 or more underlying basis distributions [g(x) = sigma j alpha j fj(x); sigma alpha j = 1]. They arise frequently in stochastic models of perception, cognition, and action in which a finite number of discrete internal states are entered probabilistically over a series of trials. This article reviews various distributional properties that have been examined to test for the presence of mixture distributions. A new multinomial maximum likelihood mixture (MMLM) analysis is discussed for estimating the mixing probabilities alpha j and the basis distributions fj(x) of a hypothesized mixture distribution. The analysis also generates a maximum likelihood goodness-of-fit statistic for testing various mixture hypotheses. Stochastic computer simulations characterize the statistical power of such tests under representative conditions. Two empirical studies of mental processes hypothesized to involve mixture distributions are summarized to illustrate applications of the MMLM analysis."
            },
            "slug": "Analyses-of-multinomial-mixture-distributions:-new-Yantis-Meyer",
            "title": {
                "fragments": [],
                "text": "Analyses of multinomial mixture distributions: new tests for stochastic models of cognition and action."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new multinomial maximum likelihood mixture (MMLM) analysis is discussed for estimating the mixing probabilities alpha j and the basis distributions fj(x) of a hypothesized mixture distribution and generates a maximum likelihood goodness-of-fit statistic for testing various mixture hypotheses."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological bulletin"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3282030"
                        ],
                        "name": "Konrad Paul Kording",
                        "slug": "Konrad-Paul-Kording",
                        "structuredName": {
                            "firstName": "Konrad",
                            "lastName": "Kording",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Konrad Paul Kording"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1960857"
                        ],
                        "name": "D. Wolpert",
                        "slug": "D.-Wolpert",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Wolpert",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wolpert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 219
                            }
                        ],
                        "text": "\u2026of human intelligence as rational adaptations to the statistical structure of the environment (Anderson, 1990; Anderson & Schooler, 1991; Geisler et al., 2001; Griffiths & Tenenbaum, 2006, in press; Kemp et al., 2004; Ko\u0308rding & Wolpert, 2004; Simoncelli & Olshausen, 2001; Wolpert et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 164
                            }
                        ],
                        "text": "Perceptual capacities such as identifying shape from shading (Freeman, 1994), motion perception (Weiss, Simoncelli, & Adelson, 2002), and sensorimotor integration (Ko\u0308rding & Wolpert, 2004; Wolpert, Ghahramani, & Jordan, 1995) appear to closely approximate optimal statistical inferences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4319021,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "f204c80c374772d66f28519795bd8929d0abf45a",
            "isKey": false,
            "numCitedBy": 1737,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "When we learn a new motor skill, such as playing an approaching tennis ball, both our sensors and the task possess variability. Our sensors provide imperfect information about the ball's velocity, so we can only estimate it. Combining information from multiple modalities can reduce the error in this estimate. On a longer time scale, not all velocities are a priori equally probable, and over the course of a match there will be a probability distribution of velocities. According to bayesian theory, an optimal estimate results from combining information about the distribution of velocities\u2014the prior\u2014with evidence from sensory feedback. As uncertainty increases, when playing in fog or at dusk, the system should increasingly rely on prior knowledge. To use a bayesian strategy, the brain would need to represent the prior distribution and the level of uncertainty in the sensory feedback. Here we control the statistical variations of a new sensorimotor task and manipulate the uncertainty of the sensory feedback. We show that subjects internally represent both the statistical distribution of the task and their sensory uncertainty, combining them in a manner consistent with a performance-optimizing bayesian process. The central nervous system therefore employs probabilistic models during sensorimotor learning."
            },
            "slug": "Bayesian-integration-in-sensorimotor-learning-Kording-Wolpert",
            "title": {
                "fragments": [],
                "text": "Bayesian integration in sensorimotor learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows that subjects internally represent both the statistical distribution of the task and their sensory uncertainty, combining them in a manner consistent with a performance-optimizing bayesian process."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144266527"
                        ],
                        "name": "H. Roediger",
                        "slug": "H.-Roediger",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Roediger",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Roediger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145563133"
                        ],
                        "name": "J. Watson",
                        "slug": "J.-Watson",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Watson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Watson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4998674"
                        ],
                        "name": "K. McDermott",
                        "slug": "K.-McDermott",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McDermott",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McDermott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2395828"
                        ],
                        "name": "D. Gallo",
                        "slug": "D.-Gallo",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Gallo",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gallo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 275
                            }
                        ],
                        "text": "\u2026and statistics derived from these norms have been shown to be important in predicting cued recall (Nelson, McKinney, Gee, & Janczura, 1998), recognition (Nelson, McKinney, et al., 1998; Nelson, Zhang, & McKinney, 2001), and false memories (Deese, 1959; McEvoy et al., 1999; Roediger et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 73
                            }
                        ],
                        "text": "We obtained predictions from this model for the 55 DRM lists reported by Roediger et al. (2001), using the 1,700-topic solution derived from the TASA corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 61
                            }
                        ],
                        "text": ", 1998; Nelson, Zhang, & McKinney, 2001), and false memories (Deese, 1959; McEvoy et al., 1999; Roediger et al., 2001)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 190
                            }
                        ],
                        "text": "To assess the performance of the topic model, we correlated the retrieval probability of the critical DRM words as predicted by the topic model with the observed intrusion rates reported by Roediger et al. (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1106,
                                "start": 73
                            }
                        ],
                        "text": "We obtained predictions from this model for the 55 DRM lists reported by Roediger et al. (2001), using the 1,700-topic solution derived from the TASA corpus. Three DRM lists were excluded because the critical items were absent from the vocabulary of the model. Of the remaining 52 DRM lists, a median of 14 out of 15 original study words were in our vocabulary. For each DRM list, we computed the retrieval probability over the whole 26,243-word vocabulary, which included the studied words as well as extra-list words. For example, Figure 12 shows the predicted gist-based retrieval probabilities for the sleep list. The retrieval probabilities are separated into two lists: the words on the study list and the 8 most likely extra-list words. The results show that sleep is the most likely word to be retrieved, which qualitatively fits with the observed high false-recall rate of this word. To assess the performance of the topic model, we correlated the retrieval probability of the critical DRM words as predicted by the topic model with the observed intrusion rates reported by Roediger et al. (2001). The rank-order correlation was ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10216043,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "68deaa30c41ef34e050e57e66801437a6f09a6a3",
            "isKey": true,
            "numCitedBy": 736,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "In the Deese-Roediger-McDermott (DRM) paradigm, subjects study lists of words that are designed to elicit the recall of an associatively related critical item. The 55 lists we have developed provide levels of false recall ranging from .01 to .65, and understanding this variability should provide a key to understanding this memory illusion. Using a simultaneous multiple regression analysis, we assessed the contribution of seven factors in creating false recall of critical items in the DRM paradigm. This analysis accounted for approximately 68% of the variance in false recall, with two main predictors: associative connections from the study words to the critical item (r+.73; semipartialr+.60) and recallability of the lists (r+.43; semipartialr-.34). Taken together, the variance in false recall captured by these predictors accounted for 84% of the variance that can be explained, given the reliability of the false recall measures (r=.90). Therefore, the results of this analysis strongly constrain theories of false memory in this paradigm, suggesting that at least two factors determine the propensity of DRM lists to elicit false recall. The results fit well within the theoretical framework postulating that both semantic activation of the critical item and strategic monitoring processes influence the probability of false recall and false recognition in this paradigm."
            },
            "slug": "Factors-that-determine-false-recall:-A-multiple-Roediger-Watson",
            "title": {
                "fragments": [],
                "text": "Factors that determine false recall: A multiple regression analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The results fit well within the theoretical framework postulating that both semantic activation of the critical item and strategic monitoring processes influence the probability of false recall and false recognition in this paradigm."
            },
            "venue": {
                "fragments": [],
                "text": "Psychonomic bulletin & review"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064181"
                        ],
                        "name": "A. Tversky",
                        "slug": "A.-Tversky",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Tversky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tversky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98104006"
                        ],
                        "name": "J. W. Hutchinson",
                        "slug": "J.-W.-Hutchinson",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hutchinson",
                            "middleNames": [
                                "Wesley"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. W. Hutchinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 138
                            }
                        ],
                        "text": "The results presented in this section provide analogues in semantic association to the problems that Tversky (1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986) identified for spatial accounts of similarity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 37
                            }
                        ],
                        "text": "Tversky (1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986) argued against defining the similarity between two stimuli in terms of the distance between those stimuli in an internalized spatial representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 224
                            }
                        ],
                        "text": "\u2026of word association\u2014 effects of word frequency, violation of the triangle inequality, and the large-scale structure of semantic networks\u2014connecting these phenomena to the notions used in Tversky\u2019s (1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986) critique of spatial representations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 163
                            }
                        ],
                        "text": "These phenomena are analogues of the phenomena of similarity judgments that are problematic for spatial models of similarity (Tversky, 1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 270
                            }
                        ],
                        "text": "\u2026space, we can compare these two models as a means of examining the implications of different kinds of semantic representation, just as featural and spatial representations have been compared as models of human similarity judgments (Tversky, 1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17034191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c98b6b0756588f1ad41f2c128523419bdfd2244",
            "isKey": true,
            "numCitedBy": 182,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Geometric models impose an upper bound on the number of points that can share the same nearest neighbor. A much more restrictive bound is implied by the assumption that the data points represent a sample from some continuous distribution in a multidimensional Euclidean space. The analysis of 100 data sets shows that most perceptual data satisfy the geometric-statistical bound whereas many conceptual data sets exceed it. The most striking discrepancies between the data and their multidimensional representations arise in semantic fields when the stimulus set includes a focal element (e.g., a superordinate category) that is the nearest neighbor of many of its instances. Theoretical and methodological implications of nearest neighbor analysis are discussed."
            },
            "slug": "Nearest-neighbor-analysis-of-psychological-spaces.-Tversky-Hutchinson",
            "title": {
                "fragments": [],
                "text": "Nearest neighbor analysis of psychological spaces."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The analysis of 100 data sets shows that most perceptual data satisfy the geometric-statistical bound whereas many conceptual data sets exceed it, and the most striking discrepancies between the data and their multidimensional representations arise in semantic fields."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 64
                            }
                        ],
                        "text": "This relationship is illustrated using graphical model notation (e.g., Jordan, 1998; Pearl, 1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 85
                            }
                        ],
                        "text": "This relationship is illustrated using graphical model notation (e.g., Jordan, 1998; Pearl,\n1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 57437891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bf6f01402e1648b7d1e6c9200ede6cb1af30123",
            "isKey": false,
            "numCitedBy": 4579,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144266527"
                        ],
                        "name": "H. Roediger",
                        "slug": "H.-Roediger",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Roediger",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Roediger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4998674"
                        ],
                        "name": "K. McDermott",
                        "slug": "K.-McDermott",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McDermott",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McDermott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 190
                            }
                        ],
                        "text": "To assess the performance of the topic model, we correlated the retrieval probability of the critical DRM words as predicted by the topic model with the observed intrusion rates reported by Roediger et al. (2001). The rank-order correlation was 0."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 105
                            }
                        ],
                        "text": "One procedure for studying gist-based memory is the Deese\u2013 Roediger\u2013McDermott (DRM) paradigm (Deese, 1959; Roediger & McDermott, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 265
                            }
                        ],
                        "text": "\u2026such as word-association norms (e.g., Nelson, McEvoy, & Schreiber, 1998), word reading times in sentence processing (e.g., Sereno, Pacht, & Rayner, 1992), semantic priming (e.g., Till, Mross, & Kintsch, 1988), and effects of semantic context in free recall (e.g., Roediger & McDermott, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7637569,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "94251836c4c160574b8887362847795da66c2c81",
            "isKey": false,
            "numCitedBy": 3167,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "False memories\u2014either remembering events that never happened, or remembering them quite differently from the way they happened\u2014have recently captured the attention of both psychologists and the public at large. The primary impetus for this recent surge of interest is the increase in the number of cases in which memories of previously unrecognized abuse are reported during the course of therapy. Some researchers have argued that certain therapeutic practices can cause the creation of false memories, and therefore, the apparent \"recovery\" of memories during the course of therapy may actually represent the creation of memories (Lindsay & Read, 1994; Loftus, 1993). Although the concept of false memories is currently enjoying an increase in publicity, it is not new; psychologists have been studying false memories in several laboratory paradigms for years. Schacter (in press) provides an historical overview of the study of memory distortions. Bartlett (1932) is usually credited with conducting the first experimental investigation of false memories; he had subjects read an Indian folktale, \"The War of the Ghosts,\" and recall it repeatedly. Although he reported no aggregate data, but only sample protocols, his results seemed to show distortions in subjects' memories over repeated attempts to recall the story. Interestingly, Bartlett's repeated reproduction results never have been successfully replicated by later researchers (see Gauld & Stephenson, 1967; Roediger, Wheeler, & Rajaram, 1993); indeed, Wheeler and Roediger (1992) showed that recall of prose passages (including \"The War of the Ghosts\")"
            },
            "slug": "Creating-false-memories:-Remembering-words-not-in-Roediger-McDermott",
            "title": {
                "fragments": [],
                "text": "Creating false memories: Remembering words not presented in lists."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2974669"
                        ],
                        "name": "R. Nosofsky",
                        "slug": "R.-Nosofsky",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Nosofsky",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nosofsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 161
                            }
                        ],
                        "text": "Asymmetry provides an excellent example, as several methods for producing\nasymmetries from spatial representations have already been suggested (Krumhansl, 1978; Nosofsky, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 177
                            }
                        ],
                        "text": "This symmetry means that the model cannot predict asymmetries in word association without adopting a more complex measure of the association between words (cf. Krumhansl, 1978; Nosofsky, 1991)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 143
                            }
                        ],
                        "text": "Asymmetry provides an excellent example, as several methods for producing asymmetries from spatial representations have already been suggested (Krumhansl, 1978; Nosofsky, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18293630,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "26a4cb8877ef09342e576728faa92873145f19b6",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Stimulus-bias,-asymmetric-similarity,-and-Nosofsky",
            "title": {
                "fragments": [],
                "text": "Stimulus bias, asymmetric similarity, and classification"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389543793"
                        ],
                        "name": "D. Spalding",
                        "slug": "D.-Spalding",
                        "structuredName": {
                            "firstName": "DOUGLAS A.",
                            "lastName": "Spalding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spalding"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 160
                            }
                        ],
                        "text": "One approach to this problem is to define a generative model in which the document boundaries are also latent variables, a strategy pursued by Purver, Ko\u0308rding, Griffiths, and Tenenbaum (2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Griffiths, T. L., & Steyvers, M. (2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 72
                            }
                        ],
                        "text": "Retrieved 2001 from http://www.gutenberg.org/etext/10681 Rosen-Zvi, M., Griffiths, T., Steyvers, M., & Smyth, P. (2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 13
                            }
                        ],
                        "text": "Blei, D. M., Griffiths, T. L., Jordan, M. I., & Tenenbaum, J. B. (2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Griffiths, T. L., & Tenenbaum, J. B. (2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 72
                            }
                        ],
                        "text": "Correspondence concerning this article should be addressed to Thomas L. Griffiths, Department of Psychology, University of California, Berkeley, 3210 Tolman Hall, MC 1650, Berkeley, CA 94720-1650."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Griffiths, T. L., & Tenenbaum, J. B. (in press)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Griffiths, T. L., & Steyvers, M. (2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 37
                            }
                        ],
                        "text": "For instance, taking an example from James (1890), a gas jet is similar to the moon, as both cast light, and the moon is similar to a ball, because of its shape, but a gas jet is not at all similar to a ball."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 42
                            }
                        ],
                        "text": "Steyvers, M., Smyth, P., Rosen-Zvi, M., & Griffiths, T. (2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 20
                            }
                        ],
                        "text": "Tenenbaum, J. B., & Griffiths, T. L. (2001)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 41
                            }
                        ],
                        "text": "If words like stream or meadow Thomas L. Griffiths, Department of Psychology, University of California, Berkeley; Mark Steyvers, Department of Cognitive Sciences, University of California, Irvine; Joshua B. Tenenbaum, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 17
                            }
                        ],
                        "text": "Blei, Griffiths, Jordan, and Tenenbaum (2004) and Teh, Jordan, Beal, and Blei (2004) have applied this strategy to learn the dimensionality of topic models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Griffiths, T. L., Steyvers, M., Blei, D. M., & Tenenbaum, J. B. (2005)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Griffiths, T. L., & Steyvers, M. (2003)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 28
                            }
                        ],
                        "text": "Purver, M., Ko\u0308rding, K. P., Griffiths, T. L., & Tenenbaum, J. B. (2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 11
                            }
                        ],
                        "text": "Rosen-Zvi, Griffiths, Steyvers, and Smyth (2004) and Steyvers, Smyth, Rosen-Zvi, and Griffiths (2004) have extensively investigated models of this form."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Griffiths, Steyvers, Blei, and Tenenbaum (2005; see also Griffiths & Steyvers, 2003) explored a composite generative model for language, in which one of the probability distributions over words used in defining a syntactic model was replaced with a semantic model."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4033418,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "c1a09e2d91009f11c464640d5fd2b9c843178ab3",
            "isKey": true,
            "numCitedBy": 8572,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "I.TO give readers some idea of the contents of a good book is very often the most useful thing a reviewer can do. Unfortunately that course is not open to us in the present instance. The subject is too vast. We cannot exhibit the grandeur; we can only in a few general phrases express our admiration of the profound, all-embracing philosophy of which the work before us is an instalment. The doctrine of evolution when taken up by Mr. Spencer was little more than a crotchet. He has made it the idea of the age. In its presence other systems of philosophy are hushed, they cease their strife and become its servants, while all the sciences do it homage. The place that the doctrine of evolution has secured in the minds of those who think for the educated public may be indicated by a few names taken just as they occur. Mr. Darwin's works, the novels of George Eliot, Mr. Tylor's \u201c Primitive Culture,\u201d Dr. Bastian's \u201c Beginnings of Life,\u201d and Mr. Bagehot's \u201c Physics and Politics,\u201d have almost nothing in common but the idea of evolution, with which they are all more or less imbued. In a word we have but one other thinker with whom in point of influence on the higher thought of this, and probably of several succeeding generations, Mr. Spencer can be classed:-it does not need saying' that that other is Mr. J, S. Mill.The Principles of Psychology.By Herbert Spencer. Second Edition. (London: Williams and Norgate.)"
            },
            "slug": "The-Principles-of-Psychology-Spalding",
            "title": {
                "fragments": [],
                "text": "The Principles of Psychology"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1873
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137198"
                        ],
                        "name": "R. Shepard",
                        "slug": "R.-Shepard",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Shepard",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shepard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 184
                            }
                        ],
                        "text": "Tversky\u2019s argument was not against spatial representations per se but against the idea that similarity is a monotonic function of a metric, such as distance in psychological space (cf. Shepard, 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2536571,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00779852a69a18653fc9df0fbe119e975213fe7c",
            "isKey": false,
            "numCitedBy": 2221,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "A psychological space is established for any set of stimuli by determining metric distances between the stimuli such that the probability that a response learned to any stimulus will generalize to any other is an invariant monotonic function of the distance between them. To a good approximation, this probability of generalization (i) decays exponentially with this distance, and (ii) does so in accordance with one of two metrics, depending on the relation between the dimensions along which the stimuli vary. These empirical regularities are mathematically derivable from universal principles of natural kinds and probabilistic geometry that may, through evolutionary internalization, tend to govern the behaviors of all sentient organisms."
            },
            "slug": "Toward-a-universal-law-of-generalization-for-Shepard",
            "title": {
                "fragments": [],
                "text": "Toward a universal law of generalization for psychological science."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A psychological space is established for any set of stimuli by determining metric distances between the stimuli such that the probability that a response learned to any stimulus will generalize to any other is an invariant monotonic function of the distance between them."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10796472"
                        ],
                        "name": "James H. Martin",
                        "slug": "James-H.-Martin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martin",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James H. Martin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 181
                            }
                        ],
                        "text": "The syntactic dependencies are introduced via a hidden Markov model, a popular probabilistic model for language that is essentially a probabilistic regular grammar (Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As a consequence, generative models have recently become popular in both computational linguistics (eg, Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schutze, 1999) and psycholinguistics (eg, Baldewein & Keller, 2004; Jurafsky, 1996), although this work has tended to emphasize syntactic structure over semantics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 117
                            }
                        ],
                        "text": "Most generative models that have been applied to language focus on latent syntactic structure (e.g., Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 122
                            }
                        ],
                        "text": "As a consequence, generative models have recently become popular in both computational linguistics (e.g., Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999) and psycholinguistics (e.g., Baldewein & Keller, 2004; Jurafsky, 1996), although this work has tended to emphasize syntactic\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 140
                            }
                        ],
                        "text": "Many of the models used in computational linguistics, such as hidden Markov models and probabilistic context-free grammars (Charniak, 1993; Jurafsky & Martin, 2000; Manning & Schu\u0308tze, 1999), generate words purely on the basis of sequential dependencies among unobserved syntactic classes, not\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5073927,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "894149cb66e8af4a20c82840ea3f774888644fa6",
            "isKey": true,
            "numCitedBy": 3258,
            "numCiting": 356,
            "paperAbstract": {
                "fragments": [],
                "text": "is one of the most recognizablecharacters in 20th century cinema. HAL is an arti\ufb01cial agent capable of such advancedlanguage behavior as speaking and understanding English, and at a crucial moment inthe plot, even reading lips. It is now clear that HAL\u2019s creator, Arthur C. Clarke, wasa little optimistic in predicting when an arti\ufb01cial agent such as HAL would be avail-able. But just how far off was he? What would it take to create at least the language-relatedpartsofHAL?WecallprogramslikeHALthatconversewithhumansinnatural"
            },
            "slug": "Speech-and-Language-Processing-Jurafsky-Martin",
            "title": {
                "fragments": [],
                "text": "Speech and Language Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 148
                            }
                        ],
                        "text": "Surprisingly subtle aspects of human vision can be explained in terms of the statistics of natural scenes (Geisler, Perry, Super, & Gallogly, 2001; Simoncelli & Olshausen, 2001), and human memory seems to be tuned to the probabilities with which particular events occur in the world (Anderson &\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 244
                            }
                        ],
                        "text": "\u2026of human intelligence as rational adaptations to the statistical structure of the environment (Anderson, 1990; Anderson & Schooler, 1991; Geisler et al., 2001; Griffiths & Tenenbaum, 2006, in press; Kemp et al., 2004; Ko\u0308rding & Wolpert, 2004; Simoncelli & Olshausen, 2001; Wolpert et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 0
                            }
                        ],
                        "text": "Steyvers and Tenenbaum (2005) found that the clustering coefficient of semantic networks is far greater than that of a random graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 147618,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "d5ad1fdd277219257c38df86770c9fd68f4c74f0",
            "isKey": false,
            "numCitedBy": 2132,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "It has long been assumed that sensory neurons are adapted, through both evolutionary and developmental processes, to the statistical properties of the signals to which they are exposed. Attneave (1954)Barlow (1961) proposed that information theory could provide a link between environmental statistics and neural responses through the concept of coding efficiency. Recent developments in statistical modeling, along with powerful computational tools, have enabled researchers to study more sophisticated statistical models for visual images, to validate these models empirically against large sets of data, and to begin experimentally testing the efficient coding hypothesis for both individual neurons and populations of neurons."
            },
            "slug": "Natural-image-statistics-and-neural-representation.-Simoncelli-Olshausen",
            "title": {
                "fragments": [],
                "text": "Natural image statistics and neural representation."
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "It has long been assumed that sensory neurons are adapted to the statistical properties of the signals to which they are exposed, but recent developments in statistical modeling have enabled researchers to study more sophisticated statistical models for visual images, to validate these models empirically against large sets of data, and to begin experimentally testing the efficient coding hypothesis."
            },
            "venue": {
                "fragments": [],
                "text": "Annual review of neuroscience"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2926253"
                        ],
                        "name": "Wayne D. Gray",
                        "slug": "Wayne-D.-Gray",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Gray",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wayne D. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58819345,
            "fieldsOfStudy": [
                "Geography"
            ],
            "id": "2f5f5b053e93f31390dff9638730b27abb11b8b4",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This Proceedings documents the talks, posters, tutorials, and symposia presented at the 24th Annual Meeting of the Cognitive Science Society. The meeting took place at George Mason University in Fairfax Virginia, USA from August 7 through August 10, 2002. Hundreds of submissions were received from around the world. Following last year's first European conference, it seems as if the annual meeting has become a truly international event."
            },
            "slug": "Proceedings-of-the-Twenty-Fourth-Annual-Conference-Gray",
            "title": {
                "fragments": [],
                "text": "Proceedings of the Twenty-Fourth Annual Conference of the Cognitive Science Society"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764325"
                        ],
                        "name": "Radford M. Neal",
                        "slug": "Radford-M.-Neal",
                        "structuredName": {
                            "firstName": "Radford",
                            "lastName": "Neal",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radford M. Neal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 235
                            }
                        ],
                        "text": "These methods are closely related to the rational model of categorization proposed by Anderson (1990), which represents categories in terms of a set of clusters, with new clusters added automatically as more data become available (see Neal, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 79
                            }
                        ],
                        "text": "Using methods from nonparametric Bayesian statistics (Muller & Quintana, 2004; Neal, 2000), we can assume that our data are generated by a model with an unbounded number of dimensions, of which only a finite subset have been observed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12129013,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "91e62d27c08db29cf011a0326a61509e574cf772",
            "isKey": false,
            "numCitedBy": 1720,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This article reviews Markov chain methods for sampling from the posterior distribution of a Dirichlet process mixture model and presents two new classes of methods. One new approach is to make Metropolis\u2014Hastings updates of the indicators specifying which mixture component is associated with each observation, perhaps supplemented with a partial form of Gibbs sampling. The other new approach extends Gibbs sampling for these indicators by using a set of auxiliary parameters. These methods are simple to implement and are more efficient than previous ways of handling general Dirichlet process mixture models with non-conjugate priors."
            },
            "slug": "Markov-Chain-Sampling-Methods-for-Dirichlet-Process-Neal",
            "title": {
                "fragments": [],
                "text": "Markov Chain Sampling Methods for Dirichlet Process Mixture Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2307115"
                        ],
                        "name": "C. Krumhansl",
                        "slug": "C.-Krumhansl",
                        "structuredName": {
                            "firstName": "Carol",
                            "lastName": "Krumhansl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Krumhansl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 144
                            }
                        ],
                        "text": "Asymmetry provides an excellent example, as several methods for producing\nasymmetries from spatial representations have already been suggested (Krumhansl, 1978; Nosofsky, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 160
                            }
                        ],
                        "text": "This symmetry means that the model cannot predict asymmetries in word association without adopting a more complex measure of the association between words (cf. Krumhansl, 1978; Nosofsky, 1991)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 143
                            }
                        ],
                        "text": "Asymmetry provides an excellent example, as several methods for producing asymmetries from spatial representations have already been suggested (Krumhansl, 1978; Nosofsky, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13926591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92084fa819299396da2316d4dab0e82c3d92e5f0",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "In a recent article, Tversky questioned the application of geometric models to similarity data and proposed an alternative set-theoretic approach. He suggested that geometric models are inappropriate because the similarity data may violate the metric assumptions underlying such models. In addition, he demonstrated that the stimulus context and the nature of the experimental task can affect the similarity relations. The present article suggests that a geometric approach may be compatible with these effects if the traditional multidimensional scaling model is augmented by the assumption that spatial density in the configuration has an effect on the similarity measure. A distance-density model is outlined that assumes that similarity is a function of both interpoint distance and the spatial density of other stimulus points in the surrounding region of the metric space. The proposed relationship between similarity and spatial density is supported by empirical evidence. The distance-density model is shown to be able to account for violations of the metric axioms and certain context and task effects. A number of other issues are discussed with respect to geometric and set-theoretic models of similarity."
            },
            "slug": "Concerning-the-Applicability-of-Geometric-Models-to-Krumhansl",
            "title": {
                "fragments": [],
                "text": "Concerning the Applicability of Geometric Models to Similarity Data : The Interrelationship Between Similarity and Spatial Density"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The present article suggests that a geometric approach may be compatible with these effects if the traditional multidimensional scaling model is augmented by the assumption that spatial density in the configuration has an effect on the similarity measure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144538257"
                        ],
                        "name": "Y. Weiss",
                        "slug": "Y.-Weiss",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2777968,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "4eda0e4608d35b62fb34a162d1de238caaed8faa",
            "isKey": false,
            "numCitedBy": 939,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "The pattern of local image velocities on the retina encodes important environmental information. Although humans are generally able to extract this information, they can easily be deceived into seeing incorrect velocities. We show that these 'illusions' arise naturally in a system that attempts to estimate local image velocity. We formulated a model of visual motion perception using standard estimation theory, under the assumptions that (i) there is noise in the initial measurements and (ii) slower motions are more likely to occur than faster ones. We found that specific instantiation of such a velocity estimator can account for a wide variety of psychophysical phenomena."
            },
            "slug": "Motion-illusions-as-optimal-percepts-Weiss-Simoncelli",
            "title": {
                "fragments": [],
                "text": "Motion illusions as optimal percepts"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A model of visual motion perception using standard estimation theory, under the assumptions that there is noise in the initial measurements and slower motions are more likely to occur than faster ones, is formulated and found that specific instantiation of such a velocity estimator can account for a wide variety of psychophysical phenomena."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1960857"
                        ],
                        "name": "D. Wolpert",
                        "slug": "D.-Wolpert",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Wolpert",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wolpert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 456,
                                "start": 257
                            }
                        ],
                        "text": "Across many areas of cognition, perception, and action, probabilistic generative models have recently come to offer a unifying framework for understanding aspects of human intelligence as rational adaptations to the statistical structure of the environment (Anderson, 1990; Anderson & Schooler, 1991; Geisler et al., 2001; Griffiths & Tenenbaum, 2006b, 2006a; Kemp et al., 2004; Koerding & Wolpert, 2004; Simoncelli & Olshausen, 2001; Wolpert et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 274
                            }
                        ],
                        "text": "\u2026of human intelligence as rational adaptations to the statistical structure of the environment (Anderson, 1990; Anderson & Schooler, 1991; Geisler et al., 2001; Griffiths & Tenenbaum, 2006, in press; Kemp et al., 2004; Ko\u0308rding & Wolpert, 2004; Simoncelli & Olshausen, 2001; Wolpert et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 112
                            }
                        ],
                        "text": "The number of meanings or senses that a word possesses has a characteristic distribution, as was first noted by Zipf (1965). Zipf examined the number of entries that appeared in dictionary definitions for words, and found that this quantity followed a power-law distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2321011,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a98b48c6746c9da9759badfcdf2870bc56697642",
            "isKey": false,
            "numCitedBy": 2965,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "On the basis of computational studies it has been proposed that the central nervous system internally simulates the dynamic behavior of the motor system in planning, control, and learning; the existence and use of such an internal model is still under debate. A sensorimotor integration task was investigated in which participants estimated the location of one of their hands at the end of movements made in the dark and under externally imposed forces. The temporal propagation of errors in this task was analyzed within the theoretical framework of optimal state estimation. These results provide direct support for the existence of an internal model."
            },
            "slug": "An-internal-model-for-sensorimotor-integration.-Wolpert-Ghahramani",
            "title": {
                "fragments": [],
                "text": "An internal model for sensorimotor integration."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A sensorimotor integration task was investigated in which participants estimated the location of one of their hands at the end of movements made in the dark and under externally imposed forces, providing direct support for the existence of an internal model."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17595314"
                        ],
                        "name": "F. Bartlett",
                        "slug": "F.-Bartlett",
                        "structuredName": {
                            "firstName": "Frederic",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "C.",
                                "Sir"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bartlett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 6
                            }
                        ],
                        "text": "Since Bartlett (1932), many memory researchers have proposed that episodic memory might be based not only on specific memory of the experienced episodes but also on reconstructive processes that extract the overall theme or gist of a collection of experiences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 115933268,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "29df5a7c613c510bcd143b47246a6a85cfb189c7",
            "isKey": false,
            "numCitedBy": 6115,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Part I. Experimental Studies: 2. Experiment in psychology 3. Experiments on perceiving III Experiments on imaging 4-8. Experiments on remembering: (a) The method of description (b) The method of repeated reproduction (c) The method of picture writing (d) The method of serial reproduction (e) The method of serial reproduction picture material 9. Perceiving, recognizing, remembering 10. A theory of remembering 11. Images and their functions 12. Meaning Part II. Remembering as a Study in Social Psychology: 13. Social psychology 14. Social psychology and the matter of recall 15. Social psychology and the manner of recall 16. Conventionalism 17. The notion of a collective unconscious 18. The basis of social recall 19. A summary and some conclusions."
            },
            "slug": "Remembering:-A-Study-in-Experimental-and-Social-Bartlett",
            "title": {
                "fragments": [],
                "text": "Remembering: A Study in Experimental and Social Psychology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1932
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783914"
                        ],
                        "name": "D. Watts",
                        "slug": "D.-Watts",
                        "structuredName": {
                            "firstName": "Duncan",
                            "lastName": "Watts",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Watts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2343210"
                        ],
                        "name": "S. Strogatz",
                        "slug": "S.-Strogatz",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Strogatz",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Strogatz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 34
                            }
                        ],
                        "text": "A standard\nmeasure of clustering (Watts & Strogatz, 1998) is the clustering coefficient, C , the mean proportion of the neighbors of a node that are also neighbors of one another."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4429113,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d61031326150ba23f90e6587c13d99188209250e",
            "isKey": false,
            "numCitedBy": 35997,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Networks of coupled dynamical systems have been used to model biological oscillators, Josephson junction arrays,, excitable media, neural networks, spatial games, genetic control networks and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks \u2018rewired\u2019 to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them \u2018small-world\u2019 networks, by analogy with the small-world phenomenon, (popularly known as six degrees of separation). The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices."
            },
            "slug": "Collective-dynamics-of-\u2018small-world\u2019-networks-Watts-Strogatz",
            "title": {
                "fragments": [],
                "text": "Collective dynamics of \u2018small-world\u2019 networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Simple models of networks that can be tuned through this middle ground: regular networks \u2018rewired\u2019 to introduce increasing amounts of disorder are explored, finding that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50528060"
                        ],
                        "name": "J. Pritchard",
                        "slug": "J.-Pritchard",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Pritchard",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pritchard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145761702"
                        ],
                        "name": "M. Stephens",
                        "slug": "M.-Stephens",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Stephens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stephens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144427783"
                        ],
                        "name": "P. Donnelly",
                        "slug": "P.-Donnelly",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Donnelly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Donnelly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 265
                            }
                        ],
                        "text": "\u20261999), variational expectation maximization (Blei et al., 2003; Buntine, 2002), ex-\npectation propagation (Minka & Lafferty, 2002), and several forms of Markov chain Monte Carlo (MCMC; Buntine & Jakulin, 2004; Erosheva, 2002; Griffiths & Steyvers, 2002, 2003, 2004; Pritchard et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52871542,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "fa02f9123abacd5ba13d41e937d99c077da8d3f6",
            "isKey": false,
            "numCitedBy": 28410,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a model-based clustering method for using multilocus genotype data to infer population structure and assign individuals to populations. We assume a model in which there are K populations (where K may be unknown), each of which is characterized by a set of allele frequencies at each locus. Individuals in the sample are assigned (probabilistically) to populations, or jointly to two or more populations if their genotypes indicate that they are admixed. Our model does not assume a particular mutation process, and it can be applied to most of the commonly used genetic markers, provided that they are not closely linked. Applications of our method include demonstrating the presence of population structure, assigning individuals to populations, studying hybrid zones, and identifying migrants and admixed individuals. We show that the method can produce highly accurate assignments using modest numbers of loci-e.g. , seven microsatellite loci in an example using genotype data from an endangered bird species. The software used for this article is available from http://www.stats.ox.ac.uk/ approximately pritch/home. html."
            },
            "slug": "Inference-of-population-structure-using-multilocus-Pritchard-Stephens",
            "title": {
                "fragments": [],
                "text": "Inference of population structure using multilocus genotype data."
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A model-based clustering method for using multilocus genotype data to infer population structure and assign individuals to populations that can be applied to most of the commonly used genetic markers, provided that they are not closely linked."
            },
            "venue": {
                "fragments": [],
                "text": "Genetics"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727849"
                        ],
                        "name": "S. Hanson",
                        "slug": "S.-Hanson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "Jose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hanson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60565534,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "69d7086300e7f5322c06f2f242a565b3a182efb5",
            "isKey": false,
            "numCitedBy": 4652,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Bill Baird { Publications References 1] B. Baird. Bifurcation analysis of oscillating neural network model of pattern recognition in the rabbit olfactory bulb. In D. 3] B. Baird. Bifurcation analysis of a network model of the rabbit olfactory bulb with periodic attractors stored by a sequence learning algorithm. 5] B. Baird. Bifurcation theory methods for programming static or periodic attractors and their bifurcations in dynamic neural networks."
            },
            "slug": "In-Advances-in-Neural-Information-Processing-Hanson",
            "title": {
                "fragments": [],
                "text": "In Advances in Neural Information Processing Systems"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS 1990"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1868490"
                        ],
                        "name": "E. Erosheva",
                        "slug": "E.-Erosheva",
                        "structuredName": {
                            "firstName": "Elena",
                            "lastName": "Erosheva",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Erosheva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 209
                            }
                        ],
                        "text": "\u20261999), variational expectation maximization (Blei et al., 2003; Buntine, 2002), ex-\npectation propagation (Minka & Lafferty, 2002), and several forms of Markov chain Monte Carlo (MCMC; Buntine & Jakulin, 2004; Erosheva, 2002; Griffiths & Steyvers, 2002, 2003, 2004; Pritchard et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Erosheva (2002) described a model, equivalent to a topic model, applied to disability data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38229618,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5458f0cfe8e0fde11827e9dbbbe4ecedb6e686e2",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 166,
            "paperAbstract": {
                "fragments": [],
                "text": "Publications in Peer-reviewed Journals 1. P. K. Crane, L. E. Gibbons, S. Haneuse, G. van Belle, E. Erosheva, E. B. Larson and D. M. Mungas. \u201cAccounting for measurement precision in a simulated longitudinal study of cognitive functioning dramatically improved the accuracy of estimates of the rate of change,\u201d Alzheimer\u2019s and Dementia (2006), 2, No. 3, Supplement 1, S302-S303. 2. E. A. Erosheva, F. S. Salek, R. A. Stone, M. M. Folan, J. Greenhouse, and P. D. Kroboth. \u201cCharacterizing the diurnal rhythm of DHEA and effects of an oral dose of Alprazolam\u201d Biological Psychiatry (2000), 47, No. 8, Supplement 1, p. S145. Non Peer-reviewed Articles, Reports, and Conference Proceedings 1. Y. S. Wang and E. A. Erosheva. Documentation for R package \u201cMixedMem: Tools for Discrete Multivariate Mixed Membership Models\u201d (2015) http://cran.rstudio.com/ web/packages/mixedMem/index.html 2. Y. S. Wang and E. A. Erosheva. Vignette for R package \u201cFitting Mixed Membership Models using mixedMem\u201d (2015). http://cran.rstudio.com/web/packages/mixedMem/ vignettes/mixedMem.pdf 3. E. A. Erosheva and S. M Curtis (2014) \u201cR code examples for Analysis of Multivariate Social Science Data (Second Edition) by Bartholomew et al. (2008)\u201d (available at http://www.lse.ac.uk/statistics/research/Social-Statistics/Multivariate-Data-Analysis/ Data-and-Syntax.aspx). 4. K. I. Fredriksen-Goldsen, H.-J. Kim, C. A. Emlet, A. Muraco,E. A. Erosheva, C. P. HoyEllis, J. Goldsen, H. Petry (2011). The Aging and Health Report: Disparities and Resilience among Lesbian, Gay, Bisexual, and Transgender Older Adults. Seattle: Institute for Multigenerational Health. 5. E. A. Erosheva and S. E. Fienberg. \u201cMixed Membership Models.\u201d In M. Lovric (Ed.), International Encyclopedia of Statistical Science, to appear (2010). 6. E. A. Erosheva and C. Joutard. \u201cThe extended Grade of Membership mixture model.\u201d In C. H. Skiadas (Ed.), Proceedings of the 12th International Conference on Applied Stochastic Models and Data Analysis (2007), Chania, Greece (available at http://www.asmda.com//CDasmda2007a/conf_papers.html). 7. J. Connor, E. A. Erosheva, S. E. Fienberg, and T. White. \u201cToward a restructuring of the National Long Term Care Survey.\u201d Technical report commissioned by the National Academy of Sciences for discussion at the Second Expert Meeting on the Future of the National Long Term Care Survey, February 16, 2006, Washington DC (available at http:// www.nia.nih.gov/ResearchInformation/ExtramuralPrograms/BehavioralAndSocialResearch/ ConferencesAndWorkshops.htm). 8. E. A. Erosheva and S. E. Fienberg. Contribution to the discussion of S. P. Brooks, P. Giudici and G. O. Roberts, \u201cEfficient construction of reversible jump Markov chain Monte Carlo proposal distributions\u201d, (2003) Journal of the Royal Statistical Society, Series B, 65, 3-55. Peer-reviewed Conference Publications 1. P. V. Nikitin, E. A. Erosheva, and D. Stancil \u201cEstimating the Number of Modes in Multimode Waveguide Propagation Environment.\u201d Antennas and Propagation (APSURSI), IEEE International Symposium on Digital Object Identifier, 2011, 1662 1665. Issued Patents 1. P. Maltseff, S. Winter, P. V. Nikitin, K. V. S. Rao, E. A. Erosheva, \u201cStochastic communication protocol method and system for RFID tags based on coalition formation, such as for tag-to-tag communication\u201d, US patent 8,488,510, July 2013. 2. P. Maltseff, S. Winter, P. V. Nikitin, K. V. S. Rao, E. A. Erosheva, \u201cStochastic communication protocol method and system for RFID tags based on coalition formation, such as for tag-to-tag communication\u201d, US patent 8,199,689, June 2012. Pending Patent Applications 1. P. Maltseff, S. Winter, P. V. Nikitin, K. V. S. Rao, E. A. Erosheva, \u201cStochastic communication protocol method and system for RFID tags based on coalition formation, such as for tag-to-tag communication\u201d, European patent application EP1938483. 2. P. Maltseff, S. Winter, P. V. Nikitin, K. V. S. Rao, E. A. Erosheva, \u201cRadio frequency identification tags based on coalition formation\u201d, WIPO patent application WO/2007/035863. Invited Talks \u2022 E. A. Erosheva and S. E. Fienberg. \u201cAn overview of mixed membership models: Some history and a general formulation,\u201d Joint Statistical Meetings, Seattle, WA, 8/2015. \u2022 E. A. Erosheva. \u201cLife-Course Data Analysis: A Generalized Hierarchical Unimodal Curve Registration Approach,\u201d London School of Economics and Political Science, 4/2015. \u2022 E. A. Erosheva, K. J. Gile, M. S. Handcock, K.I. Fredriksen-Goldsen, \u201cFeasibility analysis framework for Respondent-Driven Sampling based on egocentric social network data and chain-referral attitudes,\u201d Joint Statistical Meetings, Boston, MA, 8/2014. \u2022 E. A. Erosheva. \u201cLife-course data analysis,\u201d Duke University Department of Statistics, April 4, 2014. \u2022 E. A. Erosheva. \u201cLife-course data analysis methods in criminology and beyond,\u201d Measuring Justice and Violence Indicators for the Post-2015 Development Agenda, a meeting jointly organized by United Nations and Organization of American States, Rio de Janeiro, Brazil, January, 2014. \u2022 E. A. Erosheva. \u201cAsking questions about numbers: Practical considerations in RDS degree measurement,\u201d Social Network Data: Collection and Analysis, SAMSI Program on Computational Methods in Social Sciences, Research Triangle, NC, 10/2013. \u2022 E. A. Erosheva and J. Gruhl. \u201cSoft Clustering for Continuous Outcomes.\u201d Working Group on Model-based Clustering, Guelph, CA, July 18, 2012. \u2022 E. A. Erosheva. \u201cA Bayesian Hierarchical Curve Registration Method for Modeling Longitudinal Counts of Marijuana Smoking,\u201d Department of Psychology, University of Amsterdam, 5/14/2012. \u2022 E. A. Erosheva. \u201cModeling Criminal Careers: The Case of Marijuana Smoking,\u201d University of Massachusetts, 3/30/2012. \u2022 E. A. Erosheva. \u201cA case study in mixed membership modeling with a focus on model selection.\u201d Interface 2010: Computational Statistics and Human Behavior, Computational Social Science session, Seattle, WA, June 16-19, 2010. \u2022 E. A. Erosheva. \u201cRecent developments in mixed membership modeling.\u201d Invited State of the Art talk at International Meeting of the Psychometric Society, Cambridge, England, July 20-24, 2009. \u2022 E. A. Erosheva and T. White. \u201cUsing 2004 NLTCS survey to explore issues in chronic disability measurement\u201d. NIH Research Meeting \u201c2004 Wave of National Long Term Care Survey: New Research Directions\u201d, Bethesda, MD, May 28-29, 2009. \u2022 T. White and E. A. Erosheva. \u201cUsing Group-Based Latent Class Transition Models to Analyze Trends in NLTCS Chronic Disability Data 1984-2004\u201d. NIH Research Meeting \u201c2004 Wave of National Long Term Care Survey: New Research Directions\u201d, Bethesda, MD, May 28-29, 2009. \u2022 E. A. Erosheva \u201cAnalyzing longitudinal crime patterns\u201d Department of Statistics, Pennsylvania State University, April 16, 2009. \u2022 E. A. Erosheva, D. Telesca, R. Matsueda, and D. Kreager. \u201cUnimodal Hierarchical Curve Registration: Analyzing Longitudinal Crime Patterns\u201d International Meeting of the Psychometric Society,\u201d Durham, NH, June 30, 2008. \u2022 E. A. Erosheva. \u201cExtended Grade of Membership mixture model\u201d Department of Mathematics & Statistics, Portland State University, March 14, 2008. \u2022 E. A. Erosheva. \u201cCombining analysis of square tables and propensity score matching: Do two groups of assessors differ in their usage of the categories?\u201d Case Studies in Bayesian Statistics Workshop 9, Special Session in Honor of Stephen E. Fienberg\u2019s 65-th Birthday, Pittsburgh, PA, October 19, 2007. \u2022 E. A. Erosheva \u201cAn Extension of hierarchical Bayesian mixed-membership models\u201d Department of Statistics, Athens University of Economics and Business, Athens, Greece, June 1, 2007. \u2022 E. A. Erosheva \u201cA Bayesian analysis of multivariate binary response data using basic and compartmental Grade of Membership models\u201d, Department of Statistics and Actuarial Science, University of Waterloo, November 16, 2006. \u2022 E. A. Erosheva and S. E. Fienberg. \u201cBayesian mixed-membership models\u201d, Plenary Lecture at the Annual Conference of the German Classification Society, University of Dortmund, March 10, 2004. \u2022 E. A. Erosheva. \u201cGrade of Membership and latent structure models with applications to disability survey data\u201d, Joint Statistical Meetings, Savage Award (Application Methodology) Section, San Francisco, CA, August 5, 2003. \u2022 E. A. Erosheva, S. E. Fienberg, and J. Lafferty. \u201cMixed membership models of scientific publications\u201d Arthur M. Sackler Colloquium on Mapping Knowledge Domains, Beckman Center for National Academy of Sciences, Irvine, CA, May 10, 2003. \u2022 E. A. Erosheva. \u201cMixed membership models\u201d, Warren Neel Conference on the New Frontiers of Statistical Data Mining, Knowledge Discovery, and E-Business, Knoxville, Tennessee, June, 2002. Other Presentations and Conference Talks \u2022 Elena A. Erosheva and Y. Samuel Wang. \u201c Fast approximate mixed membership inference with rank data,\u201d International Meeting of the Psychometric Society, Beijing, China, July 12-16, 2015. \u2022 Elena A. Erosheva, Hyun-Jun Kim, Charles A. Emlet, and Karen I. Fredriksen-Goldsen. \u201cUsing egocentric data to explore size and diversity of social networks among lesbian, gay, bisexual, and transgender (LGBT) older adults,\u201d Joint Statistical Meetings, Montreal, CA, 8/2013. \u2022 E. A. Erosheva and S. M. Curtis. \u201cA relabeling procedure for dealing with rotational invariance in Bayesian confirmatory factor analysis.\u201d Joint Statistical Meetings, San Diego, CA, August 1, 2012. \u2022 E. A. Erosheva. \u201cSurvey measurement of complex latent constructs: An example from the National Long Term Care Survey (NLTS).\u201d Joint Statistical Meetings, Vancouver, Canada, August 3, 2010. \u2022 E. A. Erosheva, D. Telesca, R. Matsueda, and D. Kreager. \u201cAnalyzing longitudinal crime patterns\u201d, CSSS Seminar, University of Washington, Seattle, January 28, 2009; Working Group on Model-Based Clustering and Bayesian Model Selection, University of Washington, Seattle, October 30, 2008. \u2022 E. A. Erosheva. \u201cOn the operational definition of chronic disability in the National Long Term Care Survey, 1982-2004\u201d (pos"
            },
            "slug": "Grade-of-membership-and-latent-structure-models-to-Erosheva",
            "title": {
                "fragments": [],
                "text": "Grade of membership and latent structure models with application to disability survey data"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work examines a relatively new latent structure model, the Grade of Membership (GoM) model, integrating the GoM language and ideas with more standard statistical literature on latent variable models, and presents a general class of mixed membership models that unifies the latent structure of theGoM model and two other mixed Membership models that recently appeared in the genetics and the machine learning literatures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36100662"
                        ],
                        "name": "P. M\u00fcller",
                        "slug": "P.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145533704"
                        ],
                        "name": "F. Quintana",
                        "slug": "F.-Quintana",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Quintana",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Quintana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 54
                            }
                        ],
                        "text": "Using methods from nonparametric Bayesian statistics (Muller & Quintana, 2004; Neal, 2000), we can assume that our data are generated by a model with an unbounded number of dimensions, of which only a finite subset have been observed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14202962,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1f95ea6bf5c66c4527edbf6b2410759d24839c6b",
            "isKey": false,
            "numCitedBy": 471,
            "numCiting": 238,
            "paperAbstract": {
                "fragments": [],
                "text": "We review the current state of nonparametric Bayesian inference. The discussion follows a list of important statistical inference problems, including density estimation, regression, survival analysis, hierarchical models and model validation. For each inference problem we review relevant nonparametric Bayesian models and approaches including Dirichlet process (DP) models and variations, Polya trees, wavelet based models, neural network models, spline regression, CART, dependent DP models and model validation with DP and Polya tree extensions of parametric models."
            },
            "slug": "Nonparametric-Bayesian-data-analysis-M\u00fcller-Quintana",
            "title": {
                "fragments": [],
                "text": "Nonparametric Bayesian data analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "For each inference problem, relevant nonparametric Bayesian models and approaches including Dirichlet process models and variations, Polya trees, wavelet based models, neural network models, spline regression, CART, dependent DP models and model validation with DP and Polya tree extensions of parametric models are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699205"
                        ],
                        "name": "S. Furui",
                        "slug": "S.-Furui",
                        "structuredName": {
                            "firstName": "Sadaoki",
                            "lastName": "Furui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Furui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320076"
                        ],
                        "name": "W. Chou",
                        "slug": "W.-Chou",
                        "structuredName": {
                            "firstName": "Wu",
                            "lastName": "Chou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Chou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66495315"
                        ],
                        "name": "Understanding",
                        "slug": "Understanding",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Understanding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Understanding"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57979724,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a0f97b920912d55458b51652d3023e63b70a343",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This workshop focuses on the recent progress and new ground-breaking paradigms of automatic speech recognition and understanding, with robust modeling as the main theme."
            },
            "slug": "1997-IEEE-Workshop-on-Automatic-Speech-Recognition-Furui-Juang",
            "title": {
                "fragments": [],
                "text": "1997 IEEE Workshop on Automatic Speech Recognition and Understanding : proceedings"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This workshop focuses on the recent progress and new ground-breaking paradigms of automatic speech recognition and understanding, with robust modeling as the main theme."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51921883"
                        ],
                        "name": "Refractor",
                        "slug": "Refractor",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Refractor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Refractor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 126
                            }
                        ],
                        "text": "Our approach is motivated by an analysis of some of the computational problems addressed by semantic memory, in the spirit of Marr (1982) and Anderson (1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 149
                            }
                        ],
                        "text": "Many aspects of perception and cognition can be understood by considering the computational problem that is addressed by a particular human capacity (Anderson, 1990; Marr, 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 288,
                                "start": 278
                            }
                        ],
                        "text": "Keywords: probabilistic models, Bayesian models, semantic memory, semantic representation, computational models\nMany aspects of perception and cognition can be understood by considering the computational problem that is addressed by a particular human capacity (Anderson, 1990; Marr, 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 208793436,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "c3a24b0b38922c4f3a825edb97cc470a4ca7af75",
            "isKey": false,
            "numCitedBy": 3113,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vision-Refractor",
            "title": {
                "fragments": [],
                "text": "Vision"
            },
            "venue": {
                "fragments": [],
                "text": "The Lancet"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144263847"
                        ],
                        "name": "J. Deese",
                        "slug": "J.-Deese",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Deese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Deese"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 483,
                                "start": 62
                            }
                        ],
                        "text": ", 1998; Nelson, Zhang, & McKinney, 2001), and false memories (Deese, 1959; McEvoy, Nelson, & Komatsu, 1999; Roediger, Watson, McDermott, & Gallo, 2001). It is not our goal to develop a model of word association, as many factors other than semantic association are involved in this task (e.g., Ervin, 1961; McNeill, 1966), but we believe that issues raised by word association data can provide insight into models of semantic representation. We used the norms of Nelson et al. (1998) to evaluate the performance of LSA and the topic model in predicting human word association."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 1
                            }
                        ],
                        "text": "(Deese, 1965, p. viii)\nAssociation has been part of the theoretical armory of cognitive psychologists since Thomas Hobbes used the notion to account for the structure of our \u201ctrayne of thoughts\u201d (Hobbes, 1651/1998; detailed histories of association are provided by Deese, 1965, and Anderson & Bower,\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 124
                            }
                        ],
                        "text": "Since Galton, several psychologists have tried to classify kinds of association or to otherwise divine its structure (e.g., Deese, 1962, 1965)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 256
                            }
                        ],
                        "text": "\u20261965, p. viii)\nAssociation has been part of the theoretical armory of cognitive psychologists since Thomas Hobbes used the notion to account for the structure of our \u201ctrayne of thoughts\u201d (Hobbes, 1651/1998; detailed histories of association are provided by Deese, 1965, and Anderson & Bower, 1974)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 14
                            }
                        ],
                        "text": "Though unlike Deese (1965), we suspect that there may be more fascinating psychological data than tables of association, word association provides a useful benchmark for evaluating models of\nhuman semantic representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 145406410,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "824a7b59366d407cf9fc515cf624a6c52d2a0dfe",
            "isKey": true,
            "numCitedBy": 581,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-structure-of-associations-in-language-and-Deese",
            "title": {
                "fragments": [],
                "text": "The structure of associations in language and thought"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064181"
                        ],
                        "name": "A. Tversky",
                        "slug": "A.-Tversky",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Tversky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tversky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48190498"
                        ],
                        "name": "I. Gati",
                        "slug": "I.-Gati",
                        "structuredName": {
                            "firstName": "Itamar",
                            "lastName": "Gati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Gati"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 116
                            }
                        ],
                        "text": "The results presented in this section provide analogues in semantic association to the problems that Tversky (1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986) identified for spatial accounts of similarity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 15
                            }
                        ],
                        "text": "Tversky (1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986) argued against defining the similarity between two stimuli in terms of the distance between those stimuli in an internalized spatial representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 204
                            }
                        ],
                        "text": "\u2026to be a monotonically decreasing function of distance, then this inequality translates into a constraint on similarity relations: If x is similar to y and y is similar to z, then x must be similar to z. Tversky and Gati (1982) provided several examples in which this relationship does not hold."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 202
                            }
                        ],
                        "text": "\u2026of word association\u2014 effects of word frequency, violation of the triangle inequality, and the large-scale structure of semantic networks\u2014connecting these phenomena to the notions used in Tversky\u2019s (1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986) critique of spatial representations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 141
                            }
                        ],
                        "text": "These phenomena are analogues of the phenomena of similarity judgments that are problematic for spatial models of similarity (Tversky, 1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 248
                            }
                        ],
                        "text": "\u2026space, we can compare these two models as a means of examining the implications of different kinds of semantic representation, just as featural and spatial representations have been compared as models of human similarity judgments (Tversky, 1977; Tversky & Gati, 1982; Tversky & Hutchinson, 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 31820361,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "12a8ee579b6dde81f31196acff166b4090ccc2f0",
            "isKey": true,
            "numCitedBy": 349,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Similarity,-separability,-and-the-triangle-Tversky-Gati",
            "title": {
                "fragments": [],
                "text": "Similarity, separability, and the triangle inequality."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144263847"
                        ],
                        "name": "J. Deese",
                        "slug": "J.-Deese",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Deese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Deese"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 146
                            }
                        ],
                        "text": "This idea appears in early work exploring the use of statistical methods to extract representations of the meaning of words from human judgments (Deese, 1959; Fillenbaum & Rapoport, 1971)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 241
                            }
                        ],
                        "text": "\u2026and statistics derived from these norms have been shown to be important in predicting cued recall (Nelson, McKinney, Gee, & Janczura, 1998), recognition (Nelson, McKinney, et al., 1998; Nelson, Zhang, & McKinney, 2001), and false memories (Deese, 1959; McEvoy et al., 1999; Roediger et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 205
                            }
                        ],
                        "text": "A number of studies have shown that when people try to remember a list of words that are semantically associated with a word that does not appear on the list, the associated word intrudes on their memory (Deese, 1959; McEvoy, Nelson, & Komatsu, 1999; Roediger, Watson, McDermott, & Gallo, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 258
                            }
                        ],
                        "text": "Compared with approaches that focus on deeper conceptual relations, classic models of semantic association tend to invoke much simpler semantic representations, such as semantic spaces or holistic spreading activation networks (e.g., Collins & Loftus, 1975; Deese, 1959)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 92
                            }
                        ],
                        "text": "One procedure for studying gist-based memory is the Deese\u2013 Roediger\u2013McDermott (DRM) paradigm (Deese, 1959; Roediger & McDermott, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 61
                            }
                        ],
                        "text": ", 1998; Nelson, Zhang, & McKinney, 2001), and false memories (Deese, 1959; McEvoy et al., 1999; Roediger et al., 2001)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 30259120,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "id": "03894f9f549972bd77963172ccecc4e8144a72f4",
            "isKey": true,
            "numCitedBy": 1884,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-prediction-of-occurrence-of-particular-in-Deese",
            "title": {
                "fragments": [],
                "text": "On the prediction of occurrence of particular verbal intrusions in immediate recall."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology"
            },
            "year": 1959
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2053,
                                "start": 0
                            }
                        ],
                        "text": "Krumhansl, 1978; Nosofsky, 1991). In contrast, the topic model can predict the effect of frequency on word association. Word frequency is one of the factors that contribute to P(w2|w1). The model can account for the asymmetries in the word-association norms. As a conditional probability, P(w2|w1) is inherently asymmetric, and the model correctly predicted the direction of 30,905 (79.77%) of the 38,744 asymmetric associations, including all of the examples given above. The topic model thus accounted for almost exactly the same proportion of asymmetries as word frequency\u2014the difference was not statistically significant, (2)(1, 77488) 2.08, p .149. The explanation for asymmetries in word association provided by the topic model is extremely similar to Tversky\u2019s (1977) explanation for asymmetries in similarity judgments. Following Equation 9, P(w2|w1) reflects the extent to which the topics in which w1 appears give high probability to topic w2. Highfrequency words tend to appear in more topics than low-frequency words. If wh is a high-frequency word and wl is a low-frequency word, wh is likely to appear in many of the topics in which wl appears, but wl will appear in only a few of the topics in which wh appears. Consequently, P(wh|wl) will be large, but P(wl|wh) will be small. Violation of the triangle inequality. The triangle inequality is another of the metric axioms: For a metric d, d(x, z) d(x, y) d(y, z). This is referred to as the triangle inequality because if x, y, and z are interpreted as points composing a triangle, the equation indicates that no side of that triangle can be longer than the sum of the other two sides. This inequality places strong constraints on distance measures and strong constraints on the locations of points in a space given a set of distances. If similarity is assumed to be a monotonically decreasing function of distance, then this inequality translates into a constraint on similarity relations: If x is similar to y and y is similar to z, then x must be similar to z. Tversky and Gati (1982) provided several examples in which this relationship does not hold."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 775,
                                "start": 0
                            }
                        ],
                        "text": "Krumhansl, 1978; Nosofsky, 1991). In contrast, the topic model can predict the effect of frequency on word association. Word frequency is one of the factors that contribute to P(w2|w1). The model can account for the asymmetries in the word-association norms. As a conditional probability, P(w2|w1) is inherently asymmetric, and the model correctly predicted the direction of 30,905 (79.77%) of the 38,744 asymmetric associations, including all of the examples given above. The topic model thus accounted for almost exactly the same proportion of asymmetries as word frequency\u2014the difference was not statistically significant, (2)(1, 77488) 2.08, p .149. The explanation for asymmetries in word association provided by the topic model is extremely similar to Tversky\u2019s (1977) explanation for asymmetries in similarity judgments."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An associative thesaurus of English and its computer analysis"
            },
            "venue": {
                "fragments": [],
                "text": "The computer and literary studies"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153121908"
                        ],
                        "name": "M. Suter",
                        "slug": "M.-Suter",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Suter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Suter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 111058570,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "491fa6915fdd7a2d83f8c31432db0503743adb95",
            "isKey": false,
            "numCitedBy": 1371,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Small-World-Suter",
            "title": {
                "fragments": [],
                "text": "Small World"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153194668"
                        ],
                        "name": "D. Wells",
                        "slug": "D.-Wells",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wells",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wells"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115272816"
                        ],
                        "name": "A. Aitken",
                        "slug": "A.-Aitken",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Aitken",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aitken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40510443"
                        ],
                        "name": "R. Bailey",
                        "slug": "R.-Bailey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Bailey",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bailey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405368277"
                        ],
                        "name": "N. Hamilton-Smith",
                        "slug": "N.-Hamilton-Smith",
                        "structuredName": {
                            "firstName": "Niall",
                            "lastName": "Hamilton-Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Hamilton-Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 162245754,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "2cf4f36d97d4edc8fd285cb7659e54779073ceb5",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-computer-and-literary-studies-Wells-Aitken",
            "title": {
                "fragments": [],
                "text": "The computer and literary studies"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 147100563,
            "fieldsOfStudy": [],
            "id": "1fd724077ea4ae52d8083115750e4574a2899c64",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantic and Conceptual Development: An Ontological Perspective"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137198"
                        ],
                        "name": "R. Shepard",
                        "slug": "R.-Shepard",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Shepard",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shepard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1835120"
                        ],
                        "name": "P. Arabie",
                        "slug": "P.-Arabie",
                        "structuredName": {
                            "firstName": "Phipps",
                            "lastName": "Arabie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Arabie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 74
                            }
                        ],
                        "text": "If we assume that f( ) is linear (as in additive clustering models, e.g., Shepard & Arabie, 1979) and gives uniform weight to all features, the ratio model becomes\nS(x,y) 1/ 1\nh\n[1 P(x h)]P(y h)\nh\n[1 P(y h)]P(x h)\nh P(x h)P(y h) , (B1) where we take P(x h) to be independent for all x and h."
                    },
                    "intents": []
                }
            ],
            "corpusId": 145626727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ff0e444a98fbd883d0573186160dd532e218207",
            "isKey": false,
            "numCitedBy": 479,
            "numCiting": 119,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Additive-clustering:-Representation-of-similarities-Shepard-Arabie",
            "title": {
                "fragments": [],
                "text": "Additive clustering: Representation of similarities as combinations of discrete overlapping properties."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122137020"
                        ],
                        "name": "John R. Anderson",
                        "slug": "John-R.-Anderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Anderson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John R. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3057917"
                        ],
                        "name": "G. Bower",
                        "slug": "G.-Bower",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Bower",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bower"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 273
                            }
                        ],
                        "text": "\u20261965, p. viii)\nAssociation has been part of the theoretical armory of cognitive psychologists since Thomas Hobbes used the notion to account for the structure of our \u201ctrayne of thoughts\u201d (Hobbes, 1651/1998; detailed histories of association are provided by Deese, 1965, and Anderson & Bower, 1974)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 197658004,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b95f600554bce0850de00c010b7fb1fc39d71d7d",
            "isKey": false,
            "numCitedBy": 2306,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Human-Associative-Memory-Anderson-Bower",
            "title": {
                "fragments": [],
                "text": "Human Associative Memory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728478"
                        ],
                        "name": "D. Norman",
                        "slug": "D.-Norman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Norman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Norman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143879819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8dc2e471cc9994f712fea6b752935aee9dff477b",
            "isKey": false,
            "numCitedBy": 819,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Explorations-in-Cognition-Norman-Rumelhart",
            "title": {
                "fragments": [],
                "text": "Explorations in Cognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16318570"
                        ],
                        "name": "H. Kucera",
                        "slug": "H.-Kucera",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Kucera",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kucera"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35097577"
                        ],
                        "name": "W. Francis",
                        "slug": "W.-Francis",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Francis",
                            "middleNames": [
                                "Nelson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Francis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "75103111"
                        ],
                        "name": "W. Twaddell",
                        "slug": "W.-Twaddell",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Twaddell",
                            "middleNames": [
                                "Freeman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Twaddell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3576908"
                        ],
                        "name": "M. L. Marckworth",
                        "slug": "M.-L.-Marckworth",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marckworth",
                            "middleNames": [
                                "Lois"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. L. Marckworth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054518662"
                        ],
                        "name": "Laura M. Bell",
                        "slug": "Laura-M.-Bell",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Bell",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laura M. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40418506"
                        ],
                        "name": "J. Carroll",
                        "slug": "J.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carroll"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The results of applying the composite model to a combination of the TASA and Brown (Kucera & Francis, 1967) corpora are shown in Figure 17<anchor position=float rid=fig17 ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 143602821,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b7780f292c48e504e3a2724e54c205e6c6221932",
            "isKey": false,
            "numCitedBy": 6758,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computational-analysis-of-present-day-American-Kucera-Francis",
            "title": {
                "fragments": [],
                "text": "Computational analysis of present-day American English"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2391042"
                        ],
                        "name": "F. Keil",
                        "slug": "F.-Keil",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Keil",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Keil"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143169859,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "c0f1794494d8ad39e742fbb91ae1b84a0d0f5d64",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Semantic-and-Conceptual-Development:-An-Ontological-Keil",
            "title": {
                "fragments": [],
                "text": "Semantic and Conceptual Development: An Ontological Perspective"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90127917"
                        ],
                        "name": "F. Keller",
                        "slug": "F.-Keller",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Keller",
                            "middleNames": [
                                "Simmons"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Keller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90121869"
                        ],
                        "name": "W. N. Schoenfeld",
                        "slug": "W.-N.-Schoenfeld",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Schoenfeld",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. N. Schoenfeld"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141625011,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7d2bac5e317324b62b9c94d77486d258d213fafa",
            "isKey": false,
            "numCitedBy": 2031,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Principles-of-Psychology-Keller-Schoenfeld",
            "title": {
                "fragments": [],
                "text": "Principles of Psychology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145392702"
                        ],
                        "name": "P. Green",
                        "slug": "P.-Green",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Green",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Green"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125093681,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3f1bb45d5d20c107daa9dbc489019cf22a3a6e6b",
            "isKey": false,
            "numCitedBy": 4620,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Markov-chain-Monte-Carlo-in-Practice-Green",
            "title": {
                "fragments": [],
                "text": "Markov chain Monte Carlo in Practice"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11882804"
                        ],
                        "name": "S. Fillenbaum",
                        "slug": "S.-Fillenbaum",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Fillenbaum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fillenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48184319"
                        ],
                        "name": "A. Rapoport",
                        "slug": "A.-Rapoport",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Rapoport",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rapoport"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 159
                            }
                        ],
                        "text": "This idea appears in early work exploring the use of statistical methods to extract representations of the meaning of words from human judgments (Deese, 1959; Fillenbaum & Rapoport, 1971)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117766262,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "0b48fed53b50a7eefe902ac561c3b0d0276641e1",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Structures-in-the-subjective-lexicon-Fillenbaum-Rapoport",
            "title": {
                "fragments": [],
                "text": "Structures in the subjective lexicon"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720466"
                        ],
                        "name": "Tapio Elomaa",
                        "slug": "Tapio-Elomaa",
                        "structuredName": {
                            "firstName": "Tapio",
                            "lastName": "Elomaa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tapio Elomaa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712654"
                        ],
                        "name": "H. Mannila",
                        "slug": "H.-Mannila",
                        "structuredName": {
                            "firstName": "Heikki",
                            "lastName": "Mannila",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Mannila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143785973"
                        ],
                        "name": "Hannu (TT) Toivonen",
                        "slug": "Hannu-(TT)-Toivonen",
                        "structuredName": {
                            "firstName": "Hannu",
                            "lastName": "Toivonen",
                            "middleNames": [
                                "(TT)"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hannu (TT) Toivonen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61937001,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f10885417c63e60774619efa729f1c266f5c830",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-13th-European-Conference-on-Elomaa-Mannila",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 13th European Conference on Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3387137"
                        ],
                        "name": "K. Dieussaert",
                        "slug": "K.-Dieussaert",
                        "structuredName": {
                            "firstName": "Kristien",
                            "lastName": "Dieussaert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Dieussaert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145218872"
                        ],
                        "name": "M. Ford",
                        "slug": "M.-Ford",
                        "structuredName": {
                            "firstName": "Marilyn",
                            "lastName": "Ford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2271100"
                        ],
                        "name": "L. Horsten",
                        "slug": "L.-Horsten",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Horsten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Horsten"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64742739,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4645c19d8a52939a4a98076562b3b75fc7a7eee",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-26th-annual-conference-of-the-Dieussaert-Ford",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 26th annual conference of the cognitive science society"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4632093"
                        ],
                        "name": "G. Zipf",
                        "slug": "G.-Zipf",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Zipf",
                            "middleNames": [
                                "Kingsley"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zipf"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 112
                            }
                        ],
                        "text": "The number of meanings or senses that a word possesses has a characteristic distribution, as was first noted by Zipf (1965)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 141120597,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "2bcf3e6c2b45c052a0bd0183cc29c03acc4b49ac",
            "isKey": false,
            "numCitedBy": 7038,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Human-behavior-and-the-principle-of-least-effort-Zipf",
            "title": {
                "fragments": [],
                "text": "Human behavior and the principle of least effort"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1949
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404594758"
                        ],
                        "name": "Virginia Reviewer-Teller",
                        "slug": "Virginia-Reviewer-Teller",
                        "structuredName": {
                            "firstName": "Virginia",
                            "lastName": "Reviewer-Teller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Virginia Reviewer-Teller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60721833,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6ed7d96188fc9c56d93db7eb05f868a8e3469642",
            "isKey": false,
            "numCitedBy": 777,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Review-of-Speech-and-language-processing:-an-to-and-Reviewer-Teller",
            "title": {
                "fragments": [],
                "text": "Review of Speech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition by Daniel Jurafsky and James H. Martin. Prentice Hall 2000."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770124"
                        ],
                        "name": "Sunita Sarawagi",
                        "slug": "Sunita-Sarawagi",
                        "structuredName": {
                            "firstName": "Sunita",
                            "lastName": "Sarawagi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sunita Sarawagi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This relationship is illustrated using graphical model notation (eg, Jordan, 1998; Pearl, 1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 71
                            }
                        ],
                        "text": "This relationship is illustrated using graphical model notation (e.g., Jordan, 1998; Pearl,\n1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5080176,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e4a5edf46e65c87072c85e7362e63210849c69a",
            "isKey": false,
            "numCitedBy": 613,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical models provide a powerful framework for probabilistic modelling and reasoning. Although theory behind learning and inference is well understood, most practical applications require approximation to known algorithms. We review learning of thin junction trees\u2013a class of graphical models that permits efficient inference. We discuss particular cases in clique graphs where exact inference is possible in polynomial time and some special cases where good approximation guarantees can be given. We also point out the drawbacks of learning with approximate inference. Finally, a practical application of probabilistic generative model for learning visual attributes from images is discussed."
            },
            "slug": "Learning-with-Graphical-Models-Sarawagi",
            "title": {
                "fragments": [],
                "text": "Learning with Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Learning of thin junction trees is reviewed\u2013a class of graphical models that permits efficient inference and particular cases in clique graphs where exact inference is possible in polynomial time and some special cases where good approximation guarantees can be given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114366917"
                        ],
                        "name": "S. Ervin",
                        "slug": "S.-Ervin",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Ervin",
                            "middleNames": [
                                "Melanie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ervin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 140
                            }
                        ],
                        "text": "It is not our goal to develop a model of word association, as many factors other than semantic association are involved in this task (e.g., Ervin, 1961; McNeill, 1966), but we believe that issues raised by wordassociation data can provide insight into models of semantic representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 189
                            }
                        ],
                        "text": "However, it is clear that word order is important to many aspects of linguistic processing, including the simple word-association task that we discussed extensively earlier in the article (Ervin, 1961; Hutchinson, 2003; McNeill, 1966)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 40514074,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "51798b870982a96daebc92c25308f37d27420339",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Changes-with-age-in-the-verbal-determinants-of-word-Ervin",
            "title": {
                "fragments": [],
                "text": "Changes with age in the verbal determinants of word association."
            },
            "venue": {
                "fragments": [],
                "text": "The American journal of psychology"
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144263847"
                        ],
                        "name": "J. Deese",
                        "slug": "J.-Deese",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Deese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Deese"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 124
                            }
                        ],
                        "text": "Since Galton, several psychologists have tried to classify kinds of association or to otherwise divine its structure (e.g., Deese, 1962, 1965)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35757129,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "id": "9ccafde7c80cfa67ea4f91917fa007f1b414090e",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-structure-of-associative-meaning.-Deese",
            "title": {
                "fragments": [],
                "text": "On the structure of associative meaning."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 16
                            }
                        ],
                        "text": "Providence, RI: Brown University Press."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 84
                            }
                        ],
                        "text": "The results of applying the composite model to a combination of the TASA and Brown (Kuc\u030cera & Francis, 1967) corpora are shown in Figure 17."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computational analysis of present-day"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 273
                            }
                        ],
                        "text": "\u20261965, p. viii)\nAssociation has been part of the theoretical armory of cognitive psychologists since Thomas Hobbes used the notion to account for the structure of our \u201ctrayne of thoughts\u201d (Hobbes, 1651/1998; detailed histories of association are provided by Deese, 1965, and Anderson & Bower, 1974)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Human associative memory. Washington, DC: Hemisphere"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 227
                            }
                        ],
                        "text": "Most computational approaches to natural language have tended to focus exclusively on either structured representations (e.g., Chomsky, 1965; Pinker, 1999) or sta-\ntistical learning (e.g., Elman, 1990; Plunkett & Marchman, 1993; Rumelhart & McClelland, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On learning the past tenses of English verbs Parallel distributed processing: Explorations in the microstructure of cognition"
            },
            "venue": {
                "fragments": [],
                "text": "On learning the past tenses of English verbs Parallel distributed processing: Explorations in the microstructure of cognition"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 16
                            }
                        ],
                        "text": "Providence, RI: Brown University Press."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 84
                            }
                        ],
                        "text": "The results of applying the composite model to a combination of the TASA and Brown (Kuc\u030cera & Francis, 1967) corpora are shown in Figure 17."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computational analysis of presentday American English"
            },
            "venue": {
                "fragments": [],
                "text": "Computational analysis of presentday American English"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Interpreting the infuence of impicitly activated memories on recall and recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Psychological Review,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 209
                            }
                        ],
                        "text": "\u20261999), variational expectation maximization (Blei et al., 2003; Buntine, 2002), ex-\npectation propagation (Minka & Lafferty, 2002), and several forms of Markov chain Monte Carlo (MCMC; Buntine & Jakulin, 2004; Erosheva, 2002; Griffiths & Steyvers, 2002, 2003, 2004; Pritchard et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Erosheva (2002) described a model, equivalent to a topic model, applied to disability data."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Grade of membership and latent structure models with applications to disability survey data. Unpublished doctoral dissertation"
            },
            "venue": {
                "fragments": [],
                "text": "Grade of membership and latent structure models with applications to disability survey data. Unpublished doctoral dissertation"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 103
                            }
                        ],
                        "text": "Similar algorithms can be used to explore other representations that assume dependencies among topics (Blei & Lafferty, 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Correlated topic models. In Advances in neural information processing systems 18"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 196
                            }
                        ],
                        "text": "Computational modeling in this domain has been mostly concerned with the estimation of the relative strength of different memory routes within the framework of multinomial processing tree models (Batchelder & Riefer, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theoretical and empirical review of multinomial processing tree modeling"
            },
            "venue": {
                "fragments": [],
                "text": "Psychonomic Bulletin & Review"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical Dirichlet processes. In Advances in neural information processing systems (Vol"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "LeviathanOriginal work published 1651 Probabilistic latent semantic indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Twenty-Second Annual International SIGIR Conference"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 157
                            }
                        ],
                        "text": "An algorithm similar to that described in Appendix A can be used to infer the distributions over words associated with the topics and classes from a corpus (Griffiths et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 218
                            }
                        ],
                        "text": "The model performs about as well as a standard hidden Markov model\u2014which is a state-of-the-art method\u2014at identifying syntactic classes, and it outperforms distributional clustering (Redington et al., 1998) in this task (Griffiths et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Integrating topics and syntax. In Advances in neural information processing systems (Vol"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 254
                            }
                        ],
                        "text": "\u2026and statistics derived from these norms have been shown to be important in predicting cued recall (Nelson, McKinney, Gee, & Janczura, 1998), recognition (Nelson, McKinney, et al., 1998; Nelson, Zhang, & McKinney, 2001), and false memories (Deese, 1959; McEvoy et al., 1999; Roediger et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 61
                            }
                        ],
                        "text": ", 1998; Nelson, Zhang, & McKinney, 2001), and false memories (Deese, 1959; McEvoy et al., 1999; Roediger et al., 2001)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "What's the connection between true and false memories: The different roles of inter-item associations in recall and recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Experimental Psychology: Learning, Memory, and Cognition"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The author-topic model for"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 16
                            }
                        ],
                        "text": "Providence, RI: Brown University Press."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 84
                            }
                        ],
                        "text": "The results of applying the composite model to a combination of the TASA and Brown (Kuc\u030cera & Francis, 1967) corpora are shown in Figure 17."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computational analysis of presentday"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 34
                            }
                        ],
                        "text": "A standard\nmeasure of clustering (Watts & Strogatz, 1998) is the clustering coefficient, C , the mean proportion of the neighbors of a node that are also neighbors of one another."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Collective dynamics of \u201csmall-world"
            },
            "venue": {
                "fragments": [],
                "text": "networks. Nature,"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 77,
            "methodology": 57,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 141,
        "totalPages": 15
    },
    "page_url": "https://www.semanticscholar.org/paper/Topics-in-semantic-representation.-Griffiths-Steyvers/509a2ca90a85c62d66a16b37e0de28715dd4e89f?sort=total-citations"
}