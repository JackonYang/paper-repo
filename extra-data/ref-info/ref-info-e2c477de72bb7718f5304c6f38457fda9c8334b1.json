{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799147"
                        ],
                        "name": "F. Ratle",
                        "slug": "F.-Ratle",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Ratle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ratle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3232655"
                        ],
                        "name": "H. Mobahi",
                        "slug": "H.-Mobahi",
                        "structuredName": {
                            "firstName": "Hossein",
                            "lastName": "Mobahi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Mobahi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "(Weston et al., 2008) presents a similar approach for neural networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 1
                            }
                        ],
                        "text": "(Weston et al., 2008) presents a similar ap\u00adproach for \nneural networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 740114,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ee368e60d0b826e78f965aad8d6c7d406127104",
            "isKey": false,
            "numCitedBy": 612,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how nonlinear embedding algorithms popular for use with shallow semi-supervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture. This provides a simple alternative to existing approaches to deep learning whilst yielding competitive error rates compared to those methods, and existing shallow semi-supervised techniques."
            },
            "slug": "Deep-learning-via-semi-supervised-embedding-Weston-Ratle",
            "title": {
                "fragments": [],
                "text": "Deep learning via semi-supervised embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "It is shown how nonlinear embedding algorithms popular for use with shallow semi-supervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706109"
                        ],
                        "name": "H. Wersing",
                        "slug": "H.-Wersing",
                        "structuredName": {
                            "firstName": "Heiko",
                            "lastName": "Wersing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wersing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115105"
                        ],
                        "name": "E. K\u00f6rner",
                        "slug": "E.-K\u00f6rner",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "K\u00f6rner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. K\u00f6rner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 257
                            }
                        ],
                        "text": "\u2026&#38; K\u00a8orner, 2003) (Nearest Neighbor), an eigenspace \nplus spline recognition model (Nayar et al., 1996) (Eigen Spline), a SpinGlass Markov Random Field (SpinGlass \nMRF) (Caputo et al., 2002), and a hierarchical view-tuned network for visual recognition tasks (VTU) \n(Wersing &#38; K\u00a8orner, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 45
                            }
                        ],
                        "text": "Both 30 and 100 objects were used following (Wersing &#38; K\u00a8orner, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 147
                            }
                        ],
                        "text": "These \ninclude Support Vector Machines (SVM) using a polynomial kernel (Roobaert &#38; Hulle, 1999), a nearest \nneighbor classi.er on the direct images (Wersing &#38; K\u00a8orner, 2003) (Nearest Neighbor), an eigenspace \nplus spline recognition model (Nayar et al., 1996) (Eigen Spline), a SpinGlass\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 247
                            }
                        ],
                        "text": "We show that in this case, temporal coherence in video acts as a very good regularizer, and that, without \nus\u00ading hand-crafted or strongly engineered features one can produce models that compete with state-of-the-art \nhand-designed methods like VTU (Wersing &#38; K\u00a8orner, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3645746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d44f85fcc2eaa17e3c08313ad3ce70f8accf46fb",
            "isKey": true,
            "numCitedBy": 203,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "There is an ongoing debate over the capabilities of hierarchical neural feedforward architectures for performing real-world invariant object recognition. Although a variety of hierarchical models exists, appropriate supervised and unsupervised learning methods are still an issue of intense research. We propose a feedforward model for recognition that shares components like weight sharing, pooling stages, and competitive nonlinearities with earlier approaches but focuses on new methods for learning optimal feature-detecting cells in intermediate stages of the hierarchical network. We show that principles of sparse coding, which were previously mostly applied to the initial feature detection stages, can also be employed to obtain optimized intermediate complex features. We suggest a new approach to optimize the learning of sparse features under the constraints of a weight-sharing or convolutional architecture that uses pooling operations to achieve gradual invariance in the feature hierarchy. The approach explicitly enforces symmetry constraints like translation invariance on the feature set. This leads to a dimension reduction in the search space of optimal features and allows determining more efficiently the basis representatives, which achieve a sparse decomposition of the input. We analyze the quality of the learned feature representation by investigating the recognition performance of the resulting hierarchical network on object and face databases. We show that a hierarchy with features learned on a single object data set can also be applied to face recognition without parameter changes and is competitive with other recent machine learning recognition approaches. To investigate the effect of the interplay between sparse coding and processing nonlinearities, we also consider alternative feedforward pooling nonlinearities such as presynaptic maximum selection and sum-of-squares integration. The comparison shows that a combination of strong competitive nonlinearities with sparse coding offers the best recognition performance in the difficult scenario of segmentation-free recognition in cluttered surround. We demonstrate that for both learning and recognition, a precise segmentation of the objects is not necessary."
            },
            "slug": "Learning-Optimized-Features-for-Hierarchical-Models-Wersing-K\u00f6rner",
            "title": {
                "fragments": [],
                "text": "Learning Optimized Features for Hierarchical Models of Invariant Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a feedforward model for recognition that shares components like weight sharing, pooling stages, and competitive nonlinearities with earlier approaches but focuses on new methods for learning optimal feature-detecting cells in intermediate stages of the hierarchical network."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3295092"
                        ],
                        "name": "S. Chopra",
                        "slug": "S.-Chopra",
                        "structuredName": {
                            "firstName": "Sumit",
                            "lastName": "Chopra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chopra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2315504"
                        ],
                        "name": "R. Hadsell",
                        "slug": "R.-Hadsell",
                        "structuredName": {
                            "firstName": "Raia",
                            "lastName": "Hadsell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hadsell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 10
                            }
                        ],
                        "text": "Further, (Chopra et al., 2005) applied a siamese network similar to ours but for a fully \nsupervised (not semi-supervised) face simi\u00adlarity task (not using video)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 9
                            }
                        ],
                        "text": "Further, (Chopra et al., 2005) applied a siamese network similar to ours but for a fully supervised (not semi-supervised) face similarity task (not using video)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5555257,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfaae9b6857b834043606df3342d8dc97524aa9d",
            "isKey": false,
            "numCitedBy": 2899,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for training a similarity metric from data. The method can be used for recognition or verification applications where the number of categories is very large and not known during training, and where the number of training samples for a single category is very small. The idea is to learn a function that maps input patterns into a target space such that the L/sub 1/ norm in the target space approximates the \"semantic\" distance in the input space. The method is applied to a face verification task. The learning process minimizes a discriminative loss function that drives the similarity metric to be small for pairs of faces from the same person, and large for pairs from different persons. The mapping from raw to the target space is a convolutional network whose architecture is designed for robustness to geometric distortions. The system is tested on the Purdue/AR face database which has a very high degree of variability in the pose, lighting, expression, position, and artificial occlusions such as dark glasses and obscuring scarves."
            },
            "slug": "Learning-a-similarity-metric-discriminatively,-with-Chopra-Hadsell",
            "title": {
                "fragments": [],
                "text": "Learning a similarity metric discriminatively, with application to face verification"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The idea is to learn a function that maps input patterns into a target space such that the L/sub 1/ norm in the target space approximates the \"semantic\" distance in the input space."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700737"
                        ],
                        "name": "Margarita Osadchy",
                        "slug": "Margarita-Osadchy",
                        "structuredName": {
                            "firstName": "Margarita",
                            "lastName": "Osadchy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Margarita Osadchy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111207598"
                        ],
                        "name": "Matthew L. Miller",
                        "slug": "Matthew-L.-Miller",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Miller",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew L. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 145
                            }
                        ],
                        "text": "CNNs have justi.ed themselves \nin many visual recognitions tasks including handwritten digit recognition (LeCun et al., 1998) and face \ndetection (Osadchy et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 688047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b728a7442ca158f895d07c11c77d302269a832d",
            "isKey": false,
            "numCitedBy": 409,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel method for real-time, simultaneous multi-view face detection and facial pose estimation. The method employs a convolutional network to map face images to points on a manifold, parametrized by pose, and non-face images to points far from that manifold. This network is trained by optimizing a loss function of three variables: image, pose, and face/non-face label. We test the resulting system, in a single configuration, on three standard data sets - one for frontal pose, one for rotated faces, and one for profiles - and find that its performance on each set is comparable to previous multi-view face detectors that can only handle one form of pose variation. We also show experimentally that the system's accuracy on both face detection and pose estimation is improved by training for the two tasks together."
            },
            "slug": "Synergistic-Face-Detection-and-Pose-Estimation-with-Osadchy-LeCun",
            "title": {
                "fragments": [],
                "text": "Synergistic Face Detection and Pose Estimation with Energy-Based Models"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A novel method for real-time, simultaneous multi-view face detection and facial pose estimation that employs a convolutional network to map face images to points on a manifold, parametrized by pose, and non-face images to Points far from that manifold is described."
            },
            "venue": {
                "fragments": [],
                "text": "Toward Category-Level Object Recognition"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1699015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8346df569441c6f7778340744d4a955013299c1d",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper argues that tracking, object detection, and model building are all similar activities. We describe a fully automatic system that builds 2D articulated models known as pictorial structures from videos of animals. The learned model can be used to detect the animal in the original video - in this sense, the system can be viewed as a generalized tracker (one that is capable of modeling objects while tracking them). The learned model can be matched to a visual library; here, the system can be viewed as a video recognition algorithm. The learned model can also be used to detect the animal in novel images - in this case, the system can be seen as a method for learning models for object recognition. We find that we can significantly improve the pictorial structures by augmenting them with a discriminative texture model learned from a texture library. We develop a novel texture descriptor that outperforms the state-of-the-art for animal textures. We demonstrate the entire system on real video sequences of three different animals. We show that we can automatically track and identify the given animal. We use the learned models to recognize animals from two data sets; images taken by professional photographers from the Corel collection, and assorted images from the Web returned by Google. We demonstrate quite good performance on both data sets. Comparing our results with simple baselines, we show that, for the Google set, we can detect, localize, and recover part articulations from a collection demonstrably hard for object recognition"
            },
            "slug": "Building-models-of-animals-from-video-Ramanan-Forsyth",
            "title": {
                "fragments": [],
                "text": "Building models of animals from video"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "It is argued that tracking, object detection, and model building are all similar activities, and a fully automatic system that builds 2D articulated models known as pictorial structures from videos of animals is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1905146"
                        ],
                        "name": "H. Noor",
                        "slug": "H.-Noor",
                        "structuredName": {
                            "firstName": "Humera",
                            "lastName": "Noor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Noor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21496185"
                        ],
                        "name": "S. H. Mirza",
                        "slug": "S.-H.-Mirza",
                        "structuredName": {
                            "firstName": "Shahid",
                            "lastName": "Mirza",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. H. Mirza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774867"
                        ],
                        "name": "Yaser Sheikh",
                        "slug": "Yaser-Sheikh",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Sheikh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaser Sheikh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116199969"
                        ],
                        "name": "Amit Jain",
                        "slug": "Amit-Jain",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amit Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Noor et al (2006)  learn a graph with each node being a dierent appearance of an object connected to temporally proximal nodes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14203693,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "269748d0489d68140ae00d325a9f12baf8046fcc",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach to object recognition involving a sparse 2D model and matching using video. The model is generated on the basis of geometry and image measurables only. We first identify the underlying topological structure of an image dataset containing different views of the objects and represent it as a neighborhood graph. The graph is then refined by identifying redundant images and removing them using morphing. This gives a smaller dataset leading to reduced space requirements and faster matching. Finally we exploit motion continuity in video and extend our algorithm to perform matching based on video input and demonstrate that the results obtained using a video sequence are much robust than using a single image. Our approach is novel in that we do not require any knowledge of camera calibration or viewpoint while generating the model. We also do not assume any constraint on motion of object in test video other than following a smooth trajectory."
            },
            "slug": "Model-generation-for-video-based-object-recognition-Noor-Mirza",
            "title": {
                "fragments": [],
                "text": "Model generation for video-based object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper first identifies the underlying topological structure of an image dataset containing different views of the objects and represents it as a neighborhood graph, which gives a smaller dataset leading to reduced space requirements and faster matching."
            },
            "venue": {
                "fragments": [],
                "text": "MM '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50333420"
                        ],
                        "name": "S. Becker",
                        "slug": "S.-Becker",
                        "structuredName": {
                            "firstName": "Suzanna",
                            "lastName": "Becker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Becker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 12
                            }
                        ],
                        "text": "The work of Becker (1996a; 1999), which is proba\u00adbly the most related work to ours, \nexplores the use of temporal context using a fully connect neural network algorithm which introduces \nextra neurons, called con\u00adtextual gating units, and a Hebbian update rule for clustering based on context \n(\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 15
                            }
                        ],
                        "text": "Wiskott, L., &#38; Sejnowski, T. (2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 76
                            }
                        ],
                        "text": "From a biological point of view, several authors (Hin\u00adton &#38; \nSejnowski, 1999; Becker, 1996a) argue that pure supervised learning is a poor model of how animals really \nlearn."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 14
                            }
                        ],
                        "text": "Hinton, G., &#38; Sejnowski, T. (1999)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15969073,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67a90c040b4cafe5067a0d46d6ed2cb6f6036e1a",
            "isKey": true,
            "numCitedBy": 14,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A biologically motivated model of cortical self-organization is proposed. Context is combined with bottom-up information via a maximum likelihood cost function. Clusters of one or more units are modulated by a common contextual gating Signal; they thereby organize themselves into mutually supportive predictors of abstract contextual features. The model was tested in its ability to discover viewpoint-invariant classes on a set of real image sequences of centered, gradually rotating faces. It performed considerably better than supervised back-propagation at generalizing to novel views from a small number of training examples."
            },
            "slug": "Learning-Temporally-Persistent-Hierarchical-Becker",
            "title": {
                "fragments": [],
                "text": "Learning Temporally Persistent Hierarchical Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "The proposed biologically motivated model of cortical self-organization performed considerably better than supervised back-propagation at generalizing to novel views from a small number of training examples."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687780"
                        ],
                        "name": "Michael Bowling",
                        "slug": "Michael-Bowling",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bowling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Bowling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38565890"
                        ],
                        "name": "A. Ghodsi",
                        "slug": "A.-Ghodsi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Ghodsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ghodsi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28124748"
                        ],
                        "name": "Dana F. Wilkinson",
                        "slug": "Dana-F.-Wilkinson",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Wilkinson",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dana F. Wilkinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 9
                            }
                        ],
                        "text": "See also (Bowling et al., 2005) for an embedding algorithm using the actions of a robot which seems related to our work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 10
                            }
                        ],
                        "text": "See also (Bowling et al., 2005) \nfor an embedding algorithm using the actions of a robot which seems related to our work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1616957,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4972fd2743c8122255229fa39bf08fa370c3e189",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Dimensionality reduction is the problem of finding a low-dimensional representation of high-dimensional input data. This paper examines the case where additional information is known about the data. In particular, we assume the data are given in a sequence with action labels associated with adjacent data points, such as might come from a mobile robot. The goal is a variation on dimensionality reduction, where the output should be a representation of the input data that is both low-dimensional and respects the actions (i.e., actions correspond to simple transformations in the output representation). We show how this variation can be solved with a semidefinite program. We evaluate the technique in a synthetic, robot-inspired domain, demonstrating qualitatively superior representations and quantitative improvements on a data prediction task."
            },
            "slug": "Action-respecting-embedding-Bowling-Ghodsi",
            "title": {
                "fragments": [],
                "text": "Action respecting embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper examines the case where additional information is known about the data and shows how this variation can be solved with a semidefinite program, and evaluates the technique in a synthetic, robot-inspired domain, demonstrating qualitatively superior representations and quantitative improvements on a data prediction task."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 143
                            }
                        ],
                        "text": "Scaling to more classes has been shown to be possi\u00adble using click-through data from \nsearch engines, like in the recent 80 million tiny images (Torralba et al., 2008) database."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7487588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54d2b5c64a67f65c5dd812b89e07973f97699552",
            "isKey": false,
            "numCitedBy": 1868,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "With the advent of the Internet, billions of images are now freely available online and constitute a dense sampling of the visual world. Using a variety of non-parametric methods, we explore this world with the aid of a large dataset of 79,302,017 images collected from the Internet. Motivated by psychophysical results showing the remarkable tolerance of the human visual system to degradations in image resolution, the images in the dataset are stored as 32 x 32 color images. Each image is loosely labeled with one of the 75,062 non-abstract nouns in English, as listed in the Wordnet lexical database. Hence the image database gives a comprehensive coverage of all object categories and scenes. The semantic information from Wordnet can be used in conjunction with nearest-neighbor methods to perform object classification over a range of semantic levels minimizing the effects of labeling noise. For certain classes that are particularly prevalent in the dataset, such as people, we are able to demonstrate a recognition performance comparable to class-specific Viola-Jones style detectors."
            },
            "slug": "80-Million-Tiny-Images:-A-Large-Data-Set-for-Object-Torralba-Fergus",
            "title": {
                "fragments": [],
                "text": "80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "For certain classes that are particularly prevalent in the dataset, such as people, this work is able to demonstrate a recognition performance comparable to class-specific Viola-Jones style detectors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 38
                            }
                        ],
                        "text": "Huge \nhand-labeled datasets like NORB (LeCun et al., 2004) can be con\u00adstructed e.g. by considering a few objects \nand varying the pose (using a rotating platform) as well as lighting conditions, the presence of clutter \nand the background."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 37
                            }
                        ],
                        "text": "Huge hand-labeled datasets like NORB (LeCun et al., 2004) can be constructed e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 712708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f354310098e09c1e1dc88758fca36767fd9d084d",
            "isKey": false,
            "numCitedBy": 1306,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second."
            },
            "slug": "Learning-methods-for-generic-object-recognition-to-LeCun-Huang",
            "title": {
                "fragments": [],
                "text": "Learning methods for generic object recognition with invariance to pose and lighting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second and proved impractical, while convolutional nets yielded 16/7% error."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145840115"
                        ],
                        "name": "S. Lawrence",
                        "slug": "S.-Lawrence",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Lawrence",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lawrence"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733691"
                        ],
                        "name": "A. Tsoi",
                        "slug": "A.-Tsoi",
                        "structuredName": {
                            "firstName": "Ah",
                            "lastName": "Tsoi",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144288586"
                        ],
                        "name": "A. Back",
                        "slug": "A.-Back",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Back",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Back"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, we use a deep convolutional network architecture that can tolerate partial translation, scaling and rotation (Lawrence et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2883848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86890c82b589e24007c56e1f40c5f928a0e04183",
            "isKey": false,
            "numCitedBy": 2719,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer."
            },
            "slug": "Face-recognition:-a-convolutional-neural-network-Lawrence-Giles",
            "title": {
                "fragments": [],
                "text": "Face recognition: a convolutional neural-network approach"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A hybrid neural-network for human face recognition which compares favourably with other methods and analyzes the computational complexity and discusses how new classes could be added to the trained recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66191239"
                        ],
                        "name": "Bernhard Schlkopf",
                        "slug": "Bernhard-Schlkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Schlkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernhard Schlkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281542"
                        ],
                        "name": "A. Zien",
                        "slug": "A.-Zien",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Zien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zien"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60860751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ee8a371fc5adc5469435020a52fb815f3b57a71",
            "isKey": false,
            "numCitedBy": 2539,
            "numCiting": 473,
            "paperAbstract": {
                "fragments": [],
                "text": "In the field of machine learning, semi-supervised learning (SSL) occupies the middle ground, between supervised learning (in which all training examples are labeled) and unsupervised learning (in which no label data are given). Interest in SSL has increased in recent years, particularly because of application domains in which unlabeled data are plentiful, such as images, text, and bioinformatics. This first comprehensive overview of SSL presents state-of-the-art algorithms, a taxonomy of the field, selected applications, benchmark experiments, and perspectives on ongoing and future research. Semi-Supervised Learning first presents the key assumptions and ideas underlying the field: smoothness, cluster or low-density separation, manifold structure, and transduction. The core of the book is the presentation of SSL methods, organized according to algorithmic strategies. After an examination of generative models, the book describes algorithms that implement the low-density separation assumption, graph-based methods, and algorithms that perform two-step learning. The book then discusses SSL applications and offers guidelines for SSL practitioners by analyzing the results of extensive benchmark experiments. Finally, the book looks at interesting directions for SSL research. The book closes with a discussion of the relationship between semi-supervised learning and transduction. Adaptive Computation and Machine Learning series"
            },
            "slug": "Semi-Supervised-Learning-Chapelle-Schlkopf",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This first comprehensive overview of semi-supervised learning presents state-of-the-art algorithms, a taxonomy of the field, selected applications, benchmark experiments, and perspectives on ongoing and future research."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145520115"
                        ],
                        "name": "Mikhail Belkin",
                        "slug": "Mikhail-Belkin",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Belkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikhail Belkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770745"
                        ],
                        "name": "P. Niyogi",
                        "slug": "P.-Niyogi",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Niyogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Niyogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808676"
                        ],
                        "name": "V. Sindhwani",
                        "slug": "V.-Sindhwani",
                        "structuredName": {
                            "firstName": "Vikas",
                            "lastName": "Sindhwani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sindhwani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 27
                            }
                        ],
                        "text": "For example, Laplacian SVM (Belkin et al., 2005) works by directly regularizing for a two-class SVM that ||f(x) \u2212 f(x\u2032)||2 should be small for two examples x and x\u2032 connected in the graph."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 28
                            }
                        ],
                        "text": "For example, Laplacian SVM (Belkin et al., \n2005) works by directly regulariz\u00ading for a two-class SVM that ||f(x) - f(xl)||2 should be small for \ntwo examples x and xl connected in the graph."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16542509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7ed5131f83783a43705db78ac5c05034659893f",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a family of learning algorithms based on a new form of regularization that allows us to exploit the geometry of the marginal distribution. We focus on a semisupervised framework that incorporates labeled and unlabeled data in a generalpurpose learner. Some transductive graph learning algorithms and standard methods including Support Vector Machines and Regularized Least Squares can be obtained as special cases. We utilize properties of Reproducing Kernel Hilbert spaces to prove new Representer theorems that provide theoretical basis for the algorithms. As a result (in contrast to purely graph based approaches) we obtain a natural out-of-sample extension to novel examples and are thus able to handle both transductive and truly semi-supervised settings. We present experimental evidence suggesting that our semisupervised algorithms are able to use unlabeled data effectively. In the absence of labeled examples, our framework gives rise to a regularized form of spectral clustering with an out-of-sample extension."
            },
            "slug": "On-Manifold-Regularization-Belkin-Niyogi",
            "title": {
                "fragments": [],
                "text": "On Manifold Regularization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A semisupervised framework that incorporates labeled and unlabeled data in a generalpurpose learner and gives rise to a regularized form of spectral clustering with an out-of-sample extension is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281542"
                        ],
                        "name": "A. Zien",
                        "slug": "A.-Zien",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Zien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zien"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 108
                            }
                        ],
                        "text": "Several authors argue \nthat this makes an assumption that the decision rule lies in a region of low density (Chapelle &#38; \nZien, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14283441,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2c5d2cafc35856832f2b478790f0af119baab92",
            "isKey": false,
            "numCitedBy": 839,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We believe that the cluster assumption is key to successful semi-supervised learning. Based on this, we propose three semi-supervised algorithms: 1. deriving graph-based distances that emphazise low density regions between clusters, followed by training a standard SVM; 2. optimizing the Transductive SVM objective function, which places the decision boundary in low density regions, by gradient descent; 3. combining the first two to make maximum use of the cluster assumption. We compare with state of the art algorithms and demonstrate superior accuracy for the latter two methods."
            },
            "slug": "Semi-Supervised-Classification-by-Low-Density-Chapelle-Zien",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Classification by Low Density Separation"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "Three semi-supervised algorithms are proposed: deriving graph-based distances that emphazise low density regions between clusters, followed by training a standard SVM, and optimizing the Transductive SVM objective function by gradient descent."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 54
                            }
                        ],
                        "text": "Previous and Related Work Temporal \nCoherence Learning Wiskott and Se\u00adjnowski (2002) learn invariant (slowly varying) fea\u00adtures from unsupervised \nvideo based on a reconstruc\u00adtion loss."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12366835,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5127759530ce213f488af2859190697770f557f3",
            "isKey": false,
            "numCitedBy": 1188,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Invariant features of temporally varying signals are useful for analysis and classification. Slow feature analysis (SFA) is a new method for learning invariant or slowly varying features from a vectorial input signal. It is based on a nonlinear expansion of the input signal and application of principal component analysis to this expanded signal and its time derivative. It is guaranteed to find the optimal solution within a family of functions directly and can learn to extract a large number of decor-related features, which are ordered by their degree of invariance. SFA can be applied hierarchically to process high-dimensional input signals and extract complex features. SFA is applied first to complex cell tuning properties based on simple cell output, including disparity and motion. Then more complicated input-output functions are learned by repeated application of SFA. Finally, a hierarchical network of SFA modules is presented as a simple model of the visual system. The same unstructured network can learn translation, size, rotation, contrast, or, to a lesser degree, illumination invariance for one-dimensional objects, depending on only the training stimulus. Surprisingly, only a few training objects suffice to achieve good generalization to new objects. The generated representation is suitable for object recognition. Performance degrades if the network is trained to learn multiple invariances simultaneously."
            },
            "slug": "Slow-Feature-Analysis:-Unsupervised-Learning-of-Wiskott-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Slow Feature Analysis: Unsupervised Learning of Invariances"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Slow feature analysis (SFA) is a new method for learning invariant or slowly varying features from a vectorial input signal that is guaranteed to find the optimal solution within a family of functions directly and can learn to extract a large number of decor-related features, which are ordered by their degree of invariance."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50333420"
                        ],
                        "name": "S. Becker",
                        "slug": "S.-Becker",
                        "structuredName": {
                            "firstName": "Suzanna",
                            "lastName": "Becker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Becker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 12
                            }
                        ],
                        "text": "The work of Becker (1996a; 1999), which is proba\u00adbly the most related work to ours, \nexplores the use of temporal context using a fully connect neural network algorithm which introduces \nextra neurons, called con\u00adtextual gating units, and a Hebbian update rule for clustering based on context \n(\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11543550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c376c32d208881756f7328406fc062068a8776d",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel architecture and set of learning rules for cortical self-organization is proposed. The model is based on the idea that multiple information channels can modulate one another's plasticity. Features learned from bottom-up information sources can thus be influenced by those learned from contextual pathways, and vice versa. A maximum likelihood cost function allows this scheme to be implemented in a biologically feasible, hierarchical neural circuit. In simulations of the model, we first demonstrate the utility of temporal context in modulating plasticity. The model learns a representation that categorizes people's faces according to identity, independent of viewpoint, by taking advantage of the temporal continuity in image sequences. In a second set of simulations, we add plasticity to the contextual stream and explore variations in the architecture. In this case, the model learns a two-tiered representation, starting with a coarse view-based clustering and proceeding to a finer clustering of more specific stimulus features. This model provides a tenable account of how people may perform 3D object recognition in a hierarchical, bottom-up fashion."
            },
            "slug": "Implicit-Learning-in-3D-Object-Recognition:-The-of-Becker",
            "title": {
                "fragments": [],
                "text": "Implicit Learning in 3D Object Recognition: The Importance of Temporal Context"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This model provides a tenable account of how people may perform 3D object recognition in a hierarchical, bottom-up fashion and a maximum likelihood cost function allows this scheme to be implemented in a biologically feasible, hierarchical neural circuit."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50333420"
                        ],
                        "name": "S. Becker",
                        "slug": "S.-Becker",
                        "structuredName": {
                            "firstName": "Suzanna",
                            "lastName": "Becker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Becker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 0
                            }
                        ],
                        "text": "Becker and Hinton (1992; 1996b) also introduced the IMAX method that \nmaximizes the mutual information between di.erent output units which can be applied to learning spacial \nor temporal coherency."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4332326,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c85b7fe70dda0adbbd7630e2a341a904c74fbd2",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "THE standard form of back-propagation learning1 is implausible as a model of perceptual learning because it requires an external teacher to specify the desired output of the network. We show how the external teacher can be replaced by internally derived teaching signals. These signals are generated by using the assumption that different parts of the perceptual input have common causes in the external world. Small modules that look at separate but related parts of the perceptual input discover these common causes by striving to produce outputs that agree with each other (Fig. la). The modules may look at different modalities (such as vision and touch), or the same modality at different times (for example, the consecutive two-dimensional views of a rotating three-dimensional object), or even spatially adjacent parts of the same image. Our simulations show that when our learning procedure is applied to adjacent patches of two-dimensional images, it allows a neural network that has no prior knowledge of the third dimension to discover depth in random dot stereograms of curved surfaces."
            },
            "slug": "Self-organizing-neural-network-that-discovers-in-Becker-Hinton",
            "title": {
                "fragments": [],
                "text": "Self-organizing neural network that discovers surfaces in random-dot stereograms"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The authors' simulations show that when the learning procedure is applied to adjacent patches of two-dimensional images, it allows a neural network that has no prior knowledge of the third dimension to discover depth in random dot stereograms of curved surfaces."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 50
                            }
                        ],
                        "text": "From a biological point of view, several authors (Hin\u00adton &#38; \nSejnowski, 1999; Becker, 1996a) argue that pure supervised learning is a poor model of how animals really \nlearn."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 568745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d62bcde418144411068d5b09952090962fbc05f6",
            "isKey": false,
            "numCitedBy": 1397,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised learning studies how systems can learn to represent particular input patterns in a way that reflects the statistical structure of the overall collection of input patterns. By contrast with SUPERVISED LEARNING or REINFORCEMENT LEARNING, there are no explicit target outputs or environmental evaluations associated with each input; rather the unsupervised learner brings to bear prior biases as to what aspects of the structure of the input should be captured in the output."
            },
            "slug": "Unsupervised-Learning-Hinton-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Unsupervised learning studies how systems can learn to represent particular input patterns in a way that reflects the statistical structure of the overall collection of input patterns."
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Machine Learning and Data Mining"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5928200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb0c1e3d880e361b7ff61e5ac1d489cb75c55ece",
            "isKey": false,
            "numCitedBy": 789,
            "numCiting": 939,
            "paperAbstract": {
                "fragments": [],
                "text": "All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from this is the last candidate. next esc will revert to uncompleted text. he publisher. Overview Dataset shift is a challenging situation where the joint distribution of inputs and outputs differs between the training and test stages. Covariate shift is a simpler particular case of dataset shift where only the input distribution changes (covariate denotes input), while the conditional distribution of the outputs given the inputs p(y|x) remains unchanged. Dataset shift is present in most practical applications for reasons ranging from the bias introduced by experimental design, to the mere irreproducibility of the testing conditions at training time. For example, in an image classification task, training data might have been recorded under controlled laboratory conditions, whereas the test data may show different lighting conditions. In other applications, the process that generates data is in itself adaptive. Some of our authors consider the problem of spam email filtering: successful \" spammers \" will try to build spam in a form that differs from the spam the automatic filter has been built on. Dataset shift seems to have raised relatively little interest in the machine learning community until very recently. Indeed, many machine learning algorithms are based on the assumption that the training data is drawn from exactly the same distribution as the test data on which the model will later be evaluated. Semi-supervised learning and active learning, two problems that seem very similar to covariate shift have received much more attention. How do they differ from covariate shift? Semi-supervised learning is designed to take advantage of unlabeled data present at training time, but is not conceived to be robust against changes in the input distribution. In fact, one can easily construct examples of covariate shift for which common SSL strategies such as the \" cluster assumption \" will lead to disaster. In active learning the algorithm is asked to select from the available unlabeled inputs those for which obtaining the label will be most beneficial for learning. This is very relevant in contexts where labeling data is very costly, but active learning strategies 2 Contents are not specifically design for dealing with covariate shift. This book attempts to give an overview of the different recent efforts that are being \u2026"
            },
            "slug": "Adaptive-computation-and-machine-learning-Dietterich",
            "title": {
                "fragments": [],
                "text": "Adaptive computation and machine learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This book attempts to give an overview of the different recent efforts to deal with covariate shift, a challenging situation where the joint distribution of inputs and outputs differs between the training and test stages."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2667432"
                        ],
                        "name": "D. Roobaert",
                        "slug": "D.-Roobaert",
                        "structuredName": {
                            "firstName": "Danny",
                            "lastName": "Roobaert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roobaert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119793231"
                        ],
                        "name": "M. V. Van Hulle",
                        "slug": "M.-V.-Van-Hulle",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Van Hulle",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. V. Van Hulle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 71
                            }
                        ],
                        "text": "These \ninclude Support Vector Machines (SVM) using a polynomial kernel (Roobaert &#38; Hulle, 1999), a nearest \nneighbor classi.er on the direct images (Wersing &#38; K\u00a8orner, 2003) (Nearest Neighbor), an eigenspace \nplus spline recognition model (Nayar et al., 1996) (Eigen Spline), a SpinGlass\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62723522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ff9da53833b421eeb514e92c734c3c06cf194ec",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Support vector machines have demonstrated excellent results in pattern recognition tasks and 3D object recognition. We confirm some of the results in 3D object recognition and compare it to other object recognition systems. We use different pixel-level representations to perform the experiments, while we extend the setting to the more challenging and practical case when only a limited number of views of the object are presented during training. We report high correct classification of unseen views, especially considering that no domain knowledge is including into the proposed system. Finally, we suggest an active learning algorithm to reduce further the required number of training views."
            },
            "slug": "View-based-3D-object-recognition-with-support-Roobaert-Hulle",
            "title": {
                "fragments": [],
                "text": "View-based 3D object recognition with support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work reports high correct classification of unseen views, especially considering that no domain knowledge is including into the proposed system, and suggests an active learning algorithm to reduce further the required number of training views."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40372975"
                        ],
                        "name": "Rui Huang",
                        "slug": "Rui-Huang",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rui Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711560"
                        ],
                        "name": "Dimitris N. Metaxas",
                        "slug": "Dimitris-N.-Metaxas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris N. Metaxas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144658464"
                        ],
                        "name": "V. Pavlovic",
                        "slug": "V.-Pavlovic",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Pavlovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Pavlovic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "Spin Glass MRF essentially uses an energy function in\u00adspired by models of \nphysics of disordered systems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 318,
                                "start": 315
                            }
                        ],
                        "text": "These \ninclude Support Vector Machines (SVM) using a polynomial kernel (Roobaert &#38; Hulle, 1999), a nearest \nneighbor classi.er on the direct images (Wersing &#38; K\u00a8orner, 2003) (Nearest Neighbor), an eigenspace \nplus spline recognition model (Nayar et al., 1996) (Eigen Spline), a SpinGlass Markov Random Field (SpinGlass \nMRF) (Caputo et al., 2002), and a hierarchical view-tuned network for visual recognition tasks (VTU) \n(Wersing &#38; K\u00a8orner, 2003)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Method Nearest Neighbor 30 objects 81.8 100 objects 70.1 SVM 84.9 74.6 \nSpinGlass MRF 82.79 69.41 Eigen Spline 84.6 77.0 VTU Standard CNN videoCNN V:COIL100 videoCNN V:COIL \n70videoCNN V:COIL-LivideoCNN V:Animal 89.9 84.88 - 95.03 ke -- 79.1 71.49 92.25 -79.77 78.67 Table 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "Method k=1 k=2 k=5 Nearest \nNeighbor 69.07 81.08 94.64 PCA 56.43 71.19 88.31 LDA - 68.84 88.87 MRF 51.06 68.38 86.95 Standard CNN \n71.83 82.58 94.05 videoCNN V:ORL 90.35 94.77 98.86 Compared to a plain CNN without using unlabeled video, \nthese are improvements of about 7% and 8%."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 107
                            }
                        ],
                        "text": "We labeled k =1,2 or 5 images per subject and compared to the baselines Nearest Neighbor, PCA, LDA and MRF (Huang et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 108
                            }
                        ],
                        "text": "We la\u00adbeled k =1,2 or 5 images per subject and compared to the baselines \nNearest Neighbor, PCA, LDA and MRF (Huang et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8091380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8d4ace39c314c93c5bfacc53ded424fa63568d6",
            "isKey": true,
            "numCitedBy": 58,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a hybrid face recognition method that combines holistic and feature analysis-based approaches using a Markov random field (MRF) model. The face images are divided into small patches, and the MRF model is used to represent the relationship between the image patches and the patch ID's. The MRF model is first learned from the training image patches, given a test image. The most probable patch ID's is then inferred using the belief propagation (BP) algorithm. Finally, the ID of the test image is determined by a voting scheme from the estimated patch ID's. Experimental results on several face datasets indicate the significant potential of our method."
            },
            "slug": "A-hybrid-face-recognition-method-using-Markov-Huang-Metaxas",
            "title": {
                "fragments": [],
                "text": "A hybrid face recognition method using Markov random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A hybrid face recognition method that combines holistic and feature analysis-based approaches using a Markov random field (MRF) model, which is first learned from the training image patches, given a test image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 50
                            }
                        ],
                        "text": "From a biological point of view, several authors (Hin\u00adton &#38; \nSejnowski, 1999; Becker, 1996a) argue that pure supervised learning is a poor model of how animals really \nlearn."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60095295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e90c7dfdafd21bf30aca3129e645f1c57f5c469f",
            "isKey": false,
            "numCitedBy": 199,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Unsupervised-learning-:-foundations-of-neural-Hinton-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Unsupervised learning : foundations of neural computation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143920486"
                        ],
                        "name": "F. Samaria",
                        "slug": "F.-Samaria",
                        "structuredName": {
                            "firstName": "Ferdinando",
                            "lastName": "Samaria",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Samaria"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144024405"
                        ],
                        "name": "A. Harter",
                        "slug": "A.-Harter",
                        "structuredName": {
                            "firstName": "Andy",
                            "lastName": "Harter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Harter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 52
                            }
                        ],
                        "text": "We also report experiments on the ORL face dataset (Samaria &#38; \nHarter, 1994), with similar results."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 81
                            }
                        ],
                        "text": "Face Recognition We also report a simple experiment on AT&#38;T s ORL face database \n(Samaria &#38; Harter, 1994), which con\u00adsists of 10 di.erent gray scale images for each of the 40 distinct \nsubjects, taken at di.erent times and with varying lighting and facial expressions (open / closed eyes,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2153469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "294adb9b8dca839832836bee0f06e15be550aaaa",
            "isKey": false,
            "numCitedBy": 2542,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work on face identification using continuous density Hidden Markov Models (HMMs) has shown that stochastic modelling can be used successfully to encode feature information. When frontal images of faces are sampled using top-bottom scanning, there is a natural order in which the features appear and this can be conveniently modelled using a top-bottom HMM. However, a top-bottom HMM is characterised by different parameters, the choice of which has so far been based on subjective intuition. This paper presents a set of experimental results in which various HMM parameterisations are analysed.<<ETX>>"
            },
            "slug": "Parameterisation-of-a-stochastic-model-for-human-Samaria-Harter",
            "title": {
                "fragments": [],
                "text": "Parameterisation of a stochastic model for human face identification"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This paper presents a set of experimental results in which various HMM parameterisations are analysed and shows that stochastic modelling can be used successfully to encode feature information."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Applications of Computer Vision"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50333420"
                        ],
                        "name": "S. Becker",
                        "slug": "S.-Becker",
                        "structuredName": {
                            "firstName": "Suzanna",
                            "lastName": "Becker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Becker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 12
                            }
                        ],
                        "text": "The work of Becker (1996a; 1999), which is proba\u00adbly the most related work to ours, \nexplores the use of temporal context using a fully connect neural network algorithm which introduces \nextra neurons, called con\u00adtextual gating units, and a Hebbian update rule for clustering based on context \n(\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 15
                            }
                        ],
                        "text": "Wiskott, L., &#38; Sejnowski, T. (2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 76
                            }
                        ],
                        "text": "From a biological point of view, several authors (Hin\u00adton &#38; \nSejnowski, 1999; Becker, 1996a) argue that pure supervised learning is a poor model of how animals really \nlearn."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 14
                            }
                        ],
                        "text": "Hinton, G., &#38; Sejnowski, T. (1999)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3523845,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "705ac0caa9b3704b09758cb12a0d2b9e34f27767",
            "isKey": true,
            "numCitedBy": 175,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised learning procedures based on Hebbian principles have been successful at modelling low-level feature extraction, but are insufficient for learning to recognize higher- order features and complex objects. In this paper we explore a class of unsupervised learning algorithms called Imax (Becker and Hinton 1992 Nature 355 161-3) that are derived from information-theoretic principles. The Imax algorithms are based on the idea of maximizing the mutual information between the outputs of different network modules, and are capable of extracting higher-order features from data. They are therefore well suited to modelling intermediate-to-high-level perceptual processing stages. We substantiate this claim with some novel results for two signal classification problems, as well as by reviewing some previously published results and several related approaches. Finally, Imax is evaluated with respect to computational costs and biological plausibility."
            },
            "slug": "Mutual-information-maximization:-models-of-cortical-Becker",
            "title": {
                "fragments": [],
                "text": "Mutual information maximization: models of cortical self-organization."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The Imax algorithms are based on the idea of maximizing the mutual information between the outputs of different network modules, and are capable of extracting higher-order features from data and are well suited to modelling intermediate-to-high-level perceptual processing stages."
            },
            "venue": {
                "fragments": [],
                "text": "Network"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 53
                            }
                        ],
                        "text": "We choose a deep convolutional network \narchitec\u00adture (LeCun et al., 1998), well suited for large-scale object recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 105
                            }
                        ],
                        "text": "Exploiting Video Coherence with CNNs Our choice of architecture \nis a convolutional neural network (CNN) (LeCun et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 105
                            }
                        ],
                        "text": "CNNs have justi.ed themselves \nin many visual recognitions tasks including handwritten digit recognition (LeCun et al., 1998) and face \ndetection (Osadchy et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 67
                            }
                        ],
                        "text": "Our choice of architecture is a convolutional neural network (CNN) (LeCun et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 52
                            }
                        ],
                        "text": "We choose a deep convolutional network architecture (LeCun et al., 1998), well suited for large-scale object recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 105
                            }
                        ],
                        "text": "CNNs have justified themselves in many visual recognitions tasks including handwritten digit recognition (LeCun et al., 1998) and face detection (Osadchy et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": true,
            "numCitedBy": 35268,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082675395"
                        ],
                        "name": "eon BottouAT",
                        "slug": "eon-BottouAT",
                        "structuredName": {
                            "firstName": "eon",
                            "lastName": "BottouAT",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "eon BottouAT"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 35
                            }
                        ],
                        "text": "We use stochastic gradient descent (Bottou, 1991) optimization for that purpose."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 50
                            }
                        ],
                        "text": "N + \nU n=1 n=1 We use stochastic gradient descent (Bottou, 1991) op\u00adtimization for that purpose."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15006252,
            "fieldsOfStudy": [],
            "id": "a514e1eabb627778dedf00409cc6741cd2e51fe5",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Many connectionist learning algorithms consists of minimizing a cost of the form C(w) = E(J(z; w)) = Z J(z; w)dP(z) where dP is an unknown probability distribution that characterizes the problem to learn, and J, the loss function, deenes the learning system itself. This popular statistical formulation has led to many theoretical results. The minimization of such a cost may be achieved with a stochastic gradient descent algorithm, e.g.: w t+1 = w t ? t r w J(z; w t) With some restrictions on J and C, this algorithm converges, even if J is non diierentiable on a set of measure 0. Links with simulated annealing are depicted. R esum e De nombreux algorithmes connexionnistes consistent a minimiser un co^ ut de la forme C(w) = E(J(z; w)) = Z J(z; w)dP(z) o u dP est une distribution de probabilit e inconnue qui caract erise le probl eme, et J, le crit ere local, d ecrit le syst eme d'apprentissage lui m^ eme. Cette formulation statistique bien connue a donn e lieu a de nombreux r esultats th eoriques. La minimisation d'un tel co^ ut peut ^ etre accomplie au moyen d'un algorithme de descente stochastique de gradient, par exemple: w t+1 = w t ? t r w J(z; w t) Au prix de quelques restrictions sur C et J, cet algorithme converge, m^ eme si J n'est pas d erivable sur un ensemble de mesure nulle. Des liens avec les m ethodes de recuit simul e sont egalement soulign es."
            },
            "slug": "Stochastic-Gradient-Learning-in-Neural-Networks-BottouAT",
            "title": {
                "fragments": [],
                "text": "Stochastic Gradient Learning in Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713907"
                        ],
                        "name": "J. Hornegger",
                        "slug": "J.-Hornegger",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Hornegger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hornegger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153543875"
                        ],
                        "name": "D. Paulus",
                        "slug": "D.-Paulus",
                        "structuredName": {
                            "firstName": "Dietrich",
                            "lastName": "Paulus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paulus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144290244"
                        ],
                        "name": "H. Niemann",
                        "slug": "H.-Niemann",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "Niemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Niemann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "Spin Glass MRF essentially uses an energy function in\u00adspired by models of \nphysics of disordered systems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 161
                            }
                        ],
                        "text": "\u2026&#38; K\u00a8orner, 2003) (Nearest Neighbor), an eigenspace \nplus spline recognition model (Nayar et al., 1996) (Eigen Spline), a SpinGlass Markov Random Field (SpinGlass \nMRF) (Caputo et al., 2002), and a hierarchical view-tuned network for visual recognition tasks (VTU) \n(Wersing &#38; K\u00a8orner, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 318,
                                "start": 315
                            }
                        ],
                        "text": "These \ninclude Support Vector Machines (SVM) using a polynomial kernel (Roobaert &#38; Hulle, 1999), a nearest \nneighbor classi.er on the direct images (Wersing &#38; K\u00a8orner, 2003) (Nearest Neighbor), an eigenspace \nplus spline recognition model (Nayar et al., 1996) (Eigen Spline), a SpinGlass Markov Random Field (SpinGlass \nMRF) (Caputo et al., 2002), and a hierarchical view-tuned network for visual recognition tasks (VTU) \n(Wersing &#38; K\u00a8orner, 2003)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Method Nearest Neighbor 30 objects 81.8 100 objects 70.1 SVM 84.9 74.6 \nSpinGlass MRF 82.79 69.41 Eigen Spline 84.6 77.0 VTU Standard CNN videoCNN V:COIL100 videoCNN V:COIL \n70videoCNN V:COIL-LivideoCNN V:Animal 89.9 84.88 - 95.03 ke -- 79.1 71.49 92.25 -79.77 78.67 Table 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "Method k=1 k=2 k=5 Nearest \nNeighbor 69.07 81.08 94.64 PCA 56.43 71.19 88.31 LDA - 68.84 88.87 MRF 51.06 68.38 86.95 Standard CNN \n71.83 82.58 94.05 videoCNN V:ORL 90.35 94.77 98.86 Compared to a plain CNN without using unlabeled video, \nthese are improvements of about 7% and 8%."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 72
                            }
                        ],
                        "text": ", 1996) (Eigen Spline), a SpinGlass Markov Random Field (SpinGlass MRF) (Caputo et al., 2002), and a hierarchical view-tuned network for visual recognition tasks (VTU) (Wersing & K\u00f6rner, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "We la\u00adbeled k =1,2 or 5 images per subject and compared to the baselines \nNearest Neighbor, PCA, LDA and MRF (Huang et al., 2004)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13895625,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d12a64cced38cb82a4ad21f2796fdac31384b95c",
            "isKey": true,
            "numCitedBy": 14,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new energy function for MRF which is inspired by models of physics of disordered systems. This energy function presents two ma in advantages: it can be very easily applied to problems modeled by irregular sites becau se it considers the neighborhood system as fully connected; it does not require an algorithm f or searching the absolute minima because those and their analytical properties are given by t heory. We performed experiments on appearance-based object recognition, using the COIL 100 da tabase; we achieve a recognition rate of 98.78%."
            },
            "slug": "A-Spin-Glass-Markov-Random-Field-for-3-D-Object-Caputo-Hornegger",
            "title": {
                "fragments": [],
                "text": "A Spin-Glass Markov Random Field for 3-D Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A new energy function for MRF which is inspired by models of physics of disordered systems, which can be very easily applied to problems modeled by irregular sites and does not require an algorithm or searching the absolute minima."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9330607"
                        ],
                        "name": "S. Roweis",
                        "slug": "S.-Roweis",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Roweis",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roweis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796044"
                        ],
                        "name": "L. Saul",
                        "slug": "L.-Saul",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Saul",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Saul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 137
                            }
                        ],
                        "text": "Finally, we \nnote that many graph-based approaches are also used in an unsupervised rather than supervised setup (Tenenbaum \net al., 2000; Roweis &#38; Saul, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5987139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "afcd6da7637ddeef6715109aca248da7a24b1c65",
            "isKey": false,
            "numCitedBy": 13980,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text."
            },
            "slug": "Nonlinear-dimensionality-reduction-by-locally-Roweis-Saul",
            "title": {
                "fragments": [],
                "text": "Nonlinear dimensionality reduction by locally linear embedding."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Locally linear embedding (LLE) is introduced, an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs that learns the global structure of nonlinear manifolds."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094778056"
                        ],
                        "name": "V. De Silva",
                        "slug": "V.-De-Silva",
                        "structuredName": {
                            "firstName": "Vin",
                            "lastName": "De Silva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. De Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46657367"
                        ],
                        "name": "J. Langford",
                        "slug": "J.-Langford",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Langford",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Langford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 113
                            }
                        ],
                        "text": "Finally, we \nnote that many graph-based approaches are also used in an unsupervised rather than supervised setup (Tenenbaum \net al., 2000; Roweis &#38; Saul, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 112
                            }
                        ],
                        "text": "Finally, we note that many graph-based approaches are also used in an unsupervised rather than supervised setup (Tenenbaum et al., 2000; Roweis & Saul, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 221338160,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3537fcd0ff99a3b3cb3d279012df826358420556",
            "isKey": false,
            "numCitedBy": 12182,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs-30,000 auditory nerve fibers or 10(6) optic nerve fibers-a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure."
            },
            "slug": "A-global-geometric-framework-for-nonlinear-Tenenbaum-Silva",
            "title": {
                "fragments": [],
                "text": "A global geometric framework for nonlinear dimensionality reduction."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set and efficiently computes a globally optimal solution, and is guaranteed to converge asymptotically to the true structure."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 15
                            }
                        ],
                        "text": "In contrast to TSVMs, our method does not make a strong assumption \nthat the class labels of objects in the unlabeled video have to belong to the training classes, and we \nshow experimentally in Section 4 that our method takes advantage of examples coming from di.ering classes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 25
                            }
                        ],
                        "text": ", 2006) and transduction (Vapnik, 1995) are machinelearning classification techniques able to handle la-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 77
                            }
                        ],
                        "text": "Classical semi-supervised learning \n(Chapelle et al., 2006) and transduction (Vapnik, 1995) are machine\u00adlearning classi.cation techniques \nable to handle la- Appearing in Proceedings of the 26 th International Confer\u00adence on Machine Learning, \nMontreal, Canada, 2009."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 120
                            }
                        ],
                        "text": "A nearest-neighbor \ngraph gives no information about the class label, or equivalently there is no margin to op\u00adtimize for \nTSVMs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 32
                            }
                        ],
                        "text": "Transductive methods like TSVMs (Vapnik, 1995) involve maximizing the margin (confidence) on a set of unlabeled examples which come from the same distribution as the training data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 33
                            }
                        ],
                        "text": "Transductive methods like TSVMs (Vapnik, 1995) involve maximizing the mar\u00adgin (con.dence) on a set of \nunlabeled examples which come from the same distribution as the training data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": true,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120242409"
                        ],
                        "name": "J. Bromley",
                        "slug": "J.-Bromley",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Bromley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bromley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058232056"
                        ],
                        "name": "James W. Bentz",
                        "slug": "James-W.-Bentz",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bentz",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James W. Bentz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49015421"
                        ],
                        "name": "C. Moore",
                        "slug": "C.-Moore",
                        "structuredName": {
                            "firstName": "Cliff",
                            "lastName": "Moore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776424"
                        ],
                        "name": "Eduard S\u00e4ckinger",
                        "slug": "Eduard-S\u00e4ckinger",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "S\u00e4ckinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eduard S\u00e4ckinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105573840"
                        ],
                        "name": "Roopak Shah",
                        "slug": "Roopak-Shah",
                        "structuredName": {
                            "firstName": "Roopak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roopak Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 133
                            }
                        ],
                        "text": "In practice, minimizing (4) for all pairs of images is achieved by stochastic gradient descent over a \u201csiamese network\u201d architecture (Bromley et al., 1993): two networks sharing the same parameters \u03b8 compute the representation for two sampled images x1 and x2 as shown in Figure 2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16394033,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "997dc5d9a058753f034422afe7bd0cc0b8ad808b",
            "isKey": false,
            "numCitedBy": 2617,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an algorithm for verification of signatures written on a pen-input tablet. The algorithm is based on a novel, artificial neural network, called a \"Siamese\" neural network. This network consists of two identical sub-networks joined at their outputs. During training the two sub-networks extract features from two signatures, while the joining neuron measures the distance between the two feature vectors. Verification consists of comparing an extracted feature vector with a stored feature vector for the signer. Signatures closer to this stored representation than a chosen threshold are accepted, all other signatures are rejected as forgeries."
            },
            "slug": "Signature-Verification-Using-A-\"Siamese\"-Time-Delay-Bromley-Bentz",
            "title": {
                "fragments": [],
                "text": "Signature Verification Using A \"Siamese\" Time Delay Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "An algorithm for verification of signatures written on a pen-input tablet based on a novel, artificial neural network called a \"Siamese\" neural network, which consists of two identical sub-networks joined at their outputs."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281542"
                        ],
                        "name": "A. Zien",
                        "slug": "A.-Zien",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Zien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zien"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 36
                            }
                        ],
                        "text": "Classical semi-supervised learning \n(Chapelle et al., 2006) and transduction (Vapnik, 1995) are machine\u00adlearning classi.cation techniques \nable to handle la- Appearing in Proceedings of the 26 th International Confer\u00adence on Machine Learning, \nMontreal, Canada, 2009."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 35
                            }
                        ],
                        "text": "Classical semi-supervised learning (Chapelle et al., 2006) and transduction (Vapnik, 1995) are machinelearning classification techniques able to handle la-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 48
                            }
                        ],
                        "text": "There are many variants of each \ntype, see e.g. (Chapelle et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59913655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "463565c30b7a9c12c2ef0558a51cfc7b05055737",
            "isKey": false,
            "numCitedBy": 231,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Semi-Supervised-Learning-(Adaptive-Computation-and-Chapelle-Sch\u00f6lkopf",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Learning (Adaptive Computation and Machine Learning)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Huge collections of data can be obtained without human annotation. General idea: successfully applied to text, document retrieval, semisupervised learning"
            },
            "venue": {
                "fragments": [],
                "text": "Huge collections of data can be obtained without human annotation. General idea: successfully applied to text, document retrieval, semisupervised learning"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Coil 100-Like 40 objects, 4 types of objects in COIL100 (fruits, cars, cups, and cans) Each has 72 views, as a video stream"
            },
            "venue": {
                "fragments": [],
                "text": "Coil 100-Like 40 objects, 4 types of objects in COIL100 (fruits, cars, cups, and cans) Each has 72 views, as a video stream"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Conclusion Leverage structured data with embedding algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Conclusion Leverage structured data with embedding algorithm"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 10
                            }
                        ],
                        "text": "See also (Bowling et al., 2005) \nfor an embedding algorithm using the actions of a robot which seems related to our work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Action respecting embedding. International Conference on Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Action respecting embedding. International Conference on Machine Learning"
            },
            "year": 2005
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 18,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 36,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Deep-learning-from-temporal-coherence-in-video-Mobahi-Collobert/e2c477de72bb7718f5304c6f38457fda9c8334b1?sort=total-citations"
}