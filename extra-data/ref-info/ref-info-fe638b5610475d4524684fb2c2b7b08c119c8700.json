{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143857271"
                        ],
                        "name": "Nigel P. Duffy",
                        "slug": "Nigel-P.-Duffy",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Duffy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nigel P. Duffy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Wegiveexperimentalresultsshowing significantimprovementson two tasks:parsing Wall StreetJournaltext, and namedentity extractionfrom webdata."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 18
                            }
                        ],
                        "text": "A previous paper (Collins and Duffy 2001) showed improvementsover a PCFGin parsingthe ATIS task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 17
                            }
                        ],
                        "text": "Seefigure3 for anexample."
                    },
                    "intents": []
                }
            ],
            "corpusId": 396794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6c7adc28e20d361d5c35aa9808094b10f6a34d1",
            "isKey": false,
            "numCitedBy": 932,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the application of kernel methods to Natural Language Processing (NLP) problems. In many NLP tasks the objects being modeled are strings, trees, graphs or other discrete structures which require some mechanism to convert them into feature vectors. We describe kernels for various natural language structures, allowing rich, high dimensional representations of these structures. We show how a kernel over trees can be applied to parsing using the voted perceptron algorithm, and we give experimental results on the ATIS corpus of parse trees."
            },
            "slug": "Convolution-Kernels-for-Natural-Language-Collins-Duffy",
            "title": {
                "fragments": [],
                "text": "Convolution Kernels for Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown how a kernel over trees can be applied to parsing using the voted perceptron algorithm, and experimental results on the ATIS corpus of parse trees are given."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 188
                            }
                        ],
                        "text": "We useda feature set which includedthe current,next, and previous word; the previous two tags;variouscapitalization andotherfeaturesof thewordbeingtagged(thefull featuresetis describedin (Collins2002a))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For related work on the voted perceptron algorithm applied to NLP problems, see ( Collins 2002a ) and (Collins 2002b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We used a feature set which included the current, next, and previous word; the previous two tags; various capitalization and other features of the word being tagged (the full feature set is described in ( Collins 2002a ))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 76
                            }
                        ],
                        "text": "For relatedwork on the voted perceptronalgorithm appliedto NLP problems,see(Collins 2002a) and(Collins 2002b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 1
                            }
                        ],
                        "text": "(Collins 2002b)describeshow the votedperceptroncanbeusedto trainmaximum-entropy style taggers,andalsogivesa morethoroughdiscussion of the theory behind the perceptronalgorithm applied to rankingtasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 1
                            }
                        ],
                        "text": "(Collins 2002a)describesexperimentson the samenamed-entitydatasetas in thispaper, but usingexplicit featuresratherthankernels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "( Collins 2002a ) describes experiments on the same named-entity dataset as in this paper, but using explicit features rather than kernels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16877788,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39fb0b6873c58ec182357721eaed75801505a9df",
            "isKey": false,
            "numCitedBy": 297,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes algorithms which rerank the top N hypotheses from a maximum-entropy tagger, the application being the recovery of named-entity boundaries in a corpus of web data. The first approach uses a boosting algorithm for ranking problems. The second approach uses the voted perceptron algorithm. Both algorithms give comparable, significant improvements over the maximum-entropy baseline. The voted perceptron algorithm can be considerably more efficient to train, at some cost in computation on test examples."
            },
            "slug": "Ranking-Algorithms-for-Named-Entity-Extraction:-and-Collins",
            "title": {
                "fragments": [],
                "text": "Ranking Algorithms for Named Entity Extraction: Boosting and the VotedPerceptron"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "Algorithms which rerank the top N hypotheses from a maximum-entropy tagger, the application being the recovery of named-entity boundaries in a corpus of web data, using the voted perceptron algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17446277"
                        ],
                        "name": "J. Goodman",
                        "slug": "J.-Goodman",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Goodman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goodman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "(Goodman 1996) gives a polynomial time conversion of a DOP model into an equivalent PCFG whose size is linear in the size of the training set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 148
                            }
                        ],
                        "text": "It mightseemparadoxicalto beableto efficiently learnandapplyamodelwith anexponential numberof features.1 Thekey toouralgorithmsis the\n1Although see(Goodman1996) for an efficient algorithm for theDOPmodel,whichwediscussin section7 of thispaper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 1
                            }
                        ],
                        "text": "(Goodman1996) gives a polynomial time conversionof a DOP model into an equivalent PCFG whosesize is linear in the size of the training set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 50
                            }
                        ],
                        "text": "(Notethatasimilar recursionis de-\nscribedby Goodman(Goodman1996),Goodman\u2019s application being the conversion of Bod\u2019s model (Bod 1998)to anequivalentPCFG.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Goodman\u2019s methodstill leaves exact parsingunder the modelintractable(becauseof theneedto sumover multiple derivationsunderlyingthe sametree),but hegivesanapproximationto finding themostprobabletree,whichcanbecomputedefficiently."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 13
                            }
                        ],
                        "text": "Although see (Goodman 1996) for an efficient algorithm for the DOP model, which we discuss in section 7 of this paper."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 55
                            }
                        ],
                        "text": "(Note that a similar recursion is described by Goodman (Goodman 1996), Goodman\u2019s application being the conversion of Bod\u2019s model (Bod 1998) to an equivalent PCFG."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "155a2680a1a7fe495d0ab47224fcdbbfb3d1caaa",
            "isKey": true,
            "numCitedBy": 89,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Excellent results have been reported for Data-Oriented Parsing (DOP) of natural language texts (Bod, 1993). Unfortunately, existing algorithms are both computationally intensive and difficult to implement. Previous algorithms are expensive due to two factors: the exponential number of rules that must be generated and the use of a Monte Carlo parsing algorithm. In this paper we solve the first problem by a novel reduction of the DOP model to a small, equivalent probabilistic context-free grammar. We solve the second problem by a novel deterministic parsing strategy that maximizes the expected number of correct constituents, rather than the probability of a correct parse tree. Using the optimizations, experiments yield a 97% crossing brackets rate and 88% zero crossing brackets rate. This differs significantly from the results reported by Bod, and is comparable to results from a duplication of Pereira and Schabes's (1992) experiment on the same data. We show that Bod's results are at least partially due to an extremely fortuitous choice of test data, and partially due to using cleaner data than other researchers."
            },
            "slug": "Efficient-Algorithms-for-Parsing-the-DOP-Model-Goodman",
            "title": {
                "fragments": [],
                "text": "Efficient Algorithms for Parsing the DOP Model"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel reduction of the DOP model to a small, equivalent probabilistic context-free grammar that maximizes the expected number of correct constituents, rather than the probability of a correct parse tree, is solved."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086382679"
                        ],
                        "name": "Joshua GoodmanHarvard",
                        "slug": "Joshua-GoodmanHarvard",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "GoodmanHarvard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua GoodmanHarvard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Goodman\u2019s methodstill leaves exact parsingunder the modelintractable(becauseof theneedto sumover multiple derivationsunderlyingthe sametree),but hegivesanapproximationto finding themostprobabletree,whichcanbecomputedefficiently."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 50
                            }
                        ],
                        "text": "(Notethatasimilar recursionis de-\nscribedby Goodman(Goodman1996),Goodman\u2019s application being the conversion of Bod\u2019s model (Bod 1998)to anequivalentPCFG.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 1
                            }
                        ],
                        "text": "(Goodman1996) gives a polynomial time conversionof a DOP model into an equivalent PCFG whosesize is linear in the size of the training set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 148
                            }
                        ],
                        "text": "It mightseemparadoxicalto beableto efficiently learnandapplyamodelwith anexponential numberof features.1 Thekey toouralgorithmsis the\n1Although see(Goodman1996) for an efficient algorithm for theDOPmodel,whichwediscussin section7 of thispaper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17956293,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "584dfd7f167221bb68908b6228a208d6cf47a1b1",
            "isKey": true,
            "numCitedBy": 10,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Excellent results have been reported for Data-Oriented Parsing (DOP) of natural language texts (Bod, 1993c). Unfortunately, existing algorithms are both computationally intensive and diicult to implement. Previous algorithms are expensive due to two factors: the exponential number of rules that must be generated and the use of a Monte Carlo parsing algorithm. In this paper we solve the rst problem by a novel reduction of the DOP model to a small, equivalent probabilistic context-free grammar. We solve the second problem by a novel deterministic parsing strategy that maximizes the expected number of correct constituents , rather than the probability of a correct parse tree. Using the optimizations, experiments yield a 97% crossing brackets rate and 88% zero crossing brackets rate. This diiers signiicantly from the results reported by Bod, and is comparable to results from a duplication of Pereira and Schabes's (1992) experiment on the same data. We show that Bod's results are at least partially due to an extremely fortuitous choice of test data, and partially due to using cleaner data than other researchers."
            },
            "slug": "Eecient-Algorithms-for-Parsing-the-Dop-Model-GoodmanHarvard",
            "title": {
                "fragments": [],
                "text": "Eecient Algorithms for Parsing the Dop Model"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A novel reduction of the DOP model to a small, equivalent probabilistic context-free grammar and a novel deterministic parsing strategy that maximizes the expected number of correct constituents, rather than the probability of a correct parse tree."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 1
                            }
                        ],
                        "text": "(Collins 2002a)describesexperimentson the samenamed-entitydatasetas in thispaper, but usingexplicit featuresratherthankernels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 76
                            }
                        ],
                        "text": "For relatedwork on the voted perceptronalgorithm appliedto NLP problems,see(Collins 2002a) and(Collins 2002b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 1
                            }
                        ],
                        "text": "(Collins 2002b)describeshow the votedperceptroncanbeusedto trainmaximum-entropy style taggers,andalsogivesa morethoroughdiscussion of the theory behind the perceptronalgorithm applied to rankingtasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 188
                            }
                        ],
                        "text": "We useda feature set which includedthe current,next, and previous word; the previous two tags;variouscapitalization andotherfeaturesof thewordbeingtagged(thefull featuresetis describedin (Collins2002a))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10888973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a7958b418bceb48a315384568091ab1898b1640",
            "isKey": false,
            "numCitedBy": 2272,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe new algorithms for training tagging models, as an alternative to maximum-entropy models or conditional random fields (CRFs). The algorithms rely on Viterbi decoding of training examples, combined with simple additive updates. We describe theory justifying the algorithms through a modification of the proof of convergence of the perceptron algorithm for classification problems. We give experimental results on part-of-speech tagging and base noun phrase chunking, in both cases showing improvements over results for a maximum-entropy tagger."
            },
            "slug": "Discriminative-Training-Methods-for-Hidden-Markov-Collins",
            "title": {
                "fragments": [],
                "text": "Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results on part-of-speech tagging and base noun phrase chunking are given, in both cases showing improvements over results for a maximum-entropy tagger."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764192"
                        ],
                        "name": "R. Bod",
                        "slug": "R.-Bod",
                        "structuredName": {
                            "firstName": "Rens",
                            "lastName": "Bod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bod"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 27
                            }
                        ],
                        "text": "In spite of theseproblems,(Bod 2001) gives excellent results for the methodon parsing Wall StreetJournaltext."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 58
                            }
                        ],
                        "text": "Even after this, Bod\u2019s methodis left with a huge grammar: (Bod 2001) describesa grammarwith\nover 5 million sub-structures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 1
                            }
                        ],
                        "text": "(Bod 2001)describes experimentsgiving 90.6%/90.8%recall and precision for sentencesof lessthan40 words in length, usingtheall-subtreesrepresentation,but usingvery differentalgorithmsandparameterestimationmethodsfrom theperceptronalgorithmsin thispaper(see section7 for morediscussion)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d73a70359f568ab32943a74f7891a27257847b3e",
            "isKey": true,
            "numCitedBy": 89,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We aim at finding the minimal set of fragments which achieves maximal parse accuracy in Data Oriented Parsing. Experiments with the Penn Wall Street Journal treebank show that counts of almost arbitrary fragments within parse trees are important, leading to improved parse accuracy over previous models tested on this treebank (a precision of 90.8% and a recall of 90.6%). We isolate some dependency relations which previous models neglect but which contribute to higher parse accuracy."
            },
            "slug": "What-is-the-Minimal-Set-of-Fragments-that-Achieves-Bod",
            "title": {
                "fragments": [],
                "text": "What is the Minimal Set of Fragments that Achieves Maximal Parse Accuracy?"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work isolates some dependency relations which previous models neglect but which contribute to higher parse accuracy, and finds the minimal set of fragments which achieves maximal parse accuracy in Data Oriented Parsing."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(Charniak 2000) describes a"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 1
                            }
                        ],
                        "text": "(Charniak2000)describesa\ndifferent methodwhich achieves very similar performanceto (Collins 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 538122,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76d5e3fa888bee872b7adb7fa810089aa8ab1d58",
            "isKey": false,
            "numCitedBy": 1855,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new parser for parsing down to Penn tree-bank style parse trees that achieves 90.1% average precision/recall for sentences of length 40 and less, and 89.5% for sentences of length 100 and less when trained and tested on the previously established [5, 9, 10, 15, 17] \"standard\" sections of the Wall Street Journal treebank. This represents a 13% decrease in error rate over the best single-parser results on this corpus [9]. The major technical innovation is the use of a \"maximum-entropy-inspired\" model for conditioning and smoothing that let us successfully to test and combine many different conditioning events. We also present some partial results showing the effects of different conditioning information, including a surprising 2% improvement due to guessing the lexical head's pre-terminal before guessing the lexical head."
            },
            "slug": "A-Maximum-Entropy-Inspired-Parser-Charniak",
            "title": {
                "fragments": [],
                "text": "A Maximum-Entropy-Inspired Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A new parser for parsing down to Penn tree-bank style parse trees that achieves 90.1% average precision/recall for sentences of length 40 and less and 89.5% when trained and tested on the previously established sections of the Wall Street Journal treebank is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The experiments in this paper use the top candidates from a baseline probabilistic model: the model of ( Collins 1999 ) for parsing, and a maximumentropy tagger for named-entity recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "0 CBs, CBs are the percentage of sentences with 0 or crossing brackets respectively. CO99 is model 2 of ( Collins 1999 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In parsing Wall Street Journal text, the method gives a 5.1% relative reduction in error rate over the model of ( Collins 1999 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Model 2 of ( Collins 1999 ) was used to parse both the training and test data, producing multiple hypotheses for each sentence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7901127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fc44ff7f37ec5585310666c183c65e0a0bb2446",
            "isKey": false,
            "numCitedBy": 2062,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes three statistical models for natural language parsing. The models extend methods from probabilistic context-free grammars to lexicalized grammars, leading to approaches in which a parse tree is represented as the sequence of decisions corresponding to a head-centered, top-down derivation of the tree. Independence assumptions then lead to parameters that encode the X-bar schema, subcategorization, ordering of complements, placement of adjuncts, bigram lexical dependencies, wh-movement, and preferences for close attachment. All of these preferences are expressed by probabilities conditioned on lexical heads. The models are evaluated on the Penn Wall Street Journal Treebank, showing that their accuracy is competitive with other models in the literature. To gain a better understanding of the models, we also give results on different constituent types, as well as a breakdown of precision/recall results in recovering various types of dependencies. We analyze various characteristics of the models through experiments on parsing accuracy, by collecting frequencies of various structures in the treebank, and through linguistically motivated examples. Finally, we compare the models to others that have been applied to parsing the treebank, aiming to give some explanation of the difference in performance of the various models."
            },
            "slug": "Head-Driven-Statistical-Models-for-Natural-Language-Collins",
            "title": {
                "fragments": [],
                "text": "Head-Driven Statistical Models for Natural Language Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Three statistical models for natural language parsing are described, leading to approaches in which a parse tree is represented as the sequence of decisions corresponding to a head-centered, top-down derivation of the tree."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 252796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "isKey": false,
            "numCitedBy": 8177,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant."
            },
            "slug": "Building-a-Large-Annotated-Corpus-of-English:-The-Marcus-Santorini",
            "title": {
                "fragments": [],
                "text": "Building a Large Annotated Corpus of English: The Penn Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "As a result of this grant, the researchers have now published on CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, which includes a fully hand-parsed version of the classic Brown corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145177220"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "From a theoretical point of view, it is difficult to find motivation for the parameter estimation methods used by (Bod 1998) \u2010 see ( Johnson 2002 ) for discussion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 125
                            }
                        ],
                        "text": "From a theoreticalpoint of view, it is difficult to find motivation for the parameterestimationmethods usedby (Bod 1998) \u2013 see(Johnson2002) for discussion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6332815,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e7cc4189113dd4aa26bf0f517cf406ef874c154",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A data-oriented parsing or DOP model for statistical parsing associates fragments of linguistic representations with numerical weights, where these weights are estimated by normalizing the empirical frequency of each fragment in a training corpus (see Bod [1998] and references cited therein). This note observes that this estimation method is biased and inconsistent that is, the estimated distribution does not in general converge on the true distribution as the size of the training corpus increases."
            },
            "slug": "Squibs-and-Discussions:-The-DOP-Estimation-Method-Johnson",
            "title": {
                "fragments": [],
                "text": "Squibs and Discussions: The DOP Estimation Method is Biased and Inconsistent"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This note observes that this estimation method is biased and inconsistent that is, the estimated distribution does not in general converge on the true distribution as the size of the training corpus increases."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35371521"
                        ],
                        "name": "Kristina Toutanvoa",
                        "slug": "Kristina-Toutanvoa",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanvoa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanvoa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 125
                            }
                        ],
                        "text": "Maximum entropy taggers have been shown to be highly competitive on a number of tagging tasks, such as partof-speech tagging (Ratnaparkhi 1996), and namedentity recognition (Borthwick et."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 86
                            }
                        ],
                        "text": "As a baselinemodelwe useda maximumentropy tagger, very similar to the onedescribedin (Ratnaparkhi1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 91
                            }
                        ],
                        "text": "As a baseline model we used a maximum entropy tagger, very similar to the one described in (Ratnaparkhi 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 116
                            }
                        ],
                        "text": "Maximumentropy taggershave beenshown to be highly competitive on a numberof taggingtasks,suchaspartof-speechtagging(Ratnaparkhi1996),andnamedentity recognition(Borthwick et. al 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10807721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1504a9d5829033a8cb4cf37b8bb13dfd4baddc7b",
            "isKey": true,
            "numCitedBy": 1574,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents results for a maximum-entropy-based part of speech tagger, which achieves superior performance principally by enriching the information sources used for tagging. In particular, we get improved results by incorporating these features: (i) more extensive treatment of capitalization for unknown words; (ii) features for the disambiguation of the tense forms of verbs; (iii) features for disambiguating particles from prepositions and adverbs. The best resulting accuracy for the tagger on the Penn Treebank is 96.86% overall, and 86.91% on previously unseen words."
            },
            "slug": "Enriching-the-Knowledge-Sources-Used-in-a-Maximum-Toutanvoa-Manning",
            "title": {
                "fragments": [],
                "text": "Enriching the Knowledge Sources Used in a Maximum Entropy Part-of-Speech Tagger"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This paper presents results for a maximum-entropy-based part of speech tagger, which achieves superior performance principally by enriching the information sources used for tagging by incorporating these features: more extensive treatment of capitalization for unknown words, and features for the disambiguation of the tense forms of verbs."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764192"
                        ],
                        "name": "R. Bod",
                        "slug": "R.-Bod",
                        "structuredName": {
                            "firstName": "Rens",
                            "lastName": "Bod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bod"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 111
                            }
                        ],
                        "text": "From a theoreticalpoint of view, it is difficult to find motivation for the parameterestimationmethods usedby (Bod 1998) \u2013 see(Johnson2002) for discussion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 152
                            }
                        ],
                        "text": "Crucially, thealgorithms canbeefficiently appliedto exponentialsizedrepresentationsof parsetrees,suchasthe \u201call subtrees\u201d (DOP)representationdescribedby (Bod 1998),or a representationtrackingall sub-fragmentsof atagged sentence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 156
                            }
                        ],
                        "text": "We show how thealgorithmscanbeefficiently applied to exponential sized representations of parsetrees,suchasthe \u201call subtrees\u201d(DOP) representationdescribedby (Bod 1998), or a representationtracking all sub-fragmentsof a taggedsentence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 120
                            }
                        ],
                        "text": "(Notethatasimilar recursionis de-\nscribedby Goodman(Goodman1996),Goodman\u2019s application being the conversion of Bod\u2019s model (Bod 1998)to anequivalentPCFG.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 114
                            }
                        ],
                        "text": "Wenow considerarepresentationthattracksall subtreesseenin training data,the representationstudied extensi vely by (Bod 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "(Bod 1998)describesquitedifferentparameterestimationandparsingmethodsfor theDOP representation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 122
                            }
                        ],
                        "text": "(Notethatasimilar recursionis describedby Goodman(Goodman1996),Goodman\u2019 s application being the conversion of Bod\u2019s model (Bod 1998)to anequivalentPCFG."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 33
                            }
                        ],
                        "text": "7 Relationship to Previous Work\n(Bod 1998)describesquitedifferentparameterestimationandparsingmethodsfor theDOP representation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 114
                            }
                        ],
                        "text": "Wenow considerarepresentationthattracksall subtreesseenin training data,the representationstudied extensively by (Bod 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6090713,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67de7786e49c285bf85cd8f9404aea4bd42e2da9",
            "isKey": true,
            "numCitedBy": 304,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction: what are the productive units of natural language? 2. A DOP model for tree representations 3. Formal stochastic language theory 4. Parsing and disambiguation 5. Testing DOP: redundancy vs. minimality 6. Learning new words 7. Learning new structures 8. A DOP model for compositional semantic representations 9. Speech understanding and dialogue processing 10. DOP models for non-context-free representations 11. Conclusion: linguistics reconsidered References."
            },
            "slug": "Beyond-Grammar:-An-Experience-Based-Theory-of-Bod",
            "title": {
                "fragments": [],
                "text": "Beyond Grammar: An Experience-Based Theory of Language"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work presents a DOP model for tree representations, a formal stochastic language theory, and a model for non-context-free representations for compositional semantic representations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068005320"
                        ],
                        "name": "Raj D. Iyer",
                        "slug": "Raj-D.-Iyer",
                        "structuredName": {
                            "firstName": "Raj",
                            "lastName": "Iyer",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raj D. Iyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16692650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75e85c2e90b0abb17ae6445516a49ac05c1dbf0f",
            "isKey": false,
            "numCitedBy": 2182,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of learning to accurately rank a set of objects by combining a given collection of ranking or preference functions. This problem of combining preferences arises in several applications, such as that of combining the results of different search engines, or the \"collaborative-filtering\" problem of ranking movies for a user based on the movie rankings provided by other users. In this work, we begin by presenting a formal framework for this general problem. We then describe and analyze an efficient algorithm called RankBoost for combining preferences based on the boosting approach to machine learning. We give theoretical results describing the algorithm's behavior both on the training data, and on new test data not seen during training. We also describe an efficient implementation of the algorithm for a particular restricted but common case. We next discuss two experiments we carried out to assess the performance of RankBoost. In the first experiment, we used the algorithm to combine different web search strategies, each of which is a query expansion for a given domain. The second experiment is a collaborative-filtering task for making movie recommendations."
            },
            "slug": "An-Efficient-Boosting-Algorithm-for-Combining-Freund-Iyer",
            "title": {
                "fragments": [],
                "text": "An Efficient Boosting Algorithm for Combining Preferences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work describes and analyze an efficient algorithm called RankBoost for combining preferences based on the boosting approach to machine learning, and gives theoretical results describing the algorithm's behavior both on the training data, and on new test data not seen during training."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152465203"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47428006"
                        ],
                        "name": "S. Canon",
                        "slug": "S.-Canon",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Canon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Canon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140471"
                        ],
                        "name": "Zhiyi Chi",
                        "slug": "Zhiyi-Chi",
                        "structuredName": {
                            "firstName": "Zhiyi",
                            "lastName": "Chi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiyi Chi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289329"
                        ],
                        "name": "S. Riezler",
                        "slug": "S.-Riezler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Riezler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riezler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 19
                            }
                        ],
                        "text": "The experimentsin this paperusethe top candidatesfrom abaselineprobabilisticmodel:themodel of (Collins 1999) for parsing, and a maximumentropy taggerfor named-entityrecognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17435621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "463dbd690d912b23d29b7581fb6b253b36f50394",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Log-linear models provide a statistically sound framework for Stochastic \"Unification-Based\" Grammars (SUBGs) and stochastic versions of other kinds of grammars. We describe two computationally-tractable ways of estimating the parameters of such grammars from a training corpus of syntactic analyses, and apply these to estimate a stochastic version of Lexical-Functional Grammar."
            },
            "slug": "Estimators-for-Stochastic-\"Unification-Based\"-Johnson-Geman",
            "title": {
                "fragments": [],
                "text": "Estimators for Stochastic \"Unification-Based\" Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Two computationally-tractable ways of estimating the parameters of Stochastic \"Unification-Based\" Grammars from a training corpus of syntactic analyses are described and applied to estimate a stochastic version of Lexical-Functional Grammar."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145177220"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289329"
                        ],
                        "name": "S. Riezler",
                        "slug": "S.-Riezler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Riezler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riezler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16005368,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "1014941e7d5347fce910edbe63906451037958bb",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Log-linear models provide a statistically sound framework for Stochastic \\Uniication-Based\" Grammars (SUBGs) and stochastic versions of other kinds of grammars. We describe two computationally-tractable ways of estimating the parameters of such grammars from a training corpus of syntactic analyses, and apply these to estimate a stochastic version of Lexical-Functional Grammar."
            },
            "slug": "Estimators-for-Stochastic-\\-Uni-cation-Based-\"-Johnson-Geman",
            "title": {
                "fragments": [],
                "text": "Estimators for Stochastic \\ Uni cation-Based \" Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Two computationally-tractable ways of estimating the parameters of such grammars from a training corpus of syntactic analyses are described, and these are applied to estimate a stochastic version of Lexical-Functional Grammar."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793475"
                        ],
                        "name": "A. Ratnaparkhi",
                        "slug": "A.-Ratnaparkhi",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ratnaparkhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ratnaparkhi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 86
                            }
                        ],
                        "text": "As a baselinemodelwe useda maximumentropy tagger, very similar to the onedescribedin (Ratnaparkhi1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 116
                            }
                        ],
                        "text": "Maximumentropy taggershave beenshown to be highly competitive on a numberof taggingtasks,suchaspartof-speechtagging(Ratnaparkhi1996),andnamedentity recognition(Borthwick et. al 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5914287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a574e320d899e7e82e341eb64baef7dfe8a24642",
            "isKey": false,
            "numCitedBy": 1545,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a statistical model which trains from a corpus annotated with Part Of Speech tags and assigns them to previously unseen text with state of the art accuracy The model can be classi ed as a Maximum Entropy model and simultaneously uses many contextual features to predict the POS tag Furthermore this paper demonstrates the use of specialized fea tures to model di cult tagging decisions discusses the corpus consistency problems discovered during the implementation of these features and proposes a training strategy that mitigates these problems"
            },
            "slug": "A-Maximum-Entropy-Model-for-Part-Of-Speech-Tagging-Ratnaparkhi",
            "title": {
                "fragments": [],
                "text": "A Maximum Entropy Model for Part-Of-Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A statistical model which trains from a corpus annotated with Part Of Speech tags and assigns them to previously unseen text with state of the art accuracy and discusses the corpus consistency problems discovered during the implementation of these features."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727076"
                        ],
                        "name": "H. Lodhi",
                        "slug": "H.-Lodhi",
                        "structuredName": {
                            "firstName": "Huma",
                            "lastName": "Lodhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Lodhi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144884649"
                        ],
                        "name": "C. Saunders",
                        "slug": "C.-Saunders",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Saunders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Saunders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4562073"
                        ],
                        "name": "C. Watkins",
                        "slug": "C.-Watkins",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Watkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Watkins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 72
                            }
                        ],
                        "text": "2i.e., polynomial in the numberof training examples,and thesizeof treesor sentencesin trainingandtestdata."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 669209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f330f1f472f860212b980bb9be81eff884f7f0e1",
            "isKey": false,
            "numCitedBy": 1643,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel kernel for comparing two text documents. The kernel is an inner product in the feature space consisting of all subsequences of length k. A subsequence is any ordered sequence of k characters occurring in the text though not necessarily contiguously. The subsequences are weighted by an exponentially decaying factor of their full length in the text, hence emphasising those occurrences which are close to contiguous. A direct computation of this feature vector would involve a prohibitive amount of computation even for modest values of k, since the dimension of the feature space grows exponentially with k. The paper describes how despite this fact the inner product can be efficiently evaluated by a dynamic programming technique. A preliminary experimental comparison of the performance of the kernel compared with a standard word feature space kernel [6] is made showing encouraging results."
            },
            "slug": "Text-Classification-using-String-Kernels-Lodhi-Saunders",
            "title": {
                "fragments": [],
                "text": "Text Classification using String Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A novel kernel is introduced for comparing two text documents consisting of an inner product in the feature space consisting of all subsequences of length k, which can be efficiently evaluated by a dynamic programming technique."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32183233"
                        ],
                        "name": "Andrew Borthwick",
                        "slug": "Andrew-Borthwick",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Borthwick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Borthwick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144360624"
                        ],
                        "name": "J. Sterling",
                        "slug": "J.-Sterling",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Sterling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sterling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685296"
                        ],
                        "name": "Eugene Agichtein",
                        "slug": "Eugene-Agichtein",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Agichtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Agichtein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Maximum entropy taggers have been shown to be highly competitive on a number of tagging tasks, such as partof-speech tagging (Ratnaparkhi 1996), and namedentity recognition ( Borthwick et. al 1998 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6118890,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4df361d65a15ca9a7fc27c58c38b04d1f41e6f62",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a novel statistical namedentity (i.e. \"proper name\") recognition system built around a maximum entity framework. By working v,ithin the framework of maximum entropy theory and utilizing a flexible object-based architecture, the system is able to make use of an extraordinarily diverse range of knowledge sources in making its tagging decisions. These knowledge sources include capitalization features, lexical features, features indicating the current section of text (i.e. headline or main body), and dictionaries of single or multi-word terms. The purely statistical system contains no hand-generated patterns and achieves a result comparable with the best statistical systems. However, when combined with other handcoded systems, the system achieves scores that exceed the highest comparable scores thus-far published. 1 I N T R O D U C T I O N Named entity recognition is one of the simplest of the common message understanding tasks. The objective is to identify and categorize all members of certain categories of \"proper names\" from a given corpus. The specific test bed which will be the subject of this paper is that of the Seventh Message Understanding Conference (MUC-7), in which the task was to identify \"names\" falling into one of seven categories: person, organization, location, date, time, percentage, and monetary amount. This paper describes a new system called \"Maximum Entropy Named Entity\" or \"MENE\" (pronounced \"meanie\"). By working within the framework of maximum entropy theory and utilizing a flexible object-based architecture, the system is able to make use of an extraordinarily diverse range of knowledge sources in making its tagging decision. These knowledge sources include capitalization features, lexical features, and features indicating the current section of text. It makes use of a broad array of dictionaries of useful single or multi-word terms such as first names, company names, and corporate suffixes, and automatically handles cases where words are in more than one dictionary. Our dictio152 naries required no manual editing and were either downloaded from the web or were simply \"obvious\" lists entered by hand. This system, built from off-the-shelf knowledge sources, contained no hand-generated pat terns and achieved a result which is comparable with that of the best statistical systems. Further experiments showed that when combined with handcoded systems from NYU, the University of Manitoba, and IsoQuest, Inc., MENE was able to generate scores which exceeded the highest scores thus-far reported by any system on a MUC evaluation. Given appropriate training data, we believe that this system is highly portable to other domains and languages and have already achieved good results on upper-case English. We also feel that there are plenty of avenues to explore in enhancing the system's performance on English-language newspaper"
            },
            "slug": "Exploiting-Diverse-Knowledge-Sources-via-Maximum-in-Borthwick-Sterling",
            "title": {
                "fragments": [],
                "text": "Exploiting Diverse Knowledge Sources via Maximum Entropy in Named Entity Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "This paper describes a novel statistical namedentity recognition system built around a maximum entity framework using the framework of maximum entropy theory and utilizing a flexible object-based architecture to make use of an extraordinarily diverse range of knowledge sources in making its tagging decisions."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@COLING/ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The kernels we describe are related to the kernels over discrete structures in (Haussler 1999; Lodhi et al. 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 70
                            }
                        ],
                        "text": "Thekernelswe describearerelatedto thekernelsoverdiscretestructuresin (Haussler1999;Lodhi etal."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17702358,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "5ee0d8aeb2cb01ef4d8a858d234e72a7400c03ac",
            "isKey": false,
            "numCitedBy": 1371,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new method of constructing kernels on sets whose elements are discrete structures like strings, trees and graphs. The method can be applied iteratively to build a kernel on a innnite set from kernels involving generators of the set. The family of kernels generated generalizes the family of radial basis kernels. It can also be used to deene kernels in the form of joint Gibbs probability distributions. Kernels can be built from hidden Markov random elds, generalized regular expressions, pair-HMMs, or ANOVA de-compositions. Uses of the method lead to open problems involving the theory of innnitely divisible positive deenite functions. Fundamentals of this theory and the theory of reproducing kernel Hilbert spaces are reviewed and applied in establishing the validity of the method."
            },
            "slug": "Convolution-kernels-on-discrete-structures-Haussler",
            "title": {
                "fragments": [],
                "text": "Convolution kernels on discrete structures"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A new method of constructing kernels on sets whose elements are discrete structures like strings, trees and graphs is introduced, which can be applied iteratively to build a kernel on a innnite set from kernels involving generators of the set."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5885617,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2479a5cf6cefefb83166c612564787414e47131f",
            "isKey": false,
            "numCitedBy": 812,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce and analyze a new algorithm for linear classification which combines Rosenblatt's perceptron algorithm with Helmbold and Warmuth's leave-one-out method. Like Vapnik's maximal-margin classifier, our algorithm takes advantage of data that are linearly separable with large margins. Compared to Vapnik's algorithm, however, ours is much simpler to implement, and much more efficient in terms of computation time. We also show that our algorithm can be efficiently used in very high dimensional spaces using kernel functions. We performed some experiments using our algorithm, and some variants of it, for classifying images of handwritten digits. The performance of our algorithm is close to, but not as good as, the performance of maximal-margin classifiers on the same problem, while saving significantly on computation time and programming effort."
            },
            "slug": "Large-Margin-Classification-Using-the-Perceptron-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "Large Margin Classification Using the Perceptron Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new algorithm for linear classification which combines Rosenblatt's perceptron algorithm with Helmbold and Warmuth's leave-one-out method is introduced, which is much simpler to implement, and much more efficient in terms of computation time."
            },
            "venue": {
                "fragments": [],
                "text": "COLT' 98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 62
                            }
                        ],
                        "text": "See(CristianiniandShawe-Taylor 2000)for discussionof the perceptronalgorithm, including an overview of varioustheoremsjustifying this way of settingtheparameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14727192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c04f8002e24a8c09bfbfedca3c6c346fe1e5d53",
            "isKey": false,
            "numCitedBy": 13352,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "From the publisher: This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software."
            },
            "slug": "An-Introduction-to-Support-Vector-Machines-and-Cristianini-Shawe-Taylor",
            "title": {
                "fragments": [],
                "text": "An Introduction to Support Vector Machines and Other Kernel-based Learning Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory, and will guide practitioners to updated literature, new applications, and on-line software."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51083130"
                        ],
                        "name": "F. Rosenblatt",
                        "slug": "F.-Rosenblatt",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Rosenblatt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rosenblatt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The perceptron algorithm is one of the oldest algorithms in machine learning, going back to (Rosenblatt 1958)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 85
                            }
                        ],
                        "text": "Theperceptronalgorithmis oneof theoldestalgorithms in machinelearning,going back to (Rosenblatt 1958)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12781225,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "5d11aad09f65431b5d3cb1d85328743c9e53ba96",
            "isKey": false,
            "numCitedBy": 9074,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The first of these questions is in the province of sensory physiology, and is the only one for which appreciable understanding has been achieved. This article will be concerned primarily with the second and third questions, which are still subject to a vast amount of speculation, and where the few relevant facts currently supplied by neurophysiology have not yet been integrated into an acceptable theory. With regard to the second question, two alternative positions have been maintained. The first suggests that storage of sensory information is in the form of coded representations or images, with some sort of one-to-one mapping between the sensory stimulus"
            },
            "slug": "The-perceptron:-a-probabilistic-model-for-storage-Rosenblatt",
            "title": {
                "fragments": [],
                "text": "The perceptron: a probabilistic model for information storage and organization in the brain."
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This article will be concerned primarily with the second and third questions, which are still subject to a vast amount of speculation, and where the few relevant facts currently supplied by neurophysiology have not yet been integrated into an acceptable theory."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2545803"
                        ],
                        "name": "M. Aizerman",
                        "slug": "M.-Aizerman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Aizerman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Aizerman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60493317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3caf34c1c86633b6e80dca29e3cb2b6367a0f93",
            "isKey": false,
            "numCitedBy": 1692,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theoretical-Foundations-of-the-Potential-Function-Aizerman",
            "title": {
                "fragments": [],
                "text": "Theoretical Foundations of the Potential Function Method in Pattern Recognition Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 46
                            }
                        ],
                        "text": "We used the samedata set as that describedin (Collins 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 21
                            }
                        ],
                        "text": "Theboostingmethodof (Collins 2000)showed 89.6%/89.9%recall andprecisionon rerankingapproachesfor the samedatasets(sentenceslessthan 100 wordsin length)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 84
                            }
                        ],
                        "text": "(Charniak2000)describesa\ndifferent methodwhich achieves very similar performanceto (Collins 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 60
                            }
                        ],
                        "text": "different method which achieves very similar performance to (Collins 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 50
                            }
                        ],
                        "text": "1999), and the boosting approaches for parsing in (Collins 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 177
                            }
                        ],
                        "text": "The methodis relatedto the boostingapproachto ranking problems(Freundet al. 1998), the Markov RandomField methodsof (Johnsonet al. 1999),andtheboostingapproaches for parsingin (Collins 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 47
                            }
                        ],
                        "text": "We used the same data set as that described in (Collins 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminative Reranking for Natural L"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 111
                            }
                        ],
                        "text": "From a theoreticalpoint of view, it is difficult to find motivation for the parameterestimationmethods usedby (Bod 1998) \u2013 see(Johnson2002) for discussion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "(Bod 1998) describes quite different parameter estimation and parsing methods for the DOP representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 152
                            }
                        ],
                        "text": "Crucially, thealgorithms canbeefficiently appliedto exponentialsizedrepresentationsof parsetrees,suchasthe \u201call subtrees\u201d (DOP)representationdescribedby (Bod 1998),or a representationtrackingall sub-fragmentsof atagged sentence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 156
                            }
                        ],
                        "text": "We show how thealgorithmscanbeefficiently applied to exponential sized representations of parsetrees,suchasthe \u201call subtrees\u201d(DOP) representationdescribedby (Bod 1998), or a representationtracking all sub-fragmentsof a taggedsentence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 120
                            }
                        ],
                        "text": "(Notethatasimilar recursionis de-\nscribedby Goodman(Goodman1996),Goodman\u2019s application being the conversion of Bod\u2019s model (Bod 1998)to anequivalentPCFG.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 167
                            }
                        ],
                        "text": "Crucially, the algorithms can be efficiently applied to exponential sized representations of parse trees, such as the \u201call subtrees\u201d (DOP) representation described by (Bod 1998), or a representation tracking all sub-fragments of a tagged sentence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 168
                            }
                        ],
                        "text": "We show how the algorithms can be efficiently applied to exponential sized representations of parse trees, such as the \u201call subtrees\u201d (DOP) representation described by (Bod 1998), or a representation tracking all sub-fragments of a tagged sentence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 123
                            }
                        ],
                        "text": "We now consider a representation that tracks all subtrees seen in training data, the representation studied extensively by (Bod 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 114
                            }
                        ],
                        "text": "From a theoretical point of view, it is difficult to find motivation for the parameter estimation methods used by (Bod 1998) \u2013 see (Johnson 2002) for discussion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 33
                            }
                        ],
                        "text": "7 Relationship to Previous Work\n(Bod 1998)describesquitedifferentparameterestimationandparsingmethodsfor theDOP representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 129
                            }
                        ],
                        "text": "(Note that a similar recursion is described by Goodman (Goodman 1996), Goodman\u2019s application being the conversion of Bod\u2019s model (Bod 1998) to an equivalent PCFG."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 114
                            }
                        ],
                        "text": "Wenow considerarepresentationthattracksall subtreesseenin training data,the representationstudied extensively by (Bod 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1998).Beyond Grammar: An Experience-Based Theory of Language. CSLI Publications/Cambridge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 27
                            }
                        ],
                        "text": "In spite of theseproblems,(Bod 2001) gives excellent results for the methodon parsing Wall StreetJournaltext."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 58
                            }
                        ],
                        "text": "Even after this, Bod\u2019s methodis left with a huge grammar: (Bod 2001) describesa grammarwith"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 58
                            }
                        ],
                        "text": "Even after this, Bod\u2019s methodis left with a huge grammar: (Bod 2001) describesa grammarwith\nover 5 million sub-structures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 1
                            }
                        ],
                        "text": "(Bod 2001)describes experimentsgiving 90.6%/90.8%recall and precision for sentencesof lessthan40 words in length, usingtheall-subtreesrepresentation,but usingvery differentalgorithmsandparameterestimationmethodsfrom theperceptronalgorithmsin thispaper(see section7 for morediscussion)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "What is the Minimal Set of Fragmentsthat AchievesMaximal ParseAccuracy"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 53
                            }
                        ],
                        "text": "1%relative reductionin error rate over the model of (Collins 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 95
                            }
                        ],
                        "text": "The experimentsin this paperusethe top candidatesfrom abaselineprobabilisticmodel:themodel of (Collins 1999) for parsing, and a maximumentropy taggerfor named-entityrecognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 18
                            }
                        ],
                        "text": "CO99is model2 of (Collins 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 11
                            }
                        ],
                        "text": "Model2 of (Collins1999)was usedto parseboththetrainingandtestdata,producing multiple hypothesesfor eachsentence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60837916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc0fea53924264e4d1ec668e98a7b4a3852cc729",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Review-of-Beyond-grammar:-an-experience-based-of-by-Collins",
            "title": {
                "fragments": [],
                "text": "Review of Beyond grammar: an experience-based theory of language by Rens Bod. CSLI Publications 1998."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 125
                            }
                        ],
                        "text": "Maximum entropy taggers have been shown to be highly competitive on a number of tagging tasks, such as partof-speech tagging (Ratnaparkhi 1996), and namedentity recognition (Borthwick et."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 86
                            }
                        ],
                        "text": "As a baselinemodelwe useda maximumentropy tagger, very similar to the onedescribedin (Ratnaparkhi1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 91
                            }
                        ],
                        "text": "As a baseline model we used a maximum entropy tagger, very similar to the one described in (Ratnaparkhi 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 116
                            }
                        ],
                        "text": "Maximumentropy taggershave beenshown to be highly competitive on a numberof taggingtasks,suchaspartof-speechtagging(Ratnaparkhi1996),andnamedentity recognition(Borthwick et. al 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum entropy part-of-speech tagger. In Proceedings of the empirical methods in natural language processing conference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 1
                            }
                        ],
                        "text": "(Collins 2002a)describesexperimentson the samenamed-entitydatasetas in thispaper, but usingexplicit featuresratherthankernels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 76
                            }
                        ],
                        "text": "For relatedwork on the voted perceptronalgorithm appliedto NLP problems,see(Collins 2002a) and(Collins 2002b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 1
                            }
                        ],
                        "text": "(Collins 2002b)describeshow the votedperceptroncanbeusedto trainmaximum-entropy style taggers,andalsogivesa morethoroughdiscussion of the theory behind the perceptronalgorithm applied to rankingtasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 188
                            }
                        ],
                        "text": "We useda feature set which includedthe current,next, and previous word; the previous two tags;variouscapitalization andotherfeaturesof thewordbeingtagged(thefull featuresetis describedin (Collins2002a))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2002a).Ranking Algorithms for Named\u2013Entity Extraction:BoostingandtheVotedPerceptron"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66441953"
                        ],
                        "name": "No Value",
                        "slug": "No-Value",
                        "structuredName": {
                            "firstName": "No",
                            "lastName": "Value",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "No Value"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 196088431,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bbbe3fb9f49528ad4cff91d4cb7b1285266fe051",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-57th-Annual-Meeting-of-the-for-Value",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713919"
                        ],
                        "name": "P. Langley",
                        "slug": "P.-Langley",
                        "structuredName": {
                            "firstName": "Pat",
                            "lastName": "Langley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Langley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60013232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfd57e0e02ae9da6a289245d70970775848a8804",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-Seventeenth-International-on-CA,-Langley",
            "title": {
                "fragments": [],
                "text": "Proceedings of the Seventeenth International Conference on Machine Learning (ICML 2000), Stanford University, Stanford, CA, USA, June 29 - July 2, 2000"
            },
            "venue": {
                "fragments": [],
                "text": "ICML 2000"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The DOP estimation method is biased andinconsistent"
            },
            "venue": {
                "fragments": [],
                "text": "Text Classi cation using StringKernels . To appear in Advances in Neural Information Processing Systems"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convolution Kernelsfor Natural Language"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Neural Information Processing Systems ( NIPS 14 )"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exploiting DiverseKnowledgeSourcesvia Maximum Entropy in NamedEntity Recognition.Proc"
            },
            "venue": {
                "fragments": [],
                "text": "Sixth Workshop on Very Large Corpora"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 86
                            }
                        ],
                        "text": "As a baselinemodelwe useda maximumentropy tagger, very similar to the onedescribedin (Ratnaparkhi1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 116
                            }
                        ],
                        "text": "Maximumentropy taggershave beenshown to be highly competitive on a numberof taggingtasks,suchaspartof-speechtagging(Ratnaparkhi1996),andnamedentity recognition(Borthwick et. al 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum entropy part-ofspeech tagger"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the empirical methods in natural language processing conference"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1964).Theoretical Foundationsof thePotentialFunctionMethodin Pattern RecognitionLearning.In Automation and Remote Control, 25:821\u2013837"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimators for stochastic\u00f9niication-based\" grammars"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ProbabilisticModel for InformationStorageandOrganizationin theBrain.Psychological Review, 65,386\u2013408.(Reprintedin"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing (MIT"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 125
                            }
                        ],
                        "text": "From a theoreticalpoint of view, it is difficult to find motivation for the parameterestimationmethods usedby (Bod 1998) \u2013 see(Johnson2002) for discussion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 131
                            }
                        ],
                        "text": "From a theoretical point of view, it is difficult to find motivation for the parameter estimation methods used by (Bod 1998) \u2013 see (Johnson 2002) for discussion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The DOP estimation method is biased and inconsistent.Computational Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 42
                            }
                        ],
                        "text": "1998), the Markov Random Field methods of (Johnson et al. 1999), and the boosting approaches for parsing in (Collins 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimators for stochastic \u2018unification-based"
            },
            "venue": {
                "fragments": [],
                "text": "Convolution Kernels on Discrete Structures. Technical report,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2001).ConvolutionKernelsfor Natural Language.In"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Neural Information Processing Systems (NIPS"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Collins, M"
            },
            "venue": {
                "fragments": [],
                "text": "1999.Head-Dri"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E \u000e cient algorithms for parsingthe DOP model"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Conferenceon Empirical Methods in Natural Language Processing ( EMNLP"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2000).An introduction to Support Vector Machines and other kernel-based learning methods. CambridgeUniversityPress"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 86
                            }
                        ],
                        "text": "As a baselinemodelwe useda maximumentropy tagger, very similar to the onedescribedin (Ratnaparkhi1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 116
                            }
                        ],
                        "text": "Maximumentropy taggershave beenshown to be highly competitive on a numberof taggingtasks,suchaspartof-speechtagging(Ratnaparkhi1996),andnamedentity recognition(Borthwick et. al 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum entropy partofspeech tagger"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1993).Building a largeannotatedcorpusof english:ThePenntreebank"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 92
                            }
                        ],
                        "text": "The perceptron algorithm is one of the oldest algorithms in machine learning, going back to (Rosenblatt 1958)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 85
                            }
                        ],
                        "text": "Theperceptronalgorithmis oneof theoldestalgorithms in machinelearning,going back to (Rosenblatt 1958)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Perceptron: A Probabilistic Model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1958
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 17
                            }
                        ],
                        "text": "A previous paper (Collins and Duffy 2001) showed improvements over a PCFG in parsing the ATIS task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 18
                            }
                        ],
                        "text": "A previous paper (Collins and Duffy 2001) showed improvementsover a PCFGin parsingthe ATIS task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convolution Kernels for N"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 27,
            "methodology": 17,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 48,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/New-Ranking-Algorithms-for-Parsing-and-Tagging:-and-Collins-Duffy/fe638b5610475d4524684fb2c2b7b08c119c8700?sort=total-citations"
}