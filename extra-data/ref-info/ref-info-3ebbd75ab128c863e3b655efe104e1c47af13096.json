{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709053"
                        ],
                        "name": "Daniel Scharstein",
                        "slug": "Daniel-Scharstein",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Scharstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Scharstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 151
                            }
                        ],
                        "text": "Although some researchers have proposed measures of pixel dissimilarity that are insensitive to gain, bias, noise, and depth discontinuities [6], [9], [10], [11], [13], there seems to be no work on explicitly achieving insensitivity to image sampling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 606147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a2de374e942975655105bf9a5870904aa7a7221",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple yet powerful method to perform point-to-point matching between two images. The method uses an evidence measure, whose value for a given displacement reflects both the similarity between two locations and the confidence in a correct match. The measure is based on the gradient fields of the images, and can be computed quickly and in parallel. Accumulating the evidence measure for different displacements allows (1) stable computation, of correspondences without smoothing across motion boundaries, and (2) detection of dominant motions. The method works well both on highly textured images and on images containing regions of uniform intensities, and can be used for a variety of applications, including stereo, motion, and object tracking."
            },
            "slug": "Matching-images-by-comparing-their-gradient-fields-Scharstein",
            "title": {
                "fragments": [],
                "text": "Matching images by comparing their gradient fields"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A simple yet powerful method to perform point-to-point matching between two images that uses an evidence measure, whose value for a given displacement reflects both the similarity between two locations and the confidence in a correct match."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 12th International Conference on Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751089"
                        ],
                        "name": "Alain Crouzil",
                        "slug": "Alain-Crouzil",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Crouzil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alain Crouzil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403231565"
                        ],
                        "name": "L. Massip-Pailhes",
                        "slug": "L.-Massip-Pailhes",
                        "structuredName": {
                            "firstName": "Louis",
                            "lastName": "Massip-Pailhes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Massip-Pailhes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2272587"
                        ],
                        "name": "S. Castan",
                        "slug": "S.-Castan",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Castan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Castan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 141
                            }
                        ],
                        "text": "Although some researchers have proposed measures of pixel dissimilarity that are insensitive to gain, bias, noise, and depth discontinuities [6], [9], [10], [11], [13], there seems to be no work on explicitly achieving insensitivity to image sampling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11126660,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "932f89a0de60515a4b7941118b7e1ae24d68ecb8",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Correlation based methods are a common tool for the correspondence problem. They are able to perform a dense point-to-point matching between two images, but post-processing is often necessary to improve the results. In this paper we propose a new correlation measure using the gradient vector fields of the images. We compare our method to classical correlation measures based on the grey levels. The new method gives better results than others when it is applied on random dot stereograms and on real images."
            },
            "slug": "A-new-correlation-criterion-based-on-gradient-Crouzil-Massip-Pailhes",
            "title": {
                "fragments": [],
                "text": "A new correlation criterion based on gradient fields similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a new correlation measure using the gradient vector fields of the images that gives better results than others when it is applied on random dot stereograms and on real images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705903"
                        ],
                        "name": "S. Intille",
                        "slug": "S.-Intille",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Intille",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Intille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 197
                            }
                        ],
                        "text": "This dissimilarity measure could be effortlessly integrated into existing stereo algorithms that minimize an objective function that adds dissimilarities to occlusion penalties [1], [2], [5], [7], [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "For example, there has recently emerged a class of stereo algorithms [1], [2], [5], [7], [8] in which epipolar scanlines are matched by minimizing a cost function that sums the absolute or squared differences of pixel intensities with penalties for occlusions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15575633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbf5ed8a605e0698389599775e591127e99f3614",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for solving the stereo matching problem in the presence of large occlusion is presented. A data structure \u2014 the disparity space image \u2014 is defined in which we explicitly model the effects of occlusion regions on the stereo solution. We develop a dynamic programming algorithm that finds matches and occlusions simultaneously. We show that while some cost must be assigned to unmatched pixels, our algorithm's occlusion-cost sensitivity and algorithmic complexity can be significantly reduced when highly-reliable matches, or ground control points, are incorporated into the matching process. The use of ground control points eliminates both the need for biasing the process towards a smooth solution and the task of selecting critical prior probabilities describing image formation."
            },
            "slug": "Disparity-Space-Images-and-Large-Occlusion-Stereo-Intille-Bobick",
            "title": {
                "fragments": [],
                "text": "Disparity-Space Images and Large Occlusion Stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that while some cost must be assigned to unmatched pixels, the algorithm's occlusion-cost sensitivity and algorithmic complexity can be significantly reduced when highly-reliable matches, or ground control points, are incorporated into the matching process."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2984143"
                        ],
                        "name": "R. Zabih",
                        "slug": "R.-Zabih",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Zabih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803592"
                        ],
                        "name": "J. Woodfill",
                        "slug": "J.-Woodfill",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Woodfill",
                            "middleNames": [
                                "Iselin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Woodfill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 163
                            }
                        ],
                        "text": "Although some researchers have proposed measures of pixel dissimilarity that are insensitive to gain, bias, noise, and depth discontinuities [6], [9], [10], [11], [13], there seems to be no work on explicitly achieving insensitivity to image sampling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 703552,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b288673205c479d0a019d45f85c2716fe1f85096",
            "isKey": false,
            "numCitedBy": 1863,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new approach to the correspondence problem that makes use of non-parametric local transforms as the basis for correlation. Non-parametric local transforms rely on the relative ordering of local intensity values, and not on the intensity values themselves. Correlation using such transforms can tolerate a significant number of outliers. This can result in improved performance near object boundaries when compared with conventional methods such as normalized correlation. We introduce two non-parametric local transforms: the rank transform, which measures local intensity, and the census transform, which summarizes local image structure. We describe some properties of these transforms, and demonstrate their utility on both synthetic and real data."
            },
            "slug": "Non-parametric-Local-Transforms-for-Computing-Zabih-Woodfill",
            "title": {
                "fragments": [],
                "text": "Non-parametric Local Transforms for Computing Visual Correspondence"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new approach to the correspondence problem that makes use of non-parametric local transforms as the basis for correlation, which can result in improved performance near object boundaries when compared with conventional methods such as normalized correlation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 182
                            }
                        ],
                        "text": "This dissimilarity measure could be effortlessly integrated into existing stereo algorithms that minimize an objective function that adds dissimilarities to occlusion penalties [1], [2], [5], [7], [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "For example, there has recently emerged a class of stereo algorithms [1], [2], [5], [7], [8] in which epipolar scanlines are matched by minimizing a cost function that sums the absolute or squared differences of pixel intensities with penalties for occlusions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "With the exception of [1] and [2], all of these algorithms work at pixel resolution, and therefore a measure of pixel dissimilarity that is insensitive to sampling would eliminate the errors that they experience due to sampling effects [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1053319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7db5db57bdea8c347b202230f43655c8a247008f",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "A half-occluded region in a stereo pair is a set of pixels in one image representing points in space visible to that camera or eye only, and not to the other. These occur typically as parts of the background immediately to the left and right sides of nearby occluding objects, and are present in most natural scenes. Previous approaches to stereo either ignored these unmatchable points or attempted to weed them out in a second pass. An algorithm that incorporates them from the start as a strong clue to depth discontinuities is presented. The authors first derive a measure for goodness of fit and a prior based on a simplified model of objects in space, which leads to an energy functional depending both on the depth as measured from a central cyclopean eye and on the regions of points occluded from the left and right eye perspectives. They minimize this using dynamic programming along epipolar lines followed by annealing in both dimensions. Experiments indicate that this method is very effective even in difficult scenes.<<ETX>>"
            },
            "slug": "A-Bayesian-treatment-of-the-stereo-correspondence-Belhumeur-Mumford",
            "title": {
                "fragments": [],
                "text": "A Bayesian treatment of the stereo correspondence problem using half-occluded regions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The authors first derive a measure for goodness of fit and a prior based on a simplified model of objects in space, which leads to an energy functional depending both on the depth as measured from a central cyclopean eye and on the regions of points occluded from the left and right eye perspectives."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073254280"
                        ],
                        "name": "S. L. Hingorani",
                        "slug": "S.-L.-Hingorani",
                        "structuredName": {
                            "firstName": "Sunita",
                            "lastName": "Hingorani",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. L. Hingorani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109493725"
                        ],
                        "name": "Satish Rao",
                        "slug": "Satish-Rao",
                        "structuredName": {
                            "firstName": "Satish",
                            "lastName": "Rao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Satish Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711252"
                        ],
                        "name": "B. Maggs",
                        "slug": "B.-Maggs",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Maggs",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Maggs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 187
                            }
                        ],
                        "text": "This dissimilarity measure could be effortlessly integrated into existing stereo algorithms that minimize an objective function that adds dissimilarities to occlusion penalties [1], [2], [5], [7], [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "For example, there has recently emerged a class of stereo algorithms [1], [2], [5], [7], [8] in which epipolar scanlines are matched by minimizing a cost function that sums the absolute or squared differences of pixel intensities with penalties for occlusions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 236
                            }
                        ],
                        "text": "With the exception of [1] and [2], all of these algorithms work at pixel resolution, and therefore a measure of pixel dissimilarity that is insensitive to sampling would eliminate the errors that they experience due to sampling effects [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16802006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b232e3426e0014389ea05132ea8d08789dcc0566",
            "isKey": false,
            "numCitedBy": 555,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A stereo algorithm is presented that optimizes a maximum likelihood cost function. The maximum likelihood cost function assumes that corresponding features in the left and right images are normally distributed about a common true value and consists of a weighted squared error term if two features are matched or a (fixed) cost if a feature is determined to be occluded. The stereo algorithm finds the set of correspondences that maximize the cost function subject to ordering and uniqueness constraints. The stereo algorithm is independent of the matching primitives. However, for the experiments described in this paper, matching is performed on the $cf4$individual pixel intensities.$cf3$ Contrary to popular belief, the pixel-based stereo appears to be robust for a variety of images. It also has the advantages of (i) providing adensedisparity map, (ii) requiringnofeature extraction, and (iii)avoidingthe adaptive windowing problem of area-based correlation methods. Because feature extraction and windowing are unnecessary, a very fast implementation is possible. Experimental results reveal that good stereo correspondences can be found using only ordering and uniqueness constraints, i.e., withoutlocalsmoothness constraints. However, it is shown that the original maximum likelihood stereo algorithm exhibits multiple global minima. The dynamic programming algorithm is guaranteed to find one, but not necessarily the same one for each epipolar scanline, causing erroneous correspondences which are visible as small local differences between neighboring scanlines. Traditionally, regularization, which modifies the original cost function, has been applied to the problem of multiple global minima. We developed several variants of the algorithm that avoid classical regularization while imposing several global cohesiveness constraints. We believe this is a novel approach that has the advantage of guaranteeing that solutions minimize the original cost function and preserve discontinuities. The constraints are based on minimizing the total number of horizontal and/or vertical discontinuities along and/or between adjacent epipolar lines, and local smoothing is avoided. Experiments reveal that minimizing the sum of the horizontal and vertical discontinuities provides the most accurate results. A high percentage of correct matches and very little smearing of depth discontinuities are obtained. An alternative to imposing cohesiveness constraints to reduce the correspondence ambiguities is to use more than two cameras. We therefore extend the two camera maximum likelihood toNcameras. TheN-camera stereo algorithm determines the \u201cbest\u201d set of correspondences between a given pair of cameras, referred to as the principal cameras. Knowledge of the relative positions of the cameras allows the 3D point hypothesized by an assumed correspondence of two features in the principal pair to be projected onto the image plane of the remainingN? 2 cameras. TheseN? 2 points are then used to verify proposed matches. Not only does the algorithm explicitly model occlusion between features of the principal pair, but the possibility of occlusions in theN? 2 additional views is also modeled. Previous work did not model this occlusion process, the benefits and importance of which are experimentally verified. Like other multiframe stereo algorithms, the computational and memory costs of this approach increase linearly with each additional view. Experimental results are shown for two outdoor scenes. It is clearly demonstrated that the number of correspondence errors is significantly reduced as the number of views/cameras is increased."
            },
            "slug": "A-Maximum-Likelihood-Stereo-Algorithm-Cox-Hingorani",
            "title": {
                "fragments": [],
                "text": "A Maximum Likelihood Stereo Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Several variants of the algorithm are developed that avoid classical regularization while imposing several global cohesiveness constraints, and this is a novel approach that has the advantage of guaranteeing that solutions minimize the original cost function and preserve discontinuities."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144901036"
                        ],
                        "name": "H. Nishihara",
                        "slug": "H.-Nishihara",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Nishihara",
                            "middleNames": [
                                "Keith"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nishihara"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 146
                            }
                        ],
                        "text": "Although some researchers have proposed measures of pixel dissimilarity that are insensitive to gain, bias, noise, and depth discontinuities [6], [9], [10], [11], [13], there seems to be no work on explicitly achieving insensitivity to image sampling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61608745,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "a6329de8f396c57592b51c51fcbdead7a714f1c4",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A binocular-stereo-matching algorithm for making rapid visual range measurements in noisy images is described. This technique is developed for application to problems in robotics where noise tolerance, reliability, and speed are predominant issues. A high speed pipelined convolver for preprocessing images and an unstructured light technique for improving signal quality are introduced to help enhance performance to meet the demands of this task domain. These optimizations, however, are not sufficient. A closer examination of the problems encountered suggests that broader interpretations of both the objective of binocular stereo and of the zero-crossing theory of Marr and Poggio [Proc. R. Soc. Lond. B 204, 301 (1979)] are required. In this paper, we restrict ourselves to the problem of making a single primitive surface measurement for example, to determine whether or not a specified volume of space is occupied, to measure the range to a surface at an indicated image location, or to determine the elevation gradient at that position. In this framework we make a subtle but important shift from the explicit use of zero-crossing contours (in bandpass-filtered images) as the elements matched between left and right images, to the use of the signs between zero crossings. With this change, we obtain a simpler algorithm with a reduced sensitivity to noise and a more predictable behavior. The practical real-time imaging stereo matcher (PRISM) system incorporates this algorithm with the unstructured light technique and a high speed digital convolver. It has been used successfully by others as a sensor in a path-planning system and a bin-picking system."
            },
            "slug": "Practical-Real-Time-Imaging-Stereo-Matcher-Nishihara",
            "title": {
                "fragments": [],
                "text": "Practical Real-Time Imaging Stereo Matcher"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A binocular-stereo-matching algorithm for making rapid visual range measurements in noisy images is described, and a subtle but important shift from the explicit use of zero-crossing contours as the elements matched between left and right images, to the use of the signs between zero crossings is made."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 177
                            }
                        ],
                        "text": "This dissimilarity measure could be effortlessly integrated into existing stereo algorithms that minimize an objective function that adds dissimilarities to occlusion penalties [1], [2], [5], [7], [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "For example, there has recently emerged a class of stereo algorithms [1], [2], [5], [7], [8] in which epipolar scanlines are matched by minimizing a cost function that sums the absolute or squared differences of pixel intensities with penalties for occlusions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "With the exception of [1] and [2], all of these algorithms work at pixel resolution, and therefore a measure of pixel dissimilarity that is insensitive to sampling would eliminate the errors that they experience due to sampling effects [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14472918,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "53e606d468feedc9d581434b4853904e79083333",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The author presents a method for reconstructing the three-dimensional scene geometry, i.e., depth, surface orientation, occluding contours, and surface creases, from a pair of stereo images. This reconstruction is not done as a postprocessing step, but rather all of the quantities are estimated simultaneously as part of the matching algorithm. An energy functional is considered in which each of the quantities in the scene geometry is explicitly represented. For this energy functional, a smoothness prior that, in addition to its ability to detect surface discontinuities and the accompanying half-occluded regions, is able to reconstruct steeply sloping surfaces with sharp creases is used. Experimental results demonstrating the effectiveness of the algorithm are presented.<<ETX>>"
            },
            "slug": "A-binocular-stereo-algorithm-for-reconstructing-and-Belhumeur",
            "title": {
                "fragments": [],
                "text": "A binocular stereo algorithm for reconstructing sloping, creased, and broken surfaces in the presence of half-occlusion"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A smoothness prior that, in addition to its ability to detect surface discontinuities and the accompanying half-occluded regions, is able to reconstruct steeply sloping surfaces with sharp creases is used."
            },
            "venue": {
                "fragments": [],
                "text": "1993 (4th) International Conference on Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50234310"
                        ],
                        "name": "P. Seitz",
                        "slug": "P.-Seitz",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Seitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Seitz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "Although some researchers have proposed measures of pixel dissimilarity that are insensitive to gain, bias, noise, and depth discontinuities [6], [9], [10], [11], [13], there seems to be no work on explicitly achieving insensitivity to image sampling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121068571,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a3cfe844042a6e28d39613e7b4cffd6454a6b1d",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Orientational information can replace the traditional edges as basic image features (\"primitives\") for object recognition. A comparison of five different orientation operators on 3 x 3 windows is carried out, and it is found that these operators have similar performance. A first attempt at object recognition searches for minimum root mean square deviation of orientation in a picture. This technique shows better object discrimination than the traditional normalized cross-correlation of grey-level images. Additionally the parameters of the Gaussian distribution of orientational correlation can be accurately predicted by a simple theoretical model. The orientational correlation technique shows difficulties in recognizing geometrically distorted and partially occluded objects. For this reason a very robust algorithm for the recognition of simple objects is developed, based only on orientationl information as image feature, and local polar coordinates for the model of the object. Practical examples taken under difficult, natural conditions illustrate the reliable performance of the proposed algorithm, and it becomes apparent that orientational information is indeed a powerful image primitive."
            },
            "slug": "Using-Local-Orientational-Information-As-Image-For-Seitz",
            "title": {
                "fragments": [],
                "text": "Using Local Orientational Information As Image Primitive For Robust Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A very robust algorithm for the recognition of simple objects is developed, based only on orientationl information as image feature, and local polar coordinates for the model of the object, and it becomes apparent that orientational information is indeed a powerful image primitive."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "Recall that a function is convex if no chord lies below the function and concave if no chord lies above it [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convexity. Oxford, England"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 10,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Pixel-Dissimilarity-Measure-That-Is-Insensitive-Birchfield-Tomasi/3ebbd75ab128c863e3b655efe104e1c47af13096?sort=total-citations"
}