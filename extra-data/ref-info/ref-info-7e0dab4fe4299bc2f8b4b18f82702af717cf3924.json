{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145016534"
                        ],
                        "name": "J. Moody",
                        "slug": "J.-Moody",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Moody",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Moody"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 42
                            }
                        ],
                        "text": "These e ects will be discussed further in Moody (1992). For models trained with squared error (SSE) and quadratic weight decay g(w ) = (w )2, the assumptions of unbiasedness9 or local linearizability lead to the following expression for peff ( ) which we call the linearized e ective number of parameters plin( ): plin( ) = p X =1 \u0014 + : (18) 9Strictly speaking, a model with quadratic weight decay is unbiased only if the \\true\" weights are 0."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60756461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d6d0053f5f32ef87b60435e04ea5e0d81fad4ec",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The author proposes a new estimate of generalization performance for nonlinear learning systems called the generalized prediction error (GPE) which is based upon the notion of the effective number of parameters p/sub eff/( lambda ). GPE does not require the use of a test set or computationally intensive cross validation and generalizes previously proposed model selection criteria (such as GCV, FPE, AIC, and PSE) in that it is formulated to include biased, nonlinear models (such as back propagation networks) which may incorporate weight decay or other regularizers. The effective number of parameters p/sub eff/( lambda ) depends upon the amount of bias and smoothness (as determined by the regularization parameter lambda ) in the model, but generally differs from the number of weights p. Construction of an optimal architecture thus requires not just finding the weights w/sub lambda /* which minimize the training function U( lambda , w) but also the lambda which minimizes GPE( lambda ).<<ETX>>"
            },
            "slug": "Note-on-generalization,-regularization-and-in-Moody",
            "title": {
                "fragments": [],
                "text": "Note on generalization, regularization and architecture selection in nonlinear learning systems"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The author proposes a new estimate of generalization performance for nonlinear learning systems called the generalized prediction error (GPE) which is based upon the notion of the effective number of parameters p/sub eff/( lambda )."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing Proceedings of the 1991 IEEE Workshop"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145016534"
                        ],
                        "name": "J. Moody",
                        "slug": "J.-Moody",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Moody",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Moody"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082896"
                        ],
                        "name": "J. Utans",
                        "slug": "J.-Utans",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Utans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Utans"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13173468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a6df9164153ca9b1e6529e5d769fa25e4d7a0bf",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The notion of generalization ability can be defined precisely as the prediction risk, the expected performance of an estimator in predicting new observations. In this paper, we propose the prediction risk as a measure of the generalization ability of multi-layer perceptron networks and use it to select an optimal network architecture from a set of possible architectures. We also propose a heuristic search strategy to explore the space of possible architectures. The prediction risk is estimated from the available data; here we estimate the prediction risk by v-fold cross-validation and by asymptotic approximations of generalized cross-validation or Akaike's final prediction error. We apply the technique to the problem of predicting corporate bond ratings. This problem is very attractive as a case study, since it is characterized by the limited availability of the data and by the lack of a complete a priori model which could be used to impose a structure to the network architecture."
            },
            "slug": "Principled-Architecture-Selection-for-Neural-to-Moody-Utans",
            "title": {
                "fragments": [],
                "text": "Principled Architecture Selection for Neural Networks: Application to Corporate Bond Rating Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The prediction risk is proposed as a measure of the generalization ability of multi-layer perceptron networks and used to select an optimal network architecture from a set of possible architectures and a heuristic search strategy is proposed to explore the space of possible architecture."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737945"
                        ],
                        "name": "H. Akaike",
                        "slug": "H.-Akaike",
                        "structuredName": {
                            "firstName": "Hirotugu",
                            "lastName": "Akaike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Akaike"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 411526,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "50a42ed2f81b9fe150883a6c89194c88a9647106",
            "isKey": false,
            "numCitedBy": 42034,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. The classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion (AIC) estimate (MAICE) which is designed for the purpose of statistical identification is introduced. When there are several competing models the MAICE is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of AIC defined by AIC = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). MAICE provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. The practical utility of MAICE in time series analysis is demonstrated with some numerical examples."
            },
            "slug": "A-new-look-at-the-statistical-model-identification-Akaike",
            "title": {
                "fragments": [],
                "text": "A new look at the statistical model identification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737945"
                        ],
                        "name": "H. Akaike",
                        "slug": "H.-Akaike",
                        "structuredName": {
                            "firstName": "Hirotugu",
                            "lastName": "Akaike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Akaike"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 64903870,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "400b45a803d642b752a84147ef547af7811e8f3f",
            "isKey": false,
            "numCitedBy": 19577,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper it is shown that the classical maximum likelihood principle can be considered to be a method of asymptotic realization of an optimum estimate with respect to a very general information theoretic criterion. This observation shows an extension of the principle to provide answers to many practical problems of statistical model fitting."
            },
            "slug": "Information-Theory-and-an-Extension-of-the-Maximum-Akaike",
            "title": {
                "fragments": [],
                "text": "Information Theory and an Extension of the Maximum Likelihood Principle"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "The classical maximum likelihood principle can be considered to be a method of asymptotic realization of an optimum estimate with respect to a very general information theoretic criterion to provide answers to many practical problems of statistical model fitting."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2547829"
                        ],
                        "name": "B. Yandell",
                        "slug": "B.-Yandell",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Yandell",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yandell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 122765020,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "56c810594ae2ec5d72f5f2cfd4799f75ff6f8fe2",
            "isKey": false,
            "numCitedBy": 456,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A wheeled toy vehicle including a drive assembly which comprises a monofilament line having one extremity connected to a manually operable control means and the opposite end connected to the running gear of the vehicle. The dimensions and configuration of the monofilament line is such as to transmit rotation of the line about its own longitudinal axis, caused by activation of the control means, directly to the running gear which may comprise a drive axle and/or one or more drive wheels. Connecting means may attach the one extremity of the line to a predetermined outer portion of an axle or wheel by means of forming a socket therein correspondingly shaped to at least partially enclose a finger attached to the extremity of the line means cooperating therewith. Alternately, a finger can be connected to the extremity of the drive axle and be disposed so as to be enclosed within a socket formed within a sleeve which is connected to the extremity of the line and comprises another embodiment of the connecting means."
            },
            "slug": "Spline-smoothing-and-nonparametric-regression-Yandell",
            "title": {
                "fragments": [],
                "text": "Spline smoothing and nonparametric regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737945"
                        ],
                        "name": "H. Akaike",
                        "slug": "H.-Akaike",
                        "structuredName": {
                            "firstName": "Hirotugu",
                            "lastName": "Akaike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Akaike"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 14
                            }
                        ],
                        "text": "These include Akaike's F P E (1970), Akaike's AlC (1973) Mallow's Cp (1973), and Barron's PSE (1984). (See also Akaike (1974) and Eubank (1988).) These estimates are all based on equation (13)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 14
                            }
                        ],
                        "text": "These include Akaike's F P E (1970), Akaike's AlC (1973) Mallow's Cp (1973), and Barron's PSE (1984). (See also Akaike (1974) and Eubank (1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 14
                            }
                        ],
                        "text": "These include Akaike's F P E (1970), Akaike's AlC (1973) Mallow's Cp (1973), and Barron's PSE (1984)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 10
                            }
                        ],
                        "text": "Following Akaike (1970), Barron (1984), and numerous other authors (see Eubank 1988), we can define the prediction risk P as the expected test set error for test sets of size n e'(n) = {c;i, = (xi,zi); i = 1, ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120510150,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "22cef227af3c3700693a053655ca82f01244167b",
            "isKey": true,
            "numCitedBy": 1170,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In a recent paper by the present author [1] a simple practical procedure of predictor identification has been proposed. It is the purpose of this paper to provide a theoretical and empirical basis of the procedure."
            },
            "slug": "Statistical-predictor-identification-Akaike",
            "title": {
                "fragments": [],
                "text": "Statistical Predictor Identification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "91622077"
                        ],
                        "name": "R. L. Dekock",
                        "slug": "R.-L.-Dekock",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Dekock",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. L. Dekock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 91510374,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "b0e0997c08de50a06cfe7a562dd2938d25a9fb26",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers found that a few seconds after a lobster is dropped in boiling water it will begin to twitch its tail. The tail movement, which continues for approximately one minute, is part of a reflex action found in lobsters and crayfish (but not crabs). Known as the \u201cescape response\u201d, it is a reflex action to any sudden stimulus \u2013 a reaction that was first identified by George Johnson in 1924. The lobster is reacting to an external factor, such as an elevated water temperature. Do lobsters feel pain?"
            },
            "slug": "Some-Comments-Dekock",
            "title": {
                "fragments": [],
                "text": "Some Comments"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 10
                            }
                        ],
                        "text": "Following Akaike (1970), Barron (1984), and numerous other authors (see Eubank 1988), we can de ne the prediction risk P as the expected test set error for test sets of size n 0(n) = f i0 = (xi; zi); i = 1; : : : ; ng having the empirical input density 0(x)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 344,
                                "start": 204
                            }
                        ],
                        "text": "In addition to the surprising result that peff( ) 6= p, we propose an estimate of (1) called the generalized prediction error (GPE) which generalizes well established estimates of prediction risk such as Akaike's FPE and AIC, Mallows CP , and Barron's PSE to the nonlinear setting.1 1GPE and peff ( ) were previously introduced in Moody (1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 402,
                                "start": 228
                            }
                        ],
                        "text": "4 The Expected Test Set Error for Linear Models The relationship between expected training set and expected test set errors for linear models trained using the SSE error function with no regularizer is well known in statistics (Akaike 1970, Barron 1984, Eubank 1988). The exact relation for test and training sets with density (9): hEtesti 0 = hEtraini + 2 2 p n : (13) As pointed out by Barron (1984), (13) can also apply approximately to the case of a nonlinear model f(w; x) trained by minimizing the sum of squared errors SSE."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical predictor identi cation"
            },
            "venue": {
                "fragments": [],
                "text": "Ann. Inst. Stat. Math., 22:203."
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1392575327"
                        ],
                        "name": "C. L. Mallows",
                        "slug": "C.-L.-Mallows",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Mallows",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Mallows"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125101704,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7106fcaa56b5434d933c6985db379788a723f5f0",
            "isKey": false,
            "numCitedBy": 1933,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Some-comments-on-C_p-Mallows",
            "title": {
                "fragments": [],
                "text": "Some comments on C_p"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737945"
                        ],
                        "name": "H. Akaike",
                        "slug": "H.-Akaike",
                        "structuredName": {
                            "firstName": "Hirotugu",
                            "lastName": "Akaike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Akaike"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 87841080,
            "fieldsOfStudy": [
                "Geography"
            ],
            "id": "290e05d21ee1cee068d1917e1dc2068af9d3b5b1",
            "isKey": false,
            "numCitedBy": 1238,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "INFORMATION-THEORY-AS-AN-EXTENSION-OF-THE-MAXIMUM-Akaike",
            "title": {
                "fragments": [],
                "text": "INFORMATION THEORY AS AN EXTENSION OF THE MAXIMUM LIKELIHOOD"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123402533"
                        ],
                        "name": "M. C. Jones",
                        "slug": "M.-C.-Jones",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Jones",
                            "middleNames": [
                                "Chris"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. C. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859519"
                        ],
                        "name": "R. Eubank",
                        "slug": "R.-Eubank",
                        "structuredName": {
                            "firstName": "Randy",
                            "lastName": "Eubank",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Eubank"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124078690,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "616989e3eeb160c42ecb10eba0e62a495c7d01b9",
            "isKey": false,
            "numCitedBy": 1081,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Spline-Smoothing-and-Nonparametric-Regression.-Jones-Eubank",
            "title": {
                "fragments": [],
                "text": "Spline Smoothing and Nonparametric Regression."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Long version of this paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical predictor identiication"
            },
            "venue": {
                "fragments": [],
                "text": "Ann. Inst. Stat. Math"
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Long version of this paper, in preparation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 23
                            }
                        ],
                        "text": "x will be discussed in Moody (1992). 7 Other error functions, such as those used in generalized linear models (see for example McCullagh and NeIder 1983) or robust statistics (see for example Huber 1981) are more appropriate than the squared error if the noise is known to be non-gaussian or the data contains many outliers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust Statistics. Wiley, New York"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "methodology": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/The-Effective-Number-of-Parameters:-An-Analysis-of-Moody/7e0dab4fe4299bc2f8b4b18f82702af717cf3924?sort=total-citations"
}