{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734693"
                        ],
                        "name": "John C. Duchi",
                        "slug": "John-C.-Duchi",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Duchi",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Duchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5513850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7c8beb0291c5fca39dde887266251cdbd18ad11",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe, analyze, and experiment with a framework for empirical loss minimization with regularization. Our algorithmic framework alternates between two phases. On each iteration we first perform an unconstrained gradient descent step. We then cast and solve an instantaneous optimization problem that trades off minimization of a regularization term while keeping close proximity to the result of the first phase. This view yields a simple yet effective algorithm that can be used for batch penalized risk minimization and online learning. Furthermore, the two phase approach enables sparse solutions when used in conjunction with regularization functions that promote sparsity, such as l1. We derive concrete and very simple algorithms for minimization of loss functions with l1, l2, l22, and l\u221e regularization. We also show how to construct efficient algorithms for mixed-norm l1/lq regularization. We further extend the algorithms and give efficient implementations for very high-dimensional data with sparsity. We demonstrate the potential of the proposed framework in a series of experiments with synthetic and natural data sets."
            },
            "slug": "Efficient-Online-and-Batch-Learning-Using-Forward-Duchi-Singer",
            "title": {
                "fragments": [],
                "text": "Efficient Online and Batch Learning Using Forward Backward Splitting"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The two phase approach enables sparse solutions when used in conjunction with regularization functions that promote sparsity, such as l1, l2, l22, and l\u221e regularization, and is extended and given efficient implementations for very high-dimensional data with sparsity."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145942106"
                        ],
                        "name": "Lin Xiao",
                        "slug": "Lin-Xiao",
                        "structuredName": {
                            "firstName": "Lin",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lin Xiao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2166128,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a0a3eac29839894ea07cc3b1c2a3b2a0c63c3f7",
            "isKey": false,
            "numCitedBy": 763,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider regularized stochastic learning and online optimization problems, where the objective function is the sum of two convex terms: one is the loss function of the learning task, and the other is a simple regularization term such as l1-norm for promoting sparsity. We develop a new online algorithm, the regularized dual averaging (RDA) method, that can explicitly exploit the regularization structure in an online setting. In particular, at each iteration, the learning variables are adjusted by solving a simple optimization problem that involves the running average of all past subgradients of the loss functions and the whole regularization term, not just its subgradient. Computational experiments show that the RDA method can be very effective for sparse online learning with l1-regularization."
            },
            "slug": "Dual-Averaging-Methods-for-Regularized-Stochastic-Xiao",
            "title": {
                "fragments": [],
                "text": "Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new online algorithm is developed, the regularized dual averaging (RDA) method, that can explicitly exploit the regularization structure in an online setting and can be very effective for sparse online learning with l1-regularization."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145057514"
                        ],
                        "name": "H. B. McMahan",
                        "slug": "H.-B.-McMahan",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "McMahan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B. McMahan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7977819"
                        ],
                        "name": "M. Streeter",
                        "slug": "M.-Streeter",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Streeter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Streeter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13318811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "172a5ffc5a9b5b64c781d85dddc605c8b96b8abd",
            "isKey": false,
            "numCitedBy": 268,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new online convex optimization algorithm that adaptively chooses its regularization function based on the loss functions observed so far. This is in contrast to previous algorithms that use a fixed regularization function such as L2-squared, and modify it only via a single time-dependent parameter. Our algorithm\u2019s regret bounds are worst-case optimal, and for certain realistic classes of loss functions they are much better than existing bounds. These bounds are problem-dependent, which means they can exploit the structure of the actual problem instance. Critically, however, our algorithm does not need to know this structure in advance. Rather, we prove competitive guarantees that show the algorithm provides a bound within a constant factor of the best possible bound (of a certain functional form) in hindsight."
            },
            "slug": "Adaptive-Bound-Optimization-for-Online-Convex-McMahan-Streeter",
            "title": {
                "fragments": [],
                "text": "Adaptive Bound Optimization for Online Convex Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This work introduces a new online convex optimization algorithm that adaptively chooses its regularization function based on the loss functions observed so far, and proves competitive guarantees that show the algorithm provides a bound within a constant factor of the best possible bound in hindsight in hindsight."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34840427"
                        ],
                        "name": "Elad Hazan",
                        "slug": "Elad-Hazan",
                        "structuredName": {
                            "firstName": "Elad",
                            "lastName": "Hazan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elad Hazan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680046"
                        ],
                        "name": "A. Rakhlin",
                        "slug": "A.-Rakhlin",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Rakhlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rakhlin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 139
                            }
                        ],
                        "text": "In the online learning literature, there are results on adaptively choosing a learning rate\u03b7t based on data seen so far (Auer et al., 2002; Bartlett et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 121
                            }
                        ],
                        "text": "In the online learning literature, there are results on adaptively choosing a learning rate \u03b7t based on data seen so far (Auer et al., 2002; Bartlett et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15263248,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc263b22622558bf173ac6acbf697137667e5b53",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the rates of growth of the regret in online convex optimization. First, we show that a simple extension of the algorithm of Hazan et al eliminates the need for a priori knowledge of the lower bound on the second derivatives of the observed functions. We then provide an algorithm, Adaptive Online Gradient Descent, which interpolates between the results of Zinkevich for linear functions and of Hazan et al for strongly convex functions, achieving intermediate rates between \u221aT and log T. Furthermore, we show strong optimality of the algorithm. Finally, we provide an extension of our results to general norms."
            },
            "slug": "Adaptive-Online-Gradient-Descent-Bartlett-Hazan",
            "title": {
                "fragments": [],
                "text": "Adaptive Online Gradient Descent"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An algorithm is provided, Adaptive Online Gradient Descent, which interpolates between the results of Zinkevich for linear functions and of Hazan et al for strongly convex functions, achieving intermediate rates between \u221aT and log T and shows strong optimality of the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734693"
                        ],
                        "name": "John C. Duchi",
                        "slug": "John-C.-Duchi",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Duchi",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Duchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389955537"
                        ],
                        "name": "S. Shalev-Shwartz",
                        "slug": "S.-Shalev-Shwartz",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Shalev-Shwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shalev-Shwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073806959"
                        ],
                        "name": "Tushar Chandra",
                        "slug": "Tushar-Chandra",
                        "structuredName": {
                            "firstName": "Tushar",
                            "lastName": "Chandra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tushar Chandra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1226433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed7c7c079c8c54d3b82e016cc52a7a2c3a61f237",
            "isKey": false,
            "numCitedBy": 1244,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe efficient algorithms for projecting a vector onto the l1-ball. We present two methods for projection. The first performs exact projection in O(n) expected time, where n is the dimension of the space. The second works on vectors k of whose elements are perturbed outside the l1-ball, projecting in O(k log(n)) time. This setting is especially useful for online learning in sparse feature spaces such as text categorization applications. We demonstrate the merits and effectiveness of our algorithms in numerous batch and online learning tasks. We show that variants of stochastic gradient projection methods augmented with our efficient projection procedures outperform interior point methods, which are considered state-of-the-art optimization techniques. We also show that in online settings gradient updates with l1 projections outperform the exponentiated gradient algorithm while obtaining models with high degrees of sparsity."
            },
            "slug": "Efficient-projections-onto-the-l1-ball-for-learning-Duchi-Shalev-Shwartz",
            "title": {
                "fragments": [],
                "text": "Efficient projections onto the l1-ball for learning in high dimensions"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Efficient algorithms for projecting a vector onto the l1-ball are described and variants of stochastic gradient projection methods augmented with these efficient projection procedures outperform interior point methods, which are considered state-of-the-art optimization techniques."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144543541"
                        ],
                        "name": "P. Auer",
                        "slug": "P.-Auer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Auer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895207"
                        ],
                        "name": "C. Gentile",
                        "slug": "C.-Gentile",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Gentile",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gentile"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10645501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01343ae0bdb136c469dc6041a096be9d8371093b",
            "isKey": false,
            "numCitedBy": 229,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "Most of the performance bounds for on-line learning algorithms are proven assuming a constant learning rate. To optimize these bounds, the learning rate must be tuned based on quantities that are generally unknown, as they depend on the whole sequence of examples. In this paper we show that essentially the same optimized bounds can be obtained when the algorithms adaptively tune their learning rates as the examples in the sequence are progressively revealed. Our adaptive learning rates apply to a wide class of on-line algorithms, including p-norm algorithms for generalized linear regression and Weighted Majority for linear regression with absolute loss. We emphasize that our adaptive tunings are radically different from previous techniques, such as the so-called doubling trick. Whereas the doubling trick restarts the on-line algorithm several times using a constant learning rate for each run, our methods save information by changing the value of the learning rate very smoothly. In fact, for Weighted Majority over a finite set of experts our analysis provides a better leading constant than the doubling trick."
            },
            "slug": "Adaptive-and-Self-Confident-On-Line-Learning-Auer-Cesa-Bianchi",
            "title": {
                "fragments": [],
                "text": "Adaptive and Self-Confident On-Line Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper shows that essentially the same optimized bounds can be obtained when the algorithms adaptively tune their learning rates as the examples in the sequence are progressively revealed, as they depend on the whole sequence of examples."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40204991"
                        ],
                        "name": "A. Beck",
                        "slug": "A.-Beck",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Beck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Beck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727609"
                        ],
                        "name": "M. Teboulle",
                        "slug": "M.-Teboulle",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Teboulle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Teboulle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7036108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f0df7ed89d9a5bb5bafa5727ccdc0b6e2fb463d",
            "isKey": false,
            "numCitedBy": 925,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mirror-descent-and-nonlinear-projected-subgradient-Beck-Teboulle",
            "title": {
                "fragments": [],
                "text": "Mirror descent and nonlinear projected subgradient methods for convex optimization"
            },
            "venue": {
                "fragments": [],
                "text": "Oper. Res. Lett."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143676697"
                        ],
                        "name": "Y. Nesterov",
                        "slug": "Y.-Nesterov",
                        "structuredName": {
                            "firstName": "Yurii",
                            "lastName": "Nesterov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nesterov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 55
                            }
                        ],
                        "text": "The first is Nesterov\u2019s primal-dual subgradient method (Nesterov, 2009), and in particular Xiao\u2019s 2009 extension, regularized dual averaging (RDA) (Xiao, 2009), and the follow-the-regularized-leader (FTRL) family of algorithms (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 79
                            }
                        ],
                        "text": "Examining several well-known optimization bounds (e.g.Beck and Teboulle, 2003; Nesterov, 2009; Duchi et al., 2010b), we see that we can bound the regret as\nR\u03c6(T ) \u2264 1\n\u03b7 B\u03c8(x\n\u2217, x1) + \u03b7\n2\nT \u2211\nt=1\n\u2016f \u2032t(xt)\u2016 2 \u2217 ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 49
                            }
                        ],
                        "text": "Examining several well-known optimization bounds (e.g. Beck and Teboulle, 2003; Nesterov, 2009; Duchi et al., 2010b), we see that we can bound the regret as R\u03c6(T ) \u2264 1 \u03b7 B\u03c8(x \u2217, x1) + \u03b7 2 T \u2211"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 55
                            }
                        ],
                        "text": "The first is Nesterov\u2019s primal-dual subgradient method (Nesterov, 2009), and in particularXiao\u2019s 2009extension, regularized dual averaging (RDA) (Xiao, 2009), and the follow-the-regularized-leader (FTRL) family ofalgorithms (e.g. Kalai and Vempala, 2003; Hazan et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14935076,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "73f583aad5195324ee75eb981b8b5f1fed6f9d38",
            "isKey": true,
            "numCitedBy": 796,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new approach for constructing subgradient schemes for different types of nonsmooth problems with convex structure. Our methods are primal-dual since they are always able to generate a feasible approximation to the optimum of an appropriately formulated dual problem. Besides other advantages, this useful feature provides the methods with a reliable stopping criterion. The proposed schemes differ from the classical approaches (divergent series methods, mirror descent methods) by presence of two control sequences. The first sequence is responsible for aggregating the support functions in the dual space, and the second one establishes a dynamically updated scale between the primal and dual spaces. This additional flexibility allows to guarantee a boundedness of the sequence of primal test points even in the case of unbounded feasible set (however, we always assume the uniform boundedness of subgradients). We present the variants of subgradient schemes for nonsmooth convex minimization, minimax problems, saddle point problems, variational inequalities, and stochastic optimization. In all situations our methods are proved to be optimal from the view point of worst-case black-box lower complexity bounds."
            },
            "slug": "Primal-dual-subgradient-methods-for-convex-problems-Nesterov",
            "title": {
                "fragments": [],
                "text": "Primal-dual subgradient methods for convex problems"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A new approach for constructing subgradient schemes for different types of nonsmooth problems with convex structure that is primal-dual since they are always able to generate a feasible approximation to the optimum of an appropriately formulated dual problem."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34840427"
                        ],
                        "name": "Elad Hazan",
                        "slug": "Elad-Hazan",
                        "structuredName": {
                            "firstName": "Elad",
                            "lastName": "Hazan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elad Hazan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2078528382"
                        ],
                        "name": "A. Agarwal",
                        "slug": "A.-Agarwal",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144055676"
                        ],
                        "name": "Satyen Kale",
                        "slug": "Satyen-Kale",
                        "structuredName": {
                            "firstName": "Satyen",
                            "lastName": "Kale",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Satyen Kale"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11569359,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c883f38d202548c1d89ef5de8892d53227842092",
            "isKey": false,
            "numCitedBy": 938,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nIn an online convex optimization problem a decision-maker makes a sequence of decisions, i.e., chooses a sequence of points in Euclidean space, from a fixed feasible set. After each point is chosen, it encounters a sequence of (possibly unrelated) convex cost functions. Zinkevich (ICML 2003) introduced this framework, which models many natural repeated decision-making problems and generalizes many existing problems such as Prediction from Expert Advice and Cover\u2019s Universal Portfolios. Zinkevich showed that a simple online gradient descent algorithm achieves additive regret$O(\\sqrt{T})$\n, for an arbitrary sequence of T convex cost functions (of bounded gradients), with respect to the best single decision in hindsight.\n\nIn this paper, we give algorithms that achieve regret O(log\u2009(T)) for an arbitrary sequence of strictly convex functions (with bounded first and second derivatives). This mirrors what has been done for the special cases of prediction from expert advice by Kivinen and Warmuth (EuroCOLT 1999), and Universal Portfolios by Cover (Math. Finance 1:1\u201319, 1991). We propose several algorithms achieving logarithmic regret, which besides being more general are also much more efficient to implement.\n\nThe main new ideas give rise to an efficient algorithm based on the Newton method for optimization, a new tool in the field. Our analysis shows a surprising connection between the natural follow-the-leader approach and the Newton method. We also analyze other algorithms, which tie together several different previous approaches including follow-the-leader, exponential weighting, Cover\u2019s algorithm and gradient descent.\n"
            },
            "slug": "Logarithmic-regret-algorithms-for-online-convex-Hazan-Agarwal",
            "title": {
                "fragments": [],
                "text": "Logarithmic regret algorithms for online convex optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Several algorithms achieving logarithmic regret are proposed, which besides being more general are also much more efficient to implement, and give rise to an efficient algorithm based on the Newton method for optimization, a new tool in the field."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145853268"
                        ],
                        "name": "A. Nemirovski",
                        "slug": "A.-Nemirovski",
                        "structuredName": {
                            "firstName": "Arkadi",
                            "lastName": "Nemirovski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nemirovski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754887"
                        ],
                        "name": "A. Juditsky",
                        "slug": "A.-Juditsky",
                        "structuredName": {
                            "firstName": "Anatoli",
                            "lastName": "Juditsky",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Juditsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070945"
                        ],
                        "name": "Guanghui Lan",
                        "slug": "Guanghui-Lan",
                        "structuredName": {
                            "firstName": "Guanghui",
                            "lastName": "Lan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guanghui Lan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31474779"
                        ],
                        "name": "A. Shapiro",
                        "slug": "A.-Shapiro",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Shapiro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shapiro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The first is Nesterov\u2019s primal-dual subgradient method (2009), and in particular Xiao\u2019s 2010 extension, regularized dual averaging, and the follow-the-regularized-leader (FTRL) family of algorithms (see for instance Kalai and Vempala, 2003; Hazan et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent work by several authors (Nemirovski et al., 2009; Juditsky et al., 2008; Lan, 2010; Xiao, 2010) considered efficient and robust methods for stochastic optimization, especially in the case when the expected objective f is smooth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1767867,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "96167ed3ebc9a2c3270f6ae96043e6f086eed4de",
            "isKey": false,
            "numCitedBy": 1843,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we consider optimization problems where the objective function is given in a form of the expectation. A basic difficulty of solving such stochastic optimization problems is that the involved multidimensional integrals (expectations) cannot be computed with high accuracy. The aim of this paper is to compare two computational approaches based on Monte Carlo sampling techniques, namely, the stochastic approximation (SA) and the sample average approximation (SAA) methods. Both approaches, the SA and SAA methods, have a long history. Current opinion is that the SAA method can efficiently use a specific (say, linear) structure of the considered problem, while the SA approach is a crude subgradient method, which often performs poorly in practice. We intend to demonstrate that a properly modified SA approach can be competitive and even significantly outperform the SAA method for a certain class of convex stochastic problems. We extend the analysis to the case of convex-concave stochastic saddle point problems and present (in our opinion highly encouraging) results of numerical experiments."
            },
            "slug": "Robust-Stochastic-Approximation-Approach-to-Nemirovski-Juditsky",
            "title": {
                "fragments": [],
                "text": "Robust Stochastic Approximation Approach to Stochastic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is intended to demonstrate that a properly modified SA approach can be competitive and even significantly outperform the SAA method for a certain class of convex stochastic problems."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Optim."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2445783"
                        ],
                        "name": "A. Conconi",
                        "slug": "A.-Conconi",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Conconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Conconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895207"
                        ],
                        "name": "C. Gentile",
                        "slug": "C.-Gentile",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Gentile",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gentile"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 437093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78396e535101308d4431c08f0e85b18c920ee44f",
            "isKey": false,
            "numCitedBy": 522,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, it is shown how to extract a hypothesis with small risk from the ensemble of hypotheses generated by an arbitrary on-line learning algorithm run on an independent and identically distributed (i.i.d.) sample of data. Using a simple large deviation argument, we prove tight data-dependent bounds for the risk of this hypothesis in terms of an easily computable statistic M/sub n/ associated with the on-line performance of the ensemble. Via sharp pointwise bounds on M/sub n/, we then obtain risk tail bounds for kernel perceptron algorithms in terms of the spectrum of the empirical kernel matrix. These bounds reveal that the linear hypotheses found via our approach achieve optimal tradeoffs between hinge loss and margin size over the class of all linear functions, an issue that was left open by previous results. A distinctive feature of our approach is that the key tools for our analysis come from the model of prediction of individual sequences; i.e., a model making no probabilistic assumptions on the source generating the data. In fact, these tools turn out to be so powerful that we only need very elementary statistical facts to obtain our final risk bounds."
            },
            "slug": "On-the-generalization-ability-of-on-line-learning-Cesa-Bianchi-Conconi",
            "title": {
                "fragments": [],
                "text": "On the generalization ability of on-line learning algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proves tight data-dependent bounds for the risk of this hypothesis in terms of an easily computable statistic M/sub n/ associated with the on-line performance of the ensemble, and obtains risk tail bounds for kernel perceptron algorithms interms of the spectrum of the empirical kernel matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070945"
                        ],
                        "name": "Guanghui Lan",
                        "slug": "Guanghui-Lan",
                        "structuredName": {
                            "firstName": "Guanghui",
                            "lastName": "Lan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guanghui Lan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15039054,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1621f05894ad5fd6a8fcb8827a8c7aca36c81775",
            "isKey": false,
            "numCitedBy": 403,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers an important class of convex programming (CP) problems, namely, the stochastic composite optimization (SCO), whose objective function is given by the summation of general nonsmooth and smooth stochastic components. Since SCO covers non-smooth, smooth and stochastic CP as certain special cases, a valid lower bound on the rate of convergence for solving these problems is known from the classic complexity theory of convex programming. Note however that the optimization algorithms that can achieve this lower bound had never been developed. In this paper, we show that the simple mirror-descent stochastic approximation method exhibits the best-known rate of convergence for solving these problems. Our major contribution is to introduce the accelerated stochastic approximation (AC-SA) algorithm based on Nesterov\u2019s optimal method for smooth CP (Nesterov in Doklady AN SSSR 269:543\u2013547, 1983; Nesterov in Math Program 103:127\u2013152, 2005), and show that the AC-SA algorithm can achieve the aforementioned lower bound on the rate of convergence for SCO. To the best of our knowledge, it is also the first universally optimal algorithm in the literature for solving non-smooth, smooth and stochastic CP problems. We illustrate the significant advantages of the AC-SA algorithm over existing methods in the context of solving a special but broad class of stochastic programming problems."
            },
            "slug": "An-optimal-method-for-stochastic-composite-Lan",
            "title": {
                "fragments": [],
                "text": "An optimal method for stochastic composite optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The accelerated stochastic approximation (AC-SA) algorithm based on Nesterov\u2019s optimal method for smooth CP is introduced, and it is shown that the AC-SA algorithm can achieve the aforementioned lower bound on the rate of convergence for SCO."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737063"
                        ],
                        "name": "I. Daubechies",
                        "slug": "I.-Daubechies",
                        "structuredName": {
                            "firstName": "Ingrid",
                            "lastName": "Daubechies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Daubechies"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2722238"
                        ],
                        "name": "M. Fornasier",
                        "slug": "M.-Fornasier",
                        "structuredName": {
                            "firstName": "Massimo",
                            "lastName": "Fornasier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fornasier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3257757"
                        ],
                        "name": "I. Loris",
                        "slug": "I.-Loris",
                        "structuredName": {
                            "firstName": "Ignace",
                            "lastName": "Loris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Loris"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "3 l1-ball Projections We next consider the setting in which \u03c6 \u2261 0 and X = {x : \u2016x\u20161 \u2264 c}, which has been the topic of recent research (Duchi et al., 2008; Daubechies et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6794273,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "819e00b3cd6eaa1fcb16157ac0e2cf6ce81f28e3",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Regularization of ill-posed linear inverse problems via \u21131 penalization has been proposed for cases where the solution is known to be (almost) sparse. One way to obtain the minimizer of such an \u21131 penalized functional is via an iterative soft-thresholding algorithm. We propose an alternative implementation to \u21131-constraints, using a gradient method, with projection on \u21131-balls. The corresponding algorithm uses again iterative soft-thresholding, now with a variable thresholding parameter. We also propose accelerated versions of this iterative method, using ingredients of the (linear) steepest descent method. We prove convergence in norm for one of these projected gradient methods, without and with acceleration."
            },
            "slug": "Accelerated-Projected-Gradient-Method-for-Linear-Daubechies-Fornasier",
            "title": {
                "fragments": [],
                "text": "Accelerated Projected Gradient Method for Linear Inverse Problems with Sparsity Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes an alternative implementation to \u21131-constraints, using a gradient method, with projection on \u21221-balls, and proves convergence in norm for one of these projected gradient methods, without and with acceleration."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8195063"
                        ],
                        "name": "Martin A. Zinkevich",
                        "slug": "Martin-A.-Zinkevich",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Zinkevich",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Zinkevich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 553962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1f153c6df86d1ca8ecb9561daddfe7a54f901e7",
            "isKey": false,
            "numCitedBy": 1942,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Convex programming involves a convex set F \u2286 Rn and a convex cost function c : F \u2192 R. The goal of convex programming is to find a point in F which minimizes c. In online convex programming, the convex set is known in advance, but in each step of some repeated optimization problem, one must select a point in F before seeing the cost function for that step. This can be used to model factory production, farm production, and many other industrial optimization problems where one is unaware of the value of the items produced until they have already been constructed. We introduce an algorithm for this domain. We also apply this algorithm to repeated games, and show that it is really a generalization of infinitesimal gradient ascent, and the results here imply that generalized infinitesimal gradient ascent (GIGA) is universally consistent."
            },
            "slug": "Online-Convex-Programming-and-Generalized-Gradient-Zinkevich",
            "title": {
                "fragments": [],
                "text": "Online Convex Programming and Generalized Infinitesimal Gradient Ascent"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm for convex programming is introduced, and it is shown that it is really a generalization of infinitesimal gradient ascent, and the results here imply that generalized inf initesimalgradient ascent (GIGA) is universally consistent."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1665859045"
                        ],
                        "name": "DuchiJohn",
                        "slug": "DuchiJohn",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "DuchiJohn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "DuchiJohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644104661"
                        ],
                        "name": "HazanElad",
                        "slug": "HazanElad",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "HazanElad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HazanElad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644339920"
                        ],
                        "name": "SingerYoram",
                        "slug": "SingerYoram",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "SingerYoram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "SingerYoram"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 104
                            }
                        ],
                        "text": "For completeness, we provide the proofs of following two corollaries in the long version of this paper (Duchi et al., 2010a), though they build straightforwardly onDuchi et al.(2010b) andXiao (2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 63
                            }
                        ],
                        "text": "These results are available in the long version of this paper (Duchi et al., 2010a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 84
                            }
                        ],
                        "text": "The lemmas are quite technical, so we prove them in the long version of this paper (Duchi et al., 2010a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 95
                            }
                        ],
                        "text": "Examining several well-known optimization bounds (e.g.Beck and Teboulle, 2003; Nesterov, 2009; Duchi et al., 2010b), we see that we can bound the regret as\nR\u03c6(T ) \u2264 1\n\u03b7 B\u03c8(x\n\u2217, x1) + \u03b7\n2\nT \u2211\nt=1\n\u2016f \u2032t(xt)\u2016 2 \u2217 ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 72
                            }
                        ],
                        "text": "We provide an elaborated explanation in the full version of this paper (Duchi et al., 2010a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 159
                            }
                        ],
                        "text": "The second method also has many names, such asproximal gradient, forwardbackward splitting, and composite mirror descent (Tseng, 2008; Duchi and Singer, 2009; Duchi et al., 2010b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 211
                            }
                        ],
                        "text": "Rather than give the proof of the lower regret, we simply state the result, as it is not difficult to prove using techniques of Hazan et al.(2006), though we include the proof in the full version of this paper (Duchi et al., 2010a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 227346054,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8fef54db5c6b62757371920816d69240a0bb669d",
            "isKey": true,
            "numCitedBy": 48,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning...."
            },
            "slug": "Adaptive-Subgradient-Methods-for-Online-Learning-DuchiJohn-HazanElad",
            "title": {
                "fragments": [],
                "text": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2738621"
                        ],
                        "name": "J. Abernethy",
                        "slug": "J.-Abernethy",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Abernethy",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Abernethy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34840427"
                        ],
                        "name": "Elad Hazan",
                        "slug": "Elad-Hazan",
                        "structuredName": {
                            "firstName": "Elad",
                            "lastName": "Hazan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elad Hazan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680046"
                        ],
                        "name": "A. Rakhlin",
                        "slug": "A.-Rakhlin",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Rakhlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rakhlin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Thus, the adaptation facilitates identification and adaptation of highly predictive but comparatively rare features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8547150,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7aa0a143d8f2d89e8b71ead58a8f768716abbf81",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce an efficient algorithm for the problem of online linear optimization in the bandit setting which achieves the optimal O\u2217( \u221a T ) regret. The setting is a natural generalization of the nonstochastic multi-armed bandit problem, and the existence of an efficient optimal algorithm has been posed as an open problem in a number of recent papers. We show how the difficulties encountered by previous approaches are overcome by the use of a self-concordant potential function. Our approach presents a novel connection between online learning and interior point methods."
            },
            "slug": "Competing-in-the-Dark:-An-Efficient-Algorithm-for-Abernethy-Hazan",
            "title": {
                "fragments": [],
                "text": "Competing in the Dark: An Efficient Algorithm for Bandit Linear Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This work introduces an efficient algorithm for the problem of online linear optimization in the bandit setting which achieves the optimal O\u2217( \u221a T ) regret and presents a novel connection between online learning and interior point methods."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734693"
                        ],
                        "name": "John C. Duchi",
                        "slug": "John-C.-Duchi",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Duchi",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Duchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389955537"
                        ],
                        "name": "S. Shalev-Shwartz",
                        "slug": "S.-Shalev-Shwartz",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Shalev-Shwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shalev-Shwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3064914"
                        ],
                        "name": "Ambuj Tewari",
                        "slug": "Ambuj-Tewari",
                        "structuredName": {
                            "firstName": "Ambuj",
                            "lastName": "Tewari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ambuj Tewari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59902373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1afc2e08ea853a9f26690d0fe3851105fa4e1ea1",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for regularized convex optimization and analyze it under both online and stochastic optimization settings. In addition to unifying previously known firstorder algorithms, such as the projected gradient method, mirror descent, and forwardbackward splitting, our method yields new analysis and algorithms. We also derive specific instantiations of our method for commonly used regularization functions, such as l1, mixed norm, and trace-norm."
            },
            "slug": "Composite-Objective-Mirror-Descent-Duchi-Shalev-Shwartz",
            "title": {
                "fragments": [],
                "text": "Composite Objective Mirror Descent"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This work presents a new method for regularized convex optimization that unifies previously known firstorder algorithms, such as the projected gradient method, mirror descent, and forwardbackward splitting, and derives specific instantiations of this method for commonly used regularization functions,such as l1, mixed norm, and trace-norm."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389955537"
                        ],
                        "name": "S. Shalev-Shwartz",
                        "slug": "S.-Shalev-Shwartz",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Shalev-Shwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shalev-Shwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 178
                            }
                        ],
                        "text": "It is now well established that strong convexity of the functionsft can give significant improvements in the regret of online convex optimization algorithms (Hazan et al., 2006; Shalev-Shwartz and Singer, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 210
                            }
                        ],
                        "text": "5 Lowering the Regret for Strongly Convex Functions It is now well established that strong convexity of the functions ft can give significant improvements in the regret of online convex optimization algorithms (Hazan et al., 2006; Shalev-Shwartz and Singer, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10661811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e9dd1c197cbc73434f12e9d62d10ed2a79190d7",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Many problems arising in machine learning can be cast as a convex optimization problem, in which a sum of a loss term and a regularization term is minimized. For example, in Support Vector Machines the loss term is the average hinge-loss of a vector over a training set of examples and the regularization term is the squared Euclidean norm of this vector. In this paper we study an algorithmic framework for strongly convex repeated games and apply it for solving regularized loss minimization problems. In a convex repeated game, a predictor chooses a sequence of vectors from a convex set. After each vector is chosen, the opponent responds with a convex loss function and the predictor pays for applying the loss function to the vector she chose. The regret of the predictor is the difference between her cumulative loss and the minimal cumulative loss achievable by a fixed vector, even one that is chosen in hindsight. In strongly convex repeated games, the opponent is forced to choose loss functions that are strongly convex. We describe a family of prediction algorithms for strongly convex repeated games that attain logarithmic regret."
            },
            "slug": "Logarithmic-Regret-Algorithms-for-Strongly-Convex-Shalev-Shwartz-Singer",
            "title": {
                "fragments": [],
                "text": "Logarithmic Regret Algorithms for Strongly Convex Repeated Games"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper describes a family of prediction algorithms for strongly convex repeated games that attain logarithmic regret and applies it for solving regularized loss minimization problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143676697"
                        ],
                        "name": "Y. Nesterov",
                        "slug": "Y.-Nesterov",
                        "structuredName": {
                            "firstName": "Yurii",
                            "lastName": "Nesterov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nesterov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "N We now proceed in the same fashion as Xiao (2009) and Nesterov (2009), defining duality gap variables \u03b4t , sup x\u2208X { t \u2211"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The proof of the corollary essentially builds upon Xiao (2009) and Nesterov (2009), with a slight modification to deal with the indexing of \u03c8t."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In order to proceed, we use the following lemma, which is also used by Nesterov (2009) and Xiao (2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62288331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0b0c3e5a1e768490bc9b759685930541957508b",
            "isKey": true,
            "numCitedBy": 4857,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "It was in the middle of the 1980s, when the seminal paper by Kar markar opened a new epoch in nonlinear optimization. The importance of this paper, containing a new polynomial-time algorithm for linear op timization problems, was not only in its complexity bound. At that time, the most surprising feature of this algorithm was that the theoretical pre diction of its high efficiency was supported by excellent computational results. This unusual fact dramatically changed the style and direc tions of the research in nonlinear optimization. Thereafter it became more and more common that the new methods were provided with a complexity analysis, which was considered a better justification of their efficiency than computational experiments. In a new rapidly develop ing field, which got the name \"polynomial-time interior-point methods\", such a justification was obligatory. Afteralmost fifteen years of intensive research, the main results of this development started to appear in monographs [12, 14, 16, 17, 18, 19]. Approximately at that time the author was asked to prepare a new course on nonlinear optimization for graduate students. The idea was to create a course which would reflect the new developments in the field. Actually, this was a major challenge. At the time only the theory of interior-point methods for linear optimization was polished enough to be explained to students. The general theory of self-concordant functions had appeared in print only once in the form of research monograph [12]."
            },
            "slug": "Introductory-Lectures-on-Convex-Optimization-A-Nesterov",
            "title": {
                "fragments": [],
                "text": "Introductory Lectures on Convex Optimization - A Basic Course"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "It was in the middle of the 1980s, when the seminal paper by Kar markar opened a new epoch in nonlinear optimization, and it became more and more common that the new methods were provided with a complexity analysis, which was considered a better justification of their efficiency than computational experiments."
            },
            "venue": {
                "fragments": [],
                "text": "Applied Optimization"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754887"
                        ],
                        "name": "A. Juditsky",
                        "slug": "A.-Juditsky",
                        "structuredName": {
                            "firstName": "Anatoli",
                            "lastName": "Juditsky",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Juditsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145849792"
                        ],
                        "name": "A. Nemirovskii",
                        "slug": "A.-Nemirovskii",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Nemirovskii",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nemirovskii"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90240126"
                        ],
                        "name": "Claire Tauvel",
                        "slug": "Claire-Tauvel",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Tauvel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claire Tauvel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 31
                            }
                        ],
                        "text": "Recent work by several authors (Nemirovski et al., 2009; Juditsky et al., 2008; Lan, 2010; Xiao, 2010) considered efficient and robust methods for stochastic optimization, especially in the case when the expected objective f is smooth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5556708,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "e50c7cba0a612e8045458dd2aa130d9b2a1ff560",
            "isKey": false,
            "numCitedBy": 311,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we consider iterative methods for stochastic variational inequalities (s.v.i.) with monotone operators. Our basic assumption is that the operator possesses both smooth and nonsmooth components. Further, only noisy observations of the problem data are available. We develop a novel Stochastic Mirror-Prox (SMP) algorithm for solving s.v.i. and show that with the convenient stepsize strategy it attains the optimal rates of convergence with respect to the problem parameters. We apply the SMP algorithm to Stochastic composite minimization and describe particular applications to Stochastic Semidefinite Feasability problem and Eigenvalue minimization."
            },
            "slug": "Solving-variational-inequalities-with-Stochastic-Juditsky-Nemirovskii",
            "title": {
                "fragments": [],
                "text": "Solving variational inequalities with Stochastic Mirror-Prox algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A novel Stochastic Mirror-Prox algorithm is developed for solving s.v.i. variational inequalities with monotone operators and it is shown that with the convenient stepsize strategy it attains the optimal rates of convergence with respect to the problem parameters."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34840427"
                        ],
                        "name": "Elad Hazan",
                        "slug": "Elad-Hazan",
                        "structuredName": {
                            "firstName": "Elad",
                            "lastName": "Hazan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elad Hazan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144055676"
                        ],
                        "name": "Satyen Kale",
                        "slug": "Satyen-Kale",
                        "structuredName": {
                            "firstName": "Satyen",
                            "lastName": "Kale",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Satyen Kale"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 78
                            }
                        ],
                        "text": "The solution is obtained by definingGt = \u2211t \u03c4=1 g\u03c4g\u03c4 \u22a4, and then settingS to be a normalized version of the root ofGT , that is,S = cG 1/2 T / tr(G 1/2 T )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7528436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc0884effaa73b9dd91e683accb4068343bc776b",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Prediction from expert advice is a fundamental problem in machine learning. A major pillar of the field is the existence of learning algorithms whose average loss approaches that of the best expert in hindsight (in other words, whose average regret approaches zero). Traditionally the regret of online algorithms was bounded in terms of the number of prediction rounds.Cesa-Bianchi, Mansour and Stoltz (Mach. Learn. 66(2\u20133):21\u2013352, 2007) posed the question whether it is be possible to bound the regret of an online algorithm by the variation of the observed costs. In this paper we resolve this question, and prove such bounds in the fully adversarial setting, in two important online learning scenarios: prediction from expert advice, and online linear optimization."
            },
            "slug": "Extracting-certainty-from-uncertainty:-regret-Hazan-Kale",
            "title": {
                "fragments": [],
                "text": "Extracting certainty from uncertainty: regret bounded by\u00a0variation in\u00a0costs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The question whether it is be possible to bound the regret of an online algorithm by the variation of the observed costs is resolved, and bounds in the fully adversarial setting are proved, in two important online learning scenarios: prediction from expert advice, and online linear optimization."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2186481"
                        ],
                        "name": "A. Kalai",
                        "slug": "A.-Kalai",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Kalai",
                            "middleNames": [
                                "Tauman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kalai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737804"
                        ],
                        "name": "S. Vempala",
                        "slug": "S.-Vempala",
                        "structuredName": {
                            "firstName": "Santosh",
                            "lastName": "Vempala",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vempala"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 351791,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb3ed654be746a155573024639ab8d01e168a677",
            "isKey": false,
            "numCitedBy": 379,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Efficient-algorithms-for-online-decision-problems-Kalai-Vempala",
            "title": {
                "fragments": [],
                "text": "Efficient algorithms for online decision problems"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2738621"
                        ],
                        "name": "J. Abernethy",
                        "slug": "J.-Abernethy",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Abernethy",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Abernethy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680046"
                        ],
                        "name": "A. Rakhlin",
                        "slug": "A.-Rakhlin",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Rakhlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rakhlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3064914"
                        ],
                        "name": "Ambuj Tewari",
                        "slug": "Ambuj-Tewari",
                        "structuredName": {
                            "firstName": "Ambuj",
                            "lastName": "Tewari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ambuj Tewari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7050736,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e0a27506d9249779d4ad25082b775f070af409e",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of learning problems can be cast as an Online Convex Game: on each round, a learner makes a \nprediction x from a convex set, the environment plays a loss function f, and the learner\u2019s long-term goal is to \nminimize regret. Algorithms have been proposed by Zinkevich, when f is assumed to be convex, and Hazan et \nal., when f is assumed to be strongly convex, that have provably low regret. We consider these two settings and \nanalyze such games from a minimax perspective, proving minimax strategies and lower bounds in each case. These \nresults prove that the existing algorithms are essentially optimal."
            },
            "slug": "Optimal-Stragies-and-Minimax-Lower-Bounds-for-Games-Abernethy-Bartlett",
            "title": {
                "fragments": [],
                "text": "Optimal Stragies and Minimax Lower Bounds for Online Convex Games"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work analyzes Online Convex Game settings from a minimax perspective, proving minimax strategies and lower bounds in each case and proving that the existing algorithms are essentially optimal."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741426"
                        ],
                        "name": "P. Gallinari",
                        "slug": "P.-Gallinari",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Gallinari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gallinari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 347551,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b44ff78214ccd975ce16fbbc333423ca78d99141",
            "isKey": false,
            "numCitedBy": 358,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The SGD-QN algorithm is a stochastic gradient descent algorithm that makes careful use of second-order information and splits the parameter update into independently scheduled components. Thanks to this design, SGD-QN iterates nearly as fast as a first-order stochastic gradient descent but requires less iterations to achieve the same accuracy. This algorithm won the \"Wild Track\" of the first PASCAL Large Scale Learning Challenge (Sonnenburg et al., 2008)."
            },
            "slug": "SGD-QN:-Careful-Quasi-Newton-Stochastic-Gradient-Bordes-Bottou",
            "title": {
                "fragments": [],
                "text": "SGD-QN: Careful Quasi-Newton Stochastic Gradient Descent"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The SGD-QN algorithm is a stochastic gradient descent algorithm that makes careful use of second-order information and splits the parameter update into independently scheduled components."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693407"
                        ],
                        "name": "K. Crammer",
                        "slug": "K.-Crammer",
                        "structuredName": {
                            "firstName": "Koby",
                            "lastName": "Crammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Crammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782853"
                        ],
                        "name": "Mark Dredze",
                        "slug": "Mark-Dredze",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dredze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Dredze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The framework that is most related to ours is probably confidence weighted learning (Crammer et al., 2008) and the adaptive regularization of weights algorithm (AROW) of Crammer et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1818183,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "204e8a65992d84cb479d8ffce149c022113e6fdd",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Confidence-weighted (CW) learning [6], an online learning method for linear classifiers, maintains a Gaussian distributions over weight vectors, with a covariance matrix that represents uncertainty about weights and correlations. Confidence constraints ensure that a weight vector drawn from the hypothesis distribution correctly classifies examples with a specified probability. Within this framework, we derive a new convex form of the constraint and analyze it in the mistake bound model. Empirical evaluation with both synthetic and text data shows our version of CW learning achieves lower cumulative and out-of-sample errors than commonly used first-order and second-order online methods."
            },
            "slug": "Exact-Convex-Confidence-Weighted-Learning-Crammer-Dredze",
            "title": {
                "fragments": [],
                "text": "Exact Convex Confidence-Weighted Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Empirical evaluation with both synthetic and text data shows this version of CW learning achieves lower cumulative and out-of-sample errors than commonly used first-order and second-order online methods."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144830983"
                        ],
                        "name": "Y. Mansour",
                        "slug": "Y.-Mansour",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Mansour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Mansour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806997"
                        ],
                        "name": "Gilles Stoltz",
                        "slug": "Gilles-Stoltz",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "Stoltz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gilles Stoltz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3248698,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "ac54c82bb6d5fadd8fee51992729e7483c604ed9",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This work studies external regret in sequential prediction games with both positive and negative payoffs. External regret measures the difference between the payoff obtained by the forecasting strategy and the payoff of the best action. In this setting, we derive new and sharper regret bounds for the well-known exponentially weighted average forecaster and for a second forecaster with a different multiplicative update rule. Our analysis has two main advantages: first, no preliminary knowledge about the payoff sequence is needed, not even its range; second, our bounds are expressed in terms of sums of squared payoffs, replacing larger first-order quantities appearing in previous bounds. In addition, our most refined bounds have the natural and desirable property of being stable under rescalings and general translations of the payoff sequence."
            },
            "slug": "Improved-second-order-bounds-for-prediction-with-Cesa-Bianchi-Mansour",
            "title": {
                "fragments": [],
                "text": "Improved second-order bounds for prediction with expert advice"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "New and sharper regret bounds are derived for the well-known exponentially weighted average forecaster and for a second forecaster with a different multiplicative update rule, expressed in terms of sums of squared payoffs, replacing larger first-order quantities appearing in previous bounds."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143676697"
                        ],
                        "name": "Y. Nesterov",
                        "slug": "Y.-Nesterov",
                        "structuredName": {
                            "firstName": "Yurii",
                            "lastName": "Nesterov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nesterov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2391217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e6c6086ea725737aa6081a57ea68d43a24ca3b9",
            "isKey": false,
            "numCitedBy": 2434,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.In this paper we propose a new approach for constructing efficient schemes for non-smooth convex optimization. It is based on a special smoothing technique, which can be applied to functions with explicit max-structure. Our approach can be considered as an alternative to black-box minimization. From the viewpoint of efficiency estimates, we manage to improve the traditional bounds on the number of iterations of the gradient schemes from keeping basically the complexity of each iteration unchanged."
            },
            "slug": "Smooth-minimization-of-non-smooth-functions-Nesterov",
            "title": {
                "fragments": [],
                "text": "Smooth minimization of non-smooth functions"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A new approach for constructing efficient schemes for non-smooth convex optimization is proposed, based on a special smoothing technique, which can be applied to functions with explicit max-structure, and can be considered as an alternative to black-box minimization."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529182"
                        ],
                        "name": "David Grangier",
                        "slug": "David-Grangier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Grangier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Grangier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16809392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bb51966222accaa2b28d93284095a76bb17f659",
            "isKey": false,
            "numCitedBy": 321,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a discriminative model for the retrieval of images from text queries. Our approach formalizes the retrieval task as a ranking problem, and introduces a learning procedure optimizing a criterion related to the ranking performance. The proposed model hence addresses the retrieval problem directly and does not rely on an intermediate image annotation task, which contrasts with previous research. Moreover, our learning procedure builds upon recent work on the online learning of kernel-based classifiers. This yields an efficient, scalable algorithm, which can benefit from recent kernels developed for image comparison. The experiments performed over stock photography data show the advantage of our discriminative ranking approach over state-of-the-art alternatives (e.g. our model yields 26.3% average precision over the Corel dataset, which should be compared to 22.0%, for the best alternative model evaluated). Further analysis of the results shows that our model is especially advantageous over difficult queries such as queries with few relevant pictures or multiple-word queries."
            },
            "slug": "A-Discriminative-Kernel-Based-Approach-to-Rank-from-Grangier-Bengio",
            "title": {
                "fragments": [],
                "text": "A Discriminative Kernel-Based Approach to Rank Images from Text Queries"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper introduces a discriminative model for the retrieval of images from text queries that formalizes the retrieval task as a ranking problem, and introduces a learning procedure optimizing a criterion related to the ranking performance."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529182"
                        ],
                        "name": "David Grangier",
                        "slug": "David-Grangier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Grangier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Grangier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2828358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "beb3fb71b5b44738c7bfd52acb4409d889f257b4",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a discriminative model for the retrieval of images from text queries. Our approach formalizes the retrieval task as a ranking problem, and introduces a learning procedure optimizing a criterion related to the ranking performance. The proposed model hence addresses the retrieval problem directly and does not rely on an intermediate image annotation task, which contrasts with previous research. Moreover, our learning procedure builds upon recent work on the online learning of kernel-based classifiers. This yields an efficient, scalable algorithm, which can benefit from recent kernels developed for image comparison. The experiments performed over stock photography data show the advantage of our discriminative ranking approach over state-of-the-art alternatives (e.g. our model yields 26.3% average precision over the Corel dataset, which should be compared to 22.0%, for the best alternative model evaluated). Further analysis of the results shows that our model is especially advantageous over difficult queries such as queries with few relevant pictures or multiple-word queries."
            },
            "slug": "A-Discriminative-Kernel-based-Model-to-Rank-Images-Grangier-Bengio",
            "title": {
                "fragments": [],
                "text": "A Discriminative Kernel-based Model to Rank Images from Text Queries"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper introduces a discriminative model for the retrieval of images from text queries that formalizes the retrieval task as a ranking problem, and introduces a learning procedure optimizing a criterion related to the ranking performance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2533906"
                        ],
                        "name": "G. Obozinski",
                        "slug": "G.-Obozinski",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Obozinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Obozinski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 128
                            }
                        ],
                        "text": "This type of regularization is useful for zeroing multiple weights in a group, for example in multi-task or multiclass learning (Obozinski et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 106
                            }
                        ],
                        "text": "We consider mixed-norm regularization, which is very useful for encouraging sparsity across several tasks (Obozinski et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10492955,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "f5ec0bebd6ce4b77897ad2c6e07a15eaa9146c90",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of recovering a common set of covariates that are relevant simultaneously to several classification problems. We propose a joint measure of complexity for the group of problems that couples covariate selection. By penalizing the sum of `2-norms of the blocks of coefficients associated with each covariate across different classification problems, we encourage similar sparsity patterns in all models. To fit parameters under this regularization, we propose a blockwise boosting scheme that follows the regularization path. As the regularization coefficient decreases, the algorithm maintains and updates concurrently a growing set of covariates that are simultaneously active for all problems. We show empirically that this approach outperforms independent `1-based covariate selection on several data sets, both in accuracy and number of selected covariates."
            },
            "slug": "Joint-covariate-selection-for-grouped-Obozinski",
            "title": {
                "fragments": [],
                "text": "Joint covariate selection for grouped classification"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work proposes a joint measure of complexity for the group of problems that couples covariate selection by penalizing the sum of `2-norms of the blocks of coefficients associated with each covariate across different classification problems, and proposes a blockwise boosting scheme that follows the regularization path."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693407"
                        ],
                        "name": "K. Crammer",
                        "slug": "K.-Crammer",
                        "structuredName": {
                            "firstName": "Koby",
                            "lastName": "Crammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Crammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716876"
                        ],
                        "name": "O. Dekel",
                        "slug": "O.-Dekel",
                        "structuredName": {
                            "firstName": "Ofer",
                            "lastName": "Dekel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Dekel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771345"
                        ],
                        "name": "Joseph Keshet",
                        "slug": "Joseph-Keshet",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Keshet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Keshet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389955537"
                        ],
                        "name": "S. Shalev-Shwartz",
                        "slug": "S.-Shalev-Shwartz",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Shalev-Shwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shalev-Shwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5919882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ca4d4229b8a843c0847fc70531790df6bd017ec",
            "isKey": false,
            "numCitedBy": 1772,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a unified view for online classification, regression, and uni-class problems. This view leads to a single algorithmic framework for the three problems. We prove worst case loss bounds for various algorithms for both the realizable case and the non-realizable case. A conversion of our main online algorithm to the setting of batch learning is also discussed. The end result is new algorithms and accompanying loss bounds for the hinge-loss."
            },
            "slug": "Online-Passive-Aggressive-Algorithms-Crammer-Dekel",
            "title": {
                "fragments": [],
                "text": "Online Passive-Aggressive Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This work presents a unified view for online classification, regression, and uni-class problems, and proves worst case loss bounds for various algorithms for both the realizable case and the non-realizable case."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2445783"
                        ],
                        "name": "A. Conconi",
                        "slug": "A.-Conconi",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Conconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Conconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895207"
                        ],
                        "name": "C. Gentile",
                        "slug": "C.-Gentile",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Gentile",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gentile"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 138
                            }
                        ],
                        "text": "Crammer et al. give a mistake-bound analysis for online binary classification, which is similar in spirit to the second-order\nPerceptron (Cesa-Bianchi et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 122
                            }
                        ],
                        "text": "give a mistake-bound analysis for online binary classification, which is similar in spirit to the second-order Perceptron (Cesa-Bianchi et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13649758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c71a79eb4b8d60f116470ca4103c48ba709d83f",
            "isKey": false,
            "numCitedBy": 199,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a variant of the Perceptron algorithm called second-order Perceptron algorithm, which is able to exploit certain spectral properties of the data. We analyze the second-order Perceptron algorithm in the mistake bound model of on-line learning and prove bounds in terms of the eigenvalues of the Gram matrix created from the data. The performance of the second-order Perceptron algorithm is affected by the setting of a parameter controlling the sensitivity to the distribution of the eigenvalues of the Gram matrix. Since this information is not preliminarly available to on-line algorithms, we also design a refined version of the second-order Perceptron algorithm which adaptively sets the value of this parameter. For this second algorithm we are able to prove mistake bounds corresponding to a nearly optimal constant setting of the parameter."
            },
            "slug": "A-Second-Order-Perceptron-Algorithm-Cesa-Bianchi-Conconi",
            "title": {
                "fragments": [],
                "text": "A Second-Order Perceptron Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A refined version of the second-order Perceptron algorithm which adaptively sets the value of a parameter and is able to prove mistake bounds corresponding to a nearly optimal constant setting of the parameter."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Comput."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843103"
                        ],
                        "name": "Stephen P. Boyd",
                        "slug": "Stephen-P.-Boyd",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Boyd",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen P. Boyd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2014414"
                        ],
                        "name": "L. Vandenberghe",
                        "slug": "L.-Vandenberghe",
                        "structuredName": {
                            "firstName": "Lieven",
                            "lastName": "Vandenberghe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vandenberghe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37925315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f607f03272e4d62708f5b2441355f9e005cb452",
            "isKey": false,
            "numCitedBy": 38719,
            "numCiting": 276,
            "paperAbstract": {
                "fragments": [],
                "text": "Convex optimization problems arise frequently in many different fields. A comprehensive introduction to the subject, this book shows in detail how such problems can be solved numerically with great efficiency. The focus is on recognizing convex optimization problems and then finding the most appropriate technique for solving them. The text contains many worked examples and homework exercises and will appeal to students, researchers and practitioners in fields such as engineering, computer science, mathematics, statistics, finance, and economics."
            },
            "slug": "Convex-Optimization-Boyd-Vandenberghe",
            "title": {
                "fragments": [],
                "text": "Convex Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A comprehensive introduction to the subject of convex optimization shows in detail how such problems can be solved numerically with great efficiency."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Automatic Control"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759608"
                        ],
                        "name": "P. Pardalos",
                        "slug": "P.-Pardalos",
                        "structuredName": {
                            "firstName": "Panos",
                            "lastName": "Pardalos",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pardalos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741495"
                        ],
                        "name": "N. Kovoor",
                        "slug": "N.-Kovoor",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Kovoor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kovoor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A randomized search with bookkeeping (Pardalos and Rosen, 1990) can be straightforwardly used to derive a linear time algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9964980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "416e7bb25c51e352330c6e58f5b06da0c58190d3",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives an O(n) algorithm for a singly constrained convex quadratic program using binary search to solve the Kuhn-Tucker system. Computational results indicate that a randomized version of this algorithm runs in expected linear time and is suitable for practical applications. For the nonconvex case an\u03b5-approximate algorithm is proposed which is based on convex and piecewise linear approximations of the objective function."
            },
            "slug": "An-algorithm-for-a-singly-constrained-class-of-to-Pardalos-Kovoor",
            "title": {
                "fragments": [],
                "text": "An algorithm for a singly constrained class of quadratic programs subject to upper and lower bounds"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "An O(n) algorithm for a singly constrained convex quadratic program using binary search to solve the Kuhn-Tucker system is given."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102835246"
                        ],
                        "name": "J. Hiriart-Urruty",
                        "slug": "J.-Hiriart-Urruty",
                        "structuredName": {
                            "firstName": "Jean-Baptiste",
                            "lastName": "Hiriart-Urruty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hiriart-Urruty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8773884"
                        ],
                        "name": "C. Lemar\u00e9chal",
                        "slug": "C.-Lemar\u00e9chal",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Lemar\u00e9chal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lemar\u00e9chal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118755909,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "065c019bb27e23ed10492ca61b186eb9375dd5de",
            "isKey": false,
            "numCitedBy": 2939,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "IX. Inner Construction of the Subdifferential.- X. Conjugacy in Convex Analysis.- XI. Approximate Subdifferentials of Convex Functions.- XII. Abstract Duality for Practitioners.- XIII. Methods of ?-Descent.- XIV. Dynamic Construction of Approximate Subdifferentials: Dual Form of Bundle Methods.- XV. Acceleration of the Cutting-Plane Algorithm: Primal Forms of Bundle Methods.- Bibliographical Comments.- References."
            },
            "slug": "Convex-analysis-and-minimization-algorithms-Hiriart-Urruty-Lemar\u00e9chal",
            "title": {
                "fragments": [],
                "text": "Convex analysis and minimization algorithms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144405184"
                        ],
                        "name": "P. Brucker",
                        "slug": "P.-Brucker",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brucker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brucker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 193
                            }
                        ],
                        "text": "2 l1-ball Projections We next consider the setting in which \u03c6 \u2261 0 and X = {x : \u2016x\u20161 \u2264 c}, for which it is straightforward to adapt efficient solutions to continuous quadratic knapsack problems (Brucker, 1984)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120700813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0363376e26eaa8070fa2f0f158c0aaacee5b4097",
            "isKey": false,
            "numCitedBy": 217,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Review-of-recent-development:-An-O(-n)-algorithm-Brucker",
            "title": {
                "fragments": [],
                "text": "Review of recent development: An O( n) algorithm for quadratic knapsack problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32440409"
                        ],
                        "name": "T. Rose",
                        "slug": "T.-Rose",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Rose",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rose"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146329150"
                        ],
                        "name": "Fan Li",
                        "slug": "Fan-Li",
                        "structuredName": {
                            "firstName": "Fan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fan Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11027141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2abe6b9ea1b13653b7384e9c8ef14b0d87e20cfc",
            "isKey": false,
            "numCitedBy": 2683,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories recently made available by Reuters, Ltd. for research purposes. Use of this data for research on text categorization requires a detailed understanding of the real world constraints under which the data was produced. Drawing on interviews with Reuters personnel and access to Reuters documentation, we describe the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data. We refer to the original data as RCV1-v1, and the corrected data as RCV1-v2. We benchmark several widely used supervised learning methods on RCV1-v2, illustrating the collection's properties, suggesting new directions for research, and providing baseline results for future studies. We make available detailed, per-category experimental results, as well as corrected versions of the category assignments and taxonomy structures, via online appendices."
            },
            "slug": "RCV1:-A-New-Benchmark-Collection-for-Text-Research-Lewis-Yang",
            "title": {
                "fragments": [],
                "text": "RCV1: A New Benchmark Collection for Text Categorization Research"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48168741"
                        ],
                        "name": "T. And\u00f4",
                        "slug": "T.-And\u00f4",
                        "structuredName": {
                            "firstName": "Tsuyoshi",
                            "lastName": "And\u00f4",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. And\u00f4"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121714566,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ab899bf9f58e5d48c8600a3616fcc43d3ed4a1d6",
            "isKey": false,
            "numCitedBy": 421,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Concavity-of-certain-maps-on-positive-definite-and-And\u00f4",
            "title": {
                "fragments": [],
                "text": "Concavity of certain maps on positive definite matrices and applications to Hadamard products"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847596"
                        ],
                        "name": "Wei Dong",
                        "slug": "Wei-Dong",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94451829"
                        ],
                        "name": "K. Li",
                        "slug": "K.-Li",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "2 Image Ranking ImageNet (Deng et al., 2009) consists of images organized according to the nouns in the WordNet hierarchy, where each noun is associated on average with more than 500 images collected from the web. We selected 15,000 important nouns from the hierarchy and conducted a large scale image ranking task for each noun. This approach is identical to the task tackled by Grangier and Bengio (2008) using the Passive-Aggressive algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "2 Image Ranking ImageNet (Deng et al., 2009) consists of images organized according to the nouns in the WordNet hierarchy, where each noun is associated on average with more than 500 images collected from the web."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Experiments We performed experiments with several real world datasets with different characteristics: the ImageNet image database (Deng et al., 2009), the Reuters RCV1 text classification dataset (Lewis et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 57246310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2c733e34d48784a37d717fe43d9e93277a8c53e",
            "isKey": true,
            "numCitedBy": 27367,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond."
            },
            "slug": "ImageNet:-A-large-scale-hierarchical-image-database-Deng-Dong",
            "title": {
                "fragments": [],
                "text": "ImageNet: A large-scale hierarchical image database"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new database called \u201cImageNet\u201d is introduced, a large-scale ontology of images built upon the backbone of the WordNet structure, much larger in scale and diversity and much more accurate than the current image datasets."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1997069"
                        ],
                        "name": "J. Lenstra",
                        "slug": "J.-Lenstra",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Lenstra",
                            "middleNames": [
                                "Karel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lenstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729250"
                        ],
                        "name": "G. Woeginger",
                        "slug": "G.-Woeginger",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Woeginger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Woeginger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69053687"
                        ],
                        "name": "F. Spieksma",
                        "slug": "F.-Spieksma",
                        "structuredName": {
                            "firstName": "Frits",
                            "lastName": "Spieksma",
                            "middleNames": [
                                "C.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Spieksma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144683424"
                        ],
                        "name": "P. Marcotte",
                        "slug": "P.-Marcotte",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Marcotte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Marcotte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800675"
                        ],
                        "name": "S. Kou",
                        "slug": "S.-Kou",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Kou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706816"
                        ],
                        "name": "N. Megiddo",
                        "slug": "N.-Megiddo",
                        "structuredName": {
                            "firstName": "Nimrod",
                            "lastName": "Megiddo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Megiddo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072495112"
                        ],
                        "name": "B. Shepherd",
                        "slug": "B.-Shepherd",
                        "structuredName": {
                            "firstName": "Brenda",
                            "lastName": "Shepherd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Shepherd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782241"
                        ],
                        "name": "S. Seshadri",
                        "slug": "S.-Seshadri",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Seshadri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seshadri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157154"
                        ],
                        "name": "R. Schultz",
                        "slug": "R.-Schultz",
                        "structuredName": {
                            "firstName": "R\u00fcdiger",
                            "lastName": "Schultz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schultz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35211064"
                        ],
                        "name": "T. Kok",
                        "slug": "T.-Kok",
                        "structuredName": {
                            "firstName": "Ton",
                            "lastName": "Kok",
                            "middleNames": [
                                "G.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716078"
                        ],
                        "name": "C. Helmberg",
                        "slug": "C.-Helmberg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Helmberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Helmberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111210452"
                        ],
                        "name": "Alexander Martin",
                        "slug": "Alexander-Martin",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121235"
                        ],
                        "name": "S. Velde",
                        "slug": "S.-Velde",
                        "structuredName": {
                            "firstName": "Steef",
                            "lastName": "Velde",
                            "middleNames": [
                                "L.",
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Velde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797627"
                        ],
                        "name": "S. Andrad\u00f3ttir",
                        "slug": "S.-Andrad\u00f3ttir",
                        "structuredName": {
                            "firstName": "Sigr\u00fan",
                            "lastName": "Andrad\u00f3ttir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Andrad\u00f3ttir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731931"
                        ],
                        "name": "S. Borst",
                        "slug": "S.-Borst",
                        "structuredName": {
                            "firstName": "Sem",
                            "lastName": "Borst",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Borst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692885"
                        ],
                        "name": "T. Takine",
                        "slug": "T.-Takine",
                        "structuredName": {
                            "firstName": "Tetsuya",
                            "lastName": "Takine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Takine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705564"
                        ],
                        "name": "G. Nemhauser",
                        "slug": "G.-Nemhauser",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nemhauser",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nemhauser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2229828"
                        ],
                        "name": "K. Aardal",
                        "slug": "K.-Aardal",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Aardal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Aardal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1823941"
                        ],
                        "name": "D. Klatte",
                        "slug": "D.-Klatte",
                        "structuredName": {
                            "firstName": "Diethard",
                            "lastName": "Klatte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klatte"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 67472739,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "19cd6c0e6bcf4cf6613e4ab6a20d6cc80833827a",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Operations Research Letters is a publication for literature on all aspects of operations research and the management and decision sciences. The features distinguishing it from other journals in the field are \n* concise articles, generally limited to 6 journal pages \n* rapid review and fast publication \n* broad coverage of the literature. \nApart from the page limitation, originality, relevance, quality and clarity are the only criteria for selecting the material to be published. The journal covers continuous and discrete optimization, stochastic models, and situations with multiple decision makers. The subject matter can be theory, methodology, empirical studies, and applications. The mainstream of contributions focuses on new models, theorems, algorithms, and experimental work that the author wants to disseminate rapidly. We will publish theory and methodology with proofs only sketched, provided that the author submits support material that enables us to verify the findings. We will also publish computational and experimental studies that are not necessarily based on new theory or methodology, but are of significant scientific value because they confirm or refute prior results. Similarly, we will publish reports on applications and case studies that demonstrate a novel use of existing techniques or contain significant ideas about data collection and analysis, modelling, or implementation."
            },
            "slug": "Operations-Research-Letters-Lenstra-Woeginger",
            "title": {
                "fragments": [],
                "text": "Operations Research Letters"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "Operations Research Letters is a publication for literature on all aspects of operations research and the management and decision sciences that focuses on new models, theorems, algorithms, and experimental work that the author wants to disseminate rapidly."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8037180"
                        ],
                        "name": "James V. Bondar",
                        "slug": "James-V.-Bondar",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bondar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James V. Bondar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 116949751,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "0cc5c08e61b75ebfab986a5fdd5e03e1cfb422f9",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Inequalities:-Theory-of-majorization-and-its-by-W.-Bondar",
            "title": {
                "fragments": [],
                "text": "Inequalities: Theory of majorization and its applications: by Albert W. Marshall and Ingram Olkin"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 112
                            }
                        ],
                        "text": "The informativeness of rare features has led practitioners to craft domain-specific feature weightin s, such as TF-IDF (Salton and Buckley, 1988), which pre-emphasize infrequently occurring features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1496,
                                "start": 120
                            }
                        ],
                        "text": "The informativeness of rare features has led practitioners to craft domain-specific feature weightings, such as TF-IDF (Salton and Buckley, 1988), which pre-emphasize infrequently occurring features. We use this old idea as a motivation for applying modern learning-theoretic techniques to the problem of online and stochastic learning, focusing specifically on (sub)gradient methods. Standard stochastic subgradient methods largely follow a predetermined procedural scheme that is oblivious to the characteristics of the data being observed. In contrast, our algorithms dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. The adaptation facilitates finding and identifying very predictive but comparatively rare features. The following toy example of classification with the hinge loss highlights a problem with standard subgradient methods. We receive a sequence of 3-dimensional vectors {zt} and labels yt \u2208 {\u22121,+1}. Let ut be independent \u00b11-valued random variables, each with probability 1 2 . Each instance zt is associated with a label yt = \u22121 and is equal to (ut,\u2212ut, 0) 99% of the time, while zt = (ut,\u2212ut, 1) the remaining 1% of the cases with label yt = 1. We would like find a vector x with \u2016x\u2016\u221e \u2264 1 such that max{0,\u2212yt \u3008x, zt\u3009} = 0 for all t. Clearly, any solution vector takes the form x = (a, a, 1) with |a| \u2264 1. Standard subgradient methods, such as the one proposed by Zinkevich (2003), iterate as follows: xt+1 = \u03a0{x:\u2016x\u2016 \u221e \u22641}(xt \u2212 \u03b7tytzt) , where \u03a0X denotes Euclidean projection onto the set X and \u03b7t = 1/ \u221a t."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7725217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e50a316f97c9a405aa000d883a633bd5707f1a34",
            "isKey": false,
            "numCitedBy": 9460,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Term-Weighting-Approaches-in-Automatic-Text-Salton-Buckley",
            "title": {
                "fragments": [],
                "text": "Term-Weighting Approaches in Automatic Text Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 104
                            }
                        ],
                        "text": "For completeness, we provide the proofs of following two corollaries in the long version of this paper (Duchi et al., 2010a), though they build straightforwardly onDuchi et al.(2010b) andXiao (2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 63
                            }
                        ],
                        "text": "These results are available in the long version of this paper (Duchi et al., 2010a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 169
                            }
                        ],
                        "text": "For composite mirror descent, we obtain a simple corollary by combining the original convergence results from Corollary 4 with the strongly-convex function results from Duchi et al. (2010). We assume without loss of generality that \u03c6(x1) = 0 and x1 = 0."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 113
                            }
                        ],
                        "text": "Mirror-descent type first order algorithms, such as projected gradient methods, attain regret bounds of the form (Zinkevich, 2003; Bartlett et al., 2007; Duchi et al., 2010) R\u03c6(T ) \u2264 1 \u03b7 B\u03c8(x \u2217, x1) + \u03b7 2 T"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 84
                            }
                        ],
                        "text": "The lemmas are quite technical, so we prove them in the long version of this paper (Duchi et al., 2010a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 59
                            }
                        ],
                        "text": "We begin by stating an immediate corollary to Lemma 1 from Duchi et al. (2010). We provide the proof for completeness."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 50
                            }
                        ],
                        "text": "The second method is the composite mirror descent (Duchi et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 95
                            }
                        ],
                        "text": "Examining several well-known optimization bounds (e.g.Beck and Teboulle, 2003; Nesterov, 2009; Duchi et al., 2010b), we see that we can bound the regret as\nR\u03c6(T ) \u2264 1\n\u03b7 B\u03c8(x\n\u2217, x1) + \u03b7\n2\nT \u2211\nt=1\n\u2016f \u2032t(xt)\u2016 2 \u2217 ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 152
                            }
                        ],
                        "text": "We also consider the forward-backward splitting (Fobos) algorithmic framework (Duchi and Singer, 2009) and its composite mirror-descent generalizations (Duchi et al., 2010), which in turn include as special cases the method of projected gradient descent (Zinkevich, 2003) and mirror descent (Nemirovski and Yudin, 1983; Beck and Teboulle, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 72
                            }
                        ],
                        "text": "We provide an elaborated explanation in the full version of this paper (Duchi et al., 2010a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 159
                            }
                        ],
                        "text": "The second method also has many names, such asproximal gradient, forwardbackward splitting, and composite mirror descent (Tseng, 2008; Duchi and Singer, 2009; Duchi et al., 2010b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 211
                            }
                        ],
                        "text": "Rather than give the proof of the lower regret, we simply state the result, as it is not difficult to prove using techniques of Hazan et al.(2006), though we include the proof in the full version of this paper (Duchi et al., 2010a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Composite objective mirror"
            },
            "venue": {
                "fragments": [],
                "text": "descent. Submitted,"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 95
                            }
                        ],
                        "text": "Online learning and stochastic optimization are closely related and basically inter changeable (Cesa-Bianchi et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 84
                            }
                        ],
                        "text": "Tighter regret bounds using the va riation of the cost functionsft were proposed by Cesa-Bianchi et al. (2007) and derived by Haza n nd Kale (2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 84
                            }
                        ],
                        "text": "Tighter regret bounds using the va riation of the cost functionsft were proposed by Cesa-Bianchi et al. (2007) and derived by Haza n nd Kale (2008). Bartlett et al. (2007) explore another adaptation technique for \u03b7t where they adapt the step size to accommodate"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 104
                            }
                        ],
                        "text": "Our on line regret bounds can be naturally converted into rate of convergence and generalization bounds (Cesa-Bianchi et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 84
                            }
                        ],
                        "text": "Tighter regret bounds using the va riation of the cost functionsft were proposed by Cesa-Bianchi et al. (2007) and derived by Haza n nd Kale (2008). Bartlett et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 110
                            }
                        ],
                        "text": "Our online convergence results can be naturally converted into rate of convergence and generalization bounds (Cesa-Bianchi et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A second-order perce"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080752"
                        ],
                        "name": "N. Z. Shor",
                        "slug": "N.-Z.-Shor",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Shor",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Z. Shor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 79
                            }
                        ],
                        "text": "For RDA and FOBOS, we cross-validate the\nstepsize parameter\u03b7 by running multiple passes and then choosing the output of the learner that had the fewest mistakes during training."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122141875,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cd42a131bafb00a03a1b570ee2877ffb08f97778",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Utilization-of-the-operation-of-space-dilatation-in-Shor",
            "title": {
                "fragments": [],
                "text": "Utilization of the operation of space dilatation in the minimization of convex functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117150805"
                        ],
                        "name": "C. Davis",
                        "slug": "C.-Davis",
                        "structuredName": {
                            "firstName": "Carol",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116036657,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "680f24f9a900545d2b01fc1134ae84ddc4717166",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Notions-generalizing-convexity-for-functions-on-of-Davis",
            "title": {
                "fragments": [],
                "text": "Notions generalizing convexity for functions defined on spaces of matrices"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786249"
                        ],
                        "name": "D. Bertsekas",
                        "slug": "D.-Bertsekas",
                        "structuredName": {
                            "firstName": "Dimitri",
                            "lastName": "Bertsekas",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bertsekas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(3) implies for all x \u2208 X and \u03c6\u2032(xt+1) \u2208 \u2202\u03c6(xt+1) (Bertsekas, 1999) \u3008x\u2212 xt+1, \u03b7f (xt) +\u2207\u03c8t(xt+1)\u2212\u2207\u03c8t(xt) + \u03b7\u03c6(xt+1)\u3009 \u2265 0."
                    },
                    "intents": []
                }
            ],
            "corpusId": 64649729,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11106aadd1c133477b163f08de6c9436cd5468fe",
            "isKey": false,
            "numCitedBy": 9685,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nonlinear-Programming-Bertsekas",
            "title": {
                "fragments": [],
                "text": "Nonlinear Programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70041051"
                        ],
                        "name": "Angelia Nedi\u00c4",
                        "slug": "Angelia-Nedi\u00c4",
                        "structuredName": {
                            "firstName": "Angelia",
                            "lastName": "Nedi\u00c4",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Angelia Nedi\u00c4"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60901640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef3a45783de1e58ccf338fc26d32b555cb3864c3",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Subgradient-methods-for-convex-minimization-Nedi\u00c4",
            "title": {
                "fragments": [],
                "text": "Subgradient methods for convex minimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59673088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dc6315533aaec1741e6348c826b0dbaf869cad5",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-seventh-annual-conference-on-Warmuth",
            "title": {
                "fragments": [],
                "text": "Proceedings of the seventh annual conference on Computational learning theory"
            },
            "venue": {
                "fragments": [],
                "text": "COLT 1994"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061638288"
                        ],
                        "name": "R. Fletcher",
                        "slug": "R.-Fletcher",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Fletcher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fletcher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 125
                            }
                        ],
                        "text": "In this generalized case, the algorithm uses the the square-root of the matrix of outer products of the gradients that observed to update the parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 137
                            }
                        ],
                        "text": "There, we findShor\u2019s work on space dilation methods (1972) as well as variable metric methods, such as the BFGS family of algorithms (e.g.Fletcher, 1970)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26597321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb787c61efda995b99fb939b743c99cda3f0b9f4",
            "isKey": false,
            "numCitedBy": 3278,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-New-Approach-to-Variable-Metric-Algorithms-Fletcher",
            "title": {
                "fragments": [],
                "text": "A New Approach to Variable Metric Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. J."
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800855"
                        ],
                        "name": "A. Nedi\u0107",
                        "slug": "A.-Nedi\u0107",
                        "structuredName": {
                            "firstName": "Angelia",
                            "lastName": "Nedi\u0107",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nedi\u0107"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1792103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3559b1690b52dd74d8fd8d881532c6285e9e1efe",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Subgradient-methods-for-convex-minimization-Nedi\u0107",
            "title": {
                "fragments": [],
                "text": "Subgradient methods for convex minimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bengio . A discriminative kernelbased model to rank images from text queries"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rakhlin . Adaptive online gradient descent"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Smooth minimization of nonsmooth functions"
            },
            "venue": {
                "fragments": [],
                "text": "Mathematical Programming,"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the generalization ability ofonline learning algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 122
                            }
                        ],
                        "text": "The second method also has many names, such asproximal gradient, forwardbackward splitting, and composite mirror descent (Tseng, 2008; Duchi and Singer, 2009; Duchi et al., 2010b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 122
                            }
                        ],
                        "text": "The second method also has many names, such as proximal gradient, forwardbackward splitting, and composite mirror descent (Tseng, 2008; Duchi and Singer, 2009; Duchi et al., 2010b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On accelerated proximal gradient methods for convex-concave optimization"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report, Department of Mathematics, University of Washington,"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "UC Berkeley EECS Technical Report"
            },
            "venue": {
                "fragments": [],
                "text": "UC Berkeley EECS Technical Report"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 162
                            }
                        ],
                        "text": "Verbatim usage of the FTRL approach fails to achieve low regret, however, adding a proximal1 term to the past predictions leads to numerous low regret algorithms (Kalai and Vempala, 2003; Hazan and Kale, 2008; Rakhlin, 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lecture notes on online learning"
            },
            "venue": {
                "fragments": [],
                "text": "For the Statistical Machine Learning Course at University of California,"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convex Analysis and Minimization"
            },
            "venue": {
                "fragments": [],
                "text": "Algorithms II. Springer-Verlag,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "UCI machine learning repository"
            },
            "venue": {
                "fragments": [],
                "text": "UCI machine learning repository"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 53
                            }
                        ],
                        "text": "We focus on composite mirror descent algorithms, as the analysis of strongly convex variants of primal-dual subgradient algorithms does not seem to lend itself to dynamic learning rate adaptation."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lecture notes on online learning. For the Statistical Machine Learning Course at University of California"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture notes on online learning. For the Statistical Machine Learning Course at University of California"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "International Conference on Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Machine Learning"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comments on and complements to Inequalities : Theory of Majorization and Its Applications"
            },
            "venue": {
                "fragments": [],
                "text": "Linear Algebra and its Applications"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bengio . A discriminative kernelbased model to rank images from text queries"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comments on and complements to Inequalities: Theory of Majorization and Its Applications"
            },
            "venue": {
                "fragments": [],
                "text": "Linear Algebra and its Applications,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convex Analysis and Minimization Algorithms II"
            },
            "venue": {
                "fragments": [],
                "text": "Convex Analysis and Minimization Algorithms II"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nesterov . Smooth minimization of nonsmooth functions"
            },
            "venue": {
                "fragments": [],
                "text": "Mathematical Programming"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the Twenty Third Annual Conference on Computational Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Twenty Third Annual Conference on Computational Learning Theory"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 105
                            }
                        ],
                        "text": ", 2010), which in turn include as special cases projected gradients (Zinkevich, 2003) and mirror descent (Nemirovski and Yudin, 1983; Beck and Teboulle, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Problem Complexity and Efficiency in Optimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptive Subgradient Methods"
            },
            "venue": {
                "fragments": [],
                "text": "Adaptive Subgradient Methods"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exact convex confidenceweighted learning"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convex Analysis and Minimization Algorithms II"
            },
            "venue": {
                "fragments": [],
                "text": "Convex Analysis and Minimization Algorithms II"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bottou and P . Gallinari . Sgdqn : Careful quasinewton stochastic gradient descent"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Machine Learning Research"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A second - order percetron algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "SIAM Journal on Computing"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 161
                            }
                        ],
                        "text": "Plain usage of the FTRL approach fails to achieve low regret, however, adding a proximal(2) term to the past predictions leads to numerous low regret algorithms (Kalai and Vempala, 2003; Hazan and Kale, 2008; Rakhlin, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lecture notes on online learning. For the Statistical Machine Learning Course"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 15,
            "methodology": 16,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 75,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Adaptive-Subgradient-Methods-for-Online-Learning-Duchi-Hazan/413c1142de9d91804d6d11c67ff3fed59c9fc279?sort=total-citations"
}