{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110965354"
                        ],
                        "name": "Xiaojing Liu",
                        "slug": "Xiaojing-Liu",
                        "structuredName": {
                            "firstName": "Xiaojing",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaojing Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112256"
                        ],
                        "name": "Feiyu Gao",
                        "slug": "Feiyu-Gao",
                        "structuredName": {
                            "firstName": "Feiyu",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feiyu Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112207346"
                        ],
                        "name": "Qiong Zhang",
                        "slug": "Qiong-Zhang",
                        "structuredName": {
                            "firstName": "Qiong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36530509"
                        ],
                        "name": "Huasha Zhao",
                        "slug": "Huasha-Zhao",
                        "structuredName": {
                            "firstName": "Huasha",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huasha Zhao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ge types defined in different domains (cf. \u00a73.3). Our model combines text features and layout features to perform entity extraction. 3.2 Pre-trained LM Text Encoder Different from some existing works [19, 28] that encode words or sentences using the standard BiLSTM-CRF[33], we take advantage of pre-trained transformer-based language models influenced by BERT [6, 20] to perform text feature extraction as t"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "by clients, in order to learn the pattern to extract information in the absence of clients. More recently, graph neural networks are used to capture structural information in visually rich documents: [19] applies graph modules to encode the visual information with deep neural networks and GraphIE [28] also assumes that the graph structure is ubiquitous in the text, and applies GCN between the BiLSTM e"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "rmation is encoded into the model as features, such models may require less labeled data to train. A number of pioneering work has noticed the importance of visual features in information extraction: [19] combines the BiLSTM[33] with graph convolution for information extraction from VRDs for scanned images and has shown substantial improvement on performance. [28] introduces GraphIE, which integrates "
                    },
                    "intents": []
                }
            ],
            "corpusId": 85528598,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04df8c70257b5280b9d303502c9d7ddf946f181b",
            "isKey": true,
            "numCitedBy": 86,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Visually rich documents (VRDs) are ubiquitous in daily business and life. Examples are purchase receipts, insurance policy documents, custom declaration forms and so on. In VRDs, visual and layout information is critical for document understanding, and texts in such documents cannot be serialized into the one-dimensional sequence without losing information. Classic information extraction models such as BiLSTM-CRF typically operate on text sequences and do not incorporate visual features. In this paper, we introduce a graph convolution based model to combine textual and visual information presented in VRDs. Graph embeddings are trained to summarize the context of a text segment in the document, and further combined with text embeddings for entity extraction. Extensive experiments have been conducted to show that our method outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets. Additionally, ablation studies are also performed to evaluate the effectiveness of each component of our model."
            },
            "slug": "Graph-Convolution-for-Multimodal-Information-from-Liu-Gao",
            "title": {
                "fragments": [],
                "text": "Graph Convolution for Multimodal Information Extraction from Visually Rich Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper introduces a graph convolution based model to combine textual and visual information presented in VRDs and outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3032611"
                        ],
                        "name": "Yiheng Xu",
                        "slug": "Yiheng-Xu",
                        "structuredName": {
                            "firstName": "Yiheng",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiheng Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123545597"
                        ],
                        "name": "Minghao Li",
                        "slug": "Minghao-Li",
                        "structuredName": {
                            "firstName": "Minghao",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minghao Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500855"
                        ],
                        "name": "Lei Cui",
                        "slug": "Lei-Cui",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Cui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Cui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110003"
                        ],
                        "name": "Shaohan Huang",
                        "slug": "Shaohan-Huang",
                        "structuredName": {
                            "firstName": "Shaohan",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaohan Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49807919"
                        ],
                        "name": "Furu Wei",
                        "slug": "Furu-Wei",
                        "structuredName": {
                            "firstName": "Furu",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Furu Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92660691"
                        ],
                        "name": "Ming Zhou",
                        "slug": "Ming-Zhou",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Zhou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "n (such as coordinates of text boxes), but ignore richer layout semantics that we explore in this work. In addition, these models do not have access to pre-trained language models. Recently, LayoutLM [38] adds layout-informed embeddings in additiontotextembeddingsinpre-trainingtojointlymodeltextand layout information to better utilize visual information in OCR documents. LayoutLM has shown significant"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "as a two-dimensional grid of characters and used a fully convolutional encoder-decoder network to predict the class of all the characters and group them by the predicted item bounding boxes. LayoutLM [38] appends the language model embeddings with 2D grid information of words to jointly pre-train text and layout. These methods rely on the results of OCR and only model with information on the character"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "adapt the graph structure to model the sophisticated layouts and fonts to learn task specific visual features, rather than relying solely on the bounding box positions into the pre-trained model like [38]. 3.3.1 Node-level Features. To convert sentences in one document page to a graph, we define each graph nodevi as the RoBERTa output Ci of a text box along with its fonts encodings. We define font enc"
                    },
                    "intents": []
                }
            ],
            "corpusId": 209515395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3465c06c872d8c48d628c5fc2d484087719351b6",
            "isKey": true,
            "numCitedBy": 164,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Pre-training techniques have been verified successfully in a variety of NLP tasks in recent years. Despite the widespread use of pre-training models for NLP applications, they almost exclusively focus on text-level manipulation, while neglecting layout and style information that is vital for document image understanding. In this paper, we propose the LayoutLM to jointly model interactions between text and layout information across scanned document images, which is beneficial for a great number of real-world document image understanding tasks such as information extraction from scanned documents. Furthermore, we also leverage image features to incorporate words' visual information into LayoutLM. To the best of our knowledge, this is the first time that text and layout are jointly learned in a single framework for document-level pre-training. It achieves new state-of-the-art results in several downstream tasks, including form understanding (from 70.72 to 79.27), receipt understanding (from 94.02 to 95.24) and document image classification (from 93.07 to 94.42). The code and pre-trained LayoutLM models are publicly available at https://aka.ms/layoutlm."
            },
            "slug": "LayoutLM:-Pre-training-of-Text-and-Layout-for-Image-Xu-Li",
            "title": {
                "fragments": [],
                "text": "LayoutLM: Pre-training of Text and Layout for Document Image Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The LayoutLM is proposed to jointly model interactions between text and layout information across scanned document images, which is beneficial for a great number of real-world document image understanding tasks such as information extraction from scanned documents."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38909097"
                        ],
                        "name": "Alec Radford",
                        "slug": "Alec-Radford",
                        "structuredName": {
                            "firstName": "Alec",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alec Radford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144958935"
                        ],
                        "name": "Karthik Narasimhan",
                        "slug": "Karthik-Narasimhan",
                        "structuredName": {
                            "firstName": "Karthik",
                            "lastName": "Narasimhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karthik Narasimhan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 76
                            }
                        ],
                        "text": "After pre-training from massive text data with language modeling objectives [12, 27, 29], the encoder could learn high-level dependencies between tokens and then feed the representations to downstream tasks to perform transfer learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 49313245,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "isKey": false,
            "numCitedBy": 3533,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classi\ufb01cation. Although large unlabeled text corpora are abundant, labeled data for learning these speci\ufb01c tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative \ufb01ne-tuning on each speci\ufb01c task. In contrast to previous approaches, we make use of task-aware input transformations during \ufb01ne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, signi\ufb01cantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI)."
            },
            "slug": "Improving-Language-Understanding-by-Generative-Radford-Narasimhan",
            "title": {
                "fragments": [],
                "text": "Improving Language Understanding by Generative Pre-Training"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, improving upon the state of the art in 9 out of the 12 tasks studied."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093348519"
                        ],
                        "name": "Jeremy Howard",
                        "slug": "Jeremy-Howard",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Howard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeremy Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884561"
                        ],
                        "name": "Sebastian Ruder",
                        "slug": "Sebastian-Ruder",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Ruder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Ruder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 75
                            }
                        ],
                        "text": "After pre-training frommassive text data with language modeling objectives [12, 27, 29], the encoder could learn high-level dependencies between tokens and then feed the representations to downstream tasks to perform transfer learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40100965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e077413b25c4d34945cc2707e17e46ed4fe784a",
            "isKey": false,
            "numCitedBy": 2251,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100 times more data. We open-source our pretrained models and code."
            },
            "slug": "Universal-Language-Model-Fine-tuning-for-Text-Howard-Ruder",
            "title": {
                "fragments": [],
                "text": "Universal Language Model Fine-tuning for Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduces techniques that are key for fine- Tuning a language model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50677785"
                        ],
                        "name": "Bang Liu",
                        "slug": "Bang-Liu",
                        "structuredName": {
                            "firstName": "Bang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146320540"
                        ],
                        "name": "Ting Zhang",
                        "slug": "Ting-Zhang",
                        "structuredName": {
                            "firstName": "Ting",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ting Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714907"
                        ],
                        "name": "Di Niu",
                        "slug": "Di-Niu",
                        "structuredName": {
                            "firstName": "Di",
                            "lastName": "Niu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Di Niu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8920573"
                        ],
                        "name": "Jinghong Lin",
                        "slug": "Jinghong-Lin",
                        "structuredName": {
                            "firstName": "Jinghong",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinghong Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2710113"
                        ],
                        "name": "Kunfeng Lai",
                        "slug": "Kunfeng-Lai",
                        "structuredName": {
                            "firstName": "Kunfeng",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kunfeng Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110164912"
                        ],
                        "name": "Yu Xu",
                        "slug": "Yu-Xu",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[18] models and matches long article through a graph convolutional network to identify the relationship between two articles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3403413,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bd17d682a901ad5d25e1aafbb10b7735f168a7b",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Identifying the relationship between two text objects is a core research problem underlying many natural language processing tasks. A wide range of deep learning schemes have been proposed for text matching, mainly focusing on sentence matching, question answering or query document matching. We point out that existing approaches do not perform well at matching long documents, which is critical, for example, to AI-based news article understanding and event or story formation. The reason is that these methods either omit or fail to fully utilize complicated semantic structures in long documents. In this paper, we propose a graph approach to text matching, especially targeting long document matching, such as identifying whether two news articles report the same event in the real world, possibly with different narratives. We propose the Concept Interaction Graph to yield a graph representation for a document, with vertices representing different concepts, each being one or a group of coherent keywords in the document, and with edges representing the interactions between different concepts, connected by sentences in the document. Based on the graph representation of document pairs, we further propose a Siamese Encoded Graph Convolutional Network that learns vertex representations through a Siamese neural network and aggregates the vertex features though Graph Convolutional Networks to generate the matching result. Extensive evaluation of the proposed approach based on two labeled news article datasets created at Tencent for its intelligent news products show that the proposed graph approach to long document matching significantly outperforms a wide range of state-of-the-art methods."
            },
            "slug": "Matching-Long-Text-Documents-via-Graph-Networks-Liu-Zhang",
            "title": {
                "fragments": [],
                "text": "Matching Long Text Documents via Graph Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Extensive evaluation of the proposed approach based on two labeled news article datasets created at Tencent for its intelligent news products show that the proposed graph approach to long document matching significantly outperforms a wide range of state-of-the-art methods."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153374"
                        ],
                        "name": "Stephen Mayhew",
                        "slug": "Stephen-Mayhew",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Mayhew",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Mayhew"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2285178"
                        ],
                        "name": "Nitish Gupta",
                        "slug": "Nitish-Gupta",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nitish Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[22] comes up with a pre-training objective predicts casing in the text to address the robustness problem for named entity recognition (NER) systems and [23] introduces four different pre-training objectives for dialog context representation learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 209376564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "738c94c17ce3f894a0068c12cab9df696d978b0a",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Although modern named entity recognition (NER) systems show impressive performance on standard datasets, they perform poorly when presented with noisy data. In particular, capitalization is a strong signal for entities in many languages, and even state of the art models overfit to this feature, with drastically lower performance on uncapitalized text. In this work, we address the problem of robustness of NER systems in data with noisy or uncertain casing, using a pretraining objective that predicts casing in text, or a truecaser, leveraging unlabeled data. The pretrained truecaser is combined with a standard BiLSTM-CRF model for NER by appending output distributions to character embeddings. In experiments over several datasets of varying domain and casing quality, we show that our new model improves performance in uncased text, even adding value to uncased BERT embeddings. Our method achieves a new state of the art on the WNUT17 shared task dataset."
            },
            "slug": "Robust-Named-Entity-Recognition-with-Truecasing-Mayhew-Gupta",
            "title": {
                "fragments": [],
                "text": "Robust Named Entity Recognition with Truecasing Pretraining"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work addresses the problem of robustness of NER systems in data with noisy or uncertain casing, using a pretraining objective that predicts casing in text, or a truecaser, leveraging unlabeled data."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482533"
                        ],
                        "name": "Mo Yu",
                        "slug": "Mo-Yu",
                        "structuredName": {
                            "firstName": "Mo",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mo Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1955964"
                        ],
                        "name": "Xiaoxiao Guo",
                        "slug": "Xiaoxiao-Guo",
                        "structuredName": {
                            "firstName": "Xiaoxiao",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoxiao Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2882166"
                        ],
                        "name": "Jinfeng Yi",
                        "slug": "Jinfeng-Yi",
                        "structuredName": {
                            "firstName": "Jinfeng",
                            "lastName": "Yi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinfeng Yi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3307026"
                        ],
                        "name": "Shiyu Chang",
                        "slug": "Shiyu-Chang",
                        "structuredName": {
                            "firstName": "Shiyu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shiyu Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3543187"
                        ],
                        "name": "Saloni Potdar",
                        "slug": "Saloni-Potdar",
                        "structuredName": {
                            "firstName": "Saloni",
                            "lastName": "Potdar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saloni Potdar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145215470"
                        ],
                        "name": "Yu Cheng",
                        "slug": "Yu-Cheng",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699108"
                        ],
                        "name": "G. Tesauro",
                        "slug": "G.-Tesauro",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Tesauro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tesauro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48016687"
                        ],
                        "name": "Haoyu Wang",
                        "slug": "Haoyu-Wang",
                        "structuredName": {
                            "firstName": "Haoyu",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haoyu Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145218984"
                        ],
                        "name": "Bowen Zhou",
                        "slug": "Bowen-Zhou",
                        "structuredName": {
                            "firstName": "Bowen",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bowen Zhou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For NLP, [39] proposes an adaptive metric learning approach to automatically assign weights for newly seen few-shot task and [9] uses a few-shot learning method that leverages the dynamic routing algorithm in meta-learning for intention recognition in conversation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29162291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b868f044146a91dec16a579ffb0802b431e97a3",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We study few-shot learning in natural language domains. Compared to many existing works that apply either metric-based or optimization-based meta-learning to image domain with low inter-task variance, we consider a more realistic setting, where tasks are diverse. However, it imposes tremendous difficulties to existing state-of-the-art metric-based algorithms since a single metric is insufficient to capture complex task variations in natural language domain. To alleviate the problem, we propose an adaptive metric learning approach that automatically determines the best weighted combination from a set of metrics obtained from meta-training tasks for a newly seen few-shot task. Extensive quantitative evaluations on real-world sentiment analysis and dialog intent classification datasets demonstrate that the proposed method performs favorably against state-of-the-art few shot learning algorithms in terms of predictive accuracy. We make our code and data available for further study."
            },
            "slug": "Diverse-Few-Shot-Text-Classification-with-Multiple-Yu-Guo",
            "title": {
                "fragments": [],
                "text": "Diverse Few-Shot Text Classification with Multiple Metrics"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes an adaptive metric learning approach that automatically determines the best weighted combination from a set of metrics obtained from meta-training tasks for a newly seen few-shot task."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022957"
                        ],
                        "name": "Diego Marcheggiani",
                        "slug": "Diego-Marcheggiani",
                        "structuredName": {
                            "firstName": "Diego",
                            "lastName": "Marcheggiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diego Marcheggiani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144889265"
                        ],
                        "name": "Ivan Titov",
                        "slug": "Ivan-Titov",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Titov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivan Titov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[21] encodes sentences with GCN for semantic role labeling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16839291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3a3c163f25b9181f1fb7e71a32482a7393d2088",
            "isKey": false,
            "numCitedBy": 608,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic role labeling (SRL) is the task of identifying the predicate-argument structure of a sentence. It is typically regarded as an important step in the standard NLP pipeline. As the semantic representations are closely related to syntactic ones, we exploit syntactic information in our model. We propose a version of graph convolutional networks (GCNs), a recent class of neural networks operating on graphs, suited to model syntactic dependency graphs. GCNs over syntactic dependency trees are used as sentence encoders, producing latent feature representations of words in a sentence. We observe that GCN layers are complementary to LSTM ones: when we stack both GCN and LSTM layers, we obtain a substantial improvement over an already state-of-the-art LSTM SRL model, resulting in the best reported scores on the standard benchmark (CoNLL-2009) both for Chinese and English."
            },
            "slug": "Encoding-Sentences-with-Graph-Convolutional-for-Marcheggiani-Titov",
            "title": {
                "fragments": [],
                "text": "Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A version of graph convolutional networks (GCNs), a recent class of neural networks operating on graphs, suited to model syntactic dependency graphs, is proposed, observing that GCN layers are complementary to LSTM ones."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9706609"
                        ],
                        "name": "Ruiying Geng",
                        "slug": "Ruiying-Geng",
                        "structuredName": {
                            "firstName": "Ruiying",
                            "lastName": "Geng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruiying Geng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66200440"
                        ],
                        "name": "Binhua Li",
                        "slug": "Binhua-Li",
                        "structuredName": {
                            "firstName": "Binhua",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Binhua Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1527090216"
                        ],
                        "name": "Yongbin Li",
                        "slug": "Yongbin-Li",
                        "structuredName": {
                            "firstName": "Yongbin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongbin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150345740"
                        ],
                        "name": "Xiaodan Zhu",
                        "slug": "Xiaodan-Zhu",
                        "structuredName": {
                            "firstName": "Xiaodan",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodan Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46302667"
                        ],
                        "name": "Ping Jian",
                        "slug": "Ping-Jian",
                        "structuredName": {
                            "firstName": "Ping",
                            "lastName": "Jian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ping Jian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 202776447,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8aa1ce58e74e77663c49036651793e5421db16c3",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Text classification tends to struggle when data is deficient or when it needs to adapt to unseen classes. In such challenging scenarios, recent studies have used meta-learning to simulate the few-shot task, in which new queries are compared to a small support set at the sample-wise level. However, this sample-wise comparison may be severely disturbed by the various expressions in the same class. Therefore, we should be able to learn a general representation of each class in the support set and then compare it to new queries. In this paper, we propose a novel Induction Network to learn such a generalized class-wise representation, by innovatively leveraging the dynamic routing algorithm in meta-learning. In this way, we find the model is able to induce and generalize better. We evaluate the proposed model on a well-studied sentiment classification dataset (English) and a real-world dialogue intent classification dataset (Chinese). Experiment results show that on both datasets, the proposed model significantly outperforms the existing state-of-the-art approaches, proving the effectiveness of class-wise generalization in few-shot text classification."
            },
            "slug": "Induction-Networks-for-Few-Shot-Text-Classification-Geng-Li",
            "title": {
                "fragments": [],
                "text": "Induction Networks for Few-Shot Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a novel Induction Network to learn a generalized class-wise representation of each class in the support set, by innovatively leveraging the dynamic routing algorithm in meta-learning and finds the model is able to induce and generalize better."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41020222"
                        ],
                        "name": "Tsu-Jui Fu",
                        "slug": "Tsu-Jui-Fu",
                        "structuredName": {
                            "firstName": "Tsu-Jui",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsu-Jui Fu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24899768"
                        ],
                        "name": "Peng-Hsuan Li",
                        "slug": "Peng-Hsuan-Li",
                        "structuredName": {
                            "firstName": "Peng-Hsuan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng-Hsuan Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749660"
                        ],
                        "name": "Wei-Yun Ma",
                        "slug": "Wei-Yun-Ma",
                        "structuredName": {
                            "firstName": "Wei-Yun",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Yun Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ve attracted increasing attention. GCN[16]modelsgraph-structureddatabasedonanefficientvariant of convolutional neural networks, which has been proved effective in many NLP tasks. For example, GraphRel[8] uses a Bi-GCN (a) Invoice (b) Resume (c) Job Ad Figure 1: Digital-born documents of different fields in industry. Contents are fictional. to better extract relations by jointly learning named entitie"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 196211486,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6acacb9c81e67b50b218d173cb4022a1a5859191",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present GraphRel, an end-to-end relation extraction model which uses graph convolutional networks (GCNs) to jointly learn named entities and relations. In contrast to previous baselines, we consider the interaction between named entities and relations via a 2nd-phase relation-weighted GCN to better extract relations. Linear and dependency structures are both used to extract both sequential and regional features of the text, and a complete word graph is further utilized to extract implicit features among all word pairs of the text. With the graph-based approach, the prediction for overlapping relations is substantially improved over previous sequential approaches. We evaluate GraphRel on two public datasets: NYT and WebNLG. Results show that GraphRel maintains high precision while increasing recall substantially. Also, GraphRel outperforms previous work by 3.2% and 5.8% (F1 score), achieving a new state-of-the-art for relation extraction."
            },
            "slug": "GraphRel:-Modeling-Text-as-Relational-Graphs-for-Fu-Li",
            "title": {
                "fragments": [],
                "text": "GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "GraphRel, an end-to-end relation extraction model which uses graph convolutional networks (GCNs) to jointly learn named entities and relations, outperforms previous work by 3.2% and 5.8% and achieves a new state-of-the-art for relation extraction."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403698986"
                        ],
                        "name": "Rik Koncel-Kedziorski",
                        "slug": "Rik-Koncel-Kedziorski",
                        "structuredName": {
                            "firstName": "Rik",
                            "lastName": "Koncel-Kedziorski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rik Koncel-Kedziorski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "93836311"
                        ],
                        "name": "Dhanush Bekal",
                        "slug": "Dhanush-Bekal",
                        "structuredName": {
                            "firstName": "Dhanush",
                            "lastName": "Bekal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dhanush Bekal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081697"
                        ],
                        "name": "Yi Luan",
                        "slug": "Yi-Luan",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Luan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Luan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2548384"
                        ],
                        "name": "Hannaneh Hajishirzi",
                        "slug": "Hannaneh-Hajishirzi",
                        "structuredName": {
                            "firstName": "Hannaneh",
                            "lastName": "Hajishirzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hannaneh Hajishirzi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We also experiment with GAT[35] and G-Trans[17] layers in initial experiments, but results show worse performance than GCN."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Then Graph Transformers[17] present an end-to-end system for graph-to-text generation from knowledge graphs with multi-head attention inspired by transformers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 102354588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb15c1c51e8a7da42d5b2ebac955bf1cd9dd4022",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods."
            },
            "slug": "Text-Generation-from-Knowledge-Graphs-with-Graph-Koncel-Kedziorski-Bekal",
            "title": {
                "fragments": [],
                "text": "Text Generation from Knowledge Graphs with Graph Transformers"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work addresses the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph by introducing a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9706609"
                        ],
                        "name": "Ruiying Geng",
                        "slug": "Ruiying-Geng",
                        "structuredName": {
                            "firstName": "Ruiying",
                            "lastName": "Geng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruiying Geng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66200440"
                        ],
                        "name": "Binhua Li",
                        "slug": "Binhua-Li",
                        "structuredName": {
                            "firstName": "Binhua",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Binhua Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1527090216"
                        ],
                        "name": "Yongbin Li",
                        "slug": "Yongbin-Li",
                        "structuredName": {
                            "firstName": "Yongbin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongbin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47107411"
                        ],
                        "name": "Yuxiao Ye",
                        "slug": "Yuxiao-Ye",
                        "structuredName": {
                            "firstName": "Yuxiao",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuxiao Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46302667"
                        ],
                        "name": "Ping Jian",
                        "slug": "Ping-Jian",
                        "structuredName": {
                            "firstName": "Ping",
                            "lastName": "Jian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ping Jian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "For NLP, [39] proposes an adaptive metric learning approach to automatically assign weights for newly seen few-shot task and [9] uses a few-shot learning method that leverages the dynamic routing algorithm in meta-learning for intention recognition in conversation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 67856277,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f444b8a665ec8045e61775dd7ab6e9930e3bdf4",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Text classification tends to struggle when data is deficient or when it needs to adapt to unseen classes. In such challenging scenarios, recent studies often use meta learning to simulate the few-shot task, in which new queries are compared to a small support set on a sample-wise level. However, this sample-wise comparison may be severely disturbed by the various expressions in the same class. Therefore, we should be able to learn a general representation of each class in the support set and then compare it to new queries. In this paper, we propose a novel Induction Network to learn such generalized class-wise representations, innovatively combining the dynamic routing algorithm with the typical meta learning framework. In this way, our model is able to induce from particularity to university, which is a more human-like learning approach. We evaluate our model on a well-studied sentiment classification dataset (English) and a real-world dialogue intent classification dataset (Chinese). Experiment results show that, on both datasets, our model significantly outperforms existing state-of-the-art models and improves the average accuracy by more than 3%, which proves the effectiveness of class-wise generalization in few-shot text classification."
            },
            "slug": "Few-Shot-Text-Classification-with-Induction-Network-Geng-Li",
            "title": {
                "fragments": [],
                "text": "Few-Shot Text Classification with Induction Network"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel Induction Network is proposed to learn generalized class-wise representations in few-shot text classification, innovatively combining the dynamic routing algorithm with the typical meta learning framework, and is able to induce from particularity to university, which is a more human-like learning approach."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7648396"
                        ],
                        "name": "Bang Liu",
                        "slug": "Bang-Liu",
                        "structuredName": {
                            "firstName": "Bang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714907"
                        ],
                        "name": "Di Niu",
                        "slug": "Di-Niu",
                        "structuredName": {
                            "firstName": "Di",
                            "lastName": "Niu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Di Niu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109393901"
                        ],
                        "name": "Haojie Wei",
                        "slug": "Haojie-Wei",
                        "structuredName": {
                            "firstName": "Haojie",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haojie Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8920573"
                        ],
                        "name": "Jinghong Lin",
                        "slug": "Jinghong-Lin",
                        "structuredName": {
                            "firstName": "Jinghong",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinghong Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49990515"
                        ],
                        "name": "Yancheng He",
                        "slug": "Yancheng-He",
                        "structuredName": {
                            "firstName": "Yancheng",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yancheng He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2710113"
                        ],
                        "name": "Kunfeng Lai",
                        "slug": "Kunfeng-Lai",
                        "structuredName": {
                            "firstName": "Kunfeng",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kunfeng Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110164912"
                        ],
                        "name": "Yu Xu",
                        "slug": "Yu-Xu",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 167217689,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0fdddc750f58373ad6b1e30660812ef9903b7fe",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Identifying the relationship between two articles, e.g., whether two articles published from different sources describe the same breaking news, is critical to many document understanding tasks. Existing approaches for modeling and matching sentence pairs do not perform well in matching longer documents, which embody more complex interactions between the enclosed entities than a sentence does. To model article pairs, we propose the Concept Interaction Graph to represent an article as a graph of concepts. We then match a pair of articles by comparing the sentences that enclose the same concept vertex through a series of encoding techniques, and aggregate the matching signals through a graph convolutional network. To facilitate the evaluation of long article matching, we have created two datasets, each consisting of about 30K pairs of breaking news articles covering diverse topics in the open domain. Extensive evaluations of the proposed methods on the two datasets demonstrate significant improvements over a wide range of state-of-the-art methods for natural language matching."
            },
            "slug": "Matching-Article-Pairs-with-Graphical-Decomposition-Liu-Niu",
            "title": {
                "fragments": [],
                "text": "Matching Article Pairs with Graphical Decomposition and Convolutions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "To model article pairs, the Concept Interaction Graph is proposed to represent an article as a graph of concepts to match a pair of articles by comparing the sentences that enclose the same concept vertex through a series of encoding techniques, and aggregate the matching signals through a graph convolutional network."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39172707"
                        ],
                        "name": "Jacob Devlin",
                        "slug": "Jacob-Devlin",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Devlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob Devlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744179"
                        ],
                        "name": "Ming-Wei Chang",
                        "slug": "Ming-Wei-Chang",
                        "structuredName": {
                            "firstName": "Ming-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544107"
                        ],
                        "name": "Kenton Lee",
                        "slug": "Kenton-Lee",
                        "structuredName": {
                            "firstName": "Kenton",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenton Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259253"
                        ],
                        "name": "Kristina Toutanova",
                        "slug": "Kristina-Toutanova",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanova"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Different from some existing works [19, 28] that encode words or sentences using the standard BiLSTM-CRF[33], we take advantage of pre-trained transformer-based language models influenced by BERT [6, 20] to perform text feature extraction as they are much more expressive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Since BERT [6] achieved SOTA performances on a range of NLP tasks, there has been much more attention on pre-training with large amounts of unlabeled data to produce powerful contextual representations for downstream tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our baseline text encoder is based on pre-trained transformer-based [6] language models that"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52967399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "isKey": false,
            "numCitedBy": 33744,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
            },
            "slug": "BERT:-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang",
            "title": {
                "fragments": [],
                "text": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A new language representation model, BERT, designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers, which can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5606742"
                        ],
                        "name": "Yujie Qian",
                        "slug": "Yujie-Qian",
                        "structuredName": {
                            "firstName": "Yujie",
                            "lastName": "Qian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yujie Qian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2628786"
                        ],
                        "name": "Enrico Santus",
                        "slug": "Enrico-Santus",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Santus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Enrico Santus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8752221"
                        ],
                        "name": "Zhijing Jin",
                        "slug": "Zhijing-Jin",
                        "structuredName": {
                            "firstName": "Zhijing",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhijing Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144084849"
                        ],
                        "name": "Jiang Guo",
                        "slug": "Jiang-Guo",
                        "structuredName": {
                            "firstName": "Jiang",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiang Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Different from some existing works [19, 28] that encode words or sentences using the standard BiLSTM-CRF[33], we take advantage of pre-trained transformer-based language models influenced by BERT [6, 20] to perform text feature extraction as they are much more expressive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "More recently, graph neural networks are used to capture structural information in visually rich documents: [19] applies graph modules to encode the visual information with deep neural networks and GraphIE [28] also assumes that the graph structure is ubiquitous in the text, and applies GCN between the BiLSTM encoder-decoder structure to model the layout information in the document."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[28] introduces GraphIE, which integrates Graph Convolutional Network (GCN [16]) with Bi-LSTM for sequence tagging and uses the GCN to encode visual features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53109320,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1da8e1ad1814d81f69433ac877ef70caa950e4e6",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Most modern Information Extraction (IE) systems are implemented as sequential taggers and only model local dependencies. Non-local and non-sequential context is, however, a valuable source of information to improve predictions. In this paper, we introduce GraphIE, a framework that operates over a graph representing a broad set of dependencies between textual units (i.e. words or sentences). The algorithm propagates information between connected nodes through graph convolutions, generating a richer representation that can be exploited to improve word-level predictions. Evaluation on three different tasks \u2014 namely textual, social media and visual information extraction \u2014 shows that GraphIE consistently outperforms the state-of-the-art sequence tagging model by a significant margin."
            },
            "slug": "GraphIE:-A-Graph-Based-Framework-for-Information-Qian-Santus",
            "title": {
                "fragments": [],
                "text": "GraphIE: A Graph-Based Framework for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Evaluation on three different tasks shows that GraphIE consistently outperforms the state-of-the-art sequence tagging model by a significant margin, and generates a richer representation that can be exploited to improve word-level predictions."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51941200"
                        ],
                        "name": "Ashutosh Adhikari",
                        "slug": "Ashutosh-Adhikari",
                        "structuredName": {
                            "firstName": "Ashutosh",
                            "lastName": "Adhikari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashutosh Adhikari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46253949"
                        ],
                        "name": "Achyudh Ram",
                        "slug": "Achyudh-Ram",
                        "structuredName": {
                            "firstName": "Achyudh",
                            "lastName": "Ram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Achyudh Ram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26917433"
                        ],
                        "name": "Raphael Tang",
                        "slug": "Raphael-Tang",
                        "structuredName": {
                            "firstName": "Raphael",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raphael Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145580839"
                        ],
                        "name": "Jimmy J. Lin",
                        "slug": "Jimmy-J.-Lin",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Lin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy J. Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 135
                            }
                        ],
                        "text": "As it is pre-trained on a large corpus with a large number of parameters, BERT-like language model has shown excellent transferability [1, 25, 26]: downstream tasks can often achieve high accuracy even if the data size of the specific task is not large enough, when the models are initialized with pre-trained BERT weights."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118697759,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a9954d86466a7e4de6f98ddee452ceb50e15d86",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present, to our knowledge, the first application of BERT to document classification. A few characteristics of the task might lead one to think that BERT is not the most appropriate model: syntactic structures matter less for content categories, documents can often be longer than typical BERT input, and documents often have multiple labels. Nevertheless, we show that a straightforward classification model using BERT is able to achieve the state of the art across four popular datasets. To address the computational expense associated with BERT inference, we distill knowledge from BERT-large to small bidirectional LSTMs, reaching BERT-base parity on multiple datasets using 30x fewer parameters. The primary contribution of our paper is improved baselines that can provide the foundation for future work."
            },
            "slug": "DocBERT:-BERT-for-Document-Classification-Adhikari-Ram",
            "title": {
                "fragments": [],
                "text": "DocBERT: BERT for Document Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that a straightforward classification model using BERT is able to achieve the state of the art across four popular datasets, and distill knowledge from BERT-large to small bidirectional LSTMs, reaching Bert-base parity on multiple datasets using 30x fewer parameters."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143744603"
                        ],
                        "name": "Rodrigo Nogueira",
                        "slug": "Rodrigo-Nogueira",
                        "structuredName": {
                            "firstName": "Rodrigo",
                            "lastName": "Nogueira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rodrigo Nogueira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 135
                            }
                        ],
                        "text": "As it is pre-trained on a large corpus with a large number of parameters, BERT-like language model has shown excellent transferability [1, 25, 26]: downstream tasks can often achieve high accuracy even if the data size of the specific task is not large enough, when the models are initialized with pre-trained BERT weights."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58004692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85e07116316e686bf787114ba10ca60f4ea7c5b2",
            "isKey": false,
            "numCitedBy": 523,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, neural models pretrained on a language modeling task, such as ELMo (Peters et al., 2017), OpenAI GPT (Radford et al., 2018), and BERT (Devlin et al., 2018), have achieved impressive results on various natural language processing tasks such as question-answering and natural language inference. In this paper, we describe a simple re-implementation of BERT for query-based passage re-ranking. Our system is the state of the art on the TREC-CAR dataset and the top entry in the leaderboard of the MS MARCO passage retrieval task, outperforming the previous state of the art by 27% (relative) in MRR@10. The code to reproduce our results is available at this https URL"
            },
            "slug": "Passage-Re-ranking-with-BERT-Nogueira-Cho",
            "title": {
                "fragments": [],
                "text": "Passage Re-ranking with BERT"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A simple re-implementation of BERT for query-based passage re-ranking on the TREC-CAR dataset and the top entry in the leaderboard of the MS MARCO passage retrieval task, outperforming the previous state of the art by 27% in MRR@10."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39139825"
                        ],
                        "name": "Matthew E. Peters",
                        "slug": "Matthew-E.-Peters",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Peters",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew E. Peters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50043859"
                        ],
                        "name": "Mark Neumann",
                        "slug": "Mark-Neumann",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136562"
                        ],
                        "name": "Mohit Iyyer",
                        "slug": "Mohit-Iyyer",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Iyyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Iyyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40642935"
                        ],
                        "name": "Matt Gardner",
                        "slug": "Matt-Gardner",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Gardner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt Gardner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143997772"
                        ],
                        "name": "Christopher Clark",
                        "slug": "Christopher-Clark",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544107"
                        ],
                        "name": "Kenton Lee",
                        "slug": "Kenton-Lee",
                        "structuredName": {
                            "firstName": "Kenton",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenton Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "After pre-training from massive text data with language modeling objectives [12, 27, 29], the encoder could learn high-level dependencies between tokens and then feed the representations to downstream tasks to perform transfer learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3626819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3febb2bed8865945e7fddc99efd791887bb7e14f",
            "isKey": false,
            "numCitedBy": 7987,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals."
            },
            "slug": "Deep-Contextualized-Word-Representations-Peters-Neumann",
            "title": {
                "fragments": [],
                "text": "Deep Contextualized Word Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new type of deep contextualized word representation is introduced that models both complex characteristics of word use and how these uses vary across linguistic contexts, allowing downstream models to mix different types of semi-supervision signals."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719068"
                        ],
                        "name": "Anoop R. Katti",
                        "slug": "Anoop-R.-Katti",
                        "structuredName": {
                            "firstName": "Anoop",
                            "lastName": "Katti",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anoop R. Katti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9992847"
                        ],
                        "name": "C. Reisswig",
                        "slug": "C.-Reisswig",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Reisswig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Reisswig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39387393"
                        ],
                        "name": "Cordula Guder",
                        "slug": "Cordula-Guder",
                        "structuredName": {
                            "firstName": "Cordula",
                            "lastName": "Guder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cordula Guder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14334250"
                        ],
                        "name": "Sebastian Brarda",
                        "slug": "Sebastian-Brarda",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Brarda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Brarda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2704747"
                        ],
                        "name": "S. Bickel",
                        "slug": "S.-Bickel",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Bickel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2216963"
                        ],
                        "name": "J. H\u00f6hne",
                        "slug": "J.-H\u00f6hne",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "H\u00f6hne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H\u00f6hne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2803968"
                        ],
                        "name": "J. Faddoul",
                        "slug": "J.-Faddoul",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Faddoul",
                            "middleNames": [
                                "Baptiste"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Faddoul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Chargrid [14] models the problem by encoding each document page as a two-dimensional grid of characters and used a fully convolutional encoder-decoder network to predict the class of all the characters and group them by the predicted item bounding boxes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52815006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15aae08159856cdbf0ce539357d473a04dcbb7f3",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel type of text representation that preserves the 2D layout of a document. This is achieved by encoding each document page as a two-dimensional grid of characters. Based on this representation, we present a generic document understanding pipeline for structured documents. This pipeline makes use of a fully convolutional encoder-decoder network that predicts a segmentation mask and bounding boxes. We demonstrate its capabilities on an information extraction task from invoices and show that it significantly outperforms approaches based on sequential text or document images."
            },
            "slug": "Chargrid:-Towards-Understanding-2D-Documents-Katti-Reisswig",
            "title": {
                "fragments": [],
                "text": "Chargrid: Towards Understanding 2D Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A novel type of text representation is introduced that preserves the 2D layout of a document by encoding each document page as a two-dimensional grid of characters and it is shown that it significantly outperforms approaches based on sequential text or document images."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723876"
                        ],
                        "name": "C. Blundell",
                        "slug": "C.-Blundell",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Blundell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Blundell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542999"
                        ],
                        "name": "T. Lillicrap",
                        "slug": "T.-Lillicrap",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Lillicrap",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lillicrap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[36]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8909022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6",
            "isKey": false,
            "numCitedBy": 3736,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank."
            },
            "slug": "Matching-Networks-for-One-Shot-Learning-Vinyals-Blundell",
            "title": {
                "fragments": [],
                "text": "Matching Networks for One Shot Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work employs ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories to learn a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40348417"
                        ],
                        "name": "Ashish Vaswani",
                        "slug": "Ashish-Vaswani",
                        "structuredName": {
                            "firstName": "Ashish",
                            "lastName": "Vaswani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashish Vaswani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846258"
                        ],
                        "name": "Noam M. Shazeer",
                        "slug": "Noam-M.-Shazeer",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Shazeer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam M. Shazeer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3877127"
                        ],
                        "name": "Niki Parmar",
                        "slug": "Niki-Parmar",
                        "structuredName": {
                            "firstName": "Niki",
                            "lastName": "Parmar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Niki Parmar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39328010"
                        ],
                        "name": "Jakob Uszkoreit",
                        "slug": "Jakob-Uszkoreit",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Uszkoreit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Uszkoreit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145024664"
                        ],
                        "name": "Llion Jones",
                        "slug": "Llion-Jones",
                        "structuredName": {
                            "firstName": "Llion",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llion Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19177000"
                        ],
                        "name": "Aidan N. Gomez",
                        "slug": "Aidan-N.-Gomez",
                        "structuredName": {
                            "firstName": "Aidan",
                            "lastName": "Gomez",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aidan N. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3443442"
                        ],
                        "name": "Illia Polosukhin",
                        "slug": "Illia-Polosukhin",
                        "structuredName": {
                            "firstName": "Illia",
                            "lastName": "Polosukhin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Illia Polosukhin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The BERT model is based on the multi-layer bidirectional transformer [34] architecture that effectively encodes a sequence of tokens to produce final representations of the text."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13756489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "isKey": false,
            "numCitedBy": 35148,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
            },
            "slug": "Attention-is-All-you-Need-Vaswani-Shazeer",
            "title": {
                "fragments": [],
                "text": "Attention is All you Need"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely is proposed, which generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50335211"
                        ],
                        "name": "Thomas Wolf",
                        "slug": "Thomas-Wolf",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1380459402"
                        ],
                        "name": "Lysandre Debut",
                        "slug": "Lysandre-Debut",
                        "structuredName": {
                            "firstName": "Lysandre",
                            "lastName": "Debut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lysandre Debut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51918868"
                        ],
                        "name": "Victor Sanh",
                        "slug": "Victor-Sanh",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Sanh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Sanh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40811585"
                        ],
                        "name": "Julien Chaumond",
                        "slug": "Julien-Chaumond",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Chaumond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julien Chaumond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40899333"
                        ],
                        "name": "Clement Delangue",
                        "slug": "Clement-Delangue",
                        "structuredName": {
                            "firstName": "Clement",
                            "lastName": "Delangue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clement Delangue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1382164294"
                        ],
                        "name": "Anthony Moi",
                        "slug": "Anthony-Moi",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Moi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Moi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1382164165"
                        ],
                        "name": "Pierric Cistac",
                        "slug": "Pierric-Cistac",
                        "structuredName": {
                            "firstName": "Pierric",
                            "lastName": "Cistac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierric Cistac"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1382164170"
                        ],
                        "name": "T. Rault",
                        "slug": "T.-Rault",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Rault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rault"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2185329"
                        ],
                        "name": "R\u00e9mi Louf",
                        "slug": "R\u00e9mi-Louf",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Louf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9mi Louf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97662964"
                        ],
                        "name": "Morgan Funtowicz",
                        "slug": "Morgan-Funtowicz",
                        "structuredName": {
                            "firstName": "Morgan",
                            "lastName": "Funtowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Morgan Funtowicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1383218348"
                        ],
                        "name": "Jamie Brew",
                        "slug": "Jamie-Brew",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Brew",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jamie Brew"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "input and encoder backbone with our method and we reimplement themwith the PyTorch Transformers package [37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 204509627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fa9ed2bea208511ae698a967875e943049f16b6",
            "isKey": false,
            "numCitedBy": 2727,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. \\textit{Transformers} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. \\textit{Transformers} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at \\url{this https URL}."
            },
            "slug": "HuggingFace's-Transformers:-State-of-the-art-Wolf-Debut",
            "title": {
                "fragments": [],
                "text": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The \\textit{Transformers} library is an open-source library that consists of carefully engineered state-of-the art Transformer architectures under a unified API and a curated collection of pretrained models made by and available for the community."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401920887"
                        ],
                        "name": "V. P. d'Andecy",
                        "slug": "V.-P.-d'Andecy",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "d'Andecy",
                            "middleNames": [
                                "Poulain"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. P. d'Andecy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409412721"
                        ],
                        "name": "Emmanuel Hartmann",
                        "slug": "Emmanuel-Hartmann",
                        "structuredName": {
                            "firstName": "Emmanuel",
                            "lastName": "Hartmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emmanuel Hartmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143823474"
                        ],
                        "name": "Mar\u00e7al Rusi\u00f1ol",
                        "slug": "Mar\u00e7al-Rusi\u00f1ol",
                        "structuredName": {
                            "firstName": "Mar\u00e7al",
                            "lastName": "Rusi\u00f1ol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mar\u00e7al Rusi\u00f1ol"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ress of the approaches on this problem into three categories. The first category is rule-based systems. [30] describes an invoice extraction system using a number of rules and empirical features, and [5] builds a more stable system using tf-idf algorithm and a large number of human-designed features. Other document-level entity extraction systems combine rules and statistical models [2, 32]. Although"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 49415870,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "631971c31f5ff9b2ab645d9d748c379205f79df6",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an incremental frame-work for extracting information fields from administrative documents. First, we demonstrate some limits of the existing state-of-the-art methods such as the delay of the system efficiency. This is a concern in industrial context when we have only few samples of each document class. Based on this analysis, we propose a hybrid system combining incremental learning by means of itf-df statistics and a-priori generic models. We report in the experimental section our results obtained with a dataset of real invoices."
            },
            "slug": "Field-Extraction-by-Hybrid-Incremental-and-A-Priori-d'Andecy-Hartmann",
            "title": {
                "fragments": [],
                "text": "Field Extraction by Hybrid Incremental and A-Priori Structural Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper proposes a hybrid system combining incremental learning by means of itf-df statistics and a-priori generic models, and reports in the experimental section the results obtained with a dataset of real invoices."
            },
            "venue": {
                "fragments": [],
                "text": "2018 13th IAPR International Workshop on Document Analysis Systems (DAS)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3444569"
                        ],
                        "name": "Petar Velickovic",
                        "slug": "Petar-Velickovic",
                        "structuredName": {
                            "firstName": "Petar",
                            "lastName": "Velickovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petar Velickovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7153363"
                        ],
                        "name": "Guillem Cucurull",
                        "slug": "Guillem-Cucurull",
                        "structuredName": {
                            "firstName": "Guillem",
                            "lastName": "Cucurull",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guillem Cucurull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8742492"
                        ],
                        "name": "Arantxa Casanova",
                        "slug": "Arantxa-Casanova",
                        "structuredName": {
                            "firstName": "Arantxa",
                            "lastName": "Casanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arantxa Casanova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144290131"
                        ],
                        "name": "Adriana Romero",
                        "slug": "Adriana-Romero",
                        "structuredName": {
                            "firstName": "Adriana",
                            "lastName": "Romero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adriana Romero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144269589"
                        ],
                        "name": "P. Lio\u2019",
                        "slug": "P.-Lio\u2019",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Lio\u2019",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lio\u2019"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " multiple GCN layers to keep the information from previous layers and reduce overfitting: hl+1 i = eLU &apos; \u203a \u00ab 1 Nt N \u00d5N t t=1 j\u2208N(i)  Wl t h l i +b l  +hl i \u201c \ufb01 \u2039 (6) We also experiment with GAT[35] and G-Trans[17] layers in initial experiments, but results show worse performance than GCN. 3.4 Entity extraction With the layout encoding from GCN and the text encoding from the pre-trained language"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "el, GCN architecture is applied to encode the positional and formatting relationship between the text nodes. Attention mechanisms have been added to graph neural networks for more expressiveness. GAT [35] enables specifying different weights to different nodes and outperforms its convolutional counterparts on knowledge graph dataset. Then Graph Transformers[17] present an end-to-end system for graph-t"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3292002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33998aff64ce51df8dee45989cdca4b6b1329ec4",
            "isKey": true,
            "numCitedBy": 5524,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training)."
            },
            "slug": "Graph-Attention-Networks-Velickovic-Cucurull",
            "title": {
                "fragments": [],
                "text": "Graph Attention Networks"
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802339"
                        ],
                        "name": "M. Pazienza",
                        "slug": "M.-Pazienza",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Pazienza",
                            "middleNames": [
                                "Teresa"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pazienza"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1102517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06894f06b6411af67a0ffde61d27efd86a5d31c7",
            "isKey": false,
            "numCitedBy": 916,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "It seems widely agreed that IE (Information Extraction) is now a tested language technology that has reached precision+recall values that put it in about the same position as Information Retrieval and Machine Translation, both of which are widely used commercially. There is also a clear range of practical applications that would be eased by the sort of template-style data that IE provides. The problem for wider deployment of the technology is adaptability: the ability to customize IE rapidly to new domains. In this paper we discuss some methods that have been tried to ease this problem, and to create something more rapid than the bench-mark one-month figure, which was roughly what ARPA teams in IE needed to adapt an existing system by hand to a new domain of corpora and templates. An important distinction in discussing the issue is the degree to which a user can be assumed to know what is wanted, to have preexisting templates ready to hand, as opposed to a user who has a vague idea of what is needed from a corpus. We shall discuss attempts to derive templates directly from corpora; to derive knowledge structures and lexicons directly from corpora, including discussion of the recent LE project ECRAN which attempted to tune existing lexicons to new corpora. An important issue is how far established methods in Information Retrieval of tuning to a user\u2019s needs with feedback at an interface can be transferred to IE."
            },
            "slug": "Information-Extraction-Pazienza",
            "title": {
                "fragments": [],
                "text": "Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper discusses attempts to derive templates directly from corpora; to derive knowledge structures and lexicons directly from Corpora, including discussion of the recent LE project ECRAN which attempted to tune existing lexicons to new corpora."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2699239"
                        ],
                        "name": "Yifan Peng",
                        "slug": "Yifan-Peng",
                        "structuredName": {
                            "firstName": "Yifan",
                            "lastName": "Peng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yifan Peng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7189717"
                        ],
                        "name": "Shankai Yan",
                        "slug": "Shankai-Yan",
                        "structuredName": {
                            "firstName": "Shankai",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shankai Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144202084"
                        ],
                        "name": "Zhiyong Lu",
                        "slug": "Zhiyong-Lu",
                        "structuredName": {
                            "firstName": "Zhiyong",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiyong Lu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 189762009,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "347bac45298f37cd83c3e79d99b826dc65a70c46",
            "isKey": false,
            "numCitedBy": 337,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Inspired by the success of the General Language Understanding Evaluation benchmark, we introduce the Biomedical Language Understanding Evaluation (BLUE) benchmark to facilitate research in the development of pre-training language representations in the biomedicine domain. The benchmark consists of five tasks with ten datasets that cover both biomedical and clinical texts with different dataset sizes and difficulties. We also evaluate several baselines based on BERT and ELMo and find that the BERT model pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results. We make the datasets, pre-trained models, and codes publicly available at https://github.com/ ncbi-nlp/BLUE_Benchmark."
            },
            "slug": "Transfer-Learning-in-Biomedical-Natural-Language-An-Peng-Yan",
            "title": {
                "fragments": [],
                "text": "Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The Biomedical Language Understanding Evaluation (BLUE) benchmark is introduced to facilitate research in the development of pre-training language representations in the biomedicine domain and it is found that the BERT model pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results."
            },
            "venue": {
                "fragments": [],
                "text": "BioNLP@ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145654957"
                        ],
                        "name": "Daniel Schuster",
                        "slug": "Daniel-Schuster",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Schuster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Schuster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2956206"
                        ],
                        "name": "Klemens Muthmann",
                        "slug": "Klemens-Muthmann",
                        "structuredName": {
                            "firstName": "Klemens",
                            "lastName": "Muthmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klemens Muthmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054613265"
                        ],
                        "name": "D. Esser",
                        "slug": "D.-Esser",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Esser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Esser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145417024"
                        ],
                        "name": "A. Schill",
                        "slug": "A.-Schill",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Schill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113458452"
                        ],
                        "name": "Michael Berger",
                        "slug": "Michael-Berger",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Berger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Berger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2906706"
                        ],
                        "name": "C. Weidling",
                        "slug": "C.-Weidling",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Weidling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Weidling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2652700"
                        ],
                        "name": "Kamil Aliyev",
                        "slug": "Kamil-Aliyev",
                        "structuredName": {
                            "firstName": "Kamil",
                            "lastName": "Aliyev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kamil Aliyev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1942133"
                        ],
                        "name": "A. Hofmeier",
                        "slug": "A.-Hofmeier",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Hofmeier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hofmeier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "features, and [5] builds a more stable system using tf-idf algorithm and a large number of human-designed features. Other document-level entity extraction systems combine rules and statistical models [2, 32]. Although it is possible to craft high-precisionrulesinsomeclosed-domainapplications,rule-based systems are usually associated with extensive human effort and cannot be rapidly adapted to new domains"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18934920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87dee6b4a5fcbab541b45a967c24030df6cee29b",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic information extraction from scanned business documents is especially valuable in the application domain of document archiving. But current systems for automated document processing still require a lot of configuration work that can only be done by experienced users or administrators. We present an approach for information extraction which purely builds on end-user provided training examples and intentionally omits efficient known extraction techniques like rule based extraction that require intense training and/or information extraction expertise. Our evaluation on a large corpus of business documents shows competitive results of above 85% F1-measure on 10 commonly used fields like document type, sender, receiver and date. The system is deployed and used inside the commercial document management system DocuWare."
            },
            "slug": "Intellix-End-User-Trained-Information-Extraction-Schuster-Muthmann",
            "title": {
                "fragments": [],
                "text": "Intellix -- End-User Trained Information Extraction for Document Archiving"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents an approach for information extraction which purely builds on end-user provided training examples and intentionally omits efficient known extraction techniques like rule based extraction that require intense training and/or information extraction expertise."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Skip connection[11] is also applied for multiple GCN layers to keep the information from previous layers and reduce overfitting:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": false,
            "numCitedBy": 95318,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143823474"
                        ],
                        "name": "Mar\u00e7al Rusi\u00f1ol",
                        "slug": "Mar\u00e7al-Rusi\u00f1ol",
                        "structuredName": {
                            "firstName": "Mar\u00e7al",
                            "lastName": "Rusi\u00f1ol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mar\u00e7al Rusi\u00f1ol"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406403963"
                        ],
                        "name": "Tayeb Benkhelfallah",
                        "slug": "Tayeb-Benkhelfallah",
                        "structuredName": {
                            "firstName": "Tayeb",
                            "lastName": "Benkhelfallah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tayeb Benkhelfallah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401920887"
                        ],
                        "name": "V. P. d'Andecy",
                        "slug": "V.-P.-d'Andecy",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "d'Andecy",
                            "middleNames": [
                                "Poulain"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. P. d'Andecy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ormation extraction which is a relatively new research topic. We roughly divide the current progress of the approaches on this problem into three categories. The first category is rule-based systems. [30] describes an invoice extraction system using a number of rules and empirical features, and [5] builds a more stable system using tf-idf algorithm and a large number of human-designed features. Other "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12155580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3170d280095b2198570073eaa068d6b2946334e3",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present an incremental framework aimed at extracting field information from administrative document images in the context of a Digital Mail-room scenario. Given a single training sample in which the user has marked which fields have to be extracted from a particular document class, a document model representing structural relationships among words is built. This model is incrementally refined as the system processes more and more documents from the same class. A reformulation of the tf-idf statistic scheme allows to adjust the importance weights of the structural relationships among words. We report in the experimental section our results obtained with a large dataset of real invoices."
            },
            "slug": "Field-Extraction-from-Administrative-Documents-by-Rusi\u00f1ol-Benkhelfallah",
            "title": {
                "fragments": [],
                "text": "Field Extraction from Administrative Documents by Incremental Structural Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "An incremental framework aimed at extracting field information from administrative document images in the context of a Digital Mail-room scenario is presented and results obtained with a large dataset of real invoices are reported."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11323179"
                        ],
                        "name": "Yinhan Liu",
                        "slug": "Yinhan-Liu",
                        "structuredName": {
                            "firstName": "Yinhan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yinhan Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40511414"
                        ],
                        "name": "Myle Ott",
                        "slug": "Myle-Ott",
                        "structuredName": {
                            "firstName": "Myle",
                            "lastName": "Ott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Myle Ott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39589154"
                        ],
                        "name": "Naman Goyal",
                        "slug": "Naman-Goyal",
                        "structuredName": {
                            "firstName": "Naman",
                            "lastName": "Goyal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naman Goyal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3048577"
                        ],
                        "name": "Jingfei Du",
                        "slug": "Jingfei-Du",
                        "structuredName": {
                            "firstName": "Jingfei",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingfei Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144863691"
                        ],
                        "name": "Mandar Joshi",
                        "slug": "Mandar-Joshi",
                        "structuredName": {
                            "firstName": "Mandar",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mandar Joshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50536468"
                        ],
                        "name": "Danqi Chen",
                        "slug": "Danqi-Chen",
                        "structuredName": {
                            "firstName": "Danqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35084211"
                        ],
                        "name": "M. Lewis",
                        "slug": "M.-Lewis",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Lewis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759422"
                        ],
                        "name": "Veselin Stoyanov",
                        "slug": "Veselin-Stoyanov",
                        "structuredName": {
                            "firstName": "Veselin",
                            "lastName": "Stoyanov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Veselin Stoyanov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " achieve high accuracy even if the data size of the specific task is not large enough, when the models are initialized with pre-trained BERT weights. In our work, we use the pre-trained RoBERTa model [20], which is similar to BERT in architecture but tuned with different objectives on larger data, as the encoder backbone to obtain expressive representations of text. Given a tokenized text box si = (\u03c9 "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ned to predict these masked tokens given the contexts. In the original BERT implementation, masking is performed during data preprocessing which resulting in a static mask. We fine-tune our task with [20]\u2019s MLM implementation that use a dynamic masking strategy, which generates the masking patterns during training. In addition to using these two fine-tuning objectives separately, we also experiment wi"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ith pre-trained LMs. Our baseline text encoder is based on pre-trained transformer-based [6] language models that have recently brought significant performance gains in many NLP tasks. We use RoBERTa [20] to extract information from plain text as baseline and use its architecture as our encoder backbone. Then a GCN-based graph module is added on top of the RoBERTa network, sothatthevisualinformationof"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "der Different from some existing works [19, 28] that encode words or sentences using the standard BiLSTM-CRF[33], we take advantage of pre-trained transformer-based language models influenced by BERT [6, 20] to perform text feature extraction as they are much more expressive. The BERT model is based on the multi-layer bidirectional transformer [34] architecture that effectively encodes a sequence of toke"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 198953378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
            "isKey": true,
            "numCitedBy": 7266,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code."
            },
            "slug": "RoBERTa:-A-Robustly-Optimized-BERT-Pretraining-Liu-Ott",
            "title": {
                "fragments": [],
                "text": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is found that BERT was significantly undertrained, and can match or exceed the performance of every model published after it, and the best model achieves state-of-the-art results on GLUE, RACE and SQuAD."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41016725"
                        ],
                        "name": "Thomas Kipf",
                        "slug": "Thomas-Kipf",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kipf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Kipf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[28] introduces GraphIE, which integrates Graph Convolutional Network (GCN [16]) with Bi-LSTM for sequence tagging and uses the GCN to encode visual features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "GCN [16]models graph-structured data based on an efficient variant of convolutional neural networks, which has been proved effective in many NLP tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We use Graph Convolutional Network (GCN) [16] tomodel the graph context in ourmodel, where nodes encode text-box level text and format information and edges capture the layout information of the whole page."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3144218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36eff562f65125511b5dfab68ce7f7a943c27478",
            "isKey": false,
            "numCitedBy": 11719,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin."
            },
            "slug": "Semi-Supervised-Classification-with-Graph-Networks-Kipf-Welling",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Classification with Graph Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs which outperforms related methods by a significant margin."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41224113"
                        ],
                        "name": "E. Miller",
                        "slug": "E.-Miller",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Miller",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1837031"
                        ],
                        "name": "Nicholas E. Matsakis",
                        "slug": "Nicholas-E.-Matsakis",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Matsakis",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicholas E. Matsakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "As a remedy, the few shot learning task [7, 24] is proposed to build models that can quickly learn from a small number of samples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2699786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7aac1045e6943b4a7978e260a3035662d5b3bf8d",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We define a process called congealing in which elements of a dataset (images) are brought into correspondence with each other jointly, producing a data-defined model. It is based upon minimizing the summed component-wise (pixel-wise) entropies over a continuous set of transforms on the data. One of the biproducts of this minimization is a set of transform, one associated with each original training sample. We then demonstrate a procedure for effectively bringing test data into correspondence with the data-defined model produced in the congealing process. Subsequently; we develop a probability density over the set of transforms that arose from the congealing process. We suggest that this density over transforms may be shared by many classes, and demonstrate how using this density as \"prior knowledge\" can be used to develop a classifier based on only a single training example for each class."
            },
            "slug": "Learning-from-one-example-through-shared-densities-Miller-Matsakis",
            "title": {
                "fragments": [],
                "text": "Learning from one example through shared densities on transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A probability density over the set of transforms that arose from the congealing process is developed, and it is suggested that this density over transforms may be shared by many classes, and used to develop a classifier based on only a single training example for each class."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398126946"
                        ],
                        "name": "K. Santosh",
                        "slug": "K.-Santosh",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Santosh",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Santosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2128453"
                        ],
                        "name": "A. Bela\u00efd",
                        "slug": "A.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bela\u00efd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[31] first performs graphmining in a document with a set of key-fields selected by clients, in order to learn the pattern to extract information in the absence of clients."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8588359,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1f66bd960ea0e24b723c926fa7a45b3e337e739",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address a client-driven approach to automatically extract information content within the table in document images. We start with a graph-based representation of a set of key-fields selected by clients and perform graph mining in a document in order to learn them to produce a model. Such models are aimed to use to extract information content in the absence of clients. To avoid NP-hard general problem, our graph matching is based on relation assignment to see whether pairs of nodes are semantically identical. We have validated the concept by using a real-world industrial problem."
            },
            "slug": "Pattern-Based-Approach-to-Table-Extraction-Santosh-Bela\u00efd",
            "title": {
                "fragments": [],
                "text": "Pattern-Based Approach to Table Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper starts with a graph-based representation of a set of key-fields selected by clients and performs graph mining in a document in order to learn them to produce a model, which is validated by using a real-world industrial problem."
            },
            "venue": {
                "fragments": [],
                "text": "IbPRIA"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32251567"
                        ],
                        "name": "Shikib Mehri",
                        "slug": "Shikib-Mehri",
                        "structuredName": {
                            "firstName": "Shikib",
                            "lastName": "Mehri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shikib Mehri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66879943"
                        ],
                        "name": "E. Razumovskaia",
                        "slug": "E.-Razumovskaia",
                        "structuredName": {
                            "firstName": "Evgeniia",
                            "lastName": "Razumovskaia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Razumovskaia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8200875"
                        ],
                        "name": "Tiancheng Zhao",
                        "slug": "Tiancheng-Zhao",
                        "structuredName": {
                            "firstName": "Tiancheng",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tiancheng Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716325"
                        ],
                        "name": "M. Esk\u00e9nazi",
                        "slug": "M.-Esk\u00e9nazi",
                        "structuredName": {
                            "firstName": "Maxine",
                            "lastName": "Esk\u00e9nazi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Esk\u00e9nazi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "[22] comes up with a pre-training objective predicts casing in the text to address the robustness problem for named entity recognition (NER) systems and [23] introduces four different pre-training objectives for dialog context representation learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 173990539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "535bbc71ef9f8a8c6180c599ded774ff6f4f8258",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper examines various unsupervised pretraining objectives for learning dialog context representations. Two novel methods of pretraining dialog context encoders are proposed, and a total of four methods are examined. Each pretraining objective is fine-tuned and evaluated on a set of downstream dialog tasks using the MultiWoz dataset and strong performance improvement is observed. Further evaluation shows that our pretraining objectives result in not only better performance, but also better convergence, models that are less data hungry and have better domain generalizability."
            },
            "slug": "Pretraining-Methods-for-Dialog-Context-Learning-Mehri-Razumovskaia",
            "title": {
                "fragments": [],
                "text": "Pretraining Methods for Dialog Context Representation Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 90052,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34917892"
                        ],
                        "name": "Djork-Arn\u00e9 Clevert",
                        "slug": "Djork-Arn\u00e9-Clevert",
                        "structuredName": {
                            "firstName": "Djork-Arn\u00e9",
                            "lastName": "Clevert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Djork-Arn\u00e9 Clevert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465270"
                        ],
                        "name": "Thomas Unterthiner",
                        "slug": "Thomas-Unterthiner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Unterthiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Unterthiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "cluding i itself. N is the size of N(i), hl i is the representation of node i at the l-th layer.Wl is the weight, bl is a bias parameter, and the activation function eLU is the exponential linear unit[4] which obtains better performance than other activation functions in initial experiments. Text boxes on a page may have different types of relationships. Some relationships are spatial (e.g. the close"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5273326,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f63e917638553414526a0cc8550de4ad2d83fe7a",
            "isKey": false,
            "numCitedBy": 3667,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the \"exponential linear unit\" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with batch normalization while batch normalization does not improve ELU networks. ELU networks are among the top 10 reported CIFAR-10 results and yield the best published result on CIFAR-100, without resorting to multi-view evaluation or model averaging. On ImageNet, ELU networks considerably speed up learning compared to a ReLU network with the same architecture, obtaining less than 10% classification error for a single crop, single model network."
            },
            "slug": "Fast-and-Accurate-Deep-Network-Learning-by-Linear-Clevert-Unterthiner",
            "title": {
                "fragments": [],
                "text": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The \"exponential linear unit\" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies and significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6953475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "812355cec91fa30bb50e9e992a3549af39e4f6eb",
            "isKey": false,
            "numCitedBy": 2365,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by maximum likelihood (ML) and maximum a posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully."
            },
            "slug": "One-shot-learning-of-object-categories-Fei-Fei-Fergus",
            "title": {
                "fragments": [],
                "text": "One-shot learning of object categories"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is found that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144927151"
                        ],
                        "name": "M. Schuster",
                        "slug": "M.-Schuster",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Schuster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schuster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099761"
                        ],
                        "name": "K. Paliwal",
                        "slug": "K.-Paliwal",
                        "structuredName": {
                            "firstName": "Kuldip",
                            "lastName": "Paliwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Paliwal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "A number of pioneering work has noticed the importance of visual features in information extraction: [19] combines the BiLSTM[33] with graph convolution for information extraction from VRDs for scanned images and has shown substantial improvement on performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 310,
                                "start": 304
                            }
                        ],
                        "text": "More recently, graph neural networks are used to capture structural information in visually rich documents: [19] applies graph modules to encode the visual information with deep neural networks and GraphIE [28] also assumes that the graph structure is ubiquitous in the text, and applies GCN between the BiLSTM encoder-decoder structure to model the layout information in the document."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 88
                            }
                        ],
                        "text": "We compare our systemwith several strong baselines that only take text input, including BiLSTM-CRF and pretrained transformer-based models, which are all widely used for sequence tagging."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "Different from some existing works [19, 28] that encode words or sentences using the standard BiLSTM-CRF[33], we take advantage of pre-trained transformer-based language models influenced by BERT [6, 20] to perform text feature extraction as they are much more expressive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 13
                            }
                        ],
                        "text": "The standard BiLSTM-CRF network we use takes each text segment as an input, and tokens are encoded with the word embeddings vectors."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18375389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e23c34414e66118ecd9b08cf0cd4d016f59b0b85",
            "isKey": true,
            "numCitedBy": 5377,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In the first part of this paper, a regular recurrent neural network (RNN) is extended to a bidirectional recurrent neural network (BRNN). The BRNN can be trained without the limitation of using input information just up to a preset future frame. This is accomplished by training it simultaneously in positive and negative time direction. Structure and training procedure of the proposed network are explained. In regression and classification experiments on artificial data, the proposed structure gives better results than other approaches. For real data, classification experiments for phonemes from the TIMIT database show the same tendency. In the second part of this paper, it is shown how the proposed bidirectional structure can be easily modified to allow efficient estimation of the conditional posterior probability of complete symbol sequences without making any explicit assumption about the shape of the distribution. For this part, experiments on real data are reported."
            },
            "slug": "Bidirectional-recurrent-neural-networks-Schuster-Paliwal",
            "title": {
                "fragments": [],
                "text": "Bidirectional recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how the proposed bidirectional structure can be easily modified to allow efficient estimation of the conditional posterior probability of complete symbol sequences without making any explicit assumption about the shape of the distribution."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2128453"
                        ],
                        "name": "A. Bela\u00efd",
                        "slug": "A.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bela\u00efd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2448729"
                        ],
                        "name": "Y. Bela\u00efd",
                        "slug": "Y.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Yolande",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Bela\u00efd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2633832"
                        ],
                        "name": "L. Valverde",
                        "slug": "L.-Valverde",
                        "structuredName": {
                            "firstName": "Late",
                            "lastName": "Valverde",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valverde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3206043"
                        ],
                        "name": "S. Kebairi",
                        "slug": "S.-Kebairi",
                        "structuredName": {
                            "firstName": "Saddok",
                            "lastName": "Kebairi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kebairi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "features, and [5] builds a more stable system using tf-idf algorithm and a large number of human-designed features. Other document-level entity extraction systems combine rules and statistical models [2, 32]. Although it is possible to craft high-precisionrulesinsomeclosed-domainapplications,rule-based systems are usually associated with extensive human effort and cannot be rapidly adapted to new domains"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18188134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57c91eeb631679450daf44503605e89ac0756d1a",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, an approach for adaptive region segmentation of mail-order forms for high volume application is described. Regions are first identified through a selection of their anchor points described by a constraint graph, illustrating their typographic aspects in the nodes, and their topographical relationships in the arcs. Then the identification of the actual anchor points is performed from a list of textual candidates, using the Arc Consistency Algorithm (AC4). Finally, some contextual heuristics are investigated for properly delimiting the regions. The originality of this approach lies mainly in the absence of a rigid a priori model, replaced by a simple and reliable association of anchor points. The constraint graph used for their description can be easily derived from a general logical definition of their content. Experimental results are overall encouraging and the methodology integration is under execution for commercialization."
            },
            "slug": "Adaptive-technology-for-mail-order-form-Bela\u00efd-Bela\u00efd",
            "title": {
                "fragments": [],
                "text": "Adaptive technology for mail-order form segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An approach for adaptive region segmentation of mail-order forms for high volume application in the absence of a rigid a priori model is described, replaced by a simple and reliable association of anchor points."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 40
                            }
                        ],
                        "text": "As a remedy, the few shot learning task [7, 24] is proposed to build models that can quickly learn from a small number of samples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60977545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb66ae5f36bc84243979c522d8e3f93539cb6a9f",
            "isKey": false,
            "numCitedBy": 3687,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "IEEE-Transactions-on-Pattern-Analysis-and-Machine-Fu",
            "title": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10796472"
                        ],
                        "name": "James H. Martin",
                        "slug": "James-H.-Martin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martin",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James H. Martin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We concatenate all the origin text in Dunseen feeding into the network and train with 30 epochs where the perplexity (Perplexity score is a measurement of how well a probability model predicts a test data and the lower the better [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59755280,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "7e3cc2d92d933feb9b52f6ad8a1e0795a8d60235",
            "isKey": false,
            "numCitedBy": 446,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speech-and-Language-Processing,-2nd-Edition-Jurafsky-Martin",
            "title": {
                "fragments": [],
                "text": "Speech and Language Processing, 2nd Edition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 170
                            }
                        ],
                        "text": "Information extraction (IE) is the process of identifying within text instances of specified classes of entities as well as relations and events involving these entities [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 236152584,
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Extraction: Capabilities and Challenges"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Paliwal . 1997 . Bidirectional recurrent neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans . Signal Process ."
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ", Lukasz Kaiser , and Illia Polosukhin . 2017 . Attention is All you Need"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 24,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 44,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Robust-Layout-aware-IE-for-Visually-Rich-Documents-Wei-He/a03407e7e8a4530d9bb96672e425cfa067f92b76?sort=total-citations"
}