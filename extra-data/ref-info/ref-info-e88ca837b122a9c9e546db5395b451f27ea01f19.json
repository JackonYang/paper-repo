{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2140461"
                        ],
                        "name": "W. Long",
                        "slug": "W.-Long",
                        "structuredName": {
                            "firstName": "Warren",
                            "lastName": "Long",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35964920"
                        ],
                        "name": "Yee-Hong Yang",
                        "slug": "Yee-Hong-Yang",
                        "structuredName": {
                            "firstName": "Yee-Hong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Hong Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32110994,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "794b0a815bc50cb082b5f0cf40ac9607a94c9a74",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Motion provides extra information that can aid in the recognition of objects. One of the most commonly seen objects is, perhaps, the human body. Yet little attention has been paid to the analysis of human motion. One of the key steps required for a successful motion analysis system is the ability to track moving objects. In this paper, we describe a new system called Log-Tracker, which was recently developed for tracking the motion of the different parts of the human body. Occlusion of body parts is termed a forking condition. Two classes of forks as well as the attributes required to classify them are described. Experimental results from two gymnastics sequences indicate that the system is able to track the body parts even when they are occluded for a short period of time. Occlusions that extend for a long period of time still pose problems to Log-Tracker."
            },
            "slug": "Log-Tracker:-an-Attribute-Based-Approach-to-Human-Long-Yang",
            "title": {
                "fragments": [],
                "text": "Log-Tracker: an Attribute-Based Approach to Tracking Human Body Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results from two gymnastics sequences indicate that the new Log-Tracker system is able to track the body parts even when they are occluded for a short period of time, and occlusion of body parts is termed a forking condition."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1995364"
                        ],
                        "name": "Claudette C\u00e9dras",
                        "slug": "Claudette-C\u00e9dras",
                        "structuredName": {
                            "firstName": "Claudette",
                            "lastName": "C\u00e9dras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claudette C\u00e9dras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15425663,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c53c98734b05b640d8ca14ee4835c88b6e9dbb4",
            "isKey": false,
            "numCitedBy": 509,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Motion-based-recognition-a-survey-C\u00e9dras-Shah",
            "title": {
                "fragments": [],
                "text": "Motion-based recognition a survey"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144840247"
                        ],
                        "name": "K. Rangarajan",
                        "slug": "K.-Rangarajan",
                        "structuredName": {
                            "firstName": "Krishnan",
                            "lastName": "Rangarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rangarajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071418866"
                        ],
                        "name": "William Allen",
                        "slug": "William-Allen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Allen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Allen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46407756,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "4a6db6aa3b9308223930fd6e2cfb1a6eee474d5f",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Matching-motion-trajectories-using-scale-space-Rangarajan-Allen",
            "title": {
                "fragments": [],
                "text": "Matching motion trajectories using scale-space"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145286523"
                        ],
                        "name": "K. Rohr",
                        "slug": "K.-Rohr",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Rohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rohr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "[23] K. Rohr, \\Towards Model-Based Recognitionof Human Movements in Image Sequences,\"CVGIP, Image Understanding, Vol.59, No.1,pp.94-115, 1994."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Hogg [10] and Rohr [23]deal with the restricted movement of walking paral-lel to image plane, for which the search space is es-sentially one-dimensional."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "Regarding shape, we felt that simple cylindrical primitives (whether with elliptic XY-cross-sections or not) [10] [7] [23] would not represent body parts such as the head and torso accurately enough, therefore we employ the class of tapered super-quadrics [27], the latter including such diverse shapes as cylinders, spheres, ellipsoids and hyper-rectangles."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Hogg [10] and Rohr [23] deal with the restricted movement of walking parallel to image plane, for which the search space is essentially one-dimensional."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122238372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92ab4fc76e2f085dde81626794b79b5e9d1d00e0",
            "isKey": true,
            "numCitedBy": 491,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The interpretation of the movements of articulated bodies in image sequences is one of the most challenging problems in computer vision. In this contribution, we introduce a model-based approach for the recognition of pedestrians. We represent the human body by a 3D-model consisting of cylinders, whereas for modelling the movement of walking we use data from medical motion studies. The estimation of model parameters in consecutive images is done by applying a Kalman filter. Experimental results are shown for synthetic as well as for real image data."
            },
            "slug": "Towards-model-based-recognition-of-human-movements-Rohr",
            "title": {
                "fragments": [],
                "text": "Towards model-based recognition of human movements in image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model-based approach for the recognition of pedestrians is introduced and the human body is represented by a 3D-model consisting of cylinders, whereas for modelling the movement of walking the authors use data from medical motion studies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2652428"
                        ],
                        "name": "R. Polana",
                        "slug": "R.-Polana",
                        "structuredName": {
                            "firstName": "Ramprasad",
                            "lastName": "Polana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Polana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113399896"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randall",
                            "lastName": "Nelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6353138,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1ee01bf96b5dbd441eabda533fa89da3fa4d916a",
            "isKey": false,
            "numCitedBy": 371,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The recognition of human movements such as walking, running or climbing has been approached previously by tracking a number of feature points and either classifying the trajectories directly or matching them with a high-level model of the movement. A major difficulty with these methods is acquiring and trading the requisite feature points, which are generally specific joints such as knees or angles. This requires previous recognition and/or part segmentation of the actor. We show that the recognition of walking or any repetitive motion activity can be accomplished on the basis of bottom up processing, which does not require the prior identification of specific parts, or classification of the actor. In particular, we demonstrate that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatiotemporal template of motion features. We have implemented a real-time system that can recognize and classify repetitive motion activities in normal gray-scale image sequences.<<ETX>>"
            },
            "slug": "Low-level-recognition-of-human-motion-(or-how-to-Polana-Nelson",
            "title": {
                "fragments": [],
                "text": "Low level recognition of human motion (or how to get your man without finding his body parts)"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is demonstrated that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatiotemporal template of motion features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47265099"
                        ],
                        "name": "F. Perales",
                        "slug": "F.-Perales",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "Perales",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perales"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075317523"
                        ],
                        "name": "J. Torres",
                        "slug": "J.-Torres",
                        "structuredName": {
                            "firstName": "Jesse",
                            "lastName": "Torres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Torres"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 25
                            }
                        ],
                        "text": "[19] F.J. Perales and J. Torres, \\A System for Hu-man Motion Matching between Synthetic andReal Images Based on a Biomechanic Graphi-cal Model,\" IEEE Workshop on Motion of Non-Rigid and Articulated Objects, Austin, 1994."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "So far, existing systems which work on real images following this strategy have their limitations: Perales and Torres [19] describe a system which involves input from a human operator."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 109
                            }
                        ],
                        "text": "So far, existing systems which work on real imagesfollowing this strategy have their limitations: Peralesand Torres [19] describe a system which involves in-put from a human operator."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61493162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bbe276e98cceec07e9363ea23f8074259b6274b",
            "isKey": true,
            "numCitedBy": 33,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for analysis and synthesis of human motion is presented. The system consists of an analysis part and a synthesis part. The analysis part can be used automatically or interactively. The automatic analysis part includes the pre-processing, modeling, matching and interpretation phases. The interactive analysis part includes the same phases but with the possibility of user supervision. We present a global overview of the whole system. The user can define a biomechanic graphical model to represent the human body in a 3D space, and use tools to perform an automatic or interactive supervised matching between the animated model and the real images to recover the motion. The synthesis part uses the results of matching process to show the motion of the human body that is shown in the real images, from any viewpoint. We use specific criteria to match walking persons from different views. Some results and images are presented.<<ETX>>"
            },
            "slug": "A-system-for-human-motion-matching-between-and-real-Perales-Torres",
            "title": {
                "fragments": [],
                "text": "A system for human motion matching between synthetic and real images based on a biomechanic graphical model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The system uses specific criteria to match walking persons from different views and uses the results of matching process to show the motion of the human body that is shown in the real images, from any viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2130172714"
                        ],
                        "name": "Jianming Zhao",
                        "slug": "Jianming-Zhao",
                        "structuredName": {
                            "firstName": "Jianming",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianming Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699200"
                        ],
                        "name": "N. Badler",
                        "slug": "N.-Badler",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Badler",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Badler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 209
                            }
                        ],
                        "text": "The advantage of this is that rigorous mathematical analysis can be applied to solve for the 3-D pose; the problem can be formulated as an inverse kinematics problem [22] or a constrained optimization problem [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 115880876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01c116bc6d87d97bf79ff4cbd0b7695eca9cfb64",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Our goal is to reproduce a human figure's motion with a computer simulated human figure: Given a sequence of perspective projections of a set of feature joints of the moving figure, we tried to recover the original 3D postures through an accurate human figure model and the continuity requirement (temporal coherence) in the sequence. Our approach follows two clues: Given the human figure model, the responsible posture for a frame is constrained by the projections of all the feature joints and, in this limited set of postures we can choose one based on the postures in the previous frames and the temporal coherence, unless there occurs a critical condition, when the projection ray of a feature is perpendicular to the link of which the feature is the distal end. Owing to the fast inverse kinematics algorithm we developed to solve the spatial constraints, we were able to exploit the temporal coherence in projection sequences of frequencies as high as 100 Hz. We used finite state automata to detect critical conditions, and developed various strategies to overcome special difficulties around critical frames. Furthermore, we investigated the impact of errors in linear measurements of body parts on the reconstruction process. Based on mathematical analysis, we proposed some heuristics to discover and recover from the possible modeling errors. To test the theory, we implemented an experimental system. By imposing the temporal coherence constraint whenever possible, this system responds to the incoming images almost linearly: Since the error-prone critical conditions are detected and handled at the very early stage, the system is able to do away with endless recursive backtracking so that only one level of roll-back is needed to handle a limited number of critical conditions whose chances of occurrence are independent of the sampling rate. The system admits generic human motion. It has been tested on synthesized images from actual 3D human motions. Since we knew the original motion, we were able to evaluate results quantitatively. It turned out that the reconstructed motions agreed with the original ones not only in general but also in fine details."
            },
            "slug": "Moving-posture-reconstruction-from-perspective-of-Zhao-Badler",
            "title": {
                "fragments": [],
                "text": "Moving posture reconstruction from perspective projections of jointed figure motion"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work tried to recover the original 3D postures through an accurate human figure model and the continuity requirement (temporal coherence) in the sequence to reproduce a human figure's motion with a computer simulated human figure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144248008"
                        ],
                        "name": "K. Akita",
                        "slug": "K.-Akita",
                        "structuredName": {
                            "firstName": "Koichiro",
                            "lastName": "Akita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Akita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 203
                            }
                        ],
                        "text": "Selfocclusion makes the 2-D tracking problem hard for arbitrary movements and thus existing systems assume some a-priori knowledge of the type of movement and/or the viewpoint under which it is observed [1] [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33099756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c74c4ee1466a7c083ab70fdccfbb3e4e4226c364",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-sequence-analysis-of-real-world-human-motion-Akita",
            "title": {
                "fragments": [],
                "text": "Image sequence analysis of real world human motion"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "DTW usually assumes that the endpoints ofthe two patterns have been accurately located (i.e.segmented)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": ",twist (o), and extension (+) of arm (b) DTW match-ing with T0 (solid), T1 (dashed) and T2 (dashdot),vs. frame-number\n7 AcknowledgementsThe rst author would like to thank Ellen Koopmansfor her support during the MLD experiments and P.J.Narayanan and Pete Rander for their support in ac-quiring the multi-view images at CMU's 3-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 123
                            }
                        ],
                        "text": "An alternative clustering ap-proach is to minimize the sum of distances betweenall pairs of members within a cluster using DTW."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "We illustrate the DTW matching method usingthree movement templates T0, T1, T2 denoting\"waving hello\", \"waving-to-come\" and \"twisting\"."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 237
                            }
                        ],
                        "text": "Furthermore, weighing of the k dimensions in the distance function d(i; j) can be based on the variance of feature values of the di erent patterns of a group, when time-warped to the reference pattern (instead of the \"longest\" one as in [6])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "Therefore, we usethe DTW method at each time instant t of a testsequence, choosing a su ciently large xed time-interval N to search for the reference pattern."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 172
                            }
                        ],
                        "text": "Besides these methods, general pattern matching techniques, able to deal with timesequential data, have been applied to match movement patterns: Dynamic Time Warping (DTW) [6] [26], Hidden Markov Models (HMM) [28] and Neural Networks (NN) [9] [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 170
                            }
                        ],
                        "text": "Besides these methods, general pat-tern matching techniques, able to deal with time-sequential data, have been applied to match move-ment patterns: Dynamic Time Warping (DTW) [6][26], Hidden Markov Models (HMM) [28] and NeuralNetworks (NN) [9] [24]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "This is the approach taken by [20] [26] and [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "See Figure 6.4 Recognition of Movement -DTWWe use the word \"recognition\" to denote a processof classi cation (labeling): given K classes of knownmovement patterns, determine to which class an un-known pattern belongs, if any."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "Figure 4bshow the distance measures computed by DTW, for\nthe three movement templates."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5344867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1807058512ae2934b2be0b43f395d8583ef67303",
            "isKey": true,
            "numCitedBy": 442,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented. Objects are represented using sets of view models, rather than single templates. Stereotypical space-time patterns, i.e., gestures, are then matched to stored gesture patterns using dynamic time warping. Real-time performance is achieved by using special purpose correlation hardware and view prediction to prune as much of the search space as possible. Both view models and view predictions are learned from examples. Results showing tracking and recognition of human hand gestures at over 10 Hz are presented.<<ETX>>"
            },
            "slug": "Space-time-gestures-Darrell-Pentland",
            "title": {
                "fragments": [],
                "text": "Space-time gestures"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented and results showing tracking and recognition of human hand gestures at over 10 Hz are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710918"
                        ],
                        "name": "J. Yamato",
                        "slug": "J.-Yamato",
                        "structuredName": {
                            "firstName": "Junji",
                            "lastName": "Yamato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yamato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708785"
                        ],
                        "name": "J. Ohya",
                        "slug": "J.-Ohya",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ohya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072192824"
                        ],
                        "name": "K. Ishii",
                        "slug": "K.-Ishii",
                        "structuredName": {
                            "firstName": "Kenichiro",
                            "lastName": "Ishii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ishii"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 28489640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45336e96c04ea005b203ff3fc84aa4f4159e8cb0",
            "isKey": false,
            "numCitedBy": 1527,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A human action recognition method based on a hidden Markov model (HMM) is proposed. It is a feature-based bottom-up approach that is characterized by its learning capability and time-scale invariability. To apply HMMs, one set of time-sequential images is transformed into an image feature vector sequence, and the sequence is converted into a symbol sequence by vector quantization. In learning human action categories, the parameters of the HMMs, one per category, are optimized so as to best describe the training sequences from the category. To recognize an observed sequence, the HMM which best matches the sequence is chosen. Experimental results for real time-sequential images of sports scenes show recognition rates higher than 90%. The recognition rate is improved by increasing the number of people used to generate the training data, indicating the possibility of establishing a person-independent action recognizer.<<ETX>>"
            },
            "slug": "Recognizing-human-action-in-time-sequential-images-Yamato-Ohya",
            "title": {
                "fragments": [],
                "text": "Recognizing human action in time-sequential images using hidden Markov model"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The recognition rate is improved by increasing the number of people used to generate the training data, indicating the possibility of establishing a person-independent action recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49540989"
                        ],
                        "name": "Lee W. Campbell",
                        "slug": "Lee-W.-Campbell",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Campbell",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lee W. Campbell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 133
                            }
                        ],
                        "text": "Several meth-ods have been designed (see also overview in [5]):Rangarajan et al. [21] use scale-space, Goddard [8]uses scenarios and Campbell [4] uses a phase-space\nrepresentation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "[21] use scale-space, Goddard [8] uses scenarios and Campbell [4] uses a phase-space"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 136
                            }
                        ],
                        "text": "Problems with singularities can be dealt with by introducing weighing factors or rotating the coordinate system (see also discussion in [4])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 9
                            }
                        ],
                        "text": "[4] L.W. Campbell, Recognizing Classical BalletSteps Using Phase Space Constraints,M.S. The-sis, M.I.T., 1994."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "We prefer not to discard the time component as in [4] of the data since it can help avoid false positive matches between test and reference patterns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 56143053,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d661563689ff85fc3f232cd01dc54ba14eb08858",
            "isKey": true,
            "numCitedBy": 4,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "This work deals with the problem of representing and recognizing human body movements, given XYZ tracking data. Prior approaches by other researchers used a smaller number of classification categories, which demanded less attention to representation. We develop techniques for representation of movements based on space curves in subspaces of a \"phase space.\" The phase space has axes of joint angles and torso location and attitude, and the subspaces are subsets of the axes of the phase space. Using this representation we develop a system for learning new movements from ground truth data by searching for subspaces in which the movement to be learned describes a curve which is easily separated from other movements. We then use the learned representation for recognizing movements in data. We train and test the system on nine fundamental movements from classical ballet by two dancers, and show the system can learn, recognize and segment out five of the movements accurately, but confuses one pair of movements from one dancer and another pair from the other dancer. Finally, we suggest how the system can be improved and extended. Thesis Supervisor: Aaron F. Bobick Title: Assistant Professor of Computational Vision, MIT Media Lab This work was supported in part by a grant from Interval Research. I Nd 1-1 1 1 1 _101"
            },
            "slug": "Recognizing-classical-ballet-steps-using-plase-Campbell",
            "title": {
                "fragments": [],
                "text": "Recognizing classical ballet steps using plase space constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work develops techniques for representation of movements based on space curves in subspaces of a \"phase space\" and develops a system for learning new movements from ground truth data by searching forSubspaces in which the movement to be learned describes a curve which is easily separated from other movements."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798094"
                        ],
                        "name": "A. Downton",
                        "slug": "A.-Downton",
                        "structuredName": {
                            "firstName": "Andy",
                            "lastName": "Downton",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Downton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084976155"
                        ],
                        "name": "H. Drouet",
                        "slug": "H.-Drouet",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Drouet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Drouet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "Regarding shape, we felt that simple cylindrical primitives (whether with elliptic XY-cross-sections or not) [10] [7] [23] would not represent body parts such as the head and torso accurately enough, therefore we employ the class of tapered super-quadrics [27], the latter including such diverse shapes as cylinders, spheres, ellipsoids and hyper-rectangles."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Downton and Drouet [7] attempt to track unconstrained upper-body motion but must conclude that the tracking gets lost due to propagation of errors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 24
                            }
                        ],
                        "text": "[7] A.C. Downton and H. Drouet, \\Model-BasedImage Analysis for Unconstrained Upper-BodyMotion,\" Proceedings International Conferenceon Image Processing and its Applications, pp.274-277, IEE, 1992."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Downton and Drouet [7]attempt to track unconstrained upper-body motionbut must conclude that the tracking gets lost due topropagation of errors."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60614552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b0134c456a71f20dfd2033a720254fd8e39cf2c",
            "isKey": true,
            "numCitedBy": 24,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent research on model-based image coding for videotelephone and videoconferencing applications has mostly been concerned with head motion tracking and typically represents the human head as a 3D wire-frame model with texture-mapped surface features. However, the movements of the arms and hands are also important, particularly in sign language communication, and therefore should be included in the overall model. The paper describes a system which uses an articulated generalised cylindrical human model to track limb movements in a sequence of images. It outlines the closed-loop strategy developed to recognise and track human body motion and presents initial results for a complete implementation of the system."
            },
            "slug": "Model-based-image-analysis-for-unconstrained-human-Downton-Drouet",
            "title": {
                "fragments": [],
                "text": "Model-based image analysis for unconstrained human upper-body motion"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A system which uses an articulated generalised cylindrical human model to track limb movements in a sequence of images to recognise and track human body motion is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14133354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aaf6f7a14ba984b296b524474823e425ab3dd61e",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Passive sensing of human hand and limb motion is important for a wide range of applications from human-computer interaction to athletic performance measurement. High degree of freedom articulated mechanisms like the human hand are difficult to track because of their large state space and complex image appearance. This article describes a model-based hand tracking system, called DigitEyes, that can recover the state of a 27 DOF hand model from gray scale images at speeds of up to 10 Hz. We employ kinematic and geometric hand models, along with a high temporal sampling rate, to decompose global image patterns into incremental, local motions of simple shapes. Hand pose and joint angles are estimated from line and point features extracted from images of unmarked, unadorned hands, taken from one or more viewpoints. We present some preliminary results on a 3D mouse interface based on the DigitEyes sensor."
            },
            "slug": "DigitEyes:-Vision-Based-Human-Hand-Tracking-Rehg-Kanade",
            "title": {
                "fragments": [],
                "text": "DigitEyes: Vision-Based Human Hand Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A model-based hand tracking system that can recover the state of a 27 DOF hand model from gray scale images at speeds of up to 10 Hz is described, and some preliminary results on a 3D mouse interface based on the DigitEyes sensor are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "Regarding shape, we felt that simple cylindrical primitives (whether with elliptic XY-cross-sections or not) [10] [7] [23] would not represent body parts such as the head and torso accurately enough, therefore we employ the class of tapered super-quadrics [27], the latter including such diverse shapes as cylinders, spheres, ellipsoids and hyper-rectangles."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Hogg [10] and Rohr [23] deal with the restricted movement of walking parallel to image plane, for which the search space is essentially one-dimensional."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34873540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92f98b189cec1220d479e3079b942e71b244aa65",
            "isKey": false,
            "numCitedBy": 597,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Model-based-vision:-a-program-to-see-a-walking-Hogg",
            "title": {
                "fragments": [],
                "text": "Model-based vision: a program to see a walking person"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738740"
                        ],
                        "name": "S. B. Kang",
                        "slug": "S.-B.-Kang",
                        "structuredName": {
                            "firstName": "Sing",
                            "lastName": "Kang",
                            "middleNames": [
                                "Bing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. B. Kang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "[25] R. Szeliski and S.B. Kang, \\Recovering 3DShape and Motion from Image Streams UsingNonlinear Least Squares,\" J. Vis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 78
                            }
                        ],
                        "text": "The cameras werecalibrated using a non-linear least square methoddeveloped by Szeliski and Kang [25], kindly madeavailable to us."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "The cameras were calibrated using a non-linear least square method developed by Szeliski and Kang [25], kindly made available to us."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9709913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45d909a6f65878823735b5d36c1f7c33e1dfd2a7",
            "isKey": true,
            "numCitedBy": 330,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A shape and motion estimation algorithm based on nonlinear least squares applied to the tracks of features through time is presented. While the authors' approach requires iteration, it quickly converges to the desired solution, even in the absence of a priori knowledge about the shape or motion. Important features of the algorithm include its ability to handle partial point tracks and true perspective, its ability to use line segment matches and point matches simultaneously, and its use of an object-centered representation for faster and more accurate structure and motion recovery.<<ETX>>"
            },
            "slug": "Recovering-3D-shape-and-motion-from-image-streams-Szeliski-Kang",
            "title": {
                "fragments": [],
                "text": "Recovering 3D Shape and Motion from Image Streams Using Nonlinear Least Squares"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A shape and motion estimation algorithm based on nonlinear least squares applied to the tracks of features through time is presented, using an object-centered representation for faster and more accurate structure and motion recovery."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053178525"
                        ],
                        "name": "G. Johansson",
                        "slug": "G.-Johansson",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "Johansson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Johansson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Johansson [12] used MLD's in his now classic experiments on human perception to show that human observers can almost instantly recognize biological motion patterns even when presented with only a few of these moving data points."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 54046837,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "58ea2fa0580b2117618be6e1cc9658a5c9531dba",
            "isKey": false,
            "numCitedBy": 4094,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports the first phase of a research program on visual perception of motion patterns characteristic of living organisms in locomotion. Such motion patterns in animals and men are termed here as biological motion. They are characterized by a far higher degree of complexity than the patterns of simple mechanical motions usually studied in our laboratories. In everyday perceptions, the visual information from biological motion and from the corresponding figurative contour patterns (the shape of the body) are intermingled. A method for studying information from the motion pattern per se without interference with the form aspect was devised. In short, the motion of the living body was represented by a few bright spots describing the motions of the main joints. It is found that 10\u201312 such elements in adequate motion combinations in proximal stimulus evoke a compelling impression of human walking, running, dancing, etc. The kinetic-geometric model for visual vector analysis originally developed in the study of perception of motion combinations of the mechanical type was applied to these biological motion patterns. The validity of this model in the present context was experimentally tested and the results turned out to be highly positive."
            },
            "slug": "Visual-perception-of-biological-motion-and-a-model-Johansson",
            "title": {
                "fragments": [],
                "text": "Visual perception of biological motion and a model for its analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The kinetic-geometric model for visual vector analysis originally developed in the study of perception of motion combinations of the mechanical type was applied to biological motion patterns and the results turned out to be highly positive."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2172041094"
                        ],
                        "name": "M.K. Leung",
                        "slug": "M.K.-Leung",
                        "structuredName": {
                            "firstName": "M.K.",
                            "lastName": "Leung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M.K. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145457208"
                        ],
                        "name": "Yee Hong Yang",
                        "slug": "Yee-Hong-Yang",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Yang",
                            "middleNames": [
                                "Hong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee Hong Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "2-D Tracking under more general conditions is attempted by [13] and [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 109983501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8471da545f8e1870fc51438e4cdb1aab67beebf",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "To understand human body motion, one has to be able to identify different body parts. Because of the flexibility of the human body, numerous possible configurations are possible. The paper proposes a novel model based approach to label the outline of a human body. Based on the model, key features of the body can then be identified. In addition, we propose the use of the concept of support, a commonly used notion in dance representation. In our work, a support is defined as the structure on which the body rests. The experimental results of the proposed approach in labeling outlines are very encouraging.<<ETX>>"
            },
            "slug": "A-model-based-approach-to-labelling-human-body-Leung-Yang",
            "title": {
                "fragments": [],
                "text": "A model based approach to labelling human body outlines"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel model based approach to label the outline of a human body is proposed and the use of the concept of support, a commonly used notion in dance representation, is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696931"
                        ],
                        "name": "H. Barrow",
                        "slug": "H.-Barrow",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Barrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144592244"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11843441"
                        ],
                        "name": "H. C. Wolf",
                        "slug": "H.-C.-Wolf",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Wolf",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. C. Wolf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1621080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "358a97112cc60d6bfefb352b863fec8a86a39e28",
            "isKey": false,
            "numCitedBy": 873,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Parametric correspondence is a technique for matching images to a three dimensional symbolic reference map. An analytic camera model is used to predict the location and appearance of landmarks in the image, generating a projection for an assumed viewpoint. Correspondence is achieved by adjusting the parameters of the camera model until the appearances of the landmarks optimally match a symbolic description extracted from the image. \n \nThe matching of image and map features is performed rapidly by a new technique, called \"chamfer matching\", that compares the shapes of two collections of shape fragments, at a cost proportional to linear dimension, rather than area. These two techniques permit the matching of spatially extensive features on the basis of shape, which reduces the risk of ambiguous matches and the dependence on viewing conditions inherent in conventional image based correlation matching."
            },
            "slug": "Parametric-Correspondence-and-Chamfer-Matching:-Two-Barrow-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "Parametric Correspondence and Chamfer Matching: Two New Techniques for Image Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The matching of image and map features is performed rapidly by a new technique, called \"chamfer matching\", that compares the shapes of two collections of shape fragments, at a cost proportional to linear dimension, rather than area."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708785"
                        ],
                        "name": "J. Ohya",
                        "slug": "J.-Ohya",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ohya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289052"
                        ],
                        "name": "F. Kishino",
                        "slug": "F.-Kishino",
                        "structuredName": {
                            "firstName": "Fumio",
                            "lastName": "Kishino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kishino"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46946327,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1cc06cf0e8c342903d585a1c22377ce6dbf4af8c",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for estimating human postures at a time instant from multiple images using a genetic algorithm is proposed. The posture parameters to be estimated are assigned to the genes of individuals in the population. For each individual, its fitness evaluates to what extent the multiple human images synthesized by deforming a 3D human model according to the values of the genes are registered to the real multiple human images. Genetic operations such as natural selection, crossover and mutation are performed, and individuals in the next generation are generated. After a certain number of repetitions for these processes, the estimated parameter values are obtained from the individual with the best fitness. Experiments using synthesized human multiple images show promising results."
            },
            "slug": "Human-posture-estimation-from-multiple-images-using-Ohya-Kishino",
            "title": {
                "fragments": [],
                "text": "Human posture estimation from multiple images using genetic algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A new method for estimating human postures at a time instant from multiple images using a genetic algorithm is proposed, and experiments using synthesized human multiple images show promising results."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 12th International Conference on Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074973893"
                        ],
                        "name": "N. Goddard",
                        "slug": "N.-Goddard",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Goddard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Goddard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 103
                            }
                        ],
                        "text": "Several meth-ods have been designed (see also overview in [5]):Rangarajan et al. [21] use scale-space, Goddard [8]uses scenarios and Campbell [4] uses a phase-space\nrepresentation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 7
                            }
                        ],
                        "text": "[8] N. Goddard, \\Incremental Model-Based Dis-crimination of Articulated Movement Directfrom Motion Features,\" IEEE Workshop onMotion of Non-Rigid and Articulated Objects,Austin, 1994."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "[21] use scale-space, Goddard [8] uses scenarios and Campbell [4] uses a phase-space"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "For example, Goddard [8]uses the 2-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "For example, Goddard [8] uses the 2-D angular velocities and orientations of the links as features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58103262,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5057d6fe214435b6df4e54c7e071a910676d2675",
            "isKey": true,
            "numCitedBy": 30,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Discrimination of articulated movement is a central problem in perception. We present a model-based system designed to discriminate articulated movements and demonstrate its capabilities in distinguishing three human gaits. Recognition proceeds directly from uninterpreted visual motion features. The adaptive model of movement, the scenario, is based on discrete parameterized events separated by parameterized time intervals. Experimental results are shown for real data derived from moving light displays, demonstrating the effectiveness of the structured connectionist approach.<<ETX>>"
            },
            "slug": "Incremental-model-based-discrimination-of-movement-Goddard",
            "title": {
                "fragments": [],
                "text": "Incremental model-based discrimination of articulated movement from motion features"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work presents a model-based system designed to discriminate articulated movements and demonstrates its capabilities in distinguishing three human gaits, based on discrete parameterized events separated by parameterized time intervals."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153281777"
                        ],
                        "name": "D. Marr",
                        "slug": "D.-Marr",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Marr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144901036"
                        ],
                        "name": "H. Nishihara",
                        "slug": "H.-Nishihara",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Nishihara",
                            "middleNames": [
                                "Keith"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nishihara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 242
                            }
                        ],
                        "text": "Once 3-D tracking is successfully completed, we have the bene t of being able to derive view-point independent features for movement matching which are directly linked to the body pose: 3-D joint angles dened with respect to a human-centered [15] coordinate system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 43759520,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdf9b8f4de001f5f37bc844efbce1210d581d599",
            "isKey": false,
            "numCitedBy": 2323,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual process can be studied by examining the computational problems associated with deriving useful information from retinal images. In this paper, we apply this approach to the problem of representing three-dimensional shapes for the purpose of recognition. 1. Three criteria, accessibility, scope and uniqueness, and stability and sensitivity, are presented for judging the usefulness of a representation for shape recognition. 2. Three aspects of a representation\u2019s design are considered, (i) the representation\u2019s coordinate system, (ii) its primitives, which are the primary units of shape information used in the representation, and (iii) the organization the representation imposes on the information in its descriptions. 3. In terms of these design issues and the criteria presented, a shape representation for recognition should: (i) use an object-centred coordinate system, (ii) include volumetric primitives of varied sizes, and (iii) have a modular organization. A representation based on a shape\u2019s natural axes (for example the axes identified by a stick figure) follows directly from these choices. 4. The basic process for deriving a shape description in this representation must involve: (i) a means for identifying the natural axes of a shape in its image and (ii) a mechanism for transforming viewer-centred axis specifications to specifications in an object-centred coordinate system. 5. Shape recognition involves: (i) a collection of stored shape descriptions, and (ii) various indexes into the collection that allow a newly derived description to be associated with an appropriate stored description. The most important of these indexes allows shape recognition to proceed conservatively from the general to the specific based on the specificity of the information available from the image. 6. New constraints supplied by a conservative recognition process can be used to extract more information from the image. A relaxation process for carrying out this constraint analysis is described."
            },
            "slug": "Representation-and-recognition-of-the-spatial-of-Marr-Nishihara",
            "title": {
                "fragments": [],
                "text": "Representation and recognition of the spatial organization of three-dimensional shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The human visual process can be studied by examining the computational problems associated with deriving useful information from retinal images by applying the approach to the problem of representing three-dimensional shapes for the purpose of recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Royal Society of London. Series B. Biological Sciences"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2173222171"
                        ],
                        "name": "K. Takahashi",
                        "slug": "K.-Takahashi",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Takahashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Takahashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2006078"
                        ],
                        "name": "S. Seki",
                        "slug": "S.-Seki",
                        "structuredName": {
                            "firstName": "Susumu",
                            "lastName": "Seki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070443345"
                        ],
                        "name": "E. Kojima",
                        "slug": "E.-Kojima",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Kojima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kojima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776022"
                        ],
                        "name": "R. Oka",
                        "slug": "R.-Oka",
                        "structuredName": {
                            "firstName": "Ryu-ichi",
                            "lastName": "Oka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Oka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61151940,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "555167ea3a8bc88f10c992d9c8371c829148f2bd",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing dexterous manipulation actions that we usually perform using our hands. Our method is based on model representation using spatio-temporal vector fields and a spotting algorithm that gives segmentation-free and frame-by-frame recognition. We propose a multiview motion model that is composed of several standard sequence patterns made from different viewpoints. Results indicate that our method recognizes dexterous manipulations correctly, even if the viewing direction of the input images deviates from those of standard sequence patterns.<<ETX>>"
            },
            "slug": "Recognition-of-dexterous-manipulations-from-images-Takahashi-Seki",
            "title": {
                "fragments": [],
                "text": "Recognition of dexterous manipulations from time-varying images"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Results indicate that the method recognizes dexterous manipulations correctly, even if the viewing direction of the input images deviates from those of standard sequence patterns."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2874997"
                        ],
                        "name": "S. Niyogi",
                        "slug": "S.-Niyogi",
                        "structuredName": {
                            "firstName": "Sourabh",
                            "lastName": "Niyogi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Niyogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 207
                            }
                        ],
                        "text": "Selfocclusion makes the 2-D tracking problem hard for arbitrary movements and thus existing systems assume some a-priori knowledge of the type of movement and/or the viewpoint under which it is observed [1] [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18566850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57854a0e8309af7ad6f5d9612e20e2ba1a171a96",
            "isKey": false,
            "numCitedBy": 661,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel algorithm for gait analysis. A person walking frontoparallel to the image plane generates a characteristic \"braided\" pattern in a spatiotemporal (XYT) volume. Our algorithm detects this pattern, and fits it with a set of spatiotemporal snakes. The snakes can be used to find the bounding contours of the walker. The contours vary over time in a manner characteristic of each walker. Individual gaits can be recognized by applying standard pattern recognition techniques to the contour signals.<<ETX>>"
            },
            "slug": "Analyzing-and-recognizing-walking-figures-in-XYT-Niyogi-Adelson",
            "title": {
                "fragments": [],
                "text": "Analyzing and recognizing walking figures in XYT"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A novel algorithm for gait analysis that fits a characteristic \"braided\" pattern in a spatiotemporal volume, and fits it with a set of spatiotsemporal snakes that can be used to find the bounding contours of the walker."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942359"
                        ],
                        "name": "M. Rosenblum",
                        "slug": "M.-Rosenblum",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Rosenblum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosenblum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069324532"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 145637328,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b82984419868beff9512ddf4e1ec314c44174df7",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A radial basis function network architecture is developed that learns the correlation of facial feature motion patterns and human emotions. We describe a hierarchical approach which at the highest level identifies emotions, at the mid level determines motion of facial features, and at the low level recovers motion directions. Individual emotion networks were trained to recognize the 'smile' and 'surprise' emotions. Each emotion network was trained by viewing a set of sequences of one emotion for many subjects. The trained neural network was then tested for retention, extrapolation and rejection ability. Success rates were about 88% for retention, 73% for extrapolation, and 79% for rejection.<<ETX>>"
            },
            "slug": "Human-emotion-recognition-from-motion-using-a-basis-Rosenblum-Yacoob",
            "title": {
                "fragments": [],
                "text": "Human emotion recognition from motion using a radial basis function network architecture"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861837498"
                        ],
                        "name": "G. G. Stokes",
                        "slug": "G.-G.-Stokes",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Stokes",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. G. Stokes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 209
                            }
                        ],
                        "text": "Besides these methods, general pattern matching techniques, able to deal with timesequential data, have been applied to match movement patterns: Dynamic Time Warping (DTW) [6] [26], Hidden Markov Models (HMM) [28] and Neural Networks (NN) [9] [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 206
                            }
                        ],
                        "text": "Besides these methods, general pat-tern matching techniques, able to deal with time-sequential data, have been applied to match move-ment patterns: Dynamic Time Warping (DTW) [6][26], Hidden Markov Models (HMM) [28] and NeuralNetworks (NN) [9] [24]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 221060727,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "90006064cafcb0a9ad8a30cffeb56efe7e14129b",
            "isKey": false,
            "numCitedBy": 672670,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "however (for it was the literal soul of the life of the Redeemer, John xv. io), is the peculiar token of fellowship with the Redeemer. That love to God (what is meant here is not God\u2019s love to men) is described in such a case as a perfect love (love that has been perfected), involves no difficulty, for the simple reason that the proposition is purely hypothetical. We must, of course, also take the &dquo;keeping&dquo; in all its stringency. John knows right well that the case supposed here ncver becomes full reality. &dquo; Hereb)\u2019,&dquo; i.e. from the actual realization of love to God. &dquo; TIli7i 7e)e are ill Hinz &dquo;"
            },
            "slug": "\"J.\"-Stokes",
            "title": {
                "fragments": [],
                "text": "\"J.\""
            },
            "venue": {
                "fragments": [],
                "text": "The New Yale Book of Quotations"
            },
            "year": 2021
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708785"
                        ],
                        "name": "J. Ohya",
                        "slug": "J.-Ohya",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ohya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289052"
                        ],
                        "name": "F. Kishino",
                        "slug": "F.-Kishino",
                        "structuredName": {
                            "firstName": "Fumio",
                            "lastName": "Kishino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kishino"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Also, search techniques replace exhaustive search in the exponential pose parameter space (as in [18])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 64188726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b62a751bdb93106d80c3750979f5a84103428199",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Human-Posture-Detection-from-Trinocular-Images-:-of-Ohya-Kishino",
            "title": {
                "fragments": [],
                "text": "Human Posture Detection from Trinocular Images Using Genetic Algorithm : Posture Estimation of Upper Half Bodies and Fingers"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 256
                            }
                        ],
                        "text": "Regarding shape, we felt that simple cylindrical primitives (whether with elliptic XY-cross-sections or not) [10] [7] [23] would not represent body parts such as the head and torso accurately enough, therefore we employ the class of tapered super-quadrics [27], the latter including such diverse shapes as cylinders, spheres, ellipsoids and hyper-rectangles."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206421674,
            "fieldsOfStudy": [],
            "id": "ba5bb09a21f3a1f52f6e993f175a17ec7fb2a4dd",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic 3D Models with Local and Global Deformations: Deformable Superquadrics"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144968076"
                        ],
                        "name": "M. Jenkin",
                        "slug": "M.-Jenkin",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jenkin",
                            "middleNames": [
                                "R.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jenkin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "We have developed software to do the detection and tracking of markers semi-automatically in 3-D, comparable to [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5065445,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "ea34f5babba62eeb698badd7c46d6a00fe541c61",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Tracking-three-dimensional-moving-light-displays-Jenkin",
            "title": {
                "fragments": [],
                "text": "Tracking three-dimensional moving light displays"
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH 1986"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Performance Tradeoos in Dynamic Time Warping Algorithms for Isolated Word Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. ASSP"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9] use a combination of link orientations and joint positions of the stick gure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 239
                            }
                        ],
                        "text": "Besides these methods, general pattern matching techniques, able to deal with timesequential data, have been applied to match movement patterns: Dynamic Time Warping (DTW) [6] [26], Hidden Markov Models (HMM) [28] and Neural Networks (NN) [9] [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "G"
            },
            "venue": {
                "fragments": [],
                "text": "Xu and S. Tsuji, \\Understanding  Human Motion Patterns,\" ICPR"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "2-D Tracking under more general conditions is attempted by [13] and [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Log-tracker"
            },
            "venue": {
                "fragments": [],
                "text": "an  attribute-based approach to tracking human  body motion,\" International Journal of Pattern  Recognition and Arti cial Intelligence, vol.5,  no.3, pp.439-458"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 197
                            }
                        ],
                        "text": "Indeed, for constrained types of human movement (such as walking parallel to the image plane involving periodic motion), many of these features have been successfully used for classi cation, as in [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "This is the approach taken by [20] [26] and [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Low Level Recog-  nition of Human Motion,\" IEEE Workshop on  Motion of Non-Rigid and Articulated Objects"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adelson, \\Analyzing and Recognizing Walking gures in XYT"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Conf. Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[21] use scale-space, Goddard [8] uses scenarios and Campbell [4] uses a phase-space"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and M"
            },
            "venue": {
                "fragments": [],
                "text": "Shah,  \\Matching Motion Trajectories using Scale  Space,\" Pattern Recognition, vol.26, nr.4,  pp.595-609"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "Several methods have been designed (see also overview in [5]): Rangarajan et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Motion-Based Recog-  nition"
            },
            "venue": {
                "fragments": [],
                "text": "A Survey,\" Technical Report CS-TR-93-  ?, Univ. of Central Florida"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "See [2] for more sophisticated modelling."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Webber,  \\Simulating Humans,"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 15
                            }
                        ],
                        "text": "We have chosen Dynamic Time Warping [16] as ageneral tool to match movement patterns; althoughnot particularly a new method, it is conceptually sim-ple and e ective, as we will see, allowing su cient exibility in time-alignment between test and refer-ence pattern to allow correct classi cation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "We have chosen Dynamic Time Warping [16] as a general tool to match movement patterns; although not particularly a new method, it is conceptually simple and e ective, as we will see, allowing su cient exibility in time-alignment between test and reference pattern to allow correct classi cation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 148
                            }
                        ],
                        "text": "Besides these methods, general pat-tern matching techniques, able to deal with time-sequential data, have been applied to match move-ment patterns: Dynamic Time Warping (DTW) [6][26], Hidden Markov Models (HMM) [28] and NeuralNetworks (NN) [9] [24]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rabinier and A.E. Rosen-  berg, \\Performance Tradeo s in Dynamic Time  Warping Algorithms for Isolated Word Recogni-  tion,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. ASSP, vol.28,"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 243
                            }
                        ],
                        "text": "Besides these methods, general pattern matching techniques, able to deal with timesequential data, have been applied to match movement patterns: Dynamic Time Warping (DTW) [6] [26], Hidden Markov Models (HMM) [28] and Neural Networks (NN) [9] [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Y"
            },
            "venue": {
                "fragments": [],
                "text": "Yacoob and L.S. Davis, \\Hu-  man Emotion Recognition from Motion Using  a Radial Basis Function Network Architecture,\"  IEEE Workshop on Motion of Non-Rigid and  Articulated Objects, Austin"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 176
                            }
                        ],
                        "text": "Besides these methods, general pattern matching techniques, able to deal with timesequential data, have been applied to match movement patterns: Dynamic Time Warping (DTW) [6] [26], Hidden Markov Models (HMM) [28] and Neural Networks (NN) [9] [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "This is the same technique as the Continuous Dynamic Programming (CDP) method used recently by [26], with some di erence in the coe cients of the recursive distance computations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "This is the approach taken by [20] [26] and [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition of Dex-  trous Manipulations from Time-Varying Im-  ages,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Workshop on Motion of Non-Rigid  and Articulated Objects, Austin,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 166
                            }
                        ],
                        "text": "The advantage of this is that rigorous mathematical analysis can be applied to solve for the 3-D pose; the problem can be formulated as an inverse kinematics problem [22] or a constrained optimization problem [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DigitEyes"
            },
            "venue": {
                "fragments": [],
                "text": "Vision-  Based Human Hand Tracking,\" Technical Re-  port CMU-CS-93-220, CMU"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 155
                            }
                        ],
                        "text": "Finally, the similarity measure between model view and actual scene is based on arbitrary edge contours rather than straight lines, using chamfer matching [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parametric Correspon-  dence and Chamfer Matching: two new tech-  niques for image matching,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IJCAI,"
            },
            "year": 1977
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 20
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 41,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Towards-3-D-model-based-tracking-and-recognition-of-Gavrila-Davis/e88ca837b122a9c9e546db5395b451f27ea01f19?sort=total-citations"
}